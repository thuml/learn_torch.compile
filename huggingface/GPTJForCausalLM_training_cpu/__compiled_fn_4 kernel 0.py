
from ctypes import c_void_p, c_long
import torch
import math
import random
import os
import tempfile
from math import inf, nan
from torch._inductor.hooks import run_intermediate_hooks
from torch._inductor.utils import maybe_profile
from torch._inductor.codegen.memory_planning import _align as align

from torch import device, empty, empty_strided
from torch._inductor.codecache import AsyncCompile
from torch._inductor.select_algorithm import extern_kernels

aten = torch.ops.aten
inductor_ops = torch.ops.inductor
assert_size_stride = torch._C._dynamo.guards.assert_size_stride
alloc_from_pool = torch.ops.inductor._alloc_from_pool
reinterpret_tensor = torch.ops.inductor._reinterpret_tensor
async_compile = AsyncCompile()


cpp_fused_nll_loss_backward_nll_loss_forward_0 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const long* in_ptr0,
                       float* out_ptr0,
                       long* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(6400800L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = static_cast<float>(0.0);
                auto tmp1 = at::vec::Vectorized<float>(tmp0);
                tmp1.store(out_ptr0 + static_cast<long>(x0));
            }
        }
        #pragma omp single
        {
            {
                #pragma GCC ivdep
                for(long x0=static_cast<long>(0L); x0<static_cast<long>(127L); x0+=static_cast<long>(1L))
                {
                    auto tmp0 = in_ptr0[static_cast<long>(1L + x0)];
                    auto tmp1 = static_cast<long>(-100);
                    auto tmp2 = tmp0 != tmp1;
                    auto tmp3 = static_cast<long>(0);
                    auto tmp4 = tmp2 ? tmp0 : tmp3;
                    out_ptr1[static_cast<long>(x0)] = tmp4;
                }
            }
        }
    }
}
''')


cpp_fused__log_softmax_backward_data_add_nll_loss_backward_nll_loss_forward_slice_backward_1 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const long* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(127L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(50400L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (50400L*x0)));
                        auto tmp1 = in_ptr1[static_cast<long>(1L + x0)];
                        auto tmp4 = in_ptr2[static_cast<long>(0L)];
                        auto tmp5 = in_ptr3[static_cast<long>(0L)];
                        auto tmp2 = static_cast<int>(-100);
                        auto tmp3 = tmp1 != tmp2;
                        auto tmp6 = tmp4 / tmp5;
                        auto tmp7 = static_cast<float>(0.0);
                        auto tmp8 = tmp3 ? tmp6 : tmp7;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp0 * tmp9;
                        tmp_acc0_vec = tmp_acc0_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(50400L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1 + (50400L*x0)));
                    auto tmp1 = c10::convert<int>(x0);
                    auto tmp2 = static_cast<int>(127);
                    auto tmp3 = tmp1 < tmp2;
                    auto tmp4 = [&]
                    {
                        auto tmp5 = masked_load(in_ptr0 + static_cast<long>(x1 + (50400L*x0)), to_float_mask(tmp3));
                        auto tmp6 = in_ptr1[static_cast<long>(1L + x0)];
                        auto tmp7 = static_cast<int>(-100);
                        auto tmp8 = tmp6 != tmp7;
                        auto tmp9 = in_ptr2[static_cast<long>(0L)];
                        auto tmp10 = in_ptr3[static_cast<long>(0L)];
                        auto tmp11 = tmp9 / tmp10;
                        auto tmp12 = static_cast<float>(0.0);
                        auto tmp13 = tmp8 ? tmp11 : tmp12;
                        auto tmp14 = at::vec::Vectorized<float>(tmp13);
                        auto tmp15 = tmp5 * tmp14;
                        auto tmp16 = masked_load(in_ptr5 + static_cast<long>(x1 + (50400L*x0)), to_float_mask(tmp3));
                        auto tmp17 = tmp16.exp();
                        auto tmp18 = out_ptr0[static_cast<long>(x0)];
                        auto tmp19 = at::vec::Vectorized<float>(tmp18);
                        auto tmp20 = tmp17 * tmp19;
                        auto tmp21 = tmp15 - tmp20;
                        return tmp21;
                    }
                    ;
                    auto tmp22 = decltype(tmp4())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp4(), to_float_mask(tmp3));
                    auto tmp23 = static_cast<float>(0.0);
                    auto tmp24 = to_float_mask(tmp3);
                    auto tmp25 = at::vec::Vectorized<float>(tmp23);
                    auto tmp26 = decltype(tmp22)::blendv(tmp25, tmp22, tmp24);
                    auto tmp27 = tmp0 + tmp26;
                    tmp27.store(out_ptr1 + static_cast<long>(x1 + (50400L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_native_layer_norm_backward_sum_2 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(50400L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (50400L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = in_ptr4[static_cast<long>(x0)];
                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp7 = out_ptr1[static_cast<long>(x0)];
                    auto tmp10 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp11 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = tmp1 * tmp2;
                    auto tmp4 = static_cast<float>(4096.0);
                    auto tmp5 = at::vec::Vectorized<float>(tmp4);
                    auto tmp6 = tmp3 * tmp5;
                    auto tmp8 = at::vec::Vectorized<float>(tmp7);
                    auto tmp9 = tmp6 - tmp8;
                    auto tmp12 = at::vec::Vectorized<float>(tmp11);
                    auto tmp13 = tmp10 * tmp12;
                    auto tmp14 = tmp9 - tmp13;
                    auto tmp15 = at::vec::Vectorized<float>(tmp0);
                    auto tmp16 = tmp15 * tmp14;
                    tmp16.store(out_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr4 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr5 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_3 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_4 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_5 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_6 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_7 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_8 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_9 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_10 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_11 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_12 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_13 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_14 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_15 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_16 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_17 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_18 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_19 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_20 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_21 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_22 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_23 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       const float* in_ptr7,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    auto out_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr7[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_24 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_25 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_26 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_27 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_28 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_29 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_30 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_31 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_32 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_33 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_34 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_35 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_36 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_37 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_38 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_39 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_40 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_41 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_42 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_43 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_44 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_45 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_46 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_47 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_48 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_49 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_50 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_51 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_52 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_53 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_54 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_55 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_56 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_57 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_58 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_59 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_60 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_61 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_62 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_63 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_64 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_65 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_66 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_67 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_68 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_69 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_70 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_71 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_72 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_73 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_74 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_75 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_76 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_77 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_78 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_79 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_80 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_81 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_82 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_83 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_84 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_85 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_86 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_87 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_88 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_89 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_90 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_91 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_92 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_93 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_94 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_95 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_96 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_97 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_98 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_99 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_100 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_101 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_102 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_103 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_104 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_105 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_106 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_107 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_108 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_109 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_110 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_111 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_112 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_113 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_114 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_115 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_116 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_117 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_118 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_119 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_120 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_121 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_122 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_123 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_124 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_125 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_126 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_127 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_128 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_129 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_130 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_131 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_132 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_133 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_134 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_135 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_136 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_137 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_138 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_139 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_140 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_141 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_142 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_143 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_144 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_145 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_146 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_147 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_148 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_149 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_150 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_151 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_152 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_153 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_154 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_155 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_156 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_157 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_158 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_159 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_160 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_161 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_162 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_163 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_164 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_165 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_166 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_167 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_168 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_169 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_170 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_171 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_172 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_173 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_174 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_175 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_176 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_177 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_178 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_179 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_180 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_181 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_182 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_183 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_184 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_185 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_186 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_187 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_188 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_189 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_190 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_191 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp10 = tmp8 * tmp9;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp10;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp1 = in_ptr6[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp6 = out_ptr1[static_cast<long>(x0)];
                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr2[static_cast<long>(x0)];
                    auto tmp3 = static_cast<float>(4096.0);
                    auto tmp4 = at::vec::Vectorized<float>(tmp3);
                    auto tmp5 = tmp2 * tmp4;
                    auto tmp7 = at::vec::Vectorized<float>(tmp6);
                    auto tmp8 = tmp5 - tmp7;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 * tmp11;
                    auto tmp13 = tmp8 - tmp12;
                    auto tmp14 = at::vec::Vectorized<float>(tmp1);
                    auto tmp15 = tmp14 * tmp13;
                    auto tmp16 = tmp0 + tmp15;
                    tmp16.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_pow_sum_tanh_backward_192 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2097152L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.5);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp0 * tmp4;
                auto tmp7 = tmp6 * tmp6;
                auto tmp8 = static_cast<float>(1.0);
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp9 - tmp7;
                auto tmp11 = tmp5 * tmp10;
                auto tmp12 = static_cast<float>(0.7978845608028654);
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = static_cast<float>(0.044715);
                auto tmp16 = at::vec::Vectorized<float>(tmp15);
                auto tmp17 = tmp14 * tmp16;
                auto tmp18 = tmp1 * tmp1;
                auto tmp19 = static_cast<float>(3.0);
                auto tmp20 = at::vec::Vectorized<float>(tmp19);
                auto tmp21 = tmp18 * tmp20;
                auto tmp22 = tmp17 * tmp21;
                auto tmp23 = tmp14 + tmp22;
                auto tmp24 = tmp6 + tmp9;
                auto tmp25 = tmp0 * tmp24;
                auto tmp26 = tmp25 * tmp3;
                auto tmp27 = tmp23 + tmp26;
                tmp27.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_193 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16384L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16384L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_div_nll_loss_forward_where_194 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       const bool* in_ptr2,
                       const float* in_ptr3,
                       float* out_ptr0)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2048L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(128L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = flag_to_float_vec(in_ptr2 + static_cast<long>(x2 + (2048L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                        auto tmp4 = out_ptr0[static_cast<long>(x1 + (128L*x0))];
                        auto tmp8 = in_ptr3[static_cast<long>(0L)];
                        auto tmp3 = tmp1 * tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp4);
                        auto tmp6 = tmp2 * tmp5;
                        auto tmp7 = tmp3 - tmp6;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 / tmp9;
                        auto tmp11 = static_cast<float>(0.0);
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = decltype(tmp10)::blendv(tmp12, tmp10, tmp0);
                        tmp13.store(in_out_ptr0 + static_cast<long>(x2 + (128L*x1) + (16384L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_clone_mul_neg_slice_backward_195 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(64L); x2+=static_cast<long>(1L))
                    {
                        auto tmp31 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(x2 + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp32 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (128L*x2) + (32768L*x0)));
                        auto tmp34 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr3[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                        auto tmp0 = c10::convert<int>(x2);
                        auto tmp1 = static_cast<int>(1);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = c10::convert<int>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp6 = tmp2 & tmp5;
                        auto tmp7 = [&]
                        {
                            auto tmp8 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp9 = masked_load(in_ptr1 + static_cast<long>(x1 + (256L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (32768L*x0)), to_float_mask(tmp6));
                            auto tmp10 = tmp8 + tmp9;
                            auto tmp11 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))]; return masked_load(tmpbuf, to_float_mask(tmp6)); })();
                            auto tmp12 = tmp10 * tmp11;
                            auto tmp13 = tmp12.neg();
                            return tmp13;
                        }
                        ;
                        auto tmp14 = decltype(tmp7())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp7(), to_float_mask(tmp6));
                        auto tmp15 = static_cast<float>(0.0);
                        auto tmp16 = to_float_mask(tmp6);
                        auto tmp17 = at::vec::Vectorized<float>(tmp15);
                        auto tmp18 = decltype(tmp14)::blendv(tmp17, tmp14, tmp16);
                        auto tmp19 = c10::convert<int>(static_cast<long>(x2) % static_cast<long>(2L));
                        auto tmp20 = tmp19 == tmp4;
                        auto tmp21 = [&]
                        {
                            auto tmp22 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x1) + (256L*x1_inner) + (32768L*x0))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp23 = masked_load(in_ptr1 + static_cast<long>(128L + x1 + (256L*(c10::div_floor_integer(x2, 2L))) + (32768L*x0)), to_float_mask(tmp20));
                            auto tmp24 = tmp22 + tmp23;
                            auto tmp25 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr2[static_cast<long>((64L*x1) + (64L*x1_inner) + (c10::div_floor_integer(x2, 2L)))]; return masked_load(tmpbuf, to_float_mask(tmp20)); })();
                            auto tmp26 = tmp24 * tmp25;
                            return tmp26;
                        }
                        ;
                        auto tmp27 = decltype(tmp21())::blendv(at::vec::Vectorized<float>(static_cast<float>(0.0)), tmp21(), to_float_mask(tmp20));
                        auto tmp28 = to_float_mask(tmp20);
                        auto tmp29 = decltype(tmp27)::blendv(tmp17, tmp27, tmp28);
                        auto tmp30 = tmp18 + tmp29;
                        auto tmp33 = tmp31 + tmp32;
                        auto tmp35 = tmp33 * tmp34;
                        auto tmp36 = tmp30 + tmp35;
                        { __at_align__ float tmpbuf[8*sizeof(float)/sizeof(float)]; tmp36.store(tmpbuf); for (long x1_inner = 0; x1_inner < 8; x1_inner++) out_ptr0[static_cast<long>(x2 + (64L*x1) + (64L*x1_inner) + (8192L*x0))] = tmpbuf[x1_inner]; }
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x2 + (256L*x1) + (32768L*x0)));
                        auto tmp2 = tmp0 + tmp1;
                        tmp2.store(out_ptr1 + static_cast<long>(x2 + (256L*x0) + (4096L*x1)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_slice_backward_196 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp5 = in_ptr1[static_cast<long>(x0 + (128L*x2) + (32768L*x1))];
                            auto tmp6 = decltype(tmp4)(tmp4 + tmp5);
                            return tmp6;
                        }
                        ;
                        auto tmp7 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp8 = static_cast<float>(0.0);
                        auto tmp9 = tmp2 ? tmp7 : tmp8;
                        auto tmp10 = tmp0 < tmp1;
                        auto tmp11 = [&]
                        {
                            auto tmp12 = in_ptr2[static_cast<long>(x2 + (64L*x0) + (8192L*x1))];
                            return tmp12;
                        }
                        ;
                        auto tmp13 = tmp10 ? tmp11() : static_cast<decltype(tmp11())>(0.0);
                        auto tmp14 = tmp10 ? tmp13 : tmp8;
                        auto tmp15 = decltype(tmp9)(tmp9 + tmp14);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp15;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_neg_slice_backward_197 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(256L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = c10::convert<long>(x2);
                        auto tmp1 = static_cast<long>(64);
                        auto tmp2 = tmp0 >= tmp1;
                        auto tmp3 = [&]
                        {
                            auto tmp4 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            return tmp4;
                        }
                        ;
                        auto tmp5 = tmp2 ? tmp3() : static_cast<decltype(tmp3())>(0.0);
                        auto tmp6 = static_cast<float>(0.0);
                        auto tmp7 = tmp2 ? tmp5 : tmp6;
                        auto tmp8 = tmp0 < tmp1;
                        auto tmp9 = [&]
                        {
                            auto tmp10 = c10::convert<long>(x2);
                            auto tmp11 = static_cast<long>(1);
                            auto tmp12 = tmp10 >= tmp11;
                            auto tmp13 = c10::convert<long>(static_cast<long>(((-1L) + x2)) % static_cast<long>(2L));
                            auto tmp14 = static_cast<long>(0);
                            auto tmp15 = tmp13 == tmp14;
                            auto tmp16 = tmp12 & tmp15;
                            auto tmp17 = [&]
                            {
                                auto tmp18 = in_ptr0[static_cast<long>((2L*(c10::div_floor_integer(((-1L) + x2), 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp19 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(((-1L) + x2), 2L)) % static_cast<long>(32L)))];
                                auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                                auto tmp21 = decltype(tmp20)(-tmp20);
                                return tmp21;
                            }
                            ;
                            auto tmp22 = tmp16 ? tmp17() : static_cast<decltype(tmp17())>(0.0);
                            auto tmp23 = static_cast<float>(0.0);
                            auto tmp24 = tmp16 ? tmp22 : tmp23;
                            auto tmp25 = c10::convert<long>(static_cast<long>(x2) % static_cast<long>(2L));
                            auto tmp26 = tmp25 == tmp14;
                            auto tmp27 = [&]
                            {
                                auto tmp28 = in_ptr0[static_cast<long>(1L + (2L*(c10::div_floor_integer(x2, 2L))) + (256L*x0) + (32768L*x1))];
                                auto tmp29 = in_ptr1[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer((1L + (2L*(c10::div_floor_integer(x2, 2L)))), 2L)) % static_cast<long>(32L)))];
                                auto tmp30 = decltype(tmp28)(tmp28 * tmp29);
                                return tmp30;
                            }
                            ;
                            auto tmp31 = tmp26 ? tmp27() : static_cast<decltype(tmp27())>(0.0);
                            auto tmp32 = tmp26 ? tmp31 : tmp23;
                            auto tmp33 = decltype(tmp24)(tmp24 + tmp32);
                            auto tmp34 = in_ptr0[static_cast<long>(x2 + (256L*x0) + (32768L*x1))];
                            auto tmp35 = in_ptr2[static_cast<long>((64L*x0) + (static_cast<long>(c10::div_floor_integer(x2, 2L)) % static_cast<long>(32L)))];
                            auto tmp36 = decltype(tmp34)(tmp34 * tmp35);
                            auto tmp37 = decltype(tmp33)(tmp33 + tmp36);
                            return tmp37;
                        }
                        ;
                        auto tmp38 = tmp8 ? tmp9() : static_cast<decltype(tmp9())>(0.0);
                        auto tmp39 = tmp8 ? tmp38 : tmp6;
                        auto tmp40 = decltype(tmp7)(tmp7 + tmp39);
                        out_ptr0[static_cast<long>(x2 + (256L*x1) + (4096L*x0))] = tmp40;
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_embedding_dense_backward_native_layer_norm_native_layer_norm_backward_nll_loss_forward_198 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       const float* in_ptr7,
                       const long* in_ptr8,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1));
                        auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                        auto tmp10 = in_ptr6[static_cast<long>(x0)];
                        auto tmp13 = in_ptr7[static_cast<long>(x0)];
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp8 = tmp6 * tmp7;
                        auto tmp11 = at::vec::Vectorized<float>(tmp10);
                        auto tmp12 = tmp9 - tmp11;
                        auto tmp14 = at::vec::Vectorized<float>(tmp13);
                        auto tmp15 = tmp12 * tmp14;
                        auto tmp16 = tmp8 * tmp15;
                        tmp8.store(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp8;
                        tmp_acc1_vec = tmp_acc1_vec + tmp16;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4096L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(128L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp5 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x0 + (4096L*x1)));
                        auto tmp8 = in_ptr6[static_cast<long>(x1)];
                        auto tmp11 = in_ptr7[static_cast<long>(x1)];
                        auto tmp2 = tmp0 + tmp1;
                        auto tmp4 = tmp2 + tmp3;
                        auto tmp6 = tmp4 + tmp5;
                        auto tmp9 = at::vec::Vectorized<float>(tmp8);
                        auto tmp10 = tmp7 - tmp9;
                        auto tmp12 = at::vec::Vectorized<float>(tmp11);
                        auto tmp13 = tmp10 * tmp12;
                        auto tmp14 = tmp6 * tmp13;
                        tmp_acc0_vec = tmp_acc0_vec + tmp14;
                        tmp_acc1_vec = tmp_acc1_vec + tmp6;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(206438400L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = static_cast<float>(0.0);
                auto tmp1 = at::vec::Vectorized<float>(tmp0);
                tmp1.store(out_ptr5 + static_cast<long>(x0));
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(128L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(4096L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = in_ptr8[static_cast<long>(x0)];
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp4 = in_ptr7[static_cast<long>(x0)];
                    auto tmp7 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp10 = out_ptr1[static_cast<long>(x0)];
                    auto tmp13 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (4096L*x0)));
                    auto tmp14 = in_ptr6[static_cast<long>(x0)];
                    auto tmp19 = out_ptr2[static_cast<long>(x0)];
                    auto tmp1 = static_cast<int>(-1);
                    auto tmp2 = tmp0 == tmp1;
                    auto tmp5 = static_cast<float>(4096.0);
                    auto tmp6 = tmp4 / tmp5;
                    auto tmp8 = at::vec::Vectorized<float>(tmp5);
                    auto tmp9 = tmp7 * tmp8;
                    auto tmp11 = at::vec::Vectorized<float>(tmp10);
                    auto tmp12 = tmp9 - tmp11;
                    auto tmp15 = at::vec::Vectorized<float>(tmp14);
                    auto tmp16 = tmp13 - tmp15;
                    auto tmp17 = at::vec::Vectorized<float>(tmp4);
                    auto tmp18 = tmp16 * tmp17;
                    auto tmp20 = at::vec::Vectorized<float>(tmp19);
                    auto tmp21 = tmp18 * tmp20;
                    auto tmp22 = tmp12 - tmp21;
                    auto tmp23 = at::vec::Vectorized<float>(tmp6);
                    auto tmp24 = tmp23 * tmp22;
                    auto tmp25 = tmp3 + tmp24;
                    auto tmp26 = static_cast<float>(0.0);
                    auto tmp27 = to_float_mask(tmp2);
                    auto tmp28 = at::vec::Vectorized<float>(tmp26);
                    auto tmp29 = decltype(tmp28)::blendv(tmp25, tmp28, tmp27);
                    tmp29.store(in_out_ptr0 + static_cast<long>(x1 + (4096L*x0)));
                }
            }
        }
    }
}
''')


async_compile.wait(globals())
del async_compile

def call(args):
    primals_2, primals_12, primals_22, primals_32, primals_42, primals_52, primals_62, primals_72, primals_82, primals_92, primals_102, primals_112, primals_122, primals_132, primals_142, primals_152, primals_162, primals_172, primals_182, primals_192, primals_202, primals_212, primals_222, primals_232, primals_242, primals_252, primals_262, primals_272, primals_282, primals_288, primals_291, primals_294, primals_297, primals_300, primals_303, primals_306, primals_309, primals_312, primals_315, primals_318, primals_321, primals_324, primals_327, primals_330, primals_333, primals_336, primals_339, primals_342, primals_345, primals_348, primals_351, primals_354, primals_357, primals_360, primals_363, primals_366, primals_369, primals_371, view, embedding, getitem_1, rsqrt, view_2, unsqueeze_3, unsqueeze_5, slice_48, view_24, addmm, tanh, view_28, mul_10, view_30, unsqueeze_16, unsqueeze_18, slice_96, view_52, addmm_2, tanh_1, view_56, mul_20, view_58, unsqueeze_29, unsqueeze_31, slice_144, view_80, addmm_4, tanh_2, view_84, mul_30, view_86, unsqueeze_42, unsqueeze_44, slice_192, view_108, addmm_6, tanh_3, view_112, mul_40, view_114, unsqueeze_55, unsqueeze_57, slice_240, view_136, addmm_8, tanh_4, view_140, mul_50, view_142, unsqueeze_68, unsqueeze_70, slice_288, view_164, addmm_10, tanh_5, view_168, mul_60, view_170, unsqueeze_81, unsqueeze_83, slice_336, view_192, addmm_12, tanh_6, view_196, mul_70, view_198, unsqueeze_94, unsqueeze_96, slice_384, view_220, addmm_14, tanh_7, view_224, mul_80, view_226, unsqueeze_107, unsqueeze_109, slice_432, view_248, addmm_16, tanh_8, view_252, mul_90, view_254, unsqueeze_120, unsqueeze_122, slice_480, view_276, addmm_18, tanh_9, view_280, mul_100, view_282, unsqueeze_133, unsqueeze_135, slice_528, view_304, addmm_20, tanh_10, view_308, mul_110, view_310, unsqueeze_146, unsqueeze_148, slice_576, view_332, addmm_22, tanh_11, view_336, mul_120, view_338, unsqueeze_159, unsqueeze_161, slice_624, view_360, addmm_24, tanh_12, view_364, mul_130, view_366, unsqueeze_172, unsqueeze_174, slice_672, view_388, addmm_26, tanh_13, view_392, mul_140, view_394, unsqueeze_185, unsqueeze_187, slice_720, view_416, addmm_28, tanh_14, view_420, mul_150, view_422, unsqueeze_198, unsqueeze_200, slice_768, view_444, addmm_30, tanh_15, view_448, mul_160, view_450, unsqueeze_211, unsqueeze_213, slice_816, view_472, addmm_32, tanh_16, view_476, mul_170, view_478, unsqueeze_224, unsqueeze_226, slice_864, view_500, addmm_34, tanh_17, view_504, mul_180, view_506, unsqueeze_237, unsqueeze_239, slice_912, view_528, addmm_36, tanh_18, view_532, mul_190, view_534, unsqueeze_250, unsqueeze_252, slice_960, view_556, addmm_38, tanh_19, view_560, mul_200, view_562, unsqueeze_263, unsqueeze_265, slice_1008, view_584, addmm_40, tanh_20, view_588, mul_210, view_590, unsqueeze_276, unsqueeze_278, slice_1056, view_612, addmm_42, tanh_21, view_616, mul_220, view_618, unsqueeze_289, unsqueeze_291, slice_1104, view_640, addmm_44, tanh_22, view_644, mul_230, view_646, unsqueeze_302, unsqueeze_304, slice_1152, view_668, addmm_46, tanh_23, view_672, mul_240, view_674, unsqueeze_315, unsqueeze_317, slice_1200, view_696, addmm_48, tanh_24, view_700, mul_250, view_702, unsqueeze_328, unsqueeze_330, slice_1248, view_724, addmm_50, tanh_25, view_728, mul_260, view_730, unsqueeze_341, unsqueeze_343, slice_1296, view_752, addmm_52, tanh_26, view_756, mul_270, view_758, unsqueeze_354, unsqueeze_356, slice_1344, view_780, addmm_54, tanh_27, view_784, mul_280, view_787, sub_58, convert_element_type, permute_309, div_58, permute_313, permute_317, permute_323, permute_326, permute_327, alias_59, permute_328, permute_329, permute_336, permute_340, permute_344, div_60, permute_346, permute_350, permute_356, permute_359, permute_360, alias_61, permute_361, permute_362, permute_369, permute_373, permute_377, div_62, permute_379, permute_383, permute_389, permute_392, permute_393, alias_63, permute_394, permute_395, permute_402, permute_406, permute_410, div_64, permute_412, permute_416, permute_422, permute_425, permute_426, alias_65, permute_427, permute_428, permute_435, permute_439, permute_443, div_66, permute_445, permute_449, permute_455, permute_458, permute_459, alias_67, permute_460, permute_461, permute_468, permute_472, permute_476, div_68, permute_478, permute_482, permute_488, permute_491, permute_492, alias_69, permute_493, permute_494, permute_501, permute_505, permute_509, div_70, permute_511, permute_515, permute_521, permute_524, permute_525, alias_71, permute_526, permute_527, permute_534, permute_538, permute_542, div_72, permute_544, permute_548, permute_554, permute_557, permute_558, alias_73, permute_559, permute_560, permute_567, permute_571, permute_575, div_74, permute_577, permute_581, permute_587, permute_590, permute_591, alias_75, permute_592, permute_593, permute_600, permute_604, permute_608, div_76, permute_610, permute_614, permute_620, permute_623, permute_624, alias_77, permute_625, permute_626, permute_633, permute_637, permute_641, div_78, permute_643, permute_647, permute_653, permute_656, permute_657, alias_79, permute_658, permute_659, permute_666, permute_670, permute_674, div_80, permute_676, permute_680, permute_686, permute_689, permute_690, alias_81, permute_691, permute_692, permute_699, permute_703, permute_707, div_82, permute_709, permute_713, permute_719, permute_722, permute_723, alias_83, permute_724, permute_725, permute_732, permute_736, permute_740, div_84, permute_742, permute_746, permute_752, permute_755, permute_756, alias_85, permute_757, permute_758, permute_765, permute_769, permute_773, div_86, permute_775, permute_779, permute_785, permute_788, permute_789, alias_87, permute_790, permute_791, permute_798, permute_802, permute_806, div_88, permute_808, permute_812, permute_818, permute_821, permute_822, alias_89, permute_823, permute_824, permute_831, permute_835, permute_839, div_90, permute_841, permute_845, permute_851, permute_854, permute_855, alias_91, permute_856, permute_857, permute_864, permute_868, permute_872, div_92, permute_874, permute_878, permute_884, permute_887, permute_888, alias_93, permute_889, permute_890, permute_897, permute_901, permute_905, div_94, permute_907, permute_911, permute_917, permute_920, permute_921, alias_95, permute_922, permute_923, permute_930, permute_934, permute_938, div_96, permute_940, permute_944, permute_950, permute_953, permute_954, alias_97, permute_955, permute_956, permute_963, permute_967, permute_971, div_98, permute_973, permute_977, permute_983, permute_986, permute_987, alias_99, permute_988, permute_989, permute_996, permute_1000, permute_1004, div_100, permute_1006, permute_1010, permute_1016, permute_1019, permute_1020, alias_101, permute_1021, permute_1022, permute_1029, permute_1033, permute_1037, div_102, permute_1039, permute_1043, permute_1049, permute_1052, permute_1053, alias_103, permute_1054, permute_1055, permute_1062, permute_1066, permute_1070, div_104, permute_1072, permute_1076, permute_1082, permute_1085, permute_1086, alias_105, permute_1087, permute_1088, permute_1095, permute_1099, permute_1103, div_106, permute_1105, permute_1109, permute_1115, permute_1118, permute_1119, alias_107, permute_1120, permute_1121, permute_1128, permute_1132, permute_1136, div_108, permute_1138, permute_1142, permute_1148, permute_1151, permute_1152, alias_109, permute_1153, permute_1154, permute_1161, permute_1165, permute_1169, div_110, permute_1171, permute_1175, permute_1181, permute_1184, permute_1185, alias_111, permute_1186, permute_1187, permute_1194, permute_1198, permute_1202, div_112, permute_1204, permute_1208, permute_1214, permute_1217, permute_1218, alias_113, permute_1219, permute_1220, permute_1227, permute_1231, permute_1235, tangents_1, tangents_2, tangents_3, tangents_4, tangents_5, tangents_6, tangents_7, tangents_8, tangents_9, tangents_10, tangents_11, tangents_12, tangents_13, tangents_14, tangents_15, tangents_16, tangents_17, tangents_18, tangents_19, tangents_20, tangents_21, tangents_22, tangents_23, tangents_24, tangents_25, tangents_26, tangents_27, tangents_28, tangents_29, tangents_30, tangents_31, tangents_32, tangents_33, tangents_34, tangents_35, tangents_36, tangents_37, tangents_38, tangents_39, tangents_40, tangents_41, tangents_42, tangents_43, tangents_44, tangents_45, tangents_46, tangents_47, tangents_48, tangents_49, tangents_50, tangents_51, tangents_52, tangents_53, tangents_54, tangents_55, tangents_56, tangents_57, tangents_58 = args
    args.clear()
    assert_size_stride(primals_2, (4096, ), (1, ))
    assert_size_stride(primals_12, (4096, ), (1, ))
    assert_size_stride(primals_22, (4096, ), (1, ))
    assert_size_stride(primals_32, (4096, ), (1, ))
    assert_size_stride(primals_42, (4096, ), (1, ))
    assert_size_stride(primals_52, (4096, ), (1, ))
    assert_size_stride(primals_62, (4096, ), (1, ))
    assert_size_stride(primals_72, (4096, ), (1, ))
    assert_size_stride(primals_82, (4096, ), (1, ))
    assert_size_stride(primals_92, (4096, ), (1, ))
    assert_size_stride(primals_102, (4096, ), (1, ))
    assert_size_stride(primals_112, (4096, ), (1, ))
    assert_size_stride(primals_122, (4096, ), (1, ))
    assert_size_stride(primals_132, (4096, ), (1, ))
    assert_size_stride(primals_142, (4096, ), (1, ))
    assert_size_stride(primals_152, (4096, ), (1, ))
    assert_size_stride(primals_162, (4096, ), (1, ))
    assert_size_stride(primals_172, (4096, ), (1, ))
    assert_size_stride(primals_182, (4096, ), (1, ))
    assert_size_stride(primals_192, (4096, ), (1, ))
    assert_size_stride(primals_202, (4096, ), (1, ))
    assert_size_stride(primals_212, (4096, ), (1, ))
    assert_size_stride(primals_222, (4096, ), (1, ))
    assert_size_stride(primals_232, (4096, ), (1, ))
    assert_size_stride(primals_242, (4096, ), (1, ))
    assert_size_stride(primals_252, (4096, ), (1, ))
    assert_size_stride(primals_262, (4096, ), (1, ))
    assert_size_stride(primals_272, (4096, ), (1, ))
    assert_size_stride(primals_282, (4096, ), (1, ))
    assert_size_stride(primals_288, (), ())
    assert_size_stride(primals_291, (), ())
    assert_size_stride(primals_294, (), ())
    assert_size_stride(primals_297, (), ())
    assert_size_stride(primals_300, (), ())
    assert_size_stride(primals_303, (), ())
    assert_size_stride(primals_306, (), ())
    assert_size_stride(primals_309, (), ())
    assert_size_stride(primals_312, (), ())
    assert_size_stride(primals_315, (), ())
    assert_size_stride(primals_318, (), ())
    assert_size_stride(primals_321, (), ())
    assert_size_stride(primals_324, (), ())
    assert_size_stride(primals_327, (), ())
    assert_size_stride(primals_330, (), ())
    assert_size_stride(primals_333, (), ())
    assert_size_stride(primals_336, (), ())
    assert_size_stride(primals_339, (), ())
    assert_size_stride(primals_342, (), ())
    assert_size_stride(primals_345, (), ())
    assert_size_stride(primals_348, (), ())
    assert_size_stride(primals_351, (), ())
    assert_size_stride(primals_354, (), ())
    assert_size_stride(primals_357, (), ())
    assert_size_stride(primals_360, (), ())
    assert_size_stride(primals_363, (), ())
    assert_size_stride(primals_366, (), ())
    assert_size_stride(primals_369, (), ())
    assert_size_stride(primals_371, (1, 128), (128, 1))
    assert_size_stride(view, (1, 128), (128, 1))
    assert_size_stride(embedding, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(getitem_1, (1, 128, 1), (128, 1, 1))
    assert_size_stride(rsqrt, (1, 128, 1), (128, 1, 1))
    assert_size_stride(view_2, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_3, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_5, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_48, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_24, (128, 4096), (4096, 1))
    assert_size_stride(addmm, (128, 16384), (16384, 1))
    assert_size_stride(tanh, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_28, (128, 16384), (16384, 1))
    assert_size_stride(mul_10, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_30, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_16, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_18, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_96, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_52, (128, 4096), (4096, 1))
    assert_size_stride(addmm_2, (128, 16384), (16384, 1))
    assert_size_stride(tanh_1, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_56, (128, 16384), (16384, 1))
    assert_size_stride(mul_20, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_58, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_29, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_31, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_144, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_80, (128, 4096), (4096, 1))
    assert_size_stride(addmm_4, (128, 16384), (16384, 1))
    assert_size_stride(tanh_2, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_84, (128, 16384), (16384, 1))
    assert_size_stride(mul_30, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_86, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_42, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_44, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_192, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_108, (128, 4096), (4096, 1))
    assert_size_stride(addmm_6, (128, 16384), (16384, 1))
    assert_size_stride(tanh_3, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_112, (128, 16384), (16384, 1))
    assert_size_stride(mul_40, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_114, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_55, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_57, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_240, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_136, (128, 4096), (4096, 1))
    assert_size_stride(addmm_8, (128, 16384), (16384, 1))
    assert_size_stride(tanh_4, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_140, (128, 16384), (16384, 1))
    assert_size_stride(mul_50, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_142, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_68, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_70, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_288, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_164, (128, 4096), (4096, 1))
    assert_size_stride(addmm_10, (128, 16384), (16384, 1))
    assert_size_stride(tanh_5, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_168, (128, 16384), (16384, 1))
    assert_size_stride(mul_60, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_170, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_81, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_83, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_336, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_192, (128, 4096), (4096, 1))
    assert_size_stride(addmm_12, (128, 16384), (16384, 1))
    assert_size_stride(tanh_6, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_196, (128, 16384), (16384, 1))
    assert_size_stride(mul_70, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_198, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_94, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_96, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_384, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_220, (128, 4096), (4096, 1))
    assert_size_stride(addmm_14, (128, 16384), (16384, 1))
    assert_size_stride(tanh_7, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_224, (128, 16384), (16384, 1))
    assert_size_stride(mul_80, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_226, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_107, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_109, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_432, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_248, (128, 4096), (4096, 1))
    assert_size_stride(addmm_16, (128, 16384), (16384, 1))
    assert_size_stride(tanh_8, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_252, (128, 16384), (16384, 1))
    assert_size_stride(mul_90, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_254, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_120, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_122, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_480, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_276, (128, 4096), (4096, 1))
    assert_size_stride(addmm_18, (128, 16384), (16384, 1))
    assert_size_stride(tanh_9, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_280, (128, 16384), (16384, 1))
    assert_size_stride(mul_100, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_282, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_133, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_135, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_528, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_304, (128, 4096), (4096, 1))
    assert_size_stride(addmm_20, (128, 16384), (16384, 1))
    assert_size_stride(tanh_10, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_308, (128, 16384), (16384, 1))
    assert_size_stride(mul_110, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_310, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_146, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_148, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_576, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_332, (128, 4096), (4096, 1))
    assert_size_stride(addmm_22, (128, 16384), (16384, 1))
    assert_size_stride(tanh_11, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_336, (128, 16384), (16384, 1))
    assert_size_stride(mul_120, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_338, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_159, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_161, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_624, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_360, (128, 4096), (4096, 1))
    assert_size_stride(addmm_24, (128, 16384), (16384, 1))
    assert_size_stride(tanh_12, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_364, (128, 16384), (16384, 1))
    assert_size_stride(mul_130, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_366, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_172, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_174, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_672, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_388, (128, 4096), (4096, 1))
    assert_size_stride(addmm_26, (128, 16384), (16384, 1))
    assert_size_stride(tanh_13, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_392, (128, 16384), (16384, 1))
    assert_size_stride(mul_140, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_394, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_185, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_187, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_720, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_416, (128, 4096), (4096, 1))
    assert_size_stride(addmm_28, (128, 16384), (16384, 1))
    assert_size_stride(tanh_14, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_420, (128, 16384), (16384, 1))
    assert_size_stride(mul_150, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_422, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_198, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_200, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_768, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_444, (128, 4096), (4096, 1))
    assert_size_stride(addmm_30, (128, 16384), (16384, 1))
    assert_size_stride(tanh_15, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_448, (128, 16384), (16384, 1))
    assert_size_stride(mul_160, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_450, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_211, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_213, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_816, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_472, (128, 4096), (4096, 1))
    assert_size_stride(addmm_32, (128, 16384), (16384, 1))
    assert_size_stride(tanh_16, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_476, (128, 16384), (16384, 1))
    assert_size_stride(mul_170, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_478, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_224, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_226, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_864, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_500, (128, 4096), (4096, 1))
    assert_size_stride(addmm_34, (128, 16384), (16384, 1))
    assert_size_stride(tanh_17, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_504, (128, 16384), (16384, 1))
    assert_size_stride(mul_180, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_506, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_237, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_239, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_912, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_528, (128, 4096), (4096, 1))
    assert_size_stride(addmm_36, (128, 16384), (16384, 1))
    assert_size_stride(tanh_18, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_532, (128, 16384), (16384, 1))
    assert_size_stride(mul_190, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_534, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_250, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_252, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_960, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_556, (128, 4096), (4096, 1))
    assert_size_stride(addmm_38, (128, 16384), (16384, 1))
    assert_size_stride(tanh_19, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_560, (128, 16384), (16384, 1))
    assert_size_stride(mul_200, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_562, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_263, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_265, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_1008, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_584, (128, 4096), (4096, 1))
    assert_size_stride(addmm_40, (128, 16384), (16384, 1))
    assert_size_stride(tanh_20, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_588, (128, 16384), (16384, 1))
    assert_size_stride(mul_210, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_590, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_276, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_278, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_1056, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_612, (128, 4096), (4096, 1))
    assert_size_stride(addmm_42, (128, 16384), (16384, 1))
    assert_size_stride(tanh_21, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_616, (128, 16384), (16384, 1))
    assert_size_stride(mul_220, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_618, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_289, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_291, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_1104, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_640, (128, 4096), (4096, 1))
    assert_size_stride(addmm_44, (128, 16384), (16384, 1))
    assert_size_stride(tanh_22, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_644, (128, 16384), (16384, 1))
    assert_size_stride(mul_230, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_646, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_302, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_304, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_1152, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_668, (128, 4096), (4096, 1))
    assert_size_stride(addmm_46, (128, 16384), (16384, 1))
    assert_size_stride(tanh_23, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_672, (128, 16384), (16384, 1))
    assert_size_stride(mul_240, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_674, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_315, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_317, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_1200, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_696, (128, 4096), (4096, 1))
    assert_size_stride(addmm_48, (128, 16384), (16384, 1))
    assert_size_stride(tanh_24, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_700, (128, 16384), (16384, 1))
    assert_size_stride(mul_250, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_702, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_328, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_330, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_1248, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_724, (128, 4096), (4096, 1))
    assert_size_stride(addmm_50, (128, 16384), (16384, 1))
    assert_size_stride(tanh_25, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_728, (128, 16384), (16384, 1))
    assert_size_stride(mul_260, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_730, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_341, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_343, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_1296, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_752, (128, 4096), (4096, 1))
    assert_size_stride(addmm_52, (128, 16384), (16384, 1))
    assert_size_stride(tanh_26, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_756, (128, 16384), (16384, 1))
    assert_size_stride(mul_270, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_758, (128, 4096), (4096, 1))
    assert_size_stride(unsqueeze_354, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(unsqueeze_356, (1, 128, 1, 32, 1), (0, 64, 0, 1, 0))
    assert_size_stride(slice_1344, (1, 1, 128, 128), (4194304, 4194304, 2048, 1))
    assert_size_stride(view_780, (128, 4096), (4096, 1))
    assert_size_stride(addmm_54, (128, 16384), (16384, 1))
    assert_size_stride(tanh_27, (1, 128, 16384), (2097152, 16384, 1))
    assert_size_stride(view_784, (128, 16384), (16384, 1))
    assert_size_stride(mul_280, (1, 128, 4096), (524288, 4096, 1))
    assert_size_stride(view_787, (128, 4096), (4096, 1))
    assert_size_stride(sub_58, (127, 50400), (50400, 1))
    assert_size_stride(convert_element_type, (), ())
    assert_size_stride(permute_309, (50400, 4096), (4096, 1))
    assert_size_stride(div_58, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_313, (4096, 16384), (16384, 1))
    assert_size_stride(permute_317, (16384, 4096), (4096, 1))
    assert_size_stride(permute_323, (4096, 4096), (4096, 1))
    assert_size_stride(permute_326, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_327, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_59, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_328, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_329, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_336, (4096, 4096), (4096, 1))
    assert_size_stride(permute_340, (4096, 4096), (4096, 1))
    assert_size_stride(permute_344, (4096, 4096), (4096, 1))
    assert_size_stride(div_60, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_346, (4096, 16384), (16384, 1))
    assert_size_stride(permute_350, (16384, 4096), (4096, 1))
    assert_size_stride(permute_356, (4096, 4096), (4096, 1))
    assert_size_stride(permute_359, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_360, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_61, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_361, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_362, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_369, (4096, 4096), (4096, 1))
    assert_size_stride(permute_373, (4096, 4096), (4096, 1))
    assert_size_stride(permute_377, (4096, 4096), (4096, 1))
    assert_size_stride(div_62, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_379, (4096, 16384), (16384, 1))
    assert_size_stride(permute_383, (16384, 4096), (4096, 1))
    assert_size_stride(permute_389, (4096, 4096), (4096, 1))
    assert_size_stride(permute_392, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_393, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_63, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_394, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_395, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_402, (4096, 4096), (4096, 1))
    assert_size_stride(permute_406, (4096, 4096), (4096, 1))
    assert_size_stride(permute_410, (4096, 4096), (4096, 1))
    assert_size_stride(div_64, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_412, (4096, 16384), (16384, 1))
    assert_size_stride(permute_416, (16384, 4096), (4096, 1))
    assert_size_stride(permute_422, (4096, 4096), (4096, 1))
    assert_size_stride(permute_425, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_426, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_65, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_427, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_428, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_435, (4096, 4096), (4096, 1))
    assert_size_stride(permute_439, (4096, 4096), (4096, 1))
    assert_size_stride(permute_443, (4096, 4096), (4096, 1))
    assert_size_stride(div_66, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_445, (4096, 16384), (16384, 1))
    assert_size_stride(permute_449, (16384, 4096), (4096, 1))
    assert_size_stride(permute_455, (4096, 4096), (4096, 1))
    assert_size_stride(permute_458, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_459, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_67, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_460, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_461, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_468, (4096, 4096), (4096, 1))
    assert_size_stride(permute_472, (4096, 4096), (4096, 1))
    assert_size_stride(permute_476, (4096, 4096), (4096, 1))
    assert_size_stride(div_68, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_478, (4096, 16384), (16384, 1))
    assert_size_stride(permute_482, (16384, 4096), (4096, 1))
    assert_size_stride(permute_488, (4096, 4096), (4096, 1))
    assert_size_stride(permute_491, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_492, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_69, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_493, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_494, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_501, (4096, 4096), (4096, 1))
    assert_size_stride(permute_505, (4096, 4096), (4096, 1))
    assert_size_stride(permute_509, (4096, 4096), (4096, 1))
    assert_size_stride(div_70, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_511, (4096, 16384), (16384, 1))
    assert_size_stride(permute_515, (16384, 4096), (4096, 1))
    assert_size_stride(permute_521, (4096, 4096), (4096, 1))
    assert_size_stride(permute_524, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_525, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_71, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_526, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_527, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_534, (4096, 4096), (4096, 1))
    assert_size_stride(permute_538, (4096, 4096), (4096, 1))
    assert_size_stride(permute_542, (4096, 4096), (4096, 1))
    assert_size_stride(div_72, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_544, (4096, 16384), (16384, 1))
    assert_size_stride(permute_548, (16384, 4096), (4096, 1))
    assert_size_stride(permute_554, (4096, 4096), (4096, 1))
    assert_size_stride(permute_557, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_558, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_73, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_559, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_560, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_567, (4096, 4096), (4096, 1))
    assert_size_stride(permute_571, (4096, 4096), (4096, 1))
    assert_size_stride(permute_575, (4096, 4096), (4096, 1))
    assert_size_stride(div_74, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_577, (4096, 16384), (16384, 1))
    assert_size_stride(permute_581, (16384, 4096), (4096, 1))
    assert_size_stride(permute_587, (4096, 4096), (4096, 1))
    assert_size_stride(permute_590, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_591, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_75, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_592, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_593, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_600, (4096, 4096), (4096, 1))
    assert_size_stride(permute_604, (4096, 4096), (4096, 1))
    assert_size_stride(permute_608, (4096, 4096), (4096, 1))
    assert_size_stride(div_76, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_610, (4096, 16384), (16384, 1))
    assert_size_stride(permute_614, (16384, 4096), (4096, 1))
    assert_size_stride(permute_620, (4096, 4096), (4096, 1))
    assert_size_stride(permute_623, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_624, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_77, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_625, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_626, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_633, (4096, 4096), (4096, 1))
    assert_size_stride(permute_637, (4096, 4096), (4096, 1))
    assert_size_stride(permute_641, (4096, 4096), (4096, 1))
    assert_size_stride(div_78, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_643, (4096, 16384), (16384, 1))
    assert_size_stride(permute_647, (16384, 4096), (4096, 1))
    assert_size_stride(permute_653, (4096, 4096), (4096, 1))
    assert_size_stride(permute_656, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_657, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_79, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_658, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_659, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_666, (4096, 4096), (4096, 1))
    assert_size_stride(permute_670, (4096, 4096), (4096, 1))
    assert_size_stride(permute_674, (4096, 4096), (4096, 1))
    assert_size_stride(div_80, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_676, (4096, 16384), (16384, 1))
    assert_size_stride(permute_680, (16384, 4096), (4096, 1))
    assert_size_stride(permute_686, (4096, 4096), (4096, 1))
    assert_size_stride(permute_689, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_690, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_81, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_691, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_692, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_699, (4096, 4096), (4096, 1))
    assert_size_stride(permute_703, (4096, 4096), (4096, 1))
    assert_size_stride(permute_707, (4096, 4096), (4096, 1))
    assert_size_stride(div_82, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_709, (4096, 16384), (16384, 1))
    assert_size_stride(permute_713, (16384, 4096), (4096, 1))
    assert_size_stride(permute_719, (4096, 4096), (4096, 1))
    assert_size_stride(permute_722, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_723, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_83, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_724, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_725, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_732, (4096, 4096), (4096, 1))
    assert_size_stride(permute_736, (4096, 4096), (4096, 1))
    assert_size_stride(permute_740, (4096, 4096), (4096, 1))
    assert_size_stride(div_84, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_742, (4096, 16384), (16384, 1))
    assert_size_stride(permute_746, (16384, 4096), (4096, 1))
    assert_size_stride(permute_752, (4096, 4096), (4096, 1))
    assert_size_stride(permute_755, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_756, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_85, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_757, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_758, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_765, (4096, 4096), (4096, 1))
    assert_size_stride(permute_769, (4096, 4096), (4096, 1))
    assert_size_stride(permute_773, (4096, 4096), (4096, 1))
    assert_size_stride(div_86, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_775, (4096, 16384), (16384, 1))
    assert_size_stride(permute_779, (16384, 4096), (4096, 1))
    assert_size_stride(permute_785, (4096, 4096), (4096, 1))
    assert_size_stride(permute_788, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_789, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_87, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_790, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_791, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_798, (4096, 4096), (4096, 1))
    assert_size_stride(permute_802, (4096, 4096), (4096, 1))
    assert_size_stride(permute_806, (4096, 4096), (4096, 1))
    assert_size_stride(div_88, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_808, (4096, 16384), (16384, 1))
    assert_size_stride(permute_812, (16384, 4096), (4096, 1))
    assert_size_stride(permute_818, (4096, 4096), (4096, 1))
    assert_size_stride(permute_821, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_822, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_89, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_823, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_824, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_831, (4096, 4096), (4096, 1))
    assert_size_stride(permute_835, (4096, 4096), (4096, 1))
    assert_size_stride(permute_839, (4096, 4096), (4096, 1))
    assert_size_stride(div_90, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_841, (4096, 16384), (16384, 1))
    assert_size_stride(permute_845, (16384, 4096), (4096, 1))
    assert_size_stride(permute_851, (4096, 4096), (4096, 1))
    assert_size_stride(permute_854, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_855, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_91, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_856, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_857, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_864, (4096, 4096), (4096, 1))
    assert_size_stride(permute_868, (4096, 4096), (4096, 1))
    assert_size_stride(permute_872, (4096, 4096), (4096, 1))
    assert_size_stride(div_92, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_874, (4096, 16384), (16384, 1))
    assert_size_stride(permute_878, (16384, 4096), (4096, 1))
    assert_size_stride(permute_884, (4096, 4096), (4096, 1))
    assert_size_stride(permute_887, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_888, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_93, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_889, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_890, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_897, (4096, 4096), (4096, 1))
    assert_size_stride(permute_901, (4096, 4096), (4096, 1))
    assert_size_stride(permute_905, (4096, 4096), (4096, 1))
    assert_size_stride(div_94, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_907, (4096, 16384), (16384, 1))
    assert_size_stride(permute_911, (16384, 4096), (4096, 1))
    assert_size_stride(permute_917, (4096, 4096), (4096, 1))
    assert_size_stride(permute_920, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_921, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_95, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_922, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_923, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_930, (4096, 4096), (4096, 1))
    assert_size_stride(permute_934, (4096, 4096), (4096, 1))
    assert_size_stride(permute_938, (4096, 4096), (4096, 1))
    assert_size_stride(div_96, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_940, (4096, 16384), (16384, 1))
    assert_size_stride(permute_944, (16384, 4096), (4096, 1))
    assert_size_stride(permute_950, (4096, 4096), (4096, 1))
    assert_size_stride(permute_953, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_954, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_97, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_955, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_956, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_963, (4096, 4096), (4096, 1))
    assert_size_stride(permute_967, (4096, 4096), (4096, 1))
    assert_size_stride(permute_971, (4096, 4096), (4096, 1))
    assert_size_stride(div_98, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_973, (4096, 16384), (16384, 1))
    assert_size_stride(permute_977, (16384, 4096), (4096, 1))
    assert_size_stride(permute_983, (4096, 4096), (4096, 1))
    assert_size_stride(permute_986, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_987, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_99, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_988, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_989, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_996, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1000, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1004, (4096, 4096), (4096, 1))
    assert_size_stride(div_100, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_1006, (4096, 16384), (16384, 1))
    assert_size_stride(permute_1010, (16384, 4096), (4096, 1))
    assert_size_stride(permute_1016, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1019, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_1020, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_101, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_1021, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_1022, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_1029, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1033, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1037, (4096, 4096), (4096, 1))
    assert_size_stride(div_102, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_1039, (4096, 16384), (16384, 1))
    assert_size_stride(permute_1043, (16384, 4096), (4096, 1))
    assert_size_stride(permute_1049, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1052, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_1053, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_103, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_1054, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_1055, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_1062, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1066, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1070, (4096, 4096), (4096, 1))
    assert_size_stride(div_104, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_1072, (4096, 16384), (16384, 1))
    assert_size_stride(permute_1076, (16384, 4096), (4096, 1))
    assert_size_stride(permute_1082, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1085, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_1086, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_105, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_1087, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_1088, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_1095, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1099, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1103, (4096, 4096), (4096, 1))
    assert_size_stride(div_106, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_1105, (4096, 16384), (16384, 1))
    assert_size_stride(permute_1109, (16384, 4096), (4096, 1))
    assert_size_stride(permute_1115, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1118, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_1119, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_107, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_1120, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_1121, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_1128, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1132, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1136, (4096, 4096), (4096, 1))
    assert_size_stride(div_108, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_1138, (4096, 16384), (16384, 1))
    assert_size_stride(permute_1142, (16384, 4096), (4096, 1))
    assert_size_stride(permute_1148, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1151, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_1152, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_109, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_1153, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_1154, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_1161, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1165, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1169, (4096, 4096), (4096, 1))
    assert_size_stride(div_110, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_1171, (4096, 16384), (16384, 1))
    assert_size_stride(permute_1175, (16384, 4096), (4096, 1))
    assert_size_stride(permute_1181, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1184, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_1185, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_111, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_1186, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_1187, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_1194, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1198, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1202, (4096, 4096), (4096, 1))
    assert_size_stride(div_112, (1, 128, 1), (128, 1, 1))
    assert_size_stride(permute_1204, (4096, 16384), (16384, 1))
    assert_size_stride(permute_1208, (16384, 4096), (4096, 1))
    assert_size_stride(permute_1214, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1217, (16, 128, 128), (16384, 1, 128))
    assert_size_stride(permute_1218, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(alias_113, (1, 16, 128, 128), (262144, 16384, 128, 1))
    assert_size_stride(permute_1219, (16, 256, 128), (256, 1, 4096))
    assert_size_stride(permute_1220, (16, 128, 256), (256, 4096, 1))
    assert_size_stride(permute_1227, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1231, (4096, 4096), (4096, 1))
    assert_size_stride(permute_1235, (4096, 4096), (4096, 1))
    assert_size_stride(tangents_1, (), ())
    assert_size_stride(tangents_2, (1, 128, 50400), (6451200, 50400, 1))
    assert_size_stride(tangents_3, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_4, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_5, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_6, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_7, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_8, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_9, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_10, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_11, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_12, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_13, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_14, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_15, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_16, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_17, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_18, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_19, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_20, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_21, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_22, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_23, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_24, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_25, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_26, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_27, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_28, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_29, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_30, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_31, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_32, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_33, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_34, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_35, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_36, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_37, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_38, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_39, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_40, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_41, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_42, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_43, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_44, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_45, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_46, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_47, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_48, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_49, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_50, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_51, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_52, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_53, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_54, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_55, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_56, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_57, (1, 16, 128, 256), (524288, 32768, 256, 1))
    assert_size_stride(tangents_58, (1, 16, 128, 256), (524288, 32768, 256, 1))
    buf0 = empty((127, 50400), device='cpu', dtype=torch.float32)
    buf1 = empty_strided((127, 1), (1, 127), device='cpu', dtype=torch.int64)
    cpp_fused_nll_loss_backward_nll_loss_forward_0(c_void_p(primals_371.data_ptr()), c_void_p(buf0.data_ptr()), c_void_p(buf1.data_ptr()))
    aten.scatter_(buf0,1,buf1,-1.0)
    del buf1
    buf4 = empty_strided((127, 1), (1, 127), device='cpu', dtype=torch.float32)
    buf5 = empty((1, 128, 50400), device='cpu', dtype=torch.float32)
    cpp_fused__log_softmax_backward_data_add_nll_loss_backward_nll_loss_forward_slice_backward_1(c_void_p(buf0.data_ptr()), c_void_p(primals_371.data_ptr()), c_void_p(tangents_1.data_ptr()), c_void_p(convert_element_type.data_ptr()), c_void_p(tangents_2.data_ptr()), c_void_p(sub_58.data_ptr()), c_void_p(buf4.data_ptr()), c_void_p(buf5.data_ptr()))
    del buf0
    del buf4
    del convert_element_type
    del primals_371
    del sub_58
    del tangents_1
    del tangents_2
    buf6 = empty((128, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf5, (128, 50400), (50400, 1), 0), permute_309, out=buf6)
    del permute_309
    buf7 = empty((50400, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf5, (50400, 128), (1, 50400), 0), view_787, out=buf7)
    del view_787
    buf8 = empty((1, 50400), device='cpu', dtype=torch.float32)
    buf9 = empty_strided((1, 128, 1), (128, 1, 128), device='cpu', dtype=torch.float32)
    buf10 = empty_strided((1, 128, 1), (128, 1, 128), device='cpu', dtype=torch.float32)
    buf11 = empty((1, 128, 4096), device='cpu', dtype=torch.float32)
    buf12 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf13 = empty((4096, ), device='cpu', dtype=torch.float32)
    cpp_fused_native_layer_norm_backward_sum_2(c_void_p(buf5.data_ptr()), c_void_p(buf6.data_ptr()), c_void_p(primals_282.data_ptr()), c_void_p(mul_280.data_ptr()), c_void_p(div_58.data_ptr()), c_void_p(buf8.data_ptr()), c_void_p(buf9.data_ptr()), c_void_p(buf10.data_ptr()), c_void_p(buf11.data_ptr()), c_void_p(buf12.data_ptr()), c_void_p(buf13.data_ptr()))
    del buf5
    del div_58
    del mul_280
    del primals_282
    buf14 = empty((128, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf11, (128, 4096), (4096, 1), 0), permute_313, out=buf14)
    del permute_313
    buf15 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf11, (4096, 128), (1, 4096), 0), view_784, out=buf15)
    del view_784
    buf16 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf17 = reinterpret_tensor(buf14, (1, 128, 16384), (2097152, 16384, 1), 0); del buf14  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_3(c_void_p(buf17.data_ptr()), c_void_p(buf11.data_ptr()), c_void_p(addmm_54.data_ptr()), c_void_p(tanh_27.data_ptr()), c_void_p(buf16.data_ptr()))
    del addmm_54
    del tanh_27
    buf18 = buf6; del buf6  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf17, (128, 16384), (16384, 1), 0), permute_317, out=buf18)
    del permute_317
    buf19 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf17, (16384, 128), (1, 16384), 0), view_758, out=buf19)
    buf20 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_4(c_void_p(buf17.data_ptr()), c_void_p(buf20.data_ptr()))
    buf21 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf11, (4096, 128), (1, 4096), 0), view_780, out=buf21)
    del view_780
    buf22 = empty((128, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf11, (128, 4096), (4096, 1), 0), permute_323, out=buf22)
    del permute_323
    buf23 = empty((16, 128, 256), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_326, reinterpret_tensor(buf22, (16, 128, 256), (256, 4096, 1), 0), out=buf23)
    del permute_326
    buf24 = empty((16, 128, 128), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf22, (16, 128, 256), (256, 4096, 1), 0), permute_327, out=buf24)
    del permute_327
    buf25 = empty_strided((1, 16, 128, 1), (2048, 128, 1, 2048), device='cpu', dtype=torch.float32)
    buf26 = reinterpret_tensor(buf24, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf24  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_5(c_void_p(buf26.data_ptr()), c_void_p(alias_59.data_ptr()), c_void_p(slice_1344.data_ptr()), c_void_p(primals_369.data_ptr()), c_void_p(buf25.data_ptr()))
    del alias_59
    del primals_369
    del slice_1344
    buf27 = reinterpret_tensor(buf22, (16, 256, 128), (32768, 128, 1), 0); del buf22  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_328, reinterpret_tensor(buf26, (16, 128, 128), (16384, 128, 1), 0), out=buf27)
    del permute_328
    buf28 = empty((16, 128, 256), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf26, (16, 128, 128), (16384, 128, 1), 0), permute_329, out=buf28)
    del permute_329
    buf29 = empty_strided((1, 128, 16, 64), (131072, 64, 8192, 1), device='cpu', dtype=torch.float32)
    buf30 = empty((1, 128, 16, 256), device='cpu', dtype=torch.float32)
    cpp_fused_add_clone_mul_neg_slice_backward_6(c_void_p(tangents_57.data_ptr()), c_void_p(buf27.data_ptr()), c_void_p(unsqueeze_354.data_ptr()), c_void_p(unsqueeze_356.data_ptr()), c_void_p(tangents_58.data_ptr()), c_void_p(buf23.data_ptr()), c_void_p(buf29.data_ptr()), c_void_p(buf30.data_ptr()))
    del tangents_58
    buf31 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf30, (4096, 128), (1, 4096), 0), view_758, out=buf31)
    buf32 = reinterpret_tensor(buf23, (128, 4096), (4096, 1), 0); del buf23  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf30, (128, 4096), (4096, 1), 0), permute_336, out=buf32)
    del permute_336
    buf33 = buf30; del buf30  # reuse
    cpp_fused_add_slice_backward_7(c_void_p(tangents_57.data_ptr()), c_void_p(buf27.data_ptr()), c_void_p(buf29.data_ptr()), c_void_p(buf33.data_ptr()))
    del tangents_57
    buf34 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf33, (4096, 128), (1, 4096), 0), view_758, out=buf34)
    buf35 = reinterpret_tensor(buf27, (128, 4096), (4096, 1), 0); del buf27  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf33, (128, 4096), (4096, 1), 0), permute_340, out=buf35)
    del permute_340
    buf36 = buf33; del buf33  # reuse
    cpp_fused_add_mul_neg_slice_backward_8(c_void_p(buf28.data_ptr()), c_void_p(unsqueeze_354.data_ptr()), c_void_p(unsqueeze_356.data_ptr()), c_void_p(buf36.data_ptr()))
    del unsqueeze_354
    del unsqueeze_356
    buf37 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf36, (4096, 128), (1, 4096), 0), view_758, out=buf37)
    del view_758
    buf38 = reinterpret_tensor(buf28, (128, 4096), (4096, 1), 0); del buf28  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf36, (128, 4096), (4096, 1), 0), permute_344, out=buf38)
    del permute_344
    buf39 = reinterpret_tensor(buf36, (1, 128, 4096), (524288, 4096, 1), 0); del buf36  # reuse
    buf40 = buf9; del buf9  # reuse
    buf41 = buf10; del buf10  # reuse
    buf42 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf43 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf44 = buf11; del buf11  # reuse
    cpp_fused_add_native_layer_norm_backward_9(c_void_p(buf44.data_ptr()), c_void_p(buf18.data_ptr()), c_void_p(buf32.data_ptr()), c_void_p(buf35.data_ptr()), c_void_p(buf38.data_ptr()), c_void_p(primals_272.data_ptr()), c_void_p(mul_270.data_ptr()), c_void_p(div_60.data_ptr()), c_void_p(buf39.data_ptr()), c_void_p(buf40.data_ptr()), c_void_p(buf41.data_ptr()), c_void_p(buf42.data_ptr()), c_void_p(buf43.data_ptr()))
    del div_60
    del mul_270
    del primals_272
    buf45 = reinterpret_tensor(buf17, (128, 16384), (16384, 1), 0); del buf17  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf44, (128, 4096), (4096, 1), 0), permute_346, out=buf45)
    del permute_346
    buf46 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf44, (4096, 128), (1, 4096), 0), view_756, out=buf46)
    del view_756
    buf47 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf48 = reinterpret_tensor(buf45, (1, 128, 16384), (2097152, 16384, 1), 0); del buf45  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_10(c_void_p(buf48.data_ptr()), c_void_p(buf44.data_ptr()), c_void_p(addmm_52.data_ptr()), c_void_p(tanh_26.data_ptr()), c_void_p(buf47.data_ptr()))
    del addmm_52
    del tanh_26
    buf49 = reinterpret_tensor(buf39, (128, 4096), (4096, 1), 0); del buf39  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf48, (128, 16384), (16384, 1), 0), permute_350, out=buf49)
    del permute_350
    buf50 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf48, (16384, 128), (1, 16384), 0), view_730, out=buf50)
    buf51 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_11(c_void_p(buf48.data_ptr()), c_void_p(buf51.data_ptr()))
    buf52 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf44, (4096, 128), (1, 4096), 0), view_752, out=buf52)
    del view_752
    buf53 = buf38; del buf38  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf44, (128, 4096), (4096, 1), 0), permute_356, out=buf53)
    del permute_356
    buf54 = reinterpret_tensor(buf35, (16, 128, 256), (32768, 256, 1), 0); del buf35  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_359, reinterpret_tensor(buf53, (16, 128, 256), (256, 4096, 1), 0), out=buf54)
    del permute_359
    buf55 = reinterpret_tensor(buf26, (16, 128, 128), (16384, 128, 1), 0); del buf26  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf53, (16, 128, 256), (256, 4096, 1), 0), permute_360, out=buf55)
    del permute_360
    buf56 = buf25; del buf25  # reuse
    buf57 = reinterpret_tensor(buf55, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf55  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_12(c_void_p(buf57.data_ptr()), c_void_p(alias_61.data_ptr()), c_void_p(slice_1296.data_ptr()), c_void_p(primals_366.data_ptr()), c_void_p(buf56.data_ptr()))
    del alias_61
    del primals_366
    del slice_1296
    buf58 = reinterpret_tensor(buf53, (16, 256, 128), (32768, 128, 1), 0); del buf53  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_361, reinterpret_tensor(buf57, (16, 128, 128), (16384, 128, 1), 0), out=buf58)
    del permute_361
    buf59 = reinterpret_tensor(buf32, (16, 128, 256), (32768, 256, 1), 0); del buf32  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf57, (16, 128, 128), (16384, 128, 1), 0), permute_362, out=buf59)
    del permute_362
    buf60 = buf29; del buf29  # reuse
    buf61 = reinterpret_tensor(buf18, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf18  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_13(c_void_p(tangents_55.data_ptr()), c_void_p(buf58.data_ptr()), c_void_p(unsqueeze_341.data_ptr()), c_void_p(unsqueeze_343.data_ptr()), c_void_p(tangents_56.data_ptr()), c_void_p(buf54.data_ptr()), c_void_p(buf60.data_ptr()), c_void_p(buf61.data_ptr()))
    del tangents_56
    buf62 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf61, (4096, 128), (1, 4096), 0), view_730, out=buf62)
    buf63 = reinterpret_tensor(buf54, (128, 4096), (4096, 1), 0); del buf54  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf61, (128, 4096), (4096, 1), 0), permute_369, out=buf63)
    del permute_369
    buf64 = buf61; del buf61  # reuse
    cpp_fused_add_slice_backward_14(c_void_p(tangents_55.data_ptr()), c_void_p(buf58.data_ptr()), c_void_p(buf60.data_ptr()), c_void_p(buf64.data_ptr()))
    del tangents_55
    buf65 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf64, (4096, 128), (1, 4096), 0), view_730, out=buf65)
    buf66 = reinterpret_tensor(buf58, (128, 4096), (4096, 1), 0); del buf58  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf64, (128, 4096), (4096, 1), 0), permute_373, out=buf66)
    del permute_373
    buf67 = buf64; del buf64  # reuse
    cpp_fused_add_mul_neg_slice_backward_15(c_void_p(buf59.data_ptr()), c_void_p(unsqueeze_341.data_ptr()), c_void_p(unsqueeze_343.data_ptr()), c_void_p(buf67.data_ptr()))
    del unsqueeze_341
    del unsqueeze_343
    buf68 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf67, (4096, 128), (1, 4096), 0), view_730, out=buf68)
    del view_730
    buf69 = reinterpret_tensor(buf59, (128, 4096), (4096, 1), 0); del buf59  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf67, (128, 4096), (4096, 1), 0), permute_377, out=buf69)
    del permute_377
    buf70 = reinterpret_tensor(buf67, (1, 128, 4096), (524288, 4096, 1), 0); del buf67  # reuse
    buf71 = buf41; del buf41  # reuse
    buf72 = buf40; del buf40  # reuse
    buf73 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf74 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf75 = buf44; del buf44  # reuse
    cpp_fused_add_native_layer_norm_backward_16(c_void_p(buf75.data_ptr()), c_void_p(buf49.data_ptr()), c_void_p(buf63.data_ptr()), c_void_p(buf66.data_ptr()), c_void_p(buf69.data_ptr()), c_void_p(primals_262.data_ptr()), c_void_p(mul_260.data_ptr()), c_void_p(div_62.data_ptr()), c_void_p(buf70.data_ptr()), c_void_p(buf71.data_ptr()), c_void_p(buf72.data_ptr()), c_void_p(buf73.data_ptr()), c_void_p(buf74.data_ptr()))
    del div_62
    del mul_260
    del primals_262
    buf76 = reinterpret_tensor(buf48, (128, 16384), (16384, 1), 0); del buf48  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf75, (128, 4096), (4096, 1), 0), permute_379, out=buf76)
    del permute_379
    buf77 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf75, (4096, 128), (1, 4096), 0), view_728, out=buf77)
    del view_728
    buf78 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf79 = reinterpret_tensor(buf76, (1, 128, 16384), (2097152, 16384, 1), 0); del buf76  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_17(c_void_p(buf79.data_ptr()), c_void_p(buf75.data_ptr()), c_void_p(addmm_50.data_ptr()), c_void_p(tanh_25.data_ptr()), c_void_p(buf78.data_ptr()))
    del addmm_50
    del tanh_25
    buf80 = reinterpret_tensor(buf70, (128, 4096), (4096, 1), 0); del buf70  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf79, (128, 16384), (16384, 1), 0), permute_383, out=buf80)
    del permute_383
    buf81 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf79, (16384, 128), (1, 16384), 0), view_702, out=buf81)
    buf82 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_18(c_void_p(buf79.data_ptr()), c_void_p(buf82.data_ptr()))
    buf83 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf75, (4096, 128), (1, 4096), 0), view_724, out=buf83)
    del view_724
    buf84 = buf69; del buf69  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf75, (128, 4096), (4096, 1), 0), permute_389, out=buf84)
    del permute_389
    buf85 = reinterpret_tensor(buf66, (16, 128, 256), (32768, 256, 1), 0); del buf66  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_392, reinterpret_tensor(buf84, (16, 128, 256), (256, 4096, 1), 0), out=buf85)
    del permute_392
    buf86 = reinterpret_tensor(buf57, (16, 128, 128), (16384, 128, 1), 0); del buf57  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf84, (16, 128, 256), (256, 4096, 1), 0), permute_393, out=buf86)
    del permute_393
    buf87 = buf56; del buf56  # reuse
    buf88 = reinterpret_tensor(buf86, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf86  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_19(c_void_p(buf88.data_ptr()), c_void_p(alias_63.data_ptr()), c_void_p(slice_1248.data_ptr()), c_void_p(primals_363.data_ptr()), c_void_p(buf87.data_ptr()))
    del alias_63
    del primals_363
    del slice_1248
    buf89 = reinterpret_tensor(buf84, (16, 256, 128), (32768, 128, 1), 0); del buf84  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_394, reinterpret_tensor(buf88, (16, 128, 128), (16384, 128, 1), 0), out=buf89)
    del permute_394
    buf90 = reinterpret_tensor(buf63, (16, 128, 256), (32768, 256, 1), 0); del buf63  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf88, (16, 128, 128), (16384, 128, 1), 0), permute_395, out=buf90)
    del permute_395
    buf91 = buf60; del buf60  # reuse
    buf92 = reinterpret_tensor(buf49, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf49  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_20(c_void_p(tangents_53.data_ptr()), c_void_p(buf89.data_ptr()), c_void_p(unsqueeze_328.data_ptr()), c_void_p(unsqueeze_330.data_ptr()), c_void_p(tangents_54.data_ptr()), c_void_p(buf85.data_ptr()), c_void_p(buf91.data_ptr()), c_void_p(buf92.data_ptr()))
    del tangents_54
    buf93 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf92, (4096, 128), (1, 4096), 0), view_702, out=buf93)
    buf94 = reinterpret_tensor(buf85, (128, 4096), (4096, 1), 0); del buf85  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf92, (128, 4096), (4096, 1), 0), permute_402, out=buf94)
    del permute_402
    buf95 = buf92; del buf92  # reuse
    cpp_fused_add_slice_backward_21(c_void_p(tangents_53.data_ptr()), c_void_p(buf89.data_ptr()), c_void_p(buf91.data_ptr()), c_void_p(buf95.data_ptr()))
    del tangents_53
    buf96 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf95, (4096, 128), (1, 4096), 0), view_702, out=buf96)
    buf97 = reinterpret_tensor(buf89, (128, 4096), (4096, 1), 0); del buf89  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf95, (128, 4096), (4096, 1), 0), permute_406, out=buf97)
    del permute_406
    buf98 = buf95; del buf95  # reuse
    cpp_fused_add_mul_neg_slice_backward_22(c_void_p(buf90.data_ptr()), c_void_p(unsqueeze_328.data_ptr()), c_void_p(unsqueeze_330.data_ptr()), c_void_p(buf98.data_ptr()))
    del unsqueeze_328
    del unsqueeze_330
    buf99 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf98, (4096, 128), (1, 4096), 0), view_702, out=buf99)
    del view_702
    buf100 = reinterpret_tensor(buf90, (128, 4096), (4096, 1), 0); del buf90  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf98, (128, 4096), (4096, 1), 0), permute_410, out=buf100)
    del permute_410
    buf101 = reinterpret_tensor(buf98, (1, 128, 4096), (524288, 4096, 1), 0); del buf98  # reuse
    buf102 = buf72; del buf72  # reuse
    buf103 = buf71; del buf71  # reuse
    buf104 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf105 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf106 = buf101; del buf101  # reuse
    cpp_fused_add_native_layer_norm_backward_23(c_void_p(buf106.data_ptr()), c_void_p(buf80.data_ptr()), c_void_p(buf94.data_ptr()), c_void_p(buf97.data_ptr()), c_void_p(buf100.data_ptr()), c_void_p(primals_252.data_ptr()), c_void_p(mul_250.data_ptr()), c_void_p(buf75.data_ptr()), c_void_p(div_64.data_ptr()), c_void_p(buf102.data_ptr()), c_void_p(buf103.data_ptr()), c_void_p(buf104.data_ptr()), c_void_p(buf105.data_ptr()))
    del div_64
    del mul_250
    del primals_252
    buf107 = reinterpret_tensor(buf79, (128, 16384), (16384, 1), 0); del buf79  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf106, (128, 4096), (4096, 1), 0), permute_412, out=buf107)
    del permute_412
    buf108 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf106, (4096, 128), (1, 4096), 0), view_700, out=buf108)
    del view_700
    buf109 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf110 = reinterpret_tensor(buf107, (1, 128, 16384), (2097152, 16384, 1), 0); del buf107  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_24(c_void_p(buf110.data_ptr()), c_void_p(buf106.data_ptr()), c_void_p(addmm_48.data_ptr()), c_void_p(tanh_24.data_ptr()), c_void_p(buf109.data_ptr()))
    del addmm_48
    del tanh_24
    buf111 = buf97; del buf97  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf110, (128, 16384), (16384, 1), 0), permute_416, out=buf111)
    del permute_416
    buf112 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf110, (16384, 128), (1, 16384), 0), view_674, out=buf112)
    buf113 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_25(c_void_p(buf110.data_ptr()), c_void_p(buf113.data_ptr()))
    buf114 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf106, (4096, 128), (1, 4096), 0), view_696, out=buf114)
    del view_696
    buf115 = buf94; del buf94  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf106, (128, 4096), (4096, 1), 0), permute_422, out=buf115)
    del permute_422
    buf116 = reinterpret_tensor(buf80, (16, 128, 256), (32768, 256, 1), 0); del buf80  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_425, reinterpret_tensor(buf115, (16, 128, 256), (256, 4096, 1), 0), out=buf116)
    del permute_425
    buf117 = reinterpret_tensor(buf88, (16, 128, 128), (16384, 128, 1), 0); del buf88  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf115, (16, 128, 256), (256, 4096, 1), 0), permute_426, out=buf117)
    del permute_426
    buf118 = buf87; del buf87  # reuse
    buf119 = reinterpret_tensor(buf117, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf117  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_26(c_void_p(buf119.data_ptr()), c_void_p(alias_65.data_ptr()), c_void_p(slice_1200.data_ptr()), c_void_p(primals_360.data_ptr()), c_void_p(buf118.data_ptr()))
    del alias_65
    del primals_360
    del slice_1200
    buf120 = reinterpret_tensor(buf115, (16, 256, 128), (32768, 128, 1), 0); del buf115  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_427, reinterpret_tensor(buf119, (16, 128, 128), (16384, 128, 1), 0), out=buf120)
    del permute_427
    buf121 = reinterpret_tensor(buf75, (16, 128, 256), (32768, 256, 1), 0); del buf75  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf119, (16, 128, 128), (16384, 128, 1), 0), permute_428, out=buf121)
    del permute_428
    buf122 = buf91; del buf91  # reuse
    buf123 = reinterpret_tensor(buf100, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf100  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_27(c_void_p(tangents_51.data_ptr()), c_void_p(buf120.data_ptr()), c_void_p(unsqueeze_315.data_ptr()), c_void_p(unsqueeze_317.data_ptr()), c_void_p(tangents_52.data_ptr()), c_void_p(buf116.data_ptr()), c_void_p(buf122.data_ptr()), c_void_p(buf123.data_ptr()))
    del tangents_52
    buf124 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf123, (4096, 128), (1, 4096), 0), view_674, out=buf124)
    buf125 = reinterpret_tensor(buf116, (128, 4096), (4096, 1), 0); del buf116  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf123, (128, 4096), (4096, 1), 0), permute_435, out=buf125)
    del permute_435
    buf126 = buf123; del buf123  # reuse
    cpp_fused_add_slice_backward_28(c_void_p(tangents_51.data_ptr()), c_void_p(buf120.data_ptr()), c_void_p(buf122.data_ptr()), c_void_p(buf126.data_ptr()))
    del tangents_51
    buf127 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf126, (4096, 128), (1, 4096), 0), view_674, out=buf127)
    buf128 = reinterpret_tensor(buf120, (128, 4096), (4096, 1), 0); del buf120  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf126, (128, 4096), (4096, 1), 0), permute_439, out=buf128)
    del permute_439
    buf129 = buf126; del buf126  # reuse
    cpp_fused_add_mul_neg_slice_backward_29(c_void_p(buf121.data_ptr()), c_void_p(unsqueeze_315.data_ptr()), c_void_p(unsqueeze_317.data_ptr()), c_void_p(buf129.data_ptr()))
    del unsqueeze_315
    del unsqueeze_317
    buf130 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf129, (4096, 128), (1, 4096), 0), view_674, out=buf130)
    del view_674
    buf131 = reinterpret_tensor(buf121, (128, 4096), (4096, 1), 0); del buf121  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf129, (128, 4096), (4096, 1), 0), permute_443, out=buf131)
    del permute_443
    buf132 = reinterpret_tensor(buf129, (1, 128, 4096), (524288, 4096, 1), 0); del buf129  # reuse
    buf133 = buf103; del buf103  # reuse
    buf134 = buf102; del buf102  # reuse
    buf135 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf136 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf137 = buf106; del buf106  # reuse
    cpp_fused_add_native_layer_norm_backward_30(c_void_p(buf137.data_ptr()), c_void_p(buf111.data_ptr()), c_void_p(buf125.data_ptr()), c_void_p(buf128.data_ptr()), c_void_p(buf131.data_ptr()), c_void_p(primals_242.data_ptr()), c_void_p(mul_240.data_ptr()), c_void_p(div_66.data_ptr()), c_void_p(buf132.data_ptr()), c_void_p(buf133.data_ptr()), c_void_p(buf134.data_ptr()), c_void_p(buf135.data_ptr()), c_void_p(buf136.data_ptr()))
    del div_66
    del mul_240
    del primals_242
    buf138 = reinterpret_tensor(buf110, (128, 16384), (16384, 1), 0); del buf110  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf137, (128, 4096), (4096, 1), 0), permute_445, out=buf138)
    del permute_445
    buf139 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf137, (4096, 128), (1, 4096), 0), view_672, out=buf139)
    del view_672
    buf140 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf141 = reinterpret_tensor(buf138, (1, 128, 16384), (2097152, 16384, 1), 0); del buf138  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_31(c_void_p(buf141.data_ptr()), c_void_p(buf137.data_ptr()), c_void_p(addmm_46.data_ptr()), c_void_p(tanh_23.data_ptr()), c_void_p(buf140.data_ptr()))
    del addmm_46
    del tanh_23
    buf142 = reinterpret_tensor(buf132, (128, 4096), (4096, 1), 0); del buf132  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf141, (128, 16384), (16384, 1), 0), permute_449, out=buf142)
    del permute_449
    buf143 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf141, (16384, 128), (1, 16384), 0), view_646, out=buf143)
    buf144 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_32(c_void_p(buf141.data_ptr()), c_void_p(buf144.data_ptr()))
    buf145 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf137, (4096, 128), (1, 4096), 0), view_668, out=buf145)
    del view_668
    buf146 = buf131; del buf131  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf137, (128, 4096), (4096, 1), 0), permute_455, out=buf146)
    del permute_455
    buf147 = reinterpret_tensor(buf128, (16, 128, 256), (32768, 256, 1), 0); del buf128  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_458, reinterpret_tensor(buf146, (16, 128, 256), (256, 4096, 1), 0), out=buf147)
    del permute_458
    buf148 = reinterpret_tensor(buf119, (16, 128, 128), (16384, 128, 1), 0); del buf119  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf146, (16, 128, 256), (256, 4096, 1), 0), permute_459, out=buf148)
    del permute_459
    buf149 = buf118; del buf118  # reuse
    buf150 = reinterpret_tensor(buf148, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf148  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_33(c_void_p(buf150.data_ptr()), c_void_p(alias_67.data_ptr()), c_void_p(slice_1152.data_ptr()), c_void_p(primals_357.data_ptr()), c_void_p(buf149.data_ptr()))
    del alias_67
    del primals_357
    del slice_1152
    buf151 = reinterpret_tensor(buf146, (16, 256, 128), (32768, 128, 1), 0); del buf146  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_460, reinterpret_tensor(buf150, (16, 128, 128), (16384, 128, 1), 0), out=buf151)
    del permute_460
    buf152 = reinterpret_tensor(buf125, (16, 128, 256), (32768, 256, 1), 0); del buf125  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf150, (16, 128, 128), (16384, 128, 1), 0), permute_461, out=buf152)
    del permute_461
    buf153 = buf122; del buf122  # reuse
    buf154 = reinterpret_tensor(buf111, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf111  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_34(c_void_p(tangents_49.data_ptr()), c_void_p(buf151.data_ptr()), c_void_p(unsqueeze_302.data_ptr()), c_void_p(unsqueeze_304.data_ptr()), c_void_p(tangents_50.data_ptr()), c_void_p(buf147.data_ptr()), c_void_p(buf153.data_ptr()), c_void_p(buf154.data_ptr()))
    del tangents_50
    buf155 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf154, (4096, 128), (1, 4096), 0), view_646, out=buf155)
    buf156 = reinterpret_tensor(buf147, (128, 4096), (4096, 1), 0); del buf147  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf154, (128, 4096), (4096, 1), 0), permute_468, out=buf156)
    del permute_468
    buf157 = buf154; del buf154  # reuse
    cpp_fused_add_slice_backward_35(c_void_p(tangents_49.data_ptr()), c_void_p(buf151.data_ptr()), c_void_p(buf153.data_ptr()), c_void_p(buf157.data_ptr()))
    del tangents_49
    buf158 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf157, (4096, 128), (1, 4096), 0), view_646, out=buf158)
    buf159 = reinterpret_tensor(buf151, (128, 4096), (4096, 1), 0); del buf151  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf157, (128, 4096), (4096, 1), 0), permute_472, out=buf159)
    del permute_472
    buf160 = buf157; del buf157  # reuse
    cpp_fused_add_mul_neg_slice_backward_36(c_void_p(buf152.data_ptr()), c_void_p(unsqueeze_302.data_ptr()), c_void_p(unsqueeze_304.data_ptr()), c_void_p(buf160.data_ptr()))
    del unsqueeze_302
    del unsqueeze_304
    buf161 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf160, (4096, 128), (1, 4096), 0), view_646, out=buf161)
    del view_646
    buf162 = reinterpret_tensor(buf152, (128, 4096), (4096, 1), 0); del buf152  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf160, (128, 4096), (4096, 1), 0), permute_476, out=buf162)
    del permute_476
    buf163 = reinterpret_tensor(buf160, (1, 128, 4096), (524288, 4096, 1), 0); del buf160  # reuse
    buf164 = buf134; del buf134  # reuse
    buf165 = buf133; del buf133  # reuse
    buf166 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf167 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf168 = buf137; del buf137  # reuse
    cpp_fused_add_native_layer_norm_backward_37(c_void_p(buf168.data_ptr()), c_void_p(buf142.data_ptr()), c_void_p(buf156.data_ptr()), c_void_p(buf159.data_ptr()), c_void_p(buf162.data_ptr()), c_void_p(primals_232.data_ptr()), c_void_p(mul_230.data_ptr()), c_void_p(div_68.data_ptr()), c_void_p(buf163.data_ptr()), c_void_p(buf164.data_ptr()), c_void_p(buf165.data_ptr()), c_void_p(buf166.data_ptr()), c_void_p(buf167.data_ptr()))
    del div_68
    del mul_230
    del primals_232
    buf169 = reinterpret_tensor(buf141, (128, 16384), (16384, 1), 0); del buf141  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf168, (128, 4096), (4096, 1), 0), permute_478, out=buf169)
    del permute_478
    buf170 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf168, (4096, 128), (1, 4096), 0), view_644, out=buf170)
    del view_644
    buf171 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf172 = reinterpret_tensor(buf169, (1, 128, 16384), (2097152, 16384, 1), 0); del buf169  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_38(c_void_p(buf172.data_ptr()), c_void_p(buf168.data_ptr()), c_void_p(addmm_44.data_ptr()), c_void_p(tanh_22.data_ptr()), c_void_p(buf171.data_ptr()))
    del addmm_44
    del tanh_22
    buf173 = reinterpret_tensor(buf163, (128, 4096), (4096, 1), 0); del buf163  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf172, (128, 16384), (16384, 1), 0), permute_482, out=buf173)
    del permute_482
    buf174 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf172, (16384, 128), (1, 16384), 0), view_618, out=buf174)
    buf175 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_39(c_void_p(buf172.data_ptr()), c_void_p(buf175.data_ptr()))
    buf176 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf168, (4096, 128), (1, 4096), 0), view_640, out=buf176)
    del view_640
    buf177 = buf162; del buf162  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf168, (128, 4096), (4096, 1), 0), permute_488, out=buf177)
    del permute_488
    buf178 = reinterpret_tensor(buf159, (16, 128, 256), (32768, 256, 1), 0); del buf159  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_491, reinterpret_tensor(buf177, (16, 128, 256), (256, 4096, 1), 0), out=buf178)
    del permute_491
    buf179 = reinterpret_tensor(buf150, (16, 128, 128), (16384, 128, 1), 0); del buf150  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf177, (16, 128, 256), (256, 4096, 1), 0), permute_492, out=buf179)
    del permute_492
    buf180 = buf149; del buf149  # reuse
    buf181 = reinterpret_tensor(buf179, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf179  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_40(c_void_p(buf181.data_ptr()), c_void_p(alias_69.data_ptr()), c_void_p(slice_1104.data_ptr()), c_void_p(primals_354.data_ptr()), c_void_p(buf180.data_ptr()))
    del alias_69
    del primals_354
    del slice_1104
    buf182 = reinterpret_tensor(buf177, (16, 256, 128), (32768, 128, 1), 0); del buf177  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_493, reinterpret_tensor(buf181, (16, 128, 128), (16384, 128, 1), 0), out=buf182)
    del permute_493
    buf183 = reinterpret_tensor(buf156, (16, 128, 256), (32768, 256, 1), 0); del buf156  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf181, (16, 128, 128), (16384, 128, 1), 0), permute_494, out=buf183)
    del permute_494
    buf184 = buf153; del buf153  # reuse
    buf185 = reinterpret_tensor(buf142, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf142  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_41(c_void_p(tangents_47.data_ptr()), c_void_p(buf182.data_ptr()), c_void_p(unsqueeze_289.data_ptr()), c_void_p(unsqueeze_291.data_ptr()), c_void_p(tangents_48.data_ptr()), c_void_p(buf178.data_ptr()), c_void_p(buf184.data_ptr()), c_void_p(buf185.data_ptr()))
    del tangents_48
    buf186 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf185, (4096, 128), (1, 4096), 0), view_618, out=buf186)
    buf187 = reinterpret_tensor(buf178, (128, 4096), (4096, 1), 0); del buf178  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf185, (128, 4096), (4096, 1), 0), permute_501, out=buf187)
    del permute_501
    buf188 = buf185; del buf185  # reuse
    cpp_fused_add_slice_backward_42(c_void_p(tangents_47.data_ptr()), c_void_p(buf182.data_ptr()), c_void_p(buf184.data_ptr()), c_void_p(buf188.data_ptr()))
    del tangents_47
    buf189 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf188, (4096, 128), (1, 4096), 0), view_618, out=buf189)
    buf190 = reinterpret_tensor(buf182, (128, 4096), (4096, 1), 0); del buf182  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf188, (128, 4096), (4096, 1), 0), permute_505, out=buf190)
    del permute_505
    buf191 = buf188; del buf188  # reuse
    cpp_fused_add_mul_neg_slice_backward_43(c_void_p(buf183.data_ptr()), c_void_p(unsqueeze_289.data_ptr()), c_void_p(unsqueeze_291.data_ptr()), c_void_p(buf191.data_ptr()))
    del unsqueeze_289
    del unsqueeze_291
    buf192 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf191, (4096, 128), (1, 4096), 0), view_618, out=buf192)
    del view_618
    buf193 = reinterpret_tensor(buf183, (128, 4096), (4096, 1), 0); del buf183  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf191, (128, 4096), (4096, 1), 0), permute_509, out=buf193)
    del permute_509
    buf194 = reinterpret_tensor(buf191, (1, 128, 4096), (524288, 4096, 1), 0); del buf191  # reuse
    buf195 = buf165; del buf165  # reuse
    buf196 = buf164; del buf164  # reuse
    buf197 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf198 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf199 = buf168; del buf168  # reuse
    cpp_fused_add_native_layer_norm_backward_44(c_void_p(buf199.data_ptr()), c_void_p(buf173.data_ptr()), c_void_p(buf187.data_ptr()), c_void_p(buf190.data_ptr()), c_void_p(buf193.data_ptr()), c_void_p(primals_222.data_ptr()), c_void_p(mul_220.data_ptr()), c_void_p(div_70.data_ptr()), c_void_p(buf194.data_ptr()), c_void_p(buf195.data_ptr()), c_void_p(buf196.data_ptr()), c_void_p(buf197.data_ptr()), c_void_p(buf198.data_ptr()))
    del div_70
    del mul_220
    del primals_222
    buf200 = reinterpret_tensor(buf172, (128, 16384), (16384, 1), 0); del buf172  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf199, (128, 4096), (4096, 1), 0), permute_511, out=buf200)
    del permute_511
    buf201 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf199, (4096, 128), (1, 4096), 0), view_616, out=buf201)
    del view_616
    buf202 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf203 = reinterpret_tensor(buf200, (1, 128, 16384), (2097152, 16384, 1), 0); del buf200  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_45(c_void_p(buf203.data_ptr()), c_void_p(buf199.data_ptr()), c_void_p(addmm_42.data_ptr()), c_void_p(tanh_21.data_ptr()), c_void_p(buf202.data_ptr()))
    del addmm_42
    del tanh_21
    buf204 = reinterpret_tensor(buf194, (128, 4096), (4096, 1), 0); del buf194  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf203, (128, 16384), (16384, 1), 0), permute_515, out=buf204)
    del permute_515
    buf205 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf203, (16384, 128), (1, 16384), 0), view_590, out=buf205)
    buf206 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_46(c_void_p(buf203.data_ptr()), c_void_p(buf206.data_ptr()))
    buf207 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf199, (4096, 128), (1, 4096), 0), view_612, out=buf207)
    del view_612
    buf208 = buf193; del buf193  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf199, (128, 4096), (4096, 1), 0), permute_521, out=buf208)
    del permute_521
    buf209 = reinterpret_tensor(buf190, (16, 128, 256), (32768, 256, 1), 0); del buf190  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_524, reinterpret_tensor(buf208, (16, 128, 256), (256, 4096, 1), 0), out=buf209)
    del permute_524
    buf210 = reinterpret_tensor(buf181, (16, 128, 128), (16384, 128, 1), 0); del buf181  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf208, (16, 128, 256), (256, 4096, 1), 0), permute_525, out=buf210)
    del permute_525
    buf211 = buf180; del buf180  # reuse
    buf212 = reinterpret_tensor(buf210, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf210  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_47(c_void_p(buf212.data_ptr()), c_void_p(alias_71.data_ptr()), c_void_p(slice_1056.data_ptr()), c_void_p(primals_351.data_ptr()), c_void_p(buf211.data_ptr()))
    del alias_71
    del primals_351
    del slice_1056
    buf213 = reinterpret_tensor(buf208, (16, 256, 128), (32768, 128, 1), 0); del buf208  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_526, reinterpret_tensor(buf212, (16, 128, 128), (16384, 128, 1), 0), out=buf213)
    del permute_526
    buf214 = reinterpret_tensor(buf187, (16, 128, 256), (32768, 256, 1), 0); del buf187  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf212, (16, 128, 128), (16384, 128, 1), 0), permute_527, out=buf214)
    del permute_527
    buf215 = buf184; del buf184  # reuse
    buf216 = reinterpret_tensor(buf173, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf173  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_48(c_void_p(tangents_45.data_ptr()), c_void_p(buf213.data_ptr()), c_void_p(unsqueeze_276.data_ptr()), c_void_p(unsqueeze_278.data_ptr()), c_void_p(tangents_46.data_ptr()), c_void_p(buf209.data_ptr()), c_void_p(buf215.data_ptr()), c_void_p(buf216.data_ptr()))
    del tangents_46
    buf217 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf216, (4096, 128), (1, 4096), 0), view_590, out=buf217)
    buf218 = reinterpret_tensor(buf209, (128, 4096), (4096, 1), 0); del buf209  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf216, (128, 4096), (4096, 1), 0), permute_534, out=buf218)
    del permute_534
    buf219 = buf216; del buf216  # reuse
    cpp_fused_add_slice_backward_49(c_void_p(tangents_45.data_ptr()), c_void_p(buf213.data_ptr()), c_void_p(buf215.data_ptr()), c_void_p(buf219.data_ptr()))
    del tangents_45
    buf220 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf219, (4096, 128), (1, 4096), 0), view_590, out=buf220)
    buf221 = reinterpret_tensor(buf213, (128, 4096), (4096, 1), 0); del buf213  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf219, (128, 4096), (4096, 1), 0), permute_538, out=buf221)
    del permute_538
    buf222 = buf219; del buf219  # reuse
    cpp_fused_add_mul_neg_slice_backward_50(c_void_p(buf214.data_ptr()), c_void_p(unsqueeze_276.data_ptr()), c_void_p(unsqueeze_278.data_ptr()), c_void_p(buf222.data_ptr()))
    del unsqueeze_276
    del unsqueeze_278
    buf223 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf222, (4096, 128), (1, 4096), 0), view_590, out=buf223)
    del view_590
    buf224 = reinterpret_tensor(buf214, (128, 4096), (4096, 1), 0); del buf214  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf222, (128, 4096), (4096, 1), 0), permute_542, out=buf224)
    del permute_542
    buf225 = reinterpret_tensor(buf222, (1, 128, 4096), (524288, 4096, 1), 0); del buf222  # reuse
    buf226 = buf196; del buf196  # reuse
    buf227 = buf195; del buf195  # reuse
    buf228 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf229 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf230 = buf199; del buf199  # reuse
    cpp_fused_add_native_layer_norm_backward_51(c_void_p(buf230.data_ptr()), c_void_p(buf204.data_ptr()), c_void_p(buf218.data_ptr()), c_void_p(buf221.data_ptr()), c_void_p(buf224.data_ptr()), c_void_p(primals_212.data_ptr()), c_void_p(mul_210.data_ptr()), c_void_p(div_72.data_ptr()), c_void_p(buf225.data_ptr()), c_void_p(buf226.data_ptr()), c_void_p(buf227.data_ptr()), c_void_p(buf228.data_ptr()), c_void_p(buf229.data_ptr()))
    del div_72
    del mul_210
    del primals_212
    buf231 = reinterpret_tensor(buf203, (128, 16384), (16384, 1), 0); del buf203  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf230, (128, 4096), (4096, 1), 0), permute_544, out=buf231)
    del permute_544
    buf232 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf230, (4096, 128), (1, 4096), 0), view_588, out=buf232)
    del view_588
    buf233 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf234 = reinterpret_tensor(buf231, (1, 128, 16384), (2097152, 16384, 1), 0); del buf231  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_52(c_void_p(buf234.data_ptr()), c_void_p(buf230.data_ptr()), c_void_p(addmm_40.data_ptr()), c_void_p(tanh_20.data_ptr()), c_void_p(buf233.data_ptr()))
    del addmm_40
    del tanh_20
    buf235 = reinterpret_tensor(buf225, (128, 4096), (4096, 1), 0); del buf225  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf234, (128, 16384), (16384, 1), 0), permute_548, out=buf235)
    del permute_548
    buf236 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf234, (16384, 128), (1, 16384), 0), view_562, out=buf236)
    buf237 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_53(c_void_p(buf234.data_ptr()), c_void_p(buf237.data_ptr()))
    buf238 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf230, (4096, 128), (1, 4096), 0), view_584, out=buf238)
    del view_584
    buf239 = buf224; del buf224  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf230, (128, 4096), (4096, 1), 0), permute_554, out=buf239)
    del permute_554
    buf240 = reinterpret_tensor(buf221, (16, 128, 256), (32768, 256, 1), 0); del buf221  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_557, reinterpret_tensor(buf239, (16, 128, 256), (256, 4096, 1), 0), out=buf240)
    del permute_557
    buf241 = reinterpret_tensor(buf212, (16, 128, 128), (16384, 128, 1), 0); del buf212  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf239, (16, 128, 256), (256, 4096, 1), 0), permute_558, out=buf241)
    del permute_558
    buf242 = buf211; del buf211  # reuse
    buf243 = reinterpret_tensor(buf241, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf241  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_54(c_void_p(buf243.data_ptr()), c_void_p(alias_73.data_ptr()), c_void_p(slice_1008.data_ptr()), c_void_p(primals_348.data_ptr()), c_void_p(buf242.data_ptr()))
    del alias_73
    del primals_348
    del slice_1008
    buf244 = reinterpret_tensor(buf239, (16, 256, 128), (32768, 128, 1), 0); del buf239  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_559, reinterpret_tensor(buf243, (16, 128, 128), (16384, 128, 1), 0), out=buf244)
    del permute_559
    buf245 = reinterpret_tensor(buf218, (16, 128, 256), (32768, 256, 1), 0); del buf218  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf243, (16, 128, 128), (16384, 128, 1), 0), permute_560, out=buf245)
    del permute_560
    buf246 = buf215; del buf215  # reuse
    buf247 = reinterpret_tensor(buf204, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf204  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_55(c_void_p(tangents_43.data_ptr()), c_void_p(buf244.data_ptr()), c_void_p(unsqueeze_263.data_ptr()), c_void_p(unsqueeze_265.data_ptr()), c_void_p(tangents_44.data_ptr()), c_void_p(buf240.data_ptr()), c_void_p(buf246.data_ptr()), c_void_p(buf247.data_ptr()))
    del tangents_44
    buf248 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf247, (4096, 128), (1, 4096), 0), view_562, out=buf248)
    buf249 = reinterpret_tensor(buf240, (128, 4096), (4096, 1), 0); del buf240  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf247, (128, 4096), (4096, 1), 0), permute_567, out=buf249)
    del permute_567
    buf250 = buf247; del buf247  # reuse
    cpp_fused_add_slice_backward_56(c_void_p(tangents_43.data_ptr()), c_void_p(buf244.data_ptr()), c_void_p(buf246.data_ptr()), c_void_p(buf250.data_ptr()))
    del tangents_43
    buf251 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf250, (4096, 128), (1, 4096), 0), view_562, out=buf251)
    buf252 = reinterpret_tensor(buf244, (128, 4096), (4096, 1), 0); del buf244  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf250, (128, 4096), (4096, 1), 0), permute_571, out=buf252)
    del permute_571
    buf253 = buf250; del buf250  # reuse
    cpp_fused_add_mul_neg_slice_backward_57(c_void_p(buf245.data_ptr()), c_void_p(unsqueeze_263.data_ptr()), c_void_p(unsqueeze_265.data_ptr()), c_void_p(buf253.data_ptr()))
    del unsqueeze_263
    del unsqueeze_265
    buf254 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf253, (4096, 128), (1, 4096), 0), view_562, out=buf254)
    del view_562
    buf255 = reinterpret_tensor(buf245, (128, 4096), (4096, 1), 0); del buf245  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf253, (128, 4096), (4096, 1), 0), permute_575, out=buf255)
    del permute_575
    buf256 = reinterpret_tensor(buf253, (1, 128, 4096), (524288, 4096, 1), 0); del buf253  # reuse
    buf257 = buf227; del buf227  # reuse
    buf258 = buf226; del buf226  # reuse
    buf259 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf260 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf261 = buf230; del buf230  # reuse
    cpp_fused_add_native_layer_norm_backward_58(c_void_p(buf261.data_ptr()), c_void_p(buf235.data_ptr()), c_void_p(buf249.data_ptr()), c_void_p(buf252.data_ptr()), c_void_p(buf255.data_ptr()), c_void_p(primals_202.data_ptr()), c_void_p(mul_200.data_ptr()), c_void_p(div_74.data_ptr()), c_void_p(buf256.data_ptr()), c_void_p(buf257.data_ptr()), c_void_p(buf258.data_ptr()), c_void_p(buf259.data_ptr()), c_void_p(buf260.data_ptr()))
    del div_74
    del mul_200
    del primals_202
    buf262 = reinterpret_tensor(buf234, (128, 16384), (16384, 1), 0); del buf234  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf261, (128, 4096), (4096, 1), 0), permute_577, out=buf262)
    del permute_577
    buf263 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf261, (4096, 128), (1, 4096), 0), view_560, out=buf263)
    del view_560
    buf264 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf265 = reinterpret_tensor(buf262, (1, 128, 16384), (2097152, 16384, 1), 0); del buf262  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_59(c_void_p(buf265.data_ptr()), c_void_p(buf261.data_ptr()), c_void_p(addmm_38.data_ptr()), c_void_p(tanh_19.data_ptr()), c_void_p(buf264.data_ptr()))
    del addmm_38
    del tanh_19
    buf266 = reinterpret_tensor(buf256, (128, 4096), (4096, 1), 0); del buf256  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf265, (128, 16384), (16384, 1), 0), permute_581, out=buf266)
    del permute_581
    buf267 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf265, (16384, 128), (1, 16384), 0), view_534, out=buf267)
    buf268 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_60(c_void_p(buf265.data_ptr()), c_void_p(buf268.data_ptr()))
    buf269 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf261, (4096, 128), (1, 4096), 0), view_556, out=buf269)
    del view_556
    buf270 = buf255; del buf255  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf261, (128, 4096), (4096, 1), 0), permute_587, out=buf270)
    del permute_587
    buf271 = reinterpret_tensor(buf252, (16, 128, 256), (32768, 256, 1), 0); del buf252  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_590, reinterpret_tensor(buf270, (16, 128, 256), (256, 4096, 1), 0), out=buf271)
    del permute_590
    buf272 = reinterpret_tensor(buf243, (16, 128, 128), (16384, 128, 1), 0); del buf243  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf270, (16, 128, 256), (256, 4096, 1), 0), permute_591, out=buf272)
    del permute_591
    buf273 = buf242; del buf242  # reuse
    buf274 = reinterpret_tensor(buf272, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf272  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_61(c_void_p(buf274.data_ptr()), c_void_p(alias_75.data_ptr()), c_void_p(slice_960.data_ptr()), c_void_p(primals_345.data_ptr()), c_void_p(buf273.data_ptr()))
    del alias_75
    del primals_345
    del slice_960
    buf275 = reinterpret_tensor(buf270, (16, 256, 128), (32768, 128, 1), 0); del buf270  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_592, reinterpret_tensor(buf274, (16, 128, 128), (16384, 128, 1), 0), out=buf275)
    del permute_592
    buf276 = reinterpret_tensor(buf249, (16, 128, 256), (32768, 256, 1), 0); del buf249  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf274, (16, 128, 128), (16384, 128, 1), 0), permute_593, out=buf276)
    del permute_593
    buf277 = buf246; del buf246  # reuse
    buf278 = reinterpret_tensor(buf235, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf235  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_62(c_void_p(tangents_41.data_ptr()), c_void_p(buf275.data_ptr()), c_void_p(unsqueeze_250.data_ptr()), c_void_p(unsqueeze_252.data_ptr()), c_void_p(tangents_42.data_ptr()), c_void_p(buf271.data_ptr()), c_void_p(buf277.data_ptr()), c_void_p(buf278.data_ptr()))
    del tangents_42
    buf279 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf278, (4096, 128), (1, 4096), 0), view_534, out=buf279)
    buf280 = reinterpret_tensor(buf271, (128, 4096), (4096, 1), 0); del buf271  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf278, (128, 4096), (4096, 1), 0), permute_600, out=buf280)
    del permute_600
    buf281 = buf278; del buf278  # reuse
    cpp_fused_add_slice_backward_63(c_void_p(tangents_41.data_ptr()), c_void_p(buf275.data_ptr()), c_void_p(buf277.data_ptr()), c_void_p(buf281.data_ptr()))
    del tangents_41
    buf282 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf281, (4096, 128), (1, 4096), 0), view_534, out=buf282)
    buf283 = reinterpret_tensor(buf275, (128, 4096), (4096, 1), 0); del buf275  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf281, (128, 4096), (4096, 1), 0), permute_604, out=buf283)
    del permute_604
    buf284 = buf281; del buf281  # reuse
    cpp_fused_add_mul_neg_slice_backward_64(c_void_p(buf276.data_ptr()), c_void_p(unsqueeze_250.data_ptr()), c_void_p(unsqueeze_252.data_ptr()), c_void_p(buf284.data_ptr()))
    del unsqueeze_250
    del unsqueeze_252
    buf285 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf284, (4096, 128), (1, 4096), 0), view_534, out=buf285)
    del view_534
    buf286 = reinterpret_tensor(buf276, (128, 4096), (4096, 1), 0); del buf276  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf284, (128, 4096), (4096, 1), 0), permute_608, out=buf286)
    del permute_608
    buf287 = reinterpret_tensor(buf284, (1, 128, 4096), (524288, 4096, 1), 0); del buf284  # reuse
    buf288 = buf258; del buf258  # reuse
    buf289 = buf257; del buf257  # reuse
    buf290 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf291 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf292 = buf261; del buf261  # reuse
    cpp_fused_add_native_layer_norm_backward_65(c_void_p(buf292.data_ptr()), c_void_p(buf266.data_ptr()), c_void_p(buf280.data_ptr()), c_void_p(buf283.data_ptr()), c_void_p(buf286.data_ptr()), c_void_p(primals_192.data_ptr()), c_void_p(mul_190.data_ptr()), c_void_p(div_76.data_ptr()), c_void_p(buf287.data_ptr()), c_void_p(buf288.data_ptr()), c_void_p(buf289.data_ptr()), c_void_p(buf290.data_ptr()), c_void_p(buf291.data_ptr()))
    del div_76
    del mul_190
    del primals_192
    buf293 = reinterpret_tensor(buf265, (128, 16384), (16384, 1), 0); del buf265  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf292, (128, 4096), (4096, 1), 0), permute_610, out=buf293)
    del permute_610
    buf294 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf292, (4096, 128), (1, 4096), 0), view_532, out=buf294)
    del view_532
    buf295 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf296 = reinterpret_tensor(buf293, (1, 128, 16384), (2097152, 16384, 1), 0); del buf293  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_66(c_void_p(buf296.data_ptr()), c_void_p(buf292.data_ptr()), c_void_p(addmm_36.data_ptr()), c_void_p(tanh_18.data_ptr()), c_void_p(buf295.data_ptr()))
    del addmm_36
    del tanh_18
    buf297 = reinterpret_tensor(buf287, (128, 4096), (4096, 1), 0); del buf287  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf296, (128, 16384), (16384, 1), 0), permute_614, out=buf297)
    del permute_614
    buf298 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf296, (16384, 128), (1, 16384), 0), view_506, out=buf298)
    buf299 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_67(c_void_p(buf296.data_ptr()), c_void_p(buf299.data_ptr()))
    buf300 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf292, (4096, 128), (1, 4096), 0), view_528, out=buf300)
    del view_528
    buf301 = buf286; del buf286  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf292, (128, 4096), (4096, 1), 0), permute_620, out=buf301)
    del permute_620
    buf302 = reinterpret_tensor(buf283, (16, 128, 256), (32768, 256, 1), 0); del buf283  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_623, reinterpret_tensor(buf301, (16, 128, 256), (256, 4096, 1), 0), out=buf302)
    del permute_623
    buf303 = reinterpret_tensor(buf274, (16, 128, 128), (16384, 128, 1), 0); del buf274  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf301, (16, 128, 256), (256, 4096, 1), 0), permute_624, out=buf303)
    del permute_624
    buf304 = buf273; del buf273  # reuse
    buf305 = reinterpret_tensor(buf303, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf303  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_68(c_void_p(buf305.data_ptr()), c_void_p(alias_77.data_ptr()), c_void_p(slice_912.data_ptr()), c_void_p(primals_342.data_ptr()), c_void_p(buf304.data_ptr()))
    del alias_77
    del primals_342
    del slice_912
    buf306 = reinterpret_tensor(buf301, (16, 256, 128), (32768, 128, 1), 0); del buf301  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_625, reinterpret_tensor(buf305, (16, 128, 128), (16384, 128, 1), 0), out=buf306)
    del permute_625
    buf307 = reinterpret_tensor(buf280, (16, 128, 256), (32768, 256, 1), 0); del buf280  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf305, (16, 128, 128), (16384, 128, 1), 0), permute_626, out=buf307)
    del permute_626
    buf308 = buf277; del buf277  # reuse
    buf309 = reinterpret_tensor(buf266, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf266  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_69(c_void_p(tangents_39.data_ptr()), c_void_p(buf306.data_ptr()), c_void_p(unsqueeze_237.data_ptr()), c_void_p(unsqueeze_239.data_ptr()), c_void_p(tangents_40.data_ptr()), c_void_p(buf302.data_ptr()), c_void_p(buf308.data_ptr()), c_void_p(buf309.data_ptr()))
    del tangents_40
    buf310 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf309, (4096, 128), (1, 4096), 0), view_506, out=buf310)
    buf311 = reinterpret_tensor(buf302, (128, 4096), (4096, 1), 0); del buf302  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf309, (128, 4096), (4096, 1), 0), permute_633, out=buf311)
    del permute_633
    buf312 = buf309; del buf309  # reuse
    cpp_fused_add_slice_backward_70(c_void_p(tangents_39.data_ptr()), c_void_p(buf306.data_ptr()), c_void_p(buf308.data_ptr()), c_void_p(buf312.data_ptr()))
    del tangents_39
    buf313 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf312, (4096, 128), (1, 4096), 0), view_506, out=buf313)
    buf314 = reinterpret_tensor(buf306, (128, 4096), (4096, 1), 0); del buf306  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf312, (128, 4096), (4096, 1), 0), permute_637, out=buf314)
    del permute_637
    buf315 = buf312; del buf312  # reuse
    cpp_fused_add_mul_neg_slice_backward_71(c_void_p(buf307.data_ptr()), c_void_p(unsqueeze_237.data_ptr()), c_void_p(unsqueeze_239.data_ptr()), c_void_p(buf315.data_ptr()))
    del unsqueeze_237
    del unsqueeze_239
    buf316 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf315, (4096, 128), (1, 4096), 0), view_506, out=buf316)
    del view_506
    buf317 = reinterpret_tensor(buf307, (128, 4096), (4096, 1), 0); del buf307  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf315, (128, 4096), (4096, 1), 0), permute_641, out=buf317)
    del permute_641
    buf318 = reinterpret_tensor(buf315, (1, 128, 4096), (524288, 4096, 1), 0); del buf315  # reuse
    buf319 = buf289; del buf289  # reuse
    buf320 = buf288; del buf288  # reuse
    buf321 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf322 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf323 = buf292; del buf292  # reuse
    cpp_fused_add_native_layer_norm_backward_72(c_void_p(buf323.data_ptr()), c_void_p(buf297.data_ptr()), c_void_p(buf311.data_ptr()), c_void_p(buf314.data_ptr()), c_void_p(buf317.data_ptr()), c_void_p(primals_182.data_ptr()), c_void_p(mul_180.data_ptr()), c_void_p(div_78.data_ptr()), c_void_p(buf318.data_ptr()), c_void_p(buf319.data_ptr()), c_void_p(buf320.data_ptr()), c_void_p(buf321.data_ptr()), c_void_p(buf322.data_ptr()))
    del div_78
    del mul_180
    del primals_182
    buf324 = reinterpret_tensor(buf296, (128, 16384), (16384, 1), 0); del buf296  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf323, (128, 4096), (4096, 1), 0), permute_643, out=buf324)
    del permute_643
    buf325 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf323, (4096, 128), (1, 4096), 0), view_504, out=buf325)
    del view_504
    buf326 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf327 = reinterpret_tensor(buf324, (1, 128, 16384), (2097152, 16384, 1), 0); del buf324  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_73(c_void_p(buf327.data_ptr()), c_void_p(buf323.data_ptr()), c_void_p(addmm_34.data_ptr()), c_void_p(tanh_17.data_ptr()), c_void_p(buf326.data_ptr()))
    del addmm_34
    del tanh_17
    buf328 = reinterpret_tensor(buf318, (128, 4096), (4096, 1), 0); del buf318  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf327, (128, 16384), (16384, 1), 0), permute_647, out=buf328)
    del permute_647
    buf329 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf327, (16384, 128), (1, 16384), 0), view_478, out=buf329)
    buf330 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_74(c_void_p(buf327.data_ptr()), c_void_p(buf330.data_ptr()))
    buf331 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf323, (4096, 128), (1, 4096), 0), view_500, out=buf331)
    del view_500
    buf332 = buf317; del buf317  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf323, (128, 4096), (4096, 1), 0), permute_653, out=buf332)
    del permute_653
    buf333 = reinterpret_tensor(buf314, (16, 128, 256), (32768, 256, 1), 0); del buf314  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_656, reinterpret_tensor(buf332, (16, 128, 256), (256, 4096, 1), 0), out=buf333)
    del permute_656
    buf334 = reinterpret_tensor(buf305, (16, 128, 128), (16384, 128, 1), 0); del buf305  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf332, (16, 128, 256), (256, 4096, 1), 0), permute_657, out=buf334)
    del permute_657
    buf335 = buf304; del buf304  # reuse
    buf336 = reinterpret_tensor(buf334, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf334  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_75(c_void_p(buf336.data_ptr()), c_void_p(alias_79.data_ptr()), c_void_p(slice_864.data_ptr()), c_void_p(primals_339.data_ptr()), c_void_p(buf335.data_ptr()))
    del alias_79
    del primals_339
    del slice_864
    buf337 = reinterpret_tensor(buf332, (16, 256, 128), (32768, 128, 1), 0); del buf332  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_658, reinterpret_tensor(buf336, (16, 128, 128), (16384, 128, 1), 0), out=buf337)
    del permute_658
    buf338 = reinterpret_tensor(buf311, (16, 128, 256), (32768, 256, 1), 0); del buf311  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf336, (16, 128, 128), (16384, 128, 1), 0), permute_659, out=buf338)
    del permute_659
    buf339 = buf308; del buf308  # reuse
    buf340 = reinterpret_tensor(buf297, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf297  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_76(c_void_p(tangents_37.data_ptr()), c_void_p(buf337.data_ptr()), c_void_p(unsqueeze_224.data_ptr()), c_void_p(unsqueeze_226.data_ptr()), c_void_p(tangents_38.data_ptr()), c_void_p(buf333.data_ptr()), c_void_p(buf339.data_ptr()), c_void_p(buf340.data_ptr()))
    del tangents_38
    buf341 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf340, (4096, 128), (1, 4096), 0), view_478, out=buf341)
    buf342 = reinterpret_tensor(buf333, (128, 4096), (4096, 1), 0); del buf333  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf340, (128, 4096), (4096, 1), 0), permute_666, out=buf342)
    del permute_666
    buf343 = buf340; del buf340  # reuse
    cpp_fused_add_slice_backward_77(c_void_p(tangents_37.data_ptr()), c_void_p(buf337.data_ptr()), c_void_p(buf339.data_ptr()), c_void_p(buf343.data_ptr()))
    del tangents_37
    buf344 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf343, (4096, 128), (1, 4096), 0), view_478, out=buf344)
    buf345 = reinterpret_tensor(buf337, (128, 4096), (4096, 1), 0); del buf337  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf343, (128, 4096), (4096, 1), 0), permute_670, out=buf345)
    del permute_670
    buf346 = buf343; del buf343  # reuse
    cpp_fused_add_mul_neg_slice_backward_78(c_void_p(buf338.data_ptr()), c_void_p(unsqueeze_224.data_ptr()), c_void_p(unsqueeze_226.data_ptr()), c_void_p(buf346.data_ptr()))
    del unsqueeze_224
    del unsqueeze_226
    buf347 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf346, (4096, 128), (1, 4096), 0), view_478, out=buf347)
    del view_478
    buf348 = reinterpret_tensor(buf338, (128, 4096), (4096, 1), 0); del buf338  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf346, (128, 4096), (4096, 1), 0), permute_674, out=buf348)
    del permute_674
    buf349 = reinterpret_tensor(buf346, (1, 128, 4096), (524288, 4096, 1), 0); del buf346  # reuse
    buf350 = buf320; del buf320  # reuse
    buf351 = buf319; del buf319  # reuse
    buf352 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf353 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf354 = buf323; del buf323  # reuse
    cpp_fused_add_native_layer_norm_backward_79(c_void_p(buf354.data_ptr()), c_void_p(buf328.data_ptr()), c_void_p(buf342.data_ptr()), c_void_p(buf345.data_ptr()), c_void_p(buf348.data_ptr()), c_void_p(primals_172.data_ptr()), c_void_p(mul_170.data_ptr()), c_void_p(div_80.data_ptr()), c_void_p(buf349.data_ptr()), c_void_p(buf350.data_ptr()), c_void_p(buf351.data_ptr()), c_void_p(buf352.data_ptr()), c_void_p(buf353.data_ptr()))
    del div_80
    del mul_170
    del primals_172
    buf355 = reinterpret_tensor(buf327, (128, 16384), (16384, 1), 0); del buf327  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf354, (128, 4096), (4096, 1), 0), permute_676, out=buf355)
    del permute_676
    buf356 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf354, (4096, 128), (1, 4096), 0), view_476, out=buf356)
    del view_476
    buf357 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf358 = reinterpret_tensor(buf355, (1, 128, 16384), (2097152, 16384, 1), 0); del buf355  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_80(c_void_p(buf358.data_ptr()), c_void_p(buf354.data_ptr()), c_void_p(addmm_32.data_ptr()), c_void_p(tanh_16.data_ptr()), c_void_p(buf357.data_ptr()))
    del addmm_32
    del tanh_16
    buf359 = reinterpret_tensor(buf349, (128, 4096), (4096, 1), 0); del buf349  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf358, (128, 16384), (16384, 1), 0), permute_680, out=buf359)
    del permute_680
    buf360 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf358, (16384, 128), (1, 16384), 0), view_450, out=buf360)
    buf361 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_81(c_void_p(buf358.data_ptr()), c_void_p(buf361.data_ptr()))
    buf362 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf354, (4096, 128), (1, 4096), 0), view_472, out=buf362)
    del view_472
    buf363 = buf348; del buf348  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf354, (128, 4096), (4096, 1), 0), permute_686, out=buf363)
    del permute_686
    buf364 = reinterpret_tensor(buf345, (16, 128, 256), (32768, 256, 1), 0); del buf345  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_689, reinterpret_tensor(buf363, (16, 128, 256), (256, 4096, 1), 0), out=buf364)
    del permute_689
    buf365 = reinterpret_tensor(buf336, (16, 128, 128), (16384, 128, 1), 0); del buf336  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf363, (16, 128, 256), (256, 4096, 1), 0), permute_690, out=buf365)
    del permute_690
    buf366 = buf335; del buf335  # reuse
    buf367 = reinterpret_tensor(buf365, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf365  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_82(c_void_p(buf367.data_ptr()), c_void_p(alias_81.data_ptr()), c_void_p(slice_816.data_ptr()), c_void_p(primals_336.data_ptr()), c_void_p(buf366.data_ptr()))
    del alias_81
    del primals_336
    del slice_816
    buf368 = reinterpret_tensor(buf363, (16, 256, 128), (32768, 128, 1), 0); del buf363  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_691, reinterpret_tensor(buf367, (16, 128, 128), (16384, 128, 1), 0), out=buf368)
    del permute_691
    buf369 = reinterpret_tensor(buf342, (16, 128, 256), (32768, 256, 1), 0); del buf342  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf367, (16, 128, 128), (16384, 128, 1), 0), permute_692, out=buf369)
    del permute_692
    buf370 = buf339; del buf339  # reuse
    buf371 = reinterpret_tensor(buf328, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf328  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_83(c_void_p(tangents_35.data_ptr()), c_void_p(buf368.data_ptr()), c_void_p(unsqueeze_211.data_ptr()), c_void_p(unsqueeze_213.data_ptr()), c_void_p(tangents_36.data_ptr()), c_void_p(buf364.data_ptr()), c_void_p(buf370.data_ptr()), c_void_p(buf371.data_ptr()))
    del tangents_36
    buf372 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf371, (4096, 128), (1, 4096), 0), view_450, out=buf372)
    buf373 = reinterpret_tensor(buf364, (128, 4096), (4096, 1), 0); del buf364  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf371, (128, 4096), (4096, 1), 0), permute_699, out=buf373)
    del permute_699
    buf374 = buf371; del buf371  # reuse
    cpp_fused_add_slice_backward_84(c_void_p(tangents_35.data_ptr()), c_void_p(buf368.data_ptr()), c_void_p(buf370.data_ptr()), c_void_p(buf374.data_ptr()))
    del tangents_35
    buf375 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf374, (4096, 128), (1, 4096), 0), view_450, out=buf375)
    buf376 = reinterpret_tensor(buf368, (128, 4096), (4096, 1), 0); del buf368  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf374, (128, 4096), (4096, 1), 0), permute_703, out=buf376)
    del permute_703
    buf377 = buf374; del buf374  # reuse
    cpp_fused_add_mul_neg_slice_backward_85(c_void_p(buf369.data_ptr()), c_void_p(unsqueeze_211.data_ptr()), c_void_p(unsqueeze_213.data_ptr()), c_void_p(buf377.data_ptr()))
    del unsqueeze_211
    del unsqueeze_213
    buf378 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf377, (4096, 128), (1, 4096), 0), view_450, out=buf378)
    del view_450
    buf379 = reinterpret_tensor(buf369, (128, 4096), (4096, 1), 0); del buf369  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf377, (128, 4096), (4096, 1), 0), permute_707, out=buf379)
    del permute_707
    buf380 = reinterpret_tensor(buf377, (1, 128, 4096), (524288, 4096, 1), 0); del buf377  # reuse
    buf381 = buf351; del buf351  # reuse
    buf382 = buf350; del buf350  # reuse
    buf383 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf384 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf385 = buf354; del buf354  # reuse
    cpp_fused_add_native_layer_norm_backward_86(c_void_p(buf385.data_ptr()), c_void_p(buf359.data_ptr()), c_void_p(buf373.data_ptr()), c_void_p(buf376.data_ptr()), c_void_p(buf379.data_ptr()), c_void_p(primals_162.data_ptr()), c_void_p(mul_160.data_ptr()), c_void_p(div_82.data_ptr()), c_void_p(buf380.data_ptr()), c_void_p(buf381.data_ptr()), c_void_p(buf382.data_ptr()), c_void_p(buf383.data_ptr()), c_void_p(buf384.data_ptr()))
    del div_82
    del mul_160
    del primals_162
    buf386 = reinterpret_tensor(buf358, (128, 16384), (16384, 1), 0); del buf358  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf385, (128, 4096), (4096, 1), 0), permute_709, out=buf386)
    del permute_709
    buf387 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf385, (4096, 128), (1, 4096), 0), view_448, out=buf387)
    del view_448
    buf388 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf389 = reinterpret_tensor(buf386, (1, 128, 16384), (2097152, 16384, 1), 0); del buf386  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_87(c_void_p(buf389.data_ptr()), c_void_p(buf385.data_ptr()), c_void_p(addmm_30.data_ptr()), c_void_p(tanh_15.data_ptr()), c_void_p(buf388.data_ptr()))
    del addmm_30
    del tanh_15
    buf390 = reinterpret_tensor(buf380, (128, 4096), (4096, 1), 0); del buf380  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf389, (128, 16384), (16384, 1), 0), permute_713, out=buf390)
    del permute_713
    buf391 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf389, (16384, 128), (1, 16384), 0), view_422, out=buf391)
    buf392 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_88(c_void_p(buf389.data_ptr()), c_void_p(buf392.data_ptr()))
    buf393 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf385, (4096, 128), (1, 4096), 0), view_444, out=buf393)
    del view_444
    buf394 = buf379; del buf379  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf385, (128, 4096), (4096, 1), 0), permute_719, out=buf394)
    del permute_719
    buf395 = reinterpret_tensor(buf376, (16, 128, 256), (32768, 256, 1), 0); del buf376  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_722, reinterpret_tensor(buf394, (16, 128, 256), (256, 4096, 1), 0), out=buf395)
    del permute_722
    buf396 = reinterpret_tensor(buf367, (16, 128, 128), (16384, 128, 1), 0); del buf367  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf394, (16, 128, 256), (256, 4096, 1), 0), permute_723, out=buf396)
    del permute_723
    buf397 = buf366; del buf366  # reuse
    buf398 = reinterpret_tensor(buf396, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf396  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_89(c_void_p(buf398.data_ptr()), c_void_p(alias_83.data_ptr()), c_void_p(slice_768.data_ptr()), c_void_p(primals_333.data_ptr()), c_void_p(buf397.data_ptr()))
    del alias_83
    del primals_333
    del slice_768
    buf399 = reinterpret_tensor(buf394, (16, 256, 128), (32768, 128, 1), 0); del buf394  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_724, reinterpret_tensor(buf398, (16, 128, 128), (16384, 128, 1), 0), out=buf399)
    del permute_724
    buf400 = reinterpret_tensor(buf373, (16, 128, 256), (32768, 256, 1), 0); del buf373  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf398, (16, 128, 128), (16384, 128, 1), 0), permute_725, out=buf400)
    del permute_725
    buf401 = buf370; del buf370  # reuse
    buf402 = reinterpret_tensor(buf359, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf359  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_90(c_void_p(tangents_33.data_ptr()), c_void_p(buf399.data_ptr()), c_void_p(unsqueeze_198.data_ptr()), c_void_p(unsqueeze_200.data_ptr()), c_void_p(tangents_34.data_ptr()), c_void_p(buf395.data_ptr()), c_void_p(buf401.data_ptr()), c_void_p(buf402.data_ptr()))
    del tangents_34
    buf403 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf402, (4096, 128), (1, 4096), 0), view_422, out=buf403)
    buf404 = reinterpret_tensor(buf395, (128, 4096), (4096, 1), 0); del buf395  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf402, (128, 4096), (4096, 1), 0), permute_732, out=buf404)
    del permute_732
    buf405 = buf402; del buf402  # reuse
    cpp_fused_add_slice_backward_91(c_void_p(tangents_33.data_ptr()), c_void_p(buf399.data_ptr()), c_void_p(buf401.data_ptr()), c_void_p(buf405.data_ptr()))
    del tangents_33
    buf406 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf405, (4096, 128), (1, 4096), 0), view_422, out=buf406)
    buf407 = reinterpret_tensor(buf399, (128, 4096), (4096, 1), 0); del buf399  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf405, (128, 4096), (4096, 1), 0), permute_736, out=buf407)
    del permute_736
    buf408 = buf405; del buf405  # reuse
    cpp_fused_add_mul_neg_slice_backward_92(c_void_p(buf400.data_ptr()), c_void_p(unsqueeze_198.data_ptr()), c_void_p(unsqueeze_200.data_ptr()), c_void_p(buf408.data_ptr()))
    del unsqueeze_198
    del unsqueeze_200
    buf409 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf408, (4096, 128), (1, 4096), 0), view_422, out=buf409)
    del view_422
    buf410 = reinterpret_tensor(buf400, (128, 4096), (4096, 1), 0); del buf400  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf408, (128, 4096), (4096, 1), 0), permute_740, out=buf410)
    del permute_740
    buf411 = reinterpret_tensor(buf408, (1, 128, 4096), (524288, 4096, 1), 0); del buf408  # reuse
    buf412 = buf382; del buf382  # reuse
    buf413 = buf381; del buf381  # reuse
    buf414 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf415 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf416 = buf385; del buf385  # reuse
    cpp_fused_add_native_layer_norm_backward_93(c_void_p(buf416.data_ptr()), c_void_p(buf390.data_ptr()), c_void_p(buf404.data_ptr()), c_void_p(buf407.data_ptr()), c_void_p(buf410.data_ptr()), c_void_p(primals_152.data_ptr()), c_void_p(mul_150.data_ptr()), c_void_p(div_84.data_ptr()), c_void_p(buf411.data_ptr()), c_void_p(buf412.data_ptr()), c_void_p(buf413.data_ptr()), c_void_p(buf414.data_ptr()), c_void_p(buf415.data_ptr()))
    del div_84
    del mul_150
    del primals_152
    buf417 = reinterpret_tensor(buf389, (128, 16384), (16384, 1), 0); del buf389  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf416, (128, 4096), (4096, 1), 0), permute_742, out=buf417)
    del permute_742
    buf418 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf416, (4096, 128), (1, 4096), 0), view_420, out=buf418)
    del view_420
    buf419 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf420 = reinterpret_tensor(buf417, (1, 128, 16384), (2097152, 16384, 1), 0); del buf417  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_94(c_void_p(buf420.data_ptr()), c_void_p(buf416.data_ptr()), c_void_p(addmm_28.data_ptr()), c_void_p(tanh_14.data_ptr()), c_void_p(buf419.data_ptr()))
    del addmm_28
    del tanh_14
    buf421 = reinterpret_tensor(buf411, (128, 4096), (4096, 1), 0); del buf411  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf420, (128, 16384), (16384, 1), 0), permute_746, out=buf421)
    del permute_746
    buf422 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf420, (16384, 128), (1, 16384), 0), view_394, out=buf422)
    buf423 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_95(c_void_p(buf420.data_ptr()), c_void_p(buf423.data_ptr()))
    buf424 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf416, (4096, 128), (1, 4096), 0), view_416, out=buf424)
    del view_416
    buf425 = buf410; del buf410  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf416, (128, 4096), (4096, 1), 0), permute_752, out=buf425)
    del permute_752
    buf426 = reinterpret_tensor(buf407, (16, 128, 256), (32768, 256, 1), 0); del buf407  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_755, reinterpret_tensor(buf425, (16, 128, 256), (256, 4096, 1), 0), out=buf426)
    del permute_755
    buf427 = reinterpret_tensor(buf398, (16, 128, 128), (16384, 128, 1), 0); del buf398  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf425, (16, 128, 256), (256, 4096, 1), 0), permute_756, out=buf427)
    del permute_756
    buf428 = buf397; del buf397  # reuse
    buf429 = reinterpret_tensor(buf427, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf427  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_96(c_void_p(buf429.data_ptr()), c_void_p(alias_85.data_ptr()), c_void_p(slice_720.data_ptr()), c_void_p(primals_330.data_ptr()), c_void_p(buf428.data_ptr()))
    del alias_85
    del primals_330
    del slice_720
    buf430 = reinterpret_tensor(buf425, (16, 256, 128), (32768, 128, 1), 0); del buf425  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_757, reinterpret_tensor(buf429, (16, 128, 128), (16384, 128, 1), 0), out=buf430)
    del permute_757
    buf431 = reinterpret_tensor(buf404, (16, 128, 256), (32768, 256, 1), 0); del buf404  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf429, (16, 128, 128), (16384, 128, 1), 0), permute_758, out=buf431)
    del permute_758
    buf432 = buf401; del buf401  # reuse
    buf433 = reinterpret_tensor(buf390, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf390  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_97(c_void_p(tangents_31.data_ptr()), c_void_p(buf430.data_ptr()), c_void_p(unsqueeze_185.data_ptr()), c_void_p(unsqueeze_187.data_ptr()), c_void_p(tangents_32.data_ptr()), c_void_p(buf426.data_ptr()), c_void_p(buf432.data_ptr()), c_void_p(buf433.data_ptr()))
    del tangents_32
    buf434 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf433, (4096, 128), (1, 4096), 0), view_394, out=buf434)
    buf435 = reinterpret_tensor(buf426, (128, 4096), (4096, 1), 0); del buf426  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf433, (128, 4096), (4096, 1), 0), permute_765, out=buf435)
    del permute_765
    buf436 = buf433; del buf433  # reuse
    cpp_fused_add_slice_backward_98(c_void_p(tangents_31.data_ptr()), c_void_p(buf430.data_ptr()), c_void_p(buf432.data_ptr()), c_void_p(buf436.data_ptr()))
    del tangents_31
    buf437 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf436, (4096, 128), (1, 4096), 0), view_394, out=buf437)
    buf438 = reinterpret_tensor(buf430, (128, 4096), (4096, 1), 0); del buf430  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf436, (128, 4096), (4096, 1), 0), permute_769, out=buf438)
    del permute_769
    buf439 = buf436; del buf436  # reuse
    cpp_fused_add_mul_neg_slice_backward_99(c_void_p(buf431.data_ptr()), c_void_p(unsqueeze_185.data_ptr()), c_void_p(unsqueeze_187.data_ptr()), c_void_p(buf439.data_ptr()))
    del unsqueeze_185
    del unsqueeze_187
    buf440 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf439, (4096, 128), (1, 4096), 0), view_394, out=buf440)
    del view_394
    buf441 = reinterpret_tensor(buf431, (128, 4096), (4096, 1), 0); del buf431  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf439, (128, 4096), (4096, 1), 0), permute_773, out=buf441)
    del permute_773
    buf442 = reinterpret_tensor(buf439, (1, 128, 4096), (524288, 4096, 1), 0); del buf439  # reuse
    buf443 = buf413; del buf413  # reuse
    buf444 = buf412; del buf412  # reuse
    buf445 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf446 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf447 = buf416; del buf416  # reuse
    cpp_fused_add_native_layer_norm_backward_100(c_void_p(buf447.data_ptr()), c_void_p(buf421.data_ptr()), c_void_p(buf435.data_ptr()), c_void_p(buf438.data_ptr()), c_void_p(buf441.data_ptr()), c_void_p(primals_142.data_ptr()), c_void_p(mul_140.data_ptr()), c_void_p(div_86.data_ptr()), c_void_p(buf442.data_ptr()), c_void_p(buf443.data_ptr()), c_void_p(buf444.data_ptr()), c_void_p(buf445.data_ptr()), c_void_p(buf446.data_ptr()))
    del div_86
    del mul_140
    del primals_142
    buf448 = reinterpret_tensor(buf420, (128, 16384), (16384, 1), 0); del buf420  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf447, (128, 4096), (4096, 1), 0), permute_775, out=buf448)
    del permute_775
    buf449 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf447, (4096, 128), (1, 4096), 0), view_392, out=buf449)
    del view_392
    buf450 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf451 = reinterpret_tensor(buf448, (1, 128, 16384), (2097152, 16384, 1), 0); del buf448  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_101(c_void_p(buf451.data_ptr()), c_void_p(buf447.data_ptr()), c_void_p(addmm_26.data_ptr()), c_void_p(tanh_13.data_ptr()), c_void_p(buf450.data_ptr()))
    del addmm_26
    del tanh_13
    buf452 = reinterpret_tensor(buf442, (128, 4096), (4096, 1), 0); del buf442  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf451, (128, 16384), (16384, 1), 0), permute_779, out=buf452)
    del permute_779
    buf453 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf451, (16384, 128), (1, 16384), 0), view_366, out=buf453)
    buf454 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_102(c_void_p(buf451.data_ptr()), c_void_p(buf454.data_ptr()))
    buf455 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf447, (4096, 128), (1, 4096), 0), view_388, out=buf455)
    del view_388
    buf456 = buf441; del buf441  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf447, (128, 4096), (4096, 1), 0), permute_785, out=buf456)
    del permute_785
    buf457 = reinterpret_tensor(buf438, (16, 128, 256), (32768, 256, 1), 0); del buf438  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_788, reinterpret_tensor(buf456, (16, 128, 256), (256, 4096, 1), 0), out=buf457)
    del permute_788
    buf458 = reinterpret_tensor(buf429, (16, 128, 128), (16384, 128, 1), 0); del buf429  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf456, (16, 128, 256), (256, 4096, 1), 0), permute_789, out=buf458)
    del permute_789
    buf459 = buf428; del buf428  # reuse
    buf460 = reinterpret_tensor(buf458, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf458  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_103(c_void_p(buf460.data_ptr()), c_void_p(alias_87.data_ptr()), c_void_p(slice_672.data_ptr()), c_void_p(primals_327.data_ptr()), c_void_p(buf459.data_ptr()))
    del alias_87
    del primals_327
    del slice_672
    buf461 = reinterpret_tensor(buf456, (16, 256, 128), (32768, 128, 1), 0); del buf456  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_790, reinterpret_tensor(buf460, (16, 128, 128), (16384, 128, 1), 0), out=buf461)
    del permute_790
    buf462 = reinterpret_tensor(buf435, (16, 128, 256), (32768, 256, 1), 0); del buf435  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf460, (16, 128, 128), (16384, 128, 1), 0), permute_791, out=buf462)
    del permute_791
    buf463 = buf432; del buf432  # reuse
    buf464 = reinterpret_tensor(buf421, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf421  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_104(c_void_p(tangents_29.data_ptr()), c_void_p(buf461.data_ptr()), c_void_p(unsqueeze_172.data_ptr()), c_void_p(unsqueeze_174.data_ptr()), c_void_p(tangents_30.data_ptr()), c_void_p(buf457.data_ptr()), c_void_p(buf463.data_ptr()), c_void_p(buf464.data_ptr()))
    del tangents_30
    buf465 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf464, (4096, 128), (1, 4096), 0), view_366, out=buf465)
    buf466 = reinterpret_tensor(buf457, (128, 4096), (4096, 1), 0); del buf457  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf464, (128, 4096), (4096, 1), 0), permute_798, out=buf466)
    del permute_798
    buf467 = buf464; del buf464  # reuse
    cpp_fused_add_slice_backward_105(c_void_p(tangents_29.data_ptr()), c_void_p(buf461.data_ptr()), c_void_p(buf463.data_ptr()), c_void_p(buf467.data_ptr()))
    del tangents_29
    buf468 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf467, (4096, 128), (1, 4096), 0), view_366, out=buf468)
    buf469 = reinterpret_tensor(buf461, (128, 4096), (4096, 1), 0); del buf461  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf467, (128, 4096), (4096, 1), 0), permute_802, out=buf469)
    del permute_802
    buf470 = buf467; del buf467  # reuse
    cpp_fused_add_mul_neg_slice_backward_106(c_void_p(buf462.data_ptr()), c_void_p(unsqueeze_172.data_ptr()), c_void_p(unsqueeze_174.data_ptr()), c_void_p(buf470.data_ptr()))
    del unsqueeze_172
    del unsqueeze_174
    buf471 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf470, (4096, 128), (1, 4096), 0), view_366, out=buf471)
    del view_366
    buf472 = reinterpret_tensor(buf462, (128, 4096), (4096, 1), 0); del buf462  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf470, (128, 4096), (4096, 1), 0), permute_806, out=buf472)
    del permute_806
    buf473 = reinterpret_tensor(buf470, (1, 128, 4096), (524288, 4096, 1), 0); del buf470  # reuse
    buf474 = buf444; del buf444  # reuse
    buf475 = buf443; del buf443  # reuse
    buf476 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf477 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf478 = buf447; del buf447  # reuse
    cpp_fused_add_native_layer_norm_backward_107(c_void_p(buf478.data_ptr()), c_void_p(buf452.data_ptr()), c_void_p(buf466.data_ptr()), c_void_p(buf469.data_ptr()), c_void_p(buf472.data_ptr()), c_void_p(primals_132.data_ptr()), c_void_p(mul_130.data_ptr()), c_void_p(div_88.data_ptr()), c_void_p(buf473.data_ptr()), c_void_p(buf474.data_ptr()), c_void_p(buf475.data_ptr()), c_void_p(buf476.data_ptr()), c_void_p(buf477.data_ptr()))
    del div_88
    del mul_130
    del primals_132
    buf479 = reinterpret_tensor(buf451, (128, 16384), (16384, 1), 0); del buf451  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf478, (128, 4096), (4096, 1), 0), permute_808, out=buf479)
    del permute_808
    buf480 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf478, (4096, 128), (1, 4096), 0), view_364, out=buf480)
    del view_364
    buf481 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf482 = reinterpret_tensor(buf479, (1, 128, 16384), (2097152, 16384, 1), 0); del buf479  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_108(c_void_p(buf482.data_ptr()), c_void_p(buf478.data_ptr()), c_void_p(addmm_24.data_ptr()), c_void_p(tanh_12.data_ptr()), c_void_p(buf481.data_ptr()))
    del addmm_24
    del tanh_12
    buf483 = reinterpret_tensor(buf473, (128, 4096), (4096, 1), 0); del buf473  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf482, (128, 16384), (16384, 1), 0), permute_812, out=buf483)
    del permute_812
    buf484 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf482, (16384, 128), (1, 16384), 0), view_338, out=buf484)
    buf485 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_109(c_void_p(buf482.data_ptr()), c_void_p(buf485.data_ptr()))
    buf486 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf478, (4096, 128), (1, 4096), 0), view_360, out=buf486)
    del view_360
    buf487 = buf472; del buf472  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf478, (128, 4096), (4096, 1), 0), permute_818, out=buf487)
    del permute_818
    buf488 = reinterpret_tensor(buf469, (16, 128, 256), (32768, 256, 1), 0); del buf469  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_821, reinterpret_tensor(buf487, (16, 128, 256), (256, 4096, 1), 0), out=buf488)
    del permute_821
    buf489 = reinterpret_tensor(buf460, (16, 128, 128), (16384, 128, 1), 0); del buf460  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf487, (16, 128, 256), (256, 4096, 1), 0), permute_822, out=buf489)
    del permute_822
    buf490 = buf459; del buf459  # reuse
    buf491 = reinterpret_tensor(buf489, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf489  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_110(c_void_p(buf491.data_ptr()), c_void_p(alias_89.data_ptr()), c_void_p(slice_624.data_ptr()), c_void_p(primals_324.data_ptr()), c_void_p(buf490.data_ptr()))
    del alias_89
    del primals_324
    del slice_624
    buf492 = reinterpret_tensor(buf487, (16, 256, 128), (32768, 128, 1), 0); del buf487  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_823, reinterpret_tensor(buf491, (16, 128, 128), (16384, 128, 1), 0), out=buf492)
    del permute_823
    buf493 = reinterpret_tensor(buf466, (16, 128, 256), (32768, 256, 1), 0); del buf466  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf491, (16, 128, 128), (16384, 128, 1), 0), permute_824, out=buf493)
    del permute_824
    buf494 = buf463; del buf463  # reuse
    buf495 = reinterpret_tensor(buf452, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf452  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_111(c_void_p(tangents_27.data_ptr()), c_void_p(buf492.data_ptr()), c_void_p(unsqueeze_159.data_ptr()), c_void_p(unsqueeze_161.data_ptr()), c_void_p(tangents_28.data_ptr()), c_void_p(buf488.data_ptr()), c_void_p(buf494.data_ptr()), c_void_p(buf495.data_ptr()))
    del tangents_28
    buf496 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf495, (4096, 128), (1, 4096), 0), view_338, out=buf496)
    buf497 = reinterpret_tensor(buf488, (128, 4096), (4096, 1), 0); del buf488  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf495, (128, 4096), (4096, 1), 0), permute_831, out=buf497)
    del permute_831
    buf498 = buf495; del buf495  # reuse
    cpp_fused_add_slice_backward_112(c_void_p(tangents_27.data_ptr()), c_void_p(buf492.data_ptr()), c_void_p(buf494.data_ptr()), c_void_p(buf498.data_ptr()))
    del tangents_27
    buf499 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf498, (4096, 128), (1, 4096), 0), view_338, out=buf499)
    buf500 = reinterpret_tensor(buf492, (128, 4096), (4096, 1), 0); del buf492  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf498, (128, 4096), (4096, 1), 0), permute_835, out=buf500)
    del permute_835
    buf501 = buf498; del buf498  # reuse
    cpp_fused_add_mul_neg_slice_backward_113(c_void_p(buf493.data_ptr()), c_void_p(unsqueeze_159.data_ptr()), c_void_p(unsqueeze_161.data_ptr()), c_void_p(buf501.data_ptr()))
    del unsqueeze_159
    del unsqueeze_161
    buf502 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf501, (4096, 128), (1, 4096), 0), view_338, out=buf502)
    del view_338
    buf503 = reinterpret_tensor(buf493, (128, 4096), (4096, 1), 0); del buf493  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf501, (128, 4096), (4096, 1), 0), permute_839, out=buf503)
    del permute_839
    buf504 = reinterpret_tensor(buf501, (1, 128, 4096), (524288, 4096, 1), 0); del buf501  # reuse
    buf505 = buf475; del buf475  # reuse
    buf506 = buf474; del buf474  # reuse
    buf507 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf508 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf509 = buf478; del buf478  # reuse
    cpp_fused_add_native_layer_norm_backward_114(c_void_p(buf509.data_ptr()), c_void_p(buf483.data_ptr()), c_void_p(buf497.data_ptr()), c_void_p(buf500.data_ptr()), c_void_p(buf503.data_ptr()), c_void_p(primals_122.data_ptr()), c_void_p(mul_120.data_ptr()), c_void_p(div_90.data_ptr()), c_void_p(buf504.data_ptr()), c_void_p(buf505.data_ptr()), c_void_p(buf506.data_ptr()), c_void_p(buf507.data_ptr()), c_void_p(buf508.data_ptr()))
    del div_90
    del mul_120
    del primals_122
    buf510 = reinterpret_tensor(buf482, (128, 16384), (16384, 1), 0); del buf482  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf509, (128, 4096), (4096, 1), 0), permute_841, out=buf510)
    del permute_841
    buf511 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf509, (4096, 128), (1, 4096), 0), view_336, out=buf511)
    del view_336
    buf512 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf513 = reinterpret_tensor(buf510, (1, 128, 16384), (2097152, 16384, 1), 0); del buf510  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_115(c_void_p(buf513.data_ptr()), c_void_p(buf509.data_ptr()), c_void_p(addmm_22.data_ptr()), c_void_p(tanh_11.data_ptr()), c_void_p(buf512.data_ptr()))
    del addmm_22
    del tanh_11
    buf514 = reinterpret_tensor(buf504, (128, 4096), (4096, 1), 0); del buf504  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf513, (128, 16384), (16384, 1), 0), permute_845, out=buf514)
    del permute_845
    buf515 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf513, (16384, 128), (1, 16384), 0), view_310, out=buf515)
    buf516 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_116(c_void_p(buf513.data_ptr()), c_void_p(buf516.data_ptr()))
    buf517 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf509, (4096, 128), (1, 4096), 0), view_332, out=buf517)
    del view_332
    buf518 = buf503; del buf503  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf509, (128, 4096), (4096, 1), 0), permute_851, out=buf518)
    del permute_851
    buf519 = reinterpret_tensor(buf500, (16, 128, 256), (32768, 256, 1), 0); del buf500  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_854, reinterpret_tensor(buf518, (16, 128, 256), (256, 4096, 1), 0), out=buf519)
    del permute_854
    buf520 = reinterpret_tensor(buf491, (16, 128, 128), (16384, 128, 1), 0); del buf491  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf518, (16, 128, 256), (256, 4096, 1), 0), permute_855, out=buf520)
    del permute_855
    buf521 = buf490; del buf490  # reuse
    buf522 = reinterpret_tensor(buf520, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf520  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_117(c_void_p(buf522.data_ptr()), c_void_p(alias_91.data_ptr()), c_void_p(slice_576.data_ptr()), c_void_p(primals_321.data_ptr()), c_void_p(buf521.data_ptr()))
    del alias_91
    del primals_321
    del slice_576
    buf523 = reinterpret_tensor(buf518, (16, 256, 128), (32768, 128, 1), 0); del buf518  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_856, reinterpret_tensor(buf522, (16, 128, 128), (16384, 128, 1), 0), out=buf523)
    del permute_856
    buf524 = reinterpret_tensor(buf497, (16, 128, 256), (32768, 256, 1), 0); del buf497  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf522, (16, 128, 128), (16384, 128, 1), 0), permute_857, out=buf524)
    del permute_857
    buf525 = buf494; del buf494  # reuse
    buf526 = reinterpret_tensor(buf483, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf483  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_118(c_void_p(tangents_25.data_ptr()), c_void_p(buf523.data_ptr()), c_void_p(unsqueeze_146.data_ptr()), c_void_p(unsqueeze_148.data_ptr()), c_void_p(tangents_26.data_ptr()), c_void_p(buf519.data_ptr()), c_void_p(buf525.data_ptr()), c_void_p(buf526.data_ptr()))
    del tangents_26
    buf527 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf526, (4096, 128), (1, 4096), 0), view_310, out=buf527)
    buf528 = reinterpret_tensor(buf519, (128, 4096), (4096, 1), 0); del buf519  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf526, (128, 4096), (4096, 1), 0), permute_864, out=buf528)
    del permute_864
    buf529 = buf526; del buf526  # reuse
    cpp_fused_add_slice_backward_119(c_void_p(tangents_25.data_ptr()), c_void_p(buf523.data_ptr()), c_void_p(buf525.data_ptr()), c_void_p(buf529.data_ptr()))
    del tangents_25
    buf530 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf529, (4096, 128), (1, 4096), 0), view_310, out=buf530)
    buf531 = reinterpret_tensor(buf523, (128, 4096), (4096, 1), 0); del buf523  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf529, (128, 4096), (4096, 1), 0), permute_868, out=buf531)
    del permute_868
    buf532 = buf529; del buf529  # reuse
    cpp_fused_add_mul_neg_slice_backward_120(c_void_p(buf524.data_ptr()), c_void_p(unsqueeze_146.data_ptr()), c_void_p(unsqueeze_148.data_ptr()), c_void_p(buf532.data_ptr()))
    del unsqueeze_146
    del unsqueeze_148
    buf533 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf532, (4096, 128), (1, 4096), 0), view_310, out=buf533)
    del view_310
    buf534 = reinterpret_tensor(buf524, (128, 4096), (4096, 1), 0); del buf524  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf532, (128, 4096), (4096, 1), 0), permute_872, out=buf534)
    del permute_872
    buf535 = reinterpret_tensor(buf532, (1, 128, 4096), (524288, 4096, 1), 0); del buf532  # reuse
    buf536 = buf506; del buf506  # reuse
    buf537 = buf505; del buf505  # reuse
    buf538 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf539 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf540 = buf509; del buf509  # reuse
    cpp_fused_add_native_layer_norm_backward_121(c_void_p(buf540.data_ptr()), c_void_p(buf514.data_ptr()), c_void_p(buf528.data_ptr()), c_void_p(buf531.data_ptr()), c_void_p(buf534.data_ptr()), c_void_p(primals_112.data_ptr()), c_void_p(mul_110.data_ptr()), c_void_p(div_92.data_ptr()), c_void_p(buf535.data_ptr()), c_void_p(buf536.data_ptr()), c_void_p(buf537.data_ptr()), c_void_p(buf538.data_ptr()), c_void_p(buf539.data_ptr()))
    del div_92
    del mul_110
    del primals_112
    buf541 = reinterpret_tensor(buf513, (128, 16384), (16384, 1), 0); del buf513  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf540, (128, 4096), (4096, 1), 0), permute_874, out=buf541)
    del permute_874
    buf542 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf540, (4096, 128), (1, 4096), 0), view_308, out=buf542)
    del view_308
    buf543 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf544 = reinterpret_tensor(buf541, (1, 128, 16384), (2097152, 16384, 1), 0); del buf541  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_122(c_void_p(buf544.data_ptr()), c_void_p(buf540.data_ptr()), c_void_p(addmm_20.data_ptr()), c_void_p(tanh_10.data_ptr()), c_void_p(buf543.data_ptr()))
    del addmm_20
    del tanh_10
    buf545 = reinterpret_tensor(buf535, (128, 4096), (4096, 1), 0); del buf535  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf544, (128, 16384), (16384, 1), 0), permute_878, out=buf545)
    del permute_878
    buf546 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf544, (16384, 128), (1, 16384), 0), view_282, out=buf546)
    buf547 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_123(c_void_p(buf544.data_ptr()), c_void_p(buf547.data_ptr()))
    buf548 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf540, (4096, 128), (1, 4096), 0), view_304, out=buf548)
    del view_304
    buf549 = buf534; del buf534  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf540, (128, 4096), (4096, 1), 0), permute_884, out=buf549)
    del permute_884
    buf550 = reinterpret_tensor(buf531, (16, 128, 256), (32768, 256, 1), 0); del buf531  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_887, reinterpret_tensor(buf549, (16, 128, 256), (256, 4096, 1), 0), out=buf550)
    del permute_887
    buf551 = reinterpret_tensor(buf522, (16, 128, 128), (16384, 128, 1), 0); del buf522  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf549, (16, 128, 256), (256, 4096, 1), 0), permute_888, out=buf551)
    del permute_888
    buf552 = buf521; del buf521  # reuse
    buf553 = reinterpret_tensor(buf551, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf551  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_124(c_void_p(buf553.data_ptr()), c_void_p(alias_93.data_ptr()), c_void_p(slice_528.data_ptr()), c_void_p(primals_318.data_ptr()), c_void_p(buf552.data_ptr()))
    del alias_93
    del primals_318
    del slice_528
    buf554 = reinterpret_tensor(buf549, (16, 256, 128), (32768, 128, 1), 0); del buf549  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_889, reinterpret_tensor(buf553, (16, 128, 128), (16384, 128, 1), 0), out=buf554)
    del permute_889
    buf555 = reinterpret_tensor(buf528, (16, 128, 256), (32768, 256, 1), 0); del buf528  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf553, (16, 128, 128), (16384, 128, 1), 0), permute_890, out=buf555)
    del permute_890
    buf556 = buf525; del buf525  # reuse
    buf557 = reinterpret_tensor(buf514, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf514  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_125(c_void_p(tangents_23.data_ptr()), c_void_p(buf554.data_ptr()), c_void_p(unsqueeze_133.data_ptr()), c_void_p(unsqueeze_135.data_ptr()), c_void_p(tangents_24.data_ptr()), c_void_p(buf550.data_ptr()), c_void_p(buf556.data_ptr()), c_void_p(buf557.data_ptr()))
    del tangents_24
    buf558 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf557, (4096, 128), (1, 4096), 0), view_282, out=buf558)
    buf559 = reinterpret_tensor(buf550, (128, 4096), (4096, 1), 0); del buf550  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf557, (128, 4096), (4096, 1), 0), permute_897, out=buf559)
    del permute_897
    buf560 = buf557; del buf557  # reuse
    cpp_fused_add_slice_backward_126(c_void_p(tangents_23.data_ptr()), c_void_p(buf554.data_ptr()), c_void_p(buf556.data_ptr()), c_void_p(buf560.data_ptr()))
    del tangents_23
    buf561 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf560, (4096, 128), (1, 4096), 0), view_282, out=buf561)
    buf562 = reinterpret_tensor(buf554, (128, 4096), (4096, 1), 0); del buf554  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf560, (128, 4096), (4096, 1), 0), permute_901, out=buf562)
    del permute_901
    buf563 = buf560; del buf560  # reuse
    cpp_fused_add_mul_neg_slice_backward_127(c_void_p(buf555.data_ptr()), c_void_p(unsqueeze_133.data_ptr()), c_void_p(unsqueeze_135.data_ptr()), c_void_p(buf563.data_ptr()))
    del unsqueeze_133
    del unsqueeze_135
    buf564 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf563, (4096, 128), (1, 4096), 0), view_282, out=buf564)
    del view_282
    buf565 = reinterpret_tensor(buf555, (128, 4096), (4096, 1), 0); del buf555  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf563, (128, 4096), (4096, 1), 0), permute_905, out=buf565)
    del permute_905
    buf566 = reinterpret_tensor(buf563, (1, 128, 4096), (524288, 4096, 1), 0); del buf563  # reuse
    buf567 = buf537; del buf537  # reuse
    buf568 = buf536; del buf536  # reuse
    buf569 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf570 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf571 = buf540; del buf540  # reuse
    cpp_fused_add_native_layer_norm_backward_128(c_void_p(buf571.data_ptr()), c_void_p(buf545.data_ptr()), c_void_p(buf559.data_ptr()), c_void_p(buf562.data_ptr()), c_void_p(buf565.data_ptr()), c_void_p(primals_102.data_ptr()), c_void_p(mul_100.data_ptr()), c_void_p(div_94.data_ptr()), c_void_p(buf566.data_ptr()), c_void_p(buf567.data_ptr()), c_void_p(buf568.data_ptr()), c_void_p(buf569.data_ptr()), c_void_p(buf570.data_ptr()))
    del div_94
    del mul_100
    del primals_102
    buf572 = reinterpret_tensor(buf544, (128, 16384), (16384, 1), 0); del buf544  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf571, (128, 4096), (4096, 1), 0), permute_907, out=buf572)
    del permute_907
    buf573 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf571, (4096, 128), (1, 4096), 0), view_280, out=buf573)
    del view_280
    buf574 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf575 = reinterpret_tensor(buf572, (1, 128, 16384), (2097152, 16384, 1), 0); del buf572  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_129(c_void_p(buf575.data_ptr()), c_void_p(buf571.data_ptr()), c_void_p(addmm_18.data_ptr()), c_void_p(tanh_9.data_ptr()), c_void_p(buf574.data_ptr()))
    del addmm_18
    del tanh_9
    buf576 = reinterpret_tensor(buf566, (128, 4096), (4096, 1), 0); del buf566  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf575, (128, 16384), (16384, 1), 0), permute_911, out=buf576)
    del permute_911
    buf577 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf575, (16384, 128), (1, 16384), 0), view_254, out=buf577)
    buf578 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_130(c_void_p(buf575.data_ptr()), c_void_p(buf578.data_ptr()))
    buf579 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf571, (4096, 128), (1, 4096), 0), view_276, out=buf579)
    del view_276
    buf580 = buf565; del buf565  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf571, (128, 4096), (4096, 1), 0), permute_917, out=buf580)
    del permute_917
    buf581 = reinterpret_tensor(buf562, (16, 128, 256), (32768, 256, 1), 0); del buf562  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_920, reinterpret_tensor(buf580, (16, 128, 256), (256, 4096, 1), 0), out=buf581)
    del permute_920
    buf582 = reinterpret_tensor(buf553, (16, 128, 128), (16384, 128, 1), 0); del buf553  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf580, (16, 128, 256), (256, 4096, 1), 0), permute_921, out=buf582)
    del permute_921
    buf583 = buf552; del buf552  # reuse
    buf584 = reinterpret_tensor(buf582, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf582  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_131(c_void_p(buf584.data_ptr()), c_void_p(alias_95.data_ptr()), c_void_p(slice_480.data_ptr()), c_void_p(primals_315.data_ptr()), c_void_p(buf583.data_ptr()))
    del alias_95
    del primals_315
    del slice_480
    buf585 = reinterpret_tensor(buf580, (16, 256, 128), (32768, 128, 1), 0); del buf580  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_922, reinterpret_tensor(buf584, (16, 128, 128), (16384, 128, 1), 0), out=buf585)
    del permute_922
    buf586 = reinterpret_tensor(buf559, (16, 128, 256), (32768, 256, 1), 0); del buf559  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf584, (16, 128, 128), (16384, 128, 1), 0), permute_923, out=buf586)
    del permute_923
    buf587 = buf556; del buf556  # reuse
    buf588 = reinterpret_tensor(buf545, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf545  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_132(c_void_p(tangents_21.data_ptr()), c_void_p(buf585.data_ptr()), c_void_p(unsqueeze_120.data_ptr()), c_void_p(unsqueeze_122.data_ptr()), c_void_p(tangents_22.data_ptr()), c_void_p(buf581.data_ptr()), c_void_p(buf587.data_ptr()), c_void_p(buf588.data_ptr()))
    del tangents_22
    buf589 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf588, (4096, 128), (1, 4096), 0), view_254, out=buf589)
    buf590 = reinterpret_tensor(buf581, (128, 4096), (4096, 1), 0); del buf581  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf588, (128, 4096), (4096, 1), 0), permute_930, out=buf590)
    del permute_930
    buf591 = buf588; del buf588  # reuse
    cpp_fused_add_slice_backward_133(c_void_p(tangents_21.data_ptr()), c_void_p(buf585.data_ptr()), c_void_p(buf587.data_ptr()), c_void_p(buf591.data_ptr()))
    del tangents_21
    buf592 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf591, (4096, 128), (1, 4096), 0), view_254, out=buf592)
    buf593 = reinterpret_tensor(buf585, (128, 4096), (4096, 1), 0); del buf585  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf591, (128, 4096), (4096, 1), 0), permute_934, out=buf593)
    del permute_934
    buf594 = buf591; del buf591  # reuse
    cpp_fused_add_mul_neg_slice_backward_134(c_void_p(buf586.data_ptr()), c_void_p(unsqueeze_120.data_ptr()), c_void_p(unsqueeze_122.data_ptr()), c_void_p(buf594.data_ptr()))
    del unsqueeze_120
    del unsqueeze_122
    buf595 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf594, (4096, 128), (1, 4096), 0), view_254, out=buf595)
    del view_254
    buf596 = reinterpret_tensor(buf586, (128, 4096), (4096, 1), 0); del buf586  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf594, (128, 4096), (4096, 1), 0), permute_938, out=buf596)
    del permute_938
    buf597 = reinterpret_tensor(buf594, (1, 128, 4096), (524288, 4096, 1), 0); del buf594  # reuse
    buf598 = buf568; del buf568  # reuse
    buf599 = buf567; del buf567  # reuse
    buf600 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf601 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf602 = buf571; del buf571  # reuse
    cpp_fused_add_native_layer_norm_backward_135(c_void_p(buf602.data_ptr()), c_void_p(buf576.data_ptr()), c_void_p(buf590.data_ptr()), c_void_p(buf593.data_ptr()), c_void_p(buf596.data_ptr()), c_void_p(primals_92.data_ptr()), c_void_p(mul_90.data_ptr()), c_void_p(div_96.data_ptr()), c_void_p(buf597.data_ptr()), c_void_p(buf598.data_ptr()), c_void_p(buf599.data_ptr()), c_void_p(buf600.data_ptr()), c_void_p(buf601.data_ptr()))
    del div_96
    del mul_90
    del primals_92
    buf603 = reinterpret_tensor(buf575, (128, 16384), (16384, 1), 0); del buf575  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf602, (128, 4096), (4096, 1), 0), permute_940, out=buf603)
    del permute_940
    buf604 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf602, (4096, 128), (1, 4096), 0), view_252, out=buf604)
    del view_252
    buf605 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf606 = reinterpret_tensor(buf603, (1, 128, 16384), (2097152, 16384, 1), 0); del buf603  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_136(c_void_p(buf606.data_ptr()), c_void_p(buf602.data_ptr()), c_void_p(addmm_16.data_ptr()), c_void_p(tanh_8.data_ptr()), c_void_p(buf605.data_ptr()))
    del addmm_16
    del tanh_8
    buf607 = reinterpret_tensor(buf597, (128, 4096), (4096, 1), 0); del buf597  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf606, (128, 16384), (16384, 1), 0), permute_944, out=buf607)
    del permute_944
    buf608 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf606, (16384, 128), (1, 16384), 0), view_226, out=buf608)
    buf609 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_137(c_void_p(buf606.data_ptr()), c_void_p(buf609.data_ptr()))
    buf610 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf602, (4096, 128), (1, 4096), 0), view_248, out=buf610)
    del view_248
    buf611 = buf596; del buf596  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf602, (128, 4096), (4096, 1), 0), permute_950, out=buf611)
    del permute_950
    buf612 = reinterpret_tensor(buf593, (16, 128, 256), (32768, 256, 1), 0); del buf593  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_953, reinterpret_tensor(buf611, (16, 128, 256), (256, 4096, 1), 0), out=buf612)
    del permute_953
    buf613 = reinterpret_tensor(buf584, (16, 128, 128), (16384, 128, 1), 0); del buf584  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf611, (16, 128, 256), (256, 4096, 1), 0), permute_954, out=buf613)
    del permute_954
    buf614 = buf583; del buf583  # reuse
    buf615 = reinterpret_tensor(buf613, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf613  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_138(c_void_p(buf615.data_ptr()), c_void_p(alias_97.data_ptr()), c_void_p(slice_432.data_ptr()), c_void_p(primals_312.data_ptr()), c_void_p(buf614.data_ptr()))
    del alias_97
    del primals_312
    del slice_432
    buf616 = reinterpret_tensor(buf611, (16, 256, 128), (32768, 128, 1), 0); del buf611  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_955, reinterpret_tensor(buf615, (16, 128, 128), (16384, 128, 1), 0), out=buf616)
    del permute_955
    buf617 = reinterpret_tensor(buf590, (16, 128, 256), (32768, 256, 1), 0); del buf590  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf615, (16, 128, 128), (16384, 128, 1), 0), permute_956, out=buf617)
    del permute_956
    buf618 = buf587; del buf587  # reuse
    buf619 = reinterpret_tensor(buf576, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf576  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_139(c_void_p(tangents_19.data_ptr()), c_void_p(buf616.data_ptr()), c_void_p(unsqueeze_107.data_ptr()), c_void_p(unsqueeze_109.data_ptr()), c_void_p(tangents_20.data_ptr()), c_void_p(buf612.data_ptr()), c_void_p(buf618.data_ptr()), c_void_p(buf619.data_ptr()))
    del tangents_20
    buf620 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf619, (4096, 128), (1, 4096), 0), view_226, out=buf620)
    buf621 = reinterpret_tensor(buf612, (128, 4096), (4096, 1), 0); del buf612  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf619, (128, 4096), (4096, 1), 0), permute_963, out=buf621)
    del permute_963
    buf622 = buf619; del buf619  # reuse
    cpp_fused_add_slice_backward_140(c_void_p(tangents_19.data_ptr()), c_void_p(buf616.data_ptr()), c_void_p(buf618.data_ptr()), c_void_p(buf622.data_ptr()))
    del tangents_19
    buf623 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf622, (4096, 128), (1, 4096), 0), view_226, out=buf623)
    buf624 = reinterpret_tensor(buf616, (128, 4096), (4096, 1), 0); del buf616  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf622, (128, 4096), (4096, 1), 0), permute_967, out=buf624)
    del permute_967
    buf625 = buf622; del buf622  # reuse
    cpp_fused_add_mul_neg_slice_backward_141(c_void_p(buf617.data_ptr()), c_void_p(unsqueeze_107.data_ptr()), c_void_p(unsqueeze_109.data_ptr()), c_void_p(buf625.data_ptr()))
    del unsqueeze_107
    del unsqueeze_109
    buf626 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf625, (4096, 128), (1, 4096), 0), view_226, out=buf626)
    del view_226
    buf627 = reinterpret_tensor(buf617, (128, 4096), (4096, 1), 0); del buf617  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf625, (128, 4096), (4096, 1), 0), permute_971, out=buf627)
    del permute_971
    buf628 = reinterpret_tensor(buf625, (1, 128, 4096), (524288, 4096, 1), 0); del buf625  # reuse
    buf629 = buf599; del buf599  # reuse
    buf630 = buf598; del buf598  # reuse
    buf631 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf632 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf633 = buf602; del buf602  # reuse
    cpp_fused_add_native_layer_norm_backward_142(c_void_p(buf633.data_ptr()), c_void_p(buf607.data_ptr()), c_void_p(buf621.data_ptr()), c_void_p(buf624.data_ptr()), c_void_p(buf627.data_ptr()), c_void_p(primals_82.data_ptr()), c_void_p(mul_80.data_ptr()), c_void_p(div_98.data_ptr()), c_void_p(buf628.data_ptr()), c_void_p(buf629.data_ptr()), c_void_p(buf630.data_ptr()), c_void_p(buf631.data_ptr()), c_void_p(buf632.data_ptr()))
    del div_98
    del mul_80
    del primals_82
    buf634 = reinterpret_tensor(buf606, (128, 16384), (16384, 1), 0); del buf606  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf633, (128, 4096), (4096, 1), 0), permute_973, out=buf634)
    del permute_973
    buf635 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf633, (4096, 128), (1, 4096), 0), view_224, out=buf635)
    del view_224
    buf636 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf637 = reinterpret_tensor(buf634, (1, 128, 16384), (2097152, 16384, 1), 0); del buf634  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_143(c_void_p(buf637.data_ptr()), c_void_p(buf633.data_ptr()), c_void_p(addmm_14.data_ptr()), c_void_p(tanh_7.data_ptr()), c_void_p(buf636.data_ptr()))
    del addmm_14
    del tanh_7
    buf638 = reinterpret_tensor(buf628, (128, 4096), (4096, 1), 0); del buf628  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf637, (128, 16384), (16384, 1), 0), permute_977, out=buf638)
    del permute_977
    buf639 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf637, (16384, 128), (1, 16384), 0), view_198, out=buf639)
    buf640 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_144(c_void_p(buf637.data_ptr()), c_void_p(buf640.data_ptr()))
    buf641 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf633, (4096, 128), (1, 4096), 0), view_220, out=buf641)
    del view_220
    buf642 = buf627; del buf627  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf633, (128, 4096), (4096, 1), 0), permute_983, out=buf642)
    del permute_983
    buf643 = reinterpret_tensor(buf624, (16, 128, 256), (32768, 256, 1), 0); del buf624  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_986, reinterpret_tensor(buf642, (16, 128, 256), (256, 4096, 1), 0), out=buf643)
    del permute_986
    buf644 = reinterpret_tensor(buf615, (16, 128, 128), (16384, 128, 1), 0); del buf615  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf642, (16, 128, 256), (256, 4096, 1), 0), permute_987, out=buf644)
    del permute_987
    buf645 = buf614; del buf614  # reuse
    buf646 = reinterpret_tensor(buf644, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf644  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_145(c_void_p(buf646.data_ptr()), c_void_p(alias_99.data_ptr()), c_void_p(slice_384.data_ptr()), c_void_p(primals_309.data_ptr()), c_void_p(buf645.data_ptr()))
    del alias_99
    del primals_309
    del slice_384
    buf647 = reinterpret_tensor(buf642, (16, 256, 128), (32768, 128, 1), 0); del buf642  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_988, reinterpret_tensor(buf646, (16, 128, 128), (16384, 128, 1), 0), out=buf647)
    del permute_988
    buf648 = reinterpret_tensor(buf621, (16, 128, 256), (32768, 256, 1), 0); del buf621  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf646, (16, 128, 128), (16384, 128, 1), 0), permute_989, out=buf648)
    del permute_989
    buf649 = buf618; del buf618  # reuse
    buf650 = reinterpret_tensor(buf607, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf607  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_146(c_void_p(tangents_17.data_ptr()), c_void_p(buf647.data_ptr()), c_void_p(unsqueeze_94.data_ptr()), c_void_p(unsqueeze_96.data_ptr()), c_void_p(tangents_18.data_ptr()), c_void_p(buf643.data_ptr()), c_void_p(buf649.data_ptr()), c_void_p(buf650.data_ptr()))
    del tangents_18
    buf651 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf650, (4096, 128), (1, 4096), 0), view_198, out=buf651)
    buf652 = reinterpret_tensor(buf643, (128, 4096), (4096, 1), 0); del buf643  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf650, (128, 4096), (4096, 1), 0), permute_996, out=buf652)
    del permute_996
    buf653 = buf650; del buf650  # reuse
    cpp_fused_add_slice_backward_147(c_void_p(tangents_17.data_ptr()), c_void_p(buf647.data_ptr()), c_void_p(buf649.data_ptr()), c_void_p(buf653.data_ptr()))
    del tangents_17
    buf654 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf653, (4096, 128), (1, 4096), 0), view_198, out=buf654)
    buf655 = reinterpret_tensor(buf647, (128, 4096), (4096, 1), 0); del buf647  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf653, (128, 4096), (4096, 1), 0), permute_1000, out=buf655)
    del permute_1000
    buf656 = buf653; del buf653  # reuse
    cpp_fused_add_mul_neg_slice_backward_148(c_void_p(buf648.data_ptr()), c_void_p(unsqueeze_94.data_ptr()), c_void_p(unsqueeze_96.data_ptr()), c_void_p(buf656.data_ptr()))
    del unsqueeze_94
    del unsqueeze_96
    buf657 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf656, (4096, 128), (1, 4096), 0), view_198, out=buf657)
    del view_198
    buf658 = reinterpret_tensor(buf648, (128, 4096), (4096, 1), 0); del buf648  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf656, (128, 4096), (4096, 1), 0), permute_1004, out=buf658)
    del permute_1004
    buf659 = reinterpret_tensor(buf656, (1, 128, 4096), (524288, 4096, 1), 0); del buf656  # reuse
    buf660 = buf630; del buf630  # reuse
    buf661 = buf629; del buf629  # reuse
    buf662 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf663 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf664 = buf633; del buf633  # reuse
    cpp_fused_add_native_layer_norm_backward_149(c_void_p(buf664.data_ptr()), c_void_p(buf638.data_ptr()), c_void_p(buf652.data_ptr()), c_void_p(buf655.data_ptr()), c_void_p(buf658.data_ptr()), c_void_p(primals_72.data_ptr()), c_void_p(mul_70.data_ptr()), c_void_p(div_100.data_ptr()), c_void_p(buf659.data_ptr()), c_void_p(buf660.data_ptr()), c_void_p(buf661.data_ptr()), c_void_p(buf662.data_ptr()), c_void_p(buf663.data_ptr()))
    del div_100
    del mul_70
    del primals_72
    buf665 = reinterpret_tensor(buf637, (128, 16384), (16384, 1), 0); del buf637  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf664, (128, 4096), (4096, 1), 0), permute_1006, out=buf665)
    del permute_1006
    buf666 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf664, (4096, 128), (1, 4096), 0), view_196, out=buf666)
    del view_196
    buf667 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf668 = reinterpret_tensor(buf665, (1, 128, 16384), (2097152, 16384, 1), 0); del buf665  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_150(c_void_p(buf668.data_ptr()), c_void_p(buf664.data_ptr()), c_void_p(addmm_12.data_ptr()), c_void_p(tanh_6.data_ptr()), c_void_p(buf667.data_ptr()))
    del addmm_12
    del tanh_6
    buf669 = reinterpret_tensor(buf659, (128, 4096), (4096, 1), 0); del buf659  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf668, (128, 16384), (16384, 1), 0), permute_1010, out=buf669)
    del permute_1010
    buf670 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf668, (16384, 128), (1, 16384), 0), view_170, out=buf670)
    buf671 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_151(c_void_p(buf668.data_ptr()), c_void_p(buf671.data_ptr()))
    buf672 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf664, (4096, 128), (1, 4096), 0), view_192, out=buf672)
    del view_192
    buf673 = buf658; del buf658  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf664, (128, 4096), (4096, 1), 0), permute_1016, out=buf673)
    del permute_1016
    buf674 = reinterpret_tensor(buf655, (16, 128, 256), (32768, 256, 1), 0); del buf655  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1019, reinterpret_tensor(buf673, (16, 128, 256), (256, 4096, 1), 0), out=buf674)
    del permute_1019
    buf675 = reinterpret_tensor(buf646, (16, 128, 128), (16384, 128, 1), 0); del buf646  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf673, (16, 128, 256), (256, 4096, 1), 0), permute_1020, out=buf675)
    del permute_1020
    buf676 = buf645; del buf645  # reuse
    buf677 = reinterpret_tensor(buf675, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf675  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_152(c_void_p(buf677.data_ptr()), c_void_p(alias_101.data_ptr()), c_void_p(slice_336.data_ptr()), c_void_p(primals_306.data_ptr()), c_void_p(buf676.data_ptr()))
    del alias_101
    del primals_306
    del slice_336
    buf678 = reinterpret_tensor(buf673, (16, 256, 128), (32768, 128, 1), 0); del buf673  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1021, reinterpret_tensor(buf677, (16, 128, 128), (16384, 128, 1), 0), out=buf678)
    del permute_1021
    buf679 = reinterpret_tensor(buf652, (16, 128, 256), (32768, 256, 1), 0); del buf652  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf677, (16, 128, 128), (16384, 128, 1), 0), permute_1022, out=buf679)
    del permute_1022
    buf680 = buf649; del buf649  # reuse
    buf681 = reinterpret_tensor(buf638, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf638  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_153(c_void_p(tangents_15.data_ptr()), c_void_p(buf678.data_ptr()), c_void_p(unsqueeze_81.data_ptr()), c_void_p(unsqueeze_83.data_ptr()), c_void_p(tangents_16.data_ptr()), c_void_p(buf674.data_ptr()), c_void_p(buf680.data_ptr()), c_void_p(buf681.data_ptr()))
    del tangents_16
    buf682 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf681, (4096, 128), (1, 4096), 0), view_170, out=buf682)
    buf683 = reinterpret_tensor(buf674, (128, 4096), (4096, 1), 0); del buf674  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf681, (128, 4096), (4096, 1), 0), permute_1029, out=buf683)
    del permute_1029
    buf684 = buf681; del buf681  # reuse
    cpp_fused_add_slice_backward_154(c_void_p(tangents_15.data_ptr()), c_void_p(buf678.data_ptr()), c_void_p(buf680.data_ptr()), c_void_p(buf684.data_ptr()))
    del tangents_15
    buf685 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf684, (4096, 128), (1, 4096), 0), view_170, out=buf685)
    buf686 = reinterpret_tensor(buf678, (128, 4096), (4096, 1), 0); del buf678  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf684, (128, 4096), (4096, 1), 0), permute_1033, out=buf686)
    del permute_1033
    buf687 = buf684; del buf684  # reuse
    cpp_fused_add_mul_neg_slice_backward_155(c_void_p(buf679.data_ptr()), c_void_p(unsqueeze_81.data_ptr()), c_void_p(unsqueeze_83.data_ptr()), c_void_p(buf687.data_ptr()))
    del unsqueeze_81
    del unsqueeze_83
    buf688 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf687, (4096, 128), (1, 4096), 0), view_170, out=buf688)
    del view_170
    buf689 = reinterpret_tensor(buf679, (128, 4096), (4096, 1), 0); del buf679  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf687, (128, 4096), (4096, 1), 0), permute_1037, out=buf689)
    del permute_1037
    buf690 = reinterpret_tensor(buf687, (1, 128, 4096), (524288, 4096, 1), 0); del buf687  # reuse
    buf691 = buf661; del buf661  # reuse
    buf692 = buf660; del buf660  # reuse
    buf693 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf694 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf695 = buf664; del buf664  # reuse
    cpp_fused_add_native_layer_norm_backward_156(c_void_p(buf695.data_ptr()), c_void_p(buf669.data_ptr()), c_void_p(buf683.data_ptr()), c_void_p(buf686.data_ptr()), c_void_p(buf689.data_ptr()), c_void_p(primals_62.data_ptr()), c_void_p(mul_60.data_ptr()), c_void_p(div_102.data_ptr()), c_void_p(buf690.data_ptr()), c_void_p(buf691.data_ptr()), c_void_p(buf692.data_ptr()), c_void_p(buf693.data_ptr()), c_void_p(buf694.data_ptr()))
    del div_102
    del mul_60
    del primals_62
    buf696 = reinterpret_tensor(buf668, (128, 16384), (16384, 1), 0); del buf668  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf695, (128, 4096), (4096, 1), 0), permute_1039, out=buf696)
    del permute_1039
    buf697 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf695, (4096, 128), (1, 4096), 0), view_168, out=buf697)
    del view_168
    buf698 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf699 = reinterpret_tensor(buf696, (1, 128, 16384), (2097152, 16384, 1), 0); del buf696  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_157(c_void_p(buf699.data_ptr()), c_void_p(buf695.data_ptr()), c_void_p(addmm_10.data_ptr()), c_void_p(tanh_5.data_ptr()), c_void_p(buf698.data_ptr()))
    del addmm_10
    del tanh_5
    buf700 = reinterpret_tensor(buf690, (128, 4096), (4096, 1), 0); del buf690  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf699, (128, 16384), (16384, 1), 0), permute_1043, out=buf700)
    del permute_1043
    buf701 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf699, (16384, 128), (1, 16384), 0), view_142, out=buf701)
    buf702 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_158(c_void_p(buf699.data_ptr()), c_void_p(buf702.data_ptr()))
    buf703 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf695, (4096, 128), (1, 4096), 0), view_164, out=buf703)
    del view_164
    buf704 = buf689; del buf689  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf695, (128, 4096), (4096, 1), 0), permute_1049, out=buf704)
    del permute_1049
    buf705 = reinterpret_tensor(buf686, (16, 128, 256), (32768, 256, 1), 0); del buf686  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1052, reinterpret_tensor(buf704, (16, 128, 256), (256, 4096, 1), 0), out=buf705)
    del permute_1052
    buf706 = reinterpret_tensor(buf677, (16, 128, 128), (16384, 128, 1), 0); del buf677  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf704, (16, 128, 256), (256, 4096, 1), 0), permute_1053, out=buf706)
    del permute_1053
    buf707 = buf676; del buf676  # reuse
    buf708 = reinterpret_tensor(buf706, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf706  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_159(c_void_p(buf708.data_ptr()), c_void_p(alias_103.data_ptr()), c_void_p(slice_288.data_ptr()), c_void_p(primals_303.data_ptr()), c_void_p(buf707.data_ptr()))
    del alias_103
    del primals_303
    del slice_288
    buf709 = reinterpret_tensor(buf704, (16, 256, 128), (32768, 128, 1), 0); del buf704  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1054, reinterpret_tensor(buf708, (16, 128, 128), (16384, 128, 1), 0), out=buf709)
    del permute_1054
    buf710 = reinterpret_tensor(buf683, (16, 128, 256), (32768, 256, 1), 0); del buf683  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf708, (16, 128, 128), (16384, 128, 1), 0), permute_1055, out=buf710)
    del permute_1055
    buf711 = buf680; del buf680  # reuse
    buf712 = reinterpret_tensor(buf669, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf669  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_160(c_void_p(tangents_13.data_ptr()), c_void_p(buf709.data_ptr()), c_void_p(unsqueeze_68.data_ptr()), c_void_p(unsqueeze_70.data_ptr()), c_void_p(tangents_14.data_ptr()), c_void_p(buf705.data_ptr()), c_void_p(buf711.data_ptr()), c_void_p(buf712.data_ptr()))
    del tangents_14
    buf713 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf712, (4096, 128), (1, 4096), 0), view_142, out=buf713)
    buf714 = reinterpret_tensor(buf705, (128, 4096), (4096, 1), 0); del buf705  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf712, (128, 4096), (4096, 1), 0), permute_1062, out=buf714)
    del permute_1062
    buf715 = buf712; del buf712  # reuse
    cpp_fused_add_slice_backward_161(c_void_p(tangents_13.data_ptr()), c_void_p(buf709.data_ptr()), c_void_p(buf711.data_ptr()), c_void_p(buf715.data_ptr()))
    del tangents_13
    buf716 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf715, (4096, 128), (1, 4096), 0), view_142, out=buf716)
    buf717 = reinterpret_tensor(buf709, (128, 4096), (4096, 1), 0); del buf709  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf715, (128, 4096), (4096, 1), 0), permute_1066, out=buf717)
    del permute_1066
    buf718 = buf715; del buf715  # reuse
    cpp_fused_add_mul_neg_slice_backward_162(c_void_p(buf710.data_ptr()), c_void_p(unsqueeze_68.data_ptr()), c_void_p(unsqueeze_70.data_ptr()), c_void_p(buf718.data_ptr()))
    del unsqueeze_68
    del unsqueeze_70
    buf719 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf718, (4096, 128), (1, 4096), 0), view_142, out=buf719)
    del view_142
    buf720 = reinterpret_tensor(buf710, (128, 4096), (4096, 1), 0); del buf710  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf718, (128, 4096), (4096, 1), 0), permute_1070, out=buf720)
    del permute_1070
    buf721 = reinterpret_tensor(buf718, (1, 128, 4096), (524288, 4096, 1), 0); del buf718  # reuse
    buf722 = buf692; del buf692  # reuse
    buf723 = buf691; del buf691  # reuse
    buf724 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf725 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf726 = buf695; del buf695  # reuse
    cpp_fused_add_native_layer_norm_backward_163(c_void_p(buf726.data_ptr()), c_void_p(buf700.data_ptr()), c_void_p(buf714.data_ptr()), c_void_p(buf717.data_ptr()), c_void_p(buf720.data_ptr()), c_void_p(primals_52.data_ptr()), c_void_p(mul_50.data_ptr()), c_void_p(div_104.data_ptr()), c_void_p(buf721.data_ptr()), c_void_p(buf722.data_ptr()), c_void_p(buf723.data_ptr()), c_void_p(buf724.data_ptr()), c_void_p(buf725.data_ptr()))
    del div_104
    del mul_50
    del primals_52
    buf727 = reinterpret_tensor(buf699, (128, 16384), (16384, 1), 0); del buf699  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf726, (128, 4096), (4096, 1), 0), permute_1072, out=buf727)
    del permute_1072
    buf728 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf726, (4096, 128), (1, 4096), 0), view_140, out=buf728)
    del view_140
    buf729 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf730 = reinterpret_tensor(buf727, (1, 128, 16384), (2097152, 16384, 1), 0); del buf727  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_164(c_void_p(buf730.data_ptr()), c_void_p(buf726.data_ptr()), c_void_p(addmm_8.data_ptr()), c_void_p(tanh_4.data_ptr()), c_void_p(buf729.data_ptr()))
    del addmm_8
    del tanh_4
    buf731 = reinterpret_tensor(buf721, (128, 4096), (4096, 1), 0); del buf721  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf730, (128, 16384), (16384, 1), 0), permute_1076, out=buf731)
    del permute_1076
    buf732 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf730, (16384, 128), (1, 16384), 0), view_114, out=buf732)
    buf733 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_165(c_void_p(buf730.data_ptr()), c_void_p(buf733.data_ptr()))
    buf734 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf726, (4096, 128), (1, 4096), 0), view_136, out=buf734)
    del view_136
    buf735 = buf720; del buf720  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf726, (128, 4096), (4096, 1), 0), permute_1082, out=buf735)
    del permute_1082
    buf736 = reinterpret_tensor(buf717, (16, 128, 256), (32768, 256, 1), 0); del buf717  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1085, reinterpret_tensor(buf735, (16, 128, 256), (256, 4096, 1), 0), out=buf736)
    del permute_1085
    buf737 = reinterpret_tensor(buf708, (16, 128, 128), (16384, 128, 1), 0); del buf708  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf735, (16, 128, 256), (256, 4096, 1), 0), permute_1086, out=buf737)
    del permute_1086
    buf738 = buf707; del buf707  # reuse
    buf739 = reinterpret_tensor(buf737, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf737  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_166(c_void_p(buf739.data_ptr()), c_void_p(alias_105.data_ptr()), c_void_p(slice_240.data_ptr()), c_void_p(primals_300.data_ptr()), c_void_p(buf738.data_ptr()))
    del alias_105
    del primals_300
    del slice_240
    buf740 = reinterpret_tensor(buf735, (16, 256, 128), (32768, 128, 1), 0); del buf735  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1087, reinterpret_tensor(buf739, (16, 128, 128), (16384, 128, 1), 0), out=buf740)
    del permute_1087
    buf741 = reinterpret_tensor(buf714, (16, 128, 256), (32768, 256, 1), 0); del buf714  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf739, (16, 128, 128), (16384, 128, 1), 0), permute_1088, out=buf741)
    del permute_1088
    buf742 = buf711; del buf711  # reuse
    buf743 = reinterpret_tensor(buf700, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf700  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_167(c_void_p(tangents_11.data_ptr()), c_void_p(buf740.data_ptr()), c_void_p(unsqueeze_55.data_ptr()), c_void_p(unsqueeze_57.data_ptr()), c_void_p(tangents_12.data_ptr()), c_void_p(buf736.data_ptr()), c_void_p(buf742.data_ptr()), c_void_p(buf743.data_ptr()))
    del tangents_12
    buf744 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf743, (4096, 128), (1, 4096), 0), view_114, out=buf744)
    buf745 = reinterpret_tensor(buf736, (128, 4096), (4096, 1), 0); del buf736  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf743, (128, 4096), (4096, 1), 0), permute_1095, out=buf745)
    del permute_1095
    buf746 = buf743; del buf743  # reuse
    cpp_fused_add_slice_backward_168(c_void_p(tangents_11.data_ptr()), c_void_p(buf740.data_ptr()), c_void_p(buf742.data_ptr()), c_void_p(buf746.data_ptr()))
    del tangents_11
    buf747 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf746, (4096, 128), (1, 4096), 0), view_114, out=buf747)
    buf748 = reinterpret_tensor(buf740, (128, 4096), (4096, 1), 0); del buf740  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf746, (128, 4096), (4096, 1), 0), permute_1099, out=buf748)
    del permute_1099
    buf749 = buf746; del buf746  # reuse
    cpp_fused_add_mul_neg_slice_backward_169(c_void_p(buf741.data_ptr()), c_void_p(unsqueeze_55.data_ptr()), c_void_p(unsqueeze_57.data_ptr()), c_void_p(buf749.data_ptr()))
    del unsqueeze_55
    del unsqueeze_57
    buf750 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf749, (4096, 128), (1, 4096), 0), view_114, out=buf750)
    del view_114
    buf751 = reinterpret_tensor(buf741, (128, 4096), (4096, 1), 0); del buf741  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf749, (128, 4096), (4096, 1), 0), permute_1103, out=buf751)
    del permute_1103
    buf752 = reinterpret_tensor(buf749, (1, 128, 4096), (524288, 4096, 1), 0); del buf749  # reuse
    buf753 = buf723; del buf723  # reuse
    buf754 = buf722; del buf722  # reuse
    buf755 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf756 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf757 = buf726; del buf726  # reuse
    cpp_fused_add_native_layer_norm_backward_170(c_void_p(buf757.data_ptr()), c_void_p(buf731.data_ptr()), c_void_p(buf745.data_ptr()), c_void_p(buf748.data_ptr()), c_void_p(buf751.data_ptr()), c_void_p(primals_42.data_ptr()), c_void_p(mul_40.data_ptr()), c_void_p(div_106.data_ptr()), c_void_p(buf752.data_ptr()), c_void_p(buf753.data_ptr()), c_void_p(buf754.data_ptr()), c_void_p(buf755.data_ptr()), c_void_p(buf756.data_ptr()))
    del div_106
    del mul_40
    del primals_42
    buf758 = reinterpret_tensor(buf730, (128, 16384), (16384, 1), 0); del buf730  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf757, (128, 4096), (4096, 1), 0), permute_1105, out=buf758)
    del permute_1105
    buf759 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf757, (4096, 128), (1, 4096), 0), view_112, out=buf759)
    del view_112
    buf760 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf761 = reinterpret_tensor(buf758, (1, 128, 16384), (2097152, 16384, 1), 0); del buf758  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_171(c_void_p(buf761.data_ptr()), c_void_p(buf757.data_ptr()), c_void_p(addmm_6.data_ptr()), c_void_p(tanh_3.data_ptr()), c_void_p(buf760.data_ptr()))
    del addmm_6
    del tanh_3
    buf762 = reinterpret_tensor(buf752, (128, 4096), (4096, 1), 0); del buf752  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf761, (128, 16384), (16384, 1), 0), permute_1109, out=buf762)
    del permute_1109
    buf763 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf761, (16384, 128), (1, 16384), 0), view_86, out=buf763)
    buf764 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_172(c_void_p(buf761.data_ptr()), c_void_p(buf764.data_ptr()))
    buf765 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf757, (4096, 128), (1, 4096), 0), view_108, out=buf765)
    del view_108
    buf766 = buf751; del buf751  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf757, (128, 4096), (4096, 1), 0), permute_1115, out=buf766)
    del permute_1115
    buf767 = reinterpret_tensor(buf748, (16, 128, 256), (32768, 256, 1), 0); del buf748  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1118, reinterpret_tensor(buf766, (16, 128, 256), (256, 4096, 1), 0), out=buf767)
    del permute_1118
    buf768 = reinterpret_tensor(buf739, (16, 128, 128), (16384, 128, 1), 0); del buf739  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf766, (16, 128, 256), (256, 4096, 1), 0), permute_1119, out=buf768)
    del permute_1119
    buf769 = buf738; del buf738  # reuse
    buf770 = reinterpret_tensor(buf768, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf768  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_173(c_void_p(buf770.data_ptr()), c_void_p(alias_107.data_ptr()), c_void_p(slice_192.data_ptr()), c_void_p(primals_297.data_ptr()), c_void_p(buf769.data_ptr()))
    del alias_107
    del primals_297
    del slice_192
    buf771 = reinterpret_tensor(buf766, (16, 256, 128), (32768, 128, 1), 0); del buf766  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1120, reinterpret_tensor(buf770, (16, 128, 128), (16384, 128, 1), 0), out=buf771)
    del permute_1120
    buf772 = reinterpret_tensor(buf745, (16, 128, 256), (32768, 256, 1), 0); del buf745  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf770, (16, 128, 128), (16384, 128, 1), 0), permute_1121, out=buf772)
    del permute_1121
    buf773 = buf742; del buf742  # reuse
    buf774 = reinterpret_tensor(buf731, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf731  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_174(c_void_p(tangents_9.data_ptr()), c_void_p(buf771.data_ptr()), c_void_p(unsqueeze_42.data_ptr()), c_void_p(unsqueeze_44.data_ptr()), c_void_p(tangents_10.data_ptr()), c_void_p(buf767.data_ptr()), c_void_p(buf773.data_ptr()), c_void_p(buf774.data_ptr()))
    del tangents_10
    buf775 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf774, (4096, 128), (1, 4096), 0), view_86, out=buf775)
    buf776 = reinterpret_tensor(buf767, (128, 4096), (4096, 1), 0); del buf767  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf774, (128, 4096), (4096, 1), 0), permute_1128, out=buf776)
    del permute_1128
    buf777 = buf774; del buf774  # reuse
    cpp_fused_add_slice_backward_175(c_void_p(tangents_9.data_ptr()), c_void_p(buf771.data_ptr()), c_void_p(buf773.data_ptr()), c_void_p(buf777.data_ptr()))
    del tangents_9
    buf778 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf777, (4096, 128), (1, 4096), 0), view_86, out=buf778)
    buf779 = reinterpret_tensor(buf771, (128, 4096), (4096, 1), 0); del buf771  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf777, (128, 4096), (4096, 1), 0), permute_1132, out=buf779)
    del permute_1132
    buf780 = buf777; del buf777  # reuse
    cpp_fused_add_mul_neg_slice_backward_176(c_void_p(buf772.data_ptr()), c_void_p(unsqueeze_42.data_ptr()), c_void_p(unsqueeze_44.data_ptr()), c_void_p(buf780.data_ptr()))
    del unsqueeze_42
    del unsqueeze_44
    buf781 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf780, (4096, 128), (1, 4096), 0), view_86, out=buf781)
    del view_86
    buf782 = reinterpret_tensor(buf772, (128, 4096), (4096, 1), 0); del buf772  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf780, (128, 4096), (4096, 1), 0), permute_1136, out=buf782)
    del permute_1136
    buf783 = reinterpret_tensor(buf780, (1, 128, 4096), (524288, 4096, 1), 0); del buf780  # reuse
    buf784 = buf754; del buf754  # reuse
    buf785 = buf753; del buf753  # reuse
    buf786 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf787 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf788 = buf757; del buf757  # reuse
    cpp_fused_add_native_layer_norm_backward_177(c_void_p(buf788.data_ptr()), c_void_p(buf762.data_ptr()), c_void_p(buf776.data_ptr()), c_void_p(buf779.data_ptr()), c_void_p(buf782.data_ptr()), c_void_p(primals_32.data_ptr()), c_void_p(mul_30.data_ptr()), c_void_p(div_108.data_ptr()), c_void_p(buf783.data_ptr()), c_void_p(buf784.data_ptr()), c_void_p(buf785.data_ptr()), c_void_p(buf786.data_ptr()), c_void_p(buf787.data_ptr()))
    del div_108
    del mul_30
    del primals_32
    buf789 = reinterpret_tensor(buf761, (128, 16384), (16384, 1), 0); del buf761  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf788, (128, 4096), (4096, 1), 0), permute_1138, out=buf789)
    del permute_1138
    buf790 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf788, (4096, 128), (1, 4096), 0), view_84, out=buf790)
    del view_84
    buf791 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf792 = reinterpret_tensor(buf789, (1, 128, 16384), (2097152, 16384, 1), 0); del buf789  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_178(c_void_p(buf792.data_ptr()), c_void_p(buf788.data_ptr()), c_void_p(addmm_4.data_ptr()), c_void_p(tanh_2.data_ptr()), c_void_p(buf791.data_ptr()))
    del addmm_4
    del tanh_2
    buf793 = reinterpret_tensor(buf783, (128, 4096), (4096, 1), 0); del buf783  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf792, (128, 16384), (16384, 1), 0), permute_1142, out=buf793)
    del permute_1142
    buf794 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf792, (16384, 128), (1, 16384), 0), view_58, out=buf794)
    buf795 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_179(c_void_p(buf792.data_ptr()), c_void_p(buf795.data_ptr()))
    buf796 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf788, (4096, 128), (1, 4096), 0), view_80, out=buf796)
    del view_80
    buf797 = buf782; del buf782  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf788, (128, 4096), (4096, 1), 0), permute_1148, out=buf797)
    del permute_1148
    buf798 = reinterpret_tensor(buf779, (16, 128, 256), (32768, 256, 1), 0); del buf779  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1151, reinterpret_tensor(buf797, (16, 128, 256), (256, 4096, 1), 0), out=buf798)
    del permute_1151
    buf799 = reinterpret_tensor(buf770, (16, 128, 128), (16384, 128, 1), 0); del buf770  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf797, (16, 128, 256), (256, 4096, 1), 0), permute_1152, out=buf799)
    del permute_1152
    buf800 = buf769; del buf769  # reuse
    buf801 = reinterpret_tensor(buf799, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf799  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_180(c_void_p(buf801.data_ptr()), c_void_p(alias_109.data_ptr()), c_void_p(slice_144.data_ptr()), c_void_p(primals_294.data_ptr()), c_void_p(buf800.data_ptr()))
    del alias_109
    del primals_294
    del slice_144
    buf802 = reinterpret_tensor(buf797, (16, 256, 128), (32768, 128, 1), 0); del buf797  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1153, reinterpret_tensor(buf801, (16, 128, 128), (16384, 128, 1), 0), out=buf802)
    del permute_1153
    buf803 = reinterpret_tensor(buf776, (16, 128, 256), (32768, 256, 1), 0); del buf776  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf801, (16, 128, 128), (16384, 128, 1), 0), permute_1154, out=buf803)
    del permute_1154
    buf804 = buf773; del buf773  # reuse
    buf805 = reinterpret_tensor(buf762, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf762  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_181(c_void_p(tangents_7.data_ptr()), c_void_p(buf802.data_ptr()), c_void_p(unsqueeze_29.data_ptr()), c_void_p(unsqueeze_31.data_ptr()), c_void_p(tangents_8.data_ptr()), c_void_p(buf798.data_ptr()), c_void_p(buf804.data_ptr()), c_void_p(buf805.data_ptr()))
    del tangents_8
    buf806 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf805, (4096, 128), (1, 4096), 0), view_58, out=buf806)
    buf807 = reinterpret_tensor(buf798, (128, 4096), (4096, 1), 0); del buf798  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf805, (128, 4096), (4096, 1), 0), permute_1161, out=buf807)
    del permute_1161
    buf808 = buf805; del buf805  # reuse
    cpp_fused_add_slice_backward_182(c_void_p(tangents_7.data_ptr()), c_void_p(buf802.data_ptr()), c_void_p(buf804.data_ptr()), c_void_p(buf808.data_ptr()))
    del tangents_7
    buf809 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf808, (4096, 128), (1, 4096), 0), view_58, out=buf809)
    buf810 = reinterpret_tensor(buf802, (128, 4096), (4096, 1), 0); del buf802  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf808, (128, 4096), (4096, 1), 0), permute_1165, out=buf810)
    del permute_1165
    buf811 = buf808; del buf808  # reuse
    cpp_fused_add_mul_neg_slice_backward_183(c_void_p(buf803.data_ptr()), c_void_p(unsqueeze_29.data_ptr()), c_void_p(unsqueeze_31.data_ptr()), c_void_p(buf811.data_ptr()))
    del unsqueeze_29
    del unsqueeze_31
    buf812 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf811, (4096, 128), (1, 4096), 0), view_58, out=buf812)
    del view_58
    buf813 = reinterpret_tensor(buf803, (128, 4096), (4096, 1), 0); del buf803  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf811, (128, 4096), (4096, 1), 0), permute_1169, out=buf813)
    del permute_1169
    buf814 = reinterpret_tensor(buf811, (1, 128, 4096), (524288, 4096, 1), 0); del buf811  # reuse
    buf815 = buf785; del buf785  # reuse
    buf816 = buf784; del buf784  # reuse
    buf817 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf818 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf819 = buf788; del buf788  # reuse
    cpp_fused_add_native_layer_norm_backward_184(c_void_p(buf819.data_ptr()), c_void_p(buf793.data_ptr()), c_void_p(buf807.data_ptr()), c_void_p(buf810.data_ptr()), c_void_p(buf813.data_ptr()), c_void_p(primals_22.data_ptr()), c_void_p(mul_20.data_ptr()), c_void_p(div_110.data_ptr()), c_void_p(buf814.data_ptr()), c_void_p(buf815.data_ptr()), c_void_p(buf816.data_ptr()), c_void_p(buf817.data_ptr()), c_void_p(buf818.data_ptr()))
    del div_110
    del mul_20
    del primals_22
    buf820 = reinterpret_tensor(buf792, (128, 16384), (16384, 1), 0); del buf792  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf819, (128, 4096), (4096, 1), 0), permute_1171, out=buf820)
    del permute_1171
    buf821 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf819, (4096, 128), (1, 4096), 0), view_56, out=buf821)
    del view_56
    buf822 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf823 = reinterpret_tensor(buf820, (1, 128, 16384), (2097152, 16384, 1), 0); del buf820  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_185(c_void_p(buf823.data_ptr()), c_void_p(buf819.data_ptr()), c_void_p(addmm_2.data_ptr()), c_void_p(tanh_1.data_ptr()), c_void_p(buf822.data_ptr()))
    del addmm_2
    del tanh_1
    buf824 = reinterpret_tensor(buf814, (128, 4096), (4096, 1), 0); del buf814  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf823, (128, 16384), (16384, 1), 0), permute_1175, out=buf824)
    del permute_1175
    buf825 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf823, (16384, 128), (1, 16384), 0), view_30, out=buf825)
    buf826 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_186(c_void_p(buf823.data_ptr()), c_void_p(buf826.data_ptr()))
    buf827 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf819, (4096, 128), (1, 4096), 0), view_52, out=buf827)
    del view_52
    buf828 = buf813; del buf813  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf819, (128, 4096), (4096, 1), 0), permute_1181, out=buf828)
    del permute_1181
    buf829 = reinterpret_tensor(buf810, (16, 128, 256), (32768, 256, 1), 0); del buf810  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1184, reinterpret_tensor(buf828, (16, 128, 256), (256, 4096, 1), 0), out=buf829)
    del permute_1184
    buf830 = reinterpret_tensor(buf801, (16, 128, 128), (16384, 128, 1), 0); del buf801  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf828, (16, 128, 256), (256, 4096, 1), 0), permute_1185, out=buf830)
    del permute_1185
    buf831 = buf800; del buf800  # reuse
    buf832 = reinterpret_tensor(buf830, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf830  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_187(c_void_p(buf832.data_ptr()), c_void_p(alias_111.data_ptr()), c_void_p(slice_96.data_ptr()), c_void_p(primals_291.data_ptr()), c_void_p(buf831.data_ptr()))
    del alias_111
    del primals_291
    del slice_96
    buf833 = reinterpret_tensor(buf828, (16, 256, 128), (32768, 128, 1), 0); del buf828  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1186, reinterpret_tensor(buf832, (16, 128, 128), (16384, 128, 1), 0), out=buf833)
    del permute_1186
    buf834 = reinterpret_tensor(buf807, (16, 128, 256), (32768, 256, 1), 0); del buf807  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf832, (16, 128, 128), (16384, 128, 1), 0), permute_1187, out=buf834)
    del permute_1187
    buf835 = buf804; del buf804  # reuse
    buf836 = reinterpret_tensor(buf793, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf793  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_188(c_void_p(tangents_5.data_ptr()), c_void_p(buf833.data_ptr()), c_void_p(unsqueeze_16.data_ptr()), c_void_p(unsqueeze_18.data_ptr()), c_void_p(tangents_6.data_ptr()), c_void_p(buf829.data_ptr()), c_void_p(buf835.data_ptr()), c_void_p(buf836.data_ptr()))
    del tangents_6
    buf837 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf836, (4096, 128), (1, 4096), 0), view_30, out=buf837)
    buf838 = reinterpret_tensor(buf829, (128, 4096), (4096, 1), 0); del buf829  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf836, (128, 4096), (4096, 1), 0), permute_1194, out=buf838)
    del permute_1194
    buf839 = buf836; del buf836  # reuse
    cpp_fused_add_slice_backward_189(c_void_p(tangents_5.data_ptr()), c_void_p(buf833.data_ptr()), c_void_p(buf835.data_ptr()), c_void_p(buf839.data_ptr()))
    del tangents_5
    buf840 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf839, (4096, 128), (1, 4096), 0), view_30, out=buf840)
    buf841 = reinterpret_tensor(buf833, (128, 4096), (4096, 1), 0); del buf833  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf839, (128, 4096), (4096, 1), 0), permute_1198, out=buf841)
    del permute_1198
    buf842 = buf839; del buf839  # reuse
    cpp_fused_add_mul_neg_slice_backward_190(c_void_p(buf834.data_ptr()), c_void_p(unsqueeze_16.data_ptr()), c_void_p(unsqueeze_18.data_ptr()), c_void_p(buf842.data_ptr()))
    del unsqueeze_16
    del unsqueeze_18
    buf843 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf842, (4096, 128), (1, 4096), 0), view_30, out=buf843)
    del view_30
    buf844 = reinterpret_tensor(buf834, (128, 4096), (4096, 1), 0); del buf834  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf842, (128, 4096), (4096, 1), 0), permute_1202, out=buf844)
    del permute_1202
    buf845 = reinterpret_tensor(buf842, (1, 128, 4096), (524288, 4096, 1), 0); del buf842  # reuse
    buf846 = buf816; del buf816  # reuse
    buf847 = buf815; del buf815  # reuse
    buf848 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf849 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf850 = buf819; del buf819  # reuse
    cpp_fused_add_native_layer_norm_backward_191(c_void_p(buf850.data_ptr()), c_void_p(buf824.data_ptr()), c_void_p(buf838.data_ptr()), c_void_p(buf841.data_ptr()), c_void_p(buf844.data_ptr()), c_void_p(primals_12.data_ptr()), c_void_p(mul_10.data_ptr()), c_void_p(div_112.data_ptr()), c_void_p(buf845.data_ptr()), c_void_p(buf846.data_ptr()), c_void_p(buf847.data_ptr()), c_void_p(buf848.data_ptr()), c_void_p(buf849.data_ptr()))
    del div_112
    del mul_10
    del primals_12
    buf851 = reinterpret_tensor(buf823, (128, 16384), (16384, 1), 0); del buf823  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf850, (128, 4096), (4096, 1), 0), permute_1204, out=buf851)
    del permute_1204
    buf852 = empty((4096, 16384), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf850, (4096, 128), (1, 4096), 0), view_28, out=buf852)
    del view_28
    buf853 = empty((1, 4096), device='cpu', dtype=torch.float32)
    buf854 = reinterpret_tensor(buf851, (1, 128, 16384), (2097152, 16384, 1), 0); del buf851  # reuse
    cpp_fused_add_mul_pow_sum_tanh_backward_192(c_void_p(buf854.data_ptr()), c_void_p(buf850.data_ptr()), c_void_p(addmm.data_ptr()), c_void_p(tanh.data_ptr()), c_void_p(buf853.data_ptr()))
    del addmm
    del tanh
    buf855 = reinterpret_tensor(buf845, (128, 4096), (4096, 1), 0); del buf845  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf854, (128, 16384), (16384, 1), 0), permute_1208, out=buf855)
    del permute_1208
    buf856 = empty((16384, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf854, (16384, 128), (1, 16384), 0), view_2, out=buf856)
    buf857 = empty((1, 16384), device='cpu', dtype=torch.float32)
    cpp_fused_sum_193(c_void_p(buf854.data_ptr()), c_void_p(buf857.data_ptr()))
    del buf854
    buf858 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf850, (4096, 128), (1, 4096), 0), view_24, out=buf858)
    del view_24
    buf859 = buf844; del buf844  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf850, (128, 4096), (4096, 1), 0), permute_1214, out=buf859)
    del permute_1214
    buf860 = reinterpret_tensor(buf841, (16, 128, 256), (32768, 256, 1), 0); del buf841  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1217, reinterpret_tensor(buf859, (16, 128, 256), (256, 4096, 1), 0), out=buf860)
    del permute_1217
    buf861 = reinterpret_tensor(buf832, (16, 128, 128), (16384, 128, 1), 0); del buf832  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf859, (16, 128, 256), (256, 4096, 1), 0), permute_1218, out=buf861)
    del permute_1218
    buf862 = buf831; del buf831  # reuse
    buf863 = reinterpret_tensor(buf861, (1, 16, 128, 128), (262144, 16384, 128, 1), 0); del buf861  # reuse
    cpp_fused__softmax_backward_data_div_nll_loss_forward_where_194(c_void_p(buf863.data_ptr()), c_void_p(alias_113.data_ptr()), c_void_p(slice_48.data_ptr()), c_void_p(primals_288.data_ptr()), c_void_p(buf862.data_ptr()))
    del alias_113
    del buf862
    del primals_288
    del slice_48
    buf864 = reinterpret_tensor(buf859, (16, 256, 128), (32768, 128, 1), 0); del buf859  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1219, reinterpret_tensor(buf863, (16, 128, 128), (16384, 128, 1), 0), out=buf864)
    del permute_1219
    buf865 = reinterpret_tensor(buf838, (16, 128, 256), (32768, 256, 1), 0); del buf838  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf863, (16, 128, 128), (16384, 128, 1), 0), permute_1220, out=buf865)
    del buf863
    del permute_1220
    buf866 = buf835; del buf835  # reuse
    buf867 = reinterpret_tensor(buf824, (1, 128, 16, 256), (524288, 4096, 256, 1), 0); del buf824  # reuse
    cpp_fused_add_clone_mul_neg_slice_backward_195(c_void_p(tangents_3.data_ptr()), c_void_p(buf864.data_ptr()), c_void_p(unsqueeze_3.data_ptr()), c_void_p(unsqueeze_5.data_ptr()), c_void_p(tangents_4.data_ptr()), c_void_p(buf860.data_ptr()), c_void_p(buf866.data_ptr()), c_void_p(buf867.data_ptr()))
    del tangents_4
    buf868 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf867, (4096, 128), (1, 4096), 0), view_2, out=buf868)
    buf869 = reinterpret_tensor(buf860, (128, 4096), (4096, 1), 0); del buf860  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf867, (128, 4096), (4096, 1), 0), permute_1227, out=buf869)
    del permute_1227
    buf870 = buf867; del buf867  # reuse
    cpp_fused_add_slice_backward_196(c_void_p(tangents_3.data_ptr()), c_void_p(buf864.data_ptr()), c_void_p(buf866.data_ptr()), c_void_p(buf870.data_ptr()))
    del buf866
    del tangents_3
    buf871 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf870, (4096, 128), (1, 4096), 0), view_2, out=buf871)
    buf872 = reinterpret_tensor(buf864, (128, 4096), (4096, 1), 0); del buf864  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf870, (128, 4096), (4096, 1), 0), permute_1231, out=buf872)
    del permute_1231
    buf873 = buf870; del buf870  # reuse
    cpp_fused_add_mul_neg_slice_backward_197(c_void_p(buf865.data_ptr()), c_void_p(unsqueeze_3.data_ptr()), c_void_p(unsqueeze_5.data_ptr()), c_void_p(buf873.data_ptr()))
    del unsqueeze_3
    del unsqueeze_5
    buf874 = empty((4096, 4096), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf873, (4096, 128), (1, 4096), 0), view_2, out=buf874)
    del view_2
    buf875 = reinterpret_tensor(buf865, (128, 4096), (4096, 1), 0); del buf865  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf873, (128, 4096), (4096, 1), 0), permute_1235, out=buf875)
    del permute_1235
    buf876 = reinterpret_tensor(buf873, (1, 128, 4096), (524288, 4096, 1), 0); del buf873  # reuse
    buf877 = buf847; del buf847  # reuse
    buf878 = buf846; del buf846  # reuse
    buf879 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf880 = empty((4096, ), device='cpu', dtype=torch.float32)
    buf881 = empty((50400, 4096), device='cpu', dtype=torch.float32)
    buf882 = buf850; del buf850  # reuse
    cpp_fused_add_embedding_dense_backward_native_layer_norm_native_layer_norm_backward_nll_loss_forward_198(c_void_p(buf882.data_ptr()), c_void_p(buf855.data_ptr()), c_void_p(buf869.data_ptr()), c_void_p(buf872.data_ptr()), c_void_p(buf875.data_ptr()), c_void_p(primals_2.data_ptr()), c_void_p(embedding.data_ptr()), c_void_p(getitem_1.data_ptr()), c_void_p(rsqrt.data_ptr()), c_void_p(view.data_ptr()), c_void_p(buf876.data_ptr()), c_void_p(buf877.data_ptr()), c_void_p(buf878.data_ptr()), c_void_p(buf879.data_ptr()), c_void_p(buf880.data_ptr()), c_void_p(buf881.data_ptr()))
    del buf855
    del buf869
    del buf872
    del buf875
    del buf876
    del buf877
    del buf878
    del embedding
    del getitem_1
    del primals_2
    del rsqrt
    aten.index_put_(buf881, [view], buf882, True)
    del buf882
    del view
    return (buf881, buf879, buf880, reinterpret_tensor(buf874, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf871, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf868, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf858, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf856, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf857, (16384, ), (1, ), 0), reinterpret_tensor(buf852, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf853, (4096, ), (1, ), 0), buf848, buf849, reinterpret_tensor(buf843, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf840, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf837, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf827, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf825, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf826, (16384, ), (1, ), 0), reinterpret_tensor(buf821, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf822, (4096, ), (1, ), 0), buf817, buf818, reinterpret_tensor(buf812, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf809, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf806, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf796, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf794, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf795, (16384, ), (1, ), 0), reinterpret_tensor(buf790, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf791, (4096, ), (1, ), 0), buf786, buf787, reinterpret_tensor(buf781, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf778, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf775, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf765, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf763, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf764, (16384, ), (1, ), 0), reinterpret_tensor(buf759, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf760, (4096, ), (1, ), 0), buf755, buf756, reinterpret_tensor(buf750, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf747, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf744, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf734, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf732, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf733, (16384, ), (1, ), 0), reinterpret_tensor(buf728, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf729, (4096, ), (1, ), 0), buf724, buf725, reinterpret_tensor(buf719, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf716, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf713, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf703, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf701, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf702, (16384, ), (1, ), 0), reinterpret_tensor(buf697, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf698, (4096, ), (1, ), 0), buf693, buf694, reinterpret_tensor(buf688, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf685, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf682, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf672, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf670, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf671, (16384, ), (1, ), 0), reinterpret_tensor(buf666, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf667, (4096, ), (1, ), 0), buf662, buf663, reinterpret_tensor(buf657, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf654, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf651, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf641, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf639, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf640, (16384, ), (1, ), 0), reinterpret_tensor(buf635, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf636, (4096, ), (1, ), 0), buf631, buf632, reinterpret_tensor(buf626, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf623, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf620, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf610, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf608, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf609, (16384, ), (1, ), 0), reinterpret_tensor(buf604, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf605, (4096, ), (1, ), 0), buf600, buf601, reinterpret_tensor(buf595, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf592, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf589, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf579, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf577, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf578, (16384, ), (1, ), 0), reinterpret_tensor(buf573, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf574, (4096, ), (1, ), 0), buf569, buf570, reinterpret_tensor(buf564, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf561, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf558, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf548, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf546, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf547, (16384, ), (1, ), 0), reinterpret_tensor(buf542, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf543, (4096, ), (1, ), 0), buf538, buf539, reinterpret_tensor(buf533, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf530, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf527, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf517, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf515, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf516, (16384, ), (1, ), 0), reinterpret_tensor(buf511, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf512, (4096, ), (1, ), 0), buf507, buf508, reinterpret_tensor(buf502, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf499, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf496, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf486, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf484, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf485, (16384, ), (1, ), 0), reinterpret_tensor(buf480, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf481, (4096, ), (1, ), 0), buf476, buf477, reinterpret_tensor(buf471, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf468, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf465, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf455, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf453, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf454, (16384, ), (1, ), 0), reinterpret_tensor(buf449, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf450, (4096, ), (1, ), 0), buf445, buf446, reinterpret_tensor(buf440, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf437, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf434, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf424, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf422, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf423, (16384, ), (1, ), 0), reinterpret_tensor(buf418, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf419, (4096, ), (1, ), 0), buf414, buf415, reinterpret_tensor(buf409, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf406, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf403, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf393, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf391, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf392, (16384, ), (1, ), 0), reinterpret_tensor(buf387, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf388, (4096, ), (1, ), 0), buf383, buf384, reinterpret_tensor(buf378, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf375, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf372, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf362, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf360, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf361, (16384, ), (1, ), 0), reinterpret_tensor(buf356, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf357, (4096, ), (1, ), 0), buf352, buf353, reinterpret_tensor(buf347, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf344, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf341, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf331, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf329, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf330, (16384, ), (1, ), 0), reinterpret_tensor(buf325, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf326, (4096, ), (1, ), 0), buf321, buf322, reinterpret_tensor(buf316, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf313, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf310, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf300, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf298, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf299, (16384, ), (1, ), 0), reinterpret_tensor(buf294, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf295, (4096, ), (1, ), 0), buf290, buf291, reinterpret_tensor(buf285, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf282, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf279, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf269, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf267, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf268, (16384, ), (1, ), 0), reinterpret_tensor(buf263, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf264, (4096, ), (1, ), 0), buf259, buf260, reinterpret_tensor(buf254, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf251, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf248, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf238, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf236, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf237, (16384, ), (1, ), 0), reinterpret_tensor(buf232, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf233, (4096, ), (1, ), 0), buf228, buf229, reinterpret_tensor(buf223, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf220, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf217, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf207, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf205, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf206, (16384, ), (1, ), 0), reinterpret_tensor(buf201, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf202, (4096, ), (1, ), 0), buf197, buf198, reinterpret_tensor(buf192, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf189, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf186, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf176, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf174, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf175, (16384, ), (1, ), 0), reinterpret_tensor(buf170, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf171, (4096, ), (1, ), 0), buf166, buf167, reinterpret_tensor(buf161, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf158, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf155, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf145, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf143, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf144, (16384, ), (1, ), 0), reinterpret_tensor(buf139, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf140, (4096, ), (1, ), 0), buf135, buf136, reinterpret_tensor(buf130, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf127, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf124, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf114, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf112, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf113, (16384, ), (1, ), 0), reinterpret_tensor(buf108, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf109, (4096, ), (1, ), 0), buf104, buf105, reinterpret_tensor(buf99, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf96, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf93, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf83, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf81, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf82, (16384, ), (1, ), 0), reinterpret_tensor(buf77, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf78, (4096, ), (1, ), 0), buf73, buf74, reinterpret_tensor(buf68, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf65, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf62, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf52, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf50, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf51, (16384, ), (1, ), 0), reinterpret_tensor(buf46, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf47, (4096, ), (1, ), 0), buf42, buf43, reinterpret_tensor(buf37, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf34, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf31, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf21, (4096, 4096), (4096, 1), 0), reinterpret_tensor(buf19, (16384, 4096), (4096, 1), 0), reinterpret_tensor(buf20, (16384, ), (1, ), 0), reinterpret_tensor(buf15, (4096, 16384), (16384, 1), 0), reinterpret_tensor(buf16, (4096, ), (1, ), 0), buf12, buf13, reinterpret_tensor(buf7, (50400, 4096), (4096, 1), 0), reinterpret_tensor(buf8, (50400, ), (1, ), 0), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, )


def benchmark_compiled_module(times=10, repeat=10):
    from torch._dynamo.testing import rand_strided
    from torch._inductor.utils import print_performance
    primals_2 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_12 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_22 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_32 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_42 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_52 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_62 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_72 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_82 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_92 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_102 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_112 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_122 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_132 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_142 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_152 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_162 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_172 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_182 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_192 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_202 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_212 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_222 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_232 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_242 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_252 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_262 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_272 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_282 = rand_strided((4096, ), (1, ), device='cpu', dtype=torch.float32)
    primals_288 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_291 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_294 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_297 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_300 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_303 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_306 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_309 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_312 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_315 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_318 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_321 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_324 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_327 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_330 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_333 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_336 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_339 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_342 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_345 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_348 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_351 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_354 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_357 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_360 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_363 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_366 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_369 = rand_strided((), (), device='cpu', dtype=torch.float32)
    primals_371 = rand_strided((1, 128), (128, 1), device='cpu', dtype=torch.int64)
    view = rand_strided((1, 128), (128, 1), device='cpu', dtype=torch.int64)
    embedding = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    getitem_1 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    rsqrt = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    view_2 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_3 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_5 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_48 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_24 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_28 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_10 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_30 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_16 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_18 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_96 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_52 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_2 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_1 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_56 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_20 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_58 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_29 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_31 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_144 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_80 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_4 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_2 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_84 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_30 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_86 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_42 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_44 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_192 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_108 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_6 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_3 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_112 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_40 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_114 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_55 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_57 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_240 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_136 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_8 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_4 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_140 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_50 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_142 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_68 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_70 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_288 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_164 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_10 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_5 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_168 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_60 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_170 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_81 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_83 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_336 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_192 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_12 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_6 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_196 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_70 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_198 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_94 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_96 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_384 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_220 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_14 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_7 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_224 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_80 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_226 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_107 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_109 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_432 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_248 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_16 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_8 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_252 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_90 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_254 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_120 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_122 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_480 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_276 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_18 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_9 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_280 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_100 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_282 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_133 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_135 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_528 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_304 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_20 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_10 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_308 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_110 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_310 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_146 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_148 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_576 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_332 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_22 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_11 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_336 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_120 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_338 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_159 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_161 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_624 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_360 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_24 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_12 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_364 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_130 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_366 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_172 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_174 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_672 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_388 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_26 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_13 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_392 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_140 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_394 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_185 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_187 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_720 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_416 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_28 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_14 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_420 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_150 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_422 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_198 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_200 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_768 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_444 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_30 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_15 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_448 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_160 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_450 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_211 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_213 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_816 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_472 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_32 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_16 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_476 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_170 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_478 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_224 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_226 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_864 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_500 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_34 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_17 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_504 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_180 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_506 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_237 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_239 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_912 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_528 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_36 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_18 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_532 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_190 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_534 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_250 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_252 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_960 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_556 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_38 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_19 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_560 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_200 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_562 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_263 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_265 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_1008 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_584 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_40 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_20 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_588 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_210 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_590 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_276 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_278 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_1056 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_612 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_42 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_21 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_616 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_220 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_618 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_289 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_291 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_1104 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_640 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_44 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_22 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_644 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_230 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_646 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_302 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_304 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_1152 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_668 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_46 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_23 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_672 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_240 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_674 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_315 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_317 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_1200 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_696 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_48 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_24 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_700 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_250 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_702 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_328 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_330 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_1248 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_724 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_50 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_25 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_728 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_260 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_730 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_341 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_343 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_1296 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_752 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_52 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_26 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_756 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_270 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_758 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    unsqueeze_354 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    unsqueeze_356 = rand_strided((1, 128, 1, 32, 1), (0, 64, 0, 1, 0), device='cpu', dtype=torch.float32)
    slice_1344 = rand_strided((1, 1, 128, 128), (4194304, 4194304, 2048, 1), device='cpu', dtype=torch.bool)
    view_780 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    addmm_54 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    tanh_27 = rand_strided((1, 128, 16384), (2097152, 16384, 1), device='cpu', dtype=torch.float32)
    view_784 = rand_strided((128, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    mul_280 = rand_strided((1, 128, 4096), (524288, 4096, 1), device='cpu', dtype=torch.float32)
    view_787 = rand_strided((128, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    sub_58 = rand_strided((127, 50400), (50400, 1), device='cpu', dtype=torch.float32)
    convert_element_type = rand_strided((), (), device='cpu', dtype=torch.float32)
    permute_309 = rand_strided((50400, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_58 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_313 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_317 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_323 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_326 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_327 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_59 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_328 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_329 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_336 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_340 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_344 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_60 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_346 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_350 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_356 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_359 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_360 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_61 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_361 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_362 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_369 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_373 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_377 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_62 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_379 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_383 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_389 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_392 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_393 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_63 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_394 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_395 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_402 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_406 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_410 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_64 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_412 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_416 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_422 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_425 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_426 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_65 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_427 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_428 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_435 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_439 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_443 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_66 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_445 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_449 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_455 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_458 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_459 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_67 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_460 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_461 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_468 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_472 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_476 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_68 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_478 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_482 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_488 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_491 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_492 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_69 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_493 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_494 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_501 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_505 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_509 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_70 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_511 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_515 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_521 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_524 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_525 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_71 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_526 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_527 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_534 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_538 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_542 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_72 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_544 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_548 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_554 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_557 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_558 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_73 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_559 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_560 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_567 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_571 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_575 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_74 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_577 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_581 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_587 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_590 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_591 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_75 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_592 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_593 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_600 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_604 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_608 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_76 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_610 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_614 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_620 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_623 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_624 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_77 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_625 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_626 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_633 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_637 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_641 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_78 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_643 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_647 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_653 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_656 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_657 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_79 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_658 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_659 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_666 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_670 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_674 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_80 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_676 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_680 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_686 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_689 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_690 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_81 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_691 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_692 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_699 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_703 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_707 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_82 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_709 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_713 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_719 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_722 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_723 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_83 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_724 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_725 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_732 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_736 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_740 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_84 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_742 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_746 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_752 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_755 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_756 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_85 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_757 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_758 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_765 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_769 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_773 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_86 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_775 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_779 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_785 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_788 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_789 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_87 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_790 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_791 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_798 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_802 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_806 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_88 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_808 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_812 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_818 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_821 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_822 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_89 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_823 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_824 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_831 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_835 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_839 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_90 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_841 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_845 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_851 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_854 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_855 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_91 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_856 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_857 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_864 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_868 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_872 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_92 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_874 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_878 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_884 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_887 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_888 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_93 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_889 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_890 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_897 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_901 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_905 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_94 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_907 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_911 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_917 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_920 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_921 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_95 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_922 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_923 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_930 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_934 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_938 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_96 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_940 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_944 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_950 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_953 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_954 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_97 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_955 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_956 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_963 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_967 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_971 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_98 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_973 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_977 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_983 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_986 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_987 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_99 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_988 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_989 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_996 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1000 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1004 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_100 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_1006 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_1010 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1016 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1019 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_1020 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_101 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_1021 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_1022 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_1029 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1033 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1037 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_102 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_1039 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_1043 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1049 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1052 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_1053 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_103 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_1054 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_1055 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_1062 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1066 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1070 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_104 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_1072 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_1076 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1082 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1085 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_1086 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_105 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_1087 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_1088 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_1095 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1099 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1103 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_106 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_1105 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_1109 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1115 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1118 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_1119 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_107 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_1120 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_1121 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_1128 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1132 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1136 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_108 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_1138 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_1142 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1148 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1151 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_1152 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_109 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_1153 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_1154 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_1161 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1165 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1169 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_110 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_1171 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_1175 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1181 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1184 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_1185 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_111 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_1186 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_1187 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_1194 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1198 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1202 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    div_112 = rand_strided((1, 128, 1), (128, 1, 1), device='cpu', dtype=torch.float32)
    permute_1204 = rand_strided((4096, 16384), (16384, 1), device='cpu', dtype=torch.float32)
    permute_1208 = rand_strided((16384, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1214 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1217 = rand_strided((16, 128, 128), (16384, 1, 128), device='cpu', dtype=torch.float32)
    permute_1218 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    alias_113 = rand_strided((1, 16, 128, 128), (262144, 16384, 128, 1), device='cpu', dtype=torch.float32)
    permute_1219 = rand_strided((16, 256, 128), (256, 1, 4096), device='cpu', dtype=torch.float32)
    permute_1220 = rand_strided((16, 128, 256), (256, 4096, 1), device='cpu', dtype=torch.float32)
    permute_1227 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1231 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    permute_1235 = rand_strided((4096, 4096), (4096, 1), device='cpu', dtype=torch.float32)
    tangents_1 = rand_strided((), (), device='cpu', dtype=torch.float32)
    tangents_2 = rand_strided((1, 128, 50400), (6451200, 50400, 1), device='cpu', dtype=torch.float32)
    tangents_3 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_4 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_5 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_6 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_7 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_8 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_9 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_10 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_11 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_12 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_13 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_14 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_15 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_16 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_17 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_18 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_19 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_20 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_21 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_22 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_23 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_24 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_25 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_26 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_27 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_28 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_29 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_30 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_31 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_32 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_33 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_34 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_35 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_36 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_37 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_38 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_39 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_40 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_41 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_42 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_43 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_44 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_45 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_46 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_47 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_48 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_49 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_50 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_51 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_52 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_53 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_54 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_55 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_56 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_57 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    tangents_58 = rand_strided((1, 16, 128, 256), (524288, 32768, 256, 1), device='cpu', dtype=torch.float32)
    return print_performance(lambda: call([primals_2, primals_12, primals_22, primals_32, primals_42, primals_52, primals_62, primals_72, primals_82, primals_92, primals_102, primals_112, primals_122, primals_132, primals_142, primals_152, primals_162, primals_172, primals_182, primals_192, primals_202, primals_212, primals_222, primals_232, primals_242, primals_252, primals_262, primals_272, primals_282, primals_288, primals_291, primals_294, primals_297, primals_300, primals_303, primals_306, primals_309, primals_312, primals_315, primals_318, primals_321, primals_324, primals_327, primals_330, primals_333, primals_336, primals_339, primals_342, primals_345, primals_348, primals_351, primals_354, primals_357, primals_360, primals_363, primals_366, primals_369, primals_371, view, embedding, getitem_1, rsqrt, view_2, unsqueeze_3, unsqueeze_5, slice_48, view_24, addmm, tanh, view_28, mul_10, view_30, unsqueeze_16, unsqueeze_18, slice_96, view_52, addmm_2, tanh_1, view_56, mul_20, view_58, unsqueeze_29, unsqueeze_31, slice_144, view_80, addmm_4, tanh_2, view_84, mul_30, view_86, unsqueeze_42, unsqueeze_44, slice_192, view_108, addmm_6, tanh_3, view_112, mul_40, view_114, unsqueeze_55, unsqueeze_57, slice_240, view_136, addmm_8, tanh_4, view_140, mul_50, view_142, unsqueeze_68, unsqueeze_70, slice_288, view_164, addmm_10, tanh_5, view_168, mul_60, view_170, unsqueeze_81, unsqueeze_83, slice_336, view_192, addmm_12, tanh_6, view_196, mul_70, view_198, unsqueeze_94, unsqueeze_96, slice_384, view_220, addmm_14, tanh_7, view_224, mul_80, view_226, unsqueeze_107, unsqueeze_109, slice_432, view_248, addmm_16, tanh_8, view_252, mul_90, view_254, unsqueeze_120, unsqueeze_122, slice_480, view_276, addmm_18, tanh_9, view_280, mul_100, view_282, unsqueeze_133, unsqueeze_135, slice_528, view_304, addmm_20, tanh_10, view_308, mul_110, view_310, unsqueeze_146, unsqueeze_148, slice_576, view_332, addmm_22, tanh_11, view_336, mul_120, view_338, unsqueeze_159, unsqueeze_161, slice_624, view_360, addmm_24, tanh_12, view_364, mul_130, view_366, unsqueeze_172, unsqueeze_174, slice_672, view_388, addmm_26, tanh_13, view_392, mul_140, view_394, unsqueeze_185, unsqueeze_187, slice_720, view_416, addmm_28, tanh_14, view_420, mul_150, view_422, unsqueeze_198, unsqueeze_200, slice_768, view_444, addmm_30, tanh_15, view_448, mul_160, view_450, unsqueeze_211, unsqueeze_213, slice_816, view_472, addmm_32, tanh_16, view_476, mul_170, view_478, unsqueeze_224, unsqueeze_226, slice_864, view_500, addmm_34, tanh_17, view_504, mul_180, view_506, unsqueeze_237, unsqueeze_239, slice_912, view_528, addmm_36, tanh_18, view_532, mul_190, view_534, unsqueeze_250, unsqueeze_252, slice_960, view_556, addmm_38, tanh_19, view_560, mul_200, view_562, unsqueeze_263, unsqueeze_265, slice_1008, view_584, addmm_40, tanh_20, view_588, mul_210, view_590, unsqueeze_276, unsqueeze_278, slice_1056, view_612, addmm_42, tanh_21, view_616, mul_220, view_618, unsqueeze_289, unsqueeze_291, slice_1104, view_640, addmm_44, tanh_22, view_644, mul_230, view_646, unsqueeze_302, unsqueeze_304, slice_1152, view_668, addmm_46, tanh_23, view_672, mul_240, view_674, unsqueeze_315, unsqueeze_317, slice_1200, view_696, addmm_48, tanh_24, view_700, mul_250, view_702, unsqueeze_328, unsqueeze_330, slice_1248, view_724, addmm_50, tanh_25, view_728, mul_260, view_730, unsqueeze_341, unsqueeze_343, slice_1296, view_752, addmm_52, tanh_26, view_756, mul_270, view_758, unsqueeze_354, unsqueeze_356, slice_1344, view_780, addmm_54, tanh_27, view_784, mul_280, view_787, sub_58, convert_element_type, permute_309, div_58, permute_313, permute_317, permute_323, permute_326, permute_327, alias_59, permute_328, permute_329, permute_336, permute_340, permute_344, div_60, permute_346, permute_350, permute_356, permute_359, permute_360, alias_61, permute_361, permute_362, permute_369, permute_373, permute_377, div_62, permute_379, permute_383, permute_389, permute_392, permute_393, alias_63, permute_394, permute_395, permute_402, permute_406, permute_410, div_64, permute_412, permute_416, permute_422, permute_425, permute_426, alias_65, permute_427, permute_428, permute_435, permute_439, permute_443, div_66, permute_445, permute_449, permute_455, permute_458, permute_459, alias_67, permute_460, permute_461, permute_468, permute_472, permute_476, div_68, permute_478, permute_482, permute_488, permute_491, permute_492, alias_69, permute_493, permute_494, permute_501, permute_505, permute_509, div_70, permute_511, permute_515, permute_521, permute_524, permute_525, alias_71, permute_526, permute_527, permute_534, permute_538, permute_542, div_72, permute_544, permute_548, permute_554, permute_557, permute_558, alias_73, permute_559, permute_560, permute_567, permute_571, permute_575, div_74, permute_577, permute_581, permute_587, permute_590, permute_591, alias_75, permute_592, permute_593, permute_600, permute_604, permute_608, div_76, permute_610, permute_614, permute_620, permute_623, permute_624, alias_77, permute_625, permute_626, permute_633, permute_637, permute_641, div_78, permute_643, permute_647, permute_653, permute_656, permute_657, alias_79, permute_658, permute_659, permute_666, permute_670, permute_674, div_80, permute_676, permute_680, permute_686, permute_689, permute_690, alias_81, permute_691, permute_692, permute_699, permute_703, permute_707, div_82, permute_709, permute_713, permute_719, permute_722, permute_723, alias_83, permute_724, permute_725, permute_732, permute_736, permute_740, div_84, permute_742, permute_746, permute_752, permute_755, permute_756, alias_85, permute_757, permute_758, permute_765, permute_769, permute_773, div_86, permute_775, permute_779, permute_785, permute_788, permute_789, alias_87, permute_790, permute_791, permute_798, permute_802, permute_806, div_88, permute_808, permute_812, permute_818, permute_821, permute_822, alias_89, permute_823, permute_824, permute_831, permute_835, permute_839, div_90, permute_841, permute_845, permute_851, permute_854, permute_855, alias_91, permute_856, permute_857, permute_864, permute_868, permute_872, div_92, permute_874, permute_878, permute_884, permute_887, permute_888, alias_93, permute_889, permute_890, permute_897, permute_901, permute_905, div_94, permute_907, permute_911, permute_917, permute_920, permute_921, alias_95, permute_922, permute_923, permute_930, permute_934, permute_938, div_96, permute_940, permute_944, permute_950, permute_953, permute_954, alias_97, permute_955, permute_956, permute_963, permute_967, permute_971, div_98, permute_973, permute_977, permute_983, permute_986, permute_987, alias_99, permute_988, permute_989, permute_996, permute_1000, permute_1004, div_100, permute_1006, permute_1010, permute_1016, permute_1019, permute_1020, alias_101, permute_1021, permute_1022, permute_1029, permute_1033, permute_1037, div_102, permute_1039, permute_1043, permute_1049, permute_1052, permute_1053, alias_103, permute_1054, permute_1055, permute_1062, permute_1066, permute_1070, div_104, permute_1072, permute_1076, permute_1082, permute_1085, permute_1086, alias_105, permute_1087, permute_1088, permute_1095, permute_1099, permute_1103, div_106, permute_1105, permute_1109, permute_1115, permute_1118, permute_1119, alias_107, permute_1120, permute_1121, permute_1128, permute_1132, permute_1136, div_108, permute_1138, permute_1142, permute_1148, permute_1151, permute_1152, alias_109, permute_1153, permute_1154, permute_1161, permute_1165, permute_1169, div_110, permute_1171, permute_1175, permute_1181, permute_1184, permute_1185, alias_111, permute_1186, permute_1187, permute_1194, permute_1198, permute_1202, div_112, permute_1204, permute_1208, permute_1214, permute_1217, permute_1218, alias_113, permute_1219, permute_1220, permute_1227, permute_1231, permute_1235, tangents_1, tangents_2, tangents_3, tangents_4, tangents_5, tangents_6, tangents_7, tangents_8, tangents_9, tangents_10, tangents_11, tangents_12, tangents_13, tangents_14, tangents_15, tangents_16, tangents_17, tangents_18, tangents_19, tangents_20, tangents_21, tangents_22, tangents_23, tangents_24, tangents_25, tangents_26, tangents_27, tangents_28, tangents_29, tangents_30, tangents_31, tangents_32, tangents_33, tangents_34, tangents_35, tangents_36, tangents_37, tangents_38, tangents_39, tangents_40, tangents_41, tangents_42, tangents_43, tangents_44, tangents_45, tangents_46, tangents_47, tangents_48, tangents_49, tangents_50, tangents_51, tangents_52, tangents_53, tangents_54, tangents_55, tangents_56, tangents_57, tangents_58]), times=times, repeat=repeat)


if __name__ == "__main__":
    from torch._inductor.wrapper_benchmark import compiled_module_main
    compiled_module_main('GPTJForCausalLM', benchmark_compiled_module)
