
from ctypes import c_void_p, c_long
import torch
import math
import random
import os
import tempfile
from math import inf, nan
from torch._inductor.hooks import run_intermediate_hooks
from torch._inductor.utils import maybe_profile
from torch._inductor.codegen.memory_planning import _align as align

from torch import device, empty, empty_strided
from torch._inductor.codecache import AsyncCompile
from torch._inductor.select_algorithm import extern_kernels

aten = torch.ops.aten
inductor_ops = torch.ops.inductor
assert_size_stride = torch._C._dynamo.guards.assert_size_stride
alloc_from_pool = torch.ops.inductor._alloc_from_pool
reinterpret_tensor = torch.ops.inductor._reinterpret_tensor
async_compile = AsyncCompile()


# kernel path: /tmp/torchinductor_youkaichao/rf/crfprumiqj5iwpnsvgstphw7s5b6goyn3q7d4odctxszupsag7kj.py
# Source Nodes: [], Original ATen: []

triton_poi_fused_0 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[512, 16], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_0', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 288
    xnumel = 9
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 3
    y1 = (yindex // 3)
    tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask & ymask, eviction_policy='evict_last')
    tl.store(out_ptr0 + (y0 + (3*x2) + (27*y1)), tmp0, xmask & ymask)
''')

import triton
import triton.language as tl
from torch._inductor.triton_heuristics import grid, start_graph, end_graph
from torch._C import _cuda_getCurrentRawStream as get_cuda_stream


# kernel path: /tmp/torchinductor_youkaichao/ft/cftul2nrhhv5nsmpwpz4exiu7ypwiyd5s7hbfunupcul6smhkhoc.py
# Source Nodes: [], Original ATen: []

triton_poi_fused_1 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[32, 131072], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_1', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 24
    xnumel = 109561
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 3
    y1 = (yindex // 3)
    tmp0 = tl.load(in_ptr0 + (x2 + (109561*y3)), xmask & ymask, eviction_policy='evict_last')
    tl.store(out_ptr0 + (y0 + (3*x2) + (328683*y1)), tmp0, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/4b/c4bimuduosdzqvgf5vbttknudl5lkzeevk44y4ffg6qra77q46rm.py
# Source Nodes: [x], Original ATen: [aten.convolution]
# x => convolution
triton_poi_fused_convolution_2 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1024, 32768], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_2', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 768
    xnumel = 27225
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 96
    y1 = (yindex // 96)
    tmp0 = tl.load(in_ptr0 + (x2 + (27225*y3)), xmask & ymask, eviction_policy='evict_last')
    tl.store(out_ptr0 + (y0 + (96*x2) + (2613600*y1)), tmp0, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/m5/cm52mcxoydyd6qg2c43f76thyl3fl5qw7pwoz37xg5bakh3ictdt.py
# Source Nodes: [x_1], Original ATen: [aten._native_batch_norm_legit_functional]
# x_1 => var_mean
triton_red_fused__native_batch_norm_legit_functional_3 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[131072, 256],
    reduction_hint=ReductionHint.OUTER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_3', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 95040
    rnumel = 220
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 96
    x1 = (xindex // 96)
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    x3 = xindex
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + (x0 + (96*r2) + (21120*x1)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x3), tmp2, xmask)
    tl.store(out_ptr1 + (x3), tmp3, xmask)
    tl.store(out_ptr2 + (x3), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/4x/c4xbnkg6bxt3f7admqmsmntnjf3hqimq4tqpxpssz3rzsiob5txz.py
# Source Nodes: [x_1], Original ATen: [aten._native_batch_norm_legit_functional]
# x_1 => var_mean
triton_red_fused__native_batch_norm_legit_functional_4 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[1024, 128],
    reduction_hint=ReductionHint.OUTER_TINY,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_4', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 768
    rnumel = 124
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 8
    x1 = (xindex // 8)
    tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = r2 + (124*x0)
        tmp1 = tl.full([1, 1], 990, tl.int32)
        tmp2 = tmp0 < tmp1
        tmp3 = tl.load(in_ptr0 + (x1 + (96*r2) + (11904*x0)), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
        tmp5 = tl.where(tmp2, tmp3, tmp4)
        tmp6 = tl.load(in_ptr1 + (x1 + (96*r2) + (11904*x0)), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
        tmp8 = tl.where(tmp2, tmp6, tmp7)
        tmp9 = tl.load(in_ptr2 + (x1 + (96*r2) + (11904*x0)), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
        tmp11 = tl.where(tmp2, tmp9, tmp10)
        tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
        tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
        tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
            tmp15_mean, tmp15_m2, tmp15_weight,
            tmp12, tmp13, tmp14
        )
        tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
        tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
        tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
    tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
        tmp15_mean, tmp15_m2, tmp15_weight, 1
    )
    tmp15 = tmp15_tmp[:, None]
    tmp16 = tmp16_tmp[:, None]
    tmp17 = tmp17_tmp[:, None]
    tl.store(out_ptr0 + (x1 + (96*x0)), tmp15, xmask)
    tl.store(out_ptr1 + (x1 + (96*x0)), tmp16, xmask)
    tl.store(out_ptr2 + (x1 + (96*x0)), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/p2/cp2ijtmwtikmdvesttp6xep3h5tthsgho7p5jqbzkj52w24j3liq.py
# Source Nodes: [x_1], Original ATen: [aten._native_batch_norm_legit_functional]
# x_1 => add_1, add_2, add_3, mul_1, mul_2, mul_3, mul_4, mul_5, rsqrt, squeeze_1, var_mean
triton_per_fused__native_batch_norm_legit_functional_5 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[128, 8],
    reduction_hint=ReductionHint.OUTER_TINY,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10, 11))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_5', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 96
    rnumel = 8
    RBLOCK: tl.constexpr = 8
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (96*r1)), rmask & xmask, other=0.0)
    tmp1 = tl.load(in_ptr1 + (x0 + (96*r1)), rmask & xmask, other=0.0)
    tmp2 = tl.load(in_ptr2 + (x0 + (96*r1)), rmask & xmask, other=0.0)
    tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
    tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
    tmp7 = tl.where(rmask & xmask, tmp3, 0)
    tmp8 = tl.where(rmask & xmask, tmp4, 0)
    tmp9 = tl.where(rmask & xmask, tmp5, 0)
    tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
    tmp13 = tmp10[:, None]
    tmp14 = tmp11[:, None]
    tmp15 = tmp12[:, None]
    tmp16 = 217800.0
    tmp17 = tmp14 / tmp16
    tmp18 = 0.001
    tmp19 = tmp17 + tmp18
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = 0.1
    tmp22 = tmp13 * tmp21
    tmp24 = 0.9
    tmp25 = tmp23 * tmp24
    tmp26 = tmp22 + tmp25
    tmp27 = 1.0000045913893085
    tmp28 = tmp17 * tmp27
    tmp29 = tmp28 * tmp21
    tmp31 = tmp30 * tmp24
    tmp32 = tmp29 + tmp31
    tl.store(out_ptr2 + (x0), tmp20, xmask)
    tl.store(out_ptr4 + (x0), tmp26, xmask)
    tl.store(out_ptr6 + (x0), tmp32, xmask)
    tl.store(out_ptr0 + (x0), tmp13, xmask)
    tl.store(out_ptr1 + (x0), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/xm/cxmibiguaxkbqerqzuddsp4vh3ap45jxzmrky6zposb776quzgla.py
# Source Nodes: [x_1, x_5], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# x_1 => add_1, add_4, mul, mul_6, rsqrt, sub, var_mean
# x_5 => relu
triton_poi_fused__native_batch_norm_legit_functional_relu_6 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[33554432], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_6', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 20908800
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = xindex
    x0 = xindex % 96
    tmp0 = tl.load(in_ptr0 + (x2), xmask)
    tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 217800.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x2), tmp13, xmask)
    tl.store(out_ptr1 + (x2), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/4p/c4pmhvwlwcb7zjtk3nilwsveazkcpheu6osvuffv6ty3xcfgimlx.py
# Source Nodes: [x_6], Original ATen: [aten.convolution]
# x_6 => convolution_1
triton_poi_fused_convolution_7 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[512, 32768], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_7', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 432
    xnumel = 27225
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 54
    y1 = (yindex // 54)
    tmp0 = tl.load(in_ptr0 + (x2 + (27225*y3)), xmask & ymask, eviction_policy='evict_last')
    tl.store(out_ptr0 + (y0 + (54*x2) + (1470150*y1)), tmp0, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/7q/c7qasucfn2arajc5hbmqbpj4ys4gp72hg7zvk4rc25gws3b2zjqy.py
# Source Nodes: [x_right], Original ATen: [aten._native_batch_norm_legit_functional]
# x_right => var_mean_1
triton_red_fused__native_batch_norm_legit_functional_8 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[65536, 256],
    reduction_hint=ReductionHint.OUTER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_8', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 53460
    rnumel = 220
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 54
    x1 = (xindex // 54)
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    x3 = xindex
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + (x0 + (54*r2) + (11880*x1)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x3), tmp2, xmask)
    tl.store(out_ptr1 + (x3), tmp3, xmask)
    tl.store(out_ptr2 + (x3), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/vm/cvmrrin4sp3u43vlmriy3zl4cf4jlx4rodfuvmi3yiikuu324vwc.py
# Source Nodes: [x_right], Original ATen: [aten._native_batch_norm_legit_functional]
# x_right => var_mean_1
triton_red_fused__native_batch_norm_legit_functional_9 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[512, 128],
    reduction_hint=ReductionHint.OUTER_TINY,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_9', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 432
    rnumel = 124
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 8
    x1 = (xindex // 8)
    tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = r2 + (124*x0)
        tmp1 = tl.full([1, 1], 990, tl.int32)
        tmp2 = tmp0 < tmp1
        tmp3 = tl.load(in_ptr0 + (x1 + (54*r2) + (6696*x0)), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
        tmp5 = tl.where(tmp2, tmp3, tmp4)
        tmp6 = tl.load(in_ptr1 + (x1 + (54*r2) + (6696*x0)), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
        tmp8 = tl.where(tmp2, tmp6, tmp7)
        tmp9 = tl.load(in_ptr2 + (x1 + (54*r2) + (6696*x0)), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
        tmp11 = tl.where(tmp2, tmp9, tmp10)
        tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
        tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
        tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
            tmp15_mean, tmp15_m2, tmp15_weight,
            tmp12, tmp13, tmp14
        )
        tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
        tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
        tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
    tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
        tmp15_mean, tmp15_m2, tmp15_weight, 1
    )
    tmp15 = tmp15_tmp[:, None]
    tmp16 = tmp16_tmp[:, None]
    tmp17 = tmp17_tmp[:, None]
    tl.store(out_ptr0 + (x1 + (54*x0)), tmp15, xmask)
    tl.store(out_ptr1 + (x1 + (54*x0)), tmp16, xmask)
    tl.store(out_ptr2 + (x1 + (54*x0)), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/pq/cpqngzaejaw67mapgwu3okbgt3lv7puqa6aoahhiwr75zx2f4hkj.py
# Source Nodes: [x_right], Original ATen: [aten._native_batch_norm_legit_functional]
# x_right => add_6, add_7, add_8, mul_10, mul_11, mul_12, mul_8, mul_9, rsqrt_1, squeeze_4, var_mean_1
triton_per_fused__native_batch_norm_legit_functional_10 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[64, 8],
    reduction_hint=ReductionHint.OUTER_TINY,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_10', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 54
    rnumel = 8
    RBLOCK: tl.constexpr = 8
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (54*r1)), rmask & xmask, other=0.0)
    tmp1 = tl.load(in_ptr1 + (x0 + (54*r1)), rmask & xmask, other=0.0)
    tmp2 = tl.load(in_ptr2 + (x0 + (54*r1)), rmask & xmask, other=0.0)
    tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
    tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
    tmp7 = tl.where(rmask & xmask, tmp3, 0)
    tmp8 = tl.where(rmask & xmask, tmp4, 0)
    tmp9 = tl.where(rmask & xmask, tmp5, 0)
    tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
    tmp13 = tmp10[:, None]
    tmp14 = tmp11[:, None]
    tmp15 = tmp12[:, None]
    tmp16 = 217800.0
    tmp17 = tmp14 / tmp16
    tmp18 = 0.001
    tmp19 = tmp17 + tmp18
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = 0.1
    tmp22 = tmp13 * tmp21
    tmp24 = 0.9
    tmp25 = tmp23 * tmp24
    tmp26 = tmp22 + tmp25
    tmp27 = 1.0000045913893085
    tmp28 = tmp17 * tmp27
    tmp29 = tmp28 * tmp21
    tmp31 = tmp30 * tmp24
    tmp32 = tmp29 + tmp31
    tl.store(out_ptr2 + (x0), tmp20, xmask)
    tl.store(out_ptr4 + (x0), tmp26, xmask)
    tl.store(out_ptr6 + (x0), tmp32, xmask)
    tl.store(out_ptr0 + (x0), tmp13, xmask)
    tl.store(out_ptr1 + (x0), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ef/cefdsit6h74hiuctwu2ntafxmuwpmdkffgcdf4xqwdruoppzcbtt.py
# Source Nodes: [x_22, x_right], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu, aten.threshold_backward]
# x_22 => relu_3
# x_right => add_6, add_9, mul_13, mul_7, rsqrt_1, sub_1, var_mean_1
triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_11 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16777216], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*i1', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_11', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, xnumel, XBLOCK : tl.constexpr):
    xnumel = 11761200
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = xindex
    x0 = xindex % 54
    tmp0 = tl.load(in_ptr0 + (x2), xmask)
    tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 217800.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tmp15 = 0.0
    tmp16 = tmp14 <= tmp15
    tl.store(out_ptr0 + (x2), tmp13, xmask)
    tl.store(out_ptr1 + (x2), tmp14, xmask)
    tl.store(out_ptr2 + (x2), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/e6/ce63g2226fmtqd2zqb3aajostnn3qyoibfoekql7lgp34l45vzzz.py
# Source Nodes: [x_10], Original ATen: [aten.constant_pad_nd]
# x_10 => constant_pad_nd
triton_poi_fused_constant_pad_nd_12 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[33554432], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_12', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 21934848
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 16224) % 169
    x1 = (xindex // 96) % 169
    x3 = (xindex // 2741856)
    x4 = xindex % 16224
    x6 = xindex
    tmp0 = (-2) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 165, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-2) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-31872) + x4 + (15840*x2) + (2613600*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/4i/c4idhaq76bpnzs7at5r6665p2fpvah55xpraykojkmzzq2qgvcwu.py
# Source Nodes: [x_11], Original ATen: [aten.convolution]
# x_11 => convolution_2
triton_poi_fused_convolution_13 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1024, 8192], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_13', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 768
    xnumel = 6889
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 96
    y1 = (yindex // 96)
    tmp0 = tl.load(in_ptr0 + (x2 + (6889*y3)), xmask & ymask, eviction_policy='evict_last')
    tl.store(out_ptr0 + (y0 + (96*x2) + (661344*y1)), tmp0, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/lb/clb2hdmwygsnpeeaww2inrzt25taywibyf5yczdyuncbepmgj77o.py
# Source Nodes: [x_13], Original ATen: [aten.convolution]
# x_13 => convolution_3
triton_poi_fused_convolution_14 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[512, 8192], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_14', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 432
    xnumel = 6889
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 54
    y1 = (yindex // 54)
    tmp0 = tl.load(in_ptr0 + (x2 + (6889*y3)), xmask & ymask, eviction_policy='evict_last')
    tl.store(out_ptr0 + (y0 + (54*x2) + (372006*y1)), tmp0, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/3d/c3dpszazdvropypgxfli5gcwdfadtkdv2mysyifvapcwhlo7gqee.py
# Source Nodes: [x_14], Original ATen: [aten._native_batch_norm_legit_functional]
# x_14 => var_mean_2
triton_red_fused__native_batch_norm_legit_functional_15 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[32768, 128],
    reduction_hint=ReductionHint.OUTER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_15', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 23274
    rnumel = 128
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x1 = (xindex // 54)
    x0 = xindex % 54
    tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    x3 = xindex
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = r2 + (128*x1)
        tmp1 = tl.full([1, 1], 55112, tl.int32)
        tmp2 = tmp0 < tmp1
        tmp3 = tl.load(in_ptr0 + (x0 + (54*((r2 + (128*x1)) % 55112))), rmask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
        tmp5 = tl.where(tmp2, tmp3, tmp4)
        tmp6 = 0.0
        tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
        tmp8 = tl.where(tmp2, tmp6, tmp7)
        tmp9 = 1.0
        tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
        tmp11 = tl.where(tmp2, tmp9, tmp10)
        tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
        tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
        tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
            tmp15_mean, tmp15_m2, tmp15_weight,
            tmp12, tmp13, tmp14
        )
        tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
        tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
        tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
    tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
        tmp15_mean, tmp15_m2, tmp15_weight, 1
    )
    tmp15 = tmp15_tmp[:, None]
    tmp16 = tmp16_tmp[:, None]
    tmp17 = tmp17_tmp[:, None]
    tl.store(out_ptr0 + (x3), tmp15, xmask)
    tl.store(out_ptr1 + (x3), tmp16, xmask)
    tl.store(out_ptr2 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/g2/cg2rmxoyllgnqrbclvwnh62qobpy2x5fnrosu553cuxbsd5ehf7i.py
# Source Nodes: [x_14], Original ATen: [aten._native_batch_norm_legit_functional]
# x_14 => var_mean_2
triton_red_fused__native_batch_norm_legit_functional_16 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[256, 128],
    reduction_hint=ReductionHint.OUTER_TINY,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_16', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 216
    rnumel = 108
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 4
    x1 = (xindex // 4)
    tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = r2 + (108*x0)
        tmp1 = tl.full([1, 1], 431, tl.int32)
        tmp2 = tmp0 < tmp1
        tmp3 = tl.load(in_ptr0 + (x1 + (54*r2) + (5832*x0)), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
        tmp5 = tl.where(tmp2, tmp3, tmp4)
        tmp6 = tl.load(in_ptr1 + (x1 + (54*r2) + (5832*x0)), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
        tmp8 = tl.where(tmp2, tmp6, tmp7)
        tmp9 = tl.load(in_ptr2 + (x1 + (54*r2) + (5832*x0)), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
        tmp11 = tl.where(tmp2, tmp9, tmp10)
        tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
        tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
        tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
            tmp15_mean, tmp15_m2, tmp15_weight,
            tmp12, tmp13, tmp14
        )
        tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
        tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
        tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
    tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
        tmp15_mean, tmp15_m2, tmp15_weight, 1
    )
    tmp15 = tmp15_tmp[:, None]
    tmp16 = tmp16_tmp[:, None]
    tmp17 = tmp17_tmp[:, None]
    tl.store(out_ptr0 + (x1 + (54*x0)), tmp15, xmask)
    tl.store(out_ptr1 + (x1 + (54*x0)), tmp16, xmask)
    tl.store(out_ptr2 + (x1 + (54*x0)), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/3g/c3go2mkmbv4za4cu3rcx4wa75k6slrc4t5meacy3xffbgwclnk2i.py
# Source Nodes: [x_14], Original ATen: [aten._native_batch_norm_legit_functional]
# x_14 => add_11, add_12, add_13, mul_15, mul_16, mul_17, mul_18, mul_19, rsqrt_2, squeeze_7, var_mean_2
triton_per_fused__native_batch_norm_legit_functional_17 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[64, 4],
    reduction_hint=ReductionHint.OUTER_TINY,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_17', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 54
    rnumel = 4
    RBLOCK: tl.constexpr = 4
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (54*r1)), rmask & xmask, other=0.0)
    tmp1 = tl.load(in_ptr1 + (x0 + (54*r1)), rmask & xmask, other=0.0)
    tmp2 = tl.load(in_ptr2 + (x0 + (54*r1)), rmask & xmask, other=0.0)
    tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
    tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
    tmp7 = tl.where(rmask & xmask, tmp3, 0)
    tmp8 = tl.where(rmask & xmask, tmp4, 0)
    tmp9 = tl.where(rmask & xmask, tmp5, 0)
    tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
    tmp13 = tmp10[:, None]
    tmp14 = tmp11[:, None]
    tmp15 = tmp12[:, None]
    tmp16 = 55112.0
    tmp17 = tmp14 / tmp16
    tmp18 = 0.001
    tmp19 = tmp17 + tmp18
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = 0.1
    tmp22 = tmp13 * tmp21
    tmp24 = 0.9
    tmp25 = tmp23 * tmp24
    tmp26 = tmp22 + tmp25
    tmp27 = 1.0000181451978734
    tmp28 = tmp17 * tmp27
    tmp29 = tmp28 * tmp21
    tmp31 = tmp30 * tmp24
    tmp32 = tmp29 + tmp31
    tl.store(out_ptr2 + (x0), tmp20, xmask)
    tl.store(out_ptr4 + (x0), tmp26, xmask)
    tl.store(out_ptr6 + (x0), tmp32, xmask)
    tl.store(out_ptr0 + (x0), tmp13, xmask)
    tl.store(out_ptr1 + (x0), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/tj/ctjdncohemyrg3otsyq3aspuorawuax6vtz3l5xl4ur3cftldjtz.py
# Source Nodes: [x_14, x_15], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# x_14 => add_11, add_14, mul_14, mul_20, rsqrt_2, sub_2, var_mean_2
# x_15 => relu_2
triton_poi_fused__native_batch_norm_legit_functional_relu_18 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4194304], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_18', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 2976048
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = xindex
    x0 = xindex % 54
    tmp0 = tl.load(in_ptr0 + (x2), xmask)
    tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 55112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x2), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/jq/cjqkly5vatdxefr77bs6hzc7i76knmxtfgvms26ryhksgwm36ph2.py
# Source Nodes: [x_21], Original ATen: [aten.constant_pad_nd]
# x_21 => constant_pad_nd_1
triton_poi_fused_constant_pad_nd_19 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[33554432], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_19', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 21418752
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 16032) % 167
    x1 = (xindex // 96) % 167
    x3 = (xindex // 2677344)
    x4 = xindex % 16032
    x6 = xindex
    tmp0 = (-1) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 165, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-1) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-15936) + x4 + (15840*x2) + (2613600*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, float("-inf"), tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/rb/crb2kdqzpqlgqm3tse6d66aer7bgcc35bj6y77wygdnndwnvpxr7.py
# Source Nodes: [max_pool2d], Original ATen: [aten.max_pool2d_with_indices]
# max_pool2d => getitem_8, getitem_9
triton_poi_fused_max_pool2d_with_indices_20 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1024, 8192], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*i64', 3: 'i32', 4: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_20', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 768
    xnumel = 6889
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex % 83
    x3 = (xindex // 83)
    y0 = yindex % 96
    y1 = (yindex // 96)
    x4 = xindex
    tmp0 = tl.load(in_ptr0 + (y0 + (192*x2) + (32064*x3) + (2677344*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr0 + (96 + y0 + (192*x2) + (32064*x3) + (2677344*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr0 + (192 + y0 + (192*x2) + (32064*x3) + (2677344*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp5 = tl.load(in_ptr0 + (16032 + y0 + (192*x2) + (32064*x3) + (2677344*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr0 + (16128 + y0 + (192*x2) + (32064*x3) + (2677344*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp9 = tl.load(in_ptr0 + (16224 + y0 + (192*x2) + (32064*x3) + (2677344*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr0 + (32064 + y0 + (192*x2) + (32064*x3) + (2677344*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr0 + (32160 + y0 + (192*x2) + (32064*x3) + (2677344*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr0 + (32256 + y0 + (192*x2) + (32064*x3) + (2677344*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp2 = triton_helpers.maximum(tmp1, tmp0)
    tmp4 = triton_helpers.maximum(tmp3, tmp2)
    tmp6 = triton_helpers.maximum(tmp5, tmp4)
    tmp8 = triton_helpers.maximum(tmp7, tmp6)
    tmp10 = triton_helpers.maximum(tmp9, tmp8)
    tmp12 = triton_helpers.maximum(tmp11, tmp10)
    tmp14 = triton_helpers.maximum(tmp13, tmp12)
    tmp16 = triton_helpers.maximum(tmp15, tmp14)
    tmp17 = tmp1 > tmp0
    tmp18 = 1 + (2*x2) + (334*x3)
    tmp19 = (2*x2) + (334*x3)
    tmp20 = tl.where(tmp17, tmp18, tmp19)
    tmp21 = tmp3 > tmp2
    tmp22 = 2 + (2*x2) + (334*x3)
    tmp23 = tl.where(tmp21, tmp22, tmp20)
    tmp24 = tmp5 > tmp4
    tmp25 = 167 + (2*x2) + (334*x3)
    tmp26 = tl.where(tmp24, tmp25, tmp23)
    tmp27 = tmp7 > tmp6
    tmp28 = 168 + (2*x2) + (334*x3)
    tmp29 = tl.where(tmp27, tmp28, tmp26)
    tmp30 = tmp9 > tmp8
    tmp31 = 169 + (2*x2) + (334*x3)
    tmp32 = tl.where(tmp30, tmp31, tmp29)
    tmp33 = tmp11 > tmp10
    tmp34 = 334 + (2*x2) + (334*x3)
    tmp35 = tl.where(tmp33, tmp34, tmp32)
    tmp36 = tmp13 > tmp12
    tmp37 = 335 + (2*x2) + (334*x3)
    tmp38 = tl.where(tmp36, tmp37, tmp35)
    tmp39 = tmp15 > tmp14
    tmp40 = 336 + (2*x2) + (334*x3)
    tmp41 = tl.where(tmp39, tmp40, tmp38)
    tl.store(out_ptr0 + (y0 + (96*x4) + (661344*y1)), tmp16, xmask & ymask)
    tl.store(out_ptr1 + (y0 + (96*x4) + (661344*y1)), tmp41, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/jz/cjzahrdavew6amgn55wezs6by6q2k2gokdzspxb27visdjcpu4mk.py
# Source Nodes: [x_comb_iter_0, x_comb_iter_0_left, x_comb_iter_0_right], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_0 => add_25
# x_comb_iter_0_left => add_16, add_19, mul_21, mul_27, rsqrt_3, sub_3, var_mean_3
# x_comb_iter_0_right => add_21, add_24, mul_28, mul_34, rsqrt_4, sub_4, var_mean_4
triton_poi_fused__native_batch_norm_legit_functional_add_21 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536, 64], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32', 12: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_21', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 55112
    xnumel = 54
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 6889
    y1 = (yindex // 6889)
    tmp0 = tl.load(in_ptr0 + (x2 + (54*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x2), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x2 + (54*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x2), xmask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x2), xmask, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x2), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x2), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 55112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp13 + tmp25
    tl.store(out_ptr0 + (y0 + (6889*x2) + (1860030*y1)), tmp26, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ti/ctifmgp6abeytfdgqiaerltdfonkn5c7zp4izvzdkzuhfphhpzes.py
# Source Nodes: [x_24], Original ATen: [aten.constant_pad_nd]
# x_24 => constant_pad_nd_2
triton_poi_fused_constant_pad_nd_22 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16777216], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_22', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 12632112
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 9234) % 171
    x1 = (xindex // 54) % 171
    x3 = (xindex // 1579014)
    x4 = xindex % 9234
    x6 = xindex
    tmp0 = (-3) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 165, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-3) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-26892) + x4 + (8910*x2) + (1470150*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/v7/cv7lwzlhigzh7ulyddntiiwwndmyy4b7iooy6lyv4dlftk4stds5.py
# Source Nodes: [x_35], Original ATen: [aten.constant_pad_nd]
# x_35 => constant_pad_nd_3
triton_poi_fused_constant_pad_nd_23 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16777216], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_23', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 12048048
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 9018) % 167
    x1 = (xindex // 54) % 167
    x3 = (xindex // 1506006)
    x4 = xindex % 9018
    x6 = xindex
    tmp0 = (-1) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 165, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-1) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-8964) + x4 + (8910*x2) + (1470150*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, float("-inf"), tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/gt/cgta2cmmmwqfucnozy2n7qqizxm5cxyefmyiydrw2qnwzq2ykl3b.py
# Source Nodes: [x_comb_iter_1_right], Original ATen: [aten.max_pool2d_with_indices]
# x_comb_iter_1_right => getitem_17, max_pool2d_with_indices_1
triton_poi_fused_max_pool2d_with_indices_24 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[512, 8192], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*i64', 3: 'i32', 4: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_24', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 432
    xnumel = 6889
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex % 83
    x3 = (xindex // 83)
    y0 = yindex % 54
    y1 = (yindex // 54)
    x4 = xindex
    tmp0 = tl.load(in_ptr0 + (y0 + (108*x2) + (18036*x3) + (1506006*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr0 + (54 + y0 + (108*x2) + (18036*x3) + (1506006*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr0 + (108 + y0 + (108*x2) + (18036*x3) + (1506006*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp5 = tl.load(in_ptr0 + (9018 + y0 + (108*x2) + (18036*x3) + (1506006*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr0 + (9072 + y0 + (108*x2) + (18036*x3) + (1506006*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp9 = tl.load(in_ptr0 + (9126 + y0 + (108*x2) + (18036*x3) + (1506006*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr0 + (18036 + y0 + (108*x2) + (18036*x3) + (1506006*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr0 + (18090 + y0 + (108*x2) + (18036*x3) + (1506006*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr0 + (18144 + y0 + (108*x2) + (18036*x3) + (1506006*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp2 = triton_helpers.maximum(tmp1, tmp0)
    tmp4 = triton_helpers.maximum(tmp3, tmp2)
    tmp6 = triton_helpers.maximum(tmp5, tmp4)
    tmp8 = triton_helpers.maximum(tmp7, tmp6)
    tmp10 = triton_helpers.maximum(tmp9, tmp8)
    tmp12 = triton_helpers.maximum(tmp11, tmp10)
    tmp14 = triton_helpers.maximum(tmp13, tmp12)
    tmp16 = triton_helpers.maximum(tmp15, tmp14)
    tmp17 = tmp1 > tmp0
    tmp18 = 1 + (2*x2) + (334*x3)
    tmp19 = (2*x2) + (334*x3)
    tmp20 = tl.where(tmp17, tmp18, tmp19)
    tmp21 = tmp3 > tmp2
    tmp22 = 2 + (2*x2) + (334*x3)
    tmp23 = tl.where(tmp21, tmp22, tmp20)
    tmp24 = tmp5 > tmp4
    tmp25 = 167 + (2*x2) + (334*x3)
    tmp26 = tl.where(tmp24, tmp25, tmp23)
    tmp27 = tmp7 > tmp6
    tmp28 = 168 + (2*x2) + (334*x3)
    tmp29 = tl.where(tmp27, tmp28, tmp26)
    tmp30 = tmp9 > tmp8
    tmp31 = 169 + (2*x2) + (334*x3)
    tmp32 = tl.where(tmp30, tmp31, tmp29)
    tmp33 = tmp11 > tmp10
    tmp34 = 334 + (2*x2) + (334*x3)
    tmp35 = tl.where(tmp33, tmp34, tmp32)
    tmp36 = tmp13 > tmp12
    tmp37 = 335 + (2*x2) + (334*x3)
    tmp38 = tl.where(tmp36, tmp37, tmp35)
    tmp39 = tmp15 > tmp14
    tmp40 = 336 + (2*x2) + (334*x3)
    tmp41 = tl.where(tmp39, tmp40, tmp38)
    tl.store(out_ptr0 + (y0 + (54*x4) + (372006*y1)), tmp16, xmask & ymask)
    tl.store(out_ptr1 + (y0 + (54*x4) + (372006*y1)), tmp41, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/iw/ciwbyph2zkrs66a562f6vwlqrppqufg7gwulib3zwmnfttniqupb.py
# Source Nodes: [x_38], Original ATen: [aten.constant_pad_nd]
# x_38 => constant_pad_nd_4
triton_poi_fused_constant_pad_nd_25 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16777216], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_25', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 12338352
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 9126) % 169
    x1 = (xindex // 54) % 169
    x3 = (xindex // 1542294)
    x4 = xindex % 9126
    x6 = xindex
    tmp0 = (-2) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 165, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-2) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-17928) + x4 + (8910*x2) + (1470150*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/gr/cgreyo725acwpe5unb5b34lwuwewukoofqhtzoig34zbgtyipy4p.py
# Source Nodes: [x_50], Original ATen: [aten.constant_pad_nd]
# x_50 => constant_pad_nd_5
triton_poi_fused_constant_pad_nd_26 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16777216], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_26', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 12048048
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 9018) % 167
    x1 = (xindex // 54) % 167
    x3 = (xindex // 1506006)
    x4 = xindex % 9018
    x6 = xindex
    tmp0 = (-1) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 165, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-1) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-8964) + x4 + (8910*x2) + (1470150*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/tj/ctjgdxyv2ofwiapacwbzhnd7wkpy43ls2qhpw2in775skvkleznr.py
# Source Nodes: [x_comb_iter_2, x_comb_iter_2_left, x_comb_iter_2_right], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_2 => add_57
# x_comb_iter_2_left => add_43, add_46, mul_56, mul_62, rsqrt_8, sub_8, var_mean_8
# x_comb_iter_2_right => add_53, add_56, mul_70, mul_76, rsqrt_10, sub_10, var_mean_10
triton_poi_fused__native_batch_norm_legit_functional_add_27 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536, 64], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32', 12: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_27', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 55112
    xnumel = 54
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 6889
    y1 = (yindex // 6889)
    tmp0 = tl.load(in_ptr0 + (x2 + (54*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x2), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x2 + (54*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x2), xmask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x2), xmask, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x2), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x2), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 55112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp13 + tmp25
    tl.store(out_ptr0 + (y0 + (6889*x2) + (1860030*y1)), tmp26, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/4d/c4dpkczk5jlk2kloyfeg62mgptkif5c4fdimgxgisbptuf2lmxfu.py
# Source Nodes: [x_60], Original ATen: [aten.relu]
# x_60 => relu_9
triton_poi_fused_relu_28 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[512, 8192], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_relu_28', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 432
    xnumel = 6889
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y0 = yindex % 54
    y1 = (yindex // 54)
    tmp0 = tl.load(in_ptr0 + (x2 + (6889*y0) + (1860030*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = triton_helpers.maximum(0, tmp0)
    tl.store(out_ptr0 + (y0 + (54*x2) + (372006*y1)), tmp1, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/at/catiqoqggspvtuj2vjdz7aiofs5kw4muobwl2tcxllw7jdzwyzww.py
# Source Nodes: [x_74], Original ATen: [aten.constant_pad_nd]
# x_74 => constant_pad_nd_7
triton_poi_fused_constant_pad_nd_29 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[33554432], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_29', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 21418752
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 16032) % 167
    x1 = (xindex // 96) % 167
    x3 = (xindex // 2677344)
    x4 = xindex % 16032
    x6 = xindex
    tmp0 = (-1) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 165, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-1) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-15936) + x4 + (15840*x2) + (2613600*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/26/c26wnur3oggiaxrdh2cfqrl5sapuc4crd2b2b4s23s3azbfx4z44.py
# Source Nodes: [x_comb_iter_1, x_comb_iter_1_left, x_comb_iter_3, x_comb_iter_3_left], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_1 => add_36
# x_comb_iter_1_left => add_32, add_35, mul_42, mul_48, rsqrt_6, sub_6, var_mean_6
# x_comb_iter_3 => add_68
# x_comb_iter_3_left => add_64, add_67, mul_84, mul_90, rsqrt_12, sub_12, var_mean_12
triton_poi_fused__native_batch_norm_legit_functional_add_30 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536, 64], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: 'i32', 14: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(13,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_30', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 55112
    xnumel = 54
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 6889
    y1 = (yindex // 6889)
    tmp0 = tl.load(in_ptr0 + (x2 + (54*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x2), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x2 + (54*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr6 + (x2 + (54*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x2), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr8 + (x2), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x2), xmask, eviction_policy='evict_last')
    tmp26 = tl.load(in_ptr10 + (x2), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 55112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp18 = tmp16 - tmp17
    tmp20 = tmp19 / tmp4
    tmp21 = tmp20 + tmp6
    tmp22 = tl.math.rsqrt(tmp21)
    tmp23 = tmp18 * tmp22
    tmp25 = tmp23 * tmp24
    tmp27 = tmp25 + tmp26
    tmp28 = tmp27 + tmp14
    tl.store(out_ptr0 + (y0 + (6889*x2) + (1860030*y1)), tmp15, xmask & ymask)
    tl.store(out_ptr1 + (y0 + (6889*x2) + (1860030*y1)), tmp28, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/2d/c2dcse6kcuioumorycxg25tq3iml3fc2q526hv4njyxfnktuna7a.py
# Source Nodes: [l__mod___cell_stem_1_conv_prev_1x1_path_1_avgpool], Original ATen: [aten.avg_pool2d]
# l__mod___cell_stem_1_conv_prev_1x1_path_1_avgpool => avg_pool2d
triton_poi_fused_avg_pool2d_31 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_avg_pool2d_31', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 5290752
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex % 96
    x1 = (xindex // 96) % 83
    x2 = (xindex // 7968) % 83
    x3 = (xindex // 661344)
    x4 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (192*x1) + (31680*x2) + (2613600*x3)), xmask)
    tmp1 = 1.0
    tmp2 = tmp0 * tmp1
    tl.store(out_ptr0 + (x4), tmp2, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/hb/chbu4kygbmuls5sbvd4u4hvqfmagidkyvysa565edb7j6wjbhebm.py
# Source Nodes: [l__mod___cell_stem_1_conv_prev_1x1_path_2_pad], Original ATen: [aten.constant_pad_nd]
# l__mod___cell_stem_1_conv_prev_1x1_path_2_pad => constant_pad_nd_9
triton_poi_fused_constant_pad_nd_32 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[33554432], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_32', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 20908800
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 15840) % 165
    x1 = (xindex // 96) % 165
    x6 = xindex
    tmp0 = 1 + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 165, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = 1 + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + (15936 + x6), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ik/cik5euqdqot755jnefhaslxbztgizb4rqonse3fj36twosbmnkov.py
# Source Nodes: [l__mod___cell_stem_1_conv_prev_1x1_path_2_avgpool], Original ATen: [aten.avg_pool2d]
# l__mod___cell_stem_1_conv_prev_1x1_path_2_avgpool => avg_pool2d_1
triton_poi_fused_avg_pool2d_33 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1024, 8192], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_avg_pool2d_33', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 768
    xnumel = 6889
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex % 83
    x3 = (xindex // 83)
    y0 = yindex % 96
    y1 = (yindex // 96)
    x4 = xindex
    tmp0 = tl.load(in_ptr0 + (y0 + (192*x2) + (31680*x3) + (2613600*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = 1.0
    tmp2 = tmp0 * tmp1
    tl.store(out_ptr0 + (y0 + (96*x4) + (661344*y1)), tmp2, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/mz/cmzhc6ntk65jq2y3h22uhwyom6snrlbrjjuvqodvbed5jsuqnuzb.py
# Source Nodes: [cat_34], Original ATen: [aten.cat]
# cat_34 => cat_1
triton_poi_fused_cat_34 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1024, 8192], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32', 4: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_34', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 864
    xnumel = 6889
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    y0 = yindex % 108
    x2 = xindex
    y1 = (yindex // 108)
    tmp0 = y0
    tmp1 = tl.full([1, 1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1, 1], 54, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = tl.load(in_ptr0 + (x2 + (6889*y0) + (372006*y1)), tmp4 & xmask & ymask, eviction_policy='evict_last', other=0.0)
    tmp6 = tl.full(tmp5.shape, 0.0, tmp5.dtype)
    tmp7 = tl.where(tmp4, tmp5, tmp6)
    tmp8 = tmp0 >= tmp3
    tmp9 = tl.full([1, 1], 108, tl.int64)
    tmp10 = tmp0 < tmp9
    tmp11 = tl.load(in_ptr1 + ((-372006) + x2 + (6889*y0) + (372006*y1)), tmp8 & xmask & ymask, eviction_policy='evict_last', other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp8, tmp11, tmp12)
    tmp14 = tl.where(tmp4, tmp7, tmp13)
    tl.store(out_ptr0 + (y0 + (108*x2) + (744012*y1)), tmp14, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/kj/ckjr62cxps4iusj3ej5ftvaxfnt5ovsmzryfaaujipihrgwqmx4r.py
# Source Nodes: [x_left], Original ATen: [aten._native_batch_norm_legit_functional]
# x_left => var_mean_16
triton_red_fused__native_batch_norm_legit_functional_35 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[65536, 128],
    reduction_hint=ReductionHint.OUTER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_35', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 46548
    rnumel = 128
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x1 = (xindex // 108)
    x0 = xindex % 108
    tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    x3 = xindex
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = r2 + (128*x1)
        tmp1 = tl.full([1, 1], 55112, tl.int32)
        tmp2 = tmp0 < tmp1
        tmp3 = tl.load(in_ptr0 + (x0 + (108*((r2 + (128*x1)) % 55112))), rmask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
        tmp5 = tl.where(tmp2, tmp3, tmp4)
        tmp6 = 0.0
        tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
        tmp8 = tl.where(tmp2, tmp6, tmp7)
        tmp9 = 1.0
        tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
        tmp11 = tl.where(tmp2, tmp9, tmp10)
        tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
        tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
        tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
            tmp15_mean, tmp15_m2, tmp15_weight,
            tmp12, tmp13, tmp14
        )
        tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
        tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
        tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
    tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
        tmp15_mean, tmp15_m2, tmp15_weight, 1
    )
    tmp15 = tmp15_tmp[:, None]
    tmp16 = tmp16_tmp[:, None]
    tmp17 = tmp17_tmp[:, None]
    tl.store(out_ptr0 + (x3), tmp15, xmask)
    tl.store(out_ptr1 + (x3), tmp16, xmask)
    tl.store(out_ptr2 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/r4/cr4zkcbf2f4pd6rhnwmo6qofeplgchscyhkfverar6g2ikppaute.py
# Source Nodes: [x_left], Original ATen: [aten._native_batch_norm_legit_functional]
# x_left => var_mean_16
triton_red_fused__native_batch_norm_legit_functional_36 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[512, 128],
    reduction_hint=ReductionHint.OUTER_TINY,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_36', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 432
    rnumel = 108
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 4
    x1 = (xindex // 4)
    tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = r2 + (108*x0)
        tmp1 = tl.full([1, 1], 431, tl.int32)
        tmp2 = tmp0 < tmp1
        tmp3 = tl.load(in_ptr0 + (x1 + (108*r2) + (11664*x0)), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
        tmp5 = tl.where(tmp2, tmp3, tmp4)
        tmp6 = tl.load(in_ptr1 + (x1 + (108*r2) + (11664*x0)), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
        tmp8 = tl.where(tmp2, tmp6, tmp7)
        tmp9 = tl.load(in_ptr2 + (x1 + (108*r2) + (11664*x0)), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
        tmp11 = tl.where(tmp2, tmp9, tmp10)
        tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
        tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
        tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
            tmp15_mean, tmp15_m2, tmp15_weight,
            tmp12, tmp13, tmp14
        )
        tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
        tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
        tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
    tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
        tmp15_mean, tmp15_m2, tmp15_weight, 1
    )
    tmp15 = tmp15_tmp[:, None]
    tmp16 = tmp16_tmp[:, None]
    tmp17 = tmp17_tmp[:, None]
    tl.store(out_ptr0 + (x1 + (108*x0)), tmp15, xmask)
    tl.store(out_ptr1 + (x1 + (108*x0)), tmp16, xmask)
    tl.store(out_ptr2 + (x1 + (108*x0)), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/wn/cwnexd6c22eczijct4rc5zezqadrxllejs44r64ph2tg4fajhr5y.py
# Source Nodes: [x_left], Original ATen: [aten._native_batch_norm_legit_functional]
# x_left => add_86, add_87, add_88, mul_113, mul_114, mul_115, mul_116, mul_117, rsqrt_16, squeeze_49, var_mean_16
triton_per_fused__native_batch_norm_legit_functional_37 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[128, 4],
    reduction_hint=ReductionHint.OUTER_TINY,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_37', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 108
    rnumel = 4
    RBLOCK: tl.constexpr = 4
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (108*r1)), rmask & xmask, other=0.0)
    tmp1 = tl.load(in_ptr1 + (x0 + (108*r1)), rmask & xmask, other=0.0)
    tmp2 = tl.load(in_ptr2 + (x0 + (108*r1)), rmask & xmask, other=0.0)
    tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
    tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
    tmp7 = tl.where(rmask & xmask, tmp3, 0)
    tmp8 = tl.where(rmask & xmask, tmp4, 0)
    tmp9 = tl.where(rmask & xmask, tmp5, 0)
    tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
    tmp13 = tmp10[:, None]
    tmp14 = tmp11[:, None]
    tmp15 = tmp12[:, None]
    tmp16 = 55112.0
    tmp17 = tmp14 / tmp16
    tmp18 = 0.001
    tmp19 = tmp17 + tmp18
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = 0.1
    tmp22 = tmp13 * tmp21
    tmp24 = 0.9
    tmp25 = tmp23 * tmp24
    tmp26 = tmp22 + tmp25
    tmp27 = 1.0000181451978734
    tmp28 = tmp17 * tmp27
    tmp29 = tmp28 * tmp21
    tmp31 = tmp30 * tmp24
    tmp32 = tmp29 + tmp31
    tl.store(out_ptr2 + (x0), tmp20, xmask)
    tl.store(out_ptr4 + (x0), tmp26, xmask)
    tl.store(out_ptr6 + (x0), tmp32, xmask)
    tl.store(out_ptr0 + (x0), tmp13, xmask)
    tl.store(out_ptr1 + (x0), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/xm/cxm2hf4vm3wx7rq7prexl53f5cd3monm6q3mhmn2jwiritgj3e4b.py
# Source Nodes: [x_93, x_left], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu, aten.threshold_backward]
# x_93 => relu_16
# x_left => add_86, add_89, mul_112, mul_118, rsqrt_16, sub_16, var_mean_16
triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_38 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*i1', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_38', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 5952096
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = xindex
    x0 = xindex % 108
    tmp0 = tl.load(in_ptr0 + (x2), xmask)
    tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 55112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tmp15 = 0.0
    tmp16 = tmp14 <= tmp15
    tl.store(out_ptr0 + (x2), tmp13, xmask)
    tl.store(out_ptr1 + (x2), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/6j/c6jhoxa3fx2cu4b34o34segqn65hh3dw72nfnqjx475w4d73yybc.py
# Source Nodes: [x_90], Original ATen: [aten.relu]
# x_90 => relu_15
triton_poi_fused_relu_39 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4096, 8192], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_relu_39', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 2160
    xnumel = 6889
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 270
    y1 = (yindex // 270)
    tmp0 = tl.load(in_ptr0 + (x2 + (6889*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = triton_helpers.maximum(0, tmp0)
    tl.store(out_ptr0 + (y0 + (270*x2) + (1860030*y1)), tmp1, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/k7/ck7vcabfid7of7ouvwlkvnasmj3webqmd4kgzfxaggq3bcfreip7.py
# Source Nodes: [x_91], Original ATen: [aten.convolution]
# x_91 => convolution_30
triton_poi_fused_convolution_40 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1024, 8192], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_40', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 864
    xnumel = 6889
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 108
    y1 = (yindex // 108)
    tmp0 = tl.load(in_ptr0 + (x2 + (6889*y3)), xmask & ymask, eviction_policy='evict_last')
    tl.store(out_ptr0 + (y0 + (108*x2) + (744012*y1)), tmp0, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/gn/cgnw4unebqpmokxmfitjj2x5erhliwgrb4e5f7fqakinwpvpjxrj.py
# Source Nodes: [x_107, x_right_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu, aten.threshold_backward]
# x_107 => relu_18
# x_right_1 => add_91, add_94, mul_119, mul_125, rsqrt_17, sub_17, var_mean_17
triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_41 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*i1', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_41', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, xnumel, XBLOCK : tl.constexpr):
    xnumel = 5952096
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = xindex
    x0 = xindex % 108
    tmp0 = tl.load(in_ptr0 + (x2), xmask)
    tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 55112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tmp15 = 0.0
    tmp16 = tmp14 <= tmp15
    tl.store(out_ptr0 + (x2), tmp13, xmask)
    tl.store(out_ptr1 + (x2), tmp14, xmask)
    tl.store(out_ptr2 + (x2), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/yq/cyq3lsjddrmg3oinqzwwbp7xcf6slugxbf6eqsgwig6pc3lpyame.py
# Source Nodes: [x_93, x_95], Original ATen: [aten.constant_pad_nd, aten.relu]
# x_93 => relu_16
# x_95 => constant_pad_nd_10
triton_poi_fused_constant_pad_nd_relu_42 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_relu_42', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6539616
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 9396) % 87
    x1 = (xindex // 108) % 87
    x3 = (xindex // 817452)
    x4 = xindex % 9396
    x6 = xindex
    tmp0 = (-2) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 83, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-2) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-18144) + x4 + (8964*x2) + (744012*x3)), tmp10 & xmask, other=0.0)
    tmp12 = triton_helpers.maximum(0, tmp11)
    tmp13 = tl.full(tmp12.shape, 0.0, tmp12.dtype)
    tmp14 = tl.where(tmp10, tmp12, tmp13)
    tl.store(out_ptr0 + (x6), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/xi/cxiokz6vzulcs3rbli65cwjynfjychdz5y5ti4mbpio4kfjoxmlq.py
# Source Nodes: [x_96], Original ATen: [aten.convolution]
# x_96 => convolution_31
triton_poi_fused_convolution_43 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1024, 2048], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_43', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 864
    xnumel = 1764
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 108
    y1 = (yindex // 108)
    tmp0 = tl.load(in_ptr0 + (x2 + (1764*y3)), xmask & ymask, eviction_policy='evict_last')
    tl.store(out_ptr0 + (y0 + (108*x2) + (190512*y1)), tmp0, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/es/cesvqmsmziudno7sijx3fypowr3gxlah4xoiqfoupte2n7s73qxd.py
# Source Nodes: [x_99], Original ATen: [aten._native_batch_norm_legit_functional]
# x_99 => var_mean_18
triton_red_fused__native_batch_norm_legit_functional_44 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[16384, 128],
    reduction_hint=ReductionHint.OUTER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_44', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 11988
    rnumel = 128
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x1 = (xindex // 108)
    x0 = xindex % 108
    tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    x3 = xindex
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = r2 + (128*x1)
        tmp1 = tl.full([1, 1], 14112, tl.int32)
        tmp2 = tmp0 < tmp1
        tmp3 = tl.load(in_ptr0 + (x0 + (108*((r2 + (128*x1)) % 14112))), rmask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
        tmp5 = tl.where(tmp2, tmp3, tmp4)
        tmp6 = 0.0
        tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
        tmp8 = tl.where(tmp2, tmp6, tmp7)
        tmp9 = 1.0
        tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
        tmp11 = tl.where(tmp2, tmp9, tmp10)
        tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
        tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
        tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
            tmp15_mean, tmp15_m2, tmp15_weight,
            tmp12, tmp13, tmp14
        )
        tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
        tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
        tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
    tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
        tmp15_mean, tmp15_m2, tmp15_weight, 1
    )
    tmp15 = tmp15_tmp[:, None]
    tmp16 = tmp16_tmp[:, None]
    tmp17 = tmp17_tmp[:, None]
    tl.store(out_ptr0 + (x3), tmp15, xmask)
    tl.store(out_ptr1 + (x3), tmp16, xmask)
    tl.store(out_ptr2 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ki/ckivxrzyislsg4tvjkhoallbr3pgee23pmtsevc5fnq6ikhtbodc.py
# Source Nodes: [x_99], Original ATen: [aten._native_batch_norm_legit_functional]
# x_99 => add_96, add_97, add_98, mul_127, mul_128, mul_129, mul_130, mul_131, rsqrt_18, squeeze_55, var_mean_18
triton_red_fused__native_batch_norm_legit_functional_45 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 128],
    reduction_hint=ReductionHint.OUTER_TINY,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_45', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 108
    rnumel = 111
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex
        tmp0 = tl.load(in_ptr0 + (x0 + (108*r1)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.load(in_ptr1 + (x0 + (108*r1)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp2 = tl.load(in_ptr2 + (x0 + (108*r1)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
        tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
        tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
            tmp6_mean, tmp6_m2, tmp6_weight,
            tmp3, tmp4, tmp5
        )
        tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
        tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
        tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
    tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
        tmp6_mean, tmp6_m2, tmp6_weight, 1
    )
    tmp6 = tmp6_tmp[:, None]
    tmp7 = tmp7_tmp[:, None]
    tmp8 = tmp8_tmp[:, None]
    tl.store(out_ptr0 + (x0), tmp6, xmask)
    tl.store(out_ptr1 + (x0), tmp7, xmask)
    tmp16 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp23 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp9 = 14112.0
    tmp10 = tmp7 / tmp9
    tmp11 = 0.001
    tmp12 = tmp10 + tmp11
    tmp13 = tl.math.rsqrt(tmp12)
    tmp14 = 0.1
    tmp15 = tmp6 * tmp14
    tmp17 = 0.9
    tmp18 = tmp16 * tmp17
    tmp19 = tmp15 + tmp18
    tmp20 = 1.0000708666997378
    tmp21 = tmp10 * tmp20
    tmp22 = tmp21 * tmp14
    tmp24 = tmp23 * tmp17
    tmp25 = tmp22 + tmp24
    tl.store(out_ptr2 + (x0), tmp13, xmask)
    tl.store(out_ptr4 + (x0), tmp19, xmask)
    tl.store(out_ptr6 + (x0), tmp25, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/3u/c3ujmty2wvxpbtm4mjv6bh236i6crz4d7pxwwhgowfjcwakd3yyg.py
# Source Nodes: [x_100, x_99], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# x_100 => relu_17
# x_99 => add_96, add_99, mul_126, mul_132, rsqrt_18, sub_18, var_mean_18
triton_poi_fused__native_batch_norm_legit_functional_relu_46 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2097152], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_46', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 1524096
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = xindex
    x0 = xindex % 108
    tmp0 = tl.load(in_ptr0 + (x2), xmask)
    tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 14112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x2), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/gd/cgdlcd5bs3mzdl6oggkonf4w65qb7qb53adhupy756bbxluh3kq4.py
# Source Nodes: [x_106], Original ATen: [aten.constant_pad_nd]
# x_106 => constant_pad_nd_11
triton_poi_fused_constant_pad_nd_47 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_47', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6242400
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 9180) % 85
    x1 = (xindex // 108) % 85
    x3 = (xindex // 780300)
    x4 = xindex % 9180
    x6 = xindex
    tmp0 = (-1) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 83, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-1) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-9072) + x4 + (8964*x2) + (744012*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, float("-inf"), tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/pi/cpiz52slodwop62dfmoyoahwsufk5zg5youqzkzkfrj4y6oryzvu.py
# Source Nodes: [x_comb_iter_0_right_1], Original ATen: [aten.max_pool2d_with_indices]
# x_comb_iter_0_right_1 => getitem_47, max_pool2d_with_indices_3
triton_poi_fused_max_pool2d_with_indices_48 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1024, 2048], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*i64', 3: 'i32', 4: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_48', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 864
    xnumel = 1764
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex % 42
    x3 = (xindex // 42)
    y0 = yindex % 108
    y1 = (yindex // 108)
    x4 = xindex
    tmp0 = tl.load(in_ptr0 + (y0 + (216*x2) + (18360*x3) + (780300*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr0 + (108 + y0 + (216*x2) + (18360*x3) + (780300*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr0 + (216 + y0 + (216*x2) + (18360*x3) + (780300*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp5 = tl.load(in_ptr0 + (9180 + y0 + (216*x2) + (18360*x3) + (780300*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr0 + (9288 + y0 + (216*x2) + (18360*x3) + (780300*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp9 = tl.load(in_ptr0 + (9396 + y0 + (216*x2) + (18360*x3) + (780300*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr0 + (18360 + y0 + (216*x2) + (18360*x3) + (780300*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr0 + (18468 + y0 + (216*x2) + (18360*x3) + (780300*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr0 + (18576 + y0 + (216*x2) + (18360*x3) + (780300*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp2 = triton_helpers.maximum(tmp1, tmp0)
    tmp4 = triton_helpers.maximum(tmp3, tmp2)
    tmp6 = triton_helpers.maximum(tmp5, tmp4)
    tmp8 = triton_helpers.maximum(tmp7, tmp6)
    tmp10 = triton_helpers.maximum(tmp9, tmp8)
    tmp12 = triton_helpers.maximum(tmp11, tmp10)
    tmp14 = triton_helpers.maximum(tmp13, tmp12)
    tmp16 = triton_helpers.maximum(tmp15, tmp14)
    tmp17 = tmp1 > tmp0
    tmp18 = 1 + (2*x2) + (170*x3)
    tmp19 = (2*x2) + (170*x3)
    tmp20 = tl.where(tmp17, tmp18, tmp19)
    tmp21 = tmp3 > tmp2
    tmp22 = 2 + (2*x2) + (170*x3)
    tmp23 = tl.where(tmp21, tmp22, tmp20)
    tmp24 = tmp5 > tmp4
    tmp25 = 85 + (2*x2) + (170*x3)
    tmp26 = tl.where(tmp24, tmp25, tmp23)
    tmp27 = tmp7 > tmp6
    tmp28 = 86 + (2*x2) + (170*x3)
    tmp29 = tl.where(tmp27, tmp28, tmp26)
    tmp30 = tmp9 > tmp8
    tmp31 = 87 + (2*x2) + (170*x3)
    tmp32 = tl.where(tmp30, tmp31, tmp29)
    tmp33 = tmp11 > tmp10
    tmp34 = 170 + (2*x2) + (170*x3)
    tmp35 = tl.where(tmp33, tmp34, tmp32)
    tmp36 = tmp13 > tmp12
    tmp37 = 171 + (2*x2) + (170*x3)
    tmp38 = tl.where(tmp36, tmp37, tmp35)
    tmp39 = tmp15 > tmp14
    tmp40 = 172 + (2*x2) + (170*x3)
    tmp41 = tl.where(tmp39, tmp40, tmp38)
    tl.store(out_ptr0 + (y0 + (108*x4) + (190512*y1)), tmp16, xmask & ymask)
    tl.store(out_ptr1 + (y0 + (108*x4) + (190512*y1)), tmp41, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/6j/c6jk4l33yuscbpqlmxdkzgyhegpytgdvyrndjc6jxybwxlaap4sj.py
# Source Nodes: [x_109], Original ATen: [aten.constant_pad_nd]
# x_109 => constant_pad_nd_12
triton_poi_fused_constant_pad_nd_49 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_49', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6843744
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 9612) % 89
    x1 = (xindex // 108) % 89
    x3 = (xindex // 855468)
    x4 = xindex % 9612
    x6 = xindex
    tmp0 = (-3) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 83, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-3) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-27216) + x4 + (8964*x2) + (744012*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/s5/cs5u7snee4jz55m7nfhlljkyh4zefw5fqczgcses2l3fs57zg7yi.py
# Source Nodes: [x_123], Original ATen: [aten.constant_pad_nd]
# x_123 => constant_pad_nd_14
triton_poi_fused_constant_pad_nd_50 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_50', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6539616
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 9396) % 87
    x1 = (xindex // 108) % 87
    x3 = (xindex // 817452)
    x4 = xindex % 9396
    x6 = xindex
    tmp0 = (-2) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 83, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-2) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-18144) + x4 + (8964*x2) + (744012*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/44/c44esgpawr3dnltjl6qucdbb3kzv5n67p53zhrm7bwkrkrp2jcoq.py
# Source Nodes: [x_135], Original ATen: [aten.constant_pad_nd]
# x_135 => constant_pad_nd_15
triton_poi_fused_constant_pad_nd_51 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_51', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6242400
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 9180) % 85
    x1 = (xindex // 108) % 85
    x3 = (xindex // 780300)
    x4 = xindex % 9180
    x6 = xindex
    tmp0 = (-1) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 83, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-1) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-9072) + x4 + (8964*x2) + (744012*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/pp/cppr22w6brs7j2l2by2rqfbvmodcf3a5ul3qmafhirrbs45dejhp.py
# Source Nodes: [x_comb_iter_2_left_1, x_comb_iter_2_right_1, x_comb_iter_7], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_2_left_1 => add_123, add_126, mul_161, mul_167, rsqrt_23, sub_23, var_mean_23
# x_comb_iter_2_right_1 => add_133, add_136, mul_175, mul_181, rsqrt_25, sub_25, var_mean_25
# x_comb_iter_7 => add_137
triton_poi_fused__native_batch_norm_legit_functional_add_52 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16384, 128], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32', 12: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_52', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 14112
    xnumel = 108
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 1764
    y1 = (yindex // 1764)
    tmp0 = tl.load(in_ptr0 + (x2 + (108*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x2), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x2 + (108*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x2), xmask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x2), xmask, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x2), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x2), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 14112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp13 + tmp25
    tl.store(out_ptr0 + (y0 + (1764*x2) + (952560*y1)), tmp26, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/qb/cqbpe3xx72qvpyhh4asitd7yydegwfzdfwmuh2z32hocueyx5jx4.py
# Source Nodes: [x_145], Original ATen: [aten.relu]
# x_145 => relu_24
triton_poi_fused_relu_53 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1024, 2048], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_relu_53', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 864
    xnumel = 1764
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y0 = yindex % 108
    y1 = (yindex // 108)
    tmp0 = tl.load(in_ptr0 + (x2 + (1764*y0) + (952560*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = triton_helpers.maximum(0, tmp0)
    tl.store(out_ptr0 + (y0 + (108*x2) + (190512*y1)), tmp1, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/rg/crgo7pumxqns5sjz7u7kenrquowkxq4ham6zqsec2eaztznth5mb.py
# Source Nodes: [x_159, x_93], Original ATen: [aten.constant_pad_nd, aten.relu]
# x_159 => constant_pad_nd_17
# x_93 => relu_16
triton_poi_fused_constant_pad_nd_relu_54 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_relu_54', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6242400
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 9180) % 85
    x1 = (xindex // 108) % 85
    x3 = (xindex // 780300)
    x4 = xindex % 9180
    x6 = xindex
    tmp0 = (-1) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 83, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-1) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-9072) + x4 + (8964*x2) + (744012*x3)), tmp10 & xmask, other=0.0)
    tmp12 = triton_helpers.maximum(0, tmp11)
    tmp13 = tl.full(tmp12.shape, 0.0, tmp12.dtype)
    tmp14 = tl.where(tmp10, tmp12, tmp13)
    tl.store(out_ptr0 + (x6), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/t4/ct4wg7jwyn3fi5ny3xorf46zfme3nyd655hdu742hszos3xo3sff.py
# Source Nodes: [x_comb_iter_0_left_1, x_comb_iter_5], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_0_left_1 => add_101, add_104, mul_133, mul_139, rsqrt_19, sub_19, var_mean_19
# x_comb_iter_5 => add_105
triton_poi_fused__native_batch_norm_legit_functional_add_55 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16384, 128], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_55', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 14112
    xnumel = 108
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 1764
    y1 = (yindex // 1764)
    tmp0 = tl.load(in_ptr0 + (x2 + (108*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x2), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x2 + (108*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 14112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tl.store(out_ptr0 + (y0 + (1764*x2) + (952560*y1)), tmp15, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/rp/crpefrmjrocitnpvule2kovbzci276dzbggzgc7t7elpqi4ghqjy.py
# Source Nodes: [x_comb_iter_1_left_1, x_comb_iter_3_left_1, x_comb_iter_6, x_comb_iter_8], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_1_left_1 => add_112, add_115, mul_147, mul_153, rsqrt_21, sub_21, var_mean_21
# x_comb_iter_3_left_1 => add_144, add_147, mul_189, mul_195, rsqrt_27, sub_27, var_mean_27
# x_comb_iter_6 => add_116
# x_comb_iter_8 => add_148
triton_poi_fused__native_batch_norm_legit_functional_add_56 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16384, 128], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: 'i32', 14: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(13,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_56', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 14112
    xnumel = 108
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 1764
    y1 = (yindex // 1764)
    tmp0 = tl.load(in_ptr0 + (x2 + (108*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x2), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x2 + (108*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr6 + (x2 + (108*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x2), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr8 + (x2), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x2), xmask, eviction_policy='evict_last')
    tmp26 = tl.load(in_ptr10 + (x2), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 14112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp18 = tmp16 - tmp17
    tmp20 = tmp19 / tmp4
    tmp21 = tmp20 + tmp6
    tmp22 = tl.math.rsqrt(tmp21)
    tmp23 = tmp18 * tmp22
    tmp25 = tmp23 * tmp24
    tmp27 = tmp25 + tmp26
    tmp28 = tmp27 + tmp14
    tl.store(out_ptr0 + (y0 + (1764*x2) + (952560*y1)), tmp15, xmask & ymask)
    tl.store(out_ptr1 + (y0 + (1764*x2) + (952560*y1)), tmp28, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/5a/c5ag2rlroo7bplb5ria3aynivxzb2qdraiduhiudfbb3z7murja6.py
# Source Nodes: [l__mod___cell_0_conv_prev_1x1_path_1_avgpool], Original ATen: [aten.avg_pool2d]
# l__mod___cell_0_conv_prev_1x1_path_1_avgpool => avg_pool2d_2
triton_poi_fused_avg_pool2d_57 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4194304], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_avg_pool2d_57', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 3810240
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex % 270
    x1 = (xindex // 270) % 42
    x2 = (xindex // 11340) % 42
    x3 = (xindex // 476280)
    x4 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (540*x1) + (44820*x2) + (1860030*x3)), xmask)
    tmp1 = 1.0
    tmp2 = tmp0 * tmp1
    tl.store(out_ptr0 + (x4), tmp2, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/w2/cw2eaxugkh655c6wa4y42rqwyvqz2k7dxyoyf3z2jdpobohcipss.py
# Source Nodes: [l__mod___cell_0_conv_prev_1x1_path_2_pad], Original ATen: [aten.constant_pad_nd]
# l__mod___cell_0_conv_prev_1x1_path_2_pad => constant_pad_nd_19
triton_poi_fused_constant_pad_nd_58 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16777216], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_58', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 14880240
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 22410) % 83
    x1 = (xindex // 270) % 83
    x6 = xindex
    tmp0 = 1 + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 83, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = 1 + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + (22680 + x6), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/uw/cuwma66bijawxqzlau5pyrb33owgbzvvhq4jurbwbkcpcubyesa6.py
# Source Nodes: [l__mod___cell_0_conv_prev_1x1_path_2_avgpool], Original ATen: [aten.avg_pool2d]
# l__mod___cell_0_conv_prev_1x1_path_2_avgpool => avg_pool2d_3
triton_poi_fused_avg_pool2d_59 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4096, 2048], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_avg_pool2d_59', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 2160
    xnumel = 1764
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex % 42
    x3 = (xindex // 42)
    y0 = yindex % 270
    y1 = (yindex // 270)
    x4 = xindex
    tmp0 = tl.load(in_ptr0 + (y0 + (540*x2) + (44820*x3) + (1860030*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = 1.0
    tmp2 = tmp0 * tmp1
    tl.store(out_ptr0 + (y0 + (270*x4) + (476280*y1)), tmp2, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/hz/chzmniibjjueirxjwbdop4sumaogkxv72a5mycjdtaszaviwm7hw.py
# Source Nodes: [cat_32], Original ATen: [aten.cat]
# cat_32 => cat_3
triton_poi_fused_cat_60 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2048, 2048], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32', 4: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_60', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 1728
    xnumel = 1764
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    y0 = yindex % 216
    x2 = xindex
    y1 = (yindex // 216)
    tmp0 = y0
    tmp1 = tl.full([1, 1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1, 1], 108, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = tl.load(in_ptr0 + (x2 + (1764*y0) + (190512*y1)), tmp4 & xmask & ymask, eviction_policy='evict_last', other=0.0)
    tmp6 = tl.full(tmp5.shape, 0.0, tmp5.dtype)
    tmp7 = tl.where(tmp4, tmp5, tmp6)
    tmp8 = tmp0 >= tmp3
    tmp9 = tl.full([1, 1], 216, tl.int64)
    tmp10 = tmp0 < tmp9
    tmp11 = tl.load(in_ptr1 + ((-190512) + x2 + (1764*y0) + (190512*y1)), tmp8 & xmask & ymask, eviction_policy='evict_last', other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp8, tmp11, tmp12)
    tmp14 = tl.where(tmp4, tmp7, tmp13)
    tl.store(out_ptr0 + (y0 + (216*x2) + (381024*y1)), tmp14, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/cl/ccltwheoas3tukcrjpsfxma74ywdziolygj7u257v224nchpdnjg.py
# Source Nodes: [x_left_1], Original ATen: [aten._native_batch_norm_legit_functional]
# x_left_1 => var_mean_31
triton_red_fused__native_batch_norm_legit_functional_61 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[32768, 128],
    reduction_hint=ReductionHint.OUTER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_61', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 23976
    rnumel = 128
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x1 = (xindex // 216)
    x0 = xindex % 216
    tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    x3 = xindex
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = r2 + (128*x1)
        tmp1 = tl.full([1, 1], 14112, tl.int32)
        tmp2 = tmp0 < tmp1
        tmp3 = tl.load(in_ptr0 + (x0 + (216*((r2 + (128*x1)) % 14112))), rmask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
        tmp5 = tl.where(tmp2, tmp3, tmp4)
        tmp6 = 0.0
        tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
        tmp8 = tl.where(tmp2, tmp6, tmp7)
        tmp9 = 1.0
        tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
        tmp11 = tl.where(tmp2, tmp9, tmp10)
        tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
        tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
        tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
            tmp15_mean, tmp15_m2, tmp15_weight,
            tmp12, tmp13, tmp14
        )
        tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
        tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
        tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
    tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
        tmp15_mean, tmp15_m2, tmp15_weight, 1
    )
    tmp15 = tmp15_tmp[:, None]
    tmp16 = tmp16_tmp[:, None]
    tmp17 = tmp17_tmp[:, None]
    tl.store(out_ptr0 + (x3), tmp15, xmask)
    tl.store(out_ptr1 + (x3), tmp16, xmask)
    tl.store(out_ptr2 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/or/coryf2npgtllwtqlgiquypc7hyynvfuiucnjcfedjlrad7rfik43.py
# Source Nodes: [x_left_1], Original ATen: [aten._native_batch_norm_legit_functional]
# x_left_1 => add_166, add_167, add_168, mul_218, mul_219, mul_220, mul_221, mul_222, rsqrt_31, squeeze_94, var_mean_31
triton_red_fused__native_batch_norm_legit_functional_62 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[256, 128],
    reduction_hint=ReductionHint.OUTER_TINY,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_62', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 216
    rnumel = 111
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex
        tmp0 = tl.load(in_ptr0 + (x0 + (216*r1)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.load(in_ptr1 + (x0 + (216*r1)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp2 = tl.load(in_ptr2 + (x0 + (216*r1)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
        tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
        tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
            tmp6_mean, tmp6_m2, tmp6_weight,
            tmp3, tmp4, tmp5
        )
        tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
        tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
        tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
    tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
        tmp6_mean, tmp6_m2, tmp6_weight, 1
    )
    tmp6 = tmp6_tmp[:, None]
    tmp7 = tmp7_tmp[:, None]
    tmp8 = tmp8_tmp[:, None]
    tl.store(out_ptr0 + (x0), tmp6, xmask)
    tl.store(out_ptr1 + (x0), tmp7, xmask)
    tmp16 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp23 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp9 = 14112.0
    tmp10 = tmp7 / tmp9
    tmp11 = 0.001
    tmp12 = tmp10 + tmp11
    tmp13 = tl.math.rsqrt(tmp12)
    tmp14 = 0.1
    tmp15 = tmp6 * tmp14
    tmp17 = 0.9
    tmp18 = tmp16 * tmp17
    tmp19 = tmp15 + tmp18
    tmp20 = 1.0000708666997378
    tmp21 = tmp10 * tmp20
    tmp22 = tmp21 * tmp14
    tmp24 = tmp23 * tmp17
    tmp25 = tmp22 + tmp24
    tl.store(out_ptr2 + (x0), tmp13, xmask)
    tl.store(out_ptr4 + (x0), tmp19, xmask)
    tl.store(out_ptr6 + (x0), tmp25, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/yz/cyzfbuwwcqlx2sq3hq3xefpqrvetk55dj2ptwejqx6ts6jlaryvb.py
# Source Nodes: [x_178, x_left_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# x_178 => relu_31
# x_left_1 => add_166, add_169, mul_217, mul_223, rsqrt_31, sub_31, var_mean_31
triton_poi_fused__native_batch_norm_legit_functional_relu_63 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4194304], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_63', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 3048192
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = xindex
    x0 = xindex % 216
    tmp0 = tl.load(in_ptr0 + (x2), xmask)
    tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 14112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x2), tmp13, xmask)
    tl.store(out_ptr1 + (x2), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/d7/cd7aylj6k7m7x2uy4k7zymaapblx3pm2vpjmc3i3z2amfzod5nwv.py
# Source Nodes: [x_175], Original ATen: [aten.relu]
# x_175 => relu_30
triton_poi_fused_relu_64 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8192, 2048], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_relu_64', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 4320
    xnumel = 1764
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 540
    y1 = (yindex // 540)
    tmp0 = tl.load(in_ptr0 + (x2 + (1764*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = triton_helpers.maximum(0, tmp0)
    tl.store(out_ptr0 + (y0 + (540*x2) + (952560*y1)), tmp1, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/xy/cxy3ixrhzcbrdm7czphiqkfl5lfvutyo7yi2vpucaesxem3wtvtb.py
# Source Nodes: [x_176], Original ATen: [aten.convolution]
# x_176 => convolution_58
triton_poi_fused_convolution_65 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2048, 2048], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_65', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 1728
    xnumel = 1764
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 216
    y1 = (yindex // 216)
    tmp0 = tl.load(in_ptr0 + (x2 + (1764*y3)), xmask & ymask, eviction_policy='evict_last')
    tl.store(out_ptr0 + (y0 + (216*x2) + (381024*y1)), tmp0, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ta/ctasijchacnc45es3pgf4xuylkxzvrrkstlmdyxt5ug3a7ze7ynm.py
# Source Nodes: [x_232, x_233], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# x_232 => add_230, add_233, mul_301, mul_307, rsqrt_43, sub_43, var_mean_43
# x_233 => relu_42
triton_poi_fused__native_batch_norm_legit_functional_relu_66 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4194304], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_66', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 3048192
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = xindex
    x0 = xindex % 216
    tmp0 = tl.load(in_ptr0 + (x2), xmask)
    tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 14112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x2), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/2d/c2dbemlc7yw3jpw3og4nndzgeg734ykjvf2unmahdmklsgbjr5ke.py
# Source Nodes: [x_comb_iter_14, x_comb_iter_4_left_2, x_comb_iter_4_right_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_14 => add_239
# x_comb_iter_4_left_2 => add_235, add_238, mul_308, mul_314, rsqrt_44, sub_44, var_mean_44
# x_comb_iter_4_right_2 => add_171, add_174, mul_224, mul_230, rsqrt_32, sub_32, var_mean_32
triton_poi_fused__native_batch_norm_legit_functional_add_67 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16384, 256], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: 'i32', 13: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(12, 13))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_67', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 14112
    xnumel = 216
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x1 = xindex
    y0 = yindex
    y2 = yindex % 1764
    y3 = (yindex // 1764)
    tmp0 = tl.load(in_ptr0 + (x1 + (216*y0)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x1 + (216*y0)), xmask & ymask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x1), xmask, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x1), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 14112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp25 + tmp13
    tl.store(out_ptr0 + (x1 + (216*y0)), tmp13, xmask & ymask)
    tl.store(out_ptr1 + (y2 + (1764*x1) + (1905120*y3)), tmp26, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/f5/cf5wqthvgxoefhfhsasgh4usyq4oneukfb3y5xdxvqc4m6quf7f3.py
# Source Nodes: [x_comb_iter_0_right_2], Original ATen: [aten.max_pool2d_with_indices]
# x_comb_iter_0_right_2 => getitem_83, max_pool2d_with_indices_6
triton_poi_fused_max_pool2d_with_indices_68 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4194304], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*i64', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_68', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 3048192
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 9072) % 42
    x1 = (xindex // 216) % 42
    x6 = xindex
    x7 = (xindex // 216) % 1764
    tmp0 = (-1) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 42, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = tmp2 & tmp4
    tmp6 = (-1) + x1
    tmp7 = tmp6 >= tmp1
    tmp8 = tmp6 < tmp3
    tmp9 = tmp7 & tmp8
    tmp10 = tmp5 & tmp9
    tmp11 = tl.load(in_ptr0 + ((-9288) + x6), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, float("-inf"), tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tmp14 = x1
    tmp15 = tmp14 >= tmp1
    tmp16 = tmp14 < tmp3
    tmp17 = tmp15 & tmp16
    tmp18 = tmp5 & tmp17
    tmp19 = tl.load(in_ptr0 + ((-9072) + x6), tmp18 & xmask, other=0.0)
    tmp20 = tl.full(tmp19.shape, float("-inf"), tmp19.dtype)
    tmp21 = tl.where(tmp18, tmp19, tmp20)
    tmp22 = triton_helpers.maximum(tmp21, tmp13)
    tmp23 = 1 + x1
    tmp24 = tmp23 >= tmp1
    tmp25 = tmp23 < tmp3
    tmp26 = tmp24 & tmp25
    tmp27 = tmp5 & tmp26
    tmp28 = tl.load(in_ptr0 + ((-8856) + x6), tmp27 & xmask, other=0.0)
    tmp29 = tl.full(tmp28.shape, float("-inf"), tmp28.dtype)
    tmp30 = tl.where(tmp27, tmp28, tmp29)
    tmp31 = triton_helpers.maximum(tmp30, tmp22)
    tmp32 = x2
    tmp33 = tmp32 >= tmp1
    tmp34 = tmp32 < tmp3
    tmp35 = tmp33 & tmp34
    tmp36 = tmp35 & tmp9
    tmp37 = tl.load(in_ptr0 + ((-216) + x6), tmp36 & xmask, other=0.0)
    tmp38 = tl.full(tmp37.shape, float("-inf"), tmp37.dtype)
    tmp39 = tl.where(tmp36, tmp37, tmp38)
    tmp40 = triton_helpers.maximum(tmp39, tmp31)
    tmp41 = tmp35 & tmp17
    tmp42 = tl.load(in_ptr0 + (x6), tmp41 & xmask, other=0.0)
    tmp43 = tl.full(tmp42.shape, float("-inf"), tmp42.dtype)
    tmp44 = tl.where(tmp41, tmp42, tmp43)
    tmp45 = triton_helpers.maximum(tmp44, tmp40)
    tmp46 = tmp35 & tmp26
    tmp47 = tl.load(in_ptr0 + (216 + x6), tmp46 & xmask, other=0.0)
    tmp48 = tl.full(tmp47.shape, float("-inf"), tmp47.dtype)
    tmp49 = tl.where(tmp46, tmp47, tmp48)
    tmp50 = triton_helpers.maximum(tmp49, tmp45)
    tmp51 = 1 + x2
    tmp52 = tmp51 >= tmp1
    tmp53 = tmp51 < tmp3
    tmp54 = tmp52 & tmp53
    tmp55 = tmp54 & tmp9
    tmp56 = tl.load(in_ptr0 + (8856 + x6), tmp55 & xmask, other=0.0)
    tmp57 = tl.full(tmp56.shape, float("-inf"), tmp56.dtype)
    tmp58 = tl.where(tmp55, tmp56, tmp57)
    tmp59 = triton_helpers.maximum(tmp58, tmp50)
    tmp60 = tmp54 & tmp17
    tmp61 = tl.load(in_ptr0 + (9072 + x6), tmp60 & xmask, other=0.0)
    tmp62 = tl.full(tmp61.shape, float("-inf"), tmp61.dtype)
    tmp63 = tl.where(tmp60, tmp61, tmp62)
    tmp64 = triton_helpers.maximum(tmp63, tmp59)
    tmp65 = tmp54 & tmp26
    tmp66 = tl.load(in_ptr0 + (9288 + x6), tmp65 & xmask, other=0.0)
    tmp67 = tl.full(tmp66.shape, float("-inf"), tmp66.dtype)
    tmp68 = tl.where(tmp65, tmp66, tmp67)
    tmp69 = triton_helpers.maximum(tmp68, tmp64)
    tmp70 = tmp21 > tmp13
    tmp71 = (-42) + x7
    tmp72 = (-43) + x7
    tmp73 = tl.where(tmp70, tmp71, tmp72)
    tmp74 = tmp30 > tmp22
    tmp75 = (-41) + x7
    tmp76 = tl.where(tmp74, tmp75, tmp73)
    tmp77 = tmp39 > tmp31
    tmp78 = (-1) + x7
    tmp79 = tl.where(tmp77, tmp78, tmp76)
    tmp80 = tmp44 > tmp40
    tmp81 = x7
    tmp82 = tl.where(tmp80, tmp81, tmp79)
    tmp83 = tmp49 > tmp45
    tmp84 = 1 + x7
    tmp85 = tl.where(tmp83, tmp84, tmp82)
    tmp86 = tmp58 > tmp50
    tmp87 = 41 + x7
    tmp88 = tl.where(tmp86, tmp87, tmp85)
    tmp89 = tmp63 > tmp59
    tmp90 = 42 + x7
    tmp91 = tl.where(tmp89, tmp90, tmp88)
    tmp92 = tmp68 > tmp64
    tmp93 = 43 + x7
    tmp94 = tl.where(tmp92, tmp93, tmp91)
    tl.store(out_ptr0 + (x6), tmp69, xmask)
    tl.store(out_ptr1 + (x6), tmp94, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/3h/c3h2v7rkr4rk6f377jy3h3zv4oz6yorvtqaxt3ixqvomf2d54mjg.py
# Source Nodes: [x_188, x_comb_iter_1_right_2], Original ATen: [aten.max_pool2d_with_indices, aten.relu]
# x_188 => relu_33
# x_comb_iter_1_right_2 => getitem_89, max_pool2d_with_indices_7
triton_poi_fused_max_pool2d_with_indices_relu_69 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4194304], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*i64', 4: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_relu_69', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, XBLOCK : tl.constexpr):
    xnumel = 3048192
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    x3 = (xindex // 9072) % 42
    x2 = (xindex // 216) % 42
    x7 = (xindex // 216) % 1764
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp1 = triton_helpers.maximum(0, tmp0)
    tmp2 = (-1) + x3
    tmp3 = tl.full([1], 0, tl.int64)
    tmp4 = tmp2 >= tmp3
    tmp5 = tl.full([1], 42, tl.int64)
    tmp6 = tmp2 < tmp5
    tmp7 = tmp4 & tmp6
    tmp8 = (-1) + x2
    tmp9 = tmp8 >= tmp3
    tmp10 = tmp8 < tmp5
    tmp11 = tmp9 & tmp10
    tmp12 = tmp7 & tmp11
    tmp13 = tl.load(in_ptr0 + ((-9288) + x0), tmp12 & xmask, other=0.0)
    tmp14 = tl.full(tmp13.shape, float("-inf"), tmp13.dtype)
    tmp15 = tl.where(tmp12, tmp13, tmp14)
    tmp16 = x2
    tmp17 = tmp16 >= tmp3
    tmp18 = tmp16 < tmp5
    tmp19 = tmp17 & tmp18
    tmp20 = tmp7 & tmp19
    tmp21 = tl.load(in_ptr0 + ((-9072) + x0), tmp20 & xmask, other=0.0)
    tmp22 = tl.full(tmp21.shape, float("-inf"), tmp21.dtype)
    tmp23 = tl.where(tmp20, tmp21, tmp22)
    tmp24 = triton_helpers.maximum(tmp23, tmp15)
    tmp25 = 1 + x2
    tmp26 = tmp25 >= tmp3
    tmp27 = tmp25 < tmp5
    tmp28 = tmp26 & tmp27
    tmp29 = tmp7 & tmp28
    tmp30 = tl.load(in_ptr0 + ((-8856) + x0), tmp29 & xmask, other=0.0)
    tmp31 = tl.full(tmp30.shape, float("-inf"), tmp30.dtype)
    tmp32 = tl.where(tmp29, tmp30, tmp31)
    tmp33 = triton_helpers.maximum(tmp32, tmp24)
    tmp34 = x3
    tmp35 = tmp34 >= tmp3
    tmp36 = tmp34 < tmp5
    tmp37 = tmp35 & tmp36
    tmp38 = tmp37 & tmp11
    tmp39 = tl.load(in_ptr0 + ((-216) + x0), tmp38 & xmask, other=0.0)
    tmp40 = tl.full(tmp39.shape, float("-inf"), tmp39.dtype)
    tmp41 = tl.where(tmp38, tmp39, tmp40)
    tmp42 = triton_helpers.maximum(tmp41, tmp33)
    tmp43 = tmp37 & tmp19
    tmp44 = tl.load(in_ptr0 + (x0), tmp43 & xmask, other=0.0)
    tmp45 = tl.full(tmp44.shape, float("-inf"), tmp44.dtype)
    tmp46 = tl.where(tmp43, tmp44, tmp45)
    tmp47 = triton_helpers.maximum(tmp46, tmp42)
    tmp48 = tmp37 & tmp28
    tmp49 = tl.load(in_ptr0 + (216 + x0), tmp48 & xmask, other=0.0)
    tmp50 = tl.full(tmp49.shape, float("-inf"), tmp49.dtype)
    tmp51 = tl.where(tmp48, tmp49, tmp50)
    tmp52 = triton_helpers.maximum(tmp51, tmp47)
    tmp53 = 1 + x3
    tmp54 = tmp53 >= tmp3
    tmp55 = tmp53 < tmp5
    tmp56 = tmp54 & tmp55
    tmp57 = tmp56 & tmp11
    tmp58 = tl.load(in_ptr0 + (8856 + x0), tmp57 & xmask, other=0.0)
    tmp59 = tl.full(tmp58.shape, float("-inf"), tmp58.dtype)
    tmp60 = tl.where(tmp57, tmp58, tmp59)
    tmp61 = triton_helpers.maximum(tmp60, tmp52)
    tmp62 = tmp56 & tmp19
    tmp63 = tl.load(in_ptr0 + (9072 + x0), tmp62 & xmask, other=0.0)
    tmp64 = tl.full(tmp63.shape, float("-inf"), tmp63.dtype)
    tmp65 = tl.where(tmp62, tmp63, tmp64)
    tmp66 = triton_helpers.maximum(tmp65, tmp61)
    tmp67 = tmp56 & tmp28
    tmp68 = tl.load(in_ptr0 + (9288 + x0), tmp67 & xmask, other=0.0)
    tmp69 = tl.full(tmp68.shape, float("-inf"), tmp68.dtype)
    tmp70 = tl.where(tmp67, tmp68, tmp69)
    tmp71 = triton_helpers.maximum(tmp70, tmp66)
    tmp72 = tmp23 > tmp15
    tmp73 = (-42) + x7
    tmp74 = (-43) + x7
    tmp75 = tl.where(tmp72, tmp73, tmp74)
    tmp76 = tmp32 > tmp24
    tmp77 = (-41) + x7
    tmp78 = tl.where(tmp76, tmp77, tmp75)
    tmp79 = tmp41 > tmp33
    tmp80 = (-1) + x7
    tmp81 = tl.where(tmp79, tmp80, tmp78)
    tmp82 = tmp46 > tmp42
    tmp83 = x7
    tmp84 = tl.where(tmp82, tmp83, tmp81)
    tmp85 = tmp51 > tmp47
    tmp86 = 1 + x7
    tmp87 = tl.where(tmp85, tmp86, tmp84)
    tmp88 = tmp60 > tmp52
    tmp89 = 41 + x7
    tmp90 = tl.where(tmp88, tmp89, tmp87)
    tmp91 = tmp65 > tmp61
    tmp92 = 42 + x7
    tmp93 = tl.where(tmp91, tmp92, tmp90)
    tmp94 = tmp70 > tmp66
    tmp95 = 43 + x7
    tmp96 = tl.where(tmp94, tmp95, tmp93)
    tl.store(out_ptr0 + (x0), tmp1, xmask)
    tl.store(out_ptr1 + (x0), tmp71, xmask)
    tl.store(out_ptr2 + (x0), tmp96, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ai/caio2a3sbiktx745fieatzv66q4wfm3figbeh3pozhgluqcnrinw.py
# Source Nodes: [x_comb_iter_12, x_comb_iter_2_left_2, x_comb_iter_2_right_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_12 => add_217
# x_comb_iter_2_left_2 => add_203, add_206, mul_266, mul_272, rsqrt_38, sub_38, var_mean_38
# x_comb_iter_2_right_2 => add_213, add_216, mul_280, mul_286, rsqrt_40, sub_40, var_mean_40
triton_poi_fused__native_batch_norm_legit_functional_add_70 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16384, 256], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32', 12: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11, 12))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_70', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 14112
    xnumel = 216
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 1764
    y1 = (yindex // 1764)
    tmp0 = tl.load(in_ptr0 + (x2 + (216*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x2), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x2 + (216*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x2), xmask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x2), xmask, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x2), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x2), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 14112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp13 + tmp25
    tl.store(out_ptr0 + (y0 + (1764*x2) + (1905120*y1)), tmp26, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/l2/cl2gpqv35noleuqoisnxhbbsmmqu7vb54npzljhslgreodaarrg4.py
# Source Nodes: [x_218], Original ATen: [aten.relu]
# x_218 => relu_39
triton_poi_fused_relu_71 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2048, 2048], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_relu_71', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 1728
    xnumel = 1764
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y0 = yindex % 216
    y1 = (yindex // 216)
    tmp0 = tl.load(in_ptr0 + (x2 + (1764*y0) + (1905120*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = triton_helpers.maximum(0, tmp0)
    tl.store(out_ptr0 + (y0 + (216*x2) + (381024*y1)), tmp1, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/xo/cxoogrtiu534scne5msy7aoovwxddo5u6k6dlx4zlkscf2awieog.py
# Source Nodes: [x_comb_iter_0_left_2, x_comb_iter_10], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_0_left_2 => add_181, add_184, mul_238, mul_244, rsqrt_34, sub_34, var_mean_34
# x_comb_iter_10 => add_185
triton_poi_fused__native_batch_norm_legit_functional_add_72 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2048, 2048], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_72', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 1728
    xnumel = 1764
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y0 = yindex % 216
    y1 = (yindex // 216)
    tmp0 = tl.load(in_ptr0 + (y0 + (216*x2) + (381024*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (y0), ymask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (y0), ymask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (y0), ymask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (y0 + (216*x2) + (381024*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 14112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tl.store(out_ptr0 + (x2 + (1764*y0) + (1905120*y1)), tmp15, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/px/cpxlw6h3sbwv4ilcjodpppmqml7ph2pmvzelh4664avx3v7aulml.py
# Source Nodes: [x_comb_iter_11, x_comb_iter_13, x_comb_iter_1_left_2, x_comb_iter_3_left_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_11 => add_196
# x_comb_iter_13 => add_228
# x_comb_iter_1_left_2 => add_192, add_195, mul_252, mul_258, rsqrt_36, sub_36, var_mean_36
# x_comb_iter_3_left_2 => add_224, add_227, mul_294, mul_300, rsqrt_42, sub_42, var_mean_42
triton_poi_fused__native_batch_norm_legit_functional_add_73 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2048, 2048], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: 'i32', 14: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(13,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_73', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 1728
    xnumel = 1764
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y0 = yindex % 216
    y1 = (yindex // 216)
    tmp0 = tl.load(in_ptr0 + (y0 + (216*x2) + (381024*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (y0), ymask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (y0), ymask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (y0), ymask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (y0 + (216*x2) + (381024*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr6 + (y0 + (216*x2) + (381024*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (y0), ymask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr8 + (y0), ymask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (y0), ymask, eviction_policy='evict_last')
    tmp26 = tl.load(in_ptr10 + (y0), ymask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 14112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp18 = tmp16 - tmp17
    tmp20 = tmp19 / tmp4
    tmp21 = tmp20 + tmp6
    tmp22 = tl.math.rsqrt(tmp21)
    tmp23 = tmp18 * tmp22
    tmp25 = tmp23 * tmp24
    tmp27 = tmp25 + tmp26
    tmp28 = tmp27 + tmp14
    tl.store(out_ptr0 + (x2 + (1764*y0) + (1905120*y1)), tmp15, xmask & ymask)
    tl.store(out_ptr1 + (x2 + (1764*y0) + (1905120*y1)), tmp28, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/vd/cvddk5axvb2hr42gax4crzuypimvdgnfzz5wbpciapkevtqpauju.py
# Source Nodes: [x_241], Original ATen: [aten.relu]
# x_241 => relu_44
triton_poi_fused_relu_74 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16384, 2048], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_relu_74', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 8640
    xnumel = 1764
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 1080
    y1 = (yindex // 1080)
    tmp0 = tl.load(in_ptr0 + (x2 + (1764*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = triton_helpers.maximum(0, tmp0)
    tl.store(out_ptr0 + (y0 + (1080*x2) + (1905120*y1)), tmp1, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/lk/clkdvnlg2lu7x2kqotyczxyd3uau6lkgahk7ej4hh4mxdemymalu.py
# Source Nodes: [x_437], Original ATen: [aten.convolution]
# x_437 => convolution_161
triton_poi_fused_convolution_75 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4096, 2048], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_75', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 3456
    xnumel = 1764
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 432
    y1 = (yindex // 432)
    tmp0 = tl.load(in_ptr0 + (x2 + (1764*y3)), xmask & ymask, eviction_policy='evict_last')
    tl.store(out_ptr0 + (y0 + (432*x2) + (762048*y1)), tmp0, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/by/cby5m2qmbjuwqt7a4u3htktdlq3na56c2vgrsepqyewaj6lphaz5.py
# Source Nodes: [x_left_5], Original ATen: [aten._native_batch_norm_legit_functional]
# x_left_5 => var_mean_87
triton_red_fused__native_batch_norm_legit_functional_76 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[65536, 128],
    reduction_hint=ReductionHint.OUTER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_76', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 47952
    rnumel = 128
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x1 = (xindex // 432)
    x0 = xindex % 432
    tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    x3 = xindex
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = r2 + (128*x1)
        tmp1 = tl.full([1, 1], 14112, tl.int32)
        tmp2 = tmp0 < tmp1
        tmp3 = tl.load(in_ptr0 + (x0 + (432*((r2 + (128*x1)) % 14112))), rmask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
        tmp5 = tl.where(tmp2, tmp3, tmp4)
        tmp6 = 0.0
        tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
        tmp8 = tl.where(tmp2, tmp6, tmp7)
        tmp9 = 1.0
        tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
        tmp11 = tl.where(tmp2, tmp9, tmp10)
        tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
        tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
        tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
            tmp15_mean, tmp15_m2, tmp15_weight,
            tmp12, tmp13, tmp14
        )
        tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
        tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
        tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
    tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
        tmp15_mean, tmp15_m2, tmp15_weight, 1
    )
    tmp15 = tmp15_tmp[:, None]
    tmp16 = tmp16_tmp[:, None]
    tmp17 = tmp17_tmp[:, None]
    tl.store(out_ptr0 + (x3), tmp15, xmask)
    tl.store(out_ptr1 + (x3), tmp16, xmask)
    tl.store(out_ptr2 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/c2/cc256k23yg7pifqopw75phxheweofe6itrg4nhejw3sopvu2ehsa.py
# Source Nodes: [x_left_5], Original ATen: [aten._native_batch_norm_legit_functional]
# x_left_5 => add_466, add_467, add_468, mul_610, mul_611, mul_612, mul_613, mul_614, rsqrt_87, squeeze_262, var_mean_87
triton_red_fused__native_batch_norm_legit_functional_77 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[512, 128],
    reduction_hint=ReductionHint.OUTER_TINY,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_77', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 432
    rnumel = 111
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex
        tmp0 = tl.load(in_ptr0 + (x0 + (432*r1)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.load(in_ptr1 + (x0 + (432*r1)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp2 = tl.load(in_ptr2 + (x0 + (432*r1)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
        tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
        tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
            tmp6_mean, tmp6_m2, tmp6_weight,
            tmp3, tmp4, tmp5
        )
        tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
        tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
        tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
    tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
        tmp6_mean, tmp6_m2, tmp6_weight, 1
    )
    tmp6 = tmp6_tmp[:, None]
    tmp7 = tmp7_tmp[:, None]
    tmp8 = tmp8_tmp[:, None]
    tl.store(out_ptr0 + (x0), tmp6, xmask)
    tl.store(out_ptr1 + (x0), tmp7, xmask)
    tmp16 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp23 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp9 = 14112.0
    tmp10 = tmp7 / tmp9
    tmp11 = 0.001
    tmp12 = tmp10 + tmp11
    tmp13 = tl.math.rsqrt(tmp12)
    tmp14 = 0.1
    tmp15 = tmp6 * tmp14
    tmp17 = 0.9
    tmp18 = tmp16 * tmp17
    tmp19 = tmp15 + tmp18
    tmp20 = 1.0000708666997378
    tmp21 = tmp10 * tmp20
    tmp22 = tmp21 * tmp14
    tmp24 = tmp23 * tmp17
    tmp25 = tmp22 + tmp24
    tl.store(out_ptr2 + (x0), tmp13, xmask)
    tl.store(out_ptr4 + (x0), tmp19, xmask)
    tl.store(out_ptr6 + (x0), tmp25, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/6x/c6xx2gibz527oayhwhz3qe3sudwx46wdyhq5u2jnwtjjo7eq6dnx.py
# Source Nodes: [x_442, x_left_5], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu, aten.threshold_backward]
# x_442 => relu_87
# x_left_5 => add_466, add_469, mul_609, mul_615, rsqrt_87, sub_87, var_mean_87
triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_78 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*i1', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_78', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6096384
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = xindex
    x0 = xindex % 432
    tmp0 = tl.load(in_ptr0 + (x2), xmask)
    tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 14112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tmp15 = 0.0
    tmp16 = tmp14 <= tmp15
    tl.store(out_ptr0 + (x2), tmp13, xmask)
    tl.store(out_ptr1 + (x2), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/rc/crct5qsfdpiwo5hoytb24uil3xirjej73rwnxxxvflinfadkdgq2.py
# Source Nodes: [x_456, x_right_6], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu, aten.threshold_backward]
# x_456 => relu_89
# x_right_6 => add_471, add_474, mul_616, mul_622, rsqrt_88, sub_88, var_mean_88
triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_79 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*i1', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_79', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6096384
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = xindex
    x0 = xindex % 432
    tmp0 = tl.load(in_ptr0 + (x2), xmask)
    tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 14112.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tmp15 = 0.0
    tmp16 = tmp14 <= tmp15
    tl.store(out_ptr0 + (x2), tmp13, xmask)
    tl.store(out_ptr1 + (x2), tmp14, xmask)
    tl.store(out_ptr2 + (x2), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/sz/cszuxi5by7czx4ga66myh763ehfrewf7tphdjt4ismnak6z3ngvh.py
# Source Nodes: [x_442, x_444], Original ATen: [aten.constant_pad_nd, aten.relu]
# x_442 => relu_87
# x_444 => constant_pad_nd_20
triton_poi_fused_constant_pad_nd_relu_80 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_relu_80', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6998400
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 19440) % 45
    x1 = (xindex // 432) % 45
    x3 = (xindex // 874800)
    x4 = xindex % 19440
    x6 = xindex
    tmp0 = (-1) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 42, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-1) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-18576) + x4 + (18144*x2) + (762048*x3)), tmp10 & xmask, other=0.0)
    tmp12 = triton_helpers.maximum(0, tmp11)
    tmp13 = tl.full(tmp12.shape, 0.0, tmp12.dtype)
    tmp14 = tl.where(tmp10, tmp12, tmp13)
    tl.store(out_ptr0 + (x6), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/jp/cjp3izia3czgzfcjh3yixjw3jfohp5pnwzri7zz3dhq4ki22jjhp.py
# Source Nodes: [x_445], Original ATen: [aten.convolution]
# x_445 => convolution_163
triton_poi_fused_convolution_81 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4096, 512], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_81', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 3456
    xnumel = 441
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 432
    y1 = (yindex // 432)
    tmp0 = tl.load(in_ptr0 + (x2 + (441*y3)), xmask & ymask, eviction_policy='evict_last')
    tl.store(out_ptr0 + (y0 + (432*x2) + (190512*y1)), tmp0, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/rm/crmesrfrgx4ijyuuukdecawqftlso6n4w76zgmyfuozwhwwavwoo.py
# Source Nodes: [x_448], Original ATen: [aten._native_batch_norm_legit_functional]
# x_448 => var_mean_89
triton_red_fused__native_batch_norm_legit_functional_82 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[16384, 128],
    reduction_hint=ReductionHint.OUTER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_82', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 12096
    rnumel = 126
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 432
    x1 = (xindex // 432)
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    x3 = xindex
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + (x0 + (432*r2) + (54432*x1)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x3), tmp2, xmask)
    tl.store(out_ptr1 + (x3), tmp3, xmask)
    tl.store(out_ptr2 + (x3), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/nq/cnqabfggmobept6k3wqnv6wso5rvgani3mnwm4zk7ogjfmznh62h.py
# Source Nodes: [x_448], Original ATen: [aten._native_batch_norm_legit_functional]
# x_448 => add_476, add_477, add_478, mul_624, mul_625, mul_626, mul_627, mul_628, rsqrt_89, squeeze_268, var_mean_89
triton_per_fused__native_batch_norm_legit_functional_83 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[512, 32],
    reduction_hint=ReductionHint.OUTER_TINY,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_83', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 432
    rnumel = 28
    RBLOCK: tl.constexpr = 32
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (432*r1)), rmask & xmask, other=0.0)
    tmp1 = tl.load(in_ptr1 + (x0 + (432*r1)), rmask & xmask, other=0.0)
    tmp2 = tl.load(in_ptr2 + (x0 + (432*r1)), rmask & xmask, other=0.0)
    tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
    tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
    tmp7 = tl.where(rmask & xmask, tmp3, 0)
    tmp8 = tl.where(rmask & xmask, tmp4, 0)
    tmp9 = tl.where(rmask & xmask, tmp5, 0)
    tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
    tmp13 = tmp10[:, None]
    tmp14 = tmp11[:, None]
    tmp15 = tmp12[:, None]
    tmp16 = 3528.0
    tmp17 = tmp14 / tmp16
    tmp18 = 0.001
    tmp19 = tmp17 + tmp18
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = 0.1
    tmp22 = tmp13 * tmp21
    tmp24 = 0.9
    tmp25 = tmp23 * tmp24
    tmp26 = tmp22 + tmp25
    tmp27 = 1.0002835270768358
    tmp28 = tmp17 * tmp27
    tmp29 = tmp28 * tmp21
    tmp31 = tmp30 * tmp24
    tmp32 = tmp29 + tmp31
    tl.store(out_ptr2 + (x0), tmp20, xmask)
    tl.store(out_ptr4 + (x0), tmp26, xmask)
    tl.store(out_ptr6 + (x0), tmp32, xmask)
    tl.store(out_ptr0 + (x0), tmp13, xmask)
    tl.store(out_ptr1 + (x0), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/o6/co6rmrfefajfkav4lbrruy4zerzifshutefeicnzkbyyjtbo6n5c.py
# Source Nodes: [x_448, x_449], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# x_448 => add_476, add_479, mul_623, mul_629, rsqrt_89, sub_89, var_mean_89
# x_449 => relu_88
triton_poi_fused__native_batch_norm_legit_functional_relu_84 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2097152], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_84', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 1524096
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = xindex
    x0 = xindex % 432
    tmp0 = tl.load(in_ptr0 + (x2), xmask)
    tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 3528.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x2), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/7x/c7x7vgp2ghzrjp4ngnoxjolibqc7bnjunicrmv7l3qjpq34eicxw.py
# Source Nodes: [x_455], Original ATen: [aten.constant_pad_nd]
# x_455 => constant_pad_nd_21
triton_poi_fused_constant_pad_nd_85 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_85', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6390144
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 18576) % 43
    x1 = (xindex // 432) % 43
    x3 = (xindex // 798768)
    x4 = xindex % 18576
    x5 = xindex
    tmp0 = x2
    tmp1 = tl.full([1], 42, tl.int64)
    tmp2 = tmp0 < tmp1
    tmp3 = x1
    tmp4 = tmp3 < tmp1
    tmp5 = tmp2 & tmp4
    tmp6 = tl.load(in_ptr0 + (x4 + (18144*x2) + (762048*x3)), tmp5 & xmask, other=0.0)
    tmp7 = tl.full(tmp6.shape, float("-inf"), tmp6.dtype)
    tmp8 = tl.where(tmp5, tmp6, tmp7)
    tl.store(out_ptr0 + (x5), tmp8, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ss/cssfnin7hsiaxkxejct3fts3w64seqvdqekbkcev2v5gnrsozpe6.py
# Source Nodes: [x_comb_iter_0_right_6], Original ATen: [aten.max_pool2d_with_indices]
# x_comb_iter_0_right_6 => getitem_219, max_pool2d_with_indices_18
triton_poi_fused_max_pool2d_with_indices_86 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4096, 512], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*i64', 3: 'i32', 4: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_86', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 3456
    xnumel = 441
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex % 21
    x3 = (xindex // 21)
    y0 = yindex % 432
    y1 = (yindex // 432)
    x4 = xindex
    tmp0 = tl.load(in_ptr0 + (y0 + (864*x2) + (37152*x3) + (798768*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr0 + (432 + y0 + (864*x2) + (37152*x3) + (798768*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr0 + (864 + y0 + (864*x2) + (37152*x3) + (798768*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp5 = tl.load(in_ptr0 + (18576 + y0 + (864*x2) + (37152*x3) + (798768*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr0 + (19008 + y0 + (864*x2) + (37152*x3) + (798768*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp9 = tl.load(in_ptr0 + (19440 + y0 + (864*x2) + (37152*x3) + (798768*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr0 + (37152 + y0 + (864*x2) + (37152*x3) + (798768*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr0 + (37584 + y0 + (864*x2) + (37152*x3) + (798768*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr0 + (38016 + y0 + (864*x2) + (37152*x3) + (798768*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp2 = triton_helpers.maximum(tmp1, tmp0)
    tmp4 = triton_helpers.maximum(tmp3, tmp2)
    tmp6 = triton_helpers.maximum(tmp5, tmp4)
    tmp8 = triton_helpers.maximum(tmp7, tmp6)
    tmp10 = triton_helpers.maximum(tmp9, tmp8)
    tmp12 = triton_helpers.maximum(tmp11, tmp10)
    tmp14 = triton_helpers.maximum(tmp13, tmp12)
    tmp16 = triton_helpers.maximum(tmp15, tmp14)
    tmp17 = tmp1 > tmp0
    tmp18 = 1 + (2*x2) + (86*x3)
    tmp19 = (2*x2) + (86*x3)
    tmp20 = tl.where(tmp17, tmp18, tmp19)
    tmp21 = tmp3 > tmp2
    tmp22 = 2 + (2*x2) + (86*x3)
    tmp23 = tl.where(tmp21, tmp22, tmp20)
    tmp24 = tmp5 > tmp4
    tmp25 = 43 + (2*x2) + (86*x3)
    tmp26 = tl.where(tmp24, tmp25, tmp23)
    tmp27 = tmp7 > tmp6
    tmp28 = 44 + (2*x2) + (86*x3)
    tmp29 = tl.where(tmp27, tmp28, tmp26)
    tmp30 = tmp9 > tmp8
    tmp31 = 45 + (2*x2) + (86*x3)
    tmp32 = tl.where(tmp30, tmp31, tmp29)
    tmp33 = tmp11 > tmp10
    tmp34 = 86 + (2*x2) + (86*x3)
    tmp35 = tl.where(tmp33, tmp34, tmp32)
    tmp36 = tmp13 > tmp12
    tmp37 = 87 + (2*x2) + (86*x3)
    tmp38 = tl.where(tmp36, tmp37, tmp35)
    tmp39 = tmp15 > tmp14
    tmp40 = 88 + (2*x2) + (86*x3)
    tmp41 = tl.where(tmp39, tmp40, tmp38)
    tl.store(out_ptr0 + (y0 + (432*x4) + (190512*y1)), tmp16, xmask & ymask)
    tl.store(out_ptr1 + (y0 + (432*x4) + (190512*y1)), tmp41, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/md/cmdyeuczsqpt5go6sicevam5tqrzvwsawdkwc76mfvo7pegqvbii.py
# Source Nodes: [x_458], Original ATen: [aten.constant_pad_nd]
# x_458 => constant_pad_nd_22
triton_poi_fused_constant_pad_nd_87 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_87', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 7634304
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 20304) % 47
    x1 = (xindex // 432) % 47
    x3 = (xindex // 954288)
    x4 = xindex % 20304
    x6 = xindex
    tmp0 = (-2) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 42, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-2) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-37152) + x4 + (18144*x2) + (762048*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/2c/c2c47op3gehxohsayb6ubonw5kln4hof6gcqmgrm3ut5ff7rvhkm.py
# Source Nodes: [x_472], Original ATen: [aten.constant_pad_nd]
# x_472 => constant_pad_nd_24
triton_poi_fused_constant_pad_nd_88 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_88', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6998400
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 19440) % 45
    x1 = (xindex // 432) % 45
    x3 = (xindex // 874800)
    x4 = xindex % 19440
    x6 = xindex
    tmp0 = (-1) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 42, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-1) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-18576) + x4 + (18144*x2) + (762048*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/5v/c5vbjcwokbplqrhhxfywee2eb5go7bi2bszr4mjxzxbas4lc2k3y.py
# Source Nodes: [x_484], Original ATen: [aten.constant_pad_nd]
# x_484 => constant_pad_nd_25
triton_poi_fused_constant_pad_nd_89 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_89', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6390144
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 18576) % 43
    x1 = (xindex // 432) % 43
    x3 = (xindex // 798768)
    x4 = xindex % 18576
    x5 = xindex
    tmp0 = x2
    tmp1 = tl.full([1], 42, tl.int64)
    tmp2 = tmp0 < tmp1
    tmp3 = x1
    tmp4 = tmp3 < tmp1
    tmp5 = tmp2 & tmp4
    tmp6 = tl.load(in_ptr0 + (x4 + (18144*x2) + (762048*x3)), tmp5 & xmask, other=0.0)
    tmp7 = tl.full(tmp6.shape, 0.0, tmp6.dtype)
    tmp8 = tl.where(tmp5, tmp6, tmp7)
    tl.store(out_ptr0 + (x5), tmp8, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/oj/cojokz6vhzu6l4nnp6sy6azonn6uvbo7dnjnc6a2knzyww45xxef.py
# Source Nodes: [x_comb_iter_2_left_6, x_comb_iter_2_right_6, x_comb_iter_32], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_2_left_6 => add_503, add_506, mul_658, mul_664, rsqrt_94, sub_94, var_mean_94
# x_comb_iter_2_right_6 => add_513, add_516, mul_672, mul_678, rsqrt_96, sub_96, var_mean_96
# x_comb_iter_32 => add_517
triton_poi_fused__native_batch_norm_legit_functional_add_90 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4096, 512], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32', 12: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11, 12))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_90', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 3528
    xnumel = 432
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 441
    y1 = (yindex // 441)
    tmp0 = tl.load(in_ptr0 + (x2 + (432*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x2), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x2 + (432*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x2), xmask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x2), xmask, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x2), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x2), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 3528.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp13 + tmp25
    tl.store(out_ptr0 + (y0 + (441*x2) + (952560*y1)), tmp26, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ir/cirvddkidvvrvirs6o55r2nmoeybgevrebckowmqisf6x32afrjo.py
# Source Nodes: [x_494], Original ATen: [aten.relu]
# x_494 => relu_95
triton_poi_fused_relu_91 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4096, 512], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_relu_91', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 3456
    xnumel = 441
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y0 = yindex % 432
    y1 = (yindex // 432)
    tmp0 = tl.load(in_ptr0 + (x2 + (441*y0) + (952560*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = triton_helpers.maximum(0, tmp0)
    tl.store(out_ptr0 + (y0 + (432*x2) + (190512*y1)), tmp1, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/2i/c2i4eepkfjtppvm2bembpp5ir5jt2ympaf2jaiuofwhc3lrjoreo.py
# Source Nodes: [x_442, x_508], Original ATen: [aten.constant_pad_nd, aten.relu]
# x_442 => relu_87
# x_508 => constant_pad_nd_27
triton_poi_fused_constant_pad_nd_relu_92 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_relu_92', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6390144
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 18576) % 43
    x1 = (xindex // 432) % 43
    x3 = (xindex // 798768)
    x4 = xindex % 18576
    x5 = xindex
    tmp0 = x2
    tmp1 = tl.full([1], 42, tl.int64)
    tmp2 = tmp0 < tmp1
    tmp3 = x1
    tmp4 = tmp3 < tmp1
    tmp5 = tmp2 & tmp4
    tmp6 = tl.load(in_ptr0 + (x4 + (18144*x2) + (762048*x3)), tmp5 & xmask, other=0.0)
    tmp7 = triton_helpers.maximum(0, tmp6)
    tmp8 = tl.full(tmp7.shape, 0.0, tmp7.dtype)
    tmp9 = tl.where(tmp5, tmp7, tmp8)
    tl.store(out_ptr0 + (x5), tmp9, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/pn/cpnjz7tdvkm3i7yfcqhc7stwkacysxc53rfdkottmhscdox7r3ce.py
# Source Nodes: [x_comb_iter_0_left_6, x_comb_iter_30], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_0_left_6 => add_481, add_484, mul_630, mul_636, rsqrt_90, sub_90, var_mean_90
# x_comb_iter_30 => add_485
triton_poi_fused__native_batch_norm_legit_functional_add_93 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4096, 512], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7, 8))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_93', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 3528
    xnumel = 432
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 441
    y1 = (yindex // 441)
    tmp0 = tl.load(in_ptr0 + (x2 + (432*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x2), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x2 + (432*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 3528.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tl.store(out_ptr0 + (y0 + (441*x2) + (952560*y1)), tmp15, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/az/cazptbbaldeovok7s7gkbxjoauwxmfe3nicmrzcneyw4k6g4tmyg.py
# Source Nodes: [x_comb_iter_1_left_6, x_comb_iter_31, x_comb_iter_33, x_comb_iter_3_left_6], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_1_left_6 => add_492, add_495, mul_644, mul_650, rsqrt_92, sub_92, var_mean_92
# x_comb_iter_31 => add_496
# x_comb_iter_33 => add_528
# x_comb_iter_3_left_6 => add_524, add_527, mul_686, mul_692, rsqrt_98, sub_98, var_mean_98
triton_poi_fused__native_batch_norm_legit_functional_add_94 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4096, 512], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: 'i32', 14: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(13, 14))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_94', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 3528
    xnumel = 432
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 441
    y1 = (yindex // 441)
    tmp0 = tl.load(in_ptr0 + (x2 + (432*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x2), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x2 + (432*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr6 + (x2 + (432*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x2), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr8 + (x2), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x2), xmask, eviction_policy='evict_last')
    tmp26 = tl.load(in_ptr10 + (x2), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 3528.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp18 = tmp16 - tmp17
    tmp20 = tmp19 / tmp4
    tmp21 = tmp20 + tmp6
    tmp22 = tl.math.rsqrt(tmp21)
    tmp23 = tmp18 * tmp22
    tmp25 = tmp23 * tmp24
    tmp27 = tmp25 + tmp26
    tmp28 = tmp27 + tmp14
    tl.store(out_ptr0 + (y0 + (441*x2) + (952560*y1)), tmp15, xmask & ymask)
    tl.store(out_ptr1 + (y0 + (441*x2) + (952560*y1)), tmp28, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/7c/c7cnqkjpxvu7c7f6u6opud4hewbqrwc6yrjvmy2gwucbydlqi445.py
# Source Nodes: [l__mod___cell_5_conv_prev_1x1_path_1_avgpool], Original ATen: [aten.avg_pool2d]
# l__mod___cell_5_conv_prev_1x1_path_1_avgpool => avg_pool2d_4
triton_poi_fused_avg_pool2d_95 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4194304], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_avg_pool2d_95', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 3810240
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex % 1080
    x1 = (xindex // 1080) % 21
    x2 = (xindex // 22680)
    x3 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (2160*x1) + (90720*x2)), xmask)
    tmp1 = 1.0
    tmp2 = tmp0 * tmp1
    tl.store(out_ptr0 + (x3), tmp2, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/js/cjsezuk7layll43wtshwigiksjvstewplxojtedzep6wmsutgd4e.py
# Source Nodes: [l__mod___cell_5_conv_prev_1x1_path_2_pad], Original ATen: [aten.constant_pad_nd]
# l__mod___cell_5_conv_prev_1x1_path_2_pad => constant_pad_nd_29
triton_poi_fused_constant_pad_nd_96 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16777216], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_96', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 15240960
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 45360) % 42
    x1 = (xindex // 1080) % 42
    x6 = xindex
    tmp0 = 1 + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 42, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = 1 + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + (46440 + x6), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/jf/cjf7jcquhn6ijlrzlxet2bbsb3nazhbaih5z3nx3fzw5nkpjy377.py
# Source Nodes: [l__mod___cell_5_conv_prev_1x1_path_2_avgpool], Original ATen: [aten.avg_pool2d]
# l__mod___cell_5_conv_prev_1x1_path_2_avgpool => avg_pool2d_5
triton_poi_fused_avg_pool2d_97 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16384, 512], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_avg_pool2d_97', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 8640
    xnumel = 441
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex % 21
    x3 = (xindex // 21)
    y0 = yindex % 1080
    y1 = (yindex // 1080)
    x4 = xindex
    tmp0 = tl.load(in_ptr0 + (y0 + (2160*x2) + (90720*x3) + (1905120*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = 1.0
    tmp2 = tmp0 * tmp1
    tl.store(out_ptr0 + (y0 + (1080*x4) + (476280*y1)), tmp2, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/7p/c7pd5ns23aepjac6c4zaucs47xsnlpbulra5i6r3xi3egdxr7fkz.py
# Source Nodes: [cat_26], Original ATen: [aten.cat]
# cat_26 => cat_9
triton_poi_fused_cat_98 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4096, 512], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32', 4: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_98', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 3456
    xnumel = 441
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    y0 = yindex % 432
    x2 = xindex
    y1 = (yindex // 432)
    tmp0 = y0
    tmp1 = tl.full([1, 1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1, 1], 216, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = tl.load(in_ptr0 + (x2 + (441*y0) + (95256*y1)), tmp4 & xmask & ymask, eviction_policy='evict_last', other=0.0)
    tmp6 = tl.full(tmp5.shape, 0.0, tmp5.dtype)
    tmp7 = tl.where(tmp4, tmp5, tmp6)
    tmp8 = tmp0 >= tmp3
    tmp9 = tl.full([1, 1], 432, tl.int64)
    tmp10 = tmp0 < tmp9
    tmp11 = tl.load(in_ptr1 + ((-95256) + x2 + (441*y0) + (95256*y1)), tmp8 & xmask & ymask, eviction_policy='evict_last', other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp8, tmp11, tmp12)
    tmp14 = tl.where(tmp4, tmp7, tmp13)
    tl.store(out_ptr0 + (y0 + (432*x2) + (190512*y1)), tmp14, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ls/clsz2gt6rzquasrvkvexpojul6hbpco52mg6peal63kf7ekjkfr6.py
# Source Nodes: [x_527, x_left_6], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# x_527 => relu_102
# x_left_6 => add_546, add_549, mul_714, mul_720, rsqrt_102, sub_102, var_mean_102
triton_poi_fused__native_batch_norm_legit_functional_relu_99 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2097152], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_99', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 1524096
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = xindex
    x0 = xindex % 432
    tmp0 = tl.load(in_ptr0 + (x2), xmask)
    tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 3528.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x2), tmp13, xmask)
    tl.store(out_ptr1 + (x2), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/tl/ctl56qpxwaebkkav7k2zfopaigo5wja75bcjutpyeq5ftyk7mvms.py
# Source Nodes: [x_524], Original ATen: [aten.relu]
# x_524 => relu_101
triton_poi_fused_relu_100 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[32768, 512], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_relu_100', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 17280
    xnumel = 441
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 2160
    y1 = (yindex // 2160)
    tmp0 = tl.load(in_ptr0 + (x2 + (441*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = triton_helpers.maximum(0, tmp0)
    tl.store(out_ptr0 + (y0 + (2160*x2) + (952560*y1)), tmp1, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/wo/cwojcuj6de6k7t6hiei3zxziyov532lloamewlv4m3zx6mx52rgf.py
# Source Nodes: [x_comb_iter_39, x_comb_iter_4_left_7, x_comb_iter_4_right_7], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_39 => add_619
# x_comb_iter_4_left_7 => add_615, add_618, mul_805, mul_811, rsqrt_115, sub_115, var_mean_115
# x_comb_iter_4_right_7 => add_551, add_554, mul_721, mul_727, rsqrt_103, sub_103, var_mean_103
triton_poi_fused__native_batch_norm_legit_functional_add_101 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4096, 512], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: 'i32', 13: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(12, 13))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_101', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 3528
    xnumel = 432
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x1 = xindex
    y0 = yindex
    y2 = yindex % 441
    y3 = (yindex // 441)
    tmp0 = tl.load(in_ptr0 + (x1 + (432*y0)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x1 + (432*y0)), xmask & ymask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x1), xmask, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x1), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 3528.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp25 + tmp13
    tl.store(out_ptr0 + (x1 + (432*y0)), tmp13, xmask & ymask)
    tl.store(out_ptr1 + (y2 + (441*x1) + (952560*y3)), tmp26, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/5k/c5kbkiekwgcacw77p4i3zk4rhavfztmxq4baeiwpt3ed7vtqjt4s.py
# Source Nodes: [x_comb_iter_0_right_7], Original ATen: [aten.max_pool2d_with_indices]
# x_comb_iter_0_right_7 => getitem_255, max_pool2d_with_indices_21
triton_poi_fused_max_pool2d_with_indices_102 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2097152], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*i64', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_102', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 1524096
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 9072) % 21
    x1 = (xindex // 432) % 21
    x6 = xindex
    x7 = (xindex // 432) % 441
    tmp0 = (-1) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 21, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = tmp2 & tmp4
    tmp6 = (-1) + x1
    tmp7 = tmp6 >= tmp1
    tmp8 = tmp6 < tmp3
    tmp9 = tmp7 & tmp8
    tmp10 = tmp5 & tmp9
    tmp11 = tl.load(in_ptr0 + ((-9504) + x6), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, float("-inf"), tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tmp14 = x1
    tmp15 = tmp14 >= tmp1
    tmp16 = tmp14 < tmp3
    tmp17 = tmp15 & tmp16
    tmp18 = tmp5 & tmp17
    tmp19 = tl.load(in_ptr0 + ((-9072) + x6), tmp18 & xmask, other=0.0)
    tmp20 = tl.full(tmp19.shape, float("-inf"), tmp19.dtype)
    tmp21 = tl.where(tmp18, tmp19, tmp20)
    tmp22 = triton_helpers.maximum(tmp21, tmp13)
    tmp23 = 1 + x1
    tmp24 = tmp23 >= tmp1
    tmp25 = tmp23 < tmp3
    tmp26 = tmp24 & tmp25
    tmp27 = tmp5 & tmp26
    tmp28 = tl.load(in_ptr0 + ((-8640) + x6), tmp27 & xmask, other=0.0)
    tmp29 = tl.full(tmp28.shape, float("-inf"), tmp28.dtype)
    tmp30 = tl.where(tmp27, tmp28, tmp29)
    tmp31 = triton_helpers.maximum(tmp30, tmp22)
    tmp32 = x2
    tmp33 = tmp32 >= tmp1
    tmp34 = tmp32 < tmp3
    tmp35 = tmp33 & tmp34
    tmp36 = tmp35 & tmp9
    tmp37 = tl.load(in_ptr0 + ((-432) + x6), tmp36 & xmask, other=0.0)
    tmp38 = tl.full(tmp37.shape, float("-inf"), tmp37.dtype)
    tmp39 = tl.where(tmp36, tmp37, tmp38)
    tmp40 = triton_helpers.maximum(tmp39, tmp31)
    tmp41 = tmp35 & tmp17
    tmp42 = tl.load(in_ptr0 + (x6), tmp41 & xmask, other=0.0)
    tmp43 = tl.full(tmp42.shape, float("-inf"), tmp42.dtype)
    tmp44 = tl.where(tmp41, tmp42, tmp43)
    tmp45 = triton_helpers.maximum(tmp44, tmp40)
    tmp46 = tmp35 & tmp26
    tmp47 = tl.load(in_ptr0 + (432 + x6), tmp46 & xmask, other=0.0)
    tmp48 = tl.full(tmp47.shape, float("-inf"), tmp47.dtype)
    tmp49 = tl.where(tmp46, tmp47, tmp48)
    tmp50 = triton_helpers.maximum(tmp49, tmp45)
    tmp51 = 1 + x2
    tmp52 = tmp51 >= tmp1
    tmp53 = tmp51 < tmp3
    tmp54 = tmp52 & tmp53
    tmp55 = tmp54 & tmp9
    tmp56 = tl.load(in_ptr0 + (8640 + x6), tmp55 & xmask, other=0.0)
    tmp57 = tl.full(tmp56.shape, float("-inf"), tmp56.dtype)
    tmp58 = tl.where(tmp55, tmp56, tmp57)
    tmp59 = triton_helpers.maximum(tmp58, tmp50)
    tmp60 = tmp54 & tmp17
    tmp61 = tl.load(in_ptr0 + (9072 + x6), tmp60 & xmask, other=0.0)
    tmp62 = tl.full(tmp61.shape, float("-inf"), tmp61.dtype)
    tmp63 = tl.where(tmp60, tmp61, tmp62)
    tmp64 = triton_helpers.maximum(tmp63, tmp59)
    tmp65 = tmp54 & tmp26
    tmp66 = tl.load(in_ptr0 + (9504 + x6), tmp65 & xmask, other=0.0)
    tmp67 = tl.full(tmp66.shape, float("-inf"), tmp66.dtype)
    tmp68 = tl.where(tmp65, tmp66, tmp67)
    tmp69 = triton_helpers.maximum(tmp68, tmp64)
    tmp70 = tmp21 > tmp13
    tmp71 = (-21) + x7
    tmp72 = (-22) + x7
    tmp73 = tl.where(tmp70, tmp71, tmp72)
    tmp74 = tmp30 > tmp22
    tmp75 = (-20) + x7
    tmp76 = tl.where(tmp74, tmp75, tmp73)
    tmp77 = tmp39 > tmp31
    tmp78 = (-1) + x7
    tmp79 = tl.where(tmp77, tmp78, tmp76)
    tmp80 = tmp44 > tmp40
    tmp81 = x7
    tmp82 = tl.where(tmp80, tmp81, tmp79)
    tmp83 = tmp49 > tmp45
    tmp84 = 1 + x7
    tmp85 = tl.where(tmp83, tmp84, tmp82)
    tmp86 = tmp58 > tmp50
    tmp87 = 20 + x7
    tmp88 = tl.where(tmp86, tmp87, tmp85)
    tmp89 = tmp63 > tmp59
    tmp90 = 21 + x7
    tmp91 = tl.where(tmp89, tmp90, tmp88)
    tmp92 = tmp68 > tmp64
    tmp93 = 22 + x7
    tmp94 = tl.where(tmp92, tmp93, tmp91)
    tl.store(out_ptr0 + (x6), tmp69, xmask)
    tl.store(out_ptr1 + (x6), tmp94, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/kl/ckliocagiabanvcqzle6p25cncfbn3xpkrg3q37yntoj5mx3tbjo.py
# Source Nodes: [x_537, x_comb_iter_1_right_7], Original ATen: [aten.max_pool2d_with_indices, aten.relu]
# x_537 => relu_104
# x_comb_iter_1_right_7 => getitem_261, max_pool2d_with_indices_22
triton_poi_fused_max_pool2d_with_indices_relu_103 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2097152], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*i64', 4: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_relu_103', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, XBLOCK : tl.constexpr):
    xnumel = 1524096
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    x3 = (xindex // 9072) % 21
    x2 = (xindex // 432) % 21
    x7 = (xindex // 432) % 441
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp1 = triton_helpers.maximum(0, tmp0)
    tmp2 = (-1) + x3
    tmp3 = tl.full([1], 0, tl.int64)
    tmp4 = tmp2 >= tmp3
    tmp5 = tl.full([1], 21, tl.int64)
    tmp6 = tmp2 < tmp5
    tmp7 = tmp4 & tmp6
    tmp8 = (-1) + x2
    tmp9 = tmp8 >= tmp3
    tmp10 = tmp8 < tmp5
    tmp11 = tmp9 & tmp10
    tmp12 = tmp7 & tmp11
    tmp13 = tl.load(in_ptr0 + ((-9504) + x0), tmp12 & xmask, other=0.0)
    tmp14 = tl.full(tmp13.shape, float("-inf"), tmp13.dtype)
    tmp15 = tl.where(tmp12, tmp13, tmp14)
    tmp16 = x2
    tmp17 = tmp16 >= tmp3
    tmp18 = tmp16 < tmp5
    tmp19 = tmp17 & tmp18
    tmp20 = tmp7 & tmp19
    tmp21 = tl.load(in_ptr0 + ((-9072) + x0), tmp20 & xmask, other=0.0)
    tmp22 = tl.full(tmp21.shape, float("-inf"), tmp21.dtype)
    tmp23 = tl.where(tmp20, tmp21, tmp22)
    tmp24 = triton_helpers.maximum(tmp23, tmp15)
    tmp25 = 1 + x2
    tmp26 = tmp25 >= tmp3
    tmp27 = tmp25 < tmp5
    tmp28 = tmp26 & tmp27
    tmp29 = tmp7 & tmp28
    tmp30 = tl.load(in_ptr0 + ((-8640) + x0), tmp29 & xmask, other=0.0)
    tmp31 = tl.full(tmp30.shape, float("-inf"), tmp30.dtype)
    tmp32 = tl.where(tmp29, tmp30, tmp31)
    tmp33 = triton_helpers.maximum(tmp32, tmp24)
    tmp34 = x3
    tmp35 = tmp34 >= tmp3
    tmp36 = tmp34 < tmp5
    tmp37 = tmp35 & tmp36
    tmp38 = tmp37 & tmp11
    tmp39 = tl.load(in_ptr0 + ((-432) + x0), tmp38 & xmask, other=0.0)
    tmp40 = tl.full(tmp39.shape, float("-inf"), tmp39.dtype)
    tmp41 = tl.where(tmp38, tmp39, tmp40)
    tmp42 = triton_helpers.maximum(tmp41, tmp33)
    tmp43 = tmp37 & tmp19
    tmp44 = tl.load(in_ptr0 + (x0), tmp43 & xmask, other=0.0)
    tmp45 = tl.full(tmp44.shape, float("-inf"), tmp44.dtype)
    tmp46 = tl.where(tmp43, tmp44, tmp45)
    tmp47 = triton_helpers.maximum(tmp46, tmp42)
    tmp48 = tmp37 & tmp28
    tmp49 = tl.load(in_ptr0 + (432 + x0), tmp48 & xmask, other=0.0)
    tmp50 = tl.full(tmp49.shape, float("-inf"), tmp49.dtype)
    tmp51 = tl.where(tmp48, tmp49, tmp50)
    tmp52 = triton_helpers.maximum(tmp51, tmp47)
    tmp53 = 1 + x3
    tmp54 = tmp53 >= tmp3
    tmp55 = tmp53 < tmp5
    tmp56 = tmp54 & tmp55
    tmp57 = tmp56 & tmp11
    tmp58 = tl.load(in_ptr0 + (8640 + x0), tmp57 & xmask, other=0.0)
    tmp59 = tl.full(tmp58.shape, float("-inf"), tmp58.dtype)
    tmp60 = tl.where(tmp57, tmp58, tmp59)
    tmp61 = triton_helpers.maximum(tmp60, tmp52)
    tmp62 = tmp56 & tmp19
    tmp63 = tl.load(in_ptr0 + (9072 + x0), tmp62 & xmask, other=0.0)
    tmp64 = tl.full(tmp63.shape, float("-inf"), tmp63.dtype)
    tmp65 = tl.where(tmp62, tmp63, tmp64)
    tmp66 = triton_helpers.maximum(tmp65, tmp61)
    tmp67 = tmp56 & tmp28
    tmp68 = tl.load(in_ptr0 + (9504 + x0), tmp67 & xmask, other=0.0)
    tmp69 = tl.full(tmp68.shape, float("-inf"), tmp68.dtype)
    tmp70 = tl.where(tmp67, tmp68, tmp69)
    tmp71 = triton_helpers.maximum(tmp70, tmp66)
    tmp72 = tmp23 > tmp15
    tmp73 = (-21) + x7
    tmp74 = (-22) + x7
    tmp75 = tl.where(tmp72, tmp73, tmp74)
    tmp76 = tmp32 > tmp24
    tmp77 = (-20) + x7
    tmp78 = tl.where(tmp76, tmp77, tmp75)
    tmp79 = tmp41 > tmp33
    tmp80 = (-1) + x7
    tmp81 = tl.where(tmp79, tmp80, tmp78)
    tmp82 = tmp46 > tmp42
    tmp83 = x7
    tmp84 = tl.where(tmp82, tmp83, tmp81)
    tmp85 = tmp51 > tmp47
    tmp86 = 1 + x7
    tmp87 = tl.where(tmp85, tmp86, tmp84)
    tmp88 = tmp60 > tmp52
    tmp89 = 20 + x7
    tmp90 = tl.where(tmp88, tmp89, tmp87)
    tmp91 = tmp65 > tmp61
    tmp92 = 21 + x7
    tmp93 = tl.where(tmp91, tmp92, tmp90)
    tmp94 = tmp70 > tmp66
    tmp95 = 22 + x7
    tmp96 = tl.where(tmp94, tmp95, tmp93)
    tl.store(out_ptr0 + (x0), tmp1, xmask)
    tl.store(out_ptr1 + (x0), tmp71, xmask)
    tl.store(out_ptr2 + (x0), tmp96, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/2b/c2bzsmll24wtsgu6luqoen6ciq2bh6uwlgr2k2s7xskfibkngubn.py
# Source Nodes: [x_comb_iter_0_left_7, x_comb_iter_35], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_0_left_7 => add_561, add_564, mul_735, mul_741, rsqrt_105, sub_105, var_mean_105
# x_comb_iter_35 => add_565
triton_poi_fused__native_batch_norm_legit_functional_add_104 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4096, 512], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_104', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 3456
    xnumel = 441
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y0 = yindex % 432
    y1 = (yindex // 432)
    tmp0 = tl.load(in_ptr0 + (y0 + (432*x2) + (190512*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (y0), ymask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (y0), ymask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (y0), ymask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (y0 + (432*x2) + (190512*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 3528.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tl.store(out_ptr0 + (x2 + (441*y0) + (952560*y1)), tmp15, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/fx/cfx5updg6f3h5bx35qoonlfldhzepdnirmlnvbtwwsasshaaijbd.py
# Source Nodes: [x_comb_iter_1_left_7, x_comb_iter_36, x_comb_iter_38, x_comb_iter_3_left_7], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_1_left_7 => add_572, add_575, mul_749, mul_755, rsqrt_107, sub_107, var_mean_107
# x_comb_iter_36 => add_576
# x_comb_iter_38 => add_608
# x_comb_iter_3_left_7 => add_604, add_607, mul_791, mul_797, rsqrt_113, sub_113, var_mean_113
triton_poi_fused__native_batch_norm_legit_functional_add_105 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4096, 512], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: 'i32', 14: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(13,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_105', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 3456
    xnumel = 441
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y0 = yindex % 432
    y1 = (yindex // 432)
    tmp0 = tl.load(in_ptr0 + (y0 + (432*x2) + (190512*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (y0), ymask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (y0), ymask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (y0), ymask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (y0 + (432*x2) + (190512*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr6 + (y0 + (432*x2) + (190512*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (y0), ymask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr8 + (y0), ymask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (y0), ymask, eviction_policy='evict_last')
    tmp26 = tl.load(in_ptr10 + (y0), ymask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 3528.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp18 = tmp16 - tmp17
    tmp20 = tmp19 / tmp4
    tmp21 = tmp20 + tmp6
    tmp22 = tl.math.rsqrt(tmp21)
    tmp23 = tmp18 * tmp22
    tmp25 = tmp23 * tmp24
    tmp27 = tmp25 + tmp26
    tmp28 = tmp27 + tmp14
    tl.store(out_ptr0 + (x2 + (441*y0) + (952560*y1)), tmp15, xmask & ymask)
    tl.store(out_ptr1 + (x2 + (441*y0) + (952560*y1)), tmp28, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/wa/cwaqgl2g53shaz3plxnsdqbwt36gmr7kh5vfmspy7lxxe4363ayf.py
# Source Nodes: [x_720], Original ATen: [aten.convolution]
# x_720 => convolution_267
triton_poi_fused_convolution_106 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8192, 512], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_106', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 6912
    xnumel = 441
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 864
    y1 = (yindex // 864)
    tmp0 = tl.load(in_ptr0 + (x2 + (441*y3)), xmask & ymask, eviction_policy='evict_last')
    tl.store(out_ptr0 + (y0 + (864*x2) + (381024*y1)), tmp0, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ca/cca3bp4gk5w4ntkj22onxqkyk2fsmrywhn5qm4m4ciujiiq2hb4d.py
# Source Nodes: [x_left_9], Original ATen: [aten._native_batch_norm_legit_functional]
# x_left_9 => var_mean_144
triton_red_fused__native_batch_norm_legit_functional_107 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[32768, 128],
    reduction_hint=ReductionHint.OUTER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_107', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 24192
    rnumel = 126
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 864
    x1 = (xindex // 864)
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    x3 = xindex
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + (x0 + (864*r2) + (108864*x1)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x3), tmp2, xmask)
    tl.store(out_ptr1 + (x3), tmp3, xmask)
    tl.store(out_ptr2 + (x3), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/eb/cebybpjutmn7alcbot33yrxchmk4efuedncm2nwh7pkb6hxfewss.py
# Source Nodes: [x_left_9], Original ATen: [aten._native_batch_norm_legit_functional]
# x_left_9 => add_771, add_772, add_773, mul_1009, mul_1010, mul_1011, mul_1012, mul_1013, rsqrt_144, squeeze_433, var_mean_144
triton_per_fused__native_batch_norm_legit_functional_108 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[1024, 32],
    reduction_hint=ReductionHint.OUTER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_108', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 864
    rnumel = 28
    RBLOCK: tl.constexpr = 32
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (864*r1)), rmask & xmask, other=0.0)
    tmp1 = tl.load(in_ptr1 + (x0 + (864*r1)), rmask & xmask, other=0.0)
    tmp2 = tl.load(in_ptr2 + (x0 + (864*r1)), rmask & xmask, other=0.0)
    tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
    tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
    tmp7 = tl.where(rmask & xmask, tmp3, 0)
    tmp8 = tl.where(rmask & xmask, tmp4, 0)
    tmp9 = tl.where(rmask & xmask, tmp5, 0)
    tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
    tmp13 = tmp10[:, None]
    tmp14 = tmp11[:, None]
    tmp15 = tmp12[:, None]
    tmp16 = 3528.0
    tmp17 = tmp14 / tmp16
    tmp18 = 0.001
    tmp19 = tmp17 + tmp18
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = 0.1
    tmp22 = tmp13 * tmp21
    tmp24 = 0.9
    tmp25 = tmp23 * tmp24
    tmp26 = tmp22 + tmp25
    tmp27 = 1.0002835270768358
    tmp28 = tmp17 * tmp27
    tmp29 = tmp28 * tmp21
    tmp31 = tmp30 * tmp24
    tmp32 = tmp29 + tmp31
    tl.store(out_ptr2 + (x0), tmp20, xmask)
    tl.store(out_ptr4 + (x0), tmp26, xmask)
    tl.store(out_ptr6 + (x0), tmp32, xmask)
    tl.store(out_ptr0 + (x0), tmp13, xmask)
    tl.store(out_ptr1 + (x0), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/sa/csa5nrpu3w3xreeay5adfeypr7jgfvic5vnact7jr3sy5a5qu4zv.py
# Source Nodes: [x_725, x_left_9], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu, aten.threshold_backward]
# x_725 => relu_144
# x_left_9 => add_771, add_774, mul_1008, mul_1014, rsqrt_144, sub_144, var_mean_144
triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_109 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4194304], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*i1', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_109', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 3048192
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = xindex
    x0 = xindex % 864
    tmp0 = tl.load(in_ptr0 + (x2), xmask)
    tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 3528.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tmp15 = 0.0
    tmp16 = tmp14 <= tmp15
    tl.store(out_ptr0 + (x2), tmp13, xmask)
    tl.store(out_ptr1 + (x2), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/sm/csmzuffq7llrlknprprfsujhcp2c2whosd6zqkn4fgbxajmxyvva.py
# Source Nodes: [x_739, x_right_10], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu, aten.threshold_backward]
# x_739 => relu_146
# x_right_10 => add_776, add_779, mul_1015, mul_1021, rsqrt_145, sub_145, var_mean_145
triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_110 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4194304], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*i1', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_110', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, xnumel, XBLOCK : tl.constexpr):
    xnumel = 3048192
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = xindex
    x0 = xindex % 864
    tmp0 = tl.load(in_ptr0 + (x2), xmask)
    tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 3528.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tmp15 = 0.0
    tmp16 = tmp14 <= tmp15
    tl.store(out_ptr0 + (x2), tmp13, xmask)
    tl.store(out_ptr1 + (x2), tmp14, xmask)
    tl.store(out_ptr2 + (x2), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/uu/cuuiym4prahbr7d5b5ivgv765a67w5m77ynzureyfgiz2eg3i37b.py
# Source Nodes: [x_725, x_727], Original ATen: [aten.constant_pad_nd, aten.relu]
# x_725 => relu_144
# x_727 => constant_pad_nd_30
triton_poi_fused_constant_pad_nd_relu_111 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_relu_111', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 4320000
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 21600) % 25
    x1 = (xindex // 864) % 25
    x3 = (xindex // 540000)
    x4 = xindex % 21600
    x6 = xindex
    tmp0 = (-2) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 21, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-2) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-38016) + x4 + (18144*x2) + (381024*x3)), tmp10 & xmask, other=0.0)
    tmp12 = triton_helpers.maximum(0, tmp11)
    tmp13 = tl.full(tmp12.shape, 0.0, tmp12.dtype)
    tmp14 = tl.where(tmp10, tmp12, tmp13)
    tl.store(out_ptr0 + (x6), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/bt/cbtoiidzba4xhlfkj7dmocuae5n4qssrvplrg3xekchjhdvdo33f.py
# Source Nodes: [x_728], Original ATen: [aten.convolution]
# x_728 => convolution_269
triton_poi_fused_convolution_112 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8192, 128], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_112', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 6912
    xnumel = 121
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 864
    y1 = (yindex // 864)
    tmp0 = tl.load(in_ptr0 + (x2 + (121*y3)), xmask & ymask, eviction_policy='evict_last')
    tl.store(out_ptr0 + (y0 + (864*x2) + (104544*y1)), tmp0, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/fk/cfkcpv7timo4cra3hzwf4dkj7447fjvn4l22tsria2tr6372isng.py
# Source Nodes: [x_730, x_731], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
# x_730 => convolution_270
# x_731 => var_mean_146
triton_red_fused__native_batch_norm_legit_functional_convolution_113 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[8192, 128],
    reduction_hint=ReductionHint.OUTER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_convolution_113', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, out_ptr3, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 6912
    rnumel = 121
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x3 = xindex
    x0 = xindex % 864
    x1 = (xindex // 864)
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + (r2 + (121*x3)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
        tl.store(out_ptr0 + (x0 + (864*r2) + (104544*x1)), tmp0, rmask & xmask)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr1 + (x3), tmp2, xmask)
    tmp7_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp7_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp7_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp5 = tl.load(out_ptr0 + (x0 + (864*r2) + (104544*x1)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp6 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
        tmp7_mean_next, tmp7_m2_next, tmp7_weight_next = triton_helpers.welford_reduce(
            tmp6, tmp7_mean, tmp7_m2, tmp7_weight,
        )
        tmp7_mean = tl.where(rmask & xmask, tmp7_mean_next, tmp7_mean)
        tmp7_m2 = tl.where(rmask & xmask, tmp7_m2_next, tmp7_m2)
        tmp7_weight = tl.where(rmask & xmask, tmp7_weight_next, tmp7_weight)
    tmp7_tmp, tmp8_tmp, tmp9_tmp = triton_helpers.welford(
        tmp7_mean, tmp7_m2, tmp7_weight, 1
    )
    tmp7 = tmp7_tmp[:, None]
    tmp8 = tmp8_tmp[:, None]
    tmp9 = tmp9_tmp[:, None]
    tl.store(out_ptr2 + (x3), tmp8, xmask)
    tl.store(out_ptr3 + (x3), tmp9, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/4x/c4xs5ae6li5df4ejfp4dhqfi3twd6fy26zkxurfupyrs4pol25jq.py
# Source Nodes: [x_731], Original ATen: [aten._native_batch_norm_legit_functional]
# x_731 => add_781, add_782, add_783, mul_1023, mul_1024, mul_1025, mul_1026, mul_1027, rsqrt_146, squeeze_439, var_mean_146
triton_per_fused__native_batch_norm_legit_functional_114 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[1024, 8],
    reduction_hint=ReductionHint.OUTER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10, 11))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_114', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 864
    rnumel = 8
    RBLOCK: tl.constexpr = 8
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (864*r1)), rmask & xmask, other=0.0)
    tmp1 = tl.load(in_ptr1 + (x0 + (864*r1)), rmask & xmask, other=0.0)
    tmp2 = tl.load(in_ptr2 + (x0 + (864*r1)), rmask & xmask, other=0.0)
    tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
    tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
    tmp7 = tl.where(rmask & xmask, tmp3, 0)
    tmp8 = tl.where(rmask & xmask, tmp4, 0)
    tmp9 = tl.where(rmask & xmask, tmp5, 0)
    tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
    tmp13 = tmp10[:, None]
    tmp14 = tmp11[:, None]
    tmp15 = tmp12[:, None]
    tmp16 = 968.0
    tmp17 = tmp14 / tmp16
    tmp18 = 0.001
    tmp19 = tmp17 + tmp18
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = 0.1
    tmp22 = tmp13 * tmp21
    tmp24 = 0.9
    tmp25 = tmp23 * tmp24
    tmp26 = tmp22 + tmp25
    tmp27 = 1.001034126163392
    tmp28 = tmp17 * tmp27
    tmp29 = tmp28 * tmp21
    tmp31 = tmp30 * tmp24
    tmp32 = tmp29 + tmp31
    tl.store(out_ptr2 + (x0), tmp20, xmask)
    tl.store(out_ptr4 + (x0), tmp26, xmask)
    tl.store(out_ptr6 + (x0), tmp32, xmask)
    tl.store(out_ptr0 + (x0), tmp13, xmask)
    tl.store(out_ptr1 + (x0), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/5e/c5e7dadzv5zzkn4sqfpqwawogghd7tlqqtypopk3eeyhvcgf5hbk.py
# Source Nodes: [x_731, x_732], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# x_731 => add_781, add_784, mul_1022, mul_1028, rsqrt_146, sub_146, var_mean_146
# x_732 => relu_145
triton_poi_fused__native_batch_norm_legit_functional_relu_115 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1048576], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_115', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 836352
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = xindex
    x0 = xindex % 864
    tmp0 = tl.load(in_ptr0 + (x2), xmask)
    tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 968.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x2), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/r2/cr256zzo35kmsirjatfwnrpkwui3gmenrp346ueebug5tsnilpxq.py
# Source Nodes: [x_738], Original ATen: [aten.constant_pad_nd]
# x_738 => constant_pad_nd_31
triton_poi_fused_constant_pad_nd_116 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4194304], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_116', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 3656448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 19872) % 23
    x1 = (xindex // 864) % 23
    x3 = (xindex // 457056)
    x4 = xindex % 19872
    x6 = xindex
    tmp0 = (-1) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 21, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-1) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-19008) + x4 + (18144*x2) + (381024*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, float("-inf"), tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/dz/cdztn7ljzkch25ovzgueqdqeqbfkryds5u4wpio3tptxp5vsz4fc.py
# Source Nodes: [x_comb_iter_0_right_10], Original ATen: [aten.max_pool2d_with_indices]
# x_comb_iter_0_right_10 => getitem_357, max_pool2d_with_indices_30
triton_poi_fused_max_pool2d_with_indices_117 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8192, 128], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*i64', 3: 'i32', 4: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_117', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 6912
    xnumel = 121
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex % 11
    x3 = (xindex // 11)
    y0 = yindex % 864
    y1 = (yindex // 864)
    x4 = xindex
    tmp0 = tl.load(in_ptr0 + (y0 + (1728*x2) + (39744*x3) + (457056*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr0 + (864 + y0 + (1728*x2) + (39744*x3) + (457056*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr0 + (1728 + y0 + (1728*x2) + (39744*x3) + (457056*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp5 = tl.load(in_ptr0 + (19872 + y0 + (1728*x2) + (39744*x3) + (457056*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr0 + (20736 + y0 + (1728*x2) + (39744*x3) + (457056*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp9 = tl.load(in_ptr0 + (21600 + y0 + (1728*x2) + (39744*x3) + (457056*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr0 + (39744 + y0 + (1728*x2) + (39744*x3) + (457056*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr0 + (40608 + y0 + (1728*x2) + (39744*x3) + (457056*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr0 + (41472 + y0 + (1728*x2) + (39744*x3) + (457056*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp2 = triton_helpers.maximum(tmp1, tmp0)
    tmp4 = triton_helpers.maximum(tmp3, tmp2)
    tmp6 = triton_helpers.maximum(tmp5, tmp4)
    tmp8 = triton_helpers.maximum(tmp7, tmp6)
    tmp10 = triton_helpers.maximum(tmp9, tmp8)
    tmp12 = triton_helpers.maximum(tmp11, tmp10)
    tmp14 = triton_helpers.maximum(tmp13, tmp12)
    tmp16 = triton_helpers.maximum(tmp15, tmp14)
    tmp17 = tmp1 > tmp0
    tmp18 = 1 + (2*x2) + (46*x3)
    tmp19 = (2*x2) + (46*x3)
    tmp20 = tl.where(tmp17, tmp18, tmp19)
    tmp21 = tmp3 > tmp2
    tmp22 = 2 + (2*x2) + (46*x3)
    tmp23 = tl.where(tmp21, tmp22, tmp20)
    tmp24 = tmp5 > tmp4
    tmp25 = 23 + (2*x2) + (46*x3)
    tmp26 = tl.where(tmp24, tmp25, tmp23)
    tmp27 = tmp7 > tmp6
    tmp28 = 24 + (2*x2) + (46*x3)
    tmp29 = tl.where(tmp27, tmp28, tmp26)
    tmp30 = tmp9 > tmp8
    tmp31 = 25 + (2*x2) + (46*x3)
    tmp32 = tl.where(tmp30, tmp31, tmp29)
    tmp33 = tmp11 > tmp10
    tmp34 = 46 + (2*x2) + (46*x3)
    tmp35 = tl.where(tmp33, tmp34, tmp32)
    tmp36 = tmp13 > tmp12
    tmp37 = 47 + (2*x2) + (46*x3)
    tmp38 = tl.where(tmp36, tmp37, tmp35)
    tmp39 = tmp15 > tmp14
    tmp40 = 48 + (2*x2) + (46*x3)
    tmp41 = tl.where(tmp39, tmp40, tmp38)
    tl.store(out_ptr0 + (y0 + (864*x4) + (104544*y1)), tmp16, xmask & ymask)
    tl.store(out_ptr1 + (y0 + (864*x4) + (104544*y1)), tmp41, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/zw/czw6dhbxzozdt47hjbrd3az3giv6qlu4xoa2p7shuywl27ly2qdi.py
# Source Nodes: [x_741], Original ATen: [aten.constant_pad_nd]
# x_741 => constant_pad_nd_32
triton_poi_fused_constant_pad_nd_118 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_118', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 5038848
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 23328) % 27
    x1 = (xindex // 864) % 27
    x3 = (xindex // 629856)
    x4 = xindex % 23328
    x6 = xindex
    tmp0 = (-3) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 21, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-3) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-57024) + x4 + (18144*x2) + (381024*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/rs/crscu5bomaka2bbsrgn37tj6qp7tmaelrzis2h2iulnphmpkstxh.py
# Source Nodes: [x_755], Original ATen: [aten.constant_pad_nd]
# x_755 => constant_pad_nd_34
triton_poi_fused_constant_pad_nd_119 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_119', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 4320000
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 21600) % 25
    x1 = (xindex // 864) % 25
    x3 = (xindex // 540000)
    x4 = xindex % 21600
    x6 = xindex
    tmp0 = (-2) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 21, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-2) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-38016) + x4 + (18144*x2) + (381024*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ib/cibcen52ew7euj6kfnvrvgzbuyeoous3sm3u3x26x77dnx3d6lrw.py
# Source Nodes: [x_767], Original ATen: [aten.constant_pad_nd]
# x_767 => constant_pad_nd_35
triton_poi_fused_constant_pad_nd_120 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4194304], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_120', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 3656448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 19872) % 23
    x1 = (xindex // 864) % 23
    x3 = (xindex // 457056)
    x4 = xindex % 19872
    x6 = xindex
    tmp0 = (-1) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 21, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-1) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-19008) + x4 + (18144*x2) + (381024*x3)), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ho/choiy37bmpbgzgaxic6zgp6rxvlnwbdbnfxn3g4gfiwylgdeqlx7.py
# Source Nodes: [x_comb_iter_2_left_10, x_comb_iter_2_right_10, x_comb_iter_52], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_2_left_10 => add_808, add_811, mul_1057, mul_1063, rsqrt_151, sub_151, var_mean_151
# x_comb_iter_2_right_10 => add_818, add_821, mul_1071, mul_1077, rsqrt_153, sub_153, var_mean_153
# x_comb_iter_52 => add_822
triton_poi_fused__native_batch_norm_legit_functional_add_121 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1024, 1024], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32', 12: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11, 12))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_121', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 968
    xnumel = 864
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 121
    y1 = (yindex // 121)
    tmp0 = tl.load(in_ptr0 + (x2 + (864*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x2), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x2 + (864*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x2), xmask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x2), xmask, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x2), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x2), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 968.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp13 + tmp25
    tl.store(out_ptr0 + (y0 + (121*x2) + (522720*y1)), tmp26, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/mg/cmglu7g25oadfbca6vgtp7zpjwau4lmhrj6ppivqkb2jj4l673ye.py
# Source Nodes: [x_777], Original ATen: [aten.relu]
# x_777 => relu_152
triton_poi_fused_relu_122 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8192, 128], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_relu_122', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 6912
    xnumel = 121
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y0 = yindex % 864
    y1 = (yindex // 864)
    tmp0 = tl.load(in_ptr0 + (x2 + (121*y0) + (522720*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = triton_helpers.maximum(0, tmp0)
    tl.store(out_ptr0 + (y0 + (864*x2) + (104544*y1)), tmp1, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/wj/cwjhg6kcpve5nuawhufjveeyifpavp76qaye67u2v4oqexulenqw.py
# Source Nodes: [x_725, x_791], Original ATen: [aten.constant_pad_nd, aten.relu]
# x_725 => relu_144
# x_791 => constant_pad_nd_37
triton_poi_fused_constant_pad_nd_relu_123 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4194304], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_relu_123', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 3656448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 19872) % 23
    x1 = (xindex // 864) % 23
    x3 = (xindex // 457056)
    x4 = xindex % 19872
    x6 = xindex
    tmp0 = (-1) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 21, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = (-1) + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + ((-19008) + x4 + (18144*x2) + (381024*x3)), tmp10 & xmask, other=0.0)
    tmp12 = triton_helpers.maximum(0, tmp11)
    tmp13 = tl.full(tmp12.shape, 0.0, tmp12.dtype)
    tmp14 = tl.where(tmp10, tmp12, tmp13)
    tl.store(out_ptr0 + (x6), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/n5/cn5fvvcvflt5hxbm676io7ggborxxv774nipzb3noxstmtkd5l4o.py
# Source Nodes: [x_comb_iter_0_left_10, x_comb_iter_50], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_0_left_10 => add_786, add_789, mul_1029, mul_1035, rsqrt_147, sub_147, var_mean_147
# x_comb_iter_50 => add_790
triton_poi_fused__native_batch_norm_legit_functional_add_124 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1024, 1024], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7, 8))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_124', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 968
    xnumel = 864
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 121
    y1 = (yindex // 121)
    tmp0 = tl.load(in_ptr0 + (x2 + (864*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x2), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x2 + (864*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 968.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tl.store(out_ptr0 + (y0 + (121*x2) + (522720*y1)), tmp15, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/qr/cqrv2xjb2ntleocafaatr7qkevc5qohwmetzyabibxsske237xpj.py
# Source Nodes: [x_comb_iter_1_left_10, x_comb_iter_3_left_10, x_comb_iter_51, x_comb_iter_53], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_1_left_10 => add_797, add_800, mul_1043, mul_1049, rsqrt_149, sub_149, var_mean_149
# x_comb_iter_3_left_10 => add_829, add_832, mul_1085, mul_1091, rsqrt_155, sub_155, var_mean_155
# x_comb_iter_51 => add_801
# x_comb_iter_53 => add_833
triton_poi_fused__native_batch_norm_legit_functional_add_125 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1024, 1024], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: 'i32', 14: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(13, 14))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_125', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 968
    xnumel = 864
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 121
    y1 = (yindex // 121)
    tmp0 = tl.load(in_ptr0 + (x2 + (864*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x2), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x2 + (864*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr6 + (x2 + (864*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x2), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr8 + (x2), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x2), xmask, eviction_policy='evict_last')
    tmp26 = tl.load(in_ptr10 + (x2), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 968.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp18 = tmp16 - tmp17
    tmp20 = tmp19 / tmp4
    tmp21 = tmp20 + tmp6
    tmp22 = tl.math.rsqrt(tmp21)
    tmp23 = tmp18 * tmp22
    tmp25 = tmp23 * tmp24
    tmp27 = tmp25 + tmp26
    tmp28 = tmp27 + tmp14
    tl.store(out_ptr0 + (y0 + (121*x2) + (522720*y1)), tmp15, xmask & ymask)
    tl.store(out_ptr1 + (y0 + (121*x2) + (522720*y1)), tmp28, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/df/cdfyqszff6cg3o4hk5kfjvcsqm4ihjebjr2m4xq2yzwmqs6tz6ei.py
# Source Nodes: [l__mod___cell_9_conv_prev_1x1_path_1_avgpool], Original ATen: [aten.avg_pool2d]
# l__mod___cell_9_conv_prev_1x1_path_1_avgpool => avg_pool2d_6
triton_poi_fused_avg_pool2d_126 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2097152], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_avg_pool2d_126', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 2090880
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex % 2160
    x1 = (xindex // 2160) % 11
    x2 = (xindex // 23760) % 11
    x3 = (xindex // 261360)
    x4 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (4320*x1) + (90720*x2) + (952560*x3)), xmask)
    tmp1 = 1.0
    tmp2 = tmp0 * tmp1
    tl.store(out_ptr0 + (x4), tmp2, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/6f/c6fvc4cu3zrgz6z7rzsynvnd4eyrtifi5v4aklhh4qr2ebpiu7ab.py
# Source Nodes: [l__mod___cell_9_conv_prev_1x1_path_2_pad], Original ATen: [aten.constant_pad_nd]
# l__mod___cell_9_conv_prev_1x1_path_2_pad => constant_pad_nd_39
triton_poi_fused_constant_pad_nd_127 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_127', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 7620480
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 45360) % 21
    x1 = (xindex // 2160) % 21
    x6 = xindex
    tmp0 = 1 + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 21, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = 1 + x1
    tmp6 = tmp5 >= tmp1
    tmp7 = tmp5 < tmp3
    tmp8 = tmp2 & tmp4
    tmp9 = tmp8 & tmp6
    tmp10 = tmp9 & tmp7
    tmp11 = tl.load(in_ptr0 + (47520 + x6), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tl.store(out_ptr0 + (x6), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/zg/czgjtsygmfaaivzajxayuxf3ct2lp36u4akk6jf4f3gp2yolezfz.py
# Source Nodes: [l__mod___cell_9_conv_prev_1x1_path_2_avgpool], Original ATen: [aten.avg_pool2d]
# l__mod___cell_9_conv_prev_1x1_path_2_avgpool => avg_pool2d_7
triton_poi_fused_avg_pool2d_128 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[32768, 128], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_avg_pool2d_128', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 17280
    xnumel = 121
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex % 11
    x3 = (xindex // 11)
    y0 = yindex % 2160
    y1 = (yindex // 2160)
    x4 = xindex
    tmp0 = tl.load(in_ptr0 + (y0 + (4320*x2) + (90720*x3) + (952560*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = 1.0
    tmp2 = tmp0 * tmp1
    tl.store(out_ptr0 + (y0 + (2160*x4) + (261360*y1)), tmp2, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/te/ctepapbwxwt4jrmv66n4vued4mvx6c4gs6x3ru3gab2ecmbe6w2r.py
# Source Nodes: [cat_21, x_left_10], Original ATen: [aten._native_batch_norm_legit_functional, aten.cat]
# cat_21 => cat_14
# x_left_10 => var_mean_159
triton_red_fused__native_batch_norm_legit_functional_cat_129 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[8192, 128],
    reduction_hint=ReductionHint.OUTER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_cat_129', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, out_ptr0, out_ptr1, out_ptr2, out_ptr3, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 6912
    rnumel = 121
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 864
    x1 = (xindex // 864)
    tmp16_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp16_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp16_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    x3 = xindex
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = x0
        tmp1 = tl.full([1, 1], 0, tl.int64)
        tmp2 = tmp0 >= tmp1
        tmp3 = tl.full([1, 1], 432, tl.int64)
        tmp4 = tmp0 < tmp3
        tmp5 = tl.load(in_ptr0 + (r2 + (121*x0) + (52272*x1)), rmask & tmp4 & xmask, eviction_policy='evict_first', other=0.0)
        tmp6 = tl.full(tmp5.shape, 0.0, tmp5.dtype)
        tmp7 = tl.where(tmp4, tmp5, tmp6)
        tmp8 = tmp0 >= tmp3
        tmp9 = tl.full([1, 1], 864, tl.int64)
        tmp10 = tmp0 < tmp9
        tmp11 = tl.load(in_ptr1 + ((-52272) + r2 + (121*x0) + (52272*x1)), rmask & tmp8 & xmask, eviction_policy='evict_first', other=0.0)
        tmp12 = tl.full(tmp11.shape, 0.0, tmp11.dtype)
        tmp13 = tl.where(tmp8, tmp11, tmp12)
        tmp14 = tl.where(tmp4, tmp7, tmp13)
        tmp15 = tl.broadcast_to(tmp14, [XBLOCK, RBLOCK])
        tmp16_mean_next, tmp16_m2_next, tmp16_weight_next = triton_helpers.welford_reduce(
            tmp15, tmp16_mean, tmp16_m2, tmp16_weight,
        )
        tmp16_mean = tl.where(rmask & xmask, tmp16_mean_next, tmp16_mean)
        tmp16_m2 = tl.where(rmask & xmask, tmp16_m2_next, tmp16_m2)
        tmp16_weight = tl.where(rmask & xmask, tmp16_weight_next, tmp16_weight)
        tl.store(out_ptr0 + (x0 + (864*r2) + (104544*x1)), tmp14, rmask & xmask)
    tmp16_tmp, tmp17_tmp, tmp18_tmp = triton_helpers.welford(
        tmp16_mean, tmp16_m2, tmp16_weight, 1
    )
    tmp16 = tmp16_tmp[:, None]
    tmp17 = tmp17_tmp[:, None]
    tmp18 = tmp18_tmp[:, None]
    tl.store(out_ptr1 + (x3), tmp16, xmask)
    tmp21_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp21_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp21_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp19 = tl.load(out_ptr0 + (x0 + (864*r2) + (104544*x1)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK, RBLOCK])
        tmp21_mean_next, tmp21_m2_next, tmp21_weight_next = triton_helpers.welford_reduce(
            tmp20, tmp21_mean, tmp21_m2, tmp21_weight,
        )
        tmp21_mean = tl.where(rmask & xmask, tmp21_mean_next, tmp21_mean)
        tmp21_m2 = tl.where(rmask & xmask, tmp21_m2_next, tmp21_m2)
        tmp21_weight = tl.where(rmask & xmask, tmp21_weight_next, tmp21_weight)
    tmp21_tmp, tmp22_tmp, tmp23_tmp = triton_helpers.welford(
        tmp21_mean, tmp21_m2, tmp21_weight, 1
    )
    tmp21 = tmp21_tmp[:, None]
    tmp22 = tmp22_tmp[:, None]
    tmp23 = tmp23_tmp[:, None]
    tl.store(out_ptr2 + (x3), tmp22, xmask)
    tl.store(out_ptr3 + (x3), tmp23, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/rv/crvjbvykngxunelawp75ulrfseah77zjhl66vwjhx2so4rp2khlv.py
# Source Nodes: [x_810, x_left_10], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# x_810 => relu_159
# x_left_10 => add_851, add_854, mul_1113, mul_1119, rsqrt_159, sub_159, var_mean_159
triton_poi_fused__native_batch_norm_legit_functional_relu_130 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1048576], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_130', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 836352
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = xindex
    x0 = xindex % 864
    tmp0 = tl.load(in_ptr0 + (x2), xmask)
    tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 968.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x2), tmp13, xmask)
    tl.store(out_ptr1 + (x2), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/zy/czy2npczqkxjo6i6bazpykpcnst4du2thwpoi7d4sx4cicyxwuvj.py
# Source Nodes: [x_807], Original ATen: [aten.relu]
# x_807 => relu_158
triton_poi_fused_relu_131 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536, 128], tile_hint=TileHint.SQUARE,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_relu_131', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 34560
    xnumel = 121
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y3 = yindex
    y0 = yindex % 4320
    y1 = (yindex // 4320)
    tmp0 = tl.load(in_ptr0 + (x2 + (121*y3)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = triton_helpers.maximum(0, tmp0)
    tl.store(out_ptr0 + (y0 + (4320*x2) + (522720*y1)), tmp1, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/zu/czuy3xyvjoowqdzjfxekvxbwgmezf2c7663revpckfoo7qazoazx.py
# Source Nodes: [x_comb_iter_4_left_11, x_comb_iter_4_right_11, x_comb_iter_59], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_4_left_11 => add_920, add_923, mul_1204, mul_1210, rsqrt_172, sub_172, var_mean_172
# x_comb_iter_4_right_11 => add_856, add_859, mul_1120, mul_1126, rsqrt_160, sub_160, var_mean_160
# x_comb_iter_59 => add_924
triton_poi_fused__native_batch_norm_legit_functional_add_132 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1024, 1024], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: 'i32', 13: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(12, 13))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_132', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 968
    xnumel = 864
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x1 = xindex
    y0 = yindex
    y2 = yindex % 121
    y3 = (yindex // 121)
    tmp0 = tl.load(in_ptr0 + (x1 + (864*y0)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x1 + (864*y0)), xmask & ymask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x1), xmask, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x1), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 968.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp25 + tmp13
    tl.store(out_ptr0 + (x1 + (864*y0)), tmp13, xmask & ymask)
    tl.store(out_ptr1 + (y2 + (121*x1) + (522720*y3)), tmp26, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/6j/c6jsp4qsru3szqzs2lvlcjtgplofnkryad6g2rlq7pd3n3r6qywx.py
# Source Nodes: [x_comb_iter_0_right_11], Original ATen: [aten.max_pool2d_with_indices]
# x_comb_iter_0_right_11 => getitem_393, max_pool2d_with_indices_33
triton_poi_fused_max_pool2d_with_indices_133 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1048576], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*i64', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_133', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 836352
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x2 = (xindex // 9504) % 11
    x1 = (xindex // 864) % 11
    x6 = xindex
    x7 = (xindex // 864) % 121
    tmp0 = (-1) + x2
    tmp1 = tl.full([1], 0, tl.int64)
    tmp2 = tmp0 >= tmp1
    tmp3 = tl.full([1], 11, tl.int64)
    tmp4 = tmp0 < tmp3
    tmp5 = tmp2 & tmp4
    tmp6 = (-1) + x1
    tmp7 = tmp6 >= tmp1
    tmp8 = tmp6 < tmp3
    tmp9 = tmp7 & tmp8
    tmp10 = tmp5 & tmp9
    tmp11 = tl.load(in_ptr0 + ((-10368) + x6), tmp10 & xmask, other=0.0)
    tmp12 = tl.full(tmp11.shape, float("-inf"), tmp11.dtype)
    tmp13 = tl.where(tmp10, tmp11, tmp12)
    tmp14 = x1
    tmp15 = tmp14 >= tmp1
    tmp16 = tmp14 < tmp3
    tmp17 = tmp15 & tmp16
    tmp18 = tmp5 & tmp17
    tmp19 = tl.load(in_ptr0 + ((-9504) + x6), tmp18 & xmask, other=0.0)
    tmp20 = tl.full(tmp19.shape, float("-inf"), tmp19.dtype)
    tmp21 = tl.where(tmp18, tmp19, tmp20)
    tmp22 = triton_helpers.maximum(tmp21, tmp13)
    tmp23 = 1 + x1
    tmp24 = tmp23 >= tmp1
    tmp25 = tmp23 < tmp3
    tmp26 = tmp24 & tmp25
    tmp27 = tmp5 & tmp26
    tmp28 = tl.load(in_ptr0 + ((-8640) + x6), tmp27 & xmask, other=0.0)
    tmp29 = tl.full(tmp28.shape, float("-inf"), tmp28.dtype)
    tmp30 = tl.where(tmp27, tmp28, tmp29)
    tmp31 = triton_helpers.maximum(tmp30, tmp22)
    tmp32 = x2
    tmp33 = tmp32 >= tmp1
    tmp34 = tmp32 < tmp3
    tmp35 = tmp33 & tmp34
    tmp36 = tmp35 & tmp9
    tmp37 = tl.load(in_ptr0 + ((-864) + x6), tmp36 & xmask, other=0.0)
    tmp38 = tl.full(tmp37.shape, float("-inf"), tmp37.dtype)
    tmp39 = tl.where(tmp36, tmp37, tmp38)
    tmp40 = triton_helpers.maximum(tmp39, tmp31)
    tmp41 = tmp35 & tmp17
    tmp42 = tl.load(in_ptr0 + (x6), tmp41 & xmask, other=0.0)
    tmp43 = tl.full(tmp42.shape, float("-inf"), tmp42.dtype)
    tmp44 = tl.where(tmp41, tmp42, tmp43)
    tmp45 = triton_helpers.maximum(tmp44, tmp40)
    tmp46 = tmp35 & tmp26
    tmp47 = tl.load(in_ptr0 + (864 + x6), tmp46 & xmask, other=0.0)
    tmp48 = tl.full(tmp47.shape, float("-inf"), tmp47.dtype)
    tmp49 = tl.where(tmp46, tmp47, tmp48)
    tmp50 = triton_helpers.maximum(tmp49, tmp45)
    tmp51 = 1 + x2
    tmp52 = tmp51 >= tmp1
    tmp53 = tmp51 < tmp3
    tmp54 = tmp52 & tmp53
    tmp55 = tmp54 & tmp9
    tmp56 = tl.load(in_ptr0 + (8640 + x6), tmp55 & xmask, other=0.0)
    tmp57 = tl.full(tmp56.shape, float("-inf"), tmp56.dtype)
    tmp58 = tl.where(tmp55, tmp56, tmp57)
    tmp59 = triton_helpers.maximum(tmp58, tmp50)
    tmp60 = tmp54 & tmp17
    tmp61 = tl.load(in_ptr0 + (9504 + x6), tmp60 & xmask, other=0.0)
    tmp62 = tl.full(tmp61.shape, float("-inf"), tmp61.dtype)
    tmp63 = tl.where(tmp60, tmp61, tmp62)
    tmp64 = triton_helpers.maximum(tmp63, tmp59)
    tmp65 = tmp54 & tmp26
    tmp66 = tl.load(in_ptr0 + (10368 + x6), tmp65 & xmask, other=0.0)
    tmp67 = tl.full(tmp66.shape, float("-inf"), tmp66.dtype)
    tmp68 = tl.where(tmp65, tmp66, tmp67)
    tmp69 = triton_helpers.maximum(tmp68, tmp64)
    tmp70 = tmp21 > tmp13
    tmp71 = (-11) + x7
    tmp72 = (-12) + x7
    tmp73 = tl.where(tmp70, tmp71, tmp72)
    tmp74 = tmp30 > tmp22
    tmp75 = (-10) + x7
    tmp76 = tl.where(tmp74, tmp75, tmp73)
    tmp77 = tmp39 > tmp31
    tmp78 = (-1) + x7
    tmp79 = tl.where(tmp77, tmp78, tmp76)
    tmp80 = tmp44 > tmp40
    tmp81 = x7
    tmp82 = tl.where(tmp80, tmp81, tmp79)
    tmp83 = tmp49 > tmp45
    tmp84 = 1 + x7
    tmp85 = tl.where(tmp83, tmp84, tmp82)
    tmp86 = tmp58 > tmp50
    tmp87 = 10 + x7
    tmp88 = tl.where(tmp86, tmp87, tmp85)
    tmp89 = tmp63 > tmp59
    tmp90 = 11 + x7
    tmp91 = tl.where(tmp89, tmp90, tmp88)
    tmp92 = tmp68 > tmp64
    tmp93 = 12 + x7
    tmp94 = tl.where(tmp92, tmp93, tmp91)
    tl.store(out_ptr0 + (x6), tmp69, xmask)
    tl.store(out_ptr1 + (x6), tmp94, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ma/cmaj2zgrvevidoxrqac4iplgwg4lcl3x4m5ibwvbhmp2zysseihe.py
# Source Nodes: [x_820, x_comb_iter_1_right_11], Original ATen: [aten.max_pool2d_with_indices, aten.relu]
# x_820 => relu_161
# x_comb_iter_1_right_11 => getitem_399, max_pool2d_with_indices_34
triton_poi_fused_max_pool2d_with_indices_relu_134 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1048576], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*i64', 4: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_relu_134', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, XBLOCK : tl.constexpr):
    xnumel = 836352
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    x3 = (xindex // 9504) % 11
    x2 = (xindex // 864) % 11
    x7 = (xindex // 864) % 121
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp1 = triton_helpers.maximum(0, tmp0)
    tmp2 = (-1) + x3
    tmp3 = tl.full([1], 0, tl.int64)
    tmp4 = tmp2 >= tmp3
    tmp5 = tl.full([1], 11, tl.int64)
    tmp6 = tmp2 < tmp5
    tmp7 = tmp4 & tmp6
    tmp8 = (-1) + x2
    tmp9 = tmp8 >= tmp3
    tmp10 = tmp8 < tmp5
    tmp11 = tmp9 & tmp10
    tmp12 = tmp7 & tmp11
    tmp13 = tl.load(in_ptr0 + ((-10368) + x0), tmp12 & xmask, other=0.0)
    tmp14 = tl.full(tmp13.shape, float("-inf"), tmp13.dtype)
    tmp15 = tl.where(tmp12, tmp13, tmp14)
    tmp16 = x2
    tmp17 = tmp16 >= tmp3
    tmp18 = tmp16 < tmp5
    tmp19 = tmp17 & tmp18
    tmp20 = tmp7 & tmp19
    tmp21 = tl.load(in_ptr0 + ((-9504) + x0), tmp20 & xmask, other=0.0)
    tmp22 = tl.full(tmp21.shape, float("-inf"), tmp21.dtype)
    tmp23 = tl.where(tmp20, tmp21, tmp22)
    tmp24 = triton_helpers.maximum(tmp23, tmp15)
    tmp25 = 1 + x2
    tmp26 = tmp25 >= tmp3
    tmp27 = tmp25 < tmp5
    tmp28 = tmp26 & tmp27
    tmp29 = tmp7 & tmp28
    tmp30 = tl.load(in_ptr0 + ((-8640) + x0), tmp29 & xmask, other=0.0)
    tmp31 = tl.full(tmp30.shape, float("-inf"), tmp30.dtype)
    tmp32 = tl.where(tmp29, tmp30, tmp31)
    tmp33 = triton_helpers.maximum(tmp32, tmp24)
    tmp34 = x3
    tmp35 = tmp34 >= tmp3
    tmp36 = tmp34 < tmp5
    tmp37 = tmp35 & tmp36
    tmp38 = tmp37 & tmp11
    tmp39 = tl.load(in_ptr0 + ((-864) + x0), tmp38 & xmask, other=0.0)
    tmp40 = tl.full(tmp39.shape, float("-inf"), tmp39.dtype)
    tmp41 = tl.where(tmp38, tmp39, tmp40)
    tmp42 = triton_helpers.maximum(tmp41, tmp33)
    tmp43 = tmp37 & tmp19
    tmp44 = tl.load(in_ptr0 + (x0), tmp43 & xmask, other=0.0)
    tmp45 = tl.full(tmp44.shape, float("-inf"), tmp44.dtype)
    tmp46 = tl.where(tmp43, tmp44, tmp45)
    tmp47 = triton_helpers.maximum(tmp46, tmp42)
    tmp48 = tmp37 & tmp28
    tmp49 = tl.load(in_ptr0 + (864 + x0), tmp48 & xmask, other=0.0)
    tmp50 = tl.full(tmp49.shape, float("-inf"), tmp49.dtype)
    tmp51 = tl.where(tmp48, tmp49, tmp50)
    tmp52 = triton_helpers.maximum(tmp51, tmp47)
    tmp53 = 1 + x3
    tmp54 = tmp53 >= tmp3
    tmp55 = tmp53 < tmp5
    tmp56 = tmp54 & tmp55
    tmp57 = tmp56 & tmp11
    tmp58 = tl.load(in_ptr0 + (8640 + x0), tmp57 & xmask, other=0.0)
    tmp59 = tl.full(tmp58.shape, float("-inf"), tmp58.dtype)
    tmp60 = tl.where(tmp57, tmp58, tmp59)
    tmp61 = triton_helpers.maximum(tmp60, tmp52)
    tmp62 = tmp56 & tmp19
    tmp63 = tl.load(in_ptr0 + (9504 + x0), tmp62 & xmask, other=0.0)
    tmp64 = tl.full(tmp63.shape, float("-inf"), tmp63.dtype)
    tmp65 = tl.where(tmp62, tmp63, tmp64)
    tmp66 = triton_helpers.maximum(tmp65, tmp61)
    tmp67 = tmp56 & tmp28
    tmp68 = tl.load(in_ptr0 + (10368 + x0), tmp67 & xmask, other=0.0)
    tmp69 = tl.full(tmp68.shape, float("-inf"), tmp68.dtype)
    tmp70 = tl.where(tmp67, tmp68, tmp69)
    tmp71 = triton_helpers.maximum(tmp70, tmp66)
    tmp72 = tmp23 > tmp15
    tmp73 = (-11) + x7
    tmp74 = (-12) + x7
    tmp75 = tl.where(tmp72, tmp73, tmp74)
    tmp76 = tmp32 > tmp24
    tmp77 = (-10) + x7
    tmp78 = tl.where(tmp76, tmp77, tmp75)
    tmp79 = tmp41 > tmp33
    tmp80 = (-1) + x7
    tmp81 = tl.where(tmp79, tmp80, tmp78)
    tmp82 = tmp46 > tmp42
    tmp83 = x7
    tmp84 = tl.where(tmp82, tmp83, tmp81)
    tmp85 = tmp51 > tmp47
    tmp86 = 1 + x7
    tmp87 = tl.where(tmp85, tmp86, tmp84)
    tmp88 = tmp60 > tmp52
    tmp89 = 10 + x7
    tmp90 = tl.where(tmp88, tmp89, tmp87)
    tmp91 = tmp65 > tmp61
    tmp92 = 11 + x7
    tmp93 = tl.where(tmp91, tmp92, tmp90)
    tmp94 = tmp70 > tmp66
    tmp95 = 12 + x7
    tmp96 = tl.where(tmp94, tmp95, tmp93)
    tl.store(out_ptr0 + (x0), tmp1, xmask)
    tl.store(out_ptr1 + (x0), tmp71, xmask)
    tl.store(out_ptr2 + (x0), tmp96, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/kl/ckl6maztmsqv72uz4n3amf2fpa3qooexxbq5k2kkqau2uhvhitkc.py
# Source Nodes: [x_comb_iter_0_left_11, x_comb_iter_55], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_0_left_11 => add_866, add_869, mul_1134, mul_1140, rsqrt_162, sub_162, var_mean_162
# x_comb_iter_55 => add_870
triton_poi_fused__native_batch_norm_legit_functional_add_135 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8192, 128], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_135', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 6912
    xnumel = 121
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y0 = yindex % 864
    y1 = (yindex // 864)
    tmp0 = tl.load(in_ptr0 + (y0 + (864*x2) + (104544*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (y0), ymask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (y0), ymask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (y0), ymask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (y0 + (864*x2) + (104544*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 968.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tl.store(out_ptr0 + (x2 + (121*y0) + (522720*y1)), tmp15, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/zp/czpgx3zhs4rdzogrepw7gzqeptkdmjc4m3ly6mjltr3qom7kq67j.py
# Source Nodes: [x_comb_iter_1_left_11, x_comb_iter_3_left_11, x_comb_iter_56, x_comb_iter_58], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
# x_comb_iter_1_left_11 => add_877, add_880, mul_1148, mul_1154, rsqrt_164, sub_164, var_mean_164
# x_comb_iter_3_left_11 => add_909, add_912, mul_1190, mul_1196, rsqrt_170, sub_170, var_mean_170
# x_comb_iter_56 => add_881
# x_comb_iter_58 => add_913
triton_poi_fused__native_batch_norm_legit_functional_add_136 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8192, 128], tile_hint=TileHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: 'i32', 14: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(13,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_136', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
    ynumel = 6912
    xnumel = 121
    yoffset = tl.program_id(1) * YBLOCK
    yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
    ymask = yindex < ynumel
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    x2 = xindex
    y0 = yindex % 864
    y1 = (yindex // 864)
    tmp0 = tl.load(in_ptr0 + (y0 + (864*x2) + (104544*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (y0), ymask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (y0), ymask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (y0), ymask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (y0 + (864*x2) + (104544*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr6 + (y0 + (864*x2) + (104544*y1)), xmask & ymask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (y0), ymask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr8 + (y0), ymask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (y0), ymask, eviction_policy='evict_last')
    tmp26 = tl.load(in_ptr10 + (y0), ymask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 968.0
    tmp5 = tmp3 / tmp4
    tmp6 = 0.001
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp18 = tmp16 - tmp17
    tmp20 = tmp19 / tmp4
    tmp21 = tmp20 + tmp6
    tmp22 = tl.math.rsqrt(tmp21)
    tmp23 = tmp18 * tmp22
    tmp25 = tmp23 * tmp24
    tmp27 = tmp25 + tmp26
    tmp28 = tmp27 + tmp14
    tl.store(out_ptr0 + (x2 + (121*y0) + (522720*y1)), tmp15, xmask & ymask)
    tl.store(out_ptr1 + (x2 + (121*y0) + (522720*y1)), tmp28, xmask & ymask)
''')


# kernel path: /tmp/torchinductor_youkaichao/zi/czihrwoz6ji44ubsucbsdyivcclrhbi2v2x7xfzzsvov6vljbter.py
# Source Nodes: [x_1003, x_1004, x_1006], Original ATen: [aten.mean, aten.relu, aten.threshold_backward, aten.view]
# x_1003 => relu_199
# x_1004 => mean
# x_1006 => view
triton_per_fused_mean_relu_threshold_backward_view_137 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[65536, 128],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*i1', 3: 'i32', 4: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_mean_relu_threshold_backward_view_137', 'mutated_arg_names': ['in_out_ptr0']}
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 34560
    rnumel = 121
    RBLOCK: tl.constexpr = 128
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    x2 = xindex % 4320
    x3 = (xindex // 4320)
    tmp0 = tl.load(in_ptr0 + (r1 + (121*x0)), rmask & xmask, other=0.0)
    tmp1 = triton_helpers.maximum(0, tmp0)
    tmp2 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
    tmp4 = tl.where(rmask & xmask, tmp2, 0)
    tmp5 = tl.sum(tmp4, 1)[:, None]
    tmp6 = 0.0
    tmp7 = tmp1 <= tmp6
    tmp8 = 121.0
    tmp9 = tmp5 / tmp8
    tl.store(out_ptr0 + (x2 + (4320*r1) + (522720*x3)), tmp7, rmask & xmask)
    tl.debug_barrier()
    tl.store(in_out_ptr0 + (x0), tmp9, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/oo/cooclris4j3hfihizar4r5aqnf2beh4tmap2fpuspahkznxot3pc.py
# Source Nodes: [add_], Original ATen: [aten.add]
# add_ => add
triton_poi_fused_add_138 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1], 
    filename=__file__,
    triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_138', 'mutated_arg_names': ['in_ptr0', 'out_ptr1']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 1
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    tmp0 = tl.load(in_ptr0 + (0))
    tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
    tmp2 = tl.full([1], 1, tl.int64)
    tmp3 = tmp1 + tmp2
    tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
''')


async_compile.wait(globals())
del async_compile

def call(args):
    primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190, primals_191, primals_192, primals_193, primals_194, primals_195, primals_196, primals_197, primals_198, primals_199, primals_200, primals_201, primals_202, primals_203, primals_204, primals_205, primals_206, primals_207, primals_208, primals_209, primals_210, primals_211, primals_212, primals_213, primals_214, primals_215, primals_216, primals_217, primals_218, primals_219, primals_220, primals_221, primals_222, primals_223, primals_224, primals_225, primals_226, primals_227, primals_228, primals_229, primals_230, primals_231, primals_232, primals_233, primals_234, primals_235, primals_236, primals_237, primals_238, primals_239, primals_240, primals_241, primals_242, primals_243, primals_244, primals_245, primals_246, primals_247, primals_248, primals_249, primals_250, primals_251, primals_252, primals_253, primals_254, primals_255, primals_256, primals_257, primals_258, primals_259, primals_260, primals_261, primals_262, primals_263, primals_264, primals_265, primals_266, primals_267, primals_268, primals_269, primals_270, primals_271, primals_272, primals_273, primals_274, primals_275, primals_276, primals_277, primals_278, primals_279, primals_280, primals_281, primals_282, primals_283, primals_284, primals_285, primals_286, primals_287, primals_288, primals_289, primals_290, primals_291, primals_292, primals_293, primals_294, primals_295, primals_296, primals_297, primals_298, primals_299, primals_300, primals_301, primals_302, primals_303, primals_304, primals_305, primals_306, primals_307, primals_308, primals_309, primals_310, primals_311, primals_312, primals_313, primals_314, primals_315, primals_316, primals_317, primals_318, primals_319, primals_320, primals_321, primals_322, primals_323, primals_324, primals_325, primals_326, primals_327, primals_328, primals_329, primals_330, primals_331, primals_332, primals_333, primals_334, primals_335, primals_336, primals_337, primals_338, primals_339, primals_340, primals_341, primals_342, primals_343, primals_344, primals_345, primals_346, primals_347, primals_348, primals_349, primals_350, primals_351, primals_352, primals_353, primals_354, primals_355, primals_356, primals_357, primals_358, primals_359, primals_360, primals_361, primals_362, primals_363, primals_364, primals_365, primals_366, primals_367, primals_368, primals_369, primals_370, primals_371, primals_372, primals_373, primals_374, primals_375, primals_376, primals_377, primals_378, primals_379, primals_380, primals_381, primals_382, primals_383, primals_384, primals_385, primals_386, primals_387, primals_388, primals_389, primals_390, primals_391, primals_392, primals_393, primals_394, primals_395, primals_396, primals_397, primals_398, primals_399, primals_400, primals_401, primals_402, primals_403, primals_404, primals_405, primals_406, primals_407, primals_408, primals_409, primals_410, primals_411, primals_412, primals_413, primals_414, primals_415, primals_416, primals_417, primals_418, primals_419, primals_420, primals_421, primals_422, primals_423, primals_424, primals_425, primals_426, primals_427, primals_428, primals_429, primals_430, primals_431, primals_432, primals_433, primals_434, primals_435, primals_436, primals_437, primals_438, primals_439, primals_440, primals_441, primals_442, primals_443, primals_444, primals_445, primals_446, primals_447, primals_448, primals_449, primals_450, primals_451, primals_452, primals_453, primals_454, primals_455, primals_456, primals_457, primals_458, primals_459, primals_460, primals_461, primals_462, primals_463, primals_464, primals_465, primals_466, primals_467, primals_468, primals_469, primals_470, primals_471, primals_472, primals_473, primals_474, primals_475, primals_476, primals_477, primals_478, primals_479, primals_480, primals_481, primals_482, primals_483, primals_484, primals_485, primals_486, primals_487, primals_488, primals_489, primals_490, primals_491, primals_492, primals_493, primals_494, primals_495, primals_496, primals_497, primals_498, primals_499, primals_500, primals_501, primals_502, primals_503, primals_504, primals_505, primals_506, primals_507, primals_508, primals_509, primals_510, primals_511, primals_512, primals_513, primals_514, primals_515, primals_516, primals_517, primals_518, primals_519, primals_520, primals_521, primals_522, primals_523, primals_524, primals_525, primals_526, primals_527, primals_528, primals_529, primals_530, primals_531, primals_532, primals_533, primals_534, primals_535, primals_536, primals_537, primals_538, primals_539, primals_540, primals_541, primals_542, primals_543, primals_544, primals_545, primals_546, primals_547, primals_548, primals_549, primals_550, primals_551, primals_552, primals_553, primals_554, primals_555, primals_556, primals_557, primals_558, primals_559, primals_560, primals_561, primals_562, primals_563, primals_564, primals_565, primals_566, primals_567, primals_568, primals_569, primals_570, primals_571, primals_572, primals_573, primals_574, primals_575, primals_576, primals_577, primals_578, primals_579, primals_580, primals_581, primals_582, primals_583, primals_584, primals_585, primals_586, primals_587, primals_588, primals_589, primals_590, primals_591, primals_592, primals_593, primals_594, primals_595, primals_596, primals_597, primals_598, primals_599, primals_600, primals_601, primals_602, primals_603, primals_604, primals_605, primals_606, primals_607, primals_608, primals_609, primals_610, primals_611, primals_612, primals_613, primals_614, primals_615, primals_616, primals_617, primals_618, primals_619, primals_620, primals_621, primals_622, primals_623, primals_624, primals_625, primals_626, primals_627, primals_628, primals_629, primals_630, primals_631, primals_632, primals_633, primals_634, primals_635, primals_636, primals_637, primals_638, primals_639, primals_640, primals_641, primals_642, primals_643, primals_644, primals_645, primals_646, primals_647, primals_648, primals_649, primals_650, primals_651, primals_652, primals_653, primals_654, primals_655, primals_656, primals_657, primals_658, primals_659, primals_660, primals_661, primals_662, primals_663, primals_664, primals_665, primals_666, primals_667, primals_668, primals_669, primals_670, primals_671, primals_672, primals_673, primals_674, primals_675, primals_676, primals_677, primals_678, primals_679, primals_680, primals_681, primals_682, primals_683, primals_684, primals_685, primals_686, primals_687, primals_688, primals_689, primals_690, primals_691, primals_692, primals_693, primals_694, primals_695, primals_696, primals_697, primals_698, primals_699, primals_700, primals_701, primals_702, primals_703, primals_704, primals_705, primals_706, primals_707, primals_708, primals_709, primals_710, primals_711, primals_712, primals_713, primals_714, primals_715, primals_716, primals_717, primals_718, primals_719, primals_720, primals_721, primals_722, primals_723, primals_724, primals_725, primals_726, primals_727, primals_728, primals_729, primals_730, primals_731, primals_732, primals_733, primals_734, primals_735, primals_736, primals_737, primals_738, primals_739, primals_740, primals_741, primals_742, primals_743, primals_744, primals_745, primals_746, primals_747, primals_748, primals_749, primals_750, primals_751, primals_752, primals_753, primals_754, primals_755, primals_756, primals_757, primals_758, primals_759, primals_760, primals_761, primals_762, primals_763, primals_764, primals_765, primals_766, primals_767, primals_768, primals_769, primals_770, primals_771, primals_772, primals_773, primals_774, primals_775, primals_776, primals_777, primals_778, primals_779, primals_780, primals_781, primals_782, primals_783, primals_784, primals_785, primals_786, primals_787, primals_788, primals_789, primals_790, primals_791, primals_792, primals_793, primals_794, primals_795, primals_796, primals_797, primals_798, primals_799, primals_800, primals_801, primals_802, primals_803, primals_804, primals_805, primals_806, primals_807, primals_808, primals_809, primals_810, primals_811, primals_812, primals_813, primals_814, primals_815, primals_816, primals_817, primals_818, primals_819, primals_820, primals_821, primals_822, primals_823, primals_824, primals_825, primals_826, primals_827, primals_828, primals_829, primals_830, primals_831, primals_832, primals_833, primals_834, primals_835, primals_836, primals_837, primals_838, primals_839, primals_840, primals_841, primals_842, primals_843, primals_844, primals_845, primals_846, primals_847, primals_848, primals_849, primals_850, primals_851, primals_852, primals_853, primals_854, primals_855, primals_856, primals_857, primals_858, primals_859, primals_860, primals_861, primals_862, primals_863, primals_864, primals_865, primals_866, primals_867, primals_868, primals_869, primals_870, primals_871, primals_872, primals_873, primals_874, primals_875, primals_876, primals_877, primals_878, primals_879, primals_880, primals_881, primals_882, primals_883, primals_884, primals_885, primals_886, primals_887, primals_888, primals_889, primals_890, primals_891, primals_892, primals_893, primals_894, primals_895, primals_896, primals_897, primals_898, primals_899, primals_900, primals_901, primals_902, primals_903, primals_904, primals_905, primals_906, primals_907, primals_908, primals_909, primals_910, primals_911, primals_912, primals_913, primals_914, primals_915, primals_916, primals_917, primals_918, primals_919, primals_920, primals_921, primals_922, primals_923, primals_924, primals_925, primals_926, primals_927, primals_928, primals_929, primals_930, primals_931, primals_932, primals_933, primals_934, primals_935, primals_936, primals_937, primals_938, primals_939, primals_940, primals_941, primals_942, primals_943, primals_944, primals_945, primals_946, primals_947, primals_948, primals_949, primals_950, primals_951, primals_952, primals_953, primals_954, primals_955, primals_956, primals_957, primals_958, primals_959, primals_960, primals_961, primals_962, primals_963, primals_964, primals_965, primals_966, primals_967, primals_968, primals_969, primals_970, primals_971, primals_972, primals_973, primals_974, primals_975, primals_976, primals_977, primals_978, primals_979, primals_980, primals_981, primals_982, primals_983, primals_984, primals_985, primals_986, primals_987, primals_988, primals_989, primals_990, primals_991, primals_992, primals_993, primals_994, primals_995, primals_996, primals_997, primals_998, primals_999, primals_1000, primals_1001, primals_1002, primals_1003, primals_1004, primals_1005, primals_1006, primals_1007, primals_1008, primals_1009, primals_1010, primals_1011, primals_1012, primals_1013, primals_1014, primals_1015, primals_1016, primals_1017, primals_1018, primals_1019, primals_1020, primals_1021, primals_1022, primals_1023, primals_1024, primals_1025, primals_1026, primals_1027, primals_1028, primals_1029, primals_1030, primals_1031, primals_1032, primals_1033, primals_1034, primals_1035, primals_1036, primals_1037, primals_1038, primals_1039, primals_1040, primals_1041, primals_1042, primals_1043, primals_1044, primals_1045, primals_1046, primals_1047, primals_1048, primals_1049, primals_1050, primals_1051, primals_1052, primals_1053, primals_1054, primals_1055, primals_1056, primals_1057, primals_1058, primals_1059, primals_1060, primals_1061, primals_1062, primals_1063, primals_1064, primals_1065, primals_1066, primals_1067, primals_1068, primals_1069, primals_1070, primals_1071, primals_1072, primals_1073, primals_1074, primals_1075, primals_1076, primals_1077, primals_1078, primals_1079, primals_1080, primals_1081, primals_1082, primals_1083, primals_1084, primals_1085, primals_1086, primals_1087, primals_1088, primals_1089, primals_1090, primals_1091, primals_1092, primals_1093, primals_1094, primals_1095, primals_1096, primals_1097, primals_1098, primals_1099, primals_1100, primals_1101, primals_1102, primals_1103, primals_1104, primals_1105, primals_1106, primals_1107, primals_1108, primals_1109, primals_1110, primals_1111, primals_1112, primals_1113, primals_1114, primals_1115, primals_1116, primals_1117, primals_1118, primals_1119, primals_1120, primals_1121, primals_1122, primals_1123, primals_1124, primals_1125, primals_1126, primals_1127, primals_1128, primals_1129, primals_1130, primals_1131, primals_1132, primals_1133, primals_1134, primals_1135, primals_1136, primals_1137, primals_1138, primals_1139, primals_1140, primals_1141, primals_1142, primals_1143, primals_1144, primals_1145, primals_1146, primals_1147, primals_1148, primals_1149, primals_1150, primals_1151, primals_1152, primals_1153, primals_1154, primals_1155, primals_1156, primals_1157, primals_1158, primals_1159, primals_1160, primals_1161, primals_1162, primals_1163, primals_1164, primals_1165, primals_1166, primals_1167, primals_1168, primals_1169, primals_1170, primals_1171, primals_1172, primals_1173, primals_1174, primals_1175, primals_1176, primals_1177, primals_1178, primals_1179, primals_1180, primals_1181, primals_1182, primals_1183, primals_1184, primals_1185, primals_1186, primals_1187, primals_1188, primals_1189, primals_1190, primals_1191, primals_1192, primals_1193, primals_1194, primals_1195, primals_1196, primals_1197, primals_1198, primals_1199, primals_1200, primals_1201, primals_1202, primals_1203, primals_1204, primals_1205, primals_1206, primals_1207, primals_1208, primals_1209, primals_1210, primals_1211, primals_1212, primals_1213, primals_1214, primals_1215, primals_1216, primals_1217, primals_1218, primals_1219, primals_1220, primals_1221, primals_1222, primals_1223, primals_1224, primals_1225, primals_1226, primals_1227, primals_1228, primals_1229, primals_1230, primals_1231, primals_1232, primals_1233, primals_1234, primals_1235, primals_1236, primals_1237, primals_1238, primals_1239, primals_1240, primals_1241, primals_1242, primals_1243, primals_1244, primals_1245, primals_1246, primals_1247, primals_1248, primals_1249, primals_1250, primals_1251, primals_1252, primals_1253, primals_1254, primals_1255, primals_1256, primals_1257, primals_1258, primals_1259, primals_1260, primals_1261, primals_1262, primals_1263, primals_1264, primals_1265, primals_1266, primals_1267, primals_1268, primals_1269, primals_1270, primals_1271, primals_1272, primals_1273, primals_1274, primals_1275, primals_1276, primals_1277, primals_1278, primals_1279, primals_1280, primals_1281, primals_1282, primals_1283, primals_1284, primals_1285, primals_1286, primals_1287, primals_1288, primals_1289, primals_1290, primals_1291, primals_1292, primals_1293, primals_1294, primals_1295, primals_1296, primals_1297, primals_1298, primals_1299, primals_1300, primals_1301, primals_1302, primals_1303, primals_1304, primals_1305, primals_1306, primals_1307, primals_1308, primals_1309, primals_1310, primals_1311, primals_1312, primals_1313, primals_1314, primals_1315, primals_1316, primals_1317, primals_1318, primals_1319, primals_1320, primals_1321, primals_1322, primals_1323, primals_1324, primals_1325, primals_1326, primals_1327, primals_1328, primals_1329, primals_1330, primals_1331, primals_1332, primals_1333, primals_1334, primals_1335, primals_1336, primals_1337, primals_1338, primals_1339, primals_1340, primals_1341, primals_1342, primals_1343, primals_1344, primals_1345, primals_1346, primals_1347, primals_1348, primals_1349, primals_1350, primals_1351, primals_1352, primals_1353, primals_1354, primals_1355, primals_1356, primals_1357, primals_1358, primals_1359, primals_1360, primals_1361, primals_1362, primals_1363, primals_1364, primals_1365, primals_1366, primals_1367, primals_1368, primals_1369, primals_1370, primals_1371, primals_1372, primals_1373, primals_1374, primals_1375, primals_1376, primals_1377, primals_1378, primals_1379, primals_1380, primals_1381 = args
    args.clear()
    assert_size_stride(primals_1, (96, ), (1, ))
    assert_size_stride(primals_2, (96, ), (1, ))
    assert_size_stride(primals_3, (96, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_4, (54, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_5, (54, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_6, (54, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_7, (96, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_8, (54, 54, 1, 1), (54, 1, 1, 1))
    assert_size_stride(primals_9, (108, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_10, (108, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_11, (108, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_12, (108, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_13, (108, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_14, (108, 108, 1, 1), (108, 1, 1, 1))
    assert_size_stride(primals_15, (432, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_16, (432, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_17, (432, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_18, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_19, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_20, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_21, (864, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_22, (864, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_23, (864, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_24, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_25, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_26, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_27, (96, 3, 3, 3), (27, 9, 3, 1))
    assert_size_stride(primals_28, (54, 96, 1, 1), (96, 1, 1, 1))
    assert_size_stride(primals_29, (54, ), (1, ))
    assert_size_stride(primals_30, (54, ), (1, ))
    assert_size_stride(primals_31, (54, 96, 1, 1), (96, 1, 1, 1))
    assert_size_stride(primals_32, (54, ), (1, ))
    assert_size_stride(primals_33, (54, ), (1, ))
    assert_size_stride(primals_34, (54, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_35, (54, 54, 1, 1), (54, 1, 1, 1))
    assert_size_stride(primals_36, (54, ), (1, ))
    assert_size_stride(primals_37, (54, ), (1, ))
    assert_size_stride(primals_38, (54, 96, 1, 1), (96, 1, 1, 1))
    assert_size_stride(primals_39, (54, ), (1, ))
    assert_size_stride(primals_40, (54, ), (1, ))
    assert_size_stride(primals_41, (54, 54, 1, 1), (54, 1, 1, 1))
    assert_size_stride(primals_42, (54, ), (1, ))
    assert_size_stride(primals_43, (54, ), (1, ))
    assert_size_stride(primals_44, (54, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_45, (54, 54, 1, 1), (54, 1, 1, 1))
    assert_size_stride(primals_46, (54, ), (1, ))
    assert_size_stride(primals_47, (54, ), (1, ))
    assert_size_stride(primals_48, (54, 54, 1, 1), (54, 1, 1, 1))
    assert_size_stride(primals_49, (54, ), (1, ))
    assert_size_stride(primals_50, (54, ), (1, ))
    assert_size_stride(primals_51, (54, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_52, (54, 54, 1, 1), (54, 1, 1, 1))
    assert_size_stride(primals_53, (54, ), (1, ))
    assert_size_stride(primals_54, (54, ), (1, ))
    assert_size_stride(primals_55, (54, 54, 1, 1), (54, 1, 1, 1))
    assert_size_stride(primals_56, (54, ), (1, ))
    assert_size_stride(primals_57, (54, ), (1, ))
    assert_size_stride(primals_58, (54, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_59, (54, 54, 1, 1), (54, 1, 1, 1))
    assert_size_stride(primals_60, (54, ), (1, ))
    assert_size_stride(primals_61, (54, ), (1, ))
    assert_size_stride(primals_62, (54, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_63, (54, 54, 1, 1), (54, 1, 1, 1))
    assert_size_stride(primals_64, (54, ), (1, ))
    assert_size_stride(primals_65, (54, ), (1, ))
    assert_size_stride(primals_66, (54, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_67, (54, 54, 1, 1), (54, 1, 1, 1))
    assert_size_stride(primals_68, (54, ), (1, ))
    assert_size_stride(primals_69, (54, ), (1, ))
    assert_size_stride(primals_70, (54, 96, 1, 1), (96, 1, 1, 1))
    assert_size_stride(primals_71, (54, ), (1, ))
    assert_size_stride(primals_72, (54, ), (1, ))
    assert_size_stride(primals_73, (54, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_74, (54, 54, 1, 1), (54, 1, 1, 1))
    assert_size_stride(primals_75, (54, ), (1, ))
    assert_size_stride(primals_76, (54, ), (1, ))
    assert_size_stride(primals_77, (54, ), (1, ))
    assert_size_stride(primals_78, (54, ), (1, ))
    assert_size_stride(primals_79, (54, 96, 1, 1), (96, 1, 1, 1))
    assert_size_stride(primals_80, (54, 96, 1, 1), (96, 1, 1, 1))
    assert_size_stride(primals_81, (108, ), (1, ))
    assert_size_stride(primals_82, (108, ), (1, ))
    assert_size_stride(primals_83, (108, 270, 1, 1), (270, 1, 1, 1))
    assert_size_stride(primals_84, (108, ), (1, ))
    assert_size_stride(primals_85, (108, ), (1, ))
    assert_size_stride(primals_86, (108, 108, 1, 1), (108, 1, 1, 1))
    assert_size_stride(primals_87, (108, ), (1, ))
    assert_size_stride(primals_88, (108, ), (1, ))
    assert_size_stride(primals_89, (108, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_90, (108, 108, 1, 1), (108, 1, 1, 1))
    assert_size_stride(primals_91, (108, ), (1, ))
    assert_size_stride(primals_92, (108, ), (1, ))
    assert_size_stride(primals_93, (108, 108, 1, 1), (108, 1, 1, 1))
    assert_size_stride(primals_94, (108, ), (1, ))
    assert_size_stride(primals_95, (108, ), (1, ))
    assert_size_stride(primals_96, (108, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_97, (108, 108, 1, 1), (108, 1, 1, 1))
    assert_size_stride(primals_98, (108, ), (1, ))
    assert_size_stride(primals_99, (108, ), (1, ))
    assert_size_stride(primals_100, (108, 108, 1, 1), (108, 1, 1, 1))
    assert_size_stride(primals_101, (108, ), (1, ))
    assert_size_stride(primals_102, (108, ), (1, ))
    assert_size_stride(primals_103, (108, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_104, (108, 108, 1, 1), (108, 1, 1, 1))
    assert_size_stride(primals_105, (108, ), (1, ))
    assert_size_stride(primals_106, (108, ), (1, ))
    assert_size_stride(primals_107, (108, 108, 1, 1), (108, 1, 1, 1))
    assert_size_stride(primals_108, (108, ), (1, ))
    assert_size_stride(primals_109, (108, ), (1, ))
    assert_size_stride(primals_110, (108, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_111, (108, 108, 1, 1), (108, 1, 1, 1))
    assert_size_stride(primals_112, (108, ), (1, ))
    assert_size_stride(primals_113, (108, ), (1, ))
    assert_size_stride(primals_114, (108, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_115, (108, 108, 1, 1), (108, 1, 1, 1))
    assert_size_stride(primals_116, (108, ), (1, ))
    assert_size_stride(primals_117, (108, ), (1, ))
    assert_size_stride(primals_118, (108, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_119, (108, 108, 1, 1), (108, 1, 1, 1))
    assert_size_stride(primals_120, (108, ), (1, ))
    assert_size_stride(primals_121, (108, ), (1, ))
    assert_size_stride(primals_122, (108, 108, 1, 1), (108, 1, 1, 1))
    assert_size_stride(primals_123, (108, ), (1, ))
    assert_size_stride(primals_124, (108, ), (1, ))
    assert_size_stride(primals_125, (108, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_126, (108, 108, 1, 1), (108, 1, 1, 1))
    assert_size_stride(primals_127, (108, ), (1, ))
    assert_size_stride(primals_128, (108, ), (1, ))
    assert_size_stride(primals_129, (108, ), (1, ))
    assert_size_stride(primals_130, (108, ), (1, ))
    assert_size_stride(primals_131, (108, 270, 1, 1), (270, 1, 1, 1))
    assert_size_stride(primals_132, (108, 270, 1, 1), (270, 1, 1, 1))
    assert_size_stride(primals_133, (216, ), (1, ))
    assert_size_stride(primals_134, (216, ), (1, ))
    assert_size_stride(primals_135, (216, 540, 1, 1), (540, 1, 1, 1))
    assert_size_stride(primals_136, (216, ), (1, ))
    assert_size_stride(primals_137, (216, ), (1, ))
    assert_size_stride(primals_138, (216, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_139, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_140, (216, ), (1, ))
    assert_size_stride(primals_141, (216, ), (1, ))
    assert_size_stride(primals_142, (216, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_143, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_144, (216, ), (1, ))
    assert_size_stride(primals_145, (216, ), (1, ))
    assert_size_stride(primals_146, (216, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_147, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_148, (216, ), (1, ))
    assert_size_stride(primals_149, (216, ), (1, ))
    assert_size_stride(primals_150, (216, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_151, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_152, (216, ), (1, ))
    assert_size_stride(primals_153, (216, ), (1, ))
    assert_size_stride(primals_154, (216, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_155, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_156, (216, ), (1, ))
    assert_size_stride(primals_157, (216, ), (1, ))
    assert_size_stride(primals_158, (216, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_159, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_160, (216, ), (1, ))
    assert_size_stride(primals_161, (216, ), (1, ))
    assert_size_stride(primals_162, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_163, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_164, (216, ), (1, ))
    assert_size_stride(primals_165, (216, ), (1, ))
    assert_size_stride(primals_166, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_167, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_168, (216, ), (1, ))
    assert_size_stride(primals_169, (216, ), (1, ))
    assert_size_stride(primals_170, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_171, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_172, (216, ), (1, ))
    assert_size_stride(primals_173, (216, ), (1, ))
    assert_size_stride(primals_174, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_175, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_176, (216, ), (1, ))
    assert_size_stride(primals_177, (216, ), (1, ))
    assert_size_stride(primals_178, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_179, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_180, (216, ), (1, ))
    assert_size_stride(primals_181, (216, ), (1, ))
    assert_size_stride(primals_182, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_183, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_184, (216, ), (1, ))
    assert_size_stride(primals_185, (216, ), (1, ))
    assert_size_stride(primals_186, (216, 540, 1, 1), (540, 1, 1, 1))
    assert_size_stride(primals_187, (216, ), (1, ))
    assert_size_stride(primals_188, (216, ), (1, ))
    assert_size_stride(primals_189, (216, 1080, 1, 1), (1080, 1, 1, 1))
    assert_size_stride(primals_190, (216, ), (1, ))
    assert_size_stride(primals_191, (216, ), (1, ))
    assert_size_stride(primals_192, (216, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_193, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_194, (216, ), (1, ))
    assert_size_stride(primals_195, (216, ), (1, ))
    assert_size_stride(primals_196, (216, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_197, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_198, (216, ), (1, ))
    assert_size_stride(primals_199, (216, ), (1, ))
    assert_size_stride(primals_200, (216, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_201, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_202, (216, ), (1, ))
    assert_size_stride(primals_203, (216, ), (1, ))
    assert_size_stride(primals_204, (216, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_205, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_206, (216, ), (1, ))
    assert_size_stride(primals_207, (216, ), (1, ))
    assert_size_stride(primals_208, (216, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_209, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_210, (216, ), (1, ))
    assert_size_stride(primals_211, (216, ), (1, ))
    assert_size_stride(primals_212, (216, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_213, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_214, (216, ), (1, ))
    assert_size_stride(primals_215, (216, ), (1, ))
    assert_size_stride(primals_216, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_217, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_218, (216, ), (1, ))
    assert_size_stride(primals_219, (216, ), (1, ))
    assert_size_stride(primals_220, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_221, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_222, (216, ), (1, ))
    assert_size_stride(primals_223, (216, ), (1, ))
    assert_size_stride(primals_224, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_225, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_226, (216, ), (1, ))
    assert_size_stride(primals_227, (216, ), (1, ))
    assert_size_stride(primals_228, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_229, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_230, (216, ), (1, ))
    assert_size_stride(primals_231, (216, ), (1, ))
    assert_size_stride(primals_232, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_233, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_234, (216, ), (1, ))
    assert_size_stride(primals_235, (216, ), (1, ))
    assert_size_stride(primals_236, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_237, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_238, (216, ), (1, ))
    assert_size_stride(primals_239, (216, ), (1, ))
    assert_size_stride(primals_240, (216, 1080, 1, 1), (1080, 1, 1, 1))
    assert_size_stride(primals_241, (216, ), (1, ))
    assert_size_stride(primals_242, (216, ), (1, ))
    assert_size_stride(primals_243, (216, 1080, 1, 1), (1080, 1, 1, 1))
    assert_size_stride(primals_244, (216, ), (1, ))
    assert_size_stride(primals_245, (216, ), (1, ))
    assert_size_stride(primals_246, (216, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_247, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_248, (216, ), (1, ))
    assert_size_stride(primals_249, (216, ), (1, ))
    assert_size_stride(primals_250, (216, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_251, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_252, (216, ), (1, ))
    assert_size_stride(primals_253, (216, ), (1, ))
    assert_size_stride(primals_254, (216, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_255, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_256, (216, ), (1, ))
    assert_size_stride(primals_257, (216, ), (1, ))
    assert_size_stride(primals_258, (216, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_259, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_260, (216, ), (1, ))
    assert_size_stride(primals_261, (216, ), (1, ))
    assert_size_stride(primals_262, (216, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_263, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_264, (216, ), (1, ))
    assert_size_stride(primals_265, (216, ), (1, ))
    assert_size_stride(primals_266, (216, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_267, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_268, (216, ), (1, ))
    assert_size_stride(primals_269, (216, ), (1, ))
    assert_size_stride(primals_270, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_271, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_272, (216, ), (1, ))
    assert_size_stride(primals_273, (216, ), (1, ))
    assert_size_stride(primals_274, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_275, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_276, (216, ), (1, ))
    assert_size_stride(primals_277, (216, ), (1, ))
    assert_size_stride(primals_278, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_279, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_280, (216, ), (1, ))
    assert_size_stride(primals_281, (216, ), (1, ))
    assert_size_stride(primals_282, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_283, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_284, (216, ), (1, ))
    assert_size_stride(primals_285, (216, ), (1, ))
    assert_size_stride(primals_286, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_287, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_288, (216, ), (1, ))
    assert_size_stride(primals_289, (216, ), (1, ))
    assert_size_stride(primals_290, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_291, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_292, (216, ), (1, ))
    assert_size_stride(primals_293, (216, ), (1, ))
    assert_size_stride(primals_294, (216, 1080, 1, 1), (1080, 1, 1, 1))
    assert_size_stride(primals_295, (216, ), (1, ))
    assert_size_stride(primals_296, (216, ), (1, ))
    assert_size_stride(primals_297, (216, 1080, 1, 1), (1080, 1, 1, 1))
    assert_size_stride(primals_298, (216, ), (1, ))
    assert_size_stride(primals_299, (216, ), (1, ))
    assert_size_stride(primals_300, (216, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_301, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_302, (216, ), (1, ))
    assert_size_stride(primals_303, (216, ), (1, ))
    assert_size_stride(primals_304, (216, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_305, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_306, (216, ), (1, ))
    assert_size_stride(primals_307, (216, ), (1, ))
    assert_size_stride(primals_308, (216, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_309, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_310, (216, ), (1, ))
    assert_size_stride(primals_311, (216, ), (1, ))
    assert_size_stride(primals_312, (216, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_313, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_314, (216, ), (1, ))
    assert_size_stride(primals_315, (216, ), (1, ))
    assert_size_stride(primals_316, (216, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_317, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_318, (216, ), (1, ))
    assert_size_stride(primals_319, (216, ), (1, ))
    assert_size_stride(primals_320, (216, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_321, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_322, (216, ), (1, ))
    assert_size_stride(primals_323, (216, ), (1, ))
    assert_size_stride(primals_324, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_325, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_326, (216, ), (1, ))
    assert_size_stride(primals_327, (216, ), (1, ))
    assert_size_stride(primals_328, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_329, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_330, (216, ), (1, ))
    assert_size_stride(primals_331, (216, ), (1, ))
    assert_size_stride(primals_332, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_333, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_334, (216, ), (1, ))
    assert_size_stride(primals_335, (216, ), (1, ))
    assert_size_stride(primals_336, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_337, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_338, (216, ), (1, ))
    assert_size_stride(primals_339, (216, ), (1, ))
    assert_size_stride(primals_340, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_341, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_342, (216, ), (1, ))
    assert_size_stride(primals_343, (216, ), (1, ))
    assert_size_stride(primals_344, (216, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_345, (216, 216, 1, 1), (216, 1, 1, 1))
    assert_size_stride(primals_346, (216, ), (1, ))
    assert_size_stride(primals_347, (216, ), (1, ))
    assert_size_stride(primals_348, (432, 1080, 1, 1), (1080, 1, 1, 1))
    assert_size_stride(primals_349, (432, ), (1, ))
    assert_size_stride(primals_350, (432, ), (1, ))
    assert_size_stride(primals_351, (432, 1080, 1, 1), (1080, 1, 1, 1))
    assert_size_stride(primals_352, (432, ), (1, ))
    assert_size_stride(primals_353, (432, ), (1, ))
    assert_size_stride(primals_354, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_355, (432, ), (1, ))
    assert_size_stride(primals_356, (432, ), (1, ))
    assert_size_stride(primals_357, (432, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_358, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_359, (432, ), (1, ))
    assert_size_stride(primals_360, (432, ), (1, ))
    assert_size_stride(primals_361, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_362, (432, ), (1, ))
    assert_size_stride(primals_363, (432, ), (1, ))
    assert_size_stride(primals_364, (432, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_365, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_366, (432, ), (1, ))
    assert_size_stride(primals_367, (432, ), (1, ))
    assert_size_stride(primals_368, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_369, (432, ), (1, ))
    assert_size_stride(primals_370, (432, ), (1, ))
    assert_size_stride(primals_371, (432, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_372, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_373, (432, ), (1, ))
    assert_size_stride(primals_374, (432, ), (1, ))
    assert_size_stride(primals_375, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_376, (432, ), (1, ))
    assert_size_stride(primals_377, (432, ), (1, ))
    assert_size_stride(primals_378, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_379, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_380, (432, ), (1, ))
    assert_size_stride(primals_381, (432, ), (1, ))
    assert_size_stride(primals_382, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_383, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_384, (432, ), (1, ))
    assert_size_stride(primals_385, (432, ), (1, ))
    assert_size_stride(primals_386, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_387, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_388, (432, ), (1, ))
    assert_size_stride(primals_389, (432, ), (1, ))
    assert_size_stride(primals_390, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_391, (432, ), (1, ))
    assert_size_stride(primals_392, (432, ), (1, ))
    assert_size_stride(primals_393, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_394, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_395, (432, ), (1, ))
    assert_size_stride(primals_396, (432, ), (1, ))
    assert_size_stride(primals_397, (432, ), (1, ))
    assert_size_stride(primals_398, (432, ), (1, ))
    assert_size_stride(primals_399, (216, 1080, 1, 1), (1080, 1, 1, 1))
    assert_size_stride(primals_400, (216, 1080, 1, 1), (1080, 1, 1, 1))
    assert_size_stride(primals_401, (432, ), (1, ))
    assert_size_stride(primals_402, (432, ), (1, ))
    assert_size_stride(primals_403, (432, 2160, 1, 1), (2160, 1, 1, 1))
    assert_size_stride(primals_404, (432, ), (1, ))
    assert_size_stride(primals_405, (432, ), (1, ))
    assert_size_stride(primals_406, (432, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_407, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_408, (432, ), (1, ))
    assert_size_stride(primals_409, (432, ), (1, ))
    assert_size_stride(primals_410, (432, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_411, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_412, (432, ), (1, ))
    assert_size_stride(primals_413, (432, ), (1, ))
    assert_size_stride(primals_414, (432, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_415, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_416, (432, ), (1, ))
    assert_size_stride(primals_417, (432, ), (1, ))
    assert_size_stride(primals_418, (432, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_419, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_420, (432, ), (1, ))
    assert_size_stride(primals_421, (432, ), (1, ))
    assert_size_stride(primals_422, (432, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_423, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_424, (432, ), (1, ))
    assert_size_stride(primals_425, (432, ), (1, ))
    assert_size_stride(primals_426, (432, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_427, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_428, (432, ), (1, ))
    assert_size_stride(primals_429, (432, ), (1, ))
    assert_size_stride(primals_430, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_431, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_432, (432, ), (1, ))
    assert_size_stride(primals_433, (432, ), (1, ))
    assert_size_stride(primals_434, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_435, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_436, (432, ), (1, ))
    assert_size_stride(primals_437, (432, ), (1, ))
    assert_size_stride(primals_438, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_439, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_440, (432, ), (1, ))
    assert_size_stride(primals_441, (432, ), (1, ))
    assert_size_stride(primals_442, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_443, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_444, (432, ), (1, ))
    assert_size_stride(primals_445, (432, ), (1, ))
    assert_size_stride(primals_446, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_447, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_448, (432, ), (1, ))
    assert_size_stride(primals_449, (432, ), (1, ))
    assert_size_stride(primals_450, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_451, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_452, (432, ), (1, ))
    assert_size_stride(primals_453, (432, ), (1, ))
    assert_size_stride(primals_454, (432, 2160, 1, 1), (2160, 1, 1, 1))
    assert_size_stride(primals_455, (432, ), (1, ))
    assert_size_stride(primals_456, (432, ), (1, ))
    assert_size_stride(primals_457, (432, 2160, 1, 1), (2160, 1, 1, 1))
    assert_size_stride(primals_458, (432, ), (1, ))
    assert_size_stride(primals_459, (432, ), (1, ))
    assert_size_stride(primals_460, (432, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_461, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_462, (432, ), (1, ))
    assert_size_stride(primals_463, (432, ), (1, ))
    assert_size_stride(primals_464, (432, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_465, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_466, (432, ), (1, ))
    assert_size_stride(primals_467, (432, ), (1, ))
    assert_size_stride(primals_468, (432, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_469, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_470, (432, ), (1, ))
    assert_size_stride(primals_471, (432, ), (1, ))
    assert_size_stride(primals_472, (432, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_473, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_474, (432, ), (1, ))
    assert_size_stride(primals_475, (432, ), (1, ))
    assert_size_stride(primals_476, (432, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_477, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_478, (432, ), (1, ))
    assert_size_stride(primals_479, (432, ), (1, ))
    assert_size_stride(primals_480, (432, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_481, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_482, (432, ), (1, ))
    assert_size_stride(primals_483, (432, ), (1, ))
    assert_size_stride(primals_484, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_485, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_486, (432, ), (1, ))
    assert_size_stride(primals_487, (432, ), (1, ))
    assert_size_stride(primals_488, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_489, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_490, (432, ), (1, ))
    assert_size_stride(primals_491, (432, ), (1, ))
    assert_size_stride(primals_492, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_493, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_494, (432, ), (1, ))
    assert_size_stride(primals_495, (432, ), (1, ))
    assert_size_stride(primals_496, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_497, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_498, (432, ), (1, ))
    assert_size_stride(primals_499, (432, ), (1, ))
    assert_size_stride(primals_500, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_501, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_502, (432, ), (1, ))
    assert_size_stride(primals_503, (432, ), (1, ))
    assert_size_stride(primals_504, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_505, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_506, (432, ), (1, ))
    assert_size_stride(primals_507, (432, ), (1, ))
    assert_size_stride(primals_508, (432, 2160, 1, 1), (2160, 1, 1, 1))
    assert_size_stride(primals_509, (432, ), (1, ))
    assert_size_stride(primals_510, (432, ), (1, ))
    assert_size_stride(primals_511, (432, 2160, 1, 1), (2160, 1, 1, 1))
    assert_size_stride(primals_512, (432, ), (1, ))
    assert_size_stride(primals_513, (432, ), (1, ))
    assert_size_stride(primals_514, (432, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_515, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_516, (432, ), (1, ))
    assert_size_stride(primals_517, (432, ), (1, ))
    assert_size_stride(primals_518, (432, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_519, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_520, (432, ), (1, ))
    assert_size_stride(primals_521, (432, ), (1, ))
    assert_size_stride(primals_522, (432, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_523, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_524, (432, ), (1, ))
    assert_size_stride(primals_525, (432, ), (1, ))
    assert_size_stride(primals_526, (432, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_527, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_528, (432, ), (1, ))
    assert_size_stride(primals_529, (432, ), (1, ))
    assert_size_stride(primals_530, (432, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_531, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_532, (432, ), (1, ))
    assert_size_stride(primals_533, (432, ), (1, ))
    assert_size_stride(primals_534, (432, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_535, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_536, (432, ), (1, ))
    assert_size_stride(primals_537, (432, ), (1, ))
    assert_size_stride(primals_538, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_539, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_540, (432, ), (1, ))
    assert_size_stride(primals_541, (432, ), (1, ))
    assert_size_stride(primals_542, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_543, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_544, (432, ), (1, ))
    assert_size_stride(primals_545, (432, ), (1, ))
    assert_size_stride(primals_546, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_547, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_548, (432, ), (1, ))
    assert_size_stride(primals_549, (432, ), (1, ))
    assert_size_stride(primals_550, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_551, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_552, (432, ), (1, ))
    assert_size_stride(primals_553, (432, ), (1, ))
    assert_size_stride(primals_554, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_555, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_556, (432, ), (1, ))
    assert_size_stride(primals_557, (432, ), (1, ))
    assert_size_stride(primals_558, (432, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_559, (432, 432, 1, 1), (432, 1, 1, 1))
    assert_size_stride(primals_560, (432, ), (1, ))
    assert_size_stride(primals_561, (432, ), (1, ))
    assert_size_stride(primals_562, (864, 2160, 1, 1), (2160, 1, 1, 1))
    assert_size_stride(primals_563, (864, ), (1, ))
    assert_size_stride(primals_564, (864, ), (1, ))
    assert_size_stride(primals_565, (864, 2160, 1, 1), (2160, 1, 1, 1))
    assert_size_stride(primals_566, (864, ), (1, ))
    assert_size_stride(primals_567, (864, ), (1, ))
    assert_size_stride(primals_568, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_569, (864, ), (1, ))
    assert_size_stride(primals_570, (864, ), (1, ))
    assert_size_stride(primals_571, (864, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_572, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_573, (864, ), (1, ))
    assert_size_stride(primals_574, (864, ), (1, ))
    assert_size_stride(primals_575, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_576, (864, ), (1, ))
    assert_size_stride(primals_577, (864, ), (1, ))
    assert_size_stride(primals_578, (864, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_579, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_580, (864, ), (1, ))
    assert_size_stride(primals_581, (864, ), (1, ))
    assert_size_stride(primals_582, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_583, (864, ), (1, ))
    assert_size_stride(primals_584, (864, ), (1, ))
    assert_size_stride(primals_585, (864, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_586, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_587, (864, ), (1, ))
    assert_size_stride(primals_588, (864, ), (1, ))
    assert_size_stride(primals_589, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_590, (864, ), (1, ))
    assert_size_stride(primals_591, (864, ), (1, ))
    assert_size_stride(primals_592, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_593, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_594, (864, ), (1, ))
    assert_size_stride(primals_595, (864, ), (1, ))
    assert_size_stride(primals_596, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_597, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_598, (864, ), (1, ))
    assert_size_stride(primals_599, (864, ), (1, ))
    assert_size_stride(primals_600, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_601, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_602, (864, ), (1, ))
    assert_size_stride(primals_603, (864, ), (1, ))
    assert_size_stride(primals_604, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_605, (864, ), (1, ))
    assert_size_stride(primals_606, (864, ), (1, ))
    assert_size_stride(primals_607, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_608, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_609, (864, ), (1, ))
    assert_size_stride(primals_610, (864, ), (1, ))
    assert_size_stride(primals_611, (864, ), (1, ))
    assert_size_stride(primals_612, (864, ), (1, ))
    assert_size_stride(primals_613, (432, 2160, 1, 1), (2160, 1, 1, 1))
    assert_size_stride(primals_614, (432, 2160, 1, 1), (2160, 1, 1, 1))
    assert_size_stride(primals_615, (864, ), (1, ))
    assert_size_stride(primals_616, (864, ), (1, ))
    assert_size_stride(primals_617, (864, 4320, 1, 1), (4320, 1, 1, 1))
    assert_size_stride(primals_618, (864, ), (1, ))
    assert_size_stride(primals_619, (864, ), (1, ))
    assert_size_stride(primals_620, (864, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_621, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_622, (864, ), (1, ))
    assert_size_stride(primals_623, (864, ), (1, ))
    assert_size_stride(primals_624, (864, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_625, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_626, (864, ), (1, ))
    assert_size_stride(primals_627, (864, ), (1, ))
    assert_size_stride(primals_628, (864, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_629, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_630, (864, ), (1, ))
    assert_size_stride(primals_631, (864, ), (1, ))
    assert_size_stride(primals_632, (864, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_633, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_634, (864, ), (1, ))
    assert_size_stride(primals_635, (864, ), (1, ))
    assert_size_stride(primals_636, (864, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_637, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_638, (864, ), (1, ))
    assert_size_stride(primals_639, (864, ), (1, ))
    assert_size_stride(primals_640, (864, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_641, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_642, (864, ), (1, ))
    assert_size_stride(primals_643, (864, ), (1, ))
    assert_size_stride(primals_644, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_645, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_646, (864, ), (1, ))
    assert_size_stride(primals_647, (864, ), (1, ))
    assert_size_stride(primals_648, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_649, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_650, (864, ), (1, ))
    assert_size_stride(primals_651, (864, ), (1, ))
    assert_size_stride(primals_652, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_653, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_654, (864, ), (1, ))
    assert_size_stride(primals_655, (864, ), (1, ))
    assert_size_stride(primals_656, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_657, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_658, (864, ), (1, ))
    assert_size_stride(primals_659, (864, ), (1, ))
    assert_size_stride(primals_660, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_661, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_662, (864, ), (1, ))
    assert_size_stride(primals_663, (864, ), (1, ))
    assert_size_stride(primals_664, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_665, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_666, (864, ), (1, ))
    assert_size_stride(primals_667, (864, ), (1, ))
    assert_size_stride(primals_668, (864, 4320, 1, 1), (4320, 1, 1, 1))
    assert_size_stride(primals_669, (864, ), (1, ))
    assert_size_stride(primals_670, (864, ), (1, ))
    assert_size_stride(primals_671, (864, 4320, 1, 1), (4320, 1, 1, 1))
    assert_size_stride(primals_672, (864, ), (1, ))
    assert_size_stride(primals_673, (864, ), (1, ))
    assert_size_stride(primals_674, (864, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_675, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_676, (864, ), (1, ))
    assert_size_stride(primals_677, (864, ), (1, ))
    assert_size_stride(primals_678, (864, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_679, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_680, (864, ), (1, ))
    assert_size_stride(primals_681, (864, ), (1, ))
    assert_size_stride(primals_682, (864, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_683, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_684, (864, ), (1, ))
    assert_size_stride(primals_685, (864, ), (1, ))
    assert_size_stride(primals_686, (864, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_687, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_688, (864, ), (1, ))
    assert_size_stride(primals_689, (864, ), (1, ))
    assert_size_stride(primals_690, (864, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_691, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_692, (864, ), (1, ))
    assert_size_stride(primals_693, (864, ), (1, ))
    assert_size_stride(primals_694, (864, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_695, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_696, (864, ), (1, ))
    assert_size_stride(primals_697, (864, ), (1, ))
    assert_size_stride(primals_698, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_699, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_700, (864, ), (1, ))
    assert_size_stride(primals_701, (864, ), (1, ))
    assert_size_stride(primals_702, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_703, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_704, (864, ), (1, ))
    assert_size_stride(primals_705, (864, ), (1, ))
    assert_size_stride(primals_706, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_707, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_708, (864, ), (1, ))
    assert_size_stride(primals_709, (864, ), (1, ))
    assert_size_stride(primals_710, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_711, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_712, (864, ), (1, ))
    assert_size_stride(primals_713, (864, ), (1, ))
    assert_size_stride(primals_714, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_715, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_716, (864, ), (1, ))
    assert_size_stride(primals_717, (864, ), (1, ))
    assert_size_stride(primals_718, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_719, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_720, (864, ), (1, ))
    assert_size_stride(primals_721, (864, ), (1, ))
    assert_size_stride(primals_722, (864, 4320, 1, 1), (4320, 1, 1, 1))
    assert_size_stride(primals_723, (864, ), (1, ))
    assert_size_stride(primals_724, (864, ), (1, ))
    assert_size_stride(primals_725, (864, 4320, 1, 1), (4320, 1, 1, 1))
    assert_size_stride(primals_726, (864, ), (1, ))
    assert_size_stride(primals_727, (864, ), (1, ))
    assert_size_stride(primals_728, (864, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_729, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_730, (864, ), (1, ))
    assert_size_stride(primals_731, (864, ), (1, ))
    assert_size_stride(primals_732, (864, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_733, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_734, (864, ), (1, ))
    assert_size_stride(primals_735, (864, ), (1, ))
    assert_size_stride(primals_736, (864, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_737, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_738, (864, ), (1, ))
    assert_size_stride(primals_739, (864, ), (1, ))
    assert_size_stride(primals_740, (864, 1, 7, 7), (49, 49, 7, 1))
    assert_size_stride(primals_741, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_742, (864, ), (1, ))
    assert_size_stride(primals_743, (864, ), (1, ))
    assert_size_stride(primals_744, (864, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_745, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_746, (864, ), (1, ))
    assert_size_stride(primals_747, (864, ), (1, ))
    assert_size_stride(primals_748, (864, 1, 5, 5), (25, 25, 5, 1))
    assert_size_stride(primals_749, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_750, (864, ), (1, ))
    assert_size_stride(primals_751, (864, ), (1, ))
    assert_size_stride(primals_752, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_753, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_754, (864, ), (1, ))
    assert_size_stride(primals_755, (864, ), (1, ))
    assert_size_stride(primals_756, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_757, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_758, (864, ), (1, ))
    assert_size_stride(primals_759, (864, ), (1, ))
    assert_size_stride(primals_760, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_761, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_762, (864, ), (1, ))
    assert_size_stride(primals_763, (864, ), (1, ))
    assert_size_stride(primals_764, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_765, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_766, (864, ), (1, ))
    assert_size_stride(primals_767, (864, ), (1, ))
    assert_size_stride(primals_768, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_769, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_770, (864, ), (1, ))
    assert_size_stride(primals_771, (864, ), (1, ))
    assert_size_stride(primals_772, (864, 1, 3, 3), (9, 9, 3, 1))
    assert_size_stride(primals_773, (864, 864, 1, 1), (864, 1, 1, 1))
    assert_size_stride(primals_774, (864, ), (1, ))
    assert_size_stride(primals_775, (864, ), (1, ))
    assert_size_stride(primals_776, (1000, 4320), (4320, 1))
    assert_size_stride(primals_777, (1000, ), (1, ))
    assert_size_stride(primals_778, (), ())
    assert_size_stride(primals_779, (96, ), (1, ))
    assert_size_stride(primals_780, (96, ), (1, ))
    assert_size_stride(primals_781, (54, ), (1, ))
    assert_size_stride(primals_782, (54, ), (1, ))
    assert_size_stride(primals_783, (), ())
    assert_size_stride(primals_784, (54, ), (1, ))
    assert_size_stride(primals_785, (54, ), (1, ))
    assert_size_stride(primals_786, (), ())
    assert_size_stride(primals_787, (54, ), (1, ))
    assert_size_stride(primals_788, (54, ), (1, ))
    assert_size_stride(primals_789, (), ())
    assert_size_stride(primals_790, (54, ), (1, ))
    assert_size_stride(primals_791, (54, ), (1, ))
    assert_size_stride(primals_792, (), ())
    assert_size_stride(primals_793, (54, ), (1, ))
    assert_size_stride(primals_794, (54, ), (1, ))
    assert_size_stride(primals_795, (), ())
    assert_size_stride(primals_796, (54, ), (1, ))
    assert_size_stride(primals_797, (54, ), (1, ))
    assert_size_stride(primals_798, (), ())
    assert_size_stride(primals_799, (54, ), (1, ))
    assert_size_stride(primals_800, (54, ), (1, ))
    assert_size_stride(primals_801, (), ())
    assert_size_stride(primals_802, (54, ), (1, ))
    assert_size_stride(primals_803, (54, ), (1, ))
    assert_size_stride(primals_804, (), ())
    assert_size_stride(primals_805, (54, ), (1, ))
    assert_size_stride(primals_806, (54, ), (1, ))
    assert_size_stride(primals_807, (), ())
    assert_size_stride(primals_808, (54, ), (1, ))
    assert_size_stride(primals_809, (54, ), (1, ))
    assert_size_stride(primals_810, (), ())
    assert_size_stride(primals_811, (54, ), (1, ))
    assert_size_stride(primals_812, (54, ), (1, ))
    assert_size_stride(primals_813, (), ())
    assert_size_stride(primals_814, (54, ), (1, ))
    assert_size_stride(primals_815, (54, ), (1, ))
    assert_size_stride(primals_816, (), ())
    assert_size_stride(primals_817, (54, ), (1, ))
    assert_size_stride(primals_818, (54, ), (1, ))
    assert_size_stride(primals_819, (), ())
    assert_size_stride(primals_820, (54, ), (1, ))
    assert_size_stride(primals_821, (54, ), (1, ))
    assert_size_stride(primals_822, (), ())
    assert_size_stride(primals_823, (54, ), (1, ))
    assert_size_stride(primals_824, (54, ), (1, ))
    assert_size_stride(primals_825, (), ())
    assert_size_stride(primals_826, (108, ), (1, ))
    assert_size_stride(primals_827, (108, ), (1, ))
    assert_size_stride(primals_828, (), ())
    assert_size_stride(primals_829, (108, ), (1, ))
    assert_size_stride(primals_830, (108, ), (1, ))
    assert_size_stride(primals_831, (), ())
    assert_size_stride(primals_832, (108, ), (1, ))
    assert_size_stride(primals_833, (108, ), (1, ))
    assert_size_stride(primals_834, (), ())
    assert_size_stride(primals_835, (108, ), (1, ))
    assert_size_stride(primals_836, (108, ), (1, ))
    assert_size_stride(primals_837, (), ())
    assert_size_stride(primals_838, (108, ), (1, ))
    assert_size_stride(primals_839, (108, ), (1, ))
    assert_size_stride(primals_840, (), ())
    assert_size_stride(primals_841, (108, ), (1, ))
    assert_size_stride(primals_842, (108, ), (1, ))
    assert_size_stride(primals_843, (), ())
    assert_size_stride(primals_844, (108, ), (1, ))
    assert_size_stride(primals_845, (108, ), (1, ))
    assert_size_stride(primals_846, (), ())
    assert_size_stride(primals_847, (108, ), (1, ))
    assert_size_stride(primals_848, (108, ), (1, ))
    assert_size_stride(primals_849, (), ())
    assert_size_stride(primals_850, (108, ), (1, ))
    assert_size_stride(primals_851, (108, ), (1, ))
    assert_size_stride(primals_852, (), ())
    assert_size_stride(primals_853, (108, ), (1, ))
    assert_size_stride(primals_854, (108, ), (1, ))
    assert_size_stride(primals_855, (), ())
    assert_size_stride(primals_856, (108, ), (1, ))
    assert_size_stride(primals_857, (108, ), (1, ))
    assert_size_stride(primals_858, (), ())
    assert_size_stride(primals_859, (108, ), (1, ))
    assert_size_stride(primals_860, (108, ), (1, ))
    assert_size_stride(primals_861, (), ())
    assert_size_stride(primals_862, (108, ), (1, ))
    assert_size_stride(primals_863, (108, ), (1, ))
    assert_size_stride(primals_864, (), ())
    assert_size_stride(primals_865, (108, ), (1, ))
    assert_size_stride(primals_866, (108, ), (1, ))
    assert_size_stride(primals_867, (), ())
    assert_size_stride(primals_868, (108, ), (1, ))
    assert_size_stride(primals_869, (108, ), (1, ))
    assert_size_stride(primals_870, (), ())
    assert_size_stride(primals_871, (216, ), (1, ))
    assert_size_stride(primals_872, (216, ), (1, ))
    assert_size_stride(primals_873, (), ())
    assert_size_stride(primals_874, (216, ), (1, ))
    assert_size_stride(primals_875, (216, ), (1, ))
    assert_size_stride(primals_876, (), ())
    assert_size_stride(primals_877, (216, ), (1, ))
    assert_size_stride(primals_878, (216, ), (1, ))
    assert_size_stride(primals_879, (), ())
    assert_size_stride(primals_880, (216, ), (1, ))
    assert_size_stride(primals_881, (216, ), (1, ))
    assert_size_stride(primals_882, (), ())
    assert_size_stride(primals_883, (216, ), (1, ))
    assert_size_stride(primals_884, (216, ), (1, ))
    assert_size_stride(primals_885, (), ())
    assert_size_stride(primals_886, (216, ), (1, ))
    assert_size_stride(primals_887, (216, ), (1, ))
    assert_size_stride(primals_888, (), ())
    assert_size_stride(primals_889, (216, ), (1, ))
    assert_size_stride(primals_890, (216, ), (1, ))
    assert_size_stride(primals_891, (), ())
    assert_size_stride(primals_892, (216, ), (1, ))
    assert_size_stride(primals_893, (216, ), (1, ))
    assert_size_stride(primals_894, (), ())
    assert_size_stride(primals_895, (216, ), (1, ))
    assert_size_stride(primals_896, (216, ), (1, ))
    assert_size_stride(primals_897, (), ())
    assert_size_stride(primals_898, (216, ), (1, ))
    assert_size_stride(primals_899, (216, ), (1, ))
    assert_size_stride(primals_900, (), ())
    assert_size_stride(primals_901, (216, ), (1, ))
    assert_size_stride(primals_902, (216, ), (1, ))
    assert_size_stride(primals_903, (), ())
    assert_size_stride(primals_904, (216, ), (1, ))
    assert_size_stride(primals_905, (216, ), (1, ))
    assert_size_stride(primals_906, (), ())
    assert_size_stride(primals_907, (216, ), (1, ))
    assert_size_stride(primals_908, (216, ), (1, ))
    assert_size_stride(primals_909, (), ())
    assert_size_stride(primals_910, (216, ), (1, ))
    assert_size_stride(primals_911, (216, ), (1, ))
    assert_size_stride(primals_912, (), ())
    assert_size_stride(primals_913, (216, ), (1, ))
    assert_size_stride(primals_914, (216, ), (1, ))
    assert_size_stride(primals_915, (), ())
    assert_size_stride(primals_916, (216, ), (1, ))
    assert_size_stride(primals_917, (216, ), (1, ))
    assert_size_stride(primals_918, (), ())
    assert_size_stride(primals_919, (216, ), (1, ))
    assert_size_stride(primals_920, (216, ), (1, ))
    assert_size_stride(primals_921, (), ())
    assert_size_stride(primals_922, (216, ), (1, ))
    assert_size_stride(primals_923, (216, ), (1, ))
    assert_size_stride(primals_924, (), ())
    assert_size_stride(primals_925, (216, ), (1, ))
    assert_size_stride(primals_926, (216, ), (1, ))
    assert_size_stride(primals_927, (), ())
    assert_size_stride(primals_928, (216, ), (1, ))
    assert_size_stride(primals_929, (216, ), (1, ))
    assert_size_stride(primals_930, (), ())
    assert_size_stride(primals_931, (216, ), (1, ))
    assert_size_stride(primals_932, (216, ), (1, ))
    assert_size_stride(primals_933, (), ())
    assert_size_stride(primals_934, (216, ), (1, ))
    assert_size_stride(primals_935, (216, ), (1, ))
    assert_size_stride(primals_936, (), ())
    assert_size_stride(primals_937, (216, ), (1, ))
    assert_size_stride(primals_938, (216, ), (1, ))
    assert_size_stride(primals_939, (), ())
    assert_size_stride(primals_940, (216, ), (1, ))
    assert_size_stride(primals_941, (216, ), (1, ))
    assert_size_stride(primals_942, (), ())
    assert_size_stride(primals_943, (216, ), (1, ))
    assert_size_stride(primals_944, (216, ), (1, ))
    assert_size_stride(primals_945, (), ())
    assert_size_stride(primals_946, (216, ), (1, ))
    assert_size_stride(primals_947, (216, ), (1, ))
    assert_size_stride(primals_948, (), ())
    assert_size_stride(primals_949, (216, ), (1, ))
    assert_size_stride(primals_950, (216, ), (1, ))
    assert_size_stride(primals_951, (), ())
    assert_size_stride(primals_952, (216, ), (1, ))
    assert_size_stride(primals_953, (216, ), (1, ))
    assert_size_stride(primals_954, (), ())
    assert_size_stride(primals_955, (216, ), (1, ))
    assert_size_stride(primals_956, (216, ), (1, ))
    assert_size_stride(primals_957, (), ())
    assert_size_stride(primals_958, (216, ), (1, ))
    assert_size_stride(primals_959, (216, ), (1, ))
    assert_size_stride(primals_960, (), ())
    assert_size_stride(primals_961, (216, ), (1, ))
    assert_size_stride(primals_962, (216, ), (1, ))
    assert_size_stride(primals_963, (), ())
    assert_size_stride(primals_964, (216, ), (1, ))
    assert_size_stride(primals_965, (216, ), (1, ))
    assert_size_stride(primals_966, (), ())
    assert_size_stride(primals_967, (216, ), (1, ))
    assert_size_stride(primals_968, (216, ), (1, ))
    assert_size_stride(primals_969, (), ())
    assert_size_stride(primals_970, (216, ), (1, ))
    assert_size_stride(primals_971, (216, ), (1, ))
    assert_size_stride(primals_972, (), ())
    assert_size_stride(primals_973, (216, ), (1, ))
    assert_size_stride(primals_974, (216, ), (1, ))
    assert_size_stride(primals_975, (), ())
    assert_size_stride(primals_976, (216, ), (1, ))
    assert_size_stride(primals_977, (216, ), (1, ))
    assert_size_stride(primals_978, (), ())
    assert_size_stride(primals_979, (216, ), (1, ))
    assert_size_stride(primals_980, (216, ), (1, ))
    assert_size_stride(primals_981, (), ())
    assert_size_stride(primals_982, (216, ), (1, ))
    assert_size_stride(primals_983, (216, ), (1, ))
    assert_size_stride(primals_984, (), ())
    assert_size_stride(primals_985, (216, ), (1, ))
    assert_size_stride(primals_986, (216, ), (1, ))
    assert_size_stride(primals_987, (), ())
    assert_size_stride(primals_988, (216, ), (1, ))
    assert_size_stride(primals_989, (216, ), (1, ))
    assert_size_stride(primals_990, (), ())
    assert_size_stride(primals_991, (216, ), (1, ))
    assert_size_stride(primals_992, (216, ), (1, ))
    assert_size_stride(primals_993, (), ())
    assert_size_stride(primals_994, (216, ), (1, ))
    assert_size_stride(primals_995, (216, ), (1, ))
    assert_size_stride(primals_996, (), ())
    assert_size_stride(primals_997, (216, ), (1, ))
    assert_size_stride(primals_998, (216, ), (1, ))
    assert_size_stride(primals_999, (), ())
    assert_size_stride(primals_1000, (216, ), (1, ))
    assert_size_stride(primals_1001, (216, ), (1, ))
    assert_size_stride(primals_1002, (), ())
    assert_size_stride(primals_1003, (216, ), (1, ))
    assert_size_stride(primals_1004, (216, ), (1, ))
    assert_size_stride(primals_1005, (), ())
    assert_size_stride(primals_1006, (216, ), (1, ))
    assert_size_stride(primals_1007, (216, ), (1, ))
    assert_size_stride(primals_1008, (), ())
    assert_size_stride(primals_1009, (216, ), (1, ))
    assert_size_stride(primals_1010, (216, ), (1, ))
    assert_size_stride(primals_1011, (), ())
    assert_size_stride(primals_1012, (216, ), (1, ))
    assert_size_stride(primals_1013, (216, ), (1, ))
    assert_size_stride(primals_1014, (), ())
    assert_size_stride(primals_1015, (216, ), (1, ))
    assert_size_stride(primals_1016, (216, ), (1, ))
    assert_size_stride(primals_1017, (), ())
    assert_size_stride(primals_1018, (216, ), (1, ))
    assert_size_stride(primals_1019, (216, ), (1, ))
    assert_size_stride(primals_1020, (), ())
    assert_size_stride(primals_1021, (216, ), (1, ))
    assert_size_stride(primals_1022, (216, ), (1, ))
    assert_size_stride(primals_1023, (), ())
    assert_size_stride(primals_1024, (216, ), (1, ))
    assert_size_stride(primals_1025, (216, ), (1, ))
    assert_size_stride(primals_1026, (), ())
    assert_size_stride(primals_1027, (216, ), (1, ))
    assert_size_stride(primals_1028, (216, ), (1, ))
    assert_size_stride(primals_1029, (), ())
    assert_size_stride(primals_1030, (216, ), (1, ))
    assert_size_stride(primals_1031, (216, ), (1, ))
    assert_size_stride(primals_1032, (), ())
    assert_size_stride(primals_1033, (216, ), (1, ))
    assert_size_stride(primals_1034, (216, ), (1, ))
    assert_size_stride(primals_1035, (), ())
    assert_size_stride(primals_1036, (216, ), (1, ))
    assert_size_stride(primals_1037, (216, ), (1, ))
    assert_size_stride(primals_1038, (), ())
    assert_size_stride(primals_1039, (432, ), (1, ))
    assert_size_stride(primals_1040, (432, ), (1, ))
    assert_size_stride(primals_1041, (), ())
    assert_size_stride(primals_1042, (432, ), (1, ))
    assert_size_stride(primals_1043, (432, ), (1, ))
    assert_size_stride(primals_1044, (), ())
    assert_size_stride(primals_1045, (432, ), (1, ))
    assert_size_stride(primals_1046, (432, ), (1, ))
    assert_size_stride(primals_1047, (), ())
    assert_size_stride(primals_1048, (432, ), (1, ))
    assert_size_stride(primals_1049, (432, ), (1, ))
    assert_size_stride(primals_1050, (), ())
    assert_size_stride(primals_1051, (432, ), (1, ))
    assert_size_stride(primals_1052, (432, ), (1, ))
    assert_size_stride(primals_1053, (), ())
    assert_size_stride(primals_1054, (432, ), (1, ))
    assert_size_stride(primals_1055, (432, ), (1, ))
    assert_size_stride(primals_1056, (), ())
    assert_size_stride(primals_1057, (432, ), (1, ))
    assert_size_stride(primals_1058, (432, ), (1, ))
    assert_size_stride(primals_1059, (), ())
    assert_size_stride(primals_1060, (432, ), (1, ))
    assert_size_stride(primals_1061, (432, ), (1, ))
    assert_size_stride(primals_1062, (), ())
    assert_size_stride(primals_1063, (432, ), (1, ))
    assert_size_stride(primals_1064, (432, ), (1, ))
    assert_size_stride(primals_1065, (), ())
    assert_size_stride(primals_1066, (432, ), (1, ))
    assert_size_stride(primals_1067, (432, ), (1, ))
    assert_size_stride(primals_1068, (), ())
    assert_size_stride(primals_1069, (432, ), (1, ))
    assert_size_stride(primals_1070, (432, ), (1, ))
    assert_size_stride(primals_1071, (), ())
    assert_size_stride(primals_1072, (432, ), (1, ))
    assert_size_stride(primals_1073, (432, ), (1, ))
    assert_size_stride(primals_1074, (), ())
    assert_size_stride(primals_1075, (432, ), (1, ))
    assert_size_stride(primals_1076, (432, ), (1, ))
    assert_size_stride(primals_1077, (), ())
    assert_size_stride(primals_1078, (432, ), (1, ))
    assert_size_stride(primals_1079, (432, ), (1, ))
    assert_size_stride(primals_1080, (), ())
    assert_size_stride(primals_1081, (432, ), (1, ))
    assert_size_stride(primals_1082, (432, ), (1, ))
    assert_size_stride(primals_1083, (), ())
    assert_size_stride(primals_1084, (432, ), (1, ))
    assert_size_stride(primals_1085, (432, ), (1, ))
    assert_size_stride(primals_1086, (), ())
    assert_size_stride(primals_1087, (432, ), (1, ))
    assert_size_stride(primals_1088, (432, ), (1, ))
    assert_size_stride(primals_1089, (), ())
    assert_size_stride(primals_1090, (432, ), (1, ))
    assert_size_stride(primals_1091, (432, ), (1, ))
    assert_size_stride(primals_1092, (), ())
    assert_size_stride(primals_1093, (432, ), (1, ))
    assert_size_stride(primals_1094, (432, ), (1, ))
    assert_size_stride(primals_1095, (), ())
    assert_size_stride(primals_1096, (432, ), (1, ))
    assert_size_stride(primals_1097, (432, ), (1, ))
    assert_size_stride(primals_1098, (), ())
    assert_size_stride(primals_1099, (432, ), (1, ))
    assert_size_stride(primals_1100, (432, ), (1, ))
    assert_size_stride(primals_1101, (), ())
    assert_size_stride(primals_1102, (432, ), (1, ))
    assert_size_stride(primals_1103, (432, ), (1, ))
    assert_size_stride(primals_1104, (), ())
    assert_size_stride(primals_1105, (432, ), (1, ))
    assert_size_stride(primals_1106, (432, ), (1, ))
    assert_size_stride(primals_1107, (), ())
    assert_size_stride(primals_1108, (432, ), (1, ))
    assert_size_stride(primals_1109, (432, ), (1, ))
    assert_size_stride(primals_1110, (), ())
    assert_size_stride(primals_1111, (432, ), (1, ))
    assert_size_stride(primals_1112, (432, ), (1, ))
    assert_size_stride(primals_1113, (), ())
    assert_size_stride(primals_1114, (432, ), (1, ))
    assert_size_stride(primals_1115, (432, ), (1, ))
    assert_size_stride(primals_1116, (), ())
    assert_size_stride(primals_1117, (432, ), (1, ))
    assert_size_stride(primals_1118, (432, ), (1, ))
    assert_size_stride(primals_1119, (), ())
    assert_size_stride(primals_1120, (432, ), (1, ))
    assert_size_stride(primals_1121, (432, ), (1, ))
    assert_size_stride(primals_1122, (), ())
    assert_size_stride(primals_1123, (432, ), (1, ))
    assert_size_stride(primals_1124, (432, ), (1, ))
    assert_size_stride(primals_1125, (), ())
    assert_size_stride(primals_1126, (432, ), (1, ))
    assert_size_stride(primals_1127, (432, ), (1, ))
    assert_size_stride(primals_1128, (), ())
    assert_size_stride(primals_1129, (432, ), (1, ))
    assert_size_stride(primals_1130, (432, ), (1, ))
    assert_size_stride(primals_1131, (), ())
    assert_size_stride(primals_1132, (432, ), (1, ))
    assert_size_stride(primals_1133, (432, ), (1, ))
    assert_size_stride(primals_1134, (), ())
    assert_size_stride(primals_1135, (432, ), (1, ))
    assert_size_stride(primals_1136, (432, ), (1, ))
    assert_size_stride(primals_1137, (), ())
    assert_size_stride(primals_1138, (432, ), (1, ))
    assert_size_stride(primals_1139, (432, ), (1, ))
    assert_size_stride(primals_1140, (), ())
    assert_size_stride(primals_1141, (432, ), (1, ))
    assert_size_stride(primals_1142, (432, ), (1, ))
    assert_size_stride(primals_1143, (), ())
    assert_size_stride(primals_1144, (432, ), (1, ))
    assert_size_stride(primals_1145, (432, ), (1, ))
    assert_size_stride(primals_1146, (), ())
    assert_size_stride(primals_1147, (432, ), (1, ))
    assert_size_stride(primals_1148, (432, ), (1, ))
    assert_size_stride(primals_1149, (), ())
    assert_size_stride(primals_1150, (432, ), (1, ))
    assert_size_stride(primals_1151, (432, ), (1, ))
    assert_size_stride(primals_1152, (), ())
    assert_size_stride(primals_1153, (432, ), (1, ))
    assert_size_stride(primals_1154, (432, ), (1, ))
    assert_size_stride(primals_1155, (), ())
    assert_size_stride(primals_1156, (432, ), (1, ))
    assert_size_stride(primals_1157, (432, ), (1, ))
    assert_size_stride(primals_1158, (), ())
    assert_size_stride(primals_1159, (432, ), (1, ))
    assert_size_stride(primals_1160, (432, ), (1, ))
    assert_size_stride(primals_1161, (), ())
    assert_size_stride(primals_1162, (432, ), (1, ))
    assert_size_stride(primals_1163, (432, ), (1, ))
    assert_size_stride(primals_1164, (), ())
    assert_size_stride(primals_1165, (432, ), (1, ))
    assert_size_stride(primals_1166, (432, ), (1, ))
    assert_size_stride(primals_1167, (), ())
    assert_size_stride(primals_1168, (432, ), (1, ))
    assert_size_stride(primals_1169, (432, ), (1, ))
    assert_size_stride(primals_1170, (), ())
    assert_size_stride(primals_1171, (432, ), (1, ))
    assert_size_stride(primals_1172, (432, ), (1, ))
    assert_size_stride(primals_1173, (), ())
    assert_size_stride(primals_1174, (432, ), (1, ))
    assert_size_stride(primals_1175, (432, ), (1, ))
    assert_size_stride(primals_1176, (), ())
    assert_size_stride(primals_1177, (432, ), (1, ))
    assert_size_stride(primals_1178, (432, ), (1, ))
    assert_size_stride(primals_1179, (), ())
    assert_size_stride(primals_1180, (432, ), (1, ))
    assert_size_stride(primals_1181, (432, ), (1, ))
    assert_size_stride(primals_1182, (), ())
    assert_size_stride(primals_1183, (432, ), (1, ))
    assert_size_stride(primals_1184, (432, ), (1, ))
    assert_size_stride(primals_1185, (), ())
    assert_size_stride(primals_1186, (432, ), (1, ))
    assert_size_stride(primals_1187, (432, ), (1, ))
    assert_size_stride(primals_1188, (), ())
    assert_size_stride(primals_1189, (432, ), (1, ))
    assert_size_stride(primals_1190, (432, ), (1, ))
    assert_size_stride(primals_1191, (), ())
    assert_size_stride(primals_1192, (432, ), (1, ))
    assert_size_stride(primals_1193, (432, ), (1, ))
    assert_size_stride(primals_1194, (), ())
    assert_size_stride(primals_1195, (432, ), (1, ))
    assert_size_stride(primals_1196, (432, ), (1, ))
    assert_size_stride(primals_1197, (), ())
    assert_size_stride(primals_1198, (432, ), (1, ))
    assert_size_stride(primals_1199, (432, ), (1, ))
    assert_size_stride(primals_1200, (), ())
    assert_size_stride(primals_1201, (432, ), (1, ))
    assert_size_stride(primals_1202, (432, ), (1, ))
    assert_size_stride(primals_1203, (), ())
    assert_size_stride(primals_1204, (432, ), (1, ))
    assert_size_stride(primals_1205, (432, ), (1, ))
    assert_size_stride(primals_1206, (), ())
    assert_size_stride(primals_1207, (432, ), (1, ))
    assert_size_stride(primals_1208, (432, ), (1, ))
    assert_size_stride(primals_1209, (), ())
    assert_size_stride(primals_1210, (864, ), (1, ))
    assert_size_stride(primals_1211, (864, ), (1, ))
    assert_size_stride(primals_1212, (), ())
    assert_size_stride(primals_1213, (864, ), (1, ))
    assert_size_stride(primals_1214, (864, ), (1, ))
    assert_size_stride(primals_1215, (), ())
    assert_size_stride(primals_1216, (864, ), (1, ))
    assert_size_stride(primals_1217, (864, ), (1, ))
    assert_size_stride(primals_1218, (), ())
    assert_size_stride(primals_1219, (864, ), (1, ))
    assert_size_stride(primals_1220, (864, ), (1, ))
    assert_size_stride(primals_1221, (), ())
    assert_size_stride(primals_1222, (864, ), (1, ))
    assert_size_stride(primals_1223, (864, ), (1, ))
    assert_size_stride(primals_1224, (), ())
    assert_size_stride(primals_1225, (864, ), (1, ))
    assert_size_stride(primals_1226, (864, ), (1, ))
    assert_size_stride(primals_1227, (), ())
    assert_size_stride(primals_1228, (864, ), (1, ))
    assert_size_stride(primals_1229, (864, ), (1, ))
    assert_size_stride(primals_1230, (), ())
    assert_size_stride(primals_1231, (864, ), (1, ))
    assert_size_stride(primals_1232, (864, ), (1, ))
    assert_size_stride(primals_1233, (), ())
    assert_size_stride(primals_1234, (864, ), (1, ))
    assert_size_stride(primals_1235, (864, ), (1, ))
    assert_size_stride(primals_1236, (), ())
    assert_size_stride(primals_1237, (864, ), (1, ))
    assert_size_stride(primals_1238, (864, ), (1, ))
    assert_size_stride(primals_1239, (), ())
    assert_size_stride(primals_1240, (864, ), (1, ))
    assert_size_stride(primals_1241, (864, ), (1, ))
    assert_size_stride(primals_1242, (), ())
    assert_size_stride(primals_1243, (864, ), (1, ))
    assert_size_stride(primals_1244, (864, ), (1, ))
    assert_size_stride(primals_1245, (), ())
    assert_size_stride(primals_1246, (864, ), (1, ))
    assert_size_stride(primals_1247, (864, ), (1, ))
    assert_size_stride(primals_1248, (), ())
    assert_size_stride(primals_1249, (864, ), (1, ))
    assert_size_stride(primals_1250, (864, ), (1, ))
    assert_size_stride(primals_1251, (), ())
    assert_size_stride(primals_1252, (864, ), (1, ))
    assert_size_stride(primals_1253, (864, ), (1, ))
    assert_size_stride(primals_1254, (), ())
    assert_size_stride(primals_1255, (864, ), (1, ))
    assert_size_stride(primals_1256, (864, ), (1, ))
    assert_size_stride(primals_1257, (), ())
    assert_size_stride(primals_1258, (864, ), (1, ))
    assert_size_stride(primals_1259, (864, ), (1, ))
    assert_size_stride(primals_1260, (), ())
    assert_size_stride(primals_1261, (864, ), (1, ))
    assert_size_stride(primals_1262, (864, ), (1, ))
    assert_size_stride(primals_1263, (), ())
    assert_size_stride(primals_1264, (864, ), (1, ))
    assert_size_stride(primals_1265, (864, ), (1, ))
    assert_size_stride(primals_1266, (), ())
    assert_size_stride(primals_1267, (864, ), (1, ))
    assert_size_stride(primals_1268, (864, ), (1, ))
    assert_size_stride(primals_1269, (), ())
    assert_size_stride(primals_1270, (864, ), (1, ))
    assert_size_stride(primals_1271, (864, ), (1, ))
    assert_size_stride(primals_1272, (), ())
    assert_size_stride(primals_1273, (864, ), (1, ))
    assert_size_stride(primals_1274, (864, ), (1, ))
    assert_size_stride(primals_1275, (), ())
    assert_size_stride(primals_1276, (864, ), (1, ))
    assert_size_stride(primals_1277, (864, ), (1, ))
    assert_size_stride(primals_1278, (), ())
    assert_size_stride(primals_1279, (864, ), (1, ))
    assert_size_stride(primals_1280, (864, ), (1, ))
    assert_size_stride(primals_1281, (), ())
    assert_size_stride(primals_1282, (864, ), (1, ))
    assert_size_stride(primals_1283, (864, ), (1, ))
    assert_size_stride(primals_1284, (), ())
    assert_size_stride(primals_1285, (864, ), (1, ))
    assert_size_stride(primals_1286, (864, ), (1, ))
    assert_size_stride(primals_1287, (), ())
    assert_size_stride(primals_1288, (864, ), (1, ))
    assert_size_stride(primals_1289, (864, ), (1, ))
    assert_size_stride(primals_1290, (), ())
    assert_size_stride(primals_1291, (864, ), (1, ))
    assert_size_stride(primals_1292, (864, ), (1, ))
    assert_size_stride(primals_1293, (), ())
    assert_size_stride(primals_1294, (864, ), (1, ))
    assert_size_stride(primals_1295, (864, ), (1, ))
    assert_size_stride(primals_1296, (), ())
    assert_size_stride(primals_1297, (864, ), (1, ))
    assert_size_stride(primals_1298, (864, ), (1, ))
    assert_size_stride(primals_1299, (), ())
    assert_size_stride(primals_1300, (864, ), (1, ))
    assert_size_stride(primals_1301, (864, ), (1, ))
    assert_size_stride(primals_1302, (), ())
    assert_size_stride(primals_1303, (864, ), (1, ))
    assert_size_stride(primals_1304, (864, ), (1, ))
    assert_size_stride(primals_1305, (), ())
    assert_size_stride(primals_1306, (864, ), (1, ))
    assert_size_stride(primals_1307, (864, ), (1, ))
    assert_size_stride(primals_1308, (), ())
    assert_size_stride(primals_1309, (864, ), (1, ))
    assert_size_stride(primals_1310, (864, ), (1, ))
    assert_size_stride(primals_1311, (), ())
    assert_size_stride(primals_1312, (864, ), (1, ))
    assert_size_stride(primals_1313, (864, ), (1, ))
    assert_size_stride(primals_1314, (), ())
    assert_size_stride(primals_1315, (864, ), (1, ))
    assert_size_stride(primals_1316, (864, ), (1, ))
    assert_size_stride(primals_1317, (), ())
    assert_size_stride(primals_1318, (864, ), (1, ))
    assert_size_stride(primals_1319, (864, ), (1, ))
    assert_size_stride(primals_1320, (), ())
    assert_size_stride(primals_1321, (864, ), (1, ))
    assert_size_stride(primals_1322, (864, ), (1, ))
    assert_size_stride(primals_1323, (), ())
    assert_size_stride(primals_1324, (864, ), (1, ))
    assert_size_stride(primals_1325, (864, ), (1, ))
    assert_size_stride(primals_1326, (), ())
    assert_size_stride(primals_1327, (864, ), (1, ))
    assert_size_stride(primals_1328, (864, ), (1, ))
    assert_size_stride(primals_1329, (), ())
    assert_size_stride(primals_1330, (864, ), (1, ))
    assert_size_stride(primals_1331, (864, ), (1, ))
    assert_size_stride(primals_1332, (), ())
    assert_size_stride(primals_1333, (864, ), (1, ))
    assert_size_stride(primals_1334, (864, ), (1, ))
    assert_size_stride(primals_1335, (), ())
    assert_size_stride(primals_1336, (864, ), (1, ))
    assert_size_stride(primals_1337, (864, ), (1, ))
    assert_size_stride(primals_1338, (), ())
    assert_size_stride(primals_1339, (864, ), (1, ))
    assert_size_stride(primals_1340, (864, ), (1, ))
    assert_size_stride(primals_1341, (), ())
    assert_size_stride(primals_1342, (864, ), (1, ))
    assert_size_stride(primals_1343, (864, ), (1, ))
    assert_size_stride(primals_1344, (), ())
    assert_size_stride(primals_1345, (864, ), (1, ))
    assert_size_stride(primals_1346, (864, ), (1, ))
    assert_size_stride(primals_1347, (), ())
    assert_size_stride(primals_1348, (864, ), (1, ))
    assert_size_stride(primals_1349, (864, ), (1, ))
    assert_size_stride(primals_1350, (), ())
    assert_size_stride(primals_1351, (864, ), (1, ))
    assert_size_stride(primals_1352, (864, ), (1, ))
    assert_size_stride(primals_1353, (), ())
    assert_size_stride(primals_1354, (864, ), (1, ))
    assert_size_stride(primals_1355, (864, ), (1, ))
    assert_size_stride(primals_1356, (), ())
    assert_size_stride(primals_1357, (864, ), (1, ))
    assert_size_stride(primals_1358, (864, ), (1, ))
    assert_size_stride(primals_1359, (), ())
    assert_size_stride(primals_1360, (864, ), (1, ))
    assert_size_stride(primals_1361, (864, ), (1, ))
    assert_size_stride(primals_1362, (), ())
    assert_size_stride(primals_1363, (864, ), (1, ))
    assert_size_stride(primals_1364, (864, ), (1, ))
    assert_size_stride(primals_1365, (), ())
    assert_size_stride(primals_1366, (864, ), (1, ))
    assert_size_stride(primals_1367, (864, ), (1, ))
    assert_size_stride(primals_1368, (), ())
    assert_size_stride(primals_1369, (864, ), (1, ))
    assert_size_stride(primals_1370, (864, ), (1, ))
    assert_size_stride(primals_1371, (), ())
    assert_size_stride(primals_1372, (864, ), (1, ))
    assert_size_stride(primals_1373, (864, ), (1, ))
    assert_size_stride(primals_1374, (), ())
    assert_size_stride(primals_1375, (864, ), (1, ))
    assert_size_stride(primals_1376, (864, ), (1, ))
    assert_size_stride(primals_1377, (), ())
    assert_size_stride(primals_1378, (864, ), (1, ))
    assert_size_stride(primals_1379, (864, ), (1, ))
    assert_size_stride(primals_1380, (), ())
    assert_size_stride(primals_1381, (8, 3, 331, 331), (328683, 109561, 331, 1))
    with torch.cuda._DeviceGuard(0):
        torch.cuda.set_device(0) # no-op to ensure context
        buf0 = empty_strided((96, 3, 3, 3), (27, 1, 9, 3), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: []
        stream0 = get_cuda_stream(0)
        triton_poi_fused_0.run(primals_27, buf0, 288, 9, grid=grid(288, 9), stream=stream0)
        del primals_27
        buf1 = empty_strided((8, 3, 331, 331), (328683, 1, 993, 3), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: []
        triton_poi_fused_1.run(primals_1381, buf1, 24, 109561, grid=grid(24, 109561), stream=stream0)
        del primals_1381
        # Source Nodes: [x], Original ATen: [aten.convolution]
        buf2 = extern_kernels.convolution(buf1, buf0, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2, (8, 96, 165, 165), (2613600, 27225, 165, 1))
        buf3 = empty_strided((8, 96, 165, 165), (2613600, 1, 15840, 96), device='cuda', dtype=torch.float32)
        # Source Nodes: [x], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_2.run(buf2, buf3, 768, 27225, grid=grid(768, 27225), stream=stream0)
        buf4 = empty_strided((1, 96, 1, 1, 990), (95040, 1, 95040, 95040, 96), device='cuda', dtype=torch.float32)
        buf5 = empty_strided((1, 96, 1, 1, 990), (95040, 1, 95040, 95040, 96), device='cuda', dtype=torch.float32)
        buf6 = empty_strided((1, 96, 1, 1, 990), (95040, 1, 95040, 95040, 96), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_3.run(buf3, buf4, buf5, buf6, 95040, 220, grid=grid(95040), stream=stream0)
        buf7 = empty_strided((1, 96, 1, 1, 8), (768, 1, 768, 768, 96), device='cuda', dtype=torch.float32)
        buf8 = empty_strided((1, 96, 1, 1, 8), (768, 1, 768, 768, 96), device='cuda', dtype=torch.float32)
        buf9 = empty_strided((1, 96, 1, 1, 8), (768, 1, 768, 768, 96), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_4.run(buf4, buf5, buf6, buf7, buf8, buf9, 768, 124, grid=grid(768), stream=stream0)
        del buf4
        del buf5
        del buf6
        buf10 = empty_strided((1, 96, 1, 1), (96, 1, 96, 96), device='cuda', dtype=torch.float32)
        buf11 = empty_strided((1, 96, 1, 1), (96, 1, 96, 96), device='cuda', dtype=torch.float32)
        buf13 = empty((96, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_5.run(buf7, buf8, buf9, primals_779, primals_780, buf10, buf11, buf13, primals_779, primals_780, 96, 8, grid=grid(96), stream=stream0)
        del buf7
        del buf8
        del buf9
        del primals_779
        del primals_780
        buf14 = reinterpret_tensor(buf2, (8, 96, 165, 165), (2613600, 1, 15840, 96), 0); del buf2  # reuse
        buf15 = empty_strided((8, 96, 165, 165), (2613600, 1, 15840, 96), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1, x_5], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_6.run(buf3, buf10, buf11, primals_1, primals_2, buf14, buf15, 20908800, grid=grid(20908800), stream=stream0)
        del buf11
        del primals_2
        # Source Nodes: [x_6], Original ATen: [aten.convolution]
        buf16 = extern_kernels.convolution(buf15, primals_28, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf16, (8, 54, 165, 165), (1470150, 27225, 165, 1))
        buf17 = empty_strided((8, 54, 165, 165), (1470150, 1, 8910, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_6], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_7.run(buf16, buf17, 432, 27225, grid=grid(432, 27225), stream=stream0)
        buf18 = empty_strided((1, 54, 1, 1, 990), (53460, 1, 53460, 53460, 54), device='cuda', dtype=torch.float32)
        buf19 = empty_strided((1, 54, 1, 1, 990), (53460, 1, 53460, 53460, 54), device='cuda', dtype=torch.float32)
        buf20 = empty_strided((1, 54, 1, 1, 990), (53460, 1, 53460, 53460, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_right], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_8.run(buf17, buf18, buf19, buf20, 53460, 220, grid=grid(53460), stream=stream0)
        buf21 = empty_strided((1, 54, 1, 1, 8), (432, 1, 432, 432, 54), device='cuda', dtype=torch.float32)
        buf22 = empty_strided((1, 54, 1, 1, 8), (432, 1, 432, 432, 54), device='cuda', dtype=torch.float32)
        buf23 = empty_strided((1, 54, 1, 1, 8), (432, 1, 432, 432, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_right], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf18, buf19, buf20, buf21, buf22, buf23, 432, 124, grid=grid(432), stream=stream0)
        del buf18
        del buf19
        del buf20
        buf24 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf25 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf27 = empty((54, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_right], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf21, buf22, buf23, primals_781, primals_782, buf24, buf25, buf27, primals_781, primals_782, 54, 8, grid=grid(54), stream=stream0)
        del primals_781
        del primals_782
        buf28 = reinterpret_tensor(buf16, (8, 54, 165, 165), (1470150, 1, 8910, 54), 0); del buf16  # reuse
        buf75 = empty_strided((8, 54, 165, 165), (1470150, 1, 8910, 54), device='cuda', dtype=torch.float32)
        buf2559 = empty_strided((8, 54, 165, 165), (1470150, 1, 8910, 54), device='cuda', dtype=torch.bool)
        # Source Nodes: [x_22, x_right], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu, aten.threshold_backward]
        triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_11.run(buf17, buf24, buf25, primals_29, primals_30, buf28, buf75, buf2559, 11761200, grid=grid(11761200), stream=stream0)
        del primals_30
        buf29 = empty_strided((8, 96, 169, 169), (2741856, 1, 16224, 96), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_10], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_12.run(buf15, buf29, 21934848, grid=grid(21934848), stream=stream0)
        # Source Nodes: [x_11], Original ATen: [aten.convolution]
        buf30 = extern_kernels.convolution(buf29, primals_3, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=96, bias=None)
        assert_size_stride(buf30, (8, 96, 83, 83), (661344, 6889, 83, 1))
        buf31 = empty_strided((8, 96, 83, 83), (661344, 1, 7968, 96), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_11], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_13.run(buf30, buf31, 768, 6889, grid=grid(768, 6889), stream=stream0)
        # Source Nodes: [x_13], Original ATen: [aten.convolution]
        buf32 = extern_kernels.convolution(buf31, primals_31, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf32, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf33 = empty_strided((8, 54, 83, 83), (372006, 1, 4482, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_13], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf32, buf33, 432, 6889, grid=grid(432, 6889), stream=stream0)
        buf34 = empty_strided((1, 54, 1, 1, 431), (23274, 1, 23274, 23274, 54), device='cuda', dtype=torch.float32)
        buf35 = empty_strided((1, 54, 1, 1, 431), (23274, 1, 23274, 23274, 54), device='cuda', dtype=torch.float32)
        buf36 = empty_strided((1, 54, 1, 1, 431), (23274, 1, 23274, 23274, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_14], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_15.run(buf33, buf34, buf35, buf36, 23274, 128, grid=grid(23274), stream=stream0)
        buf37 = empty_strided((1, 54, 1, 1, 4), (216, 1, 216, 216, 54), device='cuda', dtype=torch.float32)
        buf38 = empty_strided((1, 54, 1, 1, 4), (216, 1, 216, 216, 54), device='cuda', dtype=torch.float32)
        buf39 = empty_strided((1, 54, 1, 1, 4), (216, 1, 216, 216, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_14], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf34, buf35, buf36, buf37, buf38, buf39, 216, 108, grid=grid(216), stream=stream0)
        buf40 = buf25; del buf25  # reuse
        buf41 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf43 = empty((54, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_14], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_17.run(buf37, buf38, buf39, primals_784, primals_785, buf40, buf41, buf43, primals_784, primals_785, 54, 4, grid=grid(54), stream=stream0)
        del primals_784
        del primals_785
        buf44 = reinterpret_tensor(buf32, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf32  # reuse
        # Source Nodes: [x_14, x_15], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_18.run(buf33, buf40, buf41, primals_32, primals_33, buf44, 2976048, grid=grid(2976048), stream=stream0)
        del primals_33
        # Source Nodes: [x_16], Original ATen: [aten.convolution]
        buf45 = extern_kernels.convolution(buf44, primals_34, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=54, bias=None)
        assert_size_stride(buf45, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf46 = empty_strided((8, 54, 83, 83), (372006, 1, 4482, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_16], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf45, buf46, 432, 6889, grid=grid(432, 6889), stream=stream0)
        # Source Nodes: [x_18], Original ATen: [aten.convolution]
        buf47 = extern_kernels.convolution(buf46, primals_35, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf47, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf48 = reinterpret_tensor(buf45, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf45  # reuse
        # Source Nodes: [x_18], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf47, buf48, 432, 6889, grid=grid(432, 6889), stream=stream0)
        buf49 = buf36; del buf36  # reuse
        buf50 = buf35; del buf35  # reuse
        buf51 = buf34; del buf34  # reuse
        # Source Nodes: [x_comb_iter_0_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_15.run(buf48, buf49, buf50, buf51, 23274, 128, grid=grid(23274), stream=stream0)
        buf52 = buf39; del buf39  # reuse
        buf53 = buf38; del buf38  # reuse
        buf54 = buf37; del buf37  # reuse
        # Source Nodes: [x_comb_iter_0_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf49, buf50, buf51, buf52, buf53, buf54, 216, 108, grid=grid(216), stream=stream0)
        buf55 = buf41; del buf41  # reuse
        buf56 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf58 = empty((54, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_0_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_17.run(buf52, buf53, buf54, primals_787, primals_788, buf55, buf56, buf58, primals_787, primals_788, 54, 4, grid=grid(54), stream=stream0)
        del primals_787
        del primals_788
        buf59 = empty_strided((8, 96, 167, 167), (2677344, 1, 16032, 96), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_21], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_19.run(buf14, buf59, 21418752, grid=grid(21418752), stream=stream0)
        buf60 = reinterpret_tensor(buf30, (8, 96, 83, 83), (661344, 1, 7968, 96), 0); del buf30  # reuse
        buf61 = empty_strided((8, 96, 83, 83), (661344, 1, 7968, 96), device='cuda', dtype=torch.int64)
        # Source Nodes: [max_pool2d], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_20.run(buf59, buf60, buf61, 768, 6889, grid=grid(768, 6889), stream=stream0)
        # Source Nodes: [l__mod___cell_stem_0_comb_iter_0_right_conv], Original ATen: [aten.convolution]
        buf62 = extern_kernels.convolution(buf60, primals_38, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf62, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf63 = reinterpret_tensor(buf47, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf47  # reuse
        # Source Nodes: [l__mod___cell_stem_0_comb_iter_0_right_conv], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf62, buf63, 432, 6889, grid=grid(432, 6889), stream=stream0)
        buf64 = buf51; del buf51  # reuse
        buf65 = buf50; del buf50  # reuse
        buf66 = buf49; del buf49  # reuse
        # Source Nodes: [x_comb_iter_0_right], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_15.run(buf63, buf64, buf65, buf66, 23274, 128, grid=grid(23274), stream=stream0)
        buf67 = buf54; del buf54  # reuse
        buf68 = buf53; del buf53  # reuse
        buf69 = buf52; del buf52  # reuse
        # Source Nodes: [x_comb_iter_0_right], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf64, buf65, buf66, buf67, buf68, buf69, 216, 108, grid=grid(216), stream=stream0)
        buf70 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf71 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf73 = empty((54, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_0_right], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_17.run(buf67, buf68, buf69, primals_790, primals_791, buf70, buf71, buf73, primals_790, primals_791, 54, 4, grid=grid(54), stream=stream0)
        del primals_790
        del primals_791
        buf245 = empty((8, 270, 83, 83), device='cuda', dtype=torch.float32)
        buf74 = reinterpret_tensor(buf245, (8, 54, 83, 83), (1860030, 6889, 83, 1), 0)  # alias
        # Source Nodes: [x_comb_iter_0, x_comb_iter_0_left, x_comb_iter_0_right], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_21.run(buf48, buf55, buf56, primals_36, primals_37, buf63, buf70, buf71, primals_39, primals_40, buf74, 55112, 54, grid=grid(55112, 54), stream=stream0)
        del primals_37
        del primals_40
        buf76 = empty_strided((8, 54, 171, 171), (1579014, 1, 9234, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_24], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_22.run(buf75, buf76, 12632112, grid=grid(12632112), stream=stream0)
        # Source Nodes: [x_25], Original ATen: [aten.convolution]
        buf77 = extern_kernels.convolution(buf76, primals_4, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=54, bias=None)
        assert_size_stride(buf77, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf78 = reinterpret_tensor(buf62, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf62  # reuse
        # Source Nodes: [x_25], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf77, buf78, 432, 6889, grid=grid(432, 6889), stream=stream0)
        # Source Nodes: [x_27], Original ATen: [aten.convolution]
        buf79 = extern_kernels.convolution(buf78, primals_41, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf79, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf80 = reinterpret_tensor(buf77, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf77  # reuse
        # Source Nodes: [x_27], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf79, buf80, 432, 6889, grid=grid(432, 6889), stream=stream0)
        buf81 = buf66; del buf66  # reuse
        buf82 = buf65; del buf65  # reuse
        buf83 = buf64; del buf64  # reuse
        # Source Nodes: [x_28], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_15.run(buf80, buf81, buf82, buf83, 23274, 128, grid=grid(23274), stream=stream0)
        buf84 = buf69; del buf69  # reuse
        buf85 = buf68; del buf68  # reuse
        buf86 = buf67; del buf67  # reuse
        # Source Nodes: [x_28], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf81, buf82, buf83, buf84, buf85, buf86, 216, 108, grid=grid(216), stream=stream0)
        buf87 = buf71; del buf71  # reuse
        buf88 = buf56; del buf56  # reuse
        buf90 = empty((54, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_28], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_17.run(buf84, buf85, buf86, primals_793, primals_794, buf87, buf88, buf90, primals_793, primals_794, 54, 4, grid=grid(54), stream=stream0)
        del primals_793
        del primals_794
        buf91 = reinterpret_tensor(buf79, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf79  # reuse
        # Source Nodes: [x_28, x_29], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_18.run(buf80, buf87, buf88, primals_42, primals_43, buf91, 2976048, grid=grid(2976048), stream=stream0)
        del primals_43
        # Source Nodes: [x_30], Original ATen: [aten.convolution]
        buf92 = extern_kernels.convolution(buf91, primals_44, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=54, bias=None)
        assert_size_stride(buf92, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf93 = empty_strided((8, 54, 83, 83), (372006, 1, 4482, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_30], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf92, buf93, 432, 6889, grid=grid(432, 6889), stream=stream0)
        # Source Nodes: [x_32], Original ATen: [aten.convolution]
        buf94 = extern_kernels.convolution(buf93, primals_45, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf94, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf95 = reinterpret_tensor(buf92, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf92  # reuse
        # Source Nodes: [x_32], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf94, buf95, 432, 6889, grid=grid(432, 6889), stream=stream0)
        buf96 = buf83; del buf83  # reuse
        buf97 = buf82; del buf82  # reuse
        buf98 = buf81; del buf81  # reuse
        # Source Nodes: [x_comb_iter_1_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_15.run(buf95, buf96, buf97, buf98, 23274, 128, grid=grid(23274), stream=stream0)
        buf99 = buf86; del buf86  # reuse
        buf100 = buf85; del buf85  # reuse
        buf101 = buf84; del buf84  # reuse
        # Source Nodes: [x_comb_iter_1_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf96, buf97, buf98, buf99, buf100, buf101, 216, 108, grid=grid(216), stream=stream0)
        buf102 = buf88; del buf88  # reuse
        buf103 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf105 = empty((54, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_1_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_17.run(buf99, buf100, buf101, primals_796, primals_797, buf102, buf103, buf105, primals_796, primals_797, 54, 4, grid=grid(54), stream=stream0)
        del primals_796
        del primals_797
        buf106 = empty_strided((8, 54, 167, 167), (1506006, 1, 9018, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_35], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_23.run(buf28, buf106, 12048048, grid=grid(12048048), stream=stream0)
        del buf28
        buf107 = reinterpret_tensor(buf94, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf94  # reuse
        buf108 = empty_strided((8, 54, 83, 83), (372006, 1, 4482, 54), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_1_right], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_24.run(buf106, buf107, buf108, 432, 6889, grid=grid(432, 6889), stream=stream0)
        buf109 = empty_strided((8, 54, 169, 169), (1542294, 1, 9126, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_38], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_25.run(buf75, buf109, 12338352, grid=grid(12338352), stream=stream0)
        # Source Nodes: [x_39], Original ATen: [aten.convolution]
        buf110 = extern_kernels.convolution(buf109, primals_5, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=54, bias=None)
        assert_size_stride(buf110, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf111 = empty_strided((8, 54, 83, 83), (372006, 1, 4482, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_39], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf110, buf111, 432, 6889, grid=grid(432, 6889), stream=stream0)
        # Source Nodes: [x_41], Original ATen: [aten.convolution]
        buf112 = extern_kernels.convolution(buf111, primals_48, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf112, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf113 = reinterpret_tensor(buf110, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf110  # reuse
        # Source Nodes: [x_41], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf112, buf113, 432, 6889, grid=grid(432, 6889), stream=stream0)
        buf114 = buf98; del buf98  # reuse
        buf115 = buf97; del buf97  # reuse
        buf116 = buf96; del buf96  # reuse
        # Source Nodes: [x_42], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_15.run(buf113, buf114, buf115, buf116, 23274, 128, grid=grid(23274), stream=stream0)
        buf117 = buf99; del buf99  # reuse
        buf118 = buf101; del buf101  # reuse
        buf119 = buf100; del buf100  # reuse
        # Source Nodes: [x_42], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf114, buf115, buf116, buf117, buf118, buf119, 216, 108, grid=grid(216), stream=stream0)
        buf120 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf121 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf123 = empty((54, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_42], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_17.run(buf117, buf118, buf119, primals_799, primals_800, buf120, buf121, buf123, primals_799, primals_800, 54, 4, grid=grid(54), stream=stream0)
        del primals_799
        del primals_800
        buf124 = reinterpret_tensor(buf112, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf112  # reuse
        # Source Nodes: [x_42, x_43], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_18.run(buf113, buf120, buf121, primals_49, primals_50, buf124, 2976048, grid=grid(2976048), stream=stream0)
        del primals_50
        # Source Nodes: [x_44], Original ATen: [aten.convolution]
        buf125 = extern_kernels.convolution(buf124, primals_51, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=54, bias=None)
        assert_size_stride(buf125, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf126 = empty_strided((8, 54, 83, 83), (372006, 1, 4482, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_44], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf125, buf126, 432, 6889, grid=grid(432, 6889), stream=stream0)
        # Source Nodes: [x_46], Original ATen: [aten.convolution]
        buf127 = extern_kernels.convolution(buf126, primals_52, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf127, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf128 = reinterpret_tensor(buf125, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf125  # reuse
        # Source Nodes: [x_46], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf127, buf128, 432, 6889, grid=grid(432, 6889), stream=stream0)
        buf129 = buf116; del buf116  # reuse
        buf130 = buf115; del buf115  # reuse
        buf131 = buf114; del buf114  # reuse
        # Source Nodes: [x_comb_iter_2_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_15.run(buf128, buf129, buf130, buf131, 23274, 128, grid=grid(23274), stream=stream0)
        buf132 = buf119; del buf119  # reuse
        buf133 = buf118; del buf118  # reuse
        buf134 = buf117; del buf117  # reuse
        # Source Nodes: [x_comb_iter_2_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf129, buf130, buf131, buf132, buf133, buf134, 216, 108, grid=grid(216), stream=stream0)
        buf135 = buf121; del buf121  # reuse
        buf136 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf138 = empty((54, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_17.run(buf132, buf133, buf134, primals_802, primals_803, buf135, buf136, buf138, primals_802, primals_803, 54, 4, grid=grid(54), stream=stream0)
        del primals_802
        del primals_803
        buf139 = empty_strided((8, 54, 167, 167), (1506006, 1, 9018, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_50], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_26.run(buf75, buf139, 12048048, grid=grid(12048048), stream=stream0)
        # Source Nodes: [x_51], Original ATen: [aten.convolution]
        buf140 = extern_kernels.convolution(buf139, primals_6, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=54, bias=None)
        assert_size_stride(buf140, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf141 = reinterpret_tensor(buf127, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf127  # reuse
        # Source Nodes: [x_51], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf140, buf141, 432, 6889, grid=grid(432, 6889), stream=stream0)
        # Source Nodes: [x_53], Original ATen: [aten.convolution]
        buf142 = extern_kernels.convolution(buf141, primals_55, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf142, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf143 = reinterpret_tensor(buf140, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf140  # reuse
        # Source Nodes: [x_53], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf142, buf143, 432, 6889, grid=grid(432, 6889), stream=stream0)
        buf144 = buf131; del buf131  # reuse
        buf145 = buf130; del buf130  # reuse
        buf146 = buf129; del buf129  # reuse
        # Source Nodes: [x_54], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_15.run(buf143, buf144, buf145, buf146, 23274, 128, grid=grid(23274), stream=stream0)
        buf147 = buf134; del buf134  # reuse
        buf148 = buf133; del buf133  # reuse
        buf149 = buf132; del buf132  # reuse
        # Source Nodes: [x_54], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf144, buf145, buf146, buf147, buf148, buf149, 216, 108, grid=grid(216), stream=stream0)
        buf150 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf151 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf153 = empty((54, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_54], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_17.run(buf147, buf148, buf149, primals_805, primals_806, buf150, buf151, buf153, primals_805, primals_806, 54, 4, grid=grid(54), stream=stream0)
        del primals_805
        del primals_806
        buf154 = reinterpret_tensor(buf142, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf142  # reuse
        # Source Nodes: [x_54, x_55], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_18.run(buf143, buf150, buf151, primals_56, primals_57, buf154, 2976048, grid=grid(2976048), stream=stream0)
        del primals_57
        # Source Nodes: [x_56], Original ATen: [aten.convolution]
        buf155 = extern_kernels.convolution(buf154, primals_58, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=54, bias=None)
        assert_size_stride(buf155, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf156 = empty_strided((8, 54, 83, 83), (372006, 1, 4482, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_56], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf155, buf156, 432, 6889, grid=grid(432, 6889), stream=stream0)
        # Source Nodes: [x_58], Original ATen: [aten.convolution]
        buf157 = extern_kernels.convolution(buf156, primals_59, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf157, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf158 = reinterpret_tensor(buf155, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf155  # reuse
        # Source Nodes: [x_58], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf157, buf158, 432, 6889, grid=grid(432, 6889), stream=stream0)
        buf159 = buf146; del buf146  # reuse
        buf160 = buf145; del buf145  # reuse
        buf161 = buf144; del buf144  # reuse
        # Source Nodes: [x_comb_iter_2_right], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_15.run(buf158, buf159, buf160, buf161, 23274, 128, grid=grid(23274), stream=stream0)
        buf162 = buf149; del buf149  # reuse
        buf163 = buf148; del buf148  # reuse
        buf164 = buf147; del buf147  # reuse
        # Source Nodes: [x_comb_iter_2_right], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf159, buf160, buf161, buf162, buf163, buf164, 216, 108, grid=grid(216), stream=stream0)
        buf165 = buf151; del buf151  # reuse
        buf166 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf168 = empty((54, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_right], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_17.run(buf162, buf163, buf164, primals_808, primals_809, buf165, buf166, buf168, primals_808, primals_809, 54, 4, grid=grid(54), stream=stream0)
        del primals_808
        del primals_809
        buf169 = reinterpret_tensor(buf245, (8, 54, 83, 83), (1860030, 6889, 83, 1), 744012)  # alias
        # Source Nodes: [x_comb_iter_2, x_comb_iter_2_left, x_comb_iter_2_right], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_27.run(buf128, buf135, buf136, primals_53, primals_54, buf158, buf165, buf166, primals_60, primals_61, buf169, 55112, 54, grid=grid(55112, 54), stream=stream0)
        del primals_54
        del primals_61
        buf170 = reinterpret_tensor(buf157, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf157  # reuse
        # Source Nodes: [x_60], Original ATen: [aten.relu]
        triton_poi_fused_relu_28.run(buf169, buf170, 432, 6889, grid=grid(432, 6889), stream=stream0)
        # Source Nodes: [x_61], Original ATen: [aten.convolution]
        buf171 = extern_kernels.convolution(buf170, primals_62, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=54, bias=None)
        assert_size_stride(buf171, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf172 = empty_strided((8, 54, 83, 83), (372006, 1, 4482, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_61], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf171, buf172, 432, 6889, grid=grid(432, 6889), stream=stream0)
        # Source Nodes: [x_63], Original ATen: [aten.convolution]
        buf173 = extern_kernels.convolution(buf172, primals_63, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf173, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf174 = reinterpret_tensor(buf171, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf171  # reuse
        # Source Nodes: [x_63], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf173, buf174, 432, 6889, grid=grid(432, 6889), stream=stream0)
        buf175 = buf161; del buf161  # reuse
        buf176 = buf160; del buf160  # reuse
        buf177 = buf159; del buf159  # reuse
        # Source Nodes: [x_64], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_15.run(buf174, buf175, buf176, buf177, 23274, 128, grid=grid(23274), stream=stream0)
        buf178 = buf164; del buf164  # reuse
        buf179 = buf163; del buf163  # reuse
        buf180 = buf162; del buf162  # reuse
        # Source Nodes: [x_64], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf175, buf176, buf177, buf178, buf179, buf180, 216, 108, grid=grid(216), stream=stream0)
        buf181 = buf166; del buf166  # reuse
        buf182 = buf136; del buf136  # reuse
        buf184 = empty((54, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_64], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_17.run(buf178, buf179, buf180, primals_811, primals_812, buf181, buf182, buf184, primals_811, primals_812, 54, 4, grid=grid(54), stream=stream0)
        del primals_811
        del primals_812
        buf185 = reinterpret_tensor(buf173, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf173  # reuse
        # Source Nodes: [x_64, x_65], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_18.run(buf174, buf181, buf182, primals_64, primals_65, buf185, 2976048, grid=grid(2976048), stream=stream0)
        del primals_65
        # Source Nodes: [x_66], Original ATen: [aten.convolution]
        buf186 = extern_kernels.convolution(buf185, primals_66, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=54, bias=None)
        assert_size_stride(buf186, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf187 = empty_strided((8, 54, 83, 83), (372006, 1, 4482, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_66], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf186, buf187, 432, 6889, grid=grid(432, 6889), stream=stream0)
        # Source Nodes: [x_68], Original ATen: [aten.convolution]
        buf188 = extern_kernels.convolution(buf187, primals_67, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf188, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf189 = reinterpret_tensor(buf186, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf186  # reuse
        # Source Nodes: [x_68], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf188, buf189, 432, 6889, grid=grid(432, 6889), stream=stream0)
        buf190 = buf177; del buf177  # reuse
        buf191 = buf176; del buf176  # reuse
        buf192 = buf175; del buf175  # reuse
        # Source Nodes: [x_comb_iter_3_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_15.run(buf189, buf190, buf191, buf192, 23274, 128, grid=grid(23274), stream=stream0)
        buf193 = buf180; del buf180  # reuse
        buf194 = buf179; del buf179  # reuse
        buf195 = buf178; del buf178  # reuse
        # Source Nodes: [x_comb_iter_3_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf190, buf191, buf192, buf193, buf194, buf195, 216, 108, grid=grid(216), stream=stream0)
        buf196 = buf182; del buf182  # reuse
        buf197 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf199 = empty((54, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_3_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_17.run(buf193, buf194, buf195, primals_814, primals_815, buf196, buf197, buf199, primals_814, primals_815, 54, 4, grid=grid(54), stream=stream0)
        del primals_814
        del primals_815
        buf200 = empty_strided((8, 96, 167, 167), (2677344, 1, 16032, 96), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_74], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_29.run(buf15, buf200, 21418752, grid=grid(21418752), stream=stream0)
        # Source Nodes: [x_75], Original ATen: [aten.convolution]
        buf201 = extern_kernels.convolution(buf200, primals_7, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=96, bias=None)
        assert_size_stride(buf201, (8, 96, 83, 83), (661344, 6889, 83, 1))
        buf202 = empty_strided((8, 96, 83, 83), (661344, 1, 7968, 96), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_75], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_13.run(buf201, buf202, 768, 6889, grid=grid(768, 6889), stream=stream0)
        # Source Nodes: [x_77], Original ATen: [aten.convolution]
        buf203 = extern_kernels.convolution(buf202, primals_70, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf203, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf204 = reinterpret_tensor(buf188, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf188  # reuse
        # Source Nodes: [x_77], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf203, buf204, 432, 6889, grid=grid(432, 6889), stream=stream0)
        buf205 = buf192; del buf192  # reuse
        buf206 = buf191; del buf191  # reuse
        buf207 = buf190; del buf190  # reuse
        # Source Nodes: [x_78], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_15.run(buf204, buf205, buf206, buf207, 23274, 128, grid=grid(23274), stream=stream0)
        buf208 = buf195; del buf195  # reuse
        buf209 = buf194; del buf194  # reuse
        buf210 = buf193; del buf193  # reuse
        # Source Nodes: [x_78], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf205, buf206, buf207, buf208, buf209, buf210, 216, 108, grid=grid(216), stream=stream0)
        buf211 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf212 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf214 = empty((54, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_78], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_17.run(buf208, buf209, buf210, primals_817, primals_818, buf211, buf212, buf214, primals_817, primals_818, 54, 4, grid=grid(54), stream=stream0)
        del primals_817
        del primals_818
        buf215 = reinterpret_tensor(buf203, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf203  # reuse
        # Source Nodes: [x_78, x_79], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_18.run(buf204, buf211, buf212, primals_71, primals_72, buf215, 2976048, grid=grid(2976048), stream=stream0)
        del primals_72
        # Source Nodes: [x_80], Original ATen: [aten.convolution]
        buf216 = extern_kernels.convolution(buf215, primals_73, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=54, bias=None)
        assert_size_stride(buf216, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf217 = empty_strided((8, 54, 83, 83), (372006, 1, 4482, 54), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_80], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf216, buf217, 432, 6889, grid=grid(432, 6889), stream=stream0)
        # Source Nodes: [x_82], Original ATen: [aten.convolution]
        buf218 = extern_kernels.convolution(buf217, primals_74, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf218, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf219 = reinterpret_tensor(buf216, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf216  # reuse
        # Source Nodes: [x_82], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf218, buf219, 432, 6889, grid=grid(432, 6889), stream=stream0)
        buf220 = buf207; del buf207  # reuse
        buf221 = buf206; del buf206  # reuse
        buf222 = buf205; del buf205  # reuse
        # Source Nodes: [x_comb_iter_4_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_15.run(buf219, buf220, buf221, buf222, 23274, 128, grid=grid(23274), stream=stream0)
        buf223 = buf210; del buf210  # reuse
        buf224 = buf209; del buf209  # reuse
        buf225 = buf208; del buf208  # reuse
        # Source Nodes: [x_comb_iter_4_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf220, buf221, buf222, buf223, buf224, buf225, 216, 108, grid=grid(216), stream=stream0)
        buf226 = buf212; del buf212  # reuse
        buf227 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf229 = empty((54, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_17.run(buf223, buf224, buf225, primals_820, primals_821, buf226, buf227, buf229, primals_820, primals_821, 54, 4, grid=grid(54), stream=stream0)
        del primals_820
        del primals_821
        # Source Nodes: [x_87], Original ATen: [aten.convolution]
        buf230 = extern_kernels.convolution(buf75, primals_8, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf230, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf231 = reinterpret_tensor(buf218, (8, 54, 83, 83), (372006, 1, 4482, 54), 0); del buf218  # reuse
        # Source Nodes: [x_87], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_14.run(buf230, buf231, 432, 6889, grid=grid(432, 6889), stream=stream0)
        del buf230
        buf232 = buf222; del buf222  # reuse
        buf233 = buf221; del buf221  # reuse
        buf234 = buf220; del buf220  # reuse
        # Source Nodes: [x_comb_iter_4_right], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_15.run(buf231, buf232, buf233, buf234, 23274, 128, grid=grid(23274), stream=stream0)
        buf235 = buf225; del buf225  # reuse
        buf236 = buf224; del buf224  # reuse
        buf237 = buf223; del buf223  # reuse
        # Source Nodes: [x_comb_iter_4_right], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf232, buf233, buf234, buf235, buf236, buf237, 216, 108, grid=grid(216), stream=stream0)
        del buf232
        del buf233
        del buf234
        buf238 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf239 = empty_strided((1, 54, 1, 1), (54, 1, 54, 54), device='cuda', dtype=torch.float32)
        buf241 = empty((54, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_right], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_17.run(buf235, buf236, buf237, primals_823, primals_824, buf238, buf239, buf241, primals_823, primals_824, 54, 4, grid=grid(54), stream=stream0)
        del primals_823
        del primals_824
        buf242 = reinterpret_tensor(buf245, (8, 54, 83, 83), (1860030, 6889, 83, 1), 1488024)  # alias
        # Source Nodes: [x_comb_iter_4, x_comb_iter_4_left, x_comb_iter_4_right], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_27.run(buf219, buf226, buf227, primals_75, primals_76, buf231, buf238, buf239, primals_77, primals_78, buf242, 55112, 54, grid=grid(55112, 54), stream=stream0)
        del buf227
        del buf239
        del primals_76
        del primals_78
        buf243 = reinterpret_tensor(buf245, (8, 54, 83, 83), (1860030, 6889, 83, 1), 372006)  # alias
        buf244 = reinterpret_tensor(buf245, (8, 54, 83, 83), (1860030, 6889, 83, 1), 1116018)  # alias
        # Source Nodes: [x_comb_iter_1, x_comb_iter_1_left, x_comb_iter_3, x_comb_iter_3_left], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_30.run(buf95, buf102, buf103, primals_46, primals_47, buf107, buf189, buf196, buf197, primals_68, primals_69, buf243, buf244, 55112, 54, grid=grid(55112, 54), stream=stream0)
        del buf103
        del buf107
        del buf197
        del primals_47
        del primals_69
        buf246 = reinterpret_tensor(buf201, (8, 96, 83, 83), (661344, 1, 7968, 96), 0); del buf201  # reuse
        # Source Nodes: [l__mod___cell_stem_1_conv_prev_1x1_path_1_avgpool], Original ATen: [aten.avg_pool2d]
        triton_poi_fused_avg_pool2d_31.run(buf15, buf246, 5290752, grid=grid(5290752), stream=stream0)
        del buf169
        del buf242
        del buf243
        del buf244
        del buf74
        # Source Nodes: [x_path1], Original ATen: [aten.convolution]
        buf247 = extern_kernels.convolution(buf246, primals_79, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf247, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf248 = buf14; del buf14  # reuse
        # Source Nodes: [l__mod___cell_stem_1_conv_prev_1x1_path_2_pad], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_32.run(buf15, buf248, 20908800, grid=grid(20908800), stream=stream0)
        buf249 = empty_strided((8, 96, 83, 83), (661344, 1, 7968, 96), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___cell_stem_1_conv_prev_1x1_path_2_avgpool], Original ATen: [aten.avg_pool2d]
        triton_poi_fused_avg_pool2d_33.run(buf248, buf249, 768, 6889, grid=grid(768, 6889), stream=stream0)
        # Source Nodes: [x_path2], Original ATen: [aten.convolution]
        buf250 = extern_kernels.convolution(buf249, primals_80, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf250, (8, 54, 83, 83), (372006, 6889, 83, 1))
        buf251 = empty_strided((8, 108, 83, 83), (744012, 1, 8964, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [cat_34], Original ATen: [aten.cat]
        triton_poi_fused_cat_34.run(buf247, buf250, buf251, 864, 6889, grid=grid(864, 6889), stream=stream0)
        del buf247
        del buf250
        buf252 = empty_strided((1, 108, 1, 1, 431), (46548, 1, 46548, 46548, 108), device='cuda', dtype=torch.float32)
        buf253 = empty_strided((1, 108, 1, 1, 431), (46548, 1, 46548, 46548, 108), device='cuda', dtype=torch.float32)
        buf254 = empty_strided((1, 108, 1, 1, 431), (46548, 1, 46548, 46548, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_35.run(buf251, buf252, buf253, buf254, 46548, 128, grid=grid(46548), stream=stream0)
        buf255 = reinterpret_tensor(buf23, (1, 108, 1, 1, 4), (432, 1, 432, 432, 108), 0); del buf23  # reuse
        buf256 = reinterpret_tensor(buf22, (1, 108, 1, 1, 4), (432, 1, 432, 432, 108), 0); del buf22  # reuse
        buf257 = reinterpret_tensor(buf21, (1, 108, 1, 1, 4), (432, 1, 432, 432, 108), 0); del buf21  # reuse
        # Source Nodes: [x_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_36.run(buf252, buf253, buf254, buf255, buf256, buf257, 432, 108, grid=grid(432), stream=stream0)
        buf258 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf259 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf261 = empty((108, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_left], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_37.run(buf255, buf256, buf257, primals_826, primals_827, buf258, buf259, buf261, primals_826, primals_827, 108, 4, grid=grid(108), stream=stream0)
        del primals_826
        del primals_827
        buf262 = empty_strided((8, 108, 83, 83), (744012, 1, 8964, 108), device='cuda', dtype=torch.float32)
        buf2558 = empty_strided((8, 108, 83, 83), (744012, 1, 8964, 108), device='cuda', dtype=torch.bool)
        # Source Nodes: [x_93, x_left], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu, aten.threshold_backward]
        triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_38.run(buf251, buf258, buf259, primals_81, primals_82, buf262, buf2558, 5952096, grid=grid(5952096), stream=stream0)
        del primals_82
        buf263 = empty_strided((8, 270, 83, 83), (1860030, 1, 22410, 270), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_90], Original ATen: [aten.relu]
        triton_poi_fused_relu_39.run(buf245, buf263, 2160, 6889, grid=grid(2160, 6889), stream=stream0)
        # Source Nodes: [x_91], Original ATen: [aten.convolution]
        buf264 = extern_kernels.convolution(buf263, primals_83, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf264, (8, 108, 83, 83), (744012, 6889, 83, 1))
        buf265 = empty_strided((8, 108, 83, 83), (744012, 1, 8964, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_91], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_40.run(buf264, buf265, 864, 6889, grid=grid(864, 6889), stream=stream0)
        buf266 = buf254; del buf254  # reuse
        buf267 = buf253; del buf253  # reuse
        buf268 = buf252; del buf252  # reuse
        # Source Nodes: [x_right_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_35.run(buf265, buf266, buf267, buf268, 46548, 128, grid=grid(46548), stream=stream0)
        buf269 = buf257; del buf257  # reuse
        buf270 = buf256; del buf256  # reuse
        buf271 = buf255; del buf255  # reuse
        # Source Nodes: [x_right_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_36.run(buf266, buf267, buf268, buf269, buf270, buf271, 432, 108, grid=grid(432), stream=stream0)
        del buf266
        del buf267
        del buf268
        buf272 = buf259; del buf259  # reuse
        buf273 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf275 = empty((108, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_right_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_37.run(buf269, buf270, buf271, primals_829, primals_830, buf272, buf273, buf275, primals_829, primals_830, 108, 4, grid=grid(108), stream=stream0)
        del primals_829
        del primals_830
        buf276 = reinterpret_tensor(buf264, (8, 108, 83, 83), (744012, 1, 8964, 108), 0); del buf264  # reuse
        buf304 = empty_strided((8, 108, 83, 83), (744012, 1, 8964, 108), device='cuda', dtype=torch.float32)
        buf2557 = empty_strided((8, 108, 83, 83), (744012, 1, 8964, 108), device='cuda', dtype=torch.bool)
        # Source Nodes: [x_107, x_right_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu, aten.threshold_backward]
        triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_41.run(buf265, buf272, buf273, primals_84, primals_85, buf276, buf304, buf2557, 5952096, grid=grid(5952096), stream=stream0)
        del primals_85
        buf277 = empty_strided((8, 108, 87, 87), (817452, 1, 9396, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_93, x_95], Original ATen: [aten.constant_pad_nd, aten.relu]
        triton_poi_fused_constant_pad_nd_relu_42.run(buf262, buf277, 6539616, grid=grid(6539616), stream=stream0)
        # Source Nodes: [x_96], Original ATen: [aten.convolution]
        buf278 = extern_kernels.convolution(buf277, primals_9, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=108, bias=None)
        assert_size_stride(buf278, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf279 = empty_strided((8, 108, 42, 42), (190512, 1, 4536, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_96], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf278, buf279, 864, 1764, grid=grid(864, 1764), stream=stream0)
        # Source Nodes: [x_98], Original ATen: [aten.convolution]
        buf280 = extern_kernels.convolution(buf279, primals_86, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf280, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf281 = reinterpret_tensor(buf278, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf278  # reuse
        # Source Nodes: [x_98], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf280, buf281, 864, 1764, grid=grid(864, 1764), stream=stream0)
        buf282 = empty_strided((1, 108, 1, 1, 111), (11988, 1, 11988, 11988, 108), device='cuda', dtype=torch.float32)
        buf283 = empty_strided((1, 108, 1, 1, 111), (11988, 1, 11988, 11988, 108), device='cuda', dtype=torch.float32)
        buf284 = empty_strided((1, 108, 1, 1, 111), (11988, 1, 11988, 11988, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_99], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_44.run(buf281, buf282, buf283, buf284, 11988, 128, grid=grid(11988), stream=stream0)
        buf285 = buf273; del buf273  # reuse
        buf286 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf288 = empty((108, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_99], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_45.run(buf282, buf283, buf284, primals_832, primals_833, buf285, buf286, buf288, primals_832, primals_833, 108, 111, grid=grid(108), stream=stream0)
        del primals_832
        del primals_833
        buf289 = reinterpret_tensor(buf280, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf280  # reuse
        # Source Nodes: [x_100, x_99], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_46.run(buf281, buf285, buf286, primals_87, primals_88, buf289, 1524096, grid=grid(1524096), stream=stream0)
        del primals_88
        # Source Nodes: [x_101], Original ATen: [aten.convolution]
        buf290 = extern_kernels.convolution(buf289, primals_89, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=108, bias=None)
        assert_size_stride(buf290, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf291 = empty_strided((8, 108, 42, 42), (190512, 1, 4536, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_101], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf290, buf291, 864, 1764, grid=grid(864, 1764), stream=stream0)
        # Source Nodes: [x_103], Original ATen: [aten.convolution]
        buf292 = extern_kernels.convolution(buf291, primals_90, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf292, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf293 = reinterpret_tensor(buf290, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf290  # reuse
        # Source Nodes: [x_103], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf292, buf293, 864, 1764, grid=grid(864, 1764), stream=stream0)
        buf294 = buf284; del buf284  # reuse
        buf295 = buf283; del buf283  # reuse
        buf296 = buf282; del buf282  # reuse
        # Source Nodes: [x_comb_iter_0_left_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_44.run(buf293, buf294, buf295, buf296, 11988, 128, grid=grid(11988), stream=stream0)
        buf297 = buf286; del buf286  # reuse
        buf298 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf300 = empty((108, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_0_left_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_45.run(buf294, buf295, buf296, primals_835, primals_836, buf297, buf298, buf300, primals_835, primals_836, 108, 111, grid=grid(108), stream=stream0)
        del primals_835
        del primals_836
        buf301 = empty_strided((8, 108, 85, 85), (780300, 1, 9180, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_106], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_47.run(buf262, buf301, 6242400, grid=grid(6242400), stream=stream0)
        buf302 = reinterpret_tensor(buf292, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf292  # reuse
        buf303 = empty_strided((8, 108, 42, 42), (190512, 1, 4536, 108), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_0_right_1], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_48.run(buf301, buf302, buf303, 864, 1764, grid=grid(864, 1764), stream=stream0)
        buf305 = empty_strided((8, 108, 89, 89), (855468, 1, 9612, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_109], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_49.run(buf304, buf305, 6843744, grid=grid(6843744), stream=stream0)
        # Source Nodes: [x_110], Original ATen: [aten.convolution]
        buf306 = extern_kernels.convolution(buf305, primals_10, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=108, bias=None)
        assert_size_stride(buf306, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf307 = empty_strided((8, 108, 42, 42), (190512, 1, 4536, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_110], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf306, buf307, 864, 1764, grid=grid(864, 1764), stream=stream0)
        # Source Nodes: [x_112], Original ATen: [aten.convolution]
        buf308 = extern_kernels.convolution(buf307, primals_93, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf308, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf309 = reinterpret_tensor(buf306, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf306  # reuse
        # Source Nodes: [x_112], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf308, buf309, 864, 1764, grid=grid(864, 1764), stream=stream0)
        buf310 = buf296; del buf296  # reuse
        buf311 = buf295; del buf295  # reuse
        buf312 = buf294; del buf294  # reuse
        # Source Nodes: [x_113], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_44.run(buf309, buf310, buf311, buf312, 11988, 128, grid=grid(11988), stream=stream0)
        buf313 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf314 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf316 = empty((108, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_113], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_45.run(buf310, buf311, buf312, primals_838, primals_839, buf313, buf314, buf316, primals_838, primals_839, 108, 111, grid=grid(108), stream=stream0)
        del primals_838
        del primals_839
        buf317 = reinterpret_tensor(buf308, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf308  # reuse
        # Source Nodes: [x_113, x_114], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_46.run(buf309, buf313, buf314, primals_94, primals_95, buf317, 1524096, grid=grid(1524096), stream=stream0)
        del primals_95
        # Source Nodes: [x_115], Original ATen: [aten.convolution]
        buf318 = extern_kernels.convolution(buf317, primals_96, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=108, bias=None)
        assert_size_stride(buf318, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf319 = empty_strided((8, 108, 42, 42), (190512, 1, 4536, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_115], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf318, buf319, 864, 1764, grid=grid(864, 1764), stream=stream0)
        # Source Nodes: [x_117], Original ATen: [aten.convolution]
        buf320 = extern_kernels.convolution(buf319, primals_97, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf320, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf321 = reinterpret_tensor(buf318, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf318  # reuse
        # Source Nodes: [x_117], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf320, buf321, 864, 1764, grid=grid(864, 1764), stream=stream0)
        buf322 = buf312; del buf312  # reuse
        buf323 = buf311; del buf311  # reuse
        buf324 = buf310; del buf310  # reuse
        # Source Nodes: [x_comb_iter_1_left_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_44.run(buf321, buf322, buf323, buf324, 11988, 128, grid=grid(11988), stream=stream0)
        buf325 = buf314; del buf314  # reuse
        buf326 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf328 = empty((108, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_1_left_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_45.run(buf322, buf323, buf324, primals_841, primals_842, buf325, buf326, buf328, primals_841, primals_842, 108, 111, grid=grid(108), stream=stream0)
        del primals_841
        del primals_842
        buf329 = empty_strided((8, 108, 85, 85), (780300, 1, 9180, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_120], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_47.run(buf276, buf329, 6242400, grid=grid(6242400), stream=stream0)
        del buf276
        buf330 = reinterpret_tensor(buf320, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf320  # reuse
        buf331 = empty_strided((8, 108, 42, 42), (190512, 1, 4536, 108), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_1_right_1], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_48.run(buf329, buf330, buf331, 864, 1764, grid=grid(864, 1764), stream=stream0)
        buf332 = empty_strided((8, 108, 87, 87), (817452, 1, 9396, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_123], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_50.run(buf304, buf332, 6539616, grid=grid(6539616), stream=stream0)
        # Source Nodes: [x_124], Original ATen: [aten.convolution]
        buf333 = extern_kernels.convolution(buf332, primals_11, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=108, bias=None)
        assert_size_stride(buf333, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf334 = empty_strided((8, 108, 42, 42), (190512, 1, 4536, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_124], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf333, buf334, 864, 1764, grid=grid(864, 1764), stream=stream0)
        # Source Nodes: [x_126], Original ATen: [aten.convolution]
        buf335 = extern_kernels.convolution(buf334, primals_100, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf335, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf336 = reinterpret_tensor(buf333, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf333  # reuse
        # Source Nodes: [x_126], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf335, buf336, 864, 1764, grid=grid(864, 1764), stream=stream0)
        buf337 = buf324; del buf324  # reuse
        buf338 = buf323; del buf323  # reuse
        buf339 = buf322; del buf322  # reuse
        # Source Nodes: [x_127], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_44.run(buf336, buf337, buf338, buf339, 11988, 128, grid=grid(11988), stream=stream0)
        buf340 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf341 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf343 = empty((108, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_127], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_45.run(buf337, buf338, buf339, primals_844, primals_845, buf340, buf341, buf343, primals_844, primals_845, 108, 111, grid=grid(108), stream=stream0)
        del primals_844
        del primals_845
        buf344 = reinterpret_tensor(buf335, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf335  # reuse
        # Source Nodes: [x_127, x_128], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_46.run(buf336, buf340, buf341, primals_101, primals_102, buf344, 1524096, grid=grid(1524096), stream=stream0)
        del primals_102
        # Source Nodes: [x_129], Original ATen: [aten.convolution]
        buf345 = extern_kernels.convolution(buf344, primals_103, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=108, bias=None)
        assert_size_stride(buf345, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf346 = empty_strided((8, 108, 42, 42), (190512, 1, 4536, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_129], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf345, buf346, 864, 1764, grid=grid(864, 1764), stream=stream0)
        # Source Nodes: [x_131], Original ATen: [aten.convolution]
        buf347 = extern_kernels.convolution(buf346, primals_104, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf347, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf348 = reinterpret_tensor(buf345, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf345  # reuse
        # Source Nodes: [x_131], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf347, buf348, 864, 1764, grid=grid(864, 1764), stream=stream0)
        buf349 = buf339; del buf339  # reuse
        buf350 = buf338; del buf338  # reuse
        buf351 = buf337; del buf337  # reuse
        # Source Nodes: [x_comb_iter_2_left_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_44.run(buf348, buf349, buf350, buf351, 11988, 128, grid=grid(11988), stream=stream0)
        buf352 = buf341; del buf341  # reuse
        buf353 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf355 = empty((108, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_left_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_45.run(buf349, buf350, buf351, primals_847, primals_848, buf352, buf353, buf355, primals_847, primals_848, 108, 111, grid=grid(108), stream=stream0)
        del primals_847
        del primals_848
        buf356 = empty_strided((8, 108, 85, 85), (780300, 1, 9180, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_135], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_51.run(buf304, buf356, 6242400, grid=grid(6242400), stream=stream0)
        # Source Nodes: [x_136], Original ATen: [aten.convolution]
        buf357 = extern_kernels.convolution(buf356, primals_12, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=108, bias=None)
        assert_size_stride(buf357, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf358 = reinterpret_tensor(buf347, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf347  # reuse
        # Source Nodes: [x_136], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf357, buf358, 864, 1764, grid=grid(864, 1764), stream=stream0)
        # Source Nodes: [x_138], Original ATen: [aten.convolution]
        buf359 = extern_kernels.convolution(buf358, primals_107, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf359, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf360 = reinterpret_tensor(buf357, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf357  # reuse
        # Source Nodes: [x_138], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf359, buf360, 864, 1764, grid=grid(864, 1764), stream=stream0)
        buf361 = buf351; del buf351  # reuse
        buf362 = buf350; del buf350  # reuse
        buf363 = buf349; del buf349  # reuse
        # Source Nodes: [x_139], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_44.run(buf360, buf361, buf362, buf363, 11988, 128, grid=grid(11988), stream=stream0)
        buf364 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf365 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf367 = empty((108, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_139], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_45.run(buf361, buf362, buf363, primals_850, primals_851, buf364, buf365, buf367, primals_850, primals_851, 108, 111, grid=grid(108), stream=stream0)
        del primals_850
        del primals_851
        buf368 = reinterpret_tensor(buf359, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf359  # reuse
        # Source Nodes: [x_139, x_140], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_46.run(buf360, buf364, buf365, primals_108, primals_109, buf368, 1524096, grid=grid(1524096), stream=stream0)
        del primals_109
        # Source Nodes: [x_141], Original ATen: [aten.convolution]
        buf369 = extern_kernels.convolution(buf368, primals_110, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=108, bias=None)
        assert_size_stride(buf369, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf370 = empty_strided((8, 108, 42, 42), (190512, 1, 4536, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_141], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf369, buf370, 864, 1764, grid=grid(864, 1764), stream=stream0)
        # Source Nodes: [x_143], Original ATen: [aten.convolution]
        buf371 = extern_kernels.convolution(buf370, primals_111, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf371, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf372 = reinterpret_tensor(buf369, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf369  # reuse
        # Source Nodes: [x_143], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf371, buf372, 864, 1764, grid=grid(864, 1764), stream=stream0)
        buf373 = buf363; del buf363  # reuse
        buf374 = buf362; del buf362  # reuse
        buf375 = buf361; del buf361  # reuse
        # Source Nodes: [x_comb_iter_2_right_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_44.run(buf372, buf373, buf374, buf375, 11988, 128, grid=grid(11988), stream=stream0)
        buf376 = buf365; del buf365  # reuse
        buf377 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf379 = empty((108, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_right_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_45.run(buf373, buf374, buf375, primals_853, primals_854, buf376, buf377, buf379, primals_853, primals_854, 108, 111, grid=grid(108), stream=stream0)
        del primals_853
        del primals_854
        buf442 = empty((8, 540, 42, 42), device='cuda', dtype=torch.float32)
        buf380 = reinterpret_tensor(buf442, (8, 108, 42, 42), (952560, 1764, 42, 1), 381024)  # alias
        # Source Nodes: [x_comb_iter_2_left_1, x_comb_iter_2_right_1, x_comb_iter_7], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_52.run(buf348, buf352, buf353, primals_105, primals_106, buf372, buf376, buf377, primals_112, primals_113, buf380, 14112, 108, grid=grid(14112, 108), stream=stream0)
        del primals_106
        del primals_113
        buf381 = reinterpret_tensor(buf371, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf371  # reuse
        # Source Nodes: [x_145], Original ATen: [aten.relu]
        triton_poi_fused_relu_53.run(buf380, buf381, 864, 1764, grid=grid(864, 1764), stream=stream0)
        # Source Nodes: [x_146], Original ATen: [aten.convolution]
        buf382 = extern_kernels.convolution(buf381, primals_114, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=108, bias=None)
        assert_size_stride(buf382, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf383 = empty_strided((8, 108, 42, 42), (190512, 1, 4536, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_146], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf382, buf383, 864, 1764, grid=grid(864, 1764), stream=stream0)
        # Source Nodes: [x_148], Original ATen: [aten.convolution]
        buf384 = extern_kernels.convolution(buf383, primals_115, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf384, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf385 = reinterpret_tensor(buf382, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf382  # reuse
        # Source Nodes: [x_148], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf384, buf385, 864, 1764, grid=grid(864, 1764), stream=stream0)
        buf386 = buf375; del buf375  # reuse
        buf387 = buf374; del buf374  # reuse
        buf388 = buf373; del buf373  # reuse
        # Source Nodes: [x_149], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_44.run(buf385, buf386, buf387, buf388, 11988, 128, grid=grid(11988), stream=stream0)
        buf389 = buf377; del buf377  # reuse
        buf390 = buf353; del buf353  # reuse
        buf392 = empty((108, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_149], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_45.run(buf386, buf387, buf388, primals_856, primals_857, buf389, buf390, buf392, primals_856, primals_857, 108, 111, grid=grid(108), stream=stream0)
        del primals_856
        del primals_857
        buf393 = reinterpret_tensor(buf384, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf384  # reuse
        # Source Nodes: [x_149, x_150], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_46.run(buf385, buf389, buf390, primals_116, primals_117, buf393, 1524096, grid=grid(1524096), stream=stream0)
        del primals_117
        # Source Nodes: [x_151], Original ATen: [aten.convolution]
        buf394 = extern_kernels.convolution(buf393, primals_118, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=108, bias=None)
        assert_size_stride(buf394, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf395 = empty_strided((8, 108, 42, 42), (190512, 1, 4536, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_151], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf394, buf395, 864, 1764, grid=grid(864, 1764), stream=stream0)
        # Source Nodes: [x_153], Original ATen: [aten.convolution]
        buf396 = extern_kernels.convolution(buf395, primals_119, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf396, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf397 = reinterpret_tensor(buf394, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf394  # reuse
        # Source Nodes: [x_153], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf396, buf397, 864, 1764, grid=grid(864, 1764), stream=stream0)
        buf398 = buf388; del buf388  # reuse
        buf399 = buf387; del buf387  # reuse
        buf400 = buf386; del buf386  # reuse
        # Source Nodes: [x_comb_iter_3_left_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_44.run(buf397, buf398, buf399, buf400, 11988, 128, grid=grid(11988), stream=stream0)
        buf401 = buf390; del buf390  # reuse
        buf402 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf404 = empty((108, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_3_left_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_45.run(buf398, buf399, buf400, primals_859, primals_860, buf401, buf402, buf404, primals_859, primals_860, 108, 111, grid=grid(108), stream=stream0)
        del primals_859
        del primals_860
        buf405 = empty_strided((8, 108, 85, 85), (780300, 1, 9180, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_159, x_93], Original ATen: [aten.constant_pad_nd, aten.relu]
        triton_poi_fused_constant_pad_nd_relu_54.run(buf262, buf405, 6242400, grid=grid(6242400), stream=stream0)
        del buf262
        # Source Nodes: [x_160], Original ATen: [aten.convolution]
        buf406 = extern_kernels.convolution(buf405, primals_13, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=108, bias=None)
        assert_size_stride(buf406, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf407 = reinterpret_tensor(buf396, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf396  # reuse
        # Source Nodes: [x_160], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf406, buf407, 864, 1764, grid=grid(864, 1764), stream=stream0)
        # Source Nodes: [x_162], Original ATen: [aten.convolution]
        buf408 = extern_kernels.convolution(buf407, primals_122, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf408, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf409 = reinterpret_tensor(buf406, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf406  # reuse
        # Source Nodes: [x_162], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf408, buf409, 864, 1764, grid=grid(864, 1764), stream=stream0)
        buf410 = buf400; del buf400  # reuse
        buf411 = buf399; del buf399  # reuse
        buf412 = buf398; del buf398  # reuse
        # Source Nodes: [x_163], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_44.run(buf409, buf410, buf411, buf412, 11988, 128, grid=grid(11988), stream=stream0)
        buf413 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf414 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf416 = empty((108, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_163], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_45.run(buf410, buf411, buf412, primals_862, primals_863, buf413, buf414, buf416, primals_862, primals_863, 108, 111, grid=grid(108), stream=stream0)
        del primals_862
        del primals_863
        buf417 = reinterpret_tensor(buf408, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf408  # reuse
        # Source Nodes: [x_163, x_164], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_46.run(buf409, buf413, buf414, primals_123, primals_124, buf417, 1524096, grid=grid(1524096), stream=stream0)
        del primals_124
        # Source Nodes: [x_165], Original ATen: [aten.convolution]
        buf418 = extern_kernels.convolution(buf417, primals_125, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=108, bias=None)
        assert_size_stride(buf418, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf419 = empty_strided((8, 108, 42, 42), (190512, 1, 4536, 108), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_165], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf418, buf419, 864, 1764, grid=grid(864, 1764), stream=stream0)
        # Source Nodes: [x_167], Original ATen: [aten.convolution]
        buf420 = extern_kernels.convolution(buf419, primals_126, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf420, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf421 = reinterpret_tensor(buf418, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf418  # reuse
        # Source Nodes: [x_167], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf420, buf421, 864, 1764, grid=grid(864, 1764), stream=stream0)
        buf422 = buf412; del buf412  # reuse
        buf423 = buf411; del buf411  # reuse
        buf424 = buf410; del buf410  # reuse
        # Source Nodes: [x_comb_iter_4_left_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_44.run(buf421, buf422, buf423, buf424, 11988, 128, grid=grid(11988), stream=stream0)
        buf425 = buf414; del buf414  # reuse
        buf426 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf428 = empty((108, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_left_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_45.run(buf422, buf423, buf424, primals_865, primals_866, buf425, buf426, buf428, primals_865, primals_866, 108, 111, grid=grid(108), stream=stream0)
        del primals_865
        del primals_866
        # Source Nodes: [x_172], Original ATen: [aten.convolution]
        buf429 = extern_kernels.convolution(buf304, primals_14, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf429, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf430 = reinterpret_tensor(buf420, (8, 108, 42, 42), (190512, 1, 4536, 108), 0); del buf420  # reuse
        # Source Nodes: [x_172], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_43.run(buf429, buf430, 864, 1764, grid=grid(864, 1764), stream=stream0)
        buf431 = buf424; del buf424  # reuse
        buf432 = buf423; del buf423  # reuse
        buf433 = buf422; del buf422  # reuse
        # Source Nodes: [x_comb_iter_4_right_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_44.run(buf430, buf431, buf432, buf433, 11988, 128, grid=grid(11988), stream=stream0)
        buf434 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf435 = empty_strided((1, 108, 1, 1), (108, 1, 108, 108), device='cuda', dtype=torch.float32)
        buf437 = empty((108, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_right_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_45.run(buf431, buf432, buf433, primals_868, primals_869, buf434, buf435, buf437, primals_868, primals_869, 108, 111, grid=grid(108), stream=stream0)
        del buf431
        del buf432
        del buf433
        del primals_868
        del primals_869
        buf438 = reinterpret_tensor(buf442, (8, 108, 42, 42), (952560, 1764, 42, 1), 762048)  # alias
        # Source Nodes: [x_comb_iter_4_left_1, x_comb_iter_4_right_1, x_comb_iter_9], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_52.run(buf421, buf425, buf426, primals_127, primals_128, buf430, buf434, buf435, primals_129, primals_130, buf438, 14112, 108, grid=grid(14112, 108), stream=stream0)
        del buf426
        del buf435
        del primals_128
        del primals_130
        buf439 = reinterpret_tensor(buf442, (8, 108, 42, 42), (952560, 1764, 42, 1), 0)  # alias
        # Source Nodes: [x_comb_iter_0_left_1, x_comb_iter_5], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_55.run(buf293, buf297, buf298, primals_91, primals_92, buf302, buf439, 14112, 108, grid=grid(14112, 108), stream=stream0)
        del buf298
        del primals_92
        buf440 = reinterpret_tensor(buf442, (8, 108, 42, 42), (952560, 1764, 42, 1), 190512)  # alias
        buf441 = reinterpret_tensor(buf442, (8, 108, 42, 42), (952560, 1764, 42, 1), 571536)  # alias
        # Source Nodes: [x_comb_iter_1_left_1, x_comb_iter_3_left_1, x_comb_iter_6, x_comb_iter_8], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_56.run(buf321, buf325, buf326, primals_98, primals_99, buf330, buf397, buf401, buf402, primals_120, primals_121, buf440, buf441, 14112, 108, grid=grid(14112, 108), stream=stream0)
        del buf326
        del buf402
        del primals_121
        del primals_99
        buf443 = empty_strided((8, 270, 42, 42), (476280, 1, 11340, 270), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___cell_0_conv_prev_1x1_path_1_avgpool], Original ATen: [aten.avg_pool2d]
        triton_poi_fused_avg_pool2d_57.run(buf263, buf443, 3810240, grid=grid(3810240), stream=stream0)
        del buf380
        del buf438
        del buf439
        del buf440
        del buf441
        # Source Nodes: [x_path1_1], Original ATen: [aten.convolution]
        buf444 = extern_kernels.convolution(buf443, primals_131, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf444, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf445 = reinterpret_tensor(buf245, (8, 270, 83, 83), (1860030, 1, 22410, 270), 0); del buf245  # reuse
        # Source Nodes: [l__mod___cell_0_conv_prev_1x1_path_2_pad], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_58.run(buf263, buf445, 14880240, grid=grid(14880240), stream=stream0)
        buf446 = empty_strided((8, 270, 42, 42), (476280, 1, 11340, 270), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___cell_0_conv_prev_1x1_path_2_avgpool], Original ATen: [aten.avg_pool2d]
        triton_poi_fused_avg_pool2d_59.run(buf445, buf446, 2160, 1764, grid=grid(2160, 1764), stream=stream0)
        # Source Nodes: [x_path2_1], Original ATen: [aten.convolution]
        buf447 = extern_kernels.convolution(buf446, primals_132, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf447, (8, 108, 42, 42), (190512, 1764, 42, 1))
        buf448 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [cat_32], Original ATen: [aten.cat]
        triton_poi_fused_cat_60.run(buf444, buf447, buf448, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf449 = empty_strided((1, 216, 1, 1, 111), (23976, 1, 23976, 23976, 216), device='cuda', dtype=torch.float32)
        buf450 = empty_strided((1, 216, 1, 1, 111), (23976, 1, 23976, 23976, 216), device='cuda', dtype=torch.float32)
        buf451 = empty_strided((1, 216, 1, 1, 111), (23976, 1, 23976, 23976, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_left_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf448, buf449, buf450, buf451, 23976, 128, grid=grid(23976), stream=stream0)
        buf452 = reinterpret_tensor(buf237, (1, 216, 1, 1), (216, 1, 216, 216), 0); del buf237  # reuse
        buf453 = reinterpret_tensor(buf236, (1, 216, 1, 1), (216, 1, 216, 216), 0); del buf236  # reuse
        buf455 = reinterpret_tensor(buf235, (216, ), (1, ), 0); del buf235  # reuse
        # Source Nodes: [x_left_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf449, buf450, buf451, primals_871, primals_872, buf452, buf453, buf455, primals_871, primals_872, 216, 111, grid=grid(216), stream=stream0)
        del primals_871
        del primals_872
        buf456 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        buf468 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_178, x_left_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_63.run(buf448, buf452, buf453, primals_133, primals_134, buf456, buf468, 3048192, grid=grid(3048192), stream=stream0)
        del primals_134
        buf457 = empty_strided((8, 540, 42, 42), (952560, 1, 22680, 540), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_175], Original ATen: [aten.relu]
        triton_poi_fused_relu_64.run(buf442, buf457, 4320, 1764, grid=grid(4320, 1764), stream=stream0)
        # Source Nodes: [x_176], Original ATen: [aten.convolution]
        buf458 = extern_kernels.convolution(buf457, primals_135, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf458, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf459 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_176], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf458, buf459, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf460 = buf451; del buf451  # reuse
        buf461 = buf450; del buf450  # reuse
        buf462 = buf449; del buf449  # reuse
        # Source Nodes: [x_comb_iter_4_right_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf459, buf460, buf461, buf462, 23976, 128, grid=grid(23976), stream=stream0)
        buf463 = buf453; del buf453  # reuse
        buf464 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf466 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_right_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf460, buf461, buf462, primals_874, primals_875, buf463, buf464, buf466, primals_874, primals_875, 216, 111, grid=grid(216), stream=stream0)
        del primals_874
        del primals_875
        # Source Nodes: [x_229], Original ATen: [aten.convolution]
        buf591 = extern_kernels.convolution(buf468, primals_178, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf591, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf592 = reinterpret_tensor(buf458, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf458  # reuse
        # Source Nodes: [x_229], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf591, buf592, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_231], Original ATen: [aten.convolution]
        buf593 = extern_kernels.convolution(buf592, primals_179, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf593, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf594 = reinterpret_tensor(buf591, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf591  # reuse
        # Source Nodes: [x_231], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf593, buf594, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf595 = buf462; del buf462  # reuse
        buf596 = buf461; del buf461  # reuse
        buf597 = buf460; del buf460  # reuse
        # Source Nodes: [x_232], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf594, buf595, buf596, buf597, 23976, 128, grid=grid(23976), stream=stream0)
        buf598 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf599 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf601 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_232], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf595, buf596, buf597, primals_907, primals_908, buf598, buf599, buf601, primals_907, primals_908, 216, 111, grid=grid(216), stream=stream0)
        del primals_907
        del primals_908
        buf602 = reinterpret_tensor(buf593, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf593  # reuse
        # Source Nodes: [x_232, x_233], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf594, buf598, buf599, primals_180, primals_181, buf602, 3048192, grid=grid(3048192), stream=stream0)
        del primals_181
        # Source Nodes: [x_234], Original ATen: [aten.convolution]
        buf603 = extern_kernels.convolution(buf602, primals_182, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf603, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf604 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_234], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf603, buf604, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_236], Original ATen: [aten.convolution]
        buf605 = extern_kernels.convolution(buf604, primals_183, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf605, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf606 = reinterpret_tensor(buf603, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf603  # reuse
        # Source Nodes: [x_236], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf605, buf606, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf607 = buf597; del buf597  # reuse
        buf608 = buf596; del buf596  # reuse
        buf609 = buf595; del buf595  # reuse
        # Source Nodes: [x_comb_iter_4_left_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf606, buf607, buf608, buf609, 23976, 128, grid=grid(23976), stream=stream0)
        buf610 = buf599; del buf599  # reuse
        buf611 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf613 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_left_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf607, buf608, buf609, primals_910, primals_911, buf610, buf611, buf613, primals_910, primals_911, 216, 111, grid=grid(216), stream=stream0)
        del primals_910
        del primals_911
        buf467 = reinterpret_tensor(buf605, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf605  # reuse
        buf618 = empty((8, 1080, 42, 42), device='cuda', dtype=torch.float32)
        buf617 = reinterpret_tensor(buf618, (8, 216, 42, 42), (1905120, 1764, 42, 1), 1524096)  # alias
        # Source Nodes: [x_comb_iter_14, x_comb_iter_4_left_2, x_comb_iter_4_right_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_67.run(buf459, buf463, buf464, primals_136, primals_137, buf606, buf610, buf611, primals_184, primals_185, buf467, buf617, 14112, 216, grid=grid(14112, 216), stream=stream0)
        del primals_137
        del primals_185
        # Source Nodes: [x_179], Original ATen: [aten.convolution]
        buf469 = extern_kernels.convolution(buf468, primals_138, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf469, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf470 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_179], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf469, buf470, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_181], Original ATen: [aten.convolution]
        buf471 = extern_kernels.convolution(buf470, primals_139, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf471, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf472 = reinterpret_tensor(buf469, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf469  # reuse
        # Source Nodes: [x_181], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf471, buf472, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf473 = buf609; del buf609  # reuse
        buf474 = buf608; del buf608  # reuse
        buf475 = buf607; del buf607  # reuse
        # Source Nodes: [x_182], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf472, buf473, buf474, buf475, 23976, 128, grid=grid(23976), stream=stream0)
        buf476 = buf611; del buf611  # reuse
        buf477 = buf464; del buf464  # reuse
        buf479 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_182], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf473, buf474, buf475, primals_877, primals_878, buf476, buf477, buf479, primals_877, primals_878, 216, 111, grid=grid(216), stream=stream0)
        del primals_877
        del primals_878
        buf480 = reinterpret_tensor(buf471, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf471  # reuse
        # Source Nodes: [x_182, x_183], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf472, buf476, buf477, primals_140, primals_141, buf480, 3048192, grid=grid(3048192), stream=stream0)
        del primals_141
        # Source Nodes: [x_184], Original ATen: [aten.convolution]
        buf481 = extern_kernels.convolution(buf480, primals_142, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf481, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf482 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_184], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf481, buf482, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_186], Original ATen: [aten.convolution]
        buf483 = extern_kernels.convolution(buf482, primals_143, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf483, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf484 = reinterpret_tensor(buf481, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf481  # reuse
        # Source Nodes: [x_186], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf483, buf484, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf485 = buf475; del buf475  # reuse
        buf486 = buf474; del buf474  # reuse
        buf487 = buf473; del buf473  # reuse
        # Source Nodes: [x_comb_iter_0_left_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf484, buf485, buf486, buf487, 23976, 128, grid=grid(23976), stream=stream0)
        buf488 = buf477; del buf477  # reuse
        buf489 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf491 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_0_left_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf485, buf486, buf487, primals_880, primals_881, buf488, buf489, buf491, primals_880, primals_881, 216, 111, grid=grid(216), stream=stream0)
        del primals_880
        del primals_881
        buf492 = reinterpret_tensor(buf483, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf483  # reuse
        buf493 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_0_right_2], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_68.run(buf456, buf492, buf493, 3048192, grid=grid(3048192), stream=stream0)
        buf494 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        buf518 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        buf519 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_188, x_comb_iter_1_right_2], Original ATen: [aten.max_pool2d_with_indices, aten.relu]
        triton_poi_fused_max_pool2d_with_indices_relu_69.run(buf467, buf494, buf518, buf519, 3048192, grid=grid(3048192), stream=stream0)
        # Source Nodes: [x_189], Original ATen: [aten.convolution]
        buf495 = extern_kernels.convolution(buf494, primals_146, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf495, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf496 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_189], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf495, buf496, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_191], Original ATen: [aten.convolution]
        buf497 = extern_kernels.convolution(buf496, primals_147, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf497, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf498 = reinterpret_tensor(buf495, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf495  # reuse
        # Source Nodes: [x_191], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf497, buf498, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf499 = buf487; del buf487  # reuse
        buf500 = buf486; del buf486  # reuse
        buf501 = buf485; del buf485  # reuse
        # Source Nodes: [x_192], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf498, buf499, buf500, buf501, 23976, 128, grid=grid(23976), stream=stream0)
        buf502 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf503 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf505 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_192], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf499, buf500, buf501, primals_883, primals_884, buf502, buf503, buf505, primals_883, primals_884, 216, 111, grid=grid(216), stream=stream0)
        del primals_883
        del primals_884
        buf506 = reinterpret_tensor(buf497, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf497  # reuse
        # Source Nodes: [x_192, x_193], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf498, buf502, buf503, primals_148, primals_149, buf506, 3048192, grid=grid(3048192), stream=stream0)
        del primals_149
        # Source Nodes: [x_194], Original ATen: [aten.convolution]
        buf507 = extern_kernels.convolution(buf506, primals_150, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf507, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf508 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_194], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf507, buf508, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_196], Original ATen: [aten.convolution]
        buf509 = extern_kernels.convolution(buf508, primals_151, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf509, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf510 = reinterpret_tensor(buf507, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf507  # reuse
        # Source Nodes: [x_196], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf509, buf510, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf511 = buf501; del buf501  # reuse
        buf512 = buf500; del buf500  # reuse
        buf513 = buf499; del buf499  # reuse
        # Source Nodes: [x_comb_iter_1_left_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf510, buf511, buf512, buf513, 23976, 128, grid=grid(23976), stream=stream0)
        buf514 = buf503; del buf503  # reuse
        buf515 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf517 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_1_left_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf511, buf512, buf513, primals_886, primals_887, buf514, buf515, buf517, primals_886, primals_887, 216, 111, grid=grid(216), stream=stream0)
        del primals_886
        del primals_887
        # Source Nodes: [x_199], Original ATen: [aten.convolution]
        buf520 = extern_kernels.convolution(buf494, primals_154, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf520, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf521 = reinterpret_tensor(buf509, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf509  # reuse
        # Source Nodes: [x_199], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf520, buf521, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_201], Original ATen: [aten.convolution]
        buf522 = extern_kernels.convolution(buf521, primals_155, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf522, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf523 = reinterpret_tensor(buf520, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf520  # reuse
        # Source Nodes: [x_201], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf522, buf523, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf524 = buf513; del buf513  # reuse
        buf525 = buf512; del buf512  # reuse
        buf526 = buf511; del buf511  # reuse
        # Source Nodes: [x_202], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf523, buf524, buf525, buf526, 23976, 128, grid=grid(23976), stream=stream0)
        buf527 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf528 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf530 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_202], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf524, buf525, buf526, primals_889, primals_890, buf527, buf528, buf530, primals_889, primals_890, 216, 111, grid=grid(216), stream=stream0)
        del primals_889
        del primals_890
        buf531 = reinterpret_tensor(buf522, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf522  # reuse
        # Source Nodes: [x_202, x_203], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf523, buf527, buf528, primals_156, primals_157, buf531, 3048192, grid=grid(3048192), stream=stream0)
        del primals_157
        # Source Nodes: [x_204], Original ATen: [aten.convolution]
        buf532 = extern_kernels.convolution(buf531, primals_158, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf532, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf533 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_204], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf532, buf533, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_206], Original ATen: [aten.convolution]
        buf534 = extern_kernels.convolution(buf533, primals_159, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf534, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf535 = reinterpret_tensor(buf532, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf532  # reuse
        # Source Nodes: [x_206], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf534, buf535, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf536 = buf526; del buf526  # reuse
        buf537 = buf525; del buf525  # reuse
        buf538 = buf524; del buf524  # reuse
        # Source Nodes: [x_comb_iter_2_left_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf535, buf536, buf537, buf538, 23976, 128, grid=grid(23976), stream=stream0)
        buf539 = buf528; del buf528  # reuse
        buf540 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf542 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_left_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf536, buf537, buf538, primals_892, primals_893, buf539, buf540, buf542, primals_892, primals_893, 216, 111, grid=grid(216), stream=stream0)
        del primals_892
        del primals_893
        # Source Nodes: [x_209], Original ATen: [aten.convolution]
        buf543 = extern_kernels.convolution(buf494, primals_162, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf543, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf544 = reinterpret_tensor(buf534, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf534  # reuse
        # Source Nodes: [x_209], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf543, buf544, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_211], Original ATen: [aten.convolution]
        buf545 = extern_kernels.convolution(buf544, primals_163, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf545, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf546 = reinterpret_tensor(buf543, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf543  # reuse
        # Source Nodes: [x_211], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf545, buf546, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf547 = buf538; del buf538  # reuse
        buf548 = buf537; del buf537  # reuse
        buf549 = buf536; del buf536  # reuse
        # Source Nodes: [x_212], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf546, buf547, buf548, buf549, 23976, 128, grid=grid(23976), stream=stream0)
        buf550 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf551 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf553 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_212], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf547, buf548, buf549, primals_895, primals_896, buf550, buf551, buf553, primals_895, primals_896, 216, 111, grid=grid(216), stream=stream0)
        del primals_895
        del primals_896
        buf554 = reinterpret_tensor(buf545, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf545  # reuse
        # Source Nodes: [x_212, x_213], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf546, buf550, buf551, primals_164, primals_165, buf554, 3048192, grid=grid(3048192), stream=stream0)
        del primals_165
        # Source Nodes: [x_214], Original ATen: [aten.convolution]
        buf555 = extern_kernels.convolution(buf554, primals_166, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf555, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf556 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_214], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf555, buf556, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_216], Original ATen: [aten.convolution]
        buf557 = extern_kernels.convolution(buf556, primals_167, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf557, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf558 = reinterpret_tensor(buf555, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf555  # reuse
        # Source Nodes: [x_216], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf557, buf558, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf559 = buf549; del buf549  # reuse
        buf560 = buf548; del buf548  # reuse
        buf561 = buf547; del buf547  # reuse
        # Source Nodes: [x_comb_iter_2_right_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf558, buf559, buf560, buf561, 23976, 128, grid=grid(23976), stream=stream0)
        buf562 = buf551; del buf551  # reuse
        buf563 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf565 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_right_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf559, buf560, buf561, primals_898, primals_899, buf562, buf563, buf565, primals_898, primals_899, 216, 111, grid=grid(216), stream=stream0)
        del primals_898
        del primals_899
        buf566 = reinterpret_tensor(buf618, (8, 216, 42, 42), (1905120, 1764, 42, 1), 762048)  # alias
        # Source Nodes: [x_comb_iter_12, x_comb_iter_2_left_2, x_comb_iter_2_right_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_70.run(buf535, buf539, buf540, primals_160, primals_161, buf558, buf562, buf563, primals_168, primals_169, buf566, 14112, 216, grid=grid(14112, 216), stream=stream0)
        del primals_161
        del primals_169
        buf567 = reinterpret_tensor(buf557, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf557  # reuse
        # Source Nodes: [x_218], Original ATen: [aten.relu]
        triton_poi_fused_relu_71.run(buf566, buf567, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_219], Original ATen: [aten.convolution]
        buf568 = extern_kernels.convolution(buf567, primals_170, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf568, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf569 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_219], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf568, buf569, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_221], Original ATen: [aten.convolution]
        buf570 = extern_kernels.convolution(buf569, primals_171, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf570, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf571 = reinterpret_tensor(buf568, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf568  # reuse
        # Source Nodes: [x_221], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf570, buf571, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf572 = buf561; del buf561  # reuse
        buf573 = buf560; del buf560  # reuse
        buf574 = buf559; del buf559  # reuse
        # Source Nodes: [x_222], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf571, buf572, buf573, buf574, 23976, 128, grid=grid(23976), stream=stream0)
        buf575 = buf563; del buf563  # reuse
        buf576 = buf540; del buf540  # reuse
        buf578 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_222], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf572, buf573, buf574, primals_901, primals_902, buf575, buf576, buf578, primals_901, primals_902, 216, 111, grid=grid(216), stream=stream0)
        del primals_901
        del primals_902
        buf579 = reinterpret_tensor(buf570, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf570  # reuse
        # Source Nodes: [x_222, x_223], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf571, buf575, buf576, primals_172, primals_173, buf579, 3048192, grid=grid(3048192), stream=stream0)
        del primals_173
        # Source Nodes: [x_224], Original ATen: [aten.convolution]
        buf580 = extern_kernels.convolution(buf579, primals_174, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf580, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf581 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_224], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf580, buf581, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_226], Original ATen: [aten.convolution]
        buf582 = extern_kernels.convolution(buf581, primals_175, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf582, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf583 = reinterpret_tensor(buf580, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf580  # reuse
        # Source Nodes: [x_226], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf582, buf583, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf584 = buf574; del buf574  # reuse
        buf585 = buf573; del buf573  # reuse
        buf586 = buf572; del buf572  # reuse
        # Source Nodes: [x_comb_iter_3_left_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf583, buf584, buf585, buf586, 23976, 128, grid=grid(23976), stream=stream0)
        buf587 = buf576; del buf576  # reuse
        buf588 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf590 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_3_left_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf584, buf585, buf586, primals_904, primals_905, buf587, buf588, buf590, primals_904, primals_905, 216, 111, grid=grid(216), stream=stream0)
        del primals_904
        del primals_905
        buf614 = reinterpret_tensor(buf618, (8, 216, 42, 42), (1905120, 1764, 42, 1), 0)  # alias
        # Source Nodes: [x_comb_iter_0_left_2, x_comb_iter_10], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_72.run(buf484, buf488, buf489, primals_144, primals_145, buf492, buf614, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        del primals_145
        buf615 = reinterpret_tensor(buf618, (8, 216, 42, 42), (1905120, 1764, 42, 1), 381024)  # alias
        buf616 = reinterpret_tensor(buf618, (8, 216, 42, 42), (1905120, 1764, 42, 1), 1143072)  # alias
        # Source Nodes: [x_comb_iter_11, x_comb_iter_13, x_comb_iter_1_left_2, x_comb_iter_3_left_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_73.run(buf510, buf514, buf515, primals_152, primals_153, buf518, buf583, buf587, buf588, primals_176, primals_177, buf615, buf616, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        del primals_153
        del primals_177
        del buf566
        del buf614
        del buf615
        del buf616
        del buf617
        # Source Nodes: [x_239], Original ATen: [aten.convolution]
        buf619 = extern_kernels.convolution(buf457, primals_186, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf619, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf620 = buf518; del buf518  # reuse
        # Source Nodes: [x_239], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf619, buf620, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf621 = buf586; del buf586  # reuse
        buf622 = buf585; del buf585  # reuse
        buf623 = buf584; del buf584  # reuse
        # Source Nodes: [x_left_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf620, buf621, buf622, buf623, 23976, 128, grid=grid(23976), stream=stream0)
        buf624 = buf588; del buf588  # reuse
        buf625 = buf515; del buf515  # reuse
        buf627 = reinterpret_tensor(buf489, (216, ), (1, ), 0); del buf489  # reuse
        # Source Nodes: [x_left_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf621, buf622, buf623, primals_913, primals_914, buf624, buf625, buf627, primals_913, primals_914, 216, 111, grid=grid(216), stream=stream0)
        del primals_913
        del primals_914
        buf628 = reinterpret_tensor(buf619, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf619  # reuse
        buf640 = buf492; del buf492  # reuse
        # Source Nodes: [x_244, x_left_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_63.run(buf620, buf624, buf625, primals_187, primals_188, buf628, buf640, 3048192, grid=grid(3048192), stream=stream0)
        del primals_188
        buf629 = empty_strided((8, 1080, 42, 42), (1905120, 1, 45360, 1080), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_241], Original ATen: [aten.relu]
        triton_poi_fused_relu_74.run(buf618, buf629, 8640, 1764, grid=grid(8640, 1764), stream=stream0)
        # Source Nodes: [x_242], Original ATen: [aten.convolution]
        buf630 = extern_kernels.convolution(buf629, primals_189, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf630, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf631 = reinterpret_tensor(buf582, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf582  # reuse
        # Source Nodes: [x_242], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf630, buf631, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf632 = buf623; del buf623  # reuse
        buf633 = buf622; del buf622  # reuse
        buf634 = buf621; del buf621  # reuse
        # Source Nodes: [x_comb_iter_4_right_3], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf631, buf632, buf633, buf634, 23976, 128, grid=grid(23976), stream=stream0)
        buf635 = buf625; del buf625  # reuse
        buf636 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf638 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_right_3], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf632, buf633, buf634, primals_916, primals_917, buf635, buf636, buf638, primals_916, primals_917, 216, 111, grid=grid(216), stream=stream0)
        del primals_916
        del primals_917
        # Source Nodes: [x_295], Original ATen: [aten.convolution]
        buf763 = extern_kernels.convolution(buf640, primals_232, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf763, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf764 = reinterpret_tensor(buf630, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf630  # reuse
        # Source Nodes: [x_295], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf763, buf764, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_297], Original ATen: [aten.convolution]
        buf765 = extern_kernels.convolution(buf764, primals_233, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf765, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf766 = reinterpret_tensor(buf763, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf763  # reuse
        # Source Nodes: [x_297], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf765, buf766, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf767 = buf634; del buf634  # reuse
        buf768 = buf633; del buf633  # reuse
        buf769 = buf632; del buf632  # reuse
        # Source Nodes: [x_298], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf766, buf767, buf768, buf769, 23976, 128, grid=grid(23976), stream=stream0)
        buf770 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf771 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf773 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_298], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf767, buf768, buf769, primals_949, primals_950, buf770, buf771, buf773, primals_949, primals_950, 216, 111, grid=grid(216), stream=stream0)
        del primals_949
        del primals_950
        buf774 = reinterpret_tensor(buf765, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf765  # reuse
        # Source Nodes: [x_298, x_299], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf766, buf770, buf771, primals_234, primals_235, buf774, 3048192, grid=grid(3048192), stream=stream0)
        del primals_235
        # Source Nodes: [x_300], Original ATen: [aten.convolution]
        buf775 = extern_kernels.convolution(buf774, primals_236, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf775, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf776 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_300], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf775, buf776, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_302], Original ATen: [aten.convolution]
        buf777 = extern_kernels.convolution(buf776, primals_237, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf777, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf778 = reinterpret_tensor(buf775, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf775  # reuse
        # Source Nodes: [x_302], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf777, buf778, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf779 = buf769; del buf769  # reuse
        buf780 = buf768; del buf768  # reuse
        buf781 = buf767; del buf767  # reuse
        # Source Nodes: [x_comb_iter_4_left_3], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf778, buf779, buf780, buf781, 23976, 128, grid=grid(23976), stream=stream0)
        buf782 = buf771; del buf771  # reuse
        buf783 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf785 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_left_3], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf779, buf780, buf781, primals_952, primals_953, buf782, buf783, buf785, primals_952, primals_953, 216, 111, grid=grid(216), stream=stream0)
        del primals_952
        del primals_953
        buf639 = reinterpret_tensor(buf777, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf777  # reuse
        buf790 = buf618; del buf618  # reuse
        buf789 = reinterpret_tensor(buf790, (8, 216, 42, 42), (1905120, 1764, 42, 1), 1524096)  # alias
        # Source Nodes: [x_comb_iter_19, x_comb_iter_4_left_3, x_comb_iter_4_right_3], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_67.run(buf631, buf635, buf636, primals_190, primals_191, buf778, buf782, buf783, primals_238, primals_239, buf639, buf789, 14112, 216, grid=grid(14112, 216), stream=stream0)
        del primals_191
        del primals_239
        # Source Nodes: [x_245], Original ATen: [aten.convolution]
        buf641 = extern_kernels.convolution(buf640, primals_192, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf641, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf642 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_245], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf641, buf642, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_247], Original ATen: [aten.convolution]
        buf643 = extern_kernels.convolution(buf642, primals_193, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf643, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf644 = reinterpret_tensor(buf641, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf641  # reuse
        # Source Nodes: [x_247], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf643, buf644, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf645 = buf781; del buf781  # reuse
        buf646 = buf780; del buf780  # reuse
        buf647 = buf779; del buf779  # reuse
        # Source Nodes: [x_248], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf644, buf645, buf646, buf647, 23976, 128, grid=grid(23976), stream=stream0)
        buf648 = buf783; del buf783  # reuse
        buf649 = buf636; del buf636  # reuse
        buf651 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_248], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf645, buf646, buf647, primals_919, primals_920, buf648, buf649, buf651, primals_919, primals_920, 216, 111, grid=grid(216), stream=stream0)
        del primals_919
        del primals_920
        buf652 = reinterpret_tensor(buf643, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf643  # reuse
        # Source Nodes: [x_248, x_249], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf644, buf648, buf649, primals_194, primals_195, buf652, 3048192, grid=grid(3048192), stream=stream0)
        del primals_195
        # Source Nodes: [x_250], Original ATen: [aten.convolution]
        buf653 = extern_kernels.convolution(buf652, primals_196, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf653, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf654 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_250], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf653, buf654, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_252], Original ATen: [aten.convolution]
        buf655 = extern_kernels.convolution(buf654, primals_197, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf655, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf656 = reinterpret_tensor(buf653, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf653  # reuse
        # Source Nodes: [x_252], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf655, buf656, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf657 = buf647; del buf647  # reuse
        buf658 = buf646; del buf646  # reuse
        buf659 = buf645; del buf645  # reuse
        # Source Nodes: [x_comb_iter_0_left_3], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf656, buf657, buf658, buf659, 23976, 128, grid=grid(23976), stream=stream0)
        buf660 = buf649; del buf649  # reuse
        buf661 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf663 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_0_left_3], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf657, buf658, buf659, primals_922, primals_923, buf660, buf661, buf663, primals_922, primals_923, 216, 111, grid=grid(216), stream=stream0)
        del primals_922
        del primals_923
        buf664 = reinterpret_tensor(buf655, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf655  # reuse
        buf665 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_0_right_3], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_68.run(buf628, buf664, buf665, 3048192, grid=grid(3048192), stream=stream0)
        buf666 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        buf690 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        buf691 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_254, x_comb_iter_1_right_3], Original ATen: [aten.max_pool2d_with_indices, aten.relu]
        triton_poi_fused_max_pool2d_with_indices_relu_69.run(buf639, buf666, buf690, buf691, 3048192, grid=grid(3048192), stream=stream0)
        # Source Nodes: [x_255], Original ATen: [aten.convolution]
        buf667 = extern_kernels.convolution(buf666, primals_200, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf667, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf668 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_255], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf667, buf668, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_257], Original ATen: [aten.convolution]
        buf669 = extern_kernels.convolution(buf668, primals_201, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf669, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf670 = reinterpret_tensor(buf667, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf667  # reuse
        # Source Nodes: [x_257], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf669, buf670, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf671 = buf659; del buf659  # reuse
        buf672 = buf658; del buf658  # reuse
        buf673 = buf657; del buf657  # reuse
        # Source Nodes: [x_258], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf670, buf671, buf672, buf673, 23976, 128, grid=grid(23976), stream=stream0)
        buf674 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf675 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf677 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_258], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf671, buf672, buf673, primals_925, primals_926, buf674, buf675, buf677, primals_925, primals_926, 216, 111, grid=grid(216), stream=stream0)
        del primals_925
        del primals_926
        buf678 = reinterpret_tensor(buf669, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf669  # reuse
        # Source Nodes: [x_258, x_259], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf670, buf674, buf675, primals_202, primals_203, buf678, 3048192, grid=grid(3048192), stream=stream0)
        del primals_203
        # Source Nodes: [x_260], Original ATen: [aten.convolution]
        buf679 = extern_kernels.convolution(buf678, primals_204, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf679, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf680 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_260], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf679, buf680, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_262], Original ATen: [aten.convolution]
        buf681 = extern_kernels.convolution(buf680, primals_205, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf681, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf682 = reinterpret_tensor(buf679, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf679  # reuse
        # Source Nodes: [x_262], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf681, buf682, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf683 = buf673; del buf673  # reuse
        buf684 = buf672; del buf672  # reuse
        buf685 = buf671; del buf671  # reuse
        # Source Nodes: [x_comb_iter_1_left_3], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf682, buf683, buf684, buf685, 23976, 128, grid=grid(23976), stream=stream0)
        buf686 = buf675; del buf675  # reuse
        buf687 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf689 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_1_left_3], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf683, buf684, buf685, primals_928, primals_929, buf686, buf687, buf689, primals_928, primals_929, 216, 111, grid=grid(216), stream=stream0)
        del primals_928
        del primals_929
        # Source Nodes: [x_265], Original ATen: [aten.convolution]
        buf692 = extern_kernels.convolution(buf666, primals_208, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf692, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf693 = reinterpret_tensor(buf681, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf681  # reuse
        # Source Nodes: [x_265], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf692, buf693, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_267], Original ATen: [aten.convolution]
        buf694 = extern_kernels.convolution(buf693, primals_209, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf694, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf695 = reinterpret_tensor(buf692, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf692  # reuse
        # Source Nodes: [x_267], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf694, buf695, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf696 = buf685; del buf685  # reuse
        buf697 = buf684; del buf684  # reuse
        buf698 = buf683; del buf683  # reuse
        # Source Nodes: [x_268], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf695, buf696, buf697, buf698, 23976, 128, grid=grid(23976), stream=stream0)
        buf699 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf700 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf702 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_268], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf696, buf697, buf698, primals_931, primals_932, buf699, buf700, buf702, primals_931, primals_932, 216, 111, grid=grid(216), stream=stream0)
        del primals_931
        del primals_932
        buf703 = reinterpret_tensor(buf694, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf694  # reuse
        # Source Nodes: [x_268, x_269], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf695, buf699, buf700, primals_210, primals_211, buf703, 3048192, grid=grid(3048192), stream=stream0)
        del primals_211
        # Source Nodes: [x_270], Original ATen: [aten.convolution]
        buf704 = extern_kernels.convolution(buf703, primals_212, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf704, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf705 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_270], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf704, buf705, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_272], Original ATen: [aten.convolution]
        buf706 = extern_kernels.convolution(buf705, primals_213, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf706, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf707 = reinterpret_tensor(buf704, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf704  # reuse
        # Source Nodes: [x_272], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf706, buf707, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf708 = buf698; del buf698  # reuse
        buf709 = buf697; del buf697  # reuse
        buf710 = buf696; del buf696  # reuse
        # Source Nodes: [x_comb_iter_2_left_3], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf707, buf708, buf709, buf710, 23976, 128, grid=grid(23976), stream=stream0)
        buf711 = buf700; del buf700  # reuse
        buf712 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf714 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_left_3], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf708, buf709, buf710, primals_934, primals_935, buf711, buf712, buf714, primals_934, primals_935, 216, 111, grid=grid(216), stream=stream0)
        del primals_934
        del primals_935
        # Source Nodes: [x_275], Original ATen: [aten.convolution]
        buf715 = extern_kernels.convolution(buf666, primals_216, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf715, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf716 = reinterpret_tensor(buf706, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf706  # reuse
        # Source Nodes: [x_275], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf715, buf716, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_277], Original ATen: [aten.convolution]
        buf717 = extern_kernels.convolution(buf716, primals_217, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf717, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf718 = reinterpret_tensor(buf715, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf715  # reuse
        # Source Nodes: [x_277], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf717, buf718, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf719 = buf710; del buf710  # reuse
        buf720 = buf709; del buf709  # reuse
        buf721 = buf708; del buf708  # reuse
        # Source Nodes: [x_278], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf718, buf719, buf720, buf721, 23976, 128, grid=grid(23976), stream=stream0)
        buf722 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf723 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf725 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_278], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf719, buf720, buf721, primals_937, primals_938, buf722, buf723, buf725, primals_937, primals_938, 216, 111, grid=grid(216), stream=stream0)
        del primals_937
        del primals_938
        buf726 = reinterpret_tensor(buf717, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf717  # reuse
        # Source Nodes: [x_278, x_279], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf718, buf722, buf723, primals_218, primals_219, buf726, 3048192, grid=grid(3048192), stream=stream0)
        del primals_219
        # Source Nodes: [x_280], Original ATen: [aten.convolution]
        buf727 = extern_kernels.convolution(buf726, primals_220, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf727, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf728 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_280], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf727, buf728, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_282], Original ATen: [aten.convolution]
        buf729 = extern_kernels.convolution(buf728, primals_221, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf729, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf730 = reinterpret_tensor(buf727, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf727  # reuse
        # Source Nodes: [x_282], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf729, buf730, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf731 = buf721; del buf721  # reuse
        buf732 = buf720; del buf720  # reuse
        buf733 = buf719; del buf719  # reuse
        # Source Nodes: [x_comb_iter_2_right_3], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf730, buf731, buf732, buf733, 23976, 128, grid=grid(23976), stream=stream0)
        buf734 = buf723; del buf723  # reuse
        buf735 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf737 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_right_3], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf731, buf732, buf733, primals_940, primals_941, buf734, buf735, buf737, primals_940, primals_941, 216, 111, grid=grid(216), stream=stream0)
        del primals_940
        del primals_941
        buf738 = reinterpret_tensor(buf790, (8, 216, 42, 42), (1905120, 1764, 42, 1), 762048)  # alias
        # Source Nodes: [x_comb_iter_17, x_comb_iter_2_left_3, x_comb_iter_2_right_3], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_70.run(buf707, buf711, buf712, primals_214, primals_215, buf730, buf734, buf735, primals_222, primals_223, buf738, 14112, 216, grid=grid(14112, 216), stream=stream0)
        del primals_215
        del primals_223
        buf739 = reinterpret_tensor(buf729, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf729  # reuse
        # Source Nodes: [x_284], Original ATen: [aten.relu]
        triton_poi_fused_relu_71.run(buf738, buf739, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_285], Original ATen: [aten.convolution]
        buf740 = extern_kernels.convolution(buf739, primals_224, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf740, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf741 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_285], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf740, buf741, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_287], Original ATen: [aten.convolution]
        buf742 = extern_kernels.convolution(buf741, primals_225, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf742, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf743 = reinterpret_tensor(buf740, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf740  # reuse
        # Source Nodes: [x_287], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf742, buf743, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf744 = buf733; del buf733  # reuse
        buf745 = buf732; del buf732  # reuse
        buf746 = buf731; del buf731  # reuse
        # Source Nodes: [x_288], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf743, buf744, buf745, buf746, 23976, 128, grid=grid(23976), stream=stream0)
        buf747 = buf735; del buf735  # reuse
        buf748 = buf712; del buf712  # reuse
        buf750 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_288], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf744, buf745, buf746, primals_943, primals_944, buf747, buf748, buf750, primals_943, primals_944, 216, 111, grid=grid(216), stream=stream0)
        del primals_943
        del primals_944
        buf751 = reinterpret_tensor(buf742, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf742  # reuse
        # Source Nodes: [x_288, x_289], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf743, buf747, buf748, primals_226, primals_227, buf751, 3048192, grid=grid(3048192), stream=stream0)
        del primals_227
        # Source Nodes: [x_290], Original ATen: [aten.convolution]
        buf752 = extern_kernels.convolution(buf751, primals_228, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf752, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf753 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_290], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf752, buf753, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_292], Original ATen: [aten.convolution]
        buf754 = extern_kernels.convolution(buf753, primals_229, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf754, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf755 = reinterpret_tensor(buf752, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf752  # reuse
        # Source Nodes: [x_292], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf754, buf755, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf756 = buf746; del buf746  # reuse
        buf757 = buf745; del buf745  # reuse
        buf758 = buf744; del buf744  # reuse
        # Source Nodes: [x_comb_iter_3_left_3], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf755, buf756, buf757, buf758, 23976, 128, grid=grid(23976), stream=stream0)
        buf759 = buf748; del buf748  # reuse
        buf760 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf762 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_3_left_3], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf756, buf757, buf758, primals_946, primals_947, buf759, buf760, buf762, primals_946, primals_947, 216, 111, grid=grid(216), stream=stream0)
        del primals_946
        del primals_947
        buf786 = reinterpret_tensor(buf790, (8, 216, 42, 42), (1905120, 1764, 42, 1), 0)  # alias
        # Source Nodes: [x_comb_iter_0_left_3, x_comb_iter_15], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_72.run(buf656, buf660, buf661, primals_198, primals_199, buf664, buf786, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        del primals_199
        buf787 = reinterpret_tensor(buf790, (8, 216, 42, 42), (1905120, 1764, 42, 1), 381024)  # alias
        buf788 = reinterpret_tensor(buf790, (8, 216, 42, 42), (1905120, 1764, 42, 1), 1143072)  # alias
        # Source Nodes: [x_comb_iter_16, x_comb_iter_18, x_comb_iter_1_left_3, x_comb_iter_3_left_3], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_73.run(buf682, buf686, buf687, primals_206, primals_207, buf690, buf755, buf759, buf760, primals_230, primals_231, buf787, buf788, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        del primals_207
        del primals_231
        del buf738
        del buf786
        del buf787
        del buf788
        del buf789
        # Source Nodes: [x_305], Original ATen: [aten.convolution]
        buf791 = extern_kernels.convolution(buf629, primals_240, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf791, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf792 = buf690; del buf690  # reuse
        # Source Nodes: [x_305], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf791, buf792, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf793 = buf758; del buf758  # reuse
        buf794 = buf757; del buf757  # reuse
        buf795 = buf756; del buf756  # reuse
        # Source Nodes: [x_left_3], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf792, buf793, buf794, buf795, 23976, 128, grid=grid(23976), stream=stream0)
        buf796 = buf760; del buf760  # reuse
        buf797 = buf687; del buf687  # reuse
        buf799 = reinterpret_tensor(buf661, (216, ), (1, ), 0); del buf661  # reuse
        # Source Nodes: [x_left_3], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf793, buf794, buf795, primals_955, primals_956, buf796, buf797, buf799, primals_955, primals_956, 216, 111, grid=grid(216), stream=stream0)
        del primals_955
        del primals_956
        buf800 = reinterpret_tensor(buf791, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf791  # reuse
        buf812 = buf664; del buf664  # reuse
        # Source Nodes: [x_310, x_left_3], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_63.run(buf792, buf796, buf797, primals_241, primals_242, buf800, buf812, 3048192, grid=grid(3048192), stream=stream0)
        del primals_242
        buf801 = empty_strided((8, 1080, 42, 42), (1905120, 1, 45360, 1080), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_307], Original ATen: [aten.relu]
        triton_poi_fused_relu_74.run(buf790, buf801, 8640, 1764, grid=grid(8640, 1764), stream=stream0)
        # Source Nodes: [x_308], Original ATen: [aten.convolution]
        buf802 = extern_kernels.convolution(buf801, primals_243, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf802, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf803 = reinterpret_tensor(buf754, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf754  # reuse
        # Source Nodes: [x_308], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf802, buf803, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf804 = buf795; del buf795  # reuse
        buf805 = buf794; del buf794  # reuse
        buf806 = buf793; del buf793  # reuse
        # Source Nodes: [x_comb_iter_4_right_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf803, buf804, buf805, buf806, 23976, 128, grid=grid(23976), stream=stream0)
        buf807 = buf797; del buf797  # reuse
        buf808 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf810 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_right_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf804, buf805, buf806, primals_958, primals_959, buf807, buf808, buf810, primals_958, primals_959, 216, 111, grid=grid(216), stream=stream0)
        del primals_958
        del primals_959
        # Source Nodes: [x_361], Original ATen: [aten.convolution]
        buf935 = extern_kernels.convolution(buf812, primals_286, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf935, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf936 = reinterpret_tensor(buf802, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf802  # reuse
        # Source Nodes: [x_361], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf935, buf936, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_363], Original ATen: [aten.convolution]
        buf937 = extern_kernels.convolution(buf936, primals_287, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf937, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf938 = reinterpret_tensor(buf935, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf935  # reuse
        # Source Nodes: [x_363], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf937, buf938, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf939 = buf806; del buf806  # reuse
        buf940 = buf805; del buf805  # reuse
        buf941 = buf804; del buf804  # reuse
        # Source Nodes: [x_364], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf938, buf939, buf940, buf941, 23976, 128, grid=grid(23976), stream=stream0)
        buf942 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf943 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf945 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_364], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf939, buf940, buf941, primals_991, primals_992, buf942, buf943, buf945, primals_991, primals_992, 216, 111, grid=grid(216), stream=stream0)
        del primals_991
        del primals_992
        buf946 = reinterpret_tensor(buf937, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf937  # reuse
        # Source Nodes: [x_364, x_365], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf938, buf942, buf943, primals_288, primals_289, buf946, 3048192, grid=grid(3048192), stream=stream0)
        del primals_289
        # Source Nodes: [x_366], Original ATen: [aten.convolution]
        buf947 = extern_kernels.convolution(buf946, primals_290, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf947, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf948 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_366], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf947, buf948, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_368], Original ATen: [aten.convolution]
        buf949 = extern_kernels.convolution(buf948, primals_291, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf949, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf950 = reinterpret_tensor(buf947, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf947  # reuse
        # Source Nodes: [x_368], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf949, buf950, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf951 = buf941; del buf941  # reuse
        buf952 = buf940; del buf940  # reuse
        buf953 = buf939; del buf939  # reuse
        # Source Nodes: [x_comb_iter_4_left_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf950, buf951, buf952, buf953, 23976, 128, grid=grid(23976), stream=stream0)
        buf954 = buf943; del buf943  # reuse
        buf955 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf957 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_left_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf951, buf952, buf953, primals_994, primals_995, buf954, buf955, buf957, primals_994, primals_995, 216, 111, grid=grid(216), stream=stream0)
        del primals_994
        del primals_995
        buf811 = reinterpret_tensor(buf949, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf949  # reuse
        buf962 = buf790; del buf790  # reuse
        buf961 = reinterpret_tensor(buf962, (8, 216, 42, 42), (1905120, 1764, 42, 1), 1524096)  # alias
        # Source Nodes: [x_comb_iter_24, x_comb_iter_4_left_4, x_comb_iter_4_right_4], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_67.run(buf803, buf807, buf808, primals_244, primals_245, buf950, buf954, buf955, primals_292, primals_293, buf811, buf961, 14112, 216, grid=grid(14112, 216), stream=stream0)
        del primals_245
        del primals_293
        # Source Nodes: [x_311], Original ATen: [aten.convolution]
        buf813 = extern_kernels.convolution(buf812, primals_246, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf813, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf814 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_311], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf813, buf814, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_313], Original ATen: [aten.convolution]
        buf815 = extern_kernels.convolution(buf814, primals_247, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf815, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf816 = reinterpret_tensor(buf813, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf813  # reuse
        # Source Nodes: [x_313], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf815, buf816, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf817 = buf953; del buf953  # reuse
        buf818 = buf952; del buf952  # reuse
        buf819 = buf951; del buf951  # reuse
        # Source Nodes: [x_314], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf816, buf817, buf818, buf819, 23976, 128, grid=grid(23976), stream=stream0)
        buf820 = buf955; del buf955  # reuse
        buf821 = buf808; del buf808  # reuse
        buf823 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_314], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf817, buf818, buf819, primals_961, primals_962, buf820, buf821, buf823, primals_961, primals_962, 216, 111, grid=grid(216), stream=stream0)
        del primals_961
        del primals_962
        buf824 = reinterpret_tensor(buf815, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf815  # reuse
        # Source Nodes: [x_314, x_315], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf816, buf820, buf821, primals_248, primals_249, buf824, 3048192, grid=grid(3048192), stream=stream0)
        del primals_249
        # Source Nodes: [x_316], Original ATen: [aten.convolution]
        buf825 = extern_kernels.convolution(buf824, primals_250, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf825, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf826 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_316], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf825, buf826, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_318], Original ATen: [aten.convolution]
        buf827 = extern_kernels.convolution(buf826, primals_251, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf827, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf828 = reinterpret_tensor(buf825, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf825  # reuse
        # Source Nodes: [x_318], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf827, buf828, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf829 = buf819; del buf819  # reuse
        buf830 = buf818; del buf818  # reuse
        buf831 = buf817; del buf817  # reuse
        # Source Nodes: [x_comb_iter_0_left_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf828, buf829, buf830, buf831, 23976, 128, grid=grid(23976), stream=stream0)
        buf832 = buf821; del buf821  # reuse
        buf833 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf835 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_0_left_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf829, buf830, buf831, primals_964, primals_965, buf832, buf833, buf835, primals_964, primals_965, 216, 111, grid=grid(216), stream=stream0)
        del primals_964
        del primals_965
        buf836 = reinterpret_tensor(buf827, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf827  # reuse
        buf837 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_0_right_4], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_68.run(buf800, buf836, buf837, 3048192, grid=grid(3048192), stream=stream0)
        buf838 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        buf862 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        buf863 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_320, x_comb_iter_1_right_4], Original ATen: [aten.max_pool2d_with_indices, aten.relu]
        triton_poi_fused_max_pool2d_with_indices_relu_69.run(buf811, buf838, buf862, buf863, 3048192, grid=grid(3048192), stream=stream0)
        # Source Nodes: [x_321], Original ATen: [aten.convolution]
        buf839 = extern_kernels.convolution(buf838, primals_254, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf839, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf840 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_321], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf839, buf840, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_323], Original ATen: [aten.convolution]
        buf841 = extern_kernels.convolution(buf840, primals_255, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf841, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf842 = reinterpret_tensor(buf839, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf839  # reuse
        # Source Nodes: [x_323], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf841, buf842, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf843 = buf831; del buf831  # reuse
        buf844 = buf830; del buf830  # reuse
        buf845 = buf829; del buf829  # reuse
        # Source Nodes: [x_324], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf842, buf843, buf844, buf845, 23976, 128, grid=grid(23976), stream=stream0)
        buf846 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf847 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf849 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_324], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf843, buf844, buf845, primals_967, primals_968, buf846, buf847, buf849, primals_967, primals_968, 216, 111, grid=grid(216), stream=stream0)
        del primals_967
        del primals_968
        buf850 = reinterpret_tensor(buf841, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf841  # reuse
        # Source Nodes: [x_324, x_325], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf842, buf846, buf847, primals_256, primals_257, buf850, 3048192, grid=grid(3048192), stream=stream0)
        del primals_257
        # Source Nodes: [x_326], Original ATen: [aten.convolution]
        buf851 = extern_kernels.convolution(buf850, primals_258, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf851, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf852 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_326], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf851, buf852, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_328], Original ATen: [aten.convolution]
        buf853 = extern_kernels.convolution(buf852, primals_259, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf853, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf854 = reinterpret_tensor(buf851, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf851  # reuse
        # Source Nodes: [x_328], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf853, buf854, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf855 = buf845; del buf845  # reuse
        buf856 = buf844; del buf844  # reuse
        buf857 = buf843; del buf843  # reuse
        # Source Nodes: [x_comb_iter_1_left_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf854, buf855, buf856, buf857, 23976, 128, grid=grid(23976), stream=stream0)
        buf858 = buf847; del buf847  # reuse
        buf859 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf861 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_1_left_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf855, buf856, buf857, primals_970, primals_971, buf858, buf859, buf861, primals_970, primals_971, 216, 111, grid=grid(216), stream=stream0)
        del primals_970
        del primals_971
        # Source Nodes: [x_331], Original ATen: [aten.convolution]
        buf864 = extern_kernels.convolution(buf838, primals_262, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf864, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf865 = reinterpret_tensor(buf853, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf853  # reuse
        # Source Nodes: [x_331], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf864, buf865, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_333], Original ATen: [aten.convolution]
        buf866 = extern_kernels.convolution(buf865, primals_263, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf866, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf867 = reinterpret_tensor(buf864, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf864  # reuse
        # Source Nodes: [x_333], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf866, buf867, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf868 = buf857; del buf857  # reuse
        buf869 = buf856; del buf856  # reuse
        buf870 = buf855; del buf855  # reuse
        # Source Nodes: [x_334], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf867, buf868, buf869, buf870, 23976, 128, grid=grid(23976), stream=stream0)
        buf871 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf872 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf874 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_334], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf868, buf869, buf870, primals_973, primals_974, buf871, buf872, buf874, primals_973, primals_974, 216, 111, grid=grid(216), stream=stream0)
        del primals_973
        del primals_974
        buf875 = reinterpret_tensor(buf866, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf866  # reuse
        # Source Nodes: [x_334, x_335], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf867, buf871, buf872, primals_264, primals_265, buf875, 3048192, grid=grid(3048192), stream=stream0)
        del primals_265
        # Source Nodes: [x_336], Original ATen: [aten.convolution]
        buf876 = extern_kernels.convolution(buf875, primals_266, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf876, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf877 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_336], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf876, buf877, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_338], Original ATen: [aten.convolution]
        buf878 = extern_kernels.convolution(buf877, primals_267, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf878, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf879 = reinterpret_tensor(buf876, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf876  # reuse
        # Source Nodes: [x_338], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf878, buf879, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf880 = buf870; del buf870  # reuse
        buf881 = buf869; del buf869  # reuse
        buf882 = buf868; del buf868  # reuse
        # Source Nodes: [x_comb_iter_2_left_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf879, buf880, buf881, buf882, 23976, 128, grid=grid(23976), stream=stream0)
        buf883 = buf872; del buf872  # reuse
        buf884 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf886 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_left_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf880, buf881, buf882, primals_976, primals_977, buf883, buf884, buf886, primals_976, primals_977, 216, 111, grid=grid(216), stream=stream0)
        del primals_976
        del primals_977
        # Source Nodes: [x_341], Original ATen: [aten.convolution]
        buf887 = extern_kernels.convolution(buf838, primals_270, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf887, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf888 = reinterpret_tensor(buf878, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf878  # reuse
        # Source Nodes: [x_341], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf887, buf888, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_343], Original ATen: [aten.convolution]
        buf889 = extern_kernels.convolution(buf888, primals_271, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf889, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf890 = reinterpret_tensor(buf887, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf887  # reuse
        # Source Nodes: [x_343], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf889, buf890, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf891 = buf882; del buf882  # reuse
        buf892 = buf881; del buf881  # reuse
        buf893 = buf880; del buf880  # reuse
        # Source Nodes: [x_344], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf890, buf891, buf892, buf893, 23976, 128, grid=grid(23976), stream=stream0)
        buf894 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf895 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf897 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_344], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf891, buf892, buf893, primals_979, primals_980, buf894, buf895, buf897, primals_979, primals_980, 216, 111, grid=grid(216), stream=stream0)
        del primals_979
        del primals_980
        buf898 = reinterpret_tensor(buf889, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf889  # reuse
        # Source Nodes: [x_344, x_345], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf890, buf894, buf895, primals_272, primals_273, buf898, 3048192, grid=grid(3048192), stream=stream0)
        del primals_273
        # Source Nodes: [x_346], Original ATen: [aten.convolution]
        buf899 = extern_kernels.convolution(buf898, primals_274, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf899, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf900 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_346], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf899, buf900, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_348], Original ATen: [aten.convolution]
        buf901 = extern_kernels.convolution(buf900, primals_275, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf901, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf902 = reinterpret_tensor(buf899, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf899  # reuse
        # Source Nodes: [x_348], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf901, buf902, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf903 = buf893; del buf893  # reuse
        buf904 = buf892; del buf892  # reuse
        buf905 = buf891; del buf891  # reuse
        # Source Nodes: [x_comb_iter_2_right_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf902, buf903, buf904, buf905, 23976, 128, grid=grid(23976), stream=stream0)
        buf906 = buf895; del buf895  # reuse
        buf907 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf909 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_right_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf903, buf904, buf905, primals_982, primals_983, buf906, buf907, buf909, primals_982, primals_983, 216, 111, grid=grid(216), stream=stream0)
        del primals_982
        del primals_983
        buf910 = reinterpret_tensor(buf962, (8, 216, 42, 42), (1905120, 1764, 42, 1), 762048)  # alias
        # Source Nodes: [x_comb_iter_22, x_comb_iter_2_left_4, x_comb_iter_2_right_4], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_70.run(buf879, buf883, buf884, primals_268, primals_269, buf902, buf906, buf907, primals_276, primals_277, buf910, 14112, 216, grid=grid(14112, 216), stream=stream0)
        del primals_269
        del primals_277
        buf911 = reinterpret_tensor(buf901, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf901  # reuse
        # Source Nodes: [x_350], Original ATen: [aten.relu]
        triton_poi_fused_relu_71.run(buf910, buf911, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_351], Original ATen: [aten.convolution]
        buf912 = extern_kernels.convolution(buf911, primals_278, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf912, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf913 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_351], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf912, buf913, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_353], Original ATen: [aten.convolution]
        buf914 = extern_kernels.convolution(buf913, primals_279, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf914, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf915 = reinterpret_tensor(buf912, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf912  # reuse
        # Source Nodes: [x_353], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf914, buf915, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf916 = buf905; del buf905  # reuse
        buf917 = buf904; del buf904  # reuse
        buf918 = buf903; del buf903  # reuse
        # Source Nodes: [x_354], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf915, buf916, buf917, buf918, 23976, 128, grid=grid(23976), stream=stream0)
        buf919 = buf907; del buf907  # reuse
        buf920 = buf884; del buf884  # reuse
        buf922 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_354], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf916, buf917, buf918, primals_985, primals_986, buf919, buf920, buf922, primals_985, primals_986, 216, 111, grid=grid(216), stream=stream0)
        del primals_985
        del primals_986
        buf923 = reinterpret_tensor(buf914, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf914  # reuse
        # Source Nodes: [x_354, x_355], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf915, buf919, buf920, primals_280, primals_281, buf923, 3048192, grid=grid(3048192), stream=stream0)
        del primals_281
        # Source Nodes: [x_356], Original ATen: [aten.convolution]
        buf924 = extern_kernels.convolution(buf923, primals_282, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf924, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf925 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_356], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf924, buf925, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_358], Original ATen: [aten.convolution]
        buf926 = extern_kernels.convolution(buf925, primals_283, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf926, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf927 = reinterpret_tensor(buf924, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf924  # reuse
        # Source Nodes: [x_358], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf926, buf927, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf928 = buf918; del buf918  # reuse
        buf929 = buf917; del buf917  # reuse
        buf930 = buf916; del buf916  # reuse
        # Source Nodes: [x_comb_iter_3_left_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf927, buf928, buf929, buf930, 23976, 128, grid=grid(23976), stream=stream0)
        buf931 = buf920; del buf920  # reuse
        buf932 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf934 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_3_left_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf928, buf929, buf930, primals_988, primals_989, buf931, buf932, buf934, primals_988, primals_989, 216, 111, grid=grid(216), stream=stream0)
        del primals_988
        del primals_989
        buf958 = reinterpret_tensor(buf962, (8, 216, 42, 42), (1905120, 1764, 42, 1), 0)  # alias
        # Source Nodes: [x_comb_iter_0_left_4, x_comb_iter_20], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_72.run(buf828, buf832, buf833, primals_252, primals_253, buf836, buf958, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        del primals_253
        buf959 = reinterpret_tensor(buf962, (8, 216, 42, 42), (1905120, 1764, 42, 1), 381024)  # alias
        buf960 = reinterpret_tensor(buf962, (8, 216, 42, 42), (1905120, 1764, 42, 1), 1143072)  # alias
        # Source Nodes: [x_comb_iter_1_left_4, x_comb_iter_21, x_comb_iter_23, x_comb_iter_3_left_4], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_73.run(buf854, buf858, buf859, primals_260, primals_261, buf862, buf927, buf931, buf932, primals_284, primals_285, buf959, buf960, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        del primals_261
        del primals_285
        del buf910
        del buf958
        del buf959
        del buf960
        del buf961
        # Source Nodes: [x_371], Original ATen: [aten.convolution]
        buf963 = extern_kernels.convolution(buf801, primals_294, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf963, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf964 = buf862; del buf862  # reuse
        # Source Nodes: [x_371], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf963, buf964, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf965 = buf930; del buf930  # reuse
        buf966 = buf929; del buf929  # reuse
        buf967 = buf928; del buf928  # reuse
        # Source Nodes: [x_left_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf964, buf965, buf966, buf967, 23976, 128, grid=grid(23976), stream=stream0)
        buf968 = buf932; del buf932  # reuse
        buf969 = buf859; del buf859  # reuse
        buf971 = reinterpret_tensor(buf833, (216, ), (1, ), 0); del buf833  # reuse
        # Source Nodes: [x_left_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf965, buf966, buf967, primals_997, primals_998, buf968, buf969, buf971, primals_997, primals_998, 216, 111, grid=grid(216), stream=stream0)
        del primals_997
        del primals_998
        buf972 = reinterpret_tensor(buf963, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf963  # reuse
        buf984 = buf836; del buf836  # reuse
        # Source Nodes: [x_376, x_left_4], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_63.run(buf964, buf968, buf969, primals_295, primals_296, buf972, buf984, 3048192, grid=grid(3048192), stream=stream0)
        del primals_296
        buf973 = empty_strided((8, 1080, 42, 42), (1905120, 1, 45360, 1080), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_373], Original ATen: [aten.relu]
        triton_poi_fused_relu_74.run(buf962, buf973, 8640, 1764, grid=grid(8640, 1764), stream=stream0)
        # Source Nodes: [x_374], Original ATen: [aten.convolution]
        buf974 = extern_kernels.convolution(buf973, primals_297, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf974, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf975 = reinterpret_tensor(buf926, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf926  # reuse
        # Source Nodes: [x_374], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf974, buf975, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf976 = buf967; del buf967  # reuse
        buf977 = buf966; del buf966  # reuse
        buf978 = buf965; del buf965  # reuse
        # Source Nodes: [x_comb_iter_4_right_5], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf975, buf976, buf977, buf978, 23976, 128, grid=grid(23976), stream=stream0)
        buf979 = buf969; del buf969  # reuse
        buf980 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf982 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_right_5], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf976, buf977, buf978, primals_1000, primals_1001, buf979, buf980, buf982, primals_1000, primals_1001, 216, 111, grid=grid(216), stream=stream0)
        del primals_1000
        del primals_1001
        # Source Nodes: [x_427], Original ATen: [aten.convolution]
        buf1107 = extern_kernels.convolution(buf984, primals_340, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf1107, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1108 = reinterpret_tensor(buf974, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf974  # reuse
        # Source Nodes: [x_427], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1107, buf1108, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_429], Original ATen: [aten.convolution]
        buf1109 = extern_kernels.convolution(buf1108, primals_341, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1109, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1110 = reinterpret_tensor(buf1107, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1107  # reuse
        # Source Nodes: [x_429], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1109, buf1110, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf1111 = buf978; del buf978  # reuse
        buf1112 = buf977; del buf977  # reuse
        buf1113 = buf976; del buf976  # reuse
        # Source Nodes: [x_430], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf1110, buf1111, buf1112, buf1113, 23976, 128, grid=grid(23976), stream=stream0)
        buf1114 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf1115 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf1117 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_430], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf1111, buf1112, buf1113, primals_1033, primals_1034, buf1114, buf1115, buf1117, primals_1033, primals_1034, 216, 111, grid=grid(216), stream=stream0)
        del primals_1033
        del primals_1034
        buf1118 = reinterpret_tensor(buf1109, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1109  # reuse
        # Source Nodes: [x_430, x_431], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf1110, buf1114, buf1115, primals_342, primals_343, buf1118, 3048192, grid=grid(3048192), stream=stream0)
        del primals_343
        # Source Nodes: [x_432], Original ATen: [aten.convolution]
        buf1119 = extern_kernels.convolution(buf1118, primals_344, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf1119, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1120 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_432], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1119, buf1120, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_434], Original ATen: [aten.convolution]
        buf1121 = extern_kernels.convolution(buf1120, primals_345, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1121, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1122 = reinterpret_tensor(buf1119, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1119  # reuse
        # Source Nodes: [x_434], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1121, buf1122, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf1123 = buf1113; del buf1113  # reuse
        buf1124 = buf1112; del buf1112  # reuse
        buf1125 = buf1111; del buf1111  # reuse
        # Source Nodes: [x_comb_iter_4_left_5], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf1122, buf1123, buf1124, buf1125, 23976, 128, grid=grid(23976), stream=stream0)
        buf1126 = buf1115; del buf1115  # reuse
        buf1127 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf1129 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_left_5], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf1123, buf1124, buf1125, primals_1036, primals_1037, buf1126, buf1127, buf1129, primals_1036, primals_1037, 216, 111, grid=grid(216), stream=stream0)
        del primals_1036
        del primals_1037
        buf983 = reinterpret_tensor(buf1121, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1121  # reuse
        buf1134 = buf962; del buf962  # reuse
        buf1133 = reinterpret_tensor(buf1134, (8, 216, 42, 42), (1905120, 1764, 42, 1), 1524096)  # alias
        # Source Nodes: [x_comb_iter_29, x_comb_iter_4_left_5, x_comb_iter_4_right_5], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_67.run(buf975, buf979, buf980, primals_298, primals_299, buf1122, buf1126, buf1127, primals_346, primals_347, buf983, buf1133, 14112, 216, grid=grid(14112, 216), stream=stream0)
        del primals_299
        del primals_347
        # Source Nodes: [x_377], Original ATen: [aten.convolution]
        buf985 = extern_kernels.convolution(buf984, primals_300, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf985, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf986 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_377], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf985, buf986, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_379], Original ATen: [aten.convolution]
        buf987 = extern_kernels.convolution(buf986, primals_301, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf987, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf988 = reinterpret_tensor(buf985, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf985  # reuse
        # Source Nodes: [x_379], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf987, buf988, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf989 = buf1125; del buf1125  # reuse
        buf990 = buf1124; del buf1124  # reuse
        buf991 = buf1123; del buf1123  # reuse
        # Source Nodes: [x_380], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf988, buf989, buf990, buf991, 23976, 128, grid=grid(23976), stream=stream0)
        buf992 = buf980; del buf980  # reuse
        buf993 = buf1127; del buf1127  # reuse
        buf995 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_380], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf989, buf990, buf991, primals_1003, primals_1004, buf992, buf993, buf995, primals_1003, primals_1004, 216, 111, grid=grid(216), stream=stream0)
        del primals_1003
        del primals_1004
        buf996 = reinterpret_tensor(buf987, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf987  # reuse
        # Source Nodes: [x_380, x_381], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf988, buf992, buf993, primals_302, primals_303, buf996, 3048192, grid=grid(3048192), stream=stream0)
        del primals_303
        # Source Nodes: [x_382], Original ATen: [aten.convolution]
        buf997 = extern_kernels.convolution(buf996, primals_304, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf997, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf998 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_382], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf997, buf998, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_384], Original ATen: [aten.convolution]
        buf999 = extern_kernels.convolution(buf998, primals_305, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf999, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1000 = reinterpret_tensor(buf997, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf997  # reuse
        # Source Nodes: [x_384], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf999, buf1000, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf1001 = buf991; del buf991  # reuse
        buf1002 = buf990; del buf990  # reuse
        buf1003 = buf989; del buf989  # reuse
        # Source Nodes: [x_comb_iter_0_left_5], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf1000, buf1001, buf1002, buf1003, 23976, 128, grid=grid(23976), stream=stream0)
        buf1004 = buf993; del buf993  # reuse
        buf1005 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf1007 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_0_left_5], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf1001, buf1002, buf1003, primals_1006, primals_1007, buf1004, buf1005, buf1007, primals_1006, primals_1007, 216, 111, grid=grid(216), stream=stream0)
        del primals_1006
        del primals_1007
        buf1008 = reinterpret_tensor(buf999, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf999  # reuse
        buf1009 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_0_right_5], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_68.run(buf972, buf1008, buf1009, 3048192, grid=grid(3048192), stream=stream0)
        buf1010 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        buf1034 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        buf1035 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_386, x_comb_iter_1_right_5], Original ATen: [aten.max_pool2d_with_indices, aten.relu]
        triton_poi_fused_max_pool2d_with_indices_relu_69.run(buf983, buf1010, buf1034, buf1035, 3048192, grid=grid(3048192), stream=stream0)
        # Source Nodes: [x_387], Original ATen: [aten.convolution]
        buf1011 = extern_kernels.convolution(buf1010, primals_308, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf1011, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1012 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_387], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1011, buf1012, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_389], Original ATen: [aten.convolution]
        buf1013 = extern_kernels.convolution(buf1012, primals_309, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1013, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1014 = reinterpret_tensor(buf1011, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1011  # reuse
        # Source Nodes: [x_389], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1013, buf1014, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf1015 = buf1003; del buf1003  # reuse
        buf1016 = buf1002; del buf1002  # reuse
        buf1017 = buf1001; del buf1001  # reuse
        # Source Nodes: [x_390], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf1014, buf1015, buf1016, buf1017, 23976, 128, grid=grid(23976), stream=stream0)
        buf1018 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf1019 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf1021 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_390], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf1015, buf1016, buf1017, primals_1009, primals_1010, buf1018, buf1019, buf1021, primals_1009, primals_1010, 216, 111, grid=grid(216), stream=stream0)
        del primals_1009
        del primals_1010
        buf1022 = reinterpret_tensor(buf1013, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1013  # reuse
        # Source Nodes: [x_390, x_391], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf1014, buf1018, buf1019, primals_310, primals_311, buf1022, 3048192, grid=grid(3048192), stream=stream0)
        del primals_311
        # Source Nodes: [x_392], Original ATen: [aten.convolution]
        buf1023 = extern_kernels.convolution(buf1022, primals_312, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf1023, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1024 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_392], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1023, buf1024, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_394], Original ATen: [aten.convolution]
        buf1025 = extern_kernels.convolution(buf1024, primals_313, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1025, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1026 = reinterpret_tensor(buf1023, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1023  # reuse
        # Source Nodes: [x_394], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1025, buf1026, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf1027 = buf1017; del buf1017  # reuse
        buf1028 = buf1016; del buf1016  # reuse
        buf1029 = buf1015; del buf1015  # reuse
        # Source Nodes: [x_comb_iter_1_left_5], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf1026, buf1027, buf1028, buf1029, 23976, 128, grid=grid(23976), stream=stream0)
        buf1030 = buf1019; del buf1019  # reuse
        buf1031 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf1033 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_1_left_5], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf1027, buf1028, buf1029, primals_1012, primals_1013, buf1030, buf1031, buf1033, primals_1012, primals_1013, 216, 111, grid=grid(216), stream=stream0)
        del primals_1012
        del primals_1013
        # Source Nodes: [x_397], Original ATen: [aten.convolution]
        buf1036 = extern_kernels.convolution(buf1010, primals_316, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf1036, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1037 = reinterpret_tensor(buf1025, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1025  # reuse
        # Source Nodes: [x_397], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1036, buf1037, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_399], Original ATen: [aten.convolution]
        buf1038 = extern_kernels.convolution(buf1037, primals_317, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1038, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1039 = reinterpret_tensor(buf1036, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1036  # reuse
        # Source Nodes: [x_399], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1038, buf1039, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf1040 = buf1029; del buf1029  # reuse
        buf1041 = buf1028; del buf1028  # reuse
        buf1042 = buf1027; del buf1027  # reuse
        # Source Nodes: [x_400], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf1039, buf1040, buf1041, buf1042, 23976, 128, grid=grid(23976), stream=stream0)
        buf1043 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf1044 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf1046 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_400], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf1040, buf1041, buf1042, primals_1015, primals_1016, buf1043, buf1044, buf1046, primals_1015, primals_1016, 216, 111, grid=grid(216), stream=stream0)
        del primals_1015
        del primals_1016
        buf1047 = reinterpret_tensor(buf1038, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1038  # reuse
        # Source Nodes: [x_400, x_401], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf1039, buf1043, buf1044, primals_318, primals_319, buf1047, 3048192, grid=grid(3048192), stream=stream0)
        del primals_319
        # Source Nodes: [x_402], Original ATen: [aten.convolution]
        buf1048 = extern_kernels.convolution(buf1047, primals_320, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf1048, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1049 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_402], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1048, buf1049, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_404], Original ATen: [aten.convolution]
        buf1050 = extern_kernels.convolution(buf1049, primals_321, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1050, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1051 = reinterpret_tensor(buf1048, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1048  # reuse
        # Source Nodes: [x_404], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1050, buf1051, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf1052 = buf1042; del buf1042  # reuse
        buf1053 = buf1041; del buf1041  # reuse
        buf1054 = buf1040; del buf1040  # reuse
        # Source Nodes: [x_comb_iter_2_left_5], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf1051, buf1052, buf1053, buf1054, 23976, 128, grid=grid(23976), stream=stream0)
        buf1055 = buf1044; del buf1044  # reuse
        buf1056 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf1058 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_left_5], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf1052, buf1053, buf1054, primals_1018, primals_1019, buf1055, buf1056, buf1058, primals_1018, primals_1019, 216, 111, grid=grid(216), stream=stream0)
        del primals_1018
        del primals_1019
        # Source Nodes: [x_407], Original ATen: [aten.convolution]
        buf1059 = extern_kernels.convolution(buf1010, primals_324, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf1059, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1060 = reinterpret_tensor(buf1050, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1050  # reuse
        # Source Nodes: [x_407], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1059, buf1060, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_409], Original ATen: [aten.convolution]
        buf1061 = extern_kernels.convolution(buf1060, primals_325, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1061, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1062 = reinterpret_tensor(buf1059, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1059  # reuse
        # Source Nodes: [x_409], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1061, buf1062, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf1063 = buf1054; del buf1054  # reuse
        buf1064 = buf1053; del buf1053  # reuse
        buf1065 = buf1052; del buf1052  # reuse
        # Source Nodes: [x_410], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf1062, buf1063, buf1064, buf1065, 23976, 128, grid=grid(23976), stream=stream0)
        buf1066 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf1067 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf1069 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_410], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf1063, buf1064, buf1065, primals_1021, primals_1022, buf1066, buf1067, buf1069, primals_1021, primals_1022, 216, 111, grid=grid(216), stream=stream0)
        del primals_1021
        del primals_1022
        buf1070 = reinterpret_tensor(buf1061, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1061  # reuse
        # Source Nodes: [x_410, x_411], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf1062, buf1066, buf1067, primals_326, primals_327, buf1070, 3048192, grid=grid(3048192), stream=stream0)
        del primals_327
        # Source Nodes: [x_412], Original ATen: [aten.convolution]
        buf1071 = extern_kernels.convolution(buf1070, primals_328, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf1071, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1072 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_412], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1071, buf1072, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_414], Original ATen: [aten.convolution]
        buf1073 = extern_kernels.convolution(buf1072, primals_329, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1073, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1074 = reinterpret_tensor(buf1071, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1071  # reuse
        # Source Nodes: [x_414], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1073, buf1074, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf1075 = buf1065; del buf1065  # reuse
        buf1076 = buf1064; del buf1064  # reuse
        buf1077 = buf1063; del buf1063  # reuse
        # Source Nodes: [x_comb_iter_2_right_5], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf1074, buf1075, buf1076, buf1077, 23976, 128, grid=grid(23976), stream=stream0)
        buf1078 = buf1067; del buf1067  # reuse
        buf1079 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf1081 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_right_5], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf1075, buf1076, buf1077, primals_1024, primals_1025, buf1078, buf1079, buf1081, primals_1024, primals_1025, 216, 111, grid=grid(216), stream=stream0)
        del primals_1024
        del primals_1025
        buf1082 = reinterpret_tensor(buf1134, (8, 216, 42, 42), (1905120, 1764, 42, 1), 762048)  # alias
        # Source Nodes: [x_comb_iter_27, x_comb_iter_2_left_5, x_comb_iter_2_right_5], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_70.run(buf1051, buf1055, buf1056, primals_322, primals_323, buf1074, buf1078, buf1079, primals_330, primals_331, buf1082, 14112, 216, grid=grid(14112, 216), stream=stream0)
        del primals_323
        del primals_331
        buf1083 = reinterpret_tensor(buf1073, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1073  # reuse
        # Source Nodes: [x_416], Original ATen: [aten.relu]
        triton_poi_fused_relu_71.run(buf1082, buf1083, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_417], Original ATen: [aten.convolution]
        buf1084 = extern_kernels.convolution(buf1083, primals_332, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf1084, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1085 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_417], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1084, buf1085, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_419], Original ATen: [aten.convolution]
        buf1086 = extern_kernels.convolution(buf1085, primals_333, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1086, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1087 = reinterpret_tensor(buf1084, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1084  # reuse
        # Source Nodes: [x_419], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1086, buf1087, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf1088 = buf1077; del buf1077  # reuse
        buf1089 = buf1076; del buf1076  # reuse
        buf1090 = buf1075; del buf1075  # reuse
        # Source Nodes: [x_420], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf1087, buf1088, buf1089, buf1090, 23976, 128, grid=grid(23976), stream=stream0)
        buf1091 = buf1079; del buf1079  # reuse
        buf1092 = buf1056; del buf1056  # reuse
        buf1094 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_420], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf1088, buf1089, buf1090, primals_1027, primals_1028, buf1091, buf1092, buf1094, primals_1027, primals_1028, 216, 111, grid=grid(216), stream=stream0)
        del primals_1027
        del primals_1028
        buf1095 = reinterpret_tensor(buf1086, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1086  # reuse
        # Source Nodes: [x_420, x_421], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_66.run(buf1087, buf1091, buf1092, primals_334, primals_335, buf1095, 3048192, grid=grid(3048192), stream=stream0)
        del primals_335
        # Source Nodes: [x_422], Original ATen: [aten.convolution]
        buf1096 = extern_kernels.convolution(buf1095, primals_336, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=216, bias=None)
        assert_size_stride(buf1096, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1097 = empty_strided((8, 216, 42, 42), (381024, 1, 9072, 216), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_422], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1096, buf1097, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        # Source Nodes: [x_424], Original ATen: [aten.convolution]
        buf1098 = extern_kernels.convolution(buf1097, primals_337, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1098, (8, 216, 42, 42), (381024, 1764, 42, 1))
        buf1099 = reinterpret_tensor(buf1096, (8, 216, 42, 42), (381024, 1, 9072, 216), 0); del buf1096  # reuse
        # Source Nodes: [x_424], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_65.run(buf1098, buf1099, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        buf1100 = buf1090; del buf1090  # reuse
        buf1101 = buf1089; del buf1089  # reuse
        buf1102 = buf1088; del buf1088  # reuse
        # Source Nodes: [x_comb_iter_3_left_5], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_61.run(buf1099, buf1100, buf1101, buf1102, 23976, 128, grid=grid(23976), stream=stream0)
        buf1103 = buf1092; del buf1092  # reuse
        buf1104 = empty_strided((1, 216, 1, 1), (216, 1, 216, 216), device='cuda', dtype=torch.float32)
        buf1106 = empty((216, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_3_left_5], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_62.run(buf1100, buf1101, buf1102, primals_1030, primals_1031, buf1103, buf1104, buf1106, primals_1030, primals_1031, 216, 111, grid=grid(216), stream=stream0)
        del buf1100
        del buf1101
        del buf1102
        del primals_1030
        del primals_1031
        buf1130 = reinterpret_tensor(buf1134, (8, 216, 42, 42), (1905120, 1764, 42, 1), 0)  # alias
        # Source Nodes: [x_comb_iter_0_left_5, x_comb_iter_25], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_72.run(buf1000, buf1004, buf1005, primals_306, primals_307, buf1008, buf1130, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        del buf1005
        del primals_307
        buf1131 = reinterpret_tensor(buf1134, (8, 216, 42, 42), (1905120, 1764, 42, 1), 381024)  # alias
        buf1132 = reinterpret_tensor(buf1134, (8, 216, 42, 42), (1905120, 1764, 42, 1), 1143072)  # alias
        # Source Nodes: [x_comb_iter_1_left_5, x_comb_iter_26, x_comb_iter_28, x_comb_iter_3_left_5], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_73.run(buf1026, buf1030, buf1031, primals_314, primals_315, buf1034, buf1099, buf1103, buf1104, primals_338, primals_339, buf1131, buf1132, 1728, 1764, grid=grid(1728, 1764), stream=stream0)
        del buf1031
        del buf1104
        del primals_315
        del primals_339
        del buf1082
        del buf1130
        del buf1131
        del buf1132
        del buf1133
        # Source Nodes: [x_437], Original ATen: [aten.convolution]
        buf1135 = extern_kernels.convolution(buf973, primals_348, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1135, (8, 432, 42, 42), (762048, 1764, 42, 1))
        buf1136 = empty_strided((8, 432, 42, 42), (762048, 1, 18144, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_437], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_75.run(buf1135, buf1136, 3456, 1764, grid=grid(3456, 1764), stream=stream0)
        buf1137 = empty_strided((1, 432, 1, 1, 111), (47952, 1, 47952, 47952, 432), device='cuda', dtype=torch.float32)
        buf1138 = empty_strided((1, 432, 1, 1, 111), (47952, 1, 47952, 47952, 432), device='cuda', dtype=torch.float32)
        buf1139 = empty_strided((1, 432, 1, 1, 111), (47952, 1, 47952, 47952, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_left_5], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_76.run(buf1136, buf1137, buf1138, buf1139, 47952, 128, grid=grid(47952), stream=stream0)
        buf1140 = reinterpret_tensor(buf271, (1, 432, 1, 1), (432, 1, 432, 432), 0); del buf271  # reuse
        buf1141 = reinterpret_tensor(buf270, (1, 432, 1, 1), (432, 1, 432, 432), 0); del buf270  # reuse
        buf1143 = reinterpret_tensor(buf269, (432, ), (1, ), 0); del buf269  # reuse
        # Source Nodes: [x_left_5], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_77.run(buf1137, buf1138, buf1139, primals_1039, primals_1040, buf1140, buf1141, buf1143, primals_1039, primals_1040, 432, 111, grid=grid(432), stream=stream0)
        del primals_1039
        del primals_1040
        buf1144 = reinterpret_tensor(buf1135, (8, 432, 42, 42), (762048, 1, 18144, 432), 0); del buf1135  # reuse
        buf2556 = empty_strided((8, 432, 42, 42), (762048, 1, 18144, 432), device='cuda', dtype=torch.bool)
        # Source Nodes: [x_442, x_left_5], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu, aten.threshold_backward]
        triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_78.run(buf1136, buf1140, buf1141, primals_349, primals_350, buf1144, buf2556, 6096384, grid=grid(6096384), stream=stream0)
        del primals_350
        buf1145 = empty_strided((8, 1080, 42, 42), (1905120, 1, 45360, 1080), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_439], Original ATen: [aten.relu]
        triton_poi_fused_relu_74.run(buf1134, buf1145, 8640, 1764, grid=grid(8640, 1764), stream=stream0)
        # Source Nodes: [x_440], Original ATen: [aten.convolution]
        buf1146 = extern_kernels.convolution(buf1145, primals_351, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1146, (8, 432, 42, 42), (762048, 1764, 42, 1))
        buf1147 = empty_strided((8, 432, 42, 42), (762048, 1, 18144, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_440], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_75.run(buf1146, buf1147, 3456, 1764, grid=grid(3456, 1764), stream=stream0)
        buf1148 = buf1139; del buf1139  # reuse
        buf1149 = buf1138; del buf1138  # reuse
        buf1150 = buf1137; del buf1137  # reuse
        # Source Nodes: [x_right_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_76.run(buf1147, buf1148, buf1149, buf1150, 47952, 128, grid=grid(47952), stream=stream0)
        buf1151 = buf1141; del buf1141  # reuse
        buf1152 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1154 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_right_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_77.run(buf1148, buf1149, buf1150, primals_1042, primals_1043, buf1151, buf1152, buf1154, primals_1042, primals_1043, 432, 111, grid=grid(432), stream=stream0)
        del buf1148
        del buf1149
        del buf1150
        del primals_1042
        del primals_1043
        buf1155 = reinterpret_tensor(buf1146, (8, 432, 42, 42), (762048, 1, 18144, 432), 0); del buf1146  # reuse
        buf1183 = empty_strided((8, 432, 42, 42), (762048, 1, 18144, 432), device='cuda', dtype=torch.float32)
        buf2555 = empty_strided((8, 432, 42, 42), (762048, 1, 18144, 432), device='cuda', dtype=torch.bool)
        # Source Nodes: [x_456, x_right_6], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu, aten.threshold_backward]
        triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_79.run(buf1147, buf1151, buf1152, primals_352, primals_353, buf1155, buf1183, buf2555, 6096384, grid=grid(6096384), stream=stream0)
        del primals_353
        buf1156 = empty_strided((8, 432, 45, 45), (874800, 1, 19440, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_442, x_444], Original ATen: [aten.constant_pad_nd, aten.relu]
        triton_poi_fused_constant_pad_nd_relu_80.run(buf1144, buf1156, 6998400, grid=grid(6998400), stream=stream0)
        # Source Nodes: [x_445], Original ATen: [aten.convolution]
        buf1157 = extern_kernels.convolution(buf1156, primals_15, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1157, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1158 = reinterpret_tensor(buf447, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf447  # reuse
        # Source Nodes: [x_445], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1157, buf1158, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_447], Original ATen: [aten.convolution]
        buf1159 = extern_kernels.convolution(buf1158, primals_354, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1159, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1160 = reinterpret_tensor(buf1157, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1157  # reuse
        # Source Nodes: [x_447], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1159, buf1160, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1161 = empty_strided((1, 432, 1, 1, 28), (12096, 1, 12096, 12096, 432), device='cuda', dtype=torch.float32)
        buf1162 = empty_strided((1, 432, 1, 1, 28), (12096, 1, 12096, 12096, 432), device='cuda', dtype=torch.float32)
        buf1163 = empty_strided((1, 432, 1, 1, 28), (12096, 1, 12096, 12096, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_448], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1160, buf1161, buf1162, buf1163, 12096, 126, grid=grid(12096), stream=stream0)
        buf1164 = buf1152; del buf1152  # reuse
        buf1165 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1167 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_448], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1161, buf1162, buf1163, primals_1045, primals_1046, buf1164, buf1165, buf1167, primals_1045, primals_1046, 432, 28, grid=grid(432), stream=stream0)
        del primals_1045
        del primals_1046
        buf1168 = reinterpret_tensor(buf1159, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1159  # reuse
        # Source Nodes: [x_448, x_449], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1160, buf1164, buf1165, primals_355, primals_356, buf1168, 1524096, grid=grid(1524096), stream=stream0)
        del primals_356
        # Source Nodes: [x_450], Original ATen: [aten.convolution]
        buf1169 = extern_kernels.convolution(buf1168, primals_357, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1169, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1170 = reinterpret_tensor(buf444, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf444  # reuse
        # Source Nodes: [x_450], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1169, buf1170, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_452], Original ATen: [aten.convolution]
        buf1171 = extern_kernels.convolution(buf1170, primals_358, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1171, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1172 = reinterpret_tensor(buf1169, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1169  # reuse
        # Source Nodes: [x_452], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1171, buf1172, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1173 = buf1163; del buf1163  # reuse
        buf1174 = buf1162; del buf1162  # reuse
        buf1175 = buf1161; del buf1161  # reuse
        # Source Nodes: [x_comb_iter_0_left_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1172, buf1173, buf1174, buf1175, 12096, 126, grid=grid(12096), stream=stream0)
        buf1176 = buf1165; del buf1165  # reuse
        buf1177 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1179 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_0_left_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1173, buf1174, buf1175, primals_1048, primals_1049, buf1176, buf1177, buf1179, primals_1048, primals_1049, 432, 28, grid=grid(432), stream=stream0)
        del primals_1048
        del primals_1049
        buf1180 = empty_strided((8, 432, 43, 43), (798768, 1, 18576, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_455], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_85.run(buf1144, buf1180, 6390144, grid=grid(6390144), stream=stream0)
        buf1181 = reinterpret_tensor(buf1171, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1171  # reuse
        buf1182 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_0_right_6], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_86.run(buf1180, buf1181, buf1182, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1184 = empty_strided((8, 432, 47, 47), (954288, 1, 20304, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_458], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_87.run(buf1183, buf1184, 7634304, grid=grid(7634304), stream=stream0)
        # Source Nodes: [x_459], Original ATen: [aten.convolution]
        buf1185 = extern_kernels.convolution(buf1184, primals_16, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1185, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1186 = reinterpret_tensor(buf330, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf330  # reuse
        # Source Nodes: [x_459], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1185, buf1186, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_461], Original ATen: [aten.convolution]
        buf1187 = extern_kernels.convolution(buf1186, primals_361, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1187, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1188 = reinterpret_tensor(buf1185, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1185  # reuse
        # Source Nodes: [x_461], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1187, buf1188, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1189 = buf1175; del buf1175  # reuse
        buf1190 = buf1174; del buf1174  # reuse
        buf1191 = buf1173; del buf1173  # reuse
        # Source Nodes: [x_462], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1188, buf1189, buf1190, buf1191, 12096, 126, grid=grid(12096), stream=stream0)
        buf1192 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1193 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1195 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_462], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1189, buf1190, buf1191, primals_1051, primals_1052, buf1192, buf1193, buf1195, primals_1051, primals_1052, 432, 28, grid=grid(432), stream=stream0)
        del primals_1051
        del primals_1052
        buf1196 = reinterpret_tensor(buf1187, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1187  # reuse
        # Source Nodes: [x_462, x_463], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1188, buf1192, buf1193, primals_362, primals_363, buf1196, 1524096, grid=grid(1524096), stream=stream0)
        del primals_363
        # Source Nodes: [x_464], Original ATen: [aten.convolution]
        buf1197 = extern_kernels.convolution(buf1196, primals_364, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1197, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1198 = reinterpret_tensor(buf302, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf302  # reuse
        # Source Nodes: [x_464], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1197, buf1198, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_466], Original ATen: [aten.convolution]
        buf1199 = extern_kernels.convolution(buf1198, primals_365, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1199, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1200 = reinterpret_tensor(buf1197, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1197  # reuse
        # Source Nodes: [x_466], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1199, buf1200, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1201 = buf1191; del buf1191  # reuse
        buf1202 = buf1190; del buf1190  # reuse
        buf1203 = buf1189; del buf1189  # reuse
        # Source Nodes: [x_comb_iter_1_left_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1200, buf1201, buf1202, buf1203, 12096, 126, grid=grid(12096), stream=stream0)
        buf1204 = buf1193; del buf1193  # reuse
        buf1205 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1207 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_1_left_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1201, buf1202, buf1203, primals_1054, primals_1055, buf1204, buf1205, buf1207, primals_1054, primals_1055, 432, 28, grid=grid(432), stream=stream0)
        del primals_1054
        del primals_1055
        buf1208 = empty_strided((8, 432, 43, 43), (798768, 1, 18576, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_469], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_85.run(buf1155, buf1208, 6390144, grid=grid(6390144), stream=stream0)
        del buf1155
        buf1209 = reinterpret_tensor(buf1199, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1199  # reuse
        buf1210 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_1_right_6], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_86.run(buf1208, buf1209, buf1210, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1211 = empty_strided((8, 432, 45, 45), (874800, 1, 19440, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_472], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_88.run(buf1183, buf1211, 6998400, grid=grid(6998400), stream=stream0)
        # Source Nodes: [x_473], Original ATen: [aten.convolution]
        buf1212 = extern_kernels.convolution(buf1211, primals_17, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1212, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1213 = reinterpret_tensor(buf429, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf429  # reuse
        # Source Nodes: [x_473], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1212, buf1213, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_475], Original ATen: [aten.convolution]
        buf1214 = extern_kernels.convolution(buf1213, primals_368, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1214, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1215 = reinterpret_tensor(buf1212, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1212  # reuse
        # Source Nodes: [x_475], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1214, buf1215, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1216 = buf1203; del buf1203  # reuse
        buf1217 = buf1202; del buf1202  # reuse
        buf1218 = buf1201; del buf1201  # reuse
        # Source Nodes: [x_476], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1215, buf1216, buf1217, buf1218, 12096, 126, grid=grid(12096), stream=stream0)
        buf1219 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1220 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1222 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_476], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1216, buf1217, buf1218, primals_1057, primals_1058, buf1219, buf1220, buf1222, primals_1057, primals_1058, 432, 28, grid=grid(432), stream=stream0)
        del primals_1057
        del primals_1058
        buf1223 = reinterpret_tensor(buf1214, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1214  # reuse
        # Source Nodes: [x_476, x_477], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1215, buf1219, buf1220, primals_369, primals_370, buf1223, 1524096, grid=grid(1524096), stream=stream0)
        del primals_370
        # Source Nodes: [x_478], Original ATen: [aten.convolution]
        buf1224 = extern_kernels.convolution(buf1223, primals_371, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1224, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1225 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_478], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1224, buf1225, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_480], Original ATen: [aten.convolution]
        buf1226 = extern_kernels.convolution(buf1225, primals_372, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1226, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1227 = reinterpret_tensor(buf1224, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1224  # reuse
        # Source Nodes: [x_480], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1226, buf1227, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1228 = buf1218; del buf1218  # reuse
        buf1229 = buf1217; del buf1217  # reuse
        buf1230 = buf1216; del buf1216  # reuse
        # Source Nodes: [x_comb_iter_2_left_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1227, buf1228, buf1229, buf1230, 12096, 126, grid=grid(12096), stream=stream0)
        buf1231 = buf1220; del buf1220  # reuse
        buf1232 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1234 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_left_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1228, buf1229, buf1230, primals_1060, primals_1061, buf1231, buf1232, buf1234, primals_1060, primals_1061, 432, 28, grid=grid(432), stream=stream0)
        del primals_1060
        del primals_1061
        buf1235 = empty_strided((8, 432, 43, 43), (798768, 1, 18576, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_484], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_89.run(buf1183, buf1235, 6390144, grid=grid(6390144), stream=stream0)
        # Source Nodes: [x_485], Original ATen: [aten.convolution]
        buf1236 = extern_kernels.convolution(buf1235, primals_18, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1236, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1237 = reinterpret_tensor(buf1226, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1226  # reuse
        # Source Nodes: [x_485], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1236, buf1237, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_487], Original ATen: [aten.convolution]
        buf1238 = extern_kernels.convolution(buf1237, primals_375, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1238, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1239 = reinterpret_tensor(buf1236, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1236  # reuse
        # Source Nodes: [x_487], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1238, buf1239, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1240 = buf1230; del buf1230  # reuse
        buf1241 = buf1229; del buf1229  # reuse
        buf1242 = buf1228; del buf1228  # reuse
        # Source Nodes: [x_488], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1239, buf1240, buf1241, buf1242, 12096, 126, grid=grid(12096), stream=stream0)
        buf1243 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1244 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1246 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_488], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1240, buf1241, buf1242, primals_1063, primals_1064, buf1243, buf1244, buf1246, primals_1063, primals_1064, 432, 28, grid=grid(432), stream=stream0)
        del primals_1063
        del primals_1064
        buf1247 = reinterpret_tensor(buf1238, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1238  # reuse
        # Source Nodes: [x_488, x_489], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1239, buf1243, buf1244, primals_376, primals_377, buf1247, 1524096, grid=grid(1524096), stream=stream0)
        del primals_377
        # Source Nodes: [x_490], Original ATen: [aten.convolution]
        buf1248 = extern_kernels.convolution(buf1247, primals_378, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1248, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1249 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_490], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1248, buf1249, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_492], Original ATen: [aten.convolution]
        buf1250 = extern_kernels.convolution(buf1249, primals_379, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1250, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1251 = reinterpret_tensor(buf1248, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1248  # reuse
        # Source Nodes: [x_492], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1250, buf1251, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1252 = buf1242; del buf1242  # reuse
        buf1253 = buf1241; del buf1241  # reuse
        buf1254 = buf1240; del buf1240  # reuse
        # Source Nodes: [x_comb_iter_2_right_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1251, buf1252, buf1253, buf1254, 12096, 126, grid=grid(12096), stream=stream0)
        buf1255 = buf1244; del buf1244  # reuse
        buf1256 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1258 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_right_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1252, buf1253, buf1254, primals_1066, primals_1067, buf1255, buf1256, buf1258, primals_1066, primals_1067, 432, 28, grid=grid(432), stream=stream0)
        del primals_1066
        del primals_1067
        buf1321 = reinterpret_tensor(buf442, (8, 2160, 21, 21), (952560, 441, 21, 1), 0); del buf442  # reuse
        buf1259 = reinterpret_tensor(buf1321, (8, 432, 21, 21), (952560, 441, 21, 1), 381024)  # alias
        # Source Nodes: [x_comb_iter_2_left_6, x_comb_iter_2_right_6, x_comb_iter_32], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_90.run(buf1227, buf1231, buf1232, primals_373, primals_374, buf1251, buf1255, buf1256, primals_380, primals_381, buf1259, 3528, 432, grid=grid(3528, 432), stream=stream0)
        del primals_374
        del primals_381
        buf1260 = reinterpret_tensor(buf1250, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1250  # reuse
        # Source Nodes: [x_494], Original ATen: [aten.relu]
        triton_poi_fused_relu_91.run(buf1259, buf1260, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_495], Original ATen: [aten.convolution]
        buf1261 = extern_kernels.convolution(buf1260, primals_382, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1261, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1262 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_495], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1261, buf1262, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_497], Original ATen: [aten.convolution]
        buf1263 = extern_kernels.convolution(buf1262, primals_383, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1263, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1264 = reinterpret_tensor(buf1261, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1261  # reuse
        # Source Nodes: [x_497], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1263, buf1264, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1265 = buf1254; del buf1254  # reuse
        buf1266 = buf1253; del buf1253  # reuse
        buf1267 = buf1252; del buf1252  # reuse
        # Source Nodes: [x_498], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1264, buf1265, buf1266, buf1267, 12096, 126, grid=grid(12096), stream=stream0)
        buf1268 = buf1256; del buf1256  # reuse
        buf1269 = buf1232; del buf1232  # reuse
        buf1271 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_498], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1265, buf1266, buf1267, primals_1069, primals_1070, buf1268, buf1269, buf1271, primals_1069, primals_1070, 432, 28, grid=grid(432), stream=stream0)
        del primals_1069
        del primals_1070
        buf1272 = reinterpret_tensor(buf1263, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1263  # reuse
        # Source Nodes: [x_498, x_499], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1264, buf1268, buf1269, primals_384, primals_385, buf1272, 1524096, grid=grid(1524096), stream=stream0)
        del primals_385
        # Source Nodes: [x_500], Original ATen: [aten.convolution]
        buf1273 = extern_kernels.convolution(buf1272, primals_386, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1273, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1274 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_500], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1273, buf1274, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_502], Original ATen: [aten.convolution]
        buf1275 = extern_kernels.convolution(buf1274, primals_387, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1275, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1276 = reinterpret_tensor(buf1273, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1273  # reuse
        # Source Nodes: [x_502], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1275, buf1276, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1277 = buf1267; del buf1267  # reuse
        buf1278 = buf1266; del buf1266  # reuse
        buf1279 = buf1265; del buf1265  # reuse
        # Source Nodes: [x_comb_iter_3_left_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1276, buf1277, buf1278, buf1279, 12096, 126, grid=grid(12096), stream=stream0)
        buf1280 = buf1269; del buf1269  # reuse
        buf1281 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1283 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_3_left_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1277, buf1278, buf1279, primals_1072, primals_1073, buf1280, buf1281, buf1283, primals_1072, primals_1073, 432, 28, grid=grid(432), stream=stream0)
        del primals_1072
        del primals_1073
        buf1284 = empty_strided((8, 432, 43, 43), (798768, 1, 18576, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_442, x_508], Original ATen: [aten.constant_pad_nd, aten.relu]
        triton_poi_fused_constant_pad_nd_relu_92.run(buf1144, buf1284, 6390144, grid=grid(6390144), stream=stream0)
        del buf1144
        # Source Nodes: [x_509], Original ATen: [aten.convolution]
        buf1285 = extern_kernels.convolution(buf1284, primals_19, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1285, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1286 = reinterpret_tensor(buf1275, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1275  # reuse
        # Source Nodes: [x_509], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1285, buf1286, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_511], Original ATen: [aten.convolution]
        buf1287 = extern_kernels.convolution(buf1286, primals_390, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1287, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1288 = reinterpret_tensor(buf1285, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1285  # reuse
        # Source Nodes: [x_511], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1287, buf1288, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1289 = buf1279; del buf1279  # reuse
        buf1290 = buf1278; del buf1278  # reuse
        buf1291 = buf1277; del buf1277  # reuse
        # Source Nodes: [x_512], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1288, buf1289, buf1290, buf1291, 12096, 126, grid=grid(12096), stream=stream0)
        buf1292 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1293 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1295 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_512], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1289, buf1290, buf1291, primals_1075, primals_1076, buf1292, buf1293, buf1295, primals_1075, primals_1076, 432, 28, grid=grid(432), stream=stream0)
        del primals_1075
        del primals_1076
        buf1296 = reinterpret_tensor(buf1287, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1287  # reuse
        # Source Nodes: [x_512, x_513], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1288, buf1292, buf1293, primals_391, primals_392, buf1296, 1524096, grid=grid(1524096), stream=stream0)
        del primals_392
        # Source Nodes: [x_514], Original ATen: [aten.convolution]
        buf1297 = extern_kernels.convolution(buf1296, primals_393, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1297, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1298 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_514], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1297, buf1298, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_516], Original ATen: [aten.convolution]
        buf1299 = extern_kernels.convolution(buf1298, primals_394, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1299, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1300 = reinterpret_tensor(buf1297, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1297  # reuse
        # Source Nodes: [x_516], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1299, buf1300, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1301 = buf1291; del buf1291  # reuse
        buf1302 = buf1290; del buf1290  # reuse
        buf1303 = buf1289; del buf1289  # reuse
        # Source Nodes: [x_comb_iter_4_left_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1300, buf1301, buf1302, buf1303, 12096, 126, grid=grid(12096), stream=stream0)
        buf1304 = buf1293; del buf1293  # reuse
        buf1305 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1307 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_left_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1301, buf1302, buf1303, primals_1078, primals_1079, buf1304, buf1305, buf1307, primals_1078, primals_1079, 432, 28, grid=grid(432), stream=stream0)
        del primals_1078
        del primals_1079
        # Source Nodes: [x_521], Original ATen: [aten.convolution]
        buf1308 = extern_kernels.convolution(buf1183, primals_20, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1308, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1309 = reinterpret_tensor(buf1299, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1299  # reuse
        # Source Nodes: [x_521], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1308, buf1309, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1310 = buf1303; del buf1303  # reuse
        buf1311 = buf1302; del buf1302  # reuse
        buf1312 = buf1301; del buf1301  # reuse
        # Source Nodes: [x_comb_iter_4_right_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1309, buf1310, buf1311, buf1312, 12096, 126, grid=grid(12096), stream=stream0)
        buf1313 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1314 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1316 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_right_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1310, buf1311, buf1312, primals_1081, primals_1082, buf1313, buf1314, buf1316, primals_1081, primals_1082, 432, 28, grid=grid(432), stream=stream0)
        del primals_1081
        del primals_1082
        buf1317 = reinterpret_tensor(buf1321, (8, 432, 21, 21), (952560, 441, 21, 1), 762048)  # alias
        # Source Nodes: [x_comb_iter_34, x_comb_iter_4_left_6, x_comb_iter_4_right_6], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_90.run(buf1300, buf1304, buf1305, primals_395, primals_396, buf1309, buf1313, buf1314, primals_397, primals_398, buf1317, 3528, 432, grid=grid(3528, 432), stream=stream0)
        del primals_396
        del primals_398
        buf1318 = reinterpret_tensor(buf1321, (8, 432, 21, 21), (952560, 441, 21, 1), 0)  # alias
        # Source Nodes: [x_comb_iter_0_left_6, x_comb_iter_30], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_93.run(buf1172, buf1176, buf1177, primals_359, primals_360, buf1181, buf1318, 3528, 432, grid=grid(3528, 432), stream=stream0)
        del primals_360
        buf1319 = reinterpret_tensor(buf1321, (8, 432, 21, 21), (952560, 441, 21, 1), 190512)  # alias
        buf1320 = reinterpret_tensor(buf1321, (8, 432, 21, 21), (952560, 441, 21, 1), 571536)  # alias
        # Source Nodes: [x_comb_iter_1_left_6, x_comb_iter_31, x_comb_iter_33, x_comb_iter_3_left_6], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_94.run(buf1200, buf1204, buf1205, primals_366, primals_367, buf1209, buf1276, buf1280, buf1281, primals_388, primals_389, buf1319, buf1320, 3528, 432, grid=grid(3528, 432), stream=stream0)
        del primals_367
        del primals_389
        buf1322 = empty_strided((8, 1080, 21, 21), (476280, 1, 22680, 1080), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___cell_5_conv_prev_1x1_path_1_avgpool], Original ATen: [aten.avg_pool2d]
        triton_poi_fused_avg_pool2d_95.run(buf1145, buf1322, 3810240, grid=grid(3810240), stream=stream0)
        del buf1259
        del buf1317
        del buf1318
        del buf1319
        del buf1320
        # Source Nodes: [x_path1_2], Original ATen: [aten.convolution]
        buf1323 = extern_kernels.convolution(buf1322, primals_399, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1323, (8, 216, 21, 21), (95256, 441, 21, 1))
        buf1324 = reinterpret_tensor(buf1134, (8, 1080, 42, 42), (1905120, 1, 45360, 1080), 0); del buf1134  # reuse
        # Source Nodes: [l__mod___cell_5_conv_prev_1x1_path_2_pad], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_96.run(buf1145, buf1324, 15240960, grid=grid(15240960), stream=stream0)
        buf1325 = empty_strided((8, 1080, 21, 21), (476280, 1, 22680, 1080), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___cell_5_conv_prev_1x1_path_2_avgpool], Original ATen: [aten.avg_pool2d]
        triton_poi_fused_avg_pool2d_97.run(buf1324, buf1325, 8640, 441, grid=grid(8640, 441), stream=stream0)
        # Source Nodes: [x_path2_2], Original ATen: [aten.convolution]
        buf1326 = extern_kernels.convolution(buf1325, primals_400, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1326, (8, 216, 21, 21), (95256, 441, 21, 1))
        buf1327 = buf1209; del buf1209  # reuse
        # Source Nodes: [cat_26], Original ATen: [aten.cat]
        triton_poi_fused_cat_98.run(buf1323, buf1326, buf1327, 3456, 441, grid=grid(3456, 441), stream=stream0)
        del buf1323
        del buf1326
        buf1328 = buf1312; del buf1312  # reuse
        buf1329 = buf1311; del buf1311  # reuse
        buf1330 = buf1310; del buf1310  # reuse
        # Source Nodes: [x_left_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1327, buf1328, buf1329, buf1330, 12096, 126, grid=grid(12096), stream=stream0)
        buf1331 = buf1281; del buf1281  # reuse
        buf1332 = buf1205; del buf1205  # reuse
        buf1334 = reinterpret_tensor(buf1177, (432, ), (1, ), 0); del buf1177  # reuse
        # Source Nodes: [x_left_6], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1328, buf1329, buf1330, primals_1084, primals_1085, buf1331, buf1332, buf1334, primals_1084, primals_1085, 432, 28, grid=grid(432), stream=stream0)
        del primals_1084
        del primals_1085
        buf1335 = buf1181; del buf1181  # reuse
        buf1347 = reinterpret_tensor(buf1308, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1308  # reuse
        # Source Nodes: [x_527, x_left_6], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_99.run(buf1327, buf1331, buf1332, primals_401, primals_402, buf1335, buf1347, 1524096, grid=grid(1524096), stream=stream0)
        del primals_402
        buf1336 = empty_strided((8, 2160, 21, 21), (952560, 1, 45360, 2160), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_524], Original ATen: [aten.relu]
        triton_poi_fused_relu_100.run(buf1321, buf1336, 17280, 441, grid=grid(17280, 441), stream=stream0)
        # Source Nodes: [x_525], Original ATen: [aten.convolution]
        buf1337 = extern_kernels.convolution(buf1336, primals_403, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1337, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1338 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_525], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1337, buf1338, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1339 = buf1330; del buf1330  # reuse
        buf1340 = buf1329; del buf1329  # reuse
        buf1341 = buf1328; del buf1328  # reuse
        # Source Nodes: [x_comb_iter_4_right_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1338, buf1339, buf1340, buf1341, 12096, 126, grid=grid(12096), stream=stream0)
        buf1342 = buf1332; del buf1332  # reuse
        buf1343 = buf1314; del buf1314  # reuse
        buf1345 = reinterpret_tensor(buf1305, (432, ), (1, ), 0); del buf1305  # reuse
        # Source Nodes: [x_comb_iter_4_right_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1339, buf1340, buf1341, primals_1087, primals_1088, buf1342, buf1343, buf1345, primals_1087, primals_1088, 432, 28, grid=grid(432), stream=stream0)
        del primals_1087
        del primals_1088
        # Source Nodes: [x_578], Original ATen: [aten.convolution]
        buf1470 = extern_kernels.convolution(buf1347, primals_446, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1470, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1471 = reinterpret_tensor(buf1337, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1337  # reuse
        # Source Nodes: [x_578], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1470, buf1471, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_580], Original ATen: [aten.convolution]
        buf1472 = extern_kernels.convolution(buf1471, primals_447, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1472, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1473 = reinterpret_tensor(buf1470, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1470  # reuse
        # Source Nodes: [x_580], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1472, buf1473, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1474 = buf1341; del buf1341  # reuse
        buf1475 = buf1340; del buf1340  # reuse
        buf1476 = buf1339; del buf1339  # reuse
        # Source Nodes: [x_581], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1473, buf1474, buf1475, buf1476, 12096, 126, grid=grid(12096), stream=stream0)
        buf1477 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1478 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1480 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_581], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1474, buf1475, buf1476, primals_1120, primals_1121, buf1477, buf1478, buf1480, primals_1120, primals_1121, 432, 28, grid=grid(432), stream=stream0)
        del primals_1120
        del primals_1121
        buf1481 = reinterpret_tensor(buf1472, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1472  # reuse
        # Source Nodes: [x_581, x_582], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1473, buf1477, buf1478, primals_448, primals_449, buf1481, 1524096, grid=grid(1524096), stream=stream0)
        del primals_449
        # Source Nodes: [x_583], Original ATen: [aten.convolution]
        buf1482 = extern_kernels.convolution(buf1481, primals_450, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1482, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1483 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_583], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1482, buf1483, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_585], Original ATen: [aten.convolution]
        buf1484 = extern_kernels.convolution(buf1483, primals_451, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1484, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1485 = reinterpret_tensor(buf1482, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1482  # reuse
        # Source Nodes: [x_585], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1484, buf1485, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1486 = buf1476; del buf1476  # reuse
        buf1487 = buf1475; del buf1475  # reuse
        buf1488 = buf1474; del buf1474  # reuse
        # Source Nodes: [x_comb_iter_4_left_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1485, buf1486, buf1487, buf1488, 12096, 126, grid=grid(12096), stream=stream0)
        buf1489 = buf1478; del buf1478  # reuse
        buf1490 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1492 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_left_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1486, buf1487, buf1488, primals_1123, primals_1124, buf1489, buf1490, buf1492, primals_1123, primals_1124, 432, 28, grid=grid(432), stream=stream0)
        del primals_1123
        del primals_1124
        buf1346 = reinterpret_tensor(buf1484, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1484  # reuse
        buf1497 = buf1321; del buf1321  # reuse
        buf1496 = reinterpret_tensor(buf1497, (8, 432, 21, 21), (952560, 441, 21, 1), 762048)  # alias
        # Source Nodes: [x_comb_iter_39, x_comb_iter_4_left_7, x_comb_iter_4_right_7], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_101.run(buf1338, buf1342, buf1343, primals_404, primals_405, buf1485, buf1489, buf1490, primals_452, primals_453, buf1346, buf1496, 3528, 432, grid=grid(3528, 432), stream=stream0)
        del primals_405
        del primals_453
        # Source Nodes: [x_528], Original ATen: [aten.convolution]
        buf1348 = extern_kernels.convolution(buf1347, primals_406, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1348, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1349 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_528], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1348, buf1349, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_530], Original ATen: [aten.convolution]
        buf1350 = extern_kernels.convolution(buf1349, primals_407, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1350, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1351 = reinterpret_tensor(buf1348, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1348  # reuse
        # Source Nodes: [x_530], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1350, buf1351, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1352 = buf1488; del buf1488  # reuse
        buf1353 = buf1487; del buf1487  # reuse
        buf1354 = buf1486; del buf1486  # reuse
        # Source Nodes: [x_531], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1351, buf1352, buf1353, buf1354, 12096, 126, grid=grid(12096), stream=stream0)
        buf1355 = buf1490; del buf1490  # reuse
        buf1356 = buf1343; del buf1343  # reuse
        buf1358 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_531], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1352, buf1353, buf1354, primals_1090, primals_1091, buf1355, buf1356, buf1358, primals_1090, primals_1091, 432, 28, grid=grid(432), stream=stream0)
        del primals_1090
        del primals_1091
        buf1359 = reinterpret_tensor(buf1350, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1350  # reuse
        # Source Nodes: [x_531, x_532], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1351, buf1355, buf1356, primals_408, primals_409, buf1359, 1524096, grid=grid(1524096), stream=stream0)
        del primals_409
        # Source Nodes: [x_533], Original ATen: [aten.convolution]
        buf1360 = extern_kernels.convolution(buf1359, primals_410, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1360, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1361 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_533], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1360, buf1361, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_535], Original ATen: [aten.convolution]
        buf1362 = extern_kernels.convolution(buf1361, primals_411, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1362, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1363 = reinterpret_tensor(buf1360, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1360  # reuse
        # Source Nodes: [x_535], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1362, buf1363, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1364 = buf1354; del buf1354  # reuse
        buf1365 = buf1353; del buf1353  # reuse
        buf1366 = buf1352; del buf1352  # reuse
        # Source Nodes: [x_comb_iter_0_left_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1363, buf1364, buf1365, buf1366, 12096, 126, grid=grid(12096), stream=stream0)
        buf1367 = buf1356; del buf1356  # reuse
        buf1368 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1370 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_0_left_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1364, buf1365, buf1366, primals_1093, primals_1094, buf1367, buf1368, buf1370, primals_1093, primals_1094, 432, 28, grid=grid(432), stream=stream0)
        del primals_1093
        del primals_1094
        buf1371 = reinterpret_tensor(buf1362, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1362  # reuse
        buf1372 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_0_right_7], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_102.run(buf1335, buf1371, buf1372, 1524096, grid=grid(1524096), stream=stream0)
        buf1373 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        buf1397 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        buf1398 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_537, x_comb_iter_1_right_7], Original ATen: [aten.max_pool2d_with_indices, aten.relu]
        triton_poi_fused_max_pool2d_with_indices_relu_103.run(buf1346, buf1373, buf1397, buf1398, 1524096, grid=grid(1524096), stream=stream0)
        # Source Nodes: [x_538], Original ATen: [aten.convolution]
        buf1374 = extern_kernels.convolution(buf1373, primals_414, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1374, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1375 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_538], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1374, buf1375, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_540], Original ATen: [aten.convolution]
        buf1376 = extern_kernels.convolution(buf1375, primals_415, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1376, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1377 = reinterpret_tensor(buf1374, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1374  # reuse
        # Source Nodes: [x_540], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1376, buf1377, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1378 = buf1366; del buf1366  # reuse
        buf1379 = buf1365; del buf1365  # reuse
        buf1380 = buf1364; del buf1364  # reuse
        # Source Nodes: [x_541], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1377, buf1378, buf1379, buf1380, 12096, 126, grid=grid(12096), stream=stream0)
        buf1381 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1382 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1384 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_541], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1378, buf1379, buf1380, primals_1096, primals_1097, buf1381, buf1382, buf1384, primals_1096, primals_1097, 432, 28, grid=grid(432), stream=stream0)
        del primals_1096
        del primals_1097
        buf1385 = reinterpret_tensor(buf1376, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1376  # reuse
        # Source Nodes: [x_541, x_542], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1377, buf1381, buf1382, primals_416, primals_417, buf1385, 1524096, grid=grid(1524096), stream=stream0)
        del primals_417
        # Source Nodes: [x_543], Original ATen: [aten.convolution]
        buf1386 = extern_kernels.convolution(buf1385, primals_418, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1386, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1387 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_543], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1386, buf1387, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_545], Original ATen: [aten.convolution]
        buf1388 = extern_kernels.convolution(buf1387, primals_419, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1388, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1389 = reinterpret_tensor(buf1386, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1386  # reuse
        # Source Nodes: [x_545], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1388, buf1389, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1390 = buf1380; del buf1380  # reuse
        buf1391 = buf1379; del buf1379  # reuse
        buf1392 = buf1378; del buf1378  # reuse
        # Source Nodes: [x_comb_iter_1_left_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1389, buf1390, buf1391, buf1392, 12096, 126, grid=grid(12096), stream=stream0)
        buf1393 = buf1382; del buf1382  # reuse
        buf1394 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1396 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_1_left_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1390, buf1391, buf1392, primals_1099, primals_1100, buf1393, buf1394, buf1396, primals_1099, primals_1100, 432, 28, grid=grid(432), stream=stream0)
        del primals_1099
        del primals_1100
        # Source Nodes: [x_548], Original ATen: [aten.convolution]
        buf1399 = extern_kernels.convolution(buf1373, primals_422, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1399, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1400 = reinterpret_tensor(buf1388, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1388  # reuse
        # Source Nodes: [x_548], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1399, buf1400, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_550], Original ATen: [aten.convolution]
        buf1401 = extern_kernels.convolution(buf1400, primals_423, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1401, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1402 = reinterpret_tensor(buf1399, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1399  # reuse
        # Source Nodes: [x_550], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1401, buf1402, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1403 = buf1392; del buf1392  # reuse
        buf1404 = buf1391; del buf1391  # reuse
        buf1405 = buf1390; del buf1390  # reuse
        # Source Nodes: [x_551], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1402, buf1403, buf1404, buf1405, 12096, 126, grid=grid(12096), stream=stream0)
        buf1406 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1407 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1409 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_551], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1403, buf1404, buf1405, primals_1102, primals_1103, buf1406, buf1407, buf1409, primals_1102, primals_1103, 432, 28, grid=grid(432), stream=stream0)
        del primals_1102
        del primals_1103
        buf1410 = reinterpret_tensor(buf1401, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1401  # reuse
        # Source Nodes: [x_551, x_552], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1402, buf1406, buf1407, primals_424, primals_425, buf1410, 1524096, grid=grid(1524096), stream=stream0)
        del primals_425
        # Source Nodes: [x_553], Original ATen: [aten.convolution]
        buf1411 = extern_kernels.convolution(buf1410, primals_426, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1411, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1412 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_553], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1411, buf1412, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_555], Original ATen: [aten.convolution]
        buf1413 = extern_kernels.convolution(buf1412, primals_427, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1413, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1414 = reinterpret_tensor(buf1411, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1411  # reuse
        # Source Nodes: [x_555], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1413, buf1414, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1415 = buf1405; del buf1405  # reuse
        buf1416 = buf1404; del buf1404  # reuse
        buf1417 = buf1403; del buf1403  # reuse
        # Source Nodes: [x_comb_iter_2_left_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1414, buf1415, buf1416, buf1417, 12096, 126, grid=grid(12096), stream=stream0)
        buf1418 = buf1407; del buf1407  # reuse
        buf1419 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1421 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_left_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1415, buf1416, buf1417, primals_1105, primals_1106, buf1418, buf1419, buf1421, primals_1105, primals_1106, 432, 28, grid=grid(432), stream=stream0)
        del primals_1105
        del primals_1106
        # Source Nodes: [x_558], Original ATen: [aten.convolution]
        buf1422 = extern_kernels.convolution(buf1373, primals_430, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1422, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1423 = reinterpret_tensor(buf1413, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1413  # reuse
        # Source Nodes: [x_558], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1422, buf1423, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_560], Original ATen: [aten.convolution]
        buf1424 = extern_kernels.convolution(buf1423, primals_431, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1424, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1425 = reinterpret_tensor(buf1422, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1422  # reuse
        # Source Nodes: [x_560], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1424, buf1425, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1426 = buf1417; del buf1417  # reuse
        buf1427 = buf1416; del buf1416  # reuse
        buf1428 = buf1415; del buf1415  # reuse
        # Source Nodes: [x_561], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1425, buf1426, buf1427, buf1428, 12096, 126, grid=grid(12096), stream=stream0)
        buf1429 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1430 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1432 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_561], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1426, buf1427, buf1428, primals_1108, primals_1109, buf1429, buf1430, buf1432, primals_1108, primals_1109, 432, 28, grid=grid(432), stream=stream0)
        del primals_1108
        del primals_1109
        buf1433 = reinterpret_tensor(buf1424, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1424  # reuse
        # Source Nodes: [x_561, x_562], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1425, buf1429, buf1430, primals_432, primals_433, buf1433, 1524096, grid=grid(1524096), stream=stream0)
        del primals_433
        # Source Nodes: [x_563], Original ATen: [aten.convolution]
        buf1434 = extern_kernels.convolution(buf1433, primals_434, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1434, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1435 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_563], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1434, buf1435, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_565], Original ATen: [aten.convolution]
        buf1436 = extern_kernels.convolution(buf1435, primals_435, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1436, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1437 = reinterpret_tensor(buf1434, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1434  # reuse
        # Source Nodes: [x_565], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1436, buf1437, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1438 = buf1428; del buf1428  # reuse
        buf1439 = buf1427; del buf1427  # reuse
        buf1440 = buf1426; del buf1426  # reuse
        # Source Nodes: [x_comb_iter_2_right_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1437, buf1438, buf1439, buf1440, 12096, 126, grid=grid(12096), stream=stream0)
        buf1441 = buf1430; del buf1430  # reuse
        buf1442 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1444 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_right_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1438, buf1439, buf1440, primals_1111, primals_1112, buf1441, buf1442, buf1444, primals_1111, primals_1112, 432, 28, grid=grid(432), stream=stream0)
        del primals_1111
        del primals_1112
        buf1445 = reinterpret_tensor(buf1497, (8, 432, 21, 21), (952560, 441, 21, 1), 381024)  # alias
        # Source Nodes: [x_comb_iter_2_left_7, x_comb_iter_2_right_7, x_comb_iter_37], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_90.run(buf1414, buf1418, buf1419, primals_428, primals_429, buf1437, buf1441, buf1442, primals_436, primals_437, buf1445, 3528, 432, grid=grid(3528, 432), stream=stream0)
        del primals_429
        del primals_437
        buf1446 = reinterpret_tensor(buf1436, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1436  # reuse
        # Source Nodes: [x_567], Original ATen: [aten.relu]
        triton_poi_fused_relu_91.run(buf1445, buf1446, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_568], Original ATen: [aten.convolution]
        buf1447 = extern_kernels.convolution(buf1446, primals_438, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1447, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1448 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_568], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1447, buf1448, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_570], Original ATen: [aten.convolution]
        buf1449 = extern_kernels.convolution(buf1448, primals_439, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1449, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1450 = reinterpret_tensor(buf1447, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1447  # reuse
        # Source Nodes: [x_570], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1449, buf1450, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1451 = buf1440; del buf1440  # reuse
        buf1452 = buf1439; del buf1439  # reuse
        buf1453 = buf1438; del buf1438  # reuse
        # Source Nodes: [x_571], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1450, buf1451, buf1452, buf1453, 12096, 126, grid=grid(12096), stream=stream0)
        buf1454 = buf1442; del buf1442  # reuse
        buf1455 = buf1419; del buf1419  # reuse
        buf1457 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_571], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1451, buf1452, buf1453, primals_1114, primals_1115, buf1454, buf1455, buf1457, primals_1114, primals_1115, 432, 28, grid=grid(432), stream=stream0)
        del primals_1114
        del primals_1115
        buf1458 = reinterpret_tensor(buf1449, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1449  # reuse
        # Source Nodes: [x_571, x_572], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1450, buf1454, buf1455, primals_440, primals_441, buf1458, 1524096, grid=grid(1524096), stream=stream0)
        del primals_441
        # Source Nodes: [x_573], Original ATen: [aten.convolution]
        buf1459 = extern_kernels.convolution(buf1458, primals_442, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1459, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1460 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_573], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1459, buf1460, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_575], Original ATen: [aten.convolution]
        buf1461 = extern_kernels.convolution(buf1460, primals_443, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1461, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1462 = reinterpret_tensor(buf1459, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1459  # reuse
        # Source Nodes: [x_575], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1461, buf1462, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1463 = buf1453; del buf1453  # reuse
        buf1464 = buf1452; del buf1452  # reuse
        buf1465 = buf1451; del buf1451  # reuse
        # Source Nodes: [x_comb_iter_3_left_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1462, buf1463, buf1464, buf1465, 12096, 126, grid=grid(12096), stream=stream0)
        buf1466 = buf1455; del buf1455  # reuse
        buf1467 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1469 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_3_left_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1463, buf1464, buf1465, primals_1117, primals_1118, buf1466, buf1467, buf1469, primals_1117, primals_1118, 432, 28, grid=grid(432), stream=stream0)
        del primals_1117
        del primals_1118
        buf1493 = reinterpret_tensor(buf1497, (8, 432, 21, 21), (952560, 441, 21, 1), 0)  # alias
        # Source Nodes: [x_comb_iter_0_left_7, x_comb_iter_35], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_104.run(buf1363, buf1367, buf1368, primals_412, primals_413, buf1371, buf1493, 3456, 441, grid=grid(3456, 441), stream=stream0)
        del primals_413
        buf1494 = reinterpret_tensor(buf1497, (8, 432, 21, 21), (952560, 441, 21, 1), 190512)  # alias
        buf1495 = reinterpret_tensor(buf1497, (8, 432, 21, 21), (952560, 441, 21, 1), 571536)  # alias
        # Source Nodes: [x_comb_iter_1_left_7, x_comb_iter_36, x_comb_iter_38, x_comb_iter_3_left_7], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_105.run(buf1389, buf1393, buf1394, primals_420, primals_421, buf1397, buf1462, buf1466, buf1467, primals_444, primals_445, buf1494, buf1495, 3456, 441, grid=grid(3456, 441), stream=stream0)
        del primals_421
        del primals_445
        del buf1445
        del buf1493
        del buf1494
        del buf1495
        del buf1496
        # Source Nodes: [x_588], Original ATen: [aten.convolution]
        buf1498 = extern_kernels.convolution(buf1336, primals_454, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1498, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1499 = buf1397; del buf1397  # reuse
        # Source Nodes: [x_588], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1498, buf1499, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1500 = buf1465; del buf1465  # reuse
        buf1501 = buf1464; del buf1464  # reuse
        buf1502 = buf1463; del buf1463  # reuse
        # Source Nodes: [x_left_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1499, buf1500, buf1501, buf1502, 12096, 126, grid=grid(12096), stream=stream0)
        buf1503 = buf1467; del buf1467  # reuse
        buf1504 = buf1394; del buf1394  # reuse
        buf1506 = reinterpret_tensor(buf1368, (432, ), (1, ), 0); del buf1368  # reuse
        # Source Nodes: [x_left_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1500, buf1501, buf1502, primals_1126, primals_1127, buf1503, buf1504, buf1506, primals_1126, primals_1127, 432, 28, grid=grid(432), stream=stream0)
        del primals_1126
        del primals_1127
        buf1507 = reinterpret_tensor(buf1498, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1498  # reuse
        buf1519 = buf1371; del buf1371  # reuse
        # Source Nodes: [x_593, x_left_7], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_99.run(buf1499, buf1503, buf1504, primals_455, primals_456, buf1507, buf1519, 1524096, grid=grid(1524096), stream=stream0)
        del primals_456
        buf1508 = empty_strided((8, 2160, 21, 21), (952560, 1, 45360, 2160), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_590], Original ATen: [aten.relu]
        triton_poi_fused_relu_100.run(buf1497, buf1508, 17280, 441, grid=grid(17280, 441), stream=stream0)
        # Source Nodes: [x_591], Original ATen: [aten.convolution]
        buf1509 = extern_kernels.convolution(buf1508, primals_457, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1509, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1510 = reinterpret_tensor(buf1461, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1461  # reuse
        # Source Nodes: [x_591], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1509, buf1510, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1511 = buf1502; del buf1502  # reuse
        buf1512 = buf1501; del buf1501  # reuse
        buf1513 = buf1500; del buf1500  # reuse
        # Source Nodes: [x_comb_iter_4_right_8], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1510, buf1511, buf1512, buf1513, 12096, 126, grid=grid(12096), stream=stream0)
        buf1514 = buf1504; del buf1504  # reuse
        buf1515 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1517 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_right_8], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1511, buf1512, buf1513, primals_1129, primals_1130, buf1514, buf1515, buf1517, primals_1129, primals_1130, 432, 28, grid=grid(432), stream=stream0)
        del primals_1129
        del primals_1130
        # Source Nodes: [x_644], Original ATen: [aten.convolution]
        buf1642 = extern_kernels.convolution(buf1519, primals_500, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1642, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1643 = reinterpret_tensor(buf1509, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1509  # reuse
        # Source Nodes: [x_644], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1642, buf1643, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_646], Original ATen: [aten.convolution]
        buf1644 = extern_kernels.convolution(buf1643, primals_501, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1644, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1645 = reinterpret_tensor(buf1642, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1642  # reuse
        # Source Nodes: [x_646], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1644, buf1645, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1646 = buf1513; del buf1513  # reuse
        buf1647 = buf1512; del buf1512  # reuse
        buf1648 = buf1511; del buf1511  # reuse
        # Source Nodes: [x_647], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1645, buf1646, buf1647, buf1648, 12096, 126, grid=grid(12096), stream=stream0)
        buf1649 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1650 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1652 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_647], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1646, buf1647, buf1648, primals_1162, primals_1163, buf1649, buf1650, buf1652, primals_1162, primals_1163, 432, 28, grid=grid(432), stream=stream0)
        del primals_1162
        del primals_1163
        buf1653 = reinterpret_tensor(buf1644, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1644  # reuse
        # Source Nodes: [x_647, x_648], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1645, buf1649, buf1650, primals_502, primals_503, buf1653, 1524096, grid=grid(1524096), stream=stream0)
        del primals_503
        # Source Nodes: [x_649], Original ATen: [aten.convolution]
        buf1654 = extern_kernels.convolution(buf1653, primals_504, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1654, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1655 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_649], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1654, buf1655, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_651], Original ATen: [aten.convolution]
        buf1656 = extern_kernels.convolution(buf1655, primals_505, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1656, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1657 = reinterpret_tensor(buf1654, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1654  # reuse
        # Source Nodes: [x_651], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1656, buf1657, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1658 = buf1648; del buf1648  # reuse
        buf1659 = buf1647; del buf1647  # reuse
        buf1660 = buf1646; del buf1646  # reuse
        # Source Nodes: [x_comb_iter_4_left_8], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1657, buf1658, buf1659, buf1660, 12096, 126, grid=grid(12096), stream=stream0)
        buf1661 = buf1650; del buf1650  # reuse
        buf1662 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1664 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_left_8], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1658, buf1659, buf1660, primals_1165, primals_1166, buf1661, buf1662, buf1664, primals_1165, primals_1166, 432, 28, grid=grid(432), stream=stream0)
        del primals_1165
        del primals_1166
        buf1518 = reinterpret_tensor(buf1656, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1656  # reuse
        buf1669 = buf1497; del buf1497  # reuse
        buf1668 = reinterpret_tensor(buf1669, (8, 432, 21, 21), (952560, 441, 21, 1), 762048)  # alias
        # Source Nodes: [x_comb_iter_44, x_comb_iter_4_left_8, x_comb_iter_4_right_8], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_101.run(buf1510, buf1514, buf1515, primals_458, primals_459, buf1657, buf1661, buf1662, primals_506, primals_507, buf1518, buf1668, 3528, 432, grid=grid(3528, 432), stream=stream0)
        del primals_459
        del primals_507
        # Source Nodes: [x_594], Original ATen: [aten.convolution]
        buf1520 = extern_kernels.convolution(buf1519, primals_460, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1520, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1521 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_594], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1520, buf1521, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_596], Original ATen: [aten.convolution]
        buf1522 = extern_kernels.convolution(buf1521, primals_461, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1522, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1523 = reinterpret_tensor(buf1520, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1520  # reuse
        # Source Nodes: [x_596], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1522, buf1523, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1524 = buf1660; del buf1660  # reuse
        buf1525 = buf1659; del buf1659  # reuse
        buf1526 = buf1658; del buf1658  # reuse
        # Source Nodes: [x_597], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1523, buf1524, buf1525, buf1526, 12096, 126, grid=grid(12096), stream=stream0)
        buf1527 = buf1662; del buf1662  # reuse
        buf1528 = buf1515; del buf1515  # reuse
        buf1530 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_597], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1524, buf1525, buf1526, primals_1132, primals_1133, buf1527, buf1528, buf1530, primals_1132, primals_1133, 432, 28, grid=grid(432), stream=stream0)
        del primals_1132
        del primals_1133
        buf1531 = reinterpret_tensor(buf1522, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1522  # reuse
        # Source Nodes: [x_597, x_598], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1523, buf1527, buf1528, primals_462, primals_463, buf1531, 1524096, grid=grid(1524096), stream=stream0)
        del primals_463
        # Source Nodes: [x_599], Original ATen: [aten.convolution]
        buf1532 = extern_kernels.convolution(buf1531, primals_464, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1532, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1533 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_599], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1532, buf1533, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_601], Original ATen: [aten.convolution]
        buf1534 = extern_kernels.convolution(buf1533, primals_465, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1534, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1535 = reinterpret_tensor(buf1532, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1532  # reuse
        # Source Nodes: [x_601], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1534, buf1535, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1536 = buf1526; del buf1526  # reuse
        buf1537 = buf1525; del buf1525  # reuse
        buf1538 = buf1524; del buf1524  # reuse
        # Source Nodes: [x_comb_iter_0_left_8], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1535, buf1536, buf1537, buf1538, 12096, 126, grid=grid(12096), stream=stream0)
        buf1539 = buf1528; del buf1528  # reuse
        buf1540 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1542 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_0_left_8], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1536, buf1537, buf1538, primals_1135, primals_1136, buf1539, buf1540, buf1542, primals_1135, primals_1136, 432, 28, grid=grid(432), stream=stream0)
        del primals_1135
        del primals_1136
        buf1543 = reinterpret_tensor(buf1534, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1534  # reuse
        buf1544 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_0_right_8], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_102.run(buf1507, buf1543, buf1544, 1524096, grid=grid(1524096), stream=stream0)
        buf1545 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        buf1569 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        buf1570 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_603, x_comb_iter_1_right_8], Original ATen: [aten.max_pool2d_with_indices, aten.relu]
        triton_poi_fused_max_pool2d_with_indices_relu_103.run(buf1518, buf1545, buf1569, buf1570, 1524096, grid=grid(1524096), stream=stream0)
        # Source Nodes: [x_604], Original ATen: [aten.convolution]
        buf1546 = extern_kernels.convolution(buf1545, primals_468, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1546, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1547 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_604], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1546, buf1547, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_606], Original ATen: [aten.convolution]
        buf1548 = extern_kernels.convolution(buf1547, primals_469, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1548, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1549 = reinterpret_tensor(buf1546, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1546  # reuse
        # Source Nodes: [x_606], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1548, buf1549, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1550 = buf1538; del buf1538  # reuse
        buf1551 = buf1537; del buf1537  # reuse
        buf1552 = buf1536; del buf1536  # reuse
        # Source Nodes: [x_607], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1549, buf1550, buf1551, buf1552, 12096, 126, grid=grid(12096), stream=stream0)
        buf1553 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1554 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1556 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_607], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1550, buf1551, buf1552, primals_1138, primals_1139, buf1553, buf1554, buf1556, primals_1138, primals_1139, 432, 28, grid=grid(432), stream=stream0)
        del primals_1138
        del primals_1139
        buf1557 = reinterpret_tensor(buf1548, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1548  # reuse
        # Source Nodes: [x_607, x_608], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1549, buf1553, buf1554, primals_470, primals_471, buf1557, 1524096, grid=grid(1524096), stream=stream0)
        del primals_471
        # Source Nodes: [x_609], Original ATen: [aten.convolution]
        buf1558 = extern_kernels.convolution(buf1557, primals_472, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1558, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1559 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_609], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1558, buf1559, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_611], Original ATen: [aten.convolution]
        buf1560 = extern_kernels.convolution(buf1559, primals_473, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1560, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1561 = reinterpret_tensor(buf1558, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1558  # reuse
        # Source Nodes: [x_611], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1560, buf1561, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1562 = buf1552; del buf1552  # reuse
        buf1563 = buf1551; del buf1551  # reuse
        buf1564 = buf1550; del buf1550  # reuse
        # Source Nodes: [x_comb_iter_1_left_8], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1561, buf1562, buf1563, buf1564, 12096, 126, grid=grid(12096), stream=stream0)
        buf1565 = buf1554; del buf1554  # reuse
        buf1566 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1568 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_1_left_8], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1562, buf1563, buf1564, primals_1141, primals_1142, buf1565, buf1566, buf1568, primals_1141, primals_1142, 432, 28, grid=grid(432), stream=stream0)
        del primals_1141
        del primals_1142
        # Source Nodes: [x_614], Original ATen: [aten.convolution]
        buf1571 = extern_kernels.convolution(buf1545, primals_476, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1571, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1572 = reinterpret_tensor(buf1560, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1560  # reuse
        # Source Nodes: [x_614], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1571, buf1572, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_616], Original ATen: [aten.convolution]
        buf1573 = extern_kernels.convolution(buf1572, primals_477, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1573, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1574 = reinterpret_tensor(buf1571, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1571  # reuse
        # Source Nodes: [x_616], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1573, buf1574, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1575 = buf1564; del buf1564  # reuse
        buf1576 = buf1563; del buf1563  # reuse
        buf1577 = buf1562; del buf1562  # reuse
        # Source Nodes: [x_617], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1574, buf1575, buf1576, buf1577, 12096, 126, grid=grid(12096), stream=stream0)
        buf1578 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1579 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1581 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_617], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1575, buf1576, buf1577, primals_1144, primals_1145, buf1578, buf1579, buf1581, primals_1144, primals_1145, 432, 28, grid=grid(432), stream=stream0)
        del primals_1144
        del primals_1145
        buf1582 = reinterpret_tensor(buf1573, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1573  # reuse
        # Source Nodes: [x_617, x_618], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1574, buf1578, buf1579, primals_478, primals_479, buf1582, 1524096, grid=grid(1524096), stream=stream0)
        del primals_479
        # Source Nodes: [x_619], Original ATen: [aten.convolution]
        buf1583 = extern_kernels.convolution(buf1582, primals_480, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1583, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1584 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_619], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1583, buf1584, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_621], Original ATen: [aten.convolution]
        buf1585 = extern_kernels.convolution(buf1584, primals_481, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1585, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1586 = reinterpret_tensor(buf1583, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1583  # reuse
        # Source Nodes: [x_621], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1585, buf1586, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1587 = buf1577; del buf1577  # reuse
        buf1588 = buf1576; del buf1576  # reuse
        buf1589 = buf1575; del buf1575  # reuse
        # Source Nodes: [x_comb_iter_2_left_8], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1586, buf1587, buf1588, buf1589, 12096, 126, grid=grid(12096), stream=stream0)
        buf1590 = buf1579; del buf1579  # reuse
        buf1591 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1593 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_left_8], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1587, buf1588, buf1589, primals_1147, primals_1148, buf1590, buf1591, buf1593, primals_1147, primals_1148, 432, 28, grid=grid(432), stream=stream0)
        del primals_1147
        del primals_1148
        # Source Nodes: [x_624], Original ATen: [aten.convolution]
        buf1594 = extern_kernels.convolution(buf1545, primals_484, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1594, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1595 = reinterpret_tensor(buf1585, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1585  # reuse
        # Source Nodes: [x_624], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1594, buf1595, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_626], Original ATen: [aten.convolution]
        buf1596 = extern_kernels.convolution(buf1595, primals_485, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1596, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1597 = reinterpret_tensor(buf1594, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1594  # reuse
        # Source Nodes: [x_626], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1596, buf1597, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1598 = buf1589; del buf1589  # reuse
        buf1599 = buf1588; del buf1588  # reuse
        buf1600 = buf1587; del buf1587  # reuse
        # Source Nodes: [x_627], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1597, buf1598, buf1599, buf1600, 12096, 126, grid=grid(12096), stream=stream0)
        buf1601 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1602 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1604 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_627], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1598, buf1599, buf1600, primals_1150, primals_1151, buf1601, buf1602, buf1604, primals_1150, primals_1151, 432, 28, grid=grid(432), stream=stream0)
        del primals_1150
        del primals_1151
        buf1605 = reinterpret_tensor(buf1596, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1596  # reuse
        # Source Nodes: [x_627, x_628], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1597, buf1601, buf1602, primals_486, primals_487, buf1605, 1524096, grid=grid(1524096), stream=stream0)
        del primals_487
        # Source Nodes: [x_629], Original ATen: [aten.convolution]
        buf1606 = extern_kernels.convolution(buf1605, primals_488, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1606, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1607 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_629], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1606, buf1607, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_631], Original ATen: [aten.convolution]
        buf1608 = extern_kernels.convolution(buf1607, primals_489, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1608, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1609 = reinterpret_tensor(buf1606, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1606  # reuse
        # Source Nodes: [x_631], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1608, buf1609, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1610 = buf1600; del buf1600  # reuse
        buf1611 = buf1599; del buf1599  # reuse
        buf1612 = buf1598; del buf1598  # reuse
        # Source Nodes: [x_comb_iter_2_right_8], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1609, buf1610, buf1611, buf1612, 12096, 126, grid=grid(12096), stream=stream0)
        buf1613 = buf1602; del buf1602  # reuse
        buf1614 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1616 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_right_8], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1610, buf1611, buf1612, primals_1153, primals_1154, buf1613, buf1614, buf1616, primals_1153, primals_1154, 432, 28, grid=grid(432), stream=stream0)
        del primals_1153
        del primals_1154
        buf1617 = reinterpret_tensor(buf1669, (8, 432, 21, 21), (952560, 441, 21, 1), 381024)  # alias
        # Source Nodes: [x_comb_iter_2_left_8, x_comb_iter_2_right_8, x_comb_iter_42], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_90.run(buf1586, buf1590, buf1591, primals_482, primals_483, buf1609, buf1613, buf1614, primals_490, primals_491, buf1617, 3528, 432, grid=grid(3528, 432), stream=stream0)
        del primals_483
        del primals_491
        buf1618 = reinterpret_tensor(buf1608, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1608  # reuse
        # Source Nodes: [x_633], Original ATen: [aten.relu]
        triton_poi_fused_relu_91.run(buf1617, buf1618, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_634], Original ATen: [aten.convolution]
        buf1619 = extern_kernels.convolution(buf1618, primals_492, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1619, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1620 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_634], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1619, buf1620, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_636], Original ATen: [aten.convolution]
        buf1621 = extern_kernels.convolution(buf1620, primals_493, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1621, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1622 = reinterpret_tensor(buf1619, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1619  # reuse
        # Source Nodes: [x_636], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1621, buf1622, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1623 = buf1612; del buf1612  # reuse
        buf1624 = buf1611; del buf1611  # reuse
        buf1625 = buf1610; del buf1610  # reuse
        # Source Nodes: [x_637], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1622, buf1623, buf1624, buf1625, 12096, 126, grid=grid(12096), stream=stream0)
        buf1626 = buf1614; del buf1614  # reuse
        buf1627 = buf1591; del buf1591  # reuse
        buf1629 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_637], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1623, buf1624, buf1625, primals_1156, primals_1157, buf1626, buf1627, buf1629, primals_1156, primals_1157, 432, 28, grid=grid(432), stream=stream0)
        del primals_1156
        del primals_1157
        buf1630 = reinterpret_tensor(buf1621, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1621  # reuse
        # Source Nodes: [x_637, x_638], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1622, buf1626, buf1627, primals_494, primals_495, buf1630, 1524096, grid=grid(1524096), stream=stream0)
        del primals_495
        # Source Nodes: [x_639], Original ATen: [aten.convolution]
        buf1631 = extern_kernels.convolution(buf1630, primals_496, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1631, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1632 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_639], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1631, buf1632, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_641], Original ATen: [aten.convolution]
        buf1633 = extern_kernels.convolution(buf1632, primals_497, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1633, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1634 = reinterpret_tensor(buf1631, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1631  # reuse
        # Source Nodes: [x_641], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1633, buf1634, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1635 = buf1625; del buf1625  # reuse
        buf1636 = buf1624; del buf1624  # reuse
        buf1637 = buf1623; del buf1623  # reuse
        # Source Nodes: [x_comb_iter_3_left_8], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1634, buf1635, buf1636, buf1637, 12096, 126, grid=grid(12096), stream=stream0)
        buf1638 = buf1627; del buf1627  # reuse
        buf1639 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1641 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_3_left_8], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1635, buf1636, buf1637, primals_1159, primals_1160, buf1638, buf1639, buf1641, primals_1159, primals_1160, 432, 28, grid=grid(432), stream=stream0)
        del primals_1159
        del primals_1160
        buf1665 = reinterpret_tensor(buf1669, (8, 432, 21, 21), (952560, 441, 21, 1), 0)  # alias
        # Source Nodes: [x_comb_iter_0_left_8, x_comb_iter_40], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_104.run(buf1535, buf1539, buf1540, primals_466, primals_467, buf1543, buf1665, 3456, 441, grid=grid(3456, 441), stream=stream0)
        del primals_467
        buf1666 = reinterpret_tensor(buf1669, (8, 432, 21, 21), (952560, 441, 21, 1), 190512)  # alias
        buf1667 = reinterpret_tensor(buf1669, (8, 432, 21, 21), (952560, 441, 21, 1), 571536)  # alias
        # Source Nodes: [x_comb_iter_1_left_8, x_comb_iter_3_left_8, x_comb_iter_41, x_comb_iter_43], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_105.run(buf1561, buf1565, buf1566, primals_474, primals_475, buf1569, buf1634, buf1638, buf1639, primals_498, primals_499, buf1666, buf1667, 3456, 441, grid=grid(3456, 441), stream=stream0)
        del primals_475
        del primals_499
        del buf1617
        del buf1665
        del buf1666
        del buf1667
        del buf1668
        # Source Nodes: [x_654], Original ATen: [aten.convolution]
        buf1670 = extern_kernels.convolution(buf1508, primals_508, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1670, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1671 = buf1569; del buf1569  # reuse
        # Source Nodes: [x_654], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1670, buf1671, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1672 = buf1637; del buf1637  # reuse
        buf1673 = buf1636; del buf1636  # reuse
        buf1674 = buf1635; del buf1635  # reuse
        # Source Nodes: [x_left_8], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1671, buf1672, buf1673, buf1674, 12096, 126, grid=grid(12096), stream=stream0)
        buf1675 = buf1639; del buf1639  # reuse
        buf1676 = buf1566; del buf1566  # reuse
        buf1678 = reinterpret_tensor(buf1540, (432, ), (1, ), 0); del buf1540  # reuse
        # Source Nodes: [x_left_8], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1672, buf1673, buf1674, primals_1168, primals_1169, buf1675, buf1676, buf1678, primals_1168, primals_1169, 432, 28, grid=grid(432), stream=stream0)
        del primals_1168
        del primals_1169
        buf1679 = reinterpret_tensor(buf1670, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1670  # reuse
        buf1691 = buf1543; del buf1543  # reuse
        # Source Nodes: [x_659, x_left_8], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_99.run(buf1671, buf1675, buf1676, primals_509, primals_510, buf1679, buf1691, 1524096, grid=grid(1524096), stream=stream0)
        del primals_510
        buf1680 = empty_strided((8, 2160, 21, 21), (952560, 1, 45360, 2160), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_656], Original ATen: [aten.relu]
        triton_poi_fused_relu_100.run(buf1669, buf1680, 17280, 441, grid=grid(17280, 441), stream=stream0)
        # Source Nodes: [x_657], Original ATen: [aten.convolution]
        buf1681 = extern_kernels.convolution(buf1680, primals_511, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1681, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1682 = reinterpret_tensor(buf1633, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1633  # reuse
        # Source Nodes: [x_657], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1681, buf1682, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1683 = buf1674; del buf1674  # reuse
        buf1684 = buf1673; del buf1673  # reuse
        buf1685 = buf1672; del buf1672  # reuse
        # Source Nodes: [x_comb_iter_4_right_9], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1682, buf1683, buf1684, buf1685, 12096, 126, grid=grid(12096), stream=stream0)
        buf1686 = buf1676; del buf1676  # reuse
        buf1687 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1689 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_right_9], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1683, buf1684, buf1685, primals_1171, primals_1172, buf1686, buf1687, buf1689, primals_1171, primals_1172, 432, 28, grid=grid(432), stream=stream0)
        del primals_1171
        del primals_1172
        # Source Nodes: [x_710], Original ATen: [aten.convolution]
        buf1814 = extern_kernels.convolution(buf1691, primals_554, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1814, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1815 = reinterpret_tensor(buf1681, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1681  # reuse
        # Source Nodes: [x_710], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1814, buf1815, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_712], Original ATen: [aten.convolution]
        buf1816 = extern_kernels.convolution(buf1815, primals_555, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1816, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1817 = reinterpret_tensor(buf1814, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1814  # reuse
        # Source Nodes: [x_712], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1816, buf1817, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1818 = buf1685; del buf1685  # reuse
        buf1819 = buf1684; del buf1684  # reuse
        buf1820 = buf1683; del buf1683  # reuse
        # Source Nodes: [x_713], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1817, buf1818, buf1819, buf1820, 12096, 126, grid=grid(12096), stream=stream0)
        buf1821 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1822 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1824 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_713], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1818, buf1819, buf1820, primals_1204, primals_1205, buf1821, buf1822, buf1824, primals_1204, primals_1205, 432, 28, grid=grid(432), stream=stream0)
        del primals_1204
        del primals_1205
        buf1825 = reinterpret_tensor(buf1816, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1816  # reuse
        # Source Nodes: [x_713, x_714], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1817, buf1821, buf1822, primals_556, primals_557, buf1825, 1524096, grid=grid(1524096), stream=stream0)
        del primals_557
        # Source Nodes: [x_715], Original ATen: [aten.convolution]
        buf1826 = extern_kernels.convolution(buf1825, primals_558, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1826, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1827 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_715], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1826, buf1827, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_717], Original ATen: [aten.convolution]
        buf1828 = extern_kernels.convolution(buf1827, primals_559, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1828, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1829 = reinterpret_tensor(buf1826, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1826  # reuse
        # Source Nodes: [x_717], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1828, buf1829, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1830 = buf1820; del buf1820  # reuse
        buf1831 = buf1819; del buf1819  # reuse
        buf1832 = buf1818; del buf1818  # reuse
        # Source Nodes: [x_comb_iter_4_left_9], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1829, buf1830, buf1831, buf1832, 12096, 126, grid=grid(12096), stream=stream0)
        buf1833 = buf1822; del buf1822  # reuse
        buf1834 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1836 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_left_9], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1830, buf1831, buf1832, primals_1207, primals_1208, buf1833, buf1834, buf1836, primals_1207, primals_1208, 432, 28, grid=grid(432), stream=stream0)
        del primals_1207
        del primals_1208
        buf1690 = reinterpret_tensor(buf1828, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1828  # reuse
        buf1841 = buf1669; del buf1669  # reuse
        buf1840 = reinterpret_tensor(buf1841, (8, 432, 21, 21), (952560, 441, 21, 1), 762048)  # alias
        # Source Nodes: [x_comb_iter_49, x_comb_iter_4_left_9, x_comb_iter_4_right_9], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_101.run(buf1682, buf1686, buf1687, primals_512, primals_513, buf1829, buf1833, buf1834, primals_560, primals_561, buf1690, buf1840, 3528, 432, grid=grid(3528, 432), stream=stream0)
        del primals_513
        del primals_561
        # Source Nodes: [x_660], Original ATen: [aten.convolution]
        buf1692 = extern_kernels.convolution(buf1691, primals_514, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1692, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1693 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_660], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1692, buf1693, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_662], Original ATen: [aten.convolution]
        buf1694 = extern_kernels.convolution(buf1693, primals_515, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1694, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1695 = reinterpret_tensor(buf1692, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1692  # reuse
        # Source Nodes: [x_662], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1694, buf1695, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1696 = buf1832; del buf1832  # reuse
        buf1697 = buf1831; del buf1831  # reuse
        buf1698 = buf1830; del buf1830  # reuse
        # Source Nodes: [x_663], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1695, buf1696, buf1697, buf1698, 12096, 126, grid=grid(12096), stream=stream0)
        buf1699 = buf1834; del buf1834  # reuse
        buf1700 = buf1687; del buf1687  # reuse
        buf1702 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_663], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1696, buf1697, buf1698, primals_1174, primals_1175, buf1699, buf1700, buf1702, primals_1174, primals_1175, 432, 28, grid=grid(432), stream=stream0)
        del primals_1174
        del primals_1175
        buf1703 = reinterpret_tensor(buf1694, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1694  # reuse
        # Source Nodes: [x_663, x_664], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1695, buf1699, buf1700, primals_516, primals_517, buf1703, 1524096, grid=grid(1524096), stream=stream0)
        del primals_517
        # Source Nodes: [x_665], Original ATen: [aten.convolution]
        buf1704 = extern_kernels.convolution(buf1703, primals_518, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1704, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1705 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_665], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1704, buf1705, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_667], Original ATen: [aten.convolution]
        buf1706 = extern_kernels.convolution(buf1705, primals_519, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1706, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1707 = reinterpret_tensor(buf1704, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1704  # reuse
        # Source Nodes: [x_667], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1706, buf1707, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1708 = buf1698; del buf1698  # reuse
        buf1709 = buf1697; del buf1697  # reuse
        buf1710 = buf1696; del buf1696  # reuse
        # Source Nodes: [x_comb_iter_0_left_9], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1707, buf1708, buf1709, buf1710, 12096, 126, grid=grid(12096), stream=stream0)
        buf1711 = buf1700; del buf1700  # reuse
        buf1712 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1714 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_0_left_9], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1708, buf1709, buf1710, primals_1177, primals_1178, buf1711, buf1712, buf1714, primals_1177, primals_1178, 432, 28, grid=grid(432), stream=stream0)
        del primals_1177
        del primals_1178
        buf1715 = reinterpret_tensor(buf1706, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1706  # reuse
        buf1716 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_0_right_9], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_102.run(buf1679, buf1715, buf1716, 1524096, grid=grid(1524096), stream=stream0)
        buf1717 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        buf1741 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        buf1742 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_669, x_comb_iter_1_right_9], Original ATen: [aten.max_pool2d_with_indices, aten.relu]
        triton_poi_fused_max_pool2d_with_indices_relu_103.run(buf1690, buf1717, buf1741, buf1742, 1524096, grid=grid(1524096), stream=stream0)
        # Source Nodes: [x_670], Original ATen: [aten.convolution]
        buf1718 = extern_kernels.convolution(buf1717, primals_522, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1718, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1719 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_670], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1718, buf1719, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_672], Original ATen: [aten.convolution]
        buf1720 = extern_kernels.convolution(buf1719, primals_523, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1720, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1721 = reinterpret_tensor(buf1718, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1718  # reuse
        # Source Nodes: [x_672], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1720, buf1721, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1722 = buf1710; del buf1710  # reuse
        buf1723 = buf1709; del buf1709  # reuse
        buf1724 = buf1708; del buf1708  # reuse
        # Source Nodes: [x_673], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1721, buf1722, buf1723, buf1724, 12096, 126, grid=grid(12096), stream=stream0)
        buf1725 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1726 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1728 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_673], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1722, buf1723, buf1724, primals_1180, primals_1181, buf1725, buf1726, buf1728, primals_1180, primals_1181, 432, 28, grid=grid(432), stream=stream0)
        del primals_1180
        del primals_1181
        buf1729 = reinterpret_tensor(buf1720, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1720  # reuse
        # Source Nodes: [x_673, x_674], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1721, buf1725, buf1726, primals_524, primals_525, buf1729, 1524096, grid=grid(1524096), stream=stream0)
        del primals_525
        # Source Nodes: [x_675], Original ATen: [aten.convolution]
        buf1730 = extern_kernels.convolution(buf1729, primals_526, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1730, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1731 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_675], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1730, buf1731, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_677], Original ATen: [aten.convolution]
        buf1732 = extern_kernels.convolution(buf1731, primals_527, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1732, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1733 = reinterpret_tensor(buf1730, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1730  # reuse
        # Source Nodes: [x_677], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1732, buf1733, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1734 = buf1724; del buf1724  # reuse
        buf1735 = buf1723; del buf1723  # reuse
        buf1736 = buf1722; del buf1722  # reuse
        # Source Nodes: [x_comb_iter_1_left_9], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1733, buf1734, buf1735, buf1736, 12096, 126, grid=grid(12096), stream=stream0)
        buf1737 = buf1726; del buf1726  # reuse
        buf1738 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1740 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_1_left_9], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1734, buf1735, buf1736, primals_1183, primals_1184, buf1737, buf1738, buf1740, primals_1183, primals_1184, 432, 28, grid=grid(432), stream=stream0)
        del primals_1183
        del primals_1184
        # Source Nodes: [x_680], Original ATen: [aten.convolution]
        buf1743 = extern_kernels.convolution(buf1717, primals_530, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1743, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1744 = reinterpret_tensor(buf1732, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1732  # reuse
        # Source Nodes: [x_680], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1743, buf1744, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_682], Original ATen: [aten.convolution]
        buf1745 = extern_kernels.convolution(buf1744, primals_531, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1745, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1746 = reinterpret_tensor(buf1743, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1743  # reuse
        # Source Nodes: [x_682], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1745, buf1746, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1747 = buf1736; del buf1736  # reuse
        buf1748 = buf1735; del buf1735  # reuse
        buf1749 = buf1734; del buf1734  # reuse
        # Source Nodes: [x_683], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1746, buf1747, buf1748, buf1749, 12096, 126, grid=grid(12096), stream=stream0)
        buf1750 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1751 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1753 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_683], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1747, buf1748, buf1749, primals_1186, primals_1187, buf1750, buf1751, buf1753, primals_1186, primals_1187, 432, 28, grid=grid(432), stream=stream0)
        del primals_1186
        del primals_1187
        buf1754 = reinterpret_tensor(buf1745, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1745  # reuse
        # Source Nodes: [x_683, x_684], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1746, buf1750, buf1751, primals_532, primals_533, buf1754, 1524096, grid=grid(1524096), stream=stream0)
        del primals_533
        # Source Nodes: [x_685], Original ATen: [aten.convolution]
        buf1755 = extern_kernels.convolution(buf1754, primals_534, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1755, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1756 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_685], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1755, buf1756, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_687], Original ATen: [aten.convolution]
        buf1757 = extern_kernels.convolution(buf1756, primals_535, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1757, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1758 = reinterpret_tensor(buf1755, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1755  # reuse
        # Source Nodes: [x_687], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1757, buf1758, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1759 = buf1749; del buf1749  # reuse
        buf1760 = buf1748; del buf1748  # reuse
        buf1761 = buf1747; del buf1747  # reuse
        # Source Nodes: [x_comb_iter_2_left_9], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1758, buf1759, buf1760, buf1761, 12096, 126, grid=grid(12096), stream=stream0)
        buf1762 = buf1751; del buf1751  # reuse
        buf1763 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1765 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_left_9], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1759, buf1760, buf1761, primals_1189, primals_1190, buf1762, buf1763, buf1765, primals_1189, primals_1190, 432, 28, grid=grid(432), stream=stream0)
        del primals_1189
        del primals_1190
        # Source Nodes: [x_690], Original ATen: [aten.convolution]
        buf1766 = extern_kernels.convolution(buf1717, primals_538, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1766, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1767 = reinterpret_tensor(buf1757, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1757  # reuse
        # Source Nodes: [x_690], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1766, buf1767, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_692], Original ATen: [aten.convolution]
        buf1768 = extern_kernels.convolution(buf1767, primals_539, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1768, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1769 = reinterpret_tensor(buf1766, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1766  # reuse
        # Source Nodes: [x_692], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1768, buf1769, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1770 = buf1761; del buf1761  # reuse
        buf1771 = buf1760; del buf1760  # reuse
        buf1772 = buf1759; del buf1759  # reuse
        # Source Nodes: [x_693], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1769, buf1770, buf1771, buf1772, 12096, 126, grid=grid(12096), stream=stream0)
        buf1773 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1774 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1776 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_693], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1770, buf1771, buf1772, primals_1192, primals_1193, buf1773, buf1774, buf1776, primals_1192, primals_1193, 432, 28, grid=grid(432), stream=stream0)
        del primals_1192
        del primals_1193
        buf1777 = reinterpret_tensor(buf1768, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1768  # reuse
        # Source Nodes: [x_693, x_694], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1769, buf1773, buf1774, primals_540, primals_541, buf1777, 1524096, grid=grid(1524096), stream=stream0)
        del primals_541
        # Source Nodes: [x_695], Original ATen: [aten.convolution]
        buf1778 = extern_kernels.convolution(buf1777, primals_542, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1778, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1779 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_695], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1778, buf1779, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_697], Original ATen: [aten.convolution]
        buf1780 = extern_kernels.convolution(buf1779, primals_543, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1780, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1781 = reinterpret_tensor(buf1778, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1778  # reuse
        # Source Nodes: [x_697], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1780, buf1781, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1782 = buf1772; del buf1772  # reuse
        buf1783 = buf1771; del buf1771  # reuse
        buf1784 = buf1770; del buf1770  # reuse
        # Source Nodes: [x_comb_iter_2_right_9], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1781, buf1782, buf1783, buf1784, 12096, 126, grid=grid(12096), stream=stream0)
        buf1785 = buf1774; del buf1774  # reuse
        buf1786 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1788 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_right_9], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1782, buf1783, buf1784, primals_1195, primals_1196, buf1785, buf1786, buf1788, primals_1195, primals_1196, 432, 28, grid=grid(432), stream=stream0)
        del primals_1195
        del primals_1196
        buf1789 = reinterpret_tensor(buf1841, (8, 432, 21, 21), (952560, 441, 21, 1), 381024)  # alias
        # Source Nodes: [x_comb_iter_2_left_9, x_comb_iter_2_right_9, x_comb_iter_47], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_90.run(buf1758, buf1762, buf1763, primals_536, primals_537, buf1781, buf1785, buf1786, primals_544, primals_545, buf1789, 3528, 432, grid=grid(3528, 432), stream=stream0)
        del primals_537
        del primals_545
        buf1790 = reinterpret_tensor(buf1780, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1780  # reuse
        # Source Nodes: [x_699], Original ATen: [aten.relu]
        triton_poi_fused_relu_91.run(buf1789, buf1790, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_700], Original ATen: [aten.convolution]
        buf1791 = extern_kernels.convolution(buf1790, primals_546, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1791, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1792 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_700], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1791, buf1792, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_702], Original ATen: [aten.convolution]
        buf1793 = extern_kernels.convolution(buf1792, primals_547, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1793, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1794 = reinterpret_tensor(buf1791, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1791  # reuse
        # Source Nodes: [x_702], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1793, buf1794, 3456, 441, grid=grid(3456, 441), stream=stream0)
        buf1795 = buf1784; del buf1784  # reuse
        buf1796 = buf1783; del buf1783  # reuse
        buf1797 = buf1782; del buf1782  # reuse
        # Source Nodes: [x_703], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1794, buf1795, buf1796, buf1797, 12096, 126, grid=grid(12096), stream=stream0)
        buf1798 = buf1786; del buf1786  # reuse
        buf1799 = buf1763; del buf1763  # reuse
        buf1801 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_703], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1795, buf1796, buf1797, primals_1198, primals_1199, buf1798, buf1799, buf1801, primals_1198, primals_1199, 432, 28, grid=grid(432), stream=stream0)
        del primals_1198
        del primals_1199
        buf1802 = reinterpret_tensor(buf1793, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1793  # reuse
        # Source Nodes: [x_703, x_704], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_84.run(buf1794, buf1798, buf1799, primals_548, primals_549, buf1802, 1524096, grid=grid(1524096), stream=stream0)
        del primals_549
        # Source Nodes: [x_705], Original ATen: [aten.convolution]
        buf1803 = extern_kernels.convolution(buf1802, primals_550, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=432, bias=None)
        assert_size_stride(buf1803, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1804 = empty_strided((8, 432, 21, 21), (190512, 1, 9072, 432), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_705], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1803, buf1804, 3456, 441, grid=grid(3456, 441), stream=stream0)
        # Source Nodes: [x_707], Original ATen: [aten.convolution]
        buf1805 = extern_kernels.convolution(buf1804, primals_551, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1805, (8, 432, 21, 21), (190512, 441, 21, 1))
        buf1806 = reinterpret_tensor(buf1803, (8, 432, 21, 21), (190512, 1, 9072, 432), 0); del buf1803  # reuse
        # Source Nodes: [x_707], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_81.run(buf1805, buf1806, 3456, 441, grid=grid(3456, 441), stream=stream0)
        del buf1805
        buf1807 = buf1797; del buf1797  # reuse
        buf1808 = buf1796; del buf1796  # reuse
        buf1809 = buf1795; del buf1795  # reuse
        # Source Nodes: [x_comb_iter_3_left_9], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_82.run(buf1806, buf1807, buf1808, buf1809, 12096, 126, grid=grid(12096), stream=stream0)
        buf1810 = buf1799; del buf1799  # reuse
        buf1811 = empty_strided((1, 432, 1, 1), (432, 1, 432, 432), device='cuda', dtype=torch.float32)
        buf1813 = empty((432, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_3_left_9], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_83.run(buf1807, buf1808, buf1809, primals_1201, primals_1202, buf1810, buf1811, buf1813, primals_1201, primals_1202, 432, 28, grid=grid(432), stream=stream0)
        del buf1807
        del buf1808
        del buf1809
        del primals_1201
        del primals_1202
        buf1837 = reinterpret_tensor(buf1841, (8, 432, 21, 21), (952560, 441, 21, 1), 0)  # alias
        # Source Nodes: [x_comb_iter_0_left_9, x_comb_iter_45], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_104.run(buf1707, buf1711, buf1712, primals_520, primals_521, buf1715, buf1837, 3456, 441, grid=grid(3456, 441), stream=stream0)
        del buf1712
        del buf1715
        del primals_521
        buf1838 = reinterpret_tensor(buf1841, (8, 432, 21, 21), (952560, 441, 21, 1), 190512)  # alias
        buf1839 = reinterpret_tensor(buf1841, (8, 432, 21, 21), (952560, 441, 21, 1), 571536)  # alias
        # Source Nodes: [x_comb_iter_1_left_9, x_comb_iter_3_left_9, x_comb_iter_46, x_comb_iter_48], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_105.run(buf1733, buf1737, buf1738, primals_528, primals_529, buf1741, buf1806, buf1810, buf1811, primals_552, primals_553, buf1838, buf1839, 3456, 441, grid=grid(3456, 441), stream=stream0)
        del buf1738
        del buf1741
        del buf1811
        del primals_529
        del primals_553
        del buf1789
        del buf1837
        del buf1838
        del buf1839
        del buf1840
        # Source Nodes: [x_720], Original ATen: [aten.convolution]
        buf1842 = extern_kernels.convolution(buf1680, primals_562, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1842, (8, 864, 21, 21), (381024, 441, 21, 1))
        buf1843 = reinterpret_tensor(buf1034, (8, 864, 21, 21), (381024, 1, 18144, 864), 0); del buf1034  # reuse
        # Source Nodes: [x_720], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_106.run(buf1842, buf1843, 6912, 441, grid=grid(6912, 441), stream=stream0)
        buf1844 = empty_strided((1, 864, 1, 1, 28), (24192, 1, 24192, 24192, 864), device='cuda', dtype=torch.float32)
        buf1845 = empty_strided((1, 864, 1, 1, 28), (24192, 1, 24192, 24192, 864), device='cuda', dtype=torch.float32)
        buf1846 = empty_strided((1, 864, 1, 1, 28), (24192, 1, 24192, 24192, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_left_9], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_107.run(buf1843, buf1844, buf1845, buf1846, 24192, 126, grid=grid(24192), stream=stream0)
        buf1847 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf1848 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf1850 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_left_9], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_108.run(buf1844, buf1845, buf1846, primals_1210, primals_1211, buf1847, buf1848, buf1850, primals_1210, primals_1211, 864, 28, grid=grid(864), stream=stream0)
        del primals_1210
        del primals_1211
        buf1851 = reinterpret_tensor(buf1842, (8, 864, 21, 21), (381024, 1, 18144, 864), 0); del buf1842  # reuse
        buf2554 = empty_strided((8, 864, 21, 21), (381024, 1, 18144, 864), device='cuda', dtype=torch.bool)
        # Source Nodes: [x_725, x_left_9], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu, aten.threshold_backward]
        triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_109.run(buf1843, buf1847, buf1848, primals_563, primals_564, buf1851, buf2554, 3048192, grid=grid(3048192), stream=stream0)
        del primals_564
        buf1852 = empty_strided((8, 2160, 21, 21), (952560, 1, 45360, 2160), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_722], Original ATen: [aten.relu]
        triton_poi_fused_relu_100.run(buf1841, buf1852, 17280, 441, grid=grid(17280, 441), stream=stream0)
        # Source Nodes: [x_723], Original ATen: [aten.convolution]
        buf1853 = extern_kernels.convolution(buf1852, primals_565, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1853, (8, 864, 21, 21), (381024, 441, 21, 1))
        buf1854 = reinterpret_tensor(buf1008, (8, 864, 21, 21), (381024, 1, 18144, 864), 0); del buf1008  # reuse
        # Source Nodes: [x_723], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_106.run(buf1853, buf1854, 6912, 441, grid=grid(6912, 441), stream=stream0)
        buf1855 = buf1846; del buf1846  # reuse
        buf1856 = buf1845; del buf1845  # reuse
        buf1857 = buf1844; del buf1844  # reuse
        # Source Nodes: [x_right_10], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_107.run(buf1854, buf1855, buf1856, buf1857, 24192, 126, grid=grid(24192), stream=stream0)
        buf1858 = buf1848; del buf1848  # reuse
        buf1859 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf1861 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_right_10], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_108.run(buf1855, buf1856, buf1857, primals_1213, primals_1214, buf1858, buf1859, buf1861, primals_1213, primals_1214, 864, 28, grid=grid(864), stream=stream0)
        del buf1855
        del buf1856
        del buf1857
        del primals_1213
        del primals_1214
        buf1862 = reinterpret_tensor(buf1853, (8, 864, 21, 21), (381024, 1, 18144, 864), 0); del buf1853  # reuse
        buf1890 = reinterpret_tensor(buf1098, (8, 864, 21, 21), (381024, 1, 18144, 864), 0); del buf1098  # reuse
        buf2553 = empty_strided((8, 864, 21, 21), (381024, 1, 18144, 864), device='cuda', dtype=torch.bool)
        # Source Nodes: [x_739, x_right_10], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu, aten.threshold_backward]
        triton_poi_fused__native_batch_norm_legit_functional_relu_threshold_backward_110.run(buf1854, buf1858, buf1859, primals_566, primals_567, buf1862, buf1890, buf2553, 3048192, grid=grid(3048192), stream=stream0)
        del primals_567
        buf1863 = empty_strided((8, 864, 25, 25), (540000, 1, 21600, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_725, x_727], Original ATen: [aten.constant_pad_nd, aten.relu]
        triton_poi_fused_constant_pad_nd_relu_111.run(buf1851, buf1863, 4320000, grid=grid(4320000), stream=stream0)
        # Source Nodes: [x_728], Original ATen: [aten.convolution]
        buf1864 = extern_kernels.convolution(buf1863, primals_21, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf1864, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1865 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_728], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf1864, buf1865, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_730], Original ATen: [aten.convolution]
        buf1866 = extern_kernels.convolution(buf1865, primals_568, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1866, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1867 = reinterpret_tensor(buf1864, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1864  # reuse
        buf1868 = empty_strided((1, 864, 1, 1, 8), (6912, 1, 6912, 6912, 864), device='cuda', dtype=torch.float32)
        buf1869 = empty_strided((1, 864, 1, 1, 8), (6912, 1, 6912, 6912, 864), device='cuda', dtype=torch.float32)
        buf1870 = empty_strided((1, 864, 1, 1, 8), (6912, 1, 6912, 6912, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_730, x_731], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf1866, buf1867, buf1868, buf1869, buf1870, 6912, 121, grid=grid(6912), stream=stream0)
        buf1871 = buf1859; del buf1859  # reuse
        buf1872 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf1874 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_731], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf1868, buf1869, buf1870, primals_1216, primals_1217, buf1871, buf1872, buf1874, primals_1216, primals_1217, 864, 8, grid=grid(864), stream=stream0)
        del primals_1216
        del primals_1217
        buf1875 = reinterpret_tensor(buf1866, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1866  # reuse
        # Source Nodes: [x_731, x_732], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf1867, buf1871, buf1872, primals_569, primals_570, buf1875, 836352, grid=grid(836352), stream=stream0)
        del primals_570
        # Source Nodes: [x_733], Original ATen: [aten.convolution]
        buf1876 = extern_kernels.convolution(buf1875, primals_571, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf1876, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1877 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_733], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf1876, buf1877, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_735], Original ATen: [aten.convolution]
        buf1878 = extern_kernels.convolution(buf1877, primals_572, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1878, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1879 = reinterpret_tensor(buf1876, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1876  # reuse
        buf1880 = buf1870; del buf1870  # reuse
        buf1881 = buf1869; del buf1869  # reuse
        buf1882 = buf1868; del buf1868  # reuse
        # Source Nodes: [x_735, x_comb_iter_0_left_10], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf1878, buf1879, buf1880, buf1881, buf1882, 6912, 121, grid=grid(6912), stream=stream0)
        buf1883 = buf1872; del buf1872  # reuse
        buf1884 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf1886 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_0_left_10], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf1880, buf1881, buf1882, primals_1219, primals_1220, buf1883, buf1884, buf1886, primals_1219, primals_1220, 864, 8, grid=grid(864), stream=stream0)
        del primals_1219
        del primals_1220
        buf1887 = empty_strided((8, 864, 23, 23), (457056, 1, 19872, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_738], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_116.run(buf1851, buf1887, 3656448, grid=grid(3656448), stream=stream0)
        buf1888 = reinterpret_tensor(buf1878, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1878  # reuse
        buf1889 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_0_right_10], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_117.run(buf1887, buf1888, buf1889, 6912, 121, grid=grid(6912, 121), stream=stream0)
        buf1891 = empty_strided((8, 864, 27, 27), (629856, 1, 23328, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_741], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_118.run(buf1890, buf1891, 5038848, grid=grid(5038848), stream=stream0)
        # Source Nodes: [x_742], Original ATen: [aten.convolution]
        buf1892 = extern_kernels.convolution(buf1891, primals_22, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf1892, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1893 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_742], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf1892, buf1893, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_744], Original ATen: [aten.convolution]
        buf1894 = extern_kernels.convolution(buf1893, primals_575, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1894, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1895 = reinterpret_tensor(buf1892, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1892  # reuse
        buf1896 = buf1882; del buf1882  # reuse
        buf1897 = buf1881; del buf1881  # reuse
        buf1898 = buf1880; del buf1880  # reuse
        # Source Nodes: [x_744, x_745], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf1894, buf1895, buf1896, buf1897, buf1898, 6912, 121, grid=grid(6912), stream=stream0)
        buf1899 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf1900 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf1902 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_745], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf1896, buf1897, buf1898, primals_1222, primals_1223, buf1899, buf1900, buf1902, primals_1222, primals_1223, 864, 8, grid=grid(864), stream=stream0)
        del primals_1222
        del primals_1223
        buf1903 = reinterpret_tensor(buf1894, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1894  # reuse
        # Source Nodes: [x_745, x_746], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf1895, buf1899, buf1900, primals_576, primals_577, buf1903, 836352, grid=grid(836352), stream=stream0)
        del primals_577
        # Source Nodes: [x_747], Original ATen: [aten.convolution]
        buf1904 = extern_kernels.convolution(buf1903, primals_578, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf1904, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1905 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_747], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf1904, buf1905, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_749], Original ATen: [aten.convolution]
        buf1906 = extern_kernels.convolution(buf1905, primals_579, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1906, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1907 = reinterpret_tensor(buf1904, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1904  # reuse
        buf1908 = buf1898; del buf1898  # reuse
        buf1909 = buf1897; del buf1897  # reuse
        buf1910 = buf1896; del buf1896  # reuse
        # Source Nodes: [x_749, x_comb_iter_1_left_10], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf1906, buf1907, buf1908, buf1909, buf1910, 6912, 121, grid=grid(6912), stream=stream0)
        buf1911 = buf1900; del buf1900  # reuse
        buf1912 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf1914 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_1_left_10], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf1908, buf1909, buf1910, primals_1225, primals_1226, buf1911, buf1912, buf1914, primals_1225, primals_1226, 864, 8, grid=grid(864), stream=stream0)
        del primals_1225
        del primals_1226
        buf1915 = empty_strided((8, 864, 23, 23), (457056, 1, 19872, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_752], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_116.run(buf1862, buf1915, 3656448, grid=grid(3656448), stream=stream0)
        del buf1862
        buf1916 = reinterpret_tensor(buf1906, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1906  # reuse
        buf1917 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_1_right_10], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_117.run(buf1915, buf1916, buf1917, 6912, 121, grid=grid(6912, 121), stream=stream0)
        buf1918 = empty_strided((8, 864, 25, 25), (540000, 1, 21600, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_755], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_119.run(buf1890, buf1918, 4320000, grid=grid(4320000), stream=stream0)
        # Source Nodes: [x_756], Original ATen: [aten.convolution]
        buf1919 = extern_kernels.convolution(buf1918, primals_23, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf1919, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1920 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_756], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf1919, buf1920, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_758], Original ATen: [aten.convolution]
        buf1921 = extern_kernels.convolution(buf1920, primals_582, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1921, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1922 = reinterpret_tensor(buf1919, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1919  # reuse
        buf1923 = buf1910; del buf1910  # reuse
        buf1924 = buf1909; del buf1909  # reuse
        buf1925 = buf1908; del buf1908  # reuse
        # Source Nodes: [x_758, x_759], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf1921, buf1922, buf1923, buf1924, buf1925, 6912, 121, grid=grid(6912), stream=stream0)
        buf1926 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf1927 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf1929 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_759], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf1923, buf1924, buf1925, primals_1228, primals_1229, buf1926, buf1927, buf1929, primals_1228, primals_1229, 864, 8, grid=grid(864), stream=stream0)
        del primals_1228
        del primals_1229
        buf1930 = reinterpret_tensor(buf1921, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1921  # reuse
        # Source Nodes: [x_759, x_760], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf1922, buf1926, buf1927, primals_583, primals_584, buf1930, 836352, grid=grid(836352), stream=stream0)
        del primals_584
        # Source Nodes: [x_761], Original ATen: [aten.convolution]
        buf1931 = extern_kernels.convolution(buf1930, primals_585, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf1931, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1932 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_761], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf1931, buf1932, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_763], Original ATen: [aten.convolution]
        buf1933 = extern_kernels.convolution(buf1932, primals_586, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1933, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1934 = reinterpret_tensor(buf1931, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1931  # reuse
        buf1935 = buf1925; del buf1925  # reuse
        buf1936 = buf1924; del buf1924  # reuse
        buf1937 = buf1923; del buf1923  # reuse
        # Source Nodes: [x_763, x_comb_iter_2_left_10], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf1933, buf1934, buf1935, buf1936, buf1937, 6912, 121, grid=grid(6912), stream=stream0)
        buf1938 = buf1927; del buf1927  # reuse
        buf1939 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf1941 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_left_10], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf1935, buf1936, buf1937, primals_1231, primals_1232, buf1938, buf1939, buf1941, primals_1231, primals_1232, 864, 8, grid=grid(864), stream=stream0)
        del primals_1231
        del primals_1232
        buf1942 = empty_strided((8, 864, 23, 23), (457056, 1, 19872, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_767], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_120.run(buf1890, buf1942, 3656448, grid=grid(3656448), stream=stream0)
        # Source Nodes: [x_768], Original ATen: [aten.convolution]
        buf1943 = extern_kernels.convolution(buf1942, primals_24, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf1943, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1944 = reinterpret_tensor(buf1933, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1933  # reuse
        # Source Nodes: [x_768], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf1943, buf1944, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_770], Original ATen: [aten.convolution]
        buf1945 = extern_kernels.convolution(buf1944, primals_589, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1945, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1946 = reinterpret_tensor(buf1943, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1943  # reuse
        buf1947 = buf1937; del buf1937  # reuse
        buf1948 = buf1936; del buf1936  # reuse
        buf1949 = buf1935; del buf1935  # reuse
        # Source Nodes: [x_770, x_771], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf1945, buf1946, buf1947, buf1948, buf1949, 6912, 121, grid=grid(6912), stream=stream0)
        buf1950 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf1951 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf1953 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_771], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf1947, buf1948, buf1949, primals_1234, primals_1235, buf1950, buf1951, buf1953, primals_1234, primals_1235, 864, 8, grid=grid(864), stream=stream0)
        del primals_1234
        del primals_1235
        buf1954 = reinterpret_tensor(buf1945, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1945  # reuse
        # Source Nodes: [x_771, x_772], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf1946, buf1950, buf1951, primals_590, primals_591, buf1954, 836352, grid=grid(836352), stream=stream0)
        del primals_591
        # Source Nodes: [x_773], Original ATen: [aten.convolution]
        buf1955 = extern_kernels.convolution(buf1954, primals_592, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf1955, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1956 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_773], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf1955, buf1956, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_775], Original ATen: [aten.convolution]
        buf1957 = extern_kernels.convolution(buf1956, primals_593, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1957, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1958 = reinterpret_tensor(buf1955, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1955  # reuse
        buf1959 = buf1949; del buf1949  # reuse
        buf1960 = buf1948; del buf1948  # reuse
        buf1961 = buf1947; del buf1947  # reuse
        # Source Nodes: [x_775, x_comb_iter_2_right_10], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf1957, buf1958, buf1959, buf1960, buf1961, 6912, 121, grid=grid(6912), stream=stream0)
        buf1962 = buf1951; del buf1951  # reuse
        buf1963 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf1965 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_right_10], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf1959, buf1960, buf1961, primals_1237, primals_1238, buf1962, buf1963, buf1965, primals_1237, primals_1238, 864, 8, grid=grid(864), stream=stream0)
        del primals_1237
        del primals_1238
        buf2028 = empty((8, 4320, 11, 11), device='cuda', dtype=torch.float32)
        buf1966 = reinterpret_tensor(buf2028, (8, 864, 11, 11), (522720, 121, 11, 1), 209088)  # alias
        # Source Nodes: [x_comb_iter_2_left_10, x_comb_iter_2_right_10, x_comb_iter_52], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_121.run(buf1934, buf1938, buf1939, primals_587, primals_588, buf1958, buf1962, buf1963, primals_594, primals_595, buf1966, 968, 864, grid=grid(968, 864), stream=stream0)
        del primals_588
        del primals_595
        buf1967 = reinterpret_tensor(buf1957, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1957  # reuse
        # Source Nodes: [x_777], Original ATen: [aten.relu]
        triton_poi_fused_relu_122.run(buf1966, buf1967, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_778], Original ATen: [aten.convolution]
        buf1968 = extern_kernels.convolution(buf1967, primals_596, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf1968, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1969 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_778], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf1968, buf1969, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_780], Original ATen: [aten.convolution]
        buf1970 = extern_kernels.convolution(buf1969, primals_597, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1970, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1971 = reinterpret_tensor(buf1968, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1968  # reuse
        buf1972 = buf1961; del buf1961  # reuse
        buf1973 = buf1960; del buf1960  # reuse
        buf1974 = buf1959; del buf1959  # reuse
        # Source Nodes: [x_780, x_781], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf1970, buf1971, buf1972, buf1973, buf1974, 6912, 121, grid=grid(6912), stream=stream0)
        buf1975 = buf1963; del buf1963  # reuse
        buf1976 = buf1939; del buf1939  # reuse
        buf1978 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_781], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf1972, buf1973, buf1974, primals_1240, primals_1241, buf1975, buf1976, buf1978, primals_1240, primals_1241, 864, 8, grid=grid(864), stream=stream0)
        del primals_1240
        del primals_1241
        buf1979 = reinterpret_tensor(buf1970, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1970  # reuse
        # Source Nodes: [x_781, x_782], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf1971, buf1975, buf1976, primals_598, primals_599, buf1979, 836352, grid=grid(836352), stream=stream0)
        del primals_599
        # Source Nodes: [x_783], Original ATen: [aten.convolution]
        buf1980 = extern_kernels.convolution(buf1979, primals_600, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf1980, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1981 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_783], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf1980, buf1981, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_785], Original ATen: [aten.convolution]
        buf1982 = extern_kernels.convolution(buf1981, primals_601, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1982, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1983 = reinterpret_tensor(buf1980, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1980  # reuse
        buf1984 = buf1974; del buf1974  # reuse
        buf1985 = buf1973; del buf1973  # reuse
        buf1986 = buf1972; del buf1972  # reuse
        # Source Nodes: [x_785, x_comb_iter_3_left_10], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf1982, buf1983, buf1984, buf1985, buf1986, 6912, 121, grid=grid(6912), stream=stream0)
        buf1987 = buf1976; del buf1976  # reuse
        buf1988 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf1990 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_3_left_10], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf1984, buf1985, buf1986, primals_1243, primals_1244, buf1987, buf1988, buf1990, primals_1243, primals_1244, 864, 8, grid=grid(864), stream=stream0)
        del primals_1243
        del primals_1244
        buf1991 = empty_strided((8, 864, 23, 23), (457056, 1, 19872, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_725, x_791], Original ATen: [aten.constant_pad_nd, aten.relu]
        triton_poi_fused_constant_pad_nd_relu_123.run(buf1851, buf1991, 3656448, grid=grid(3656448), stream=stream0)
        del buf1851
        # Source Nodes: [x_792], Original ATen: [aten.convolution]
        buf1992 = extern_kernels.convolution(buf1991, primals_25, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf1992, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1993 = reinterpret_tensor(buf1982, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1982  # reuse
        # Source Nodes: [x_792], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf1992, buf1993, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_794], Original ATen: [aten.convolution]
        buf1994 = extern_kernels.convolution(buf1993, primals_604, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1994, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf1995 = reinterpret_tensor(buf1992, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1992  # reuse
        buf1996 = buf1986; del buf1986  # reuse
        buf1997 = buf1985; del buf1985  # reuse
        buf1998 = buf1984; del buf1984  # reuse
        # Source Nodes: [x_794, x_795], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf1994, buf1995, buf1996, buf1997, buf1998, 6912, 121, grid=grid(6912), stream=stream0)
        buf1999 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2000 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2002 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_795], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf1996, buf1997, buf1998, primals_1246, primals_1247, buf1999, buf2000, buf2002, primals_1246, primals_1247, 864, 8, grid=grid(864), stream=stream0)
        del primals_1246
        del primals_1247
        buf2003 = reinterpret_tensor(buf1994, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf1994  # reuse
        # Source Nodes: [x_795, x_796], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf1995, buf1999, buf2000, primals_605, primals_606, buf2003, 836352, grid=grid(836352), stream=stream0)
        del primals_606
        # Source Nodes: [x_797], Original ATen: [aten.convolution]
        buf2004 = extern_kernels.convolution(buf2003, primals_607, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2004, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2005 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_797], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2004, buf2005, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_799], Original ATen: [aten.convolution]
        buf2006 = extern_kernels.convolution(buf2005, primals_608, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2006, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2007 = reinterpret_tensor(buf2004, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2004  # reuse
        buf2008 = buf1998; del buf1998  # reuse
        buf2009 = buf1997; del buf1997  # reuse
        buf2010 = buf1996; del buf1996  # reuse
        # Source Nodes: [x_799, x_comb_iter_4_left_10], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2006, buf2007, buf2008, buf2009, buf2010, 6912, 121, grid=grid(6912), stream=stream0)
        buf2011 = buf2000; del buf2000  # reuse
        buf2012 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2014 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_left_10], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2008, buf2009, buf2010, primals_1249, primals_1250, buf2011, buf2012, buf2014, primals_1249, primals_1250, 864, 8, grid=grid(864), stream=stream0)
        del primals_1249
        del primals_1250
        # Source Nodes: [x_804], Original ATen: [aten.convolution]
        buf2015 = extern_kernels.convolution(buf1890, primals_26, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2015, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2016 = reinterpret_tensor(buf2006, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2006  # reuse
        buf2017 = buf2010; del buf2010  # reuse
        buf2018 = buf2009; del buf2009  # reuse
        buf2019 = buf2008; del buf2008  # reuse
        # Source Nodes: [x_804, x_comb_iter_4_right_10], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2015, buf2016, buf2017, buf2018, buf2019, 6912, 121, grid=grid(6912), stream=stream0)
        buf2020 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2021 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2023 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_right_10], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2017, buf2018, buf2019, primals_1252, primals_1253, buf2020, buf2021, buf2023, primals_1252, primals_1253, 864, 8, grid=grid(864), stream=stream0)
        del primals_1252
        del primals_1253
        buf2024 = reinterpret_tensor(buf2028, (8, 864, 11, 11), (522720, 121, 11, 1), 418176)  # alias
        # Source Nodes: [x_comb_iter_4_left_10, x_comb_iter_4_right_10, x_comb_iter_54], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_121.run(buf2007, buf2011, buf2012, primals_609, primals_610, buf2016, buf2020, buf2021, primals_611, primals_612, buf2024, 968, 864, grid=grid(968, 864), stream=stream0)
        del primals_610
        del primals_612
        buf2025 = reinterpret_tensor(buf2028, (8, 864, 11, 11), (522720, 121, 11, 1), 0)  # alias
        # Source Nodes: [x_comb_iter_0_left_10, x_comb_iter_50], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_124.run(buf1879, buf1883, buf1884, primals_573, primals_574, buf1888, buf2025, 968, 864, grid=grid(968, 864), stream=stream0)
        del primals_574
        buf2026 = reinterpret_tensor(buf2028, (8, 864, 11, 11), (522720, 121, 11, 1), 104544)  # alias
        buf2027 = reinterpret_tensor(buf2028, (8, 864, 11, 11), (522720, 121, 11, 1), 313632)  # alias
        # Source Nodes: [x_comb_iter_1_left_10, x_comb_iter_3_left_10, x_comb_iter_51, x_comb_iter_53], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_125.run(buf1907, buf1911, buf1912, primals_580, primals_581, buf1916, buf1983, buf1987, buf1988, primals_602, primals_603, buf2026, buf2027, 968, 864, grid=grid(968, 864), stream=stream0)
        del primals_581
        del primals_603
        buf2029 = empty_strided((8, 2160, 11, 11), (261360, 1, 23760, 2160), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___cell_9_conv_prev_1x1_path_1_avgpool], Original ATen: [aten.avg_pool2d]
        triton_poi_fused_avg_pool2d_126.run(buf1852, buf2029, 2090880, grid=grid(2090880), stream=stream0)
        del buf1966
        del buf2024
        del buf2025
        del buf2026
        del buf2027
        # Source Nodes: [x_path1_3], Original ATen: [aten.convolution]
        buf2030 = extern_kernels.convolution(buf2029, primals_613, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2030, (8, 432, 11, 11), (52272, 121, 11, 1))
        buf2031 = reinterpret_tensor(buf1841, (8, 2160, 21, 21), (952560, 1, 45360, 2160), 0); del buf1841  # reuse
        # Source Nodes: [l__mod___cell_9_conv_prev_1x1_path_2_pad], Original ATen: [aten.constant_pad_nd]
        triton_poi_fused_constant_pad_nd_127.run(buf1852, buf2031, 7620480, grid=grid(7620480), stream=stream0)
        buf2032 = empty_strided((8, 2160, 11, 11), (261360, 1, 23760, 2160), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___cell_9_conv_prev_1x1_path_2_avgpool], Original ATen: [aten.avg_pool2d]
        triton_poi_fused_avg_pool2d_128.run(buf2031, buf2032, 17280, 121, grid=grid(17280, 121), stream=stream0)
        # Source Nodes: [x_path2_3], Original ATen: [aten.convolution]
        buf2033 = extern_kernels.convolution(buf2032, primals_614, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2033, (8, 432, 11, 11), (52272, 121, 11, 1))
        buf2034 = buf1916; del buf1916  # reuse
        buf2035 = buf2019; del buf2019  # reuse
        buf2036 = buf2018; del buf2018  # reuse
        buf2037 = buf2017; del buf2017  # reuse
        # Source Nodes: [cat_21, x_left_10], Original ATen: [aten._native_batch_norm_legit_functional, aten.cat]
        triton_red_fused__native_batch_norm_legit_functional_cat_129.run(buf2030, buf2033, buf2034, buf2035, buf2036, buf2037, 6912, 121, grid=grid(6912), stream=stream0)
        del buf2030
        del buf2033
        buf2038 = buf1988; del buf1988  # reuse
        buf2039 = buf1912; del buf1912  # reuse
        buf2041 = reinterpret_tensor(buf1884, (864, ), (1, ), 0); del buf1884  # reuse
        # Source Nodes: [x_left_10], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2035, buf2036, buf2037, primals_1255, primals_1256, buf2038, buf2039, buf2041, primals_1255, primals_1256, 864, 8, grid=grid(864), stream=stream0)
        del primals_1255
        del primals_1256
        buf2042 = buf1888; del buf1888  # reuse
        buf2054 = reinterpret_tensor(buf2015, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2015  # reuse
        # Source Nodes: [x_810, x_left_10], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_130.run(buf2034, buf2038, buf2039, primals_615, primals_616, buf2042, buf2054, 836352, grid=grid(836352), stream=stream0)
        del primals_616
        buf2043 = empty_strided((8, 4320, 11, 11), (522720, 1, 47520, 4320), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_807], Original ATen: [aten.relu]
        triton_poi_fused_relu_131.run(buf2028, buf2043, 34560, 121, grid=grid(34560, 121), stream=stream0)
        # Source Nodes: [x_808], Original ATen: [aten.convolution]
        buf2044 = extern_kernels.convolution(buf2043, primals_617, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2044, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2045 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        buf2046 = buf2037; del buf2037  # reuse
        buf2047 = buf2036; del buf2036  # reuse
        buf2048 = buf2035; del buf2035  # reuse
        # Source Nodes: [x_808, x_comb_iter_4_right_11], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2044, buf2045, buf2046, buf2047, buf2048, 6912, 121, grid=grid(6912), stream=stream0)
        buf2049 = buf2039; del buf2039  # reuse
        buf2050 = buf2021; del buf2021  # reuse
        buf2052 = reinterpret_tensor(buf2012, (864, ), (1, ), 0); del buf2012  # reuse
        # Source Nodes: [x_comb_iter_4_right_11], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2046, buf2047, buf2048, primals_1258, primals_1259, buf2049, buf2050, buf2052, primals_1258, primals_1259, 864, 8, grid=grid(864), stream=stream0)
        del primals_1258
        del primals_1259
        # Source Nodes: [x_861], Original ATen: [aten.convolution]
        buf2177 = extern_kernels.convolution(buf2054, primals_660, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2177, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2178 = reinterpret_tensor(buf2044, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2044  # reuse
        # Source Nodes: [x_861], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2177, buf2178, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_863], Original ATen: [aten.convolution]
        buf2179 = extern_kernels.convolution(buf2178, primals_661, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2179, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2180 = reinterpret_tensor(buf2177, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2177  # reuse
        buf2181 = buf2048; del buf2048  # reuse
        buf2182 = buf2047; del buf2047  # reuse
        buf2183 = buf2046; del buf2046  # reuse
        # Source Nodes: [x_863, x_864], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2179, buf2180, buf2181, buf2182, buf2183, 6912, 121, grid=grid(6912), stream=stream0)
        buf2184 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2185 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2187 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_864], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2181, buf2182, buf2183, primals_1291, primals_1292, buf2184, buf2185, buf2187, primals_1291, primals_1292, 864, 8, grid=grid(864), stream=stream0)
        del primals_1291
        del primals_1292
        buf2188 = reinterpret_tensor(buf2179, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2179  # reuse
        # Source Nodes: [x_864, x_865], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2180, buf2184, buf2185, primals_662, primals_663, buf2188, 836352, grid=grid(836352), stream=stream0)
        del primals_663
        # Source Nodes: [x_866], Original ATen: [aten.convolution]
        buf2189 = extern_kernels.convolution(buf2188, primals_664, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2189, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2190 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_866], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2189, buf2190, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_868], Original ATen: [aten.convolution]
        buf2191 = extern_kernels.convolution(buf2190, primals_665, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2191, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2192 = reinterpret_tensor(buf2189, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2189  # reuse
        buf2193 = buf2183; del buf2183  # reuse
        buf2194 = buf2182; del buf2182  # reuse
        buf2195 = buf2181; del buf2181  # reuse
        # Source Nodes: [x_868, x_comb_iter_4_left_11], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2191, buf2192, buf2193, buf2194, buf2195, 6912, 121, grid=grid(6912), stream=stream0)
        buf2196 = buf2185; del buf2185  # reuse
        buf2197 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2199 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_left_11], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2193, buf2194, buf2195, primals_1294, primals_1295, buf2196, buf2197, buf2199, primals_1294, primals_1295, 864, 8, grid=grid(864), stream=stream0)
        del primals_1294
        del primals_1295
        buf2053 = reinterpret_tensor(buf2191, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2191  # reuse
        buf2204 = buf2028; del buf2028  # reuse
        buf2203 = reinterpret_tensor(buf2204, (8, 864, 11, 11), (522720, 121, 11, 1), 418176)  # alias
        # Source Nodes: [x_comb_iter_4_left_11, x_comb_iter_4_right_11, x_comb_iter_59], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_132.run(buf2045, buf2049, buf2050, primals_618, primals_619, buf2192, buf2196, buf2197, primals_666, primals_667, buf2053, buf2203, 968, 864, grid=grid(968, 864), stream=stream0)
        del primals_619
        del primals_667
        # Source Nodes: [x_811], Original ATen: [aten.convolution]
        buf2055 = extern_kernels.convolution(buf2054, primals_620, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2055, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2056 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_811], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2055, buf2056, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_813], Original ATen: [aten.convolution]
        buf2057 = extern_kernels.convolution(buf2056, primals_621, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2057, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2058 = reinterpret_tensor(buf2055, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2055  # reuse
        buf2059 = buf2195; del buf2195  # reuse
        buf2060 = buf2194; del buf2194  # reuse
        buf2061 = buf2193; del buf2193  # reuse
        # Source Nodes: [x_813, x_814], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2057, buf2058, buf2059, buf2060, buf2061, 6912, 121, grid=grid(6912), stream=stream0)
        buf2062 = buf2197; del buf2197  # reuse
        buf2063 = buf2050; del buf2050  # reuse
        buf2065 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_814], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2059, buf2060, buf2061, primals_1261, primals_1262, buf2062, buf2063, buf2065, primals_1261, primals_1262, 864, 8, grid=grid(864), stream=stream0)
        del primals_1261
        del primals_1262
        buf2066 = reinterpret_tensor(buf2057, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2057  # reuse
        # Source Nodes: [x_814, x_815], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2058, buf2062, buf2063, primals_622, primals_623, buf2066, 836352, grid=grid(836352), stream=stream0)
        del primals_623
        # Source Nodes: [x_816], Original ATen: [aten.convolution]
        buf2067 = extern_kernels.convolution(buf2066, primals_624, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2067, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2068 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_816], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2067, buf2068, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_818], Original ATen: [aten.convolution]
        buf2069 = extern_kernels.convolution(buf2068, primals_625, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2069, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2070 = reinterpret_tensor(buf2067, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2067  # reuse
        buf2071 = buf2061; del buf2061  # reuse
        buf2072 = buf2060; del buf2060  # reuse
        buf2073 = buf2059; del buf2059  # reuse
        # Source Nodes: [x_818, x_comb_iter_0_left_11], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2069, buf2070, buf2071, buf2072, buf2073, 6912, 121, grid=grid(6912), stream=stream0)
        buf2074 = buf2063; del buf2063  # reuse
        buf2075 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2077 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_0_left_11], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2071, buf2072, buf2073, primals_1264, primals_1265, buf2074, buf2075, buf2077, primals_1264, primals_1265, 864, 8, grid=grid(864), stream=stream0)
        del primals_1264
        del primals_1265
        buf2078 = reinterpret_tensor(buf2069, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2069  # reuse
        buf2079 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_0_right_11], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_133.run(buf2042, buf2078, buf2079, 836352, grid=grid(836352), stream=stream0)
        buf2080 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        buf2104 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        buf2105 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_820, x_comb_iter_1_right_11], Original ATen: [aten.max_pool2d_with_indices, aten.relu]
        triton_poi_fused_max_pool2d_with_indices_relu_134.run(buf2053, buf2080, buf2104, buf2105, 836352, grid=grid(836352), stream=stream0)
        # Source Nodes: [x_821], Original ATen: [aten.convolution]
        buf2081 = extern_kernels.convolution(buf2080, primals_628, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2081, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2082 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_821], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2081, buf2082, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_823], Original ATen: [aten.convolution]
        buf2083 = extern_kernels.convolution(buf2082, primals_629, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2083, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2084 = reinterpret_tensor(buf2081, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2081  # reuse
        buf2085 = buf2073; del buf2073  # reuse
        buf2086 = buf2072; del buf2072  # reuse
        buf2087 = buf2071; del buf2071  # reuse
        # Source Nodes: [x_823, x_824], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2083, buf2084, buf2085, buf2086, buf2087, 6912, 121, grid=grid(6912), stream=stream0)
        buf2088 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2089 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2091 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_824], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2085, buf2086, buf2087, primals_1267, primals_1268, buf2088, buf2089, buf2091, primals_1267, primals_1268, 864, 8, grid=grid(864), stream=stream0)
        del primals_1267
        del primals_1268
        buf2092 = reinterpret_tensor(buf2083, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2083  # reuse
        # Source Nodes: [x_824, x_825], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2084, buf2088, buf2089, primals_630, primals_631, buf2092, 836352, grid=grid(836352), stream=stream0)
        del primals_631
        # Source Nodes: [x_826], Original ATen: [aten.convolution]
        buf2093 = extern_kernels.convolution(buf2092, primals_632, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2093, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2094 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_826], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2093, buf2094, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_828], Original ATen: [aten.convolution]
        buf2095 = extern_kernels.convolution(buf2094, primals_633, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2095, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2096 = reinterpret_tensor(buf2093, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2093  # reuse
        buf2097 = buf2087; del buf2087  # reuse
        buf2098 = buf2086; del buf2086  # reuse
        buf2099 = buf2085; del buf2085  # reuse
        # Source Nodes: [x_828, x_comb_iter_1_left_11], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2095, buf2096, buf2097, buf2098, buf2099, 6912, 121, grid=grid(6912), stream=stream0)
        buf2100 = buf2089; del buf2089  # reuse
        buf2101 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2103 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_1_left_11], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2097, buf2098, buf2099, primals_1270, primals_1271, buf2100, buf2101, buf2103, primals_1270, primals_1271, 864, 8, grid=grid(864), stream=stream0)
        del primals_1270
        del primals_1271
        # Source Nodes: [x_831], Original ATen: [aten.convolution]
        buf2106 = extern_kernels.convolution(buf2080, primals_636, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2106, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2107 = reinterpret_tensor(buf2095, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2095  # reuse
        # Source Nodes: [x_831], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2106, buf2107, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_833], Original ATen: [aten.convolution]
        buf2108 = extern_kernels.convolution(buf2107, primals_637, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2108, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2109 = reinterpret_tensor(buf2106, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2106  # reuse
        buf2110 = buf2099; del buf2099  # reuse
        buf2111 = buf2098; del buf2098  # reuse
        buf2112 = buf2097; del buf2097  # reuse
        # Source Nodes: [x_833, x_834], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2108, buf2109, buf2110, buf2111, buf2112, 6912, 121, grid=grid(6912), stream=stream0)
        buf2113 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2114 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2116 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_834], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2110, buf2111, buf2112, primals_1273, primals_1274, buf2113, buf2114, buf2116, primals_1273, primals_1274, 864, 8, grid=grid(864), stream=stream0)
        del primals_1273
        del primals_1274
        buf2117 = reinterpret_tensor(buf2108, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2108  # reuse
        # Source Nodes: [x_834, x_835], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2109, buf2113, buf2114, primals_638, primals_639, buf2117, 836352, grid=grid(836352), stream=stream0)
        del primals_639
        # Source Nodes: [x_836], Original ATen: [aten.convolution]
        buf2118 = extern_kernels.convolution(buf2117, primals_640, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2118, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2119 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_836], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2118, buf2119, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_838], Original ATen: [aten.convolution]
        buf2120 = extern_kernels.convolution(buf2119, primals_641, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2120, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2121 = reinterpret_tensor(buf2118, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2118  # reuse
        buf2122 = buf2112; del buf2112  # reuse
        buf2123 = buf2111; del buf2111  # reuse
        buf2124 = buf2110; del buf2110  # reuse
        # Source Nodes: [x_838, x_comb_iter_2_left_11], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2120, buf2121, buf2122, buf2123, buf2124, 6912, 121, grid=grid(6912), stream=stream0)
        buf2125 = buf2114; del buf2114  # reuse
        buf2126 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2128 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_left_11], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2122, buf2123, buf2124, primals_1276, primals_1277, buf2125, buf2126, buf2128, primals_1276, primals_1277, 864, 8, grid=grid(864), stream=stream0)
        del primals_1276
        del primals_1277
        # Source Nodes: [x_841], Original ATen: [aten.convolution]
        buf2129 = extern_kernels.convolution(buf2080, primals_644, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2129, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2130 = reinterpret_tensor(buf2120, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2120  # reuse
        # Source Nodes: [x_841], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2129, buf2130, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_843], Original ATen: [aten.convolution]
        buf2131 = extern_kernels.convolution(buf2130, primals_645, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2131, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2132 = reinterpret_tensor(buf2129, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2129  # reuse
        buf2133 = buf2124; del buf2124  # reuse
        buf2134 = buf2123; del buf2123  # reuse
        buf2135 = buf2122; del buf2122  # reuse
        # Source Nodes: [x_843, x_844], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2131, buf2132, buf2133, buf2134, buf2135, 6912, 121, grid=grid(6912), stream=stream0)
        buf2136 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2137 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2139 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_844], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2133, buf2134, buf2135, primals_1279, primals_1280, buf2136, buf2137, buf2139, primals_1279, primals_1280, 864, 8, grid=grid(864), stream=stream0)
        del primals_1279
        del primals_1280
        buf2140 = reinterpret_tensor(buf2131, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2131  # reuse
        # Source Nodes: [x_844, x_845], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2132, buf2136, buf2137, primals_646, primals_647, buf2140, 836352, grid=grid(836352), stream=stream0)
        del primals_647
        # Source Nodes: [x_846], Original ATen: [aten.convolution]
        buf2141 = extern_kernels.convolution(buf2140, primals_648, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2141, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2142 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_846], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2141, buf2142, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_848], Original ATen: [aten.convolution]
        buf2143 = extern_kernels.convolution(buf2142, primals_649, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2143, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2144 = reinterpret_tensor(buf2141, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2141  # reuse
        buf2145 = buf2135; del buf2135  # reuse
        buf2146 = buf2134; del buf2134  # reuse
        buf2147 = buf2133; del buf2133  # reuse
        # Source Nodes: [x_848, x_comb_iter_2_right_11], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2143, buf2144, buf2145, buf2146, buf2147, 6912, 121, grid=grid(6912), stream=stream0)
        buf2148 = buf2137; del buf2137  # reuse
        buf2149 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2151 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_right_11], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2145, buf2146, buf2147, primals_1282, primals_1283, buf2148, buf2149, buf2151, primals_1282, primals_1283, 864, 8, grid=grid(864), stream=stream0)
        del primals_1282
        del primals_1283
        buf2152 = reinterpret_tensor(buf2204, (8, 864, 11, 11), (522720, 121, 11, 1), 209088)  # alias
        # Source Nodes: [x_comb_iter_2_left_11, x_comb_iter_2_right_11, x_comb_iter_57], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_121.run(buf2121, buf2125, buf2126, primals_642, primals_643, buf2144, buf2148, buf2149, primals_650, primals_651, buf2152, 968, 864, grid=grid(968, 864), stream=stream0)
        del primals_643
        del primals_651
        buf2153 = reinterpret_tensor(buf2143, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2143  # reuse
        # Source Nodes: [x_850], Original ATen: [aten.relu]
        triton_poi_fused_relu_122.run(buf2152, buf2153, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_851], Original ATen: [aten.convolution]
        buf2154 = extern_kernels.convolution(buf2153, primals_652, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2154, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2155 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_851], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2154, buf2155, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_853], Original ATen: [aten.convolution]
        buf2156 = extern_kernels.convolution(buf2155, primals_653, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2156, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2157 = reinterpret_tensor(buf2154, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2154  # reuse
        buf2158 = buf2147; del buf2147  # reuse
        buf2159 = buf2146; del buf2146  # reuse
        buf2160 = buf2145; del buf2145  # reuse
        # Source Nodes: [x_853, x_854], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2156, buf2157, buf2158, buf2159, buf2160, 6912, 121, grid=grid(6912), stream=stream0)
        buf2161 = buf2149; del buf2149  # reuse
        buf2162 = buf2126; del buf2126  # reuse
        buf2164 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_854], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2158, buf2159, buf2160, primals_1285, primals_1286, buf2161, buf2162, buf2164, primals_1285, primals_1286, 864, 8, grid=grid(864), stream=stream0)
        del primals_1285
        del primals_1286
        buf2165 = reinterpret_tensor(buf2156, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2156  # reuse
        # Source Nodes: [x_854, x_855], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2157, buf2161, buf2162, primals_654, primals_655, buf2165, 836352, grid=grid(836352), stream=stream0)
        del primals_655
        # Source Nodes: [x_856], Original ATen: [aten.convolution]
        buf2166 = extern_kernels.convolution(buf2165, primals_656, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2166, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2167 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_856], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2166, buf2167, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_858], Original ATen: [aten.convolution]
        buf2168 = extern_kernels.convolution(buf2167, primals_657, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2168, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2169 = reinterpret_tensor(buf2166, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2166  # reuse
        buf2170 = buf2160; del buf2160  # reuse
        buf2171 = buf2159; del buf2159  # reuse
        buf2172 = buf2158; del buf2158  # reuse
        # Source Nodes: [x_858, x_comb_iter_3_left_11], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2168, buf2169, buf2170, buf2171, buf2172, 6912, 121, grid=grid(6912), stream=stream0)
        buf2173 = buf2162; del buf2162  # reuse
        buf2174 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2176 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_3_left_11], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2170, buf2171, buf2172, primals_1288, primals_1289, buf2173, buf2174, buf2176, primals_1288, primals_1289, 864, 8, grid=grid(864), stream=stream0)
        del primals_1288
        del primals_1289
        buf2200 = reinterpret_tensor(buf2204, (8, 864, 11, 11), (522720, 121, 11, 1), 0)  # alias
        # Source Nodes: [x_comb_iter_0_left_11, x_comb_iter_55], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_135.run(buf2070, buf2074, buf2075, primals_626, primals_627, buf2078, buf2200, 6912, 121, grid=grid(6912, 121), stream=stream0)
        del primals_627
        buf2201 = reinterpret_tensor(buf2204, (8, 864, 11, 11), (522720, 121, 11, 1), 104544)  # alias
        buf2202 = reinterpret_tensor(buf2204, (8, 864, 11, 11), (522720, 121, 11, 1), 313632)  # alias
        # Source Nodes: [x_comb_iter_1_left_11, x_comb_iter_3_left_11, x_comb_iter_56, x_comb_iter_58], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_136.run(buf2096, buf2100, buf2101, primals_634, primals_635, buf2104, buf2169, buf2173, buf2174, primals_658, primals_659, buf2201, buf2202, 6912, 121, grid=grid(6912, 121), stream=stream0)
        del primals_635
        del primals_659
        del buf2152
        del buf2200
        del buf2201
        del buf2202
        del buf2203
        # Source Nodes: [x_871], Original ATen: [aten.convolution]
        buf2205 = extern_kernels.convolution(buf2043, primals_668, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2205, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2206 = buf2104; del buf2104  # reuse
        buf2207 = buf2172; del buf2172  # reuse
        buf2208 = buf2171; del buf2171  # reuse
        buf2209 = buf2170; del buf2170  # reuse
        # Source Nodes: [x_871, x_left_11], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2205, buf2206, buf2207, buf2208, buf2209, 6912, 121, grid=grid(6912), stream=stream0)
        buf2210 = buf2174; del buf2174  # reuse
        buf2211 = buf2101; del buf2101  # reuse
        buf2213 = reinterpret_tensor(buf2075, (864, ), (1, ), 0); del buf2075  # reuse
        # Source Nodes: [x_left_11], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2207, buf2208, buf2209, primals_1297, primals_1298, buf2210, buf2211, buf2213, primals_1297, primals_1298, 864, 8, grid=grid(864), stream=stream0)
        del primals_1297
        del primals_1298
        buf2214 = reinterpret_tensor(buf2205, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2205  # reuse
        buf2226 = buf2078; del buf2078  # reuse
        # Source Nodes: [x_876, x_left_11], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_130.run(buf2206, buf2210, buf2211, primals_669, primals_670, buf2214, buf2226, 836352, grid=grid(836352), stream=stream0)
        del primals_670
        buf2215 = empty_strided((8, 4320, 11, 11), (522720, 1, 47520, 4320), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_873], Original ATen: [aten.relu]
        triton_poi_fused_relu_131.run(buf2204, buf2215, 34560, 121, grid=grid(34560, 121), stream=stream0)
        # Source Nodes: [x_874], Original ATen: [aten.convolution]
        buf2216 = extern_kernels.convolution(buf2215, primals_671, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2216, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2217 = reinterpret_tensor(buf2168, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2168  # reuse
        buf2218 = buf2209; del buf2209  # reuse
        buf2219 = buf2208; del buf2208  # reuse
        buf2220 = buf2207; del buf2207  # reuse
        # Source Nodes: [x_874, x_comb_iter_4_right_12], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2216, buf2217, buf2218, buf2219, buf2220, 6912, 121, grid=grid(6912), stream=stream0)
        buf2221 = buf2211; del buf2211  # reuse
        buf2222 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2224 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_right_12], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2218, buf2219, buf2220, primals_1300, primals_1301, buf2221, buf2222, buf2224, primals_1300, primals_1301, 864, 8, grid=grid(864), stream=stream0)
        del primals_1300
        del primals_1301
        # Source Nodes: [x_927], Original ATen: [aten.convolution]
        buf2349 = extern_kernels.convolution(buf2226, primals_714, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2349, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2350 = reinterpret_tensor(buf2216, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2216  # reuse
        # Source Nodes: [x_927], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2349, buf2350, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_929], Original ATen: [aten.convolution]
        buf2351 = extern_kernels.convolution(buf2350, primals_715, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2351, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2352 = reinterpret_tensor(buf2349, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2349  # reuse
        buf2353 = buf2220; del buf2220  # reuse
        buf2354 = buf2219; del buf2219  # reuse
        buf2355 = buf2218; del buf2218  # reuse
        # Source Nodes: [x_929, x_930], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2351, buf2352, buf2353, buf2354, buf2355, 6912, 121, grid=grid(6912), stream=stream0)
        buf2356 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2357 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2359 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_930], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2353, buf2354, buf2355, primals_1333, primals_1334, buf2356, buf2357, buf2359, primals_1333, primals_1334, 864, 8, grid=grid(864), stream=stream0)
        del primals_1333
        del primals_1334
        buf2360 = reinterpret_tensor(buf2351, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2351  # reuse
        # Source Nodes: [x_930, x_931], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2352, buf2356, buf2357, primals_716, primals_717, buf2360, 836352, grid=grid(836352), stream=stream0)
        del primals_717
        # Source Nodes: [x_932], Original ATen: [aten.convolution]
        buf2361 = extern_kernels.convolution(buf2360, primals_718, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2361, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2362 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_932], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2361, buf2362, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_934], Original ATen: [aten.convolution]
        buf2363 = extern_kernels.convolution(buf2362, primals_719, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2363, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2364 = reinterpret_tensor(buf2361, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2361  # reuse
        buf2365 = buf2355; del buf2355  # reuse
        buf2366 = buf2354; del buf2354  # reuse
        buf2367 = buf2353; del buf2353  # reuse
        # Source Nodes: [x_934, x_comb_iter_4_left_12], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2363, buf2364, buf2365, buf2366, buf2367, 6912, 121, grid=grid(6912), stream=stream0)
        buf2368 = buf2357; del buf2357  # reuse
        buf2369 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2371 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_left_12], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2365, buf2366, buf2367, primals_1336, primals_1337, buf2368, buf2369, buf2371, primals_1336, primals_1337, 864, 8, grid=grid(864), stream=stream0)
        del primals_1336
        del primals_1337
        buf2225 = reinterpret_tensor(buf2363, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2363  # reuse
        buf2376 = buf2204; del buf2204  # reuse
        buf2375 = reinterpret_tensor(buf2376, (8, 864, 11, 11), (522720, 121, 11, 1), 418176)  # alias
        # Source Nodes: [x_comb_iter_4_left_12, x_comb_iter_4_right_12, x_comb_iter_64], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_132.run(buf2217, buf2221, buf2222, primals_672, primals_673, buf2364, buf2368, buf2369, primals_720, primals_721, buf2225, buf2375, 968, 864, grid=grid(968, 864), stream=stream0)
        del primals_673
        del primals_721
        # Source Nodes: [x_877], Original ATen: [aten.convolution]
        buf2227 = extern_kernels.convolution(buf2226, primals_674, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2227, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2228 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_877], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2227, buf2228, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_879], Original ATen: [aten.convolution]
        buf2229 = extern_kernels.convolution(buf2228, primals_675, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2229, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2230 = reinterpret_tensor(buf2227, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2227  # reuse
        buf2231 = buf2367; del buf2367  # reuse
        buf2232 = buf2366; del buf2366  # reuse
        buf2233 = buf2365; del buf2365  # reuse
        # Source Nodes: [x_879, x_880], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2229, buf2230, buf2231, buf2232, buf2233, 6912, 121, grid=grid(6912), stream=stream0)
        buf2234 = buf2369; del buf2369  # reuse
        buf2235 = buf2222; del buf2222  # reuse
        buf2237 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_880], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2231, buf2232, buf2233, primals_1303, primals_1304, buf2234, buf2235, buf2237, primals_1303, primals_1304, 864, 8, grid=grid(864), stream=stream0)
        del primals_1303
        del primals_1304
        buf2238 = reinterpret_tensor(buf2229, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2229  # reuse
        # Source Nodes: [x_880, x_881], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2230, buf2234, buf2235, primals_676, primals_677, buf2238, 836352, grid=grid(836352), stream=stream0)
        del primals_677
        # Source Nodes: [x_882], Original ATen: [aten.convolution]
        buf2239 = extern_kernels.convolution(buf2238, primals_678, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2239, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2240 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_882], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2239, buf2240, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_884], Original ATen: [aten.convolution]
        buf2241 = extern_kernels.convolution(buf2240, primals_679, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2241, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2242 = reinterpret_tensor(buf2239, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2239  # reuse
        buf2243 = buf2233; del buf2233  # reuse
        buf2244 = buf2232; del buf2232  # reuse
        buf2245 = buf2231; del buf2231  # reuse
        # Source Nodes: [x_884, x_comb_iter_0_left_12], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2241, buf2242, buf2243, buf2244, buf2245, 6912, 121, grid=grid(6912), stream=stream0)
        buf2246 = buf2235; del buf2235  # reuse
        buf2247 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2249 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_0_left_12], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2243, buf2244, buf2245, primals_1306, primals_1307, buf2246, buf2247, buf2249, primals_1306, primals_1307, 864, 8, grid=grid(864), stream=stream0)
        del primals_1306
        del primals_1307
        buf2250 = reinterpret_tensor(buf2241, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2241  # reuse
        buf2251 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_0_right_12], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_133.run(buf2214, buf2250, buf2251, 836352, grid=grid(836352), stream=stream0)
        buf2252 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        buf2276 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        buf2277 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_886, x_comb_iter_1_right_12], Original ATen: [aten.max_pool2d_with_indices, aten.relu]
        triton_poi_fused_max_pool2d_with_indices_relu_134.run(buf2225, buf2252, buf2276, buf2277, 836352, grid=grid(836352), stream=stream0)
        # Source Nodes: [x_887], Original ATen: [aten.convolution]
        buf2253 = extern_kernels.convolution(buf2252, primals_682, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2253, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2254 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_887], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2253, buf2254, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_889], Original ATen: [aten.convolution]
        buf2255 = extern_kernels.convolution(buf2254, primals_683, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2255, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2256 = reinterpret_tensor(buf2253, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2253  # reuse
        buf2257 = buf2245; del buf2245  # reuse
        buf2258 = buf2244; del buf2244  # reuse
        buf2259 = buf2243; del buf2243  # reuse
        # Source Nodes: [x_889, x_890], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2255, buf2256, buf2257, buf2258, buf2259, 6912, 121, grid=grid(6912), stream=stream0)
        buf2260 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2261 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2263 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_890], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2257, buf2258, buf2259, primals_1309, primals_1310, buf2260, buf2261, buf2263, primals_1309, primals_1310, 864, 8, grid=grid(864), stream=stream0)
        del primals_1309
        del primals_1310
        buf2264 = reinterpret_tensor(buf2255, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2255  # reuse
        # Source Nodes: [x_890, x_891], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2256, buf2260, buf2261, primals_684, primals_685, buf2264, 836352, grid=grid(836352), stream=stream0)
        del primals_685
        # Source Nodes: [x_892], Original ATen: [aten.convolution]
        buf2265 = extern_kernels.convolution(buf2264, primals_686, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2265, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2266 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_892], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2265, buf2266, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_894], Original ATen: [aten.convolution]
        buf2267 = extern_kernels.convolution(buf2266, primals_687, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2267, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2268 = reinterpret_tensor(buf2265, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2265  # reuse
        buf2269 = buf2259; del buf2259  # reuse
        buf2270 = buf2258; del buf2258  # reuse
        buf2271 = buf2257; del buf2257  # reuse
        # Source Nodes: [x_894, x_comb_iter_1_left_12], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2267, buf2268, buf2269, buf2270, buf2271, 6912, 121, grid=grid(6912), stream=stream0)
        buf2272 = buf2261; del buf2261  # reuse
        buf2273 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2275 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_1_left_12], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2269, buf2270, buf2271, primals_1312, primals_1313, buf2272, buf2273, buf2275, primals_1312, primals_1313, 864, 8, grid=grid(864), stream=stream0)
        del primals_1312
        del primals_1313
        # Source Nodes: [x_897], Original ATen: [aten.convolution]
        buf2278 = extern_kernels.convolution(buf2252, primals_690, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2278, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2279 = reinterpret_tensor(buf2267, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2267  # reuse
        # Source Nodes: [x_897], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2278, buf2279, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_899], Original ATen: [aten.convolution]
        buf2280 = extern_kernels.convolution(buf2279, primals_691, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2280, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2281 = reinterpret_tensor(buf2278, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2278  # reuse
        buf2282 = buf2271; del buf2271  # reuse
        buf2283 = buf2270; del buf2270  # reuse
        buf2284 = buf2269; del buf2269  # reuse
        # Source Nodes: [x_899, x_900], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2280, buf2281, buf2282, buf2283, buf2284, 6912, 121, grid=grid(6912), stream=stream0)
        buf2285 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2286 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2288 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_900], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2282, buf2283, buf2284, primals_1315, primals_1316, buf2285, buf2286, buf2288, primals_1315, primals_1316, 864, 8, grid=grid(864), stream=stream0)
        del primals_1315
        del primals_1316
        buf2289 = reinterpret_tensor(buf2280, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2280  # reuse
        # Source Nodes: [x_900, x_901], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2281, buf2285, buf2286, primals_692, primals_693, buf2289, 836352, grid=grid(836352), stream=stream0)
        del primals_693
        # Source Nodes: [x_902], Original ATen: [aten.convolution]
        buf2290 = extern_kernels.convolution(buf2289, primals_694, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2290, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2291 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_902], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2290, buf2291, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_904], Original ATen: [aten.convolution]
        buf2292 = extern_kernels.convolution(buf2291, primals_695, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2292, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2293 = reinterpret_tensor(buf2290, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2290  # reuse
        buf2294 = buf2284; del buf2284  # reuse
        buf2295 = buf2283; del buf2283  # reuse
        buf2296 = buf2282; del buf2282  # reuse
        # Source Nodes: [x_904, x_comb_iter_2_left_12], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2292, buf2293, buf2294, buf2295, buf2296, 6912, 121, grid=grid(6912), stream=stream0)
        buf2297 = buf2286; del buf2286  # reuse
        buf2298 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2300 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_left_12], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2294, buf2295, buf2296, primals_1318, primals_1319, buf2297, buf2298, buf2300, primals_1318, primals_1319, 864, 8, grid=grid(864), stream=stream0)
        del primals_1318
        del primals_1319
        # Source Nodes: [x_907], Original ATen: [aten.convolution]
        buf2301 = extern_kernels.convolution(buf2252, primals_698, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2301, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2302 = reinterpret_tensor(buf2292, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2292  # reuse
        # Source Nodes: [x_907], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2301, buf2302, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_909], Original ATen: [aten.convolution]
        buf2303 = extern_kernels.convolution(buf2302, primals_699, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2303, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2304 = reinterpret_tensor(buf2301, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2301  # reuse
        buf2305 = buf2296; del buf2296  # reuse
        buf2306 = buf2295; del buf2295  # reuse
        buf2307 = buf2294; del buf2294  # reuse
        # Source Nodes: [x_909, x_910], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2303, buf2304, buf2305, buf2306, buf2307, 6912, 121, grid=grid(6912), stream=stream0)
        buf2308 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2309 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2311 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_910], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2305, buf2306, buf2307, primals_1321, primals_1322, buf2308, buf2309, buf2311, primals_1321, primals_1322, 864, 8, grid=grid(864), stream=stream0)
        del primals_1321
        del primals_1322
        buf2312 = reinterpret_tensor(buf2303, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2303  # reuse
        # Source Nodes: [x_910, x_911], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2304, buf2308, buf2309, primals_700, primals_701, buf2312, 836352, grid=grid(836352), stream=stream0)
        del primals_701
        # Source Nodes: [x_912], Original ATen: [aten.convolution]
        buf2313 = extern_kernels.convolution(buf2312, primals_702, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2313, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2314 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_912], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2313, buf2314, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_914], Original ATen: [aten.convolution]
        buf2315 = extern_kernels.convolution(buf2314, primals_703, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2315, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2316 = reinterpret_tensor(buf2313, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2313  # reuse
        buf2317 = buf2307; del buf2307  # reuse
        buf2318 = buf2306; del buf2306  # reuse
        buf2319 = buf2305; del buf2305  # reuse
        # Source Nodes: [x_914, x_comb_iter_2_right_12], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2315, buf2316, buf2317, buf2318, buf2319, 6912, 121, grid=grid(6912), stream=stream0)
        buf2320 = buf2309; del buf2309  # reuse
        buf2321 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2323 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_right_12], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2317, buf2318, buf2319, primals_1324, primals_1325, buf2320, buf2321, buf2323, primals_1324, primals_1325, 864, 8, grid=grid(864), stream=stream0)
        del primals_1324
        del primals_1325
        buf2324 = reinterpret_tensor(buf2376, (8, 864, 11, 11), (522720, 121, 11, 1), 209088)  # alias
        # Source Nodes: [x_comb_iter_2_left_12, x_comb_iter_2_right_12, x_comb_iter_62], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_121.run(buf2293, buf2297, buf2298, primals_696, primals_697, buf2316, buf2320, buf2321, primals_704, primals_705, buf2324, 968, 864, grid=grid(968, 864), stream=stream0)
        del primals_697
        del primals_705
        buf2325 = reinterpret_tensor(buf2315, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2315  # reuse
        # Source Nodes: [x_916], Original ATen: [aten.relu]
        triton_poi_fused_relu_122.run(buf2324, buf2325, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_917], Original ATen: [aten.convolution]
        buf2326 = extern_kernels.convolution(buf2325, primals_706, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2326, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2327 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_917], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2326, buf2327, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_919], Original ATen: [aten.convolution]
        buf2328 = extern_kernels.convolution(buf2327, primals_707, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2328, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2329 = reinterpret_tensor(buf2326, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2326  # reuse
        buf2330 = buf2319; del buf2319  # reuse
        buf2331 = buf2318; del buf2318  # reuse
        buf2332 = buf2317; del buf2317  # reuse
        # Source Nodes: [x_919, x_920], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2328, buf2329, buf2330, buf2331, buf2332, 6912, 121, grid=grid(6912), stream=stream0)
        buf2333 = buf2321; del buf2321  # reuse
        buf2334 = buf2298; del buf2298  # reuse
        buf2336 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_920], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2330, buf2331, buf2332, primals_1327, primals_1328, buf2333, buf2334, buf2336, primals_1327, primals_1328, 864, 8, grid=grid(864), stream=stream0)
        del primals_1327
        del primals_1328
        buf2337 = reinterpret_tensor(buf2328, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2328  # reuse
        # Source Nodes: [x_920, x_921], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2329, buf2333, buf2334, primals_708, primals_709, buf2337, 836352, grid=grid(836352), stream=stream0)
        del primals_709
        # Source Nodes: [x_922], Original ATen: [aten.convolution]
        buf2338 = extern_kernels.convolution(buf2337, primals_710, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2338, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2339 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_922], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2338, buf2339, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_924], Original ATen: [aten.convolution]
        buf2340 = extern_kernels.convolution(buf2339, primals_711, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2340, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2341 = reinterpret_tensor(buf2338, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2338  # reuse
        buf2342 = buf2332; del buf2332  # reuse
        buf2343 = buf2331; del buf2331  # reuse
        buf2344 = buf2330; del buf2330  # reuse
        # Source Nodes: [x_924, x_comb_iter_3_left_12], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2340, buf2341, buf2342, buf2343, buf2344, 6912, 121, grid=grid(6912), stream=stream0)
        buf2345 = buf2334; del buf2334  # reuse
        buf2346 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2348 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_3_left_12], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2342, buf2343, buf2344, primals_1330, primals_1331, buf2345, buf2346, buf2348, primals_1330, primals_1331, 864, 8, grid=grid(864), stream=stream0)
        del primals_1330
        del primals_1331
        buf2372 = reinterpret_tensor(buf2376, (8, 864, 11, 11), (522720, 121, 11, 1), 0)  # alias
        # Source Nodes: [x_comb_iter_0_left_12, x_comb_iter_60], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_135.run(buf2242, buf2246, buf2247, primals_680, primals_681, buf2250, buf2372, 6912, 121, grid=grid(6912, 121), stream=stream0)
        del primals_681
        buf2373 = reinterpret_tensor(buf2376, (8, 864, 11, 11), (522720, 121, 11, 1), 104544)  # alias
        buf2374 = reinterpret_tensor(buf2376, (8, 864, 11, 11), (522720, 121, 11, 1), 313632)  # alias
        # Source Nodes: [x_comb_iter_1_left_12, x_comb_iter_3_left_12, x_comb_iter_61, x_comb_iter_63], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_136.run(buf2268, buf2272, buf2273, primals_688, primals_689, buf2276, buf2341, buf2345, buf2346, primals_712, primals_713, buf2373, buf2374, 6912, 121, grid=grid(6912, 121), stream=stream0)
        del primals_689
        del primals_713
        del buf2324
        del buf2372
        del buf2373
        del buf2374
        del buf2375
        # Source Nodes: [x_937], Original ATen: [aten.convolution]
        buf2377 = extern_kernels.convolution(buf2215, primals_722, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2377, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2378 = buf2276; del buf2276  # reuse
        buf2379 = buf2344; del buf2344  # reuse
        buf2380 = buf2343; del buf2343  # reuse
        buf2381 = buf2342; del buf2342  # reuse
        # Source Nodes: [x_937, x_left_12], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2377, buf2378, buf2379, buf2380, buf2381, 6912, 121, grid=grid(6912), stream=stream0)
        buf2382 = buf2346; del buf2346  # reuse
        buf2383 = buf2273; del buf2273  # reuse
        buf2385 = reinterpret_tensor(buf2247, (864, ), (1, ), 0); del buf2247  # reuse
        # Source Nodes: [x_left_12], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2379, buf2380, buf2381, primals_1339, primals_1340, buf2382, buf2383, buf2385, primals_1339, primals_1340, 864, 8, grid=grid(864), stream=stream0)
        del primals_1339
        del primals_1340
        buf2386 = reinterpret_tensor(buf2377, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2377  # reuse
        buf2398 = buf2250; del buf2250  # reuse
        # Source Nodes: [x_942, x_left_12], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_130.run(buf2378, buf2382, buf2383, primals_723, primals_724, buf2386, buf2398, 836352, grid=grid(836352), stream=stream0)
        del primals_724
        buf2387 = empty_strided((8, 4320, 11, 11), (522720, 1, 47520, 4320), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_939], Original ATen: [aten.relu]
        triton_poi_fused_relu_131.run(buf2376, buf2387, 34560, 121, grid=grid(34560, 121), stream=stream0)
        # Source Nodes: [x_940], Original ATen: [aten.convolution]
        buf2388 = extern_kernels.convolution(buf2387, primals_725, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2388, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2389 = reinterpret_tensor(buf2340, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2340  # reuse
        buf2390 = buf2381; del buf2381  # reuse
        buf2391 = buf2380; del buf2380  # reuse
        buf2392 = buf2379; del buf2379  # reuse
        # Source Nodes: [x_940, x_comb_iter_4_right_13], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2388, buf2389, buf2390, buf2391, buf2392, 6912, 121, grid=grid(6912), stream=stream0)
        buf2393 = buf2383; del buf2383  # reuse
        buf2394 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2396 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_right_13], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2390, buf2391, buf2392, primals_1342, primals_1343, buf2393, buf2394, buf2396, primals_1342, primals_1343, 864, 8, grid=grid(864), stream=stream0)
        del primals_1342
        del primals_1343
        # Source Nodes: [x_993], Original ATen: [aten.convolution]
        buf2521 = extern_kernels.convolution(buf2398, primals_768, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2521, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2522 = reinterpret_tensor(buf2388, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2388  # reuse
        # Source Nodes: [x_993], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2521, buf2522, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_995], Original ATen: [aten.convolution]
        buf2523 = extern_kernels.convolution(buf2522, primals_769, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2523, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2524 = reinterpret_tensor(buf2521, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2521  # reuse
        buf2525 = buf2392; del buf2392  # reuse
        buf2526 = buf2391; del buf2391  # reuse
        buf2527 = buf2390; del buf2390  # reuse
        # Source Nodes: [x_995, x_996], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2523, buf2524, buf2525, buf2526, buf2527, 6912, 121, grid=grid(6912), stream=stream0)
        buf2528 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2529 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2531 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_996], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2525, buf2526, buf2527, primals_1375, primals_1376, buf2528, buf2529, buf2531, primals_1375, primals_1376, 864, 8, grid=grid(864), stream=stream0)
        del primals_1375
        del primals_1376
        buf2532 = reinterpret_tensor(buf2523, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2523  # reuse
        # Source Nodes: [x_996, x_997], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2524, buf2528, buf2529, primals_770, primals_771, buf2532, 836352, grid=grid(836352), stream=stream0)
        del primals_771
        # Source Nodes: [x_998], Original ATen: [aten.convolution]
        buf2533 = extern_kernels.convolution(buf2532, primals_772, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2533, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2534 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_998], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2533, buf2534, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_1000], Original ATen: [aten.convolution]
        buf2535 = extern_kernels.convolution(buf2534, primals_773, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2535, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2536 = reinterpret_tensor(buf2533, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2533  # reuse
        buf2537 = buf2527; del buf2527  # reuse
        buf2538 = buf2526; del buf2526  # reuse
        buf2539 = buf2525; del buf2525  # reuse
        # Source Nodes: [x_1000, x_comb_iter_4_left_13], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2535, buf2536, buf2537, buf2538, buf2539, 6912, 121, grid=grid(6912), stream=stream0)
        buf2540 = buf2529; del buf2529  # reuse
        buf2541 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2543 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_4_left_13], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2537, buf2538, buf2539, primals_1378, primals_1379, buf2540, buf2541, buf2543, primals_1378, primals_1379, 864, 8, grid=grid(864), stream=stream0)
        del primals_1378
        del primals_1379
        buf2397 = reinterpret_tensor(buf2535, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2535  # reuse
        buf2548 = buf2376; del buf2376  # reuse
        buf2547 = reinterpret_tensor(buf2548, (8, 864, 11, 11), (522720, 121, 11, 1), 418176)  # alias
        # Source Nodes: [x_comb_iter_4_left_13, x_comb_iter_4_right_13, x_comb_iter_69], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_132.run(buf2389, buf2393, buf2394, primals_726, primals_727, buf2536, buf2540, buf2541, primals_774, primals_775, buf2397, buf2547, 968, 864, grid=grid(968, 864), stream=stream0)
        del primals_727
        del primals_775
        # Source Nodes: [x_943], Original ATen: [aten.convolution]
        buf2399 = extern_kernels.convolution(buf2398, primals_728, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2399, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2400 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_943], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2399, buf2400, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_945], Original ATen: [aten.convolution]
        buf2401 = extern_kernels.convolution(buf2400, primals_729, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2401, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2402 = reinterpret_tensor(buf2399, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2399  # reuse
        buf2403 = buf2539; del buf2539  # reuse
        buf2404 = buf2538; del buf2538  # reuse
        buf2405 = buf2537; del buf2537  # reuse
        # Source Nodes: [x_945, x_946], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2401, buf2402, buf2403, buf2404, buf2405, 6912, 121, grid=grid(6912), stream=stream0)
        buf2406 = buf2541; del buf2541  # reuse
        buf2407 = buf2394; del buf2394  # reuse
        buf2409 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_946], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2403, buf2404, buf2405, primals_1345, primals_1346, buf2406, buf2407, buf2409, primals_1345, primals_1346, 864, 8, grid=grid(864), stream=stream0)
        del primals_1345
        del primals_1346
        buf2410 = reinterpret_tensor(buf2401, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2401  # reuse
        # Source Nodes: [x_946, x_947], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2402, buf2406, buf2407, primals_730, primals_731, buf2410, 836352, grid=grid(836352), stream=stream0)
        del primals_731
        # Source Nodes: [x_948], Original ATen: [aten.convolution]
        buf2411 = extern_kernels.convolution(buf2410, primals_732, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2411, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2412 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_948], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2411, buf2412, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_950], Original ATen: [aten.convolution]
        buf2413 = extern_kernels.convolution(buf2412, primals_733, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2413, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2414 = reinterpret_tensor(buf2411, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2411  # reuse
        buf2415 = buf2405; del buf2405  # reuse
        buf2416 = buf2404; del buf2404  # reuse
        buf2417 = buf2403; del buf2403  # reuse
        # Source Nodes: [x_950, x_comb_iter_0_left_13], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2413, buf2414, buf2415, buf2416, buf2417, 6912, 121, grid=grid(6912), stream=stream0)
        buf2418 = buf2407; del buf2407  # reuse
        buf2419 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2421 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_0_left_13], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2415, buf2416, buf2417, primals_1348, primals_1349, buf2418, buf2419, buf2421, primals_1348, primals_1349, 864, 8, grid=grid(864), stream=stream0)
        del primals_1348
        del primals_1349
        buf2422 = reinterpret_tensor(buf2413, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2413  # reuse
        buf2423 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_comb_iter_0_right_13], Original ATen: [aten.max_pool2d_with_indices]
        triton_poi_fused_max_pool2d_with_indices_133.run(buf2386, buf2422, buf2423, 836352, grid=grid(836352), stream=stream0)
        buf2424 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        buf2448 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        buf2449 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.int64)
        # Source Nodes: [x_952, x_comb_iter_1_right_13], Original ATen: [aten.max_pool2d_with_indices, aten.relu]
        triton_poi_fused_max_pool2d_with_indices_relu_134.run(buf2397, buf2424, buf2448, buf2449, 836352, grid=grid(836352), stream=stream0)
        # Source Nodes: [x_953], Original ATen: [aten.convolution]
        buf2425 = extern_kernels.convolution(buf2424, primals_736, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2425, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2426 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_953], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2425, buf2426, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_955], Original ATen: [aten.convolution]
        buf2427 = extern_kernels.convolution(buf2426, primals_737, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2427, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2428 = reinterpret_tensor(buf2425, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2425  # reuse
        buf2429 = buf2417; del buf2417  # reuse
        buf2430 = buf2416; del buf2416  # reuse
        buf2431 = buf2415; del buf2415  # reuse
        # Source Nodes: [x_955, x_956], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2427, buf2428, buf2429, buf2430, buf2431, 6912, 121, grid=grid(6912), stream=stream0)
        buf2432 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2433 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2435 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_956], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2429, buf2430, buf2431, primals_1351, primals_1352, buf2432, buf2433, buf2435, primals_1351, primals_1352, 864, 8, grid=grid(864), stream=stream0)
        del primals_1351
        del primals_1352
        buf2436 = reinterpret_tensor(buf2427, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2427  # reuse
        # Source Nodes: [x_956, x_957], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2428, buf2432, buf2433, primals_738, primals_739, buf2436, 836352, grid=grid(836352), stream=stream0)
        del primals_739
        # Source Nodes: [x_958], Original ATen: [aten.convolution]
        buf2437 = extern_kernels.convolution(buf2436, primals_740, stride=(1, 1), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2437, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2438 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_958], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2437, buf2438, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_960], Original ATen: [aten.convolution]
        buf2439 = extern_kernels.convolution(buf2438, primals_741, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2439, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2440 = reinterpret_tensor(buf2437, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2437  # reuse
        buf2441 = buf2431; del buf2431  # reuse
        buf2442 = buf2430; del buf2430  # reuse
        buf2443 = buf2429; del buf2429  # reuse
        # Source Nodes: [x_960, x_comb_iter_1_left_13], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2439, buf2440, buf2441, buf2442, buf2443, 6912, 121, grid=grid(6912), stream=stream0)
        buf2444 = buf2433; del buf2433  # reuse
        buf2445 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2447 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_1_left_13], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2441, buf2442, buf2443, primals_1354, primals_1355, buf2444, buf2445, buf2447, primals_1354, primals_1355, 864, 8, grid=grid(864), stream=stream0)
        del primals_1354
        del primals_1355
        # Source Nodes: [x_963], Original ATen: [aten.convolution]
        buf2450 = extern_kernels.convolution(buf2424, primals_744, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2450, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2451 = reinterpret_tensor(buf2439, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2439  # reuse
        # Source Nodes: [x_963], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2450, buf2451, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_965], Original ATen: [aten.convolution]
        buf2452 = extern_kernels.convolution(buf2451, primals_745, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2452, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2453 = reinterpret_tensor(buf2450, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2450  # reuse
        buf2454 = buf2443; del buf2443  # reuse
        buf2455 = buf2442; del buf2442  # reuse
        buf2456 = buf2441; del buf2441  # reuse
        # Source Nodes: [x_965, x_966], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2452, buf2453, buf2454, buf2455, buf2456, 6912, 121, grid=grid(6912), stream=stream0)
        buf2457 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2458 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2460 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_966], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2454, buf2455, buf2456, primals_1357, primals_1358, buf2457, buf2458, buf2460, primals_1357, primals_1358, 864, 8, grid=grid(864), stream=stream0)
        del primals_1357
        del primals_1358
        buf2461 = reinterpret_tensor(buf2452, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2452  # reuse
        # Source Nodes: [x_966, x_967], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2453, buf2457, buf2458, primals_746, primals_747, buf2461, 836352, grid=grid(836352), stream=stream0)
        del primals_747
        # Source Nodes: [x_968], Original ATen: [aten.convolution]
        buf2462 = extern_kernels.convolution(buf2461, primals_748, stride=(1, 1), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2462, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2463 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_968], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2462, buf2463, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_970], Original ATen: [aten.convolution]
        buf2464 = extern_kernels.convolution(buf2463, primals_749, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2464, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2465 = reinterpret_tensor(buf2462, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2462  # reuse
        buf2466 = buf2456; del buf2456  # reuse
        buf2467 = buf2455; del buf2455  # reuse
        buf2468 = buf2454; del buf2454  # reuse
        # Source Nodes: [x_970, x_comb_iter_2_left_13], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2464, buf2465, buf2466, buf2467, buf2468, 6912, 121, grid=grid(6912), stream=stream0)
        buf2469 = buf2458; del buf2458  # reuse
        buf2470 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2472 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_left_13], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2466, buf2467, buf2468, primals_1360, primals_1361, buf2469, buf2470, buf2472, primals_1360, primals_1361, 864, 8, grid=grid(864), stream=stream0)
        del primals_1360
        del primals_1361
        # Source Nodes: [x_973], Original ATen: [aten.convolution]
        buf2473 = extern_kernels.convolution(buf2424, primals_752, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2473, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2474 = reinterpret_tensor(buf2464, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2464  # reuse
        # Source Nodes: [x_973], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2473, buf2474, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_975], Original ATen: [aten.convolution]
        buf2475 = extern_kernels.convolution(buf2474, primals_753, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2475, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2476 = reinterpret_tensor(buf2473, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2473  # reuse
        buf2477 = buf2468; del buf2468  # reuse
        buf2478 = buf2467; del buf2467  # reuse
        buf2479 = buf2466; del buf2466  # reuse
        # Source Nodes: [x_975, x_976], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2475, buf2476, buf2477, buf2478, buf2479, 6912, 121, grid=grid(6912), stream=stream0)
        buf2480 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2481 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2483 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_976], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2477, buf2478, buf2479, primals_1363, primals_1364, buf2480, buf2481, buf2483, primals_1363, primals_1364, 864, 8, grid=grid(864), stream=stream0)
        del primals_1363
        del primals_1364
        buf2484 = reinterpret_tensor(buf2475, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2475  # reuse
        # Source Nodes: [x_976, x_977], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2476, buf2480, buf2481, primals_754, primals_755, buf2484, 836352, grid=grid(836352), stream=stream0)
        del primals_755
        # Source Nodes: [x_978], Original ATen: [aten.convolution]
        buf2485 = extern_kernels.convolution(buf2484, primals_756, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2485, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2486 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_978], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2485, buf2486, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_980], Original ATen: [aten.convolution]
        buf2487 = extern_kernels.convolution(buf2486, primals_757, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2487, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2488 = reinterpret_tensor(buf2485, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2485  # reuse
        buf2489 = buf2479; del buf2479  # reuse
        buf2490 = buf2478; del buf2478  # reuse
        buf2491 = buf2477; del buf2477  # reuse
        # Source Nodes: [x_980, x_comb_iter_2_right_13], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2487, buf2488, buf2489, buf2490, buf2491, 6912, 121, grid=grid(6912), stream=stream0)
        buf2492 = buf2481; del buf2481  # reuse
        buf2493 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2495 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_2_right_13], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2489, buf2490, buf2491, primals_1366, primals_1367, buf2492, buf2493, buf2495, primals_1366, primals_1367, 864, 8, grid=grid(864), stream=stream0)
        del primals_1366
        del primals_1367
        buf2496 = reinterpret_tensor(buf2548, (8, 864, 11, 11), (522720, 121, 11, 1), 209088)  # alias
        # Source Nodes: [x_comb_iter_2_left_13, x_comb_iter_2_right_13, x_comb_iter_67], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_121.run(buf2465, buf2469, buf2470, primals_750, primals_751, buf2488, buf2492, buf2493, primals_758, primals_759, buf2496, 968, 864, grid=grid(968, 864), stream=stream0)
        del primals_751
        del primals_759
        buf2497 = reinterpret_tensor(buf2487, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2487  # reuse
        # Source Nodes: [x_982], Original ATen: [aten.relu]
        triton_poi_fused_relu_122.run(buf2496, buf2497, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_983], Original ATen: [aten.convolution]
        buf2498 = extern_kernels.convolution(buf2497, primals_760, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2498, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2499 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_983], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2498, buf2499, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_985], Original ATen: [aten.convolution]
        buf2500 = extern_kernels.convolution(buf2499, primals_761, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2500, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2501 = reinterpret_tensor(buf2498, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2498  # reuse
        buf2502 = buf2491; del buf2491  # reuse
        buf2503 = buf2490; del buf2490  # reuse
        buf2504 = buf2489; del buf2489  # reuse
        # Source Nodes: [x_985, x_986], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2500, buf2501, buf2502, buf2503, buf2504, 6912, 121, grid=grid(6912), stream=stream0)
        buf2505 = buf2493; del buf2493  # reuse
        buf2506 = buf2470; del buf2470  # reuse
        buf2508 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_986], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2502, buf2503, buf2504, primals_1369, primals_1370, buf2505, buf2506, buf2508, primals_1369, primals_1370, 864, 8, grid=grid(864), stream=stream0)
        del primals_1369
        del primals_1370
        buf2509 = reinterpret_tensor(buf2500, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2500  # reuse
        # Source Nodes: [x_986, x_987], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_115.run(buf2501, buf2505, buf2506, primals_762, primals_763, buf2509, 836352, grid=grid(836352), stream=stream0)
        del primals_763
        # Source Nodes: [x_988], Original ATen: [aten.convolution]
        buf2510 = extern_kernels.convolution(buf2509, primals_764, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=864, bias=None)
        assert_size_stride(buf2510, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2511 = empty_strided((8, 864, 11, 11), (104544, 1, 9504, 864), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_988], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_112.run(buf2510, buf2511, 6912, 121, grid=grid(6912, 121), stream=stream0)
        # Source Nodes: [x_990], Original ATen: [aten.convolution]
        buf2512 = extern_kernels.convolution(buf2511, primals_765, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2512, (8, 864, 11, 11), (104544, 121, 11, 1))
        buf2513 = reinterpret_tensor(buf2510, (8, 864, 11, 11), (104544, 1, 9504, 864), 0); del buf2510  # reuse
        buf2514 = buf2504; del buf2504  # reuse
        buf2515 = buf2503; del buf2503  # reuse
        buf2516 = buf2502; del buf2502  # reuse
        # Source Nodes: [x_990, x_comb_iter_3_left_13], Original ATen: [aten._native_batch_norm_legit_functional, aten.convolution]
        triton_red_fused__native_batch_norm_legit_functional_convolution_113.run(buf2512, buf2513, buf2514, buf2515, buf2516, 6912, 121, grid=grid(6912), stream=stream0)
        del buf2512
        buf2517 = buf2506; del buf2506  # reuse
        buf2518 = empty_strided((1, 864, 1, 1), (864, 1, 864, 864), device='cuda', dtype=torch.float32)
        buf2520 = empty((864, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_comb_iter_3_left_13], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_114.run(buf2514, buf2515, buf2516, primals_1372, primals_1373, buf2517, buf2518, buf2520, primals_1372, primals_1373, 864, 8, grid=grid(864), stream=stream0)
        del buf2514
        del buf2515
        del buf2516
        del primals_1372
        del primals_1373
        buf2544 = reinterpret_tensor(buf2548, (8, 864, 11, 11), (522720, 121, 11, 1), 0)  # alias
        # Source Nodes: [x_comb_iter_0_left_13, x_comb_iter_65], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_135.run(buf2414, buf2418, buf2419, primals_734, primals_735, buf2422, buf2544, 6912, 121, grid=grid(6912, 121), stream=stream0)
        del buf2419
        del buf2422
        del primals_735
        buf2545 = reinterpret_tensor(buf2548, (8, 864, 11, 11), (522720, 121, 11, 1), 104544)  # alias
        buf2546 = reinterpret_tensor(buf2548, (8, 864, 11, 11), (522720, 121, 11, 1), 313632)  # alias
        # Source Nodes: [x_comb_iter_1_left_13, x_comb_iter_3_left_13, x_comb_iter_66, x_comb_iter_68], Original ATen: [aten._native_batch_norm_legit_functional, aten.add]
        triton_poi_fused__native_batch_norm_legit_functional_add_136.run(buf2440, buf2444, buf2445, primals_742, primals_743, buf2448, buf2513, buf2517, buf2518, primals_766, primals_767, buf2545, buf2546, 6912, 121, grid=grid(6912, 121), stream=stream0)
        del buf2445
        del buf2448
        del buf2518
        del primals_743
        del primals_767
        buf2549 = empty_strided((8, 4320, 1, 1), (4320, 1, 34560, 34560), device='cuda', dtype=torch.float32)
        buf2552 = empty_strided((8, 4320, 11, 11), (522720, 1, 47520, 4320), device='cuda', dtype=torch.bool)
        buf2550 = reinterpret_tensor(buf2549, (8, 4320), (4320, 1), 0); del buf2549  # reuse
        # Source Nodes: [x_1003, x_1004, x_1006], Original ATen: [aten.mean, aten.relu, aten.threshold_backward, aten.view]
        triton_per_fused_mean_relu_threshold_backward_view_137.run(buf2550, buf2548, buf2552, 34560, 121, grid=grid(34560), stream=stream0)
        del buf2496
        del buf2544
        del buf2545
        del buf2546
        del buf2547
        del buf2548
        buf2551 = empty((8, 1000), device='cuda', dtype=torch.float32)
        # Source Nodes: [pred], Original ATen: [aten.addmm]
        extern_kernels.addmm(primals_777, buf2550, reinterpret_tensor(primals_776, (4320, 1000), (1, 4320), 0), alpha=1, beta=1, out=buf2551)
        del primals_777
        # Source Nodes: [add_], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_778, primals_778, 1, grid=grid(1), stream=stream0)
        del primals_778
        # Source Nodes: [x_right], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_783, primals_783, 1, grid=grid(1), stream=stream0)
        del primals_783
        # Source Nodes: [x_14], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_786, primals_786, 1, grid=grid(1), stream=stream0)
        del primals_786
        # Source Nodes: [x_comb_iter_0_left], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_789, primals_789, 1, grid=grid(1), stream=stream0)
        del primals_789
        # Source Nodes: [x_comb_iter_0_right], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_792, primals_792, 1, grid=grid(1), stream=stream0)
        del primals_792
        # Source Nodes: [x_28], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_795, primals_795, 1, grid=grid(1), stream=stream0)
        del primals_795
        # Source Nodes: [x_comb_iter_1_left], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_798, primals_798, 1, grid=grid(1), stream=stream0)
        del primals_798
        # Source Nodes: [x_42], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_801, primals_801, 1, grid=grid(1), stream=stream0)
        del primals_801
        # Source Nodes: [x_comb_iter_2_left], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_804, primals_804, 1, grid=grid(1), stream=stream0)
        del primals_804
        # Source Nodes: [x_54], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_807, primals_807, 1, grid=grid(1), stream=stream0)
        del primals_807
        # Source Nodes: [x_comb_iter_2_right], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_810, primals_810, 1, grid=grid(1), stream=stream0)
        del primals_810
        # Source Nodes: [x_64], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_813, primals_813, 1, grid=grid(1), stream=stream0)
        del primals_813
        # Source Nodes: [x_comb_iter_3_left], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_816, primals_816, 1, grid=grid(1), stream=stream0)
        del primals_816
        # Source Nodes: [x_78], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_819, primals_819, 1, grid=grid(1), stream=stream0)
        del primals_819
        # Source Nodes: [x_comb_iter_4_left], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_822, primals_822, 1, grid=grid(1), stream=stream0)
        del primals_822
        # Source Nodes: [x_comb_iter_4_right], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_825, primals_825, 1, grid=grid(1), stream=stream0)
        del primals_825
        # Source Nodes: [x_left], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_828, primals_828, 1, grid=grid(1), stream=stream0)
        del primals_828
        # Source Nodes: [x_right_1], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_831, primals_831, 1, grid=grid(1), stream=stream0)
        del primals_831
        # Source Nodes: [x_99], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_834, primals_834, 1, grid=grid(1), stream=stream0)
        del primals_834
        # Source Nodes: [x_comb_iter_0_left_1], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_837, primals_837, 1, grid=grid(1), stream=stream0)
        del primals_837
        # Source Nodes: [x_113], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_840, primals_840, 1, grid=grid(1), stream=stream0)
        del primals_840
        # Source Nodes: [x_comb_iter_1_left_1], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_843, primals_843, 1, grid=grid(1), stream=stream0)
        del primals_843
        # Source Nodes: [x_127], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_846, primals_846, 1, grid=grid(1), stream=stream0)
        del primals_846
        # Source Nodes: [x_comb_iter_2_left_1], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_849, primals_849, 1, grid=grid(1), stream=stream0)
        del primals_849
        # Source Nodes: [x_139], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_852, primals_852, 1, grid=grid(1), stream=stream0)
        del primals_852
        # Source Nodes: [x_comb_iter_2_right_1], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_855, primals_855, 1, grid=grid(1), stream=stream0)
        del primals_855
        # Source Nodes: [x_149], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_858, primals_858, 1, grid=grid(1), stream=stream0)
        del primals_858
        # Source Nodes: [x_comb_iter_3_left_1], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_861, primals_861, 1, grid=grid(1), stream=stream0)
        del primals_861
        # Source Nodes: [x_163], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_864, primals_864, 1, grid=grid(1), stream=stream0)
        del primals_864
        # Source Nodes: [x_comb_iter_4_left_1], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_867, primals_867, 1, grid=grid(1), stream=stream0)
        del primals_867
        # Source Nodes: [x_comb_iter_4_right_1], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_870, primals_870, 1, grid=grid(1), stream=stream0)
        del primals_870
        # Source Nodes: [x_left_1], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_873, primals_873, 1, grid=grid(1), stream=stream0)
        del primals_873
        # Source Nodes: [x_comb_iter_4_right_2], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_876, primals_876, 1, grid=grid(1), stream=stream0)
        del primals_876
        # Source Nodes: [x_182], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_879, primals_879, 1, grid=grid(1), stream=stream0)
        del primals_879
        # Source Nodes: [x_comb_iter_0_left_2], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_882, primals_882, 1, grid=grid(1), stream=stream0)
        del primals_882
        # Source Nodes: [x_192], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_885, primals_885, 1, grid=grid(1), stream=stream0)
        del primals_885
        # Source Nodes: [x_comb_iter_1_left_2], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_888, primals_888, 1, grid=grid(1), stream=stream0)
        del primals_888
        # Source Nodes: [x_202], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_891, primals_891, 1, grid=grid(1), stream=stream0)
        del primals_891
        # Source Nodes: [x_comb_iter_2_left_2], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_894, primals_894, 1, grid=grid(1), stream=stream0)
        del primals_894
        # Source Nodes: [x_212], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_897, primals_897, 1, grid=grid(1), stream=stream0)
        del primals_897
        # Source Nodes: [x_comb_iter_2_right_2], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_900, primals_900, 1, grid=grid(1), stream=stream0)
        del primals_900
        # Source Nodes: [x_222], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_903, primals_903, 1, grid=grid(1), stream=stream0)
        del primals_903
        # Source Nodes: [x_comb_iter_3_left_2], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_906, primals_906, 1, grid=grid(1), stream=stream0)
        del primals_906
        # Source Nodes: [x_232], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_909, primals_909, 1, grid=grid(1), stream=stream0)
        del primals_909
        # Source Nodes: [x_comb_iter_4_left_2], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_912, primals_912, 1, grid=grid(1), stream=stream0)
        del primals_912
        # Source Nodes: [x_left_2], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_915, primals_915, 1, grid=grid(1), stream=stream0)
        del primals_915
        # Source Nodes: [x_comb_iter_4_right_3], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_918, primals_918, 1, grid=grid(1), stream=stream0)
        del primals_918
        # Source Nodes: [x_248], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_921, primals_921, 1, grid=grid(1), stream=stream0)
        del primals_921
        # Source Nodes: [x_comb_iter_0_left_3], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_924, primals_924, 1, grid=grid(1), stream=stream0)
        del primals_924
        # Source Nodes: [x_258], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_927, primals_927, 1, grid=grid(1), stream=stream0)
        del primals_927
        # Source Nodes: [x_comb_iter_1_left_3], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_930, primals_930, 1, grid=grid(1), stream=stream0)
        del primals_930
        # Source Nodes: [x_268], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_933, primals_933, 1, grid=grid(1), stream=stream0)
        del primals_933
        # Source Nodes: [x_comb_iter_2_left_3], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_936, primals_936, 1, grid=grid(1), stream=stream0)
        del primals_936
        # Source Nodes: [x_278], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_939, primals_939, 1, grid=grid(1), stream=stream0)
        del primals_939
        # Source Nodes: [x_comb_iter_2_right_3], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_942, primals_942, 1, grid=grid(1), stream=stream0)
        del primals_942
        # Source Nodes: [x_288], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_945, primals_945, 1, grid=grid(1), stream=stream0)
        del primals_945
        # Source Nodes: [x_comb_iter_3_left_3], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_948, primals_948, 1, grid=grid(1), stream=stream0)
        del primals_948
        # Source Nodes: [x_298], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_951, primals_951, 1, grid=grid(1), stream=stream0)
        del primals_951
        # Source Nodes: [x_comb_iter_4_left_3], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_954, primals_954, 1, grid=grid(1), stream=stream0)
        del primals_954
        # Source Nodes: [x_left_3], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_957, primals_957, 1, grid=grid(1), stream=stream0)
        del primals_957
        # Source Nodes: [x_comb_iter_4_right_4], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_960, primals_960, 1, grid=grid(1), stream=stream0)
        del primals_960
        # Source Nodes: [x_314], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_963, primals_963, 1, grid=grid(1), stream=stream0)
        del primals_963
        # Source Nodes: [x_comb_iter_0_left_4], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_966, primals_966, 1, grid=grid(1), stream=stream0)
        del primals_966
        # Source Nodes: [x_324], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_969, primals_969, 1, grid=grid(1), stream=stream0)
        del primals_969
        # Source Nodes: [x_comb_iter_1_left_4], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_972, primals_972, 1, grid=grid(1), stream=stream0)
        del primals_972
        # Source Nodes: [x_334], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_975, primals_975, 1, grid=grid(1), stream=stream0)
        del primals_975
        # Source Nodes: [x_comb_iter_2_left_4], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_978, primals_978, 1, grid=grid(1), stream=stream0)
        del primals_978
        # Source Nodes: [x_344], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_981, primals_981, 1, grid=grid(1), stream=stream0)
        del primals_981
        # Source Nodes: [x_comb_iter_2_right_4], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_984, primals_984, 1, grid=grid(1), stream=stream0)
        del primals_984
        # Source Nodes: [x_354], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_987, primals_987, 1, grid=grid(1), stream=stream0)
        del primals_987
        # Source Nodes: [x_comb_iter_3_left_4], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_990, primals_990, 1, grid=grid(1), stream=stream0)
        del primals_990
        # Source Nodes: [x_364], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_993, primals_993, 1, grid=grid(1), stream=stream0)
        del primals_993
        # Source Nodes: [x_comb_iter_4_left_4], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_996, primals_996, 1, grid=grid(1), stream=stream0)
        del primals_996
        # Source Nodes: [x_left_4], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_999, primals_999, 1, grid=grid(1), stream=stream0)
        del primals_999
        # Source Nodes: [x_comb_iter_4_right_5], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1002, primals_1002, 1, grid=grid(1), stream=stream0)
        del primals_1002
        # Source Nodes: [x_380], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1005, primals_1005, 1, grid=grid(1), stream=stream0)
        del primals_1005
        # Source Nodes: [x_comb_iter_0_left_5], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1008, primals_1008, 1, grid=grid(1), stream=stream0)
        del primals_1008
        # Source Nodes: [x_390], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1011, primals_1011, 1, grid=grid(1), stream=stream0)
        del primals_1011
        # Source Nodes: [x_comb_iter_1_left_5], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1014, primals_1014, 1, grid=grid(1), stream=stream0)
        del primals_1014
        # Source Nodes: [x_400], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1017, primals_1017, 1, grid=grid(1), stream=stream0)
        del primals_1017
        # Source Nodes: [x_comb_iter_2_left_5], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1020, primals_1020, 1, grid=grid(1), stream=stream0)
        del primals_1020
        # Source Nodes: [x_410], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1023, primals_1023, 1, grid=grid(1), stream=stream0)
        del primals_1023
        # Source Nodes: [x_comb_iter_2_right_5], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1026, primals_1026, 1, grid=grid(1), stream=stream0)
        del primals_1026
        # Source Nodes: [x_420], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1029, primals_1029, 1, grid=grid(1), stream=stream0)
        del primals_1029
        # Source Nodes: [x_comb_iter_3_left_5], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1032, primals_1032, 1, grid=grid(1), stream=stream0)
        del primals_1032
        # Source Nodes: [x_430], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1035, primals_1035, 1, grid=grid(1), stream=stream0)
        del primals_1035
        # Source Nodes: [x_comb_iter_4_left_5], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1038, primals_1038, 1, grid=grid(1), stream=stream0)
        del primals_1038
        # Source Nodes: [x_left_5], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1041, primals_1041, 1, grid=grid(1), stream=stream0)
        del primals_1041
        # Source Nodes: [x_right_6], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1044, primals_1044, 1, grid=grid(1), stream=stream0)
        del primals_1044
        # Source Nodes: [x_448], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1047, primals_1047, 1, grid=grid(1), stream=stream0)
        del primals_1047
        # Source Nodes: [x_comb_iter_0_left_6], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1050, primals_1050, 1, grid=grid(1), stream=stream0)
        del primals_1050
        # Source Nodes: [x_462], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1053, primals_1053, 1, grid=grid(1), stream=stream0)
        del primals_1053
        # Source Nodes: [x_comb_iter_1_left_6], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1056, primals_1056, 1, grid=grid(1), stream=stream0)
        del primals_1056
        # Source Nodes: [x_476], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1059, primals_1059, 1, grid=grid(1), stream=stream0)
        del primals_1059
        # Source Nodes: [x_comb_iter_2_left_6], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1062, primals_1062, 1, grid=grid(1), stream=stream0)
        del primals_1062
        # Source Nodes: [x_488], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1065, primals_1065, 1, grid=grid(1), stream=stream0)
        del primals_1065
        # Source Nodes: [x_comb_iter_2_right_6], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1068, primals_1068, 1, grid=grid(1), stream=stream0)
        del primals_1068
        # Source Nodes: [x_498], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1071, primals_1071, 1, grid=grid(1), stream=stream0)
        del primals_1071
        # Source Nodes: [x_comb_iter_3_left_6], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1074, primals_1074, 1, grid=grid(1), stream=stream0)
        del primals_1074
        # Source Nodes: [x_512], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1077, primals_1077, 1, grid=grid(1), stream=stream0)
        del primals_1077
        # Source Nodes: [x_comb_iter_4_left_6], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1080, primals_1080, 1, grid=grid(1), stream=stream0)
        del primals_1080
        # Source Nodes: [x_comb_iter_4_right_6], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1083, primals_1083, 1, grid=grid(1), stream=stream0)
        del primals_1083
        # Source Nodes: [x_left_6], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1086, primals_1086, 1, grid=grid(1), stream=stream0)
        del primals_1086
        # Source Nodes: [x_comb_iter_4_right_7], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1089, primals_1089, 1, grid=grid(1), stream=stream0)
        del primals_1089
        # Source Nodes: [x_531], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1092, primals_1092, 1, grid=grid(1), stream=stream0)
        del primals_1092
        # Source Nodes: [x_comb_iter_0_left_7], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1095, primals_1095, 1, grid=grid(1), stream=stream0)
        del primals_1095
        # Source Nodes: [x_541], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1098, primals_1098, 1, grid=grid(1), stream=stream0)
        del primals_1098
        # Source Nodes: [x_comb_iter_1_left_7], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1101, primals_1101, 1, grid=grid(1), stream=stream0)
        del primals_1101
        # Source Nodes: [x_551], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1104, primals_1104, 1, grid=grid(1), stream=stream0)
        del primals_1104
        # Source Nodes: [x_comb_iter_2_left_7], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1107, primals_1107, 1, grid=grid(1), stream=stream0)
        del primals_1107
        # Source Nodes: [x_561], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1110, primals_1110, 1, grid=grid(1), stream=stream0)
        del primals_1110
        # Source Nodes: [x_comb_iter_2_right_7], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1113, primals_1113, 1, grid=grid(1), stream=stream0)
        del primals_1113
        # Source Nodes: [x_571], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1116, primals_1116, 1, grid=grid(1), stream=stream0)
        del primals_1116
        # Source Nodes: [x_comb_iter_3_left_7], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1119, primals_1119, 1, grid=grid(1), stream=stream0)
        del primals_1119
        # Source Nodes: [x_581], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1122, primals_1122, 1, grid=grid(1), stream=stream0)
        del primals_1122
        # Source Nodes: [x_comb_iter_4_left_7], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1125, primals_1125, 1, grid=grid(1), stream=stream0)
        del primals_1125
        # Source Nodes: [x_left_7], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1128, primals_1128, 1, grid=grid(1), stream=stream0)
        del primals_1128
        # Source Nodes: [x_comb_iter_4_right_8], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1131, primals_1131, 1, grid=grid(1), stream=stream0)
        del primals_1131
        # Source Nodes: [x_597], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1134, primals_1134, 1, grid=grid(1), stream=stream0)
        del primals_1134
        # Source Nodes: [x_comb_iter_0_left_8], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1137, primals_1137, 1, grid=grid(1), stream=stream0)
        del primals_1137
        # Source Nodes: [x_607], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1140, primals_1140, 1, grid=grid(1), stream=stream0)
        del primals_1140
        # Source Nodes: [x_comb_iter_1_left_8], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1143, primals_1143, 1, grid=grid(1), stream=stream0)
        del primals_1143
        # Source Nodes: [x_617], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1146, primals_1146, 1, grid=grid(1), stream=stream0)
        del primals_1146
        # Source Nodes: [x_comb_iter_2_left_8], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1149, primals_1149, 1, grid=grid(1), stream=stream0)
        del primals_1149
        # Source Nodes: [x_627], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1152, primals_1152, 1, grid=grid(1), stream=stream0)
        del primals_1152
        # Source Nodes: [x_comb_iter_2_right_8], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1155, primals_1155, 1, grid=grid(1), stream=stream0)
        del primals_1155
        # Source Nodes: [x_637], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1158, primals_1158, 1, grid=grid(1), stream=stream0)
        del primals_1158
        # Source Nodes: [x_comb_iter_3_left_8], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1161, primals_1161, 1, grid=grid(1), stream=stream0)
        del primals_1161
        # Source Nodes: [x_647], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1164, primals_1164, 1, grid=grid(1), stream=stream0)
        del primals_1164
        # Source Nodes: [x_comb_iter_4_left_8], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1167, primals_1167, 1, grid=grid(1), stream=stream0)
        del primals_1167
        # Source Nodes: [x_left_8], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1170, primals_1170, 1, grid=grid(1), stream=stream0)
        del primals_1170
        # Source Nodes: [x_comb_iter_4_right_9], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1173, primals_1173, 1, grid=grid(1), stream=stream0)
        del primals_1173
        # Source Nodes: [x_663], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1176, primals_1176, 1, grid=grid(1), stream=stream0)
        del primals_1176
        # Source Nodes: [x_comb_iter_0_left_9], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1179, primals_1179, 1, grid=grid(1), stream=stream0)
        del primals_1179
        # Source Nodes: [x_673], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1182, primals_1182, 1, grid=grid(1), stream=stream0)
        del primals_1182
        # Source Nodes: [x_comb_iter_1_left_9], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1185, primals_1185, 1, grid=grid(1), stream=stream0)
        del primals_1185
        # Source Nodes: [x_683], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1188, primals_1188, 1, grid=grid(1), stream=stream0)
        del primals_1188
        # Source Nodes: [x_comb_iter_2_left_9], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1191, primals_1191, 1, grid=grid(1), stream=stream0)
        del primals_1191
        # Source Nodes: [x_693], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1194, primals_1194, 1, grid=grid(1), stream=stream0)
        del primals_1194
        # Source Nodes: [x_comb_iter_2_right_9], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1197, primals_1197, 1, grid=grid(1), stream=stream0)
        del primals_1197
        # Source Nodes: [x_703], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1200, primals_1200, 1, grid=grid(1), stream=stream0)
        del primals_1200
        # Source Nodes: [x_comb_iter_3_left_9], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1203, primals_1203, 1, grid=grid(1), stream=stream0)
        del primals_1203
        # Source Nodes: [x_713], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1206, primals_1206, 1, grid=grid(1), stream=stream0)
        del primals_1206
        # Source Nodes: [x_comb_iter_4_left_9], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1209, primals_1209, 1, grid=grid(1), stream=stream0)
        del primals_1209
        # Source Nodes: [x_left_9], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1212, primals_1212, 1, grid=grid(1), stream=stream0)
        del primals_1212
        # Source Nodes: [x_right_10], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1215, primals_1215, 1, grid=grid(1), stream=stream0)
        del primals_1215
        # Source Nodes: [x_731], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1218, primals_1218, 1, grid=grid(1), stream=stream0)
        del primals_1218
        # Source Nodes: [x_comb_iter_0_left_10], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1221, primals_1221, 1, grid=grid(1), stream=stream0)
        del primals_1221
        # Source Nodes: [x_745], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1224, primals_1224, 1, grid=grid(1), stream=stream0)
        del primals_1224
        # Source Nodes: [x_comb_iter_1_left_10], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1227, primals_1227, 1, grid=grid(1), stream=stream0)
        del primals_1227
        # Source Nodes: [x_759], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1230, primals_1230, 1, grid=grid(1), stream=stream0)
        del primals_1230
        # Source Nodes: [x_comb_iter_2_left_10], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1233, primals_1233, 1, grid=grid(1), stream=stream0)
        del primals_1233
        # Source Nodes: [x_771], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1236, primals_1236, 1, grid=grid(1), stream=stream0)
        del primals_1236
        # Source Nodes: [x_comb_iter_2_right_10], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1239, primals_1239, 1, grid=grid(1), stream=stream0)
        del primals_1239
        # Source Nodes: [x_781], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1242, primals_1242, 1, grid=grid(1), stream=stream0)
        del primals_1242
        # Source Nodes: [x_comb_iter_3_left_10], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1245, primals_1245, 1, grid=grid(1), stream=stream0)
        del primals_1245
        # Source Nodes: [x_795], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1248, primals_1248, 1, grid=grid(1), stream=stream0)
        del primals_1248
        # Source Nodes: [x_comb_iter_4_left_10], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1251, primals_1251, 1, grid=grid(1), stream=stream0)
        del primals_1251
        # Source Nodes: [x_comb_iter_4_right_10], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1254, primals_1254, 1, grid=grid(1), stream=stream0)
        del primals_1254
        # Source Nodes: [x_left_10], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1257, primals_1257, 1, grid=grid(1), stream=stream0)
        del primals_1257
        # Source Nodes: [x_comb_iter_4_right_11], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1260, primals_1260, 1, grid=grid(1), stream=stream0)
        del primals_1260
        # Source Nodes: [x_814], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1263, primals_1263, 1, grid=grid(1), stream=stream0)
        del primals_1263
        # Source Nodes: [x_comb_iter_0_left_11], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1266, primals_1266, 1, grid=grid(1), stream=stream0)
        del primals_1266
        # Source Nodes: [x_824], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1269, primals_1269, 1, grid=grid(1), stream=stream0)
        del primals_1269
        # Source Nodes: [x_comb_iter_1_left_11], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1272, primals_1272, 1, grid=grid(1), stream=stream0)
        del primals_1272
        # Source Nodes: [x_834], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1275, primals_1275, 1, grid=grid(1), stream=stream0)
        del primals_1275
        # Source Nodes: [x_comb_iter_2_left_11], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1278, primals_1278, 1, grid=grid(1), stream=stream0)
        del primals_1278
        # Source Nodes: [x_844], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1281, primals_1281, 1, grid=grid(1), stream=stream0)
        del primals_1281
        # Source Nodes: [x_comb_iter_2_right_11], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1284, primals_1284, 1, grid=grid(1), stream=stream0)
        del primals_1284
        # Source Nodes: [x_854], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1287, primals_1287, 1, grid=grid(1), stream=stream0)
        del primals_1287
        # Source Nodes: [x_comb_iter_3_left_11], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1290, primals_1290, 1, grid=grid(1), stream=stream0)
        del primals_1290
        # Source Nodes: [x_864], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1293, primals_1293, 1, grid=grid(1), stream=stream0)
        del primals_1293
        # Source Nodes: [x_comb_iter_4_left_11], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1296, primals_1296, 1, grid=grid(1), stream=stream0)
        del primals_1296
        # Source Nodes: [x_left_11], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1299, primals_1299, 1, grid=grid(1), stream=stream0)
        del primals_1299
        # Source Nodes: [x_comb_iter_4_right_12], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1302, primals_1302, 1, grid=grid(1), stream=stream0)
        del primals_1302
        # Source Nodes: [x_880], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1305, primals_1305, 1, grid=grid(1), stream=stream0)
        del primals_1305
        # Source Nodes: [x_comb_iter_0_left_12], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1308, primals_1308, 1, grid=grid(1), stream=stream0)
        del primals_1308
        # Source Nodes: [x_890], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1311, primals_1311, 1, grid=grid(1), stream=stream0)
        del primals_1311
        # Source Nodes: [x_comb_iter_1_left_12], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1314, primals_1314, 1, grid=grid(1), stream=stream0)
        del primals_1314
        # Source Nodes: [x_900], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1317, primals_1317, 1, grid=grid(1), stream=stream0)
        del primals_1317
        # Source Nodes: [x_comb_iter_2_left_12], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1320, primals_1320, 1, grid=grid(1), stream=stream0)
        del primals_1320
        # Source Nodes: [x_910], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1323, primals_1323, 1, grid=grid(1), stream=stream0)
        del primals_1323
        # Source Nodes: [x_comb_iter_2_right_12], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1326, primals_1326, 1, grid=grid(1), stream=stream0)
        del primals_1326
        # Source Nodes: [x_920], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1329, primals_1329, 1, grid=grid(1), stream=stream0)
        del primals_1329
        # Source Nodes: [x_comb_iter_3_left_12], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1332, primals_1332, 1, grid=grid(1), stream=stream0)
        del primals_1332
        # Source Nodes: [x_930], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1335, primals_1335, 1, grid=grid(1), stream=stream0)
        del primals_1335
        # Source Nodes: [x_comb_iter_4_left_12], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1338, primals_1338, 1, grid=grid(1), stream=stream0)
        del primals_1338
        # Source Nodes: [x_left_12], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1341, primals_1341, 1, grid=grid(1), stream=stream0)
        del primals_1341
        # Source Nodes: [x_comb_iter_4_right_13], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1344, primals_1344, 1, grid=grid(1), stream=stream0)
        del primals_1344
        # Source Nodes: [x_946], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1347, primals_1347, 1, grid=grid(1), stream=stream0)
        del primals_1347
        # Source Nodes: [x_comb_iter_0_left_13], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1350, primals_1350, 1, grid=grid(1), stream=stream0)
        del primals_1350
        # Source Nodes: [x_956], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1353, primals_1353, 1, grid=grid(1), stream=stream0)
        del primals_1353
        # Source Nodes: [x_comb_iter_1_left_13], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1356, primals_1356, 1, grid=grid(1), stream=stream0)
        del primals_1356
        # Source Nodes: [x_966], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1359, primals_1359, 1, grid=grid(1), stream=stream0)
        del primals_1359
        # Source Nodes: [x_comb_iter_2_left_13], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1362, primals_1362, 1, grid=grid(1), stream=stream0)
        del primals_1362
        # Source Nodes: [x_976], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1365, primals_1365, 1, grid=grid(1), stream=stream0)
        del primals_1365
        # Source Nodes: [x_comb_iter_2_right_13], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1368, primals_1368, 1, grid=grid(1), stream=stream0)
        del primals_1368
        # Source Nodes: [x_986], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1371, primals_1371, 1, grid=grid(1), stream=stream0)
        del primals_1371
        # Source Nodes: [x_comb_iter_3_left_13], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1374, primals_1374, 1, grid=grid(1), stream=stream0)
        del primals_1374
        # Source Nodes: [x_996], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1377, primals_1377, 1, grid=grid(1), stream=stream0)
        del primals_1377
        # Source Nodes: [x_comb_iter_4_left_13], Original ATen: [aten.add]
        triton_poi_fused_add_138.run(primals_1380, primals_1380, 1, grid=grid(1), stream=stream0)
        del primals_1380
        return (buf2551, primals_1, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, buf0, primals_28, primals_29, primals_31, primals_32, primals_34, primals_35, primals_36, primals_38, primals_39, primals_41, primals_42, primals_44, primals_45, primals_46, primals_48, primals_49, primals_51, primals_52, primals_53, primals_55, primals_56, primals_58, primals_59, primals_60, primals_62, primals_63, primals_64, primals_66, primals_67, primals_68, primals_70, primals_71, primals_73, primals_74, primals_75, primals_77, primals_79, primals_80, primals_81, primals_83, primals_84, primals_86, primals_87, primals_89, primals_90, primals_91, primals_93, primals_94, primals_96, primals_97, primals_98, primals_100, primals_101, primals_103, primals_104, primals_105, primals_107, primals_108, primals_110, primals_111, primals_112, primals_114, primals_115, primals_116, primals_118, primals_119, primals_120, primals_122, primals_123, primals_125, primals_126, primals_127, primals_129, primals_131, primals_132, primals_133, primals_135, primals_136, primals_138, primals_139, primals_140, primals_142, primals_143, primals_144, primals_146, primals_147, primals_148, primals_150, primals_151, primals_152, primals_154, primals_155, primals_156, primals_158, primals_159, primals_160, primals_162, primals_163, primals_164, primals_166, primals_167, primals_168, primals_170, primals_171, primals_172, primals_174, primals_175, primals_176, primals_178, primals_179, primals_180, primals_182, primals_183, primals_184, primals_186, primals_187, primals_189, primals_190, primals_192, primals_193, primals_194, primals_196, primals_197, primals_198, primals_200, primals_201, primals_202, primals_204, primals_205, primals_206, primals_208, primals_209, primals_210, primals_212, primals_213, primals_214, primals_216, primals_217, primals_218, primals_220, primals_221, primals_222, primals_224, primals_225, primals_226, primals_228, primals_229, primals_230, primals_232, primals_233, primals_234, primals_236, primals_237, primals_238, primals_240, primals_241, primals_243, primals_244, primals_246, primals_247, primals_248, primals_250, primals_251, primals_252, primals_254, primals_255, primals_256, primals_258, primals_259, primals_260, primals_262, primals_263, primals_264, primals_266, primals_267, primals_268, primals_270, primals_271, primals_272, primals_274, primals_275, primals_276, primals_278, primals_279, primals_280, primals_282, primals_283, primals_284, primals_286, primals_287, primals_288, primals_290, primals_291, primals_292, primals_294, primals_295, primals_297, primals_298, primals_300, primals_301, primals_302, primals_304, primals_305, primals_306, primals_308, primals_309, primals_310, primals_312, primals_313, primals_314, primals_316, primals_317, primals_318, primals_320, primals_321, primals_322, primals_324, primals_325, primals_326, primals_328, primals_329, primals_330, primals_332, primals_333, primals_334, primals_336, primals_337, primals_338, primals_340, primals_341, primals_342, primals_344, primals_345, primals_346, primals_348, primals_349, primals_351, primals_352, primals_354, primals_355, primals_357, primals_358, primals_359, primals_361, primals_362, primals_364, primals_365, primals_366, primals_368, primals_369, primals_371, primals_372, primals_373, primals_375, primals_376, primals_378, primals_379, primals_380, primals_382, primals_383, primals_384, primals_386, primals_387, primals_388, primals_390, primals_391, primals_393, primals_394, primals_395, primals_397, primals_399, primals_400, primals_401, primals_403, primals_404, primals_406, primals_407, primals_408, primals_410, primals_411, primals_412, primals_414, primals_415, primals_416, primals_418, primals_419, primals_420, primals_422, primals_423, primals_424, primals_426, primals_427, primals_428, primals_430, primals_431, primals_432, primals_434, primals_435, primals_436, primals_438, primals_439, primals_440, primals_442, primals_443, primals_444, primals_446, primals_447, primals_448, primals_450, primals_451, primals_452, primals_454, primals_455, primals_457, primals_458, primals_460, primals_461, primals_462, primals_464, primals_465, primals_466, primals_468, primals_469, primals_470, primals_472, primals_473, primals_474, primals_476, primals_477, primals_478, primals_480, primals_481, primals_482, primals_484, primals_485, primals_486, primals_488, primals_489, primals_490, primals_492, primals_493, primals_494, primals_496, primals_497, primals_498, primals_500, primals_501, primals_502, primals_504, primals_505, primals_506, primals_508, primals_509, primals_511, primals_512, primals_514, primals_515, primals_516, primals_518, primals_519, primals_520, primals_522, primals_523, primals_524, primals_526, primals_527, primals_528, primals_530, primals_531, primals_532, primals_534, primals_535, primals_536, primals_538, primals_539, primals_540, primals_542, primals_543, primals_544, primals_546, primals_547, primals_548, primals_550, primals_551, primals_552, primals_554, primals_555, primals_556, primals_558, primals_559, primals_560, primals_562, primals_563, primals_565, primals_566, primals_568, primals_569, primals_571, primals_572, primals_573, primals_575, primals_576, primals_578, primals_579, primals_580, primals_582, primals_583, primals_585, primals_586, primals_587, primals_589, primals_590, primals_592, primals_593, primals_594, primals_596, primals_597, primals_598, primals_600, primals_601, primals_602, primals_604, primals_605, primals_607, primals_608, primals_609, primals_611, primals_613, primals_614, primals_615, primals_617, primals_618, primals_620, primals_621, primals_622, primals_624, primals_625, primals_626, primals_628, primals_629, primals_630, primals_632, primals_633, primals_634, primals_636, primals_637, primals_638, primals_640, primals_641, primals_642, primals_644, primals_645, primals_646, primals_648, primals_649, primals_650, primals_652, primals_653, primals_654, primals_656, primals_657, primals_658, primals_660, primals_661, primals_662, primals_664, primals_665, primals_666, primals_668, primals_669, primals_671, primals_672, primals_674, primals_675, primals_676, primals_678, primals_679, primals_680, primals_682, primals_683, primals_684, primals_686, primals_687, primals_688, primals_690, primals_691, primals_692, primals_694, primals_695, primals_696, primals_698, primals_699, primals_700, primals_702, primals_703, primals_704, primals_706, primals_707, primals_708, primals_710, primals_711, primals_712, primals_714, primals_715, primals_716, primals_718, primals_719, primals_720, primals_722, primals_723, primals_725, primals_726, primals_728, primals_729, primals_730, primals_732, primals_733, primals_734, primals_736, primals_737, primals_738, primals_740, primals_741, primals_742, primals_744, primals_745, primals_746, primals_748, primals_749, primals_750, primals_752, primals_753, primals_754, primals_756, primals_757, primals_758, primals_760, primals_761, primals_762, primals_764, primals_765, primals_766, primals_768, primals_769, primals_770, primals_772, primals_773, primals_774, buf1, buf3, buf13, buf15, buf17, buf27, buf29, buf31, buf33, buf43, buf44, buf46, buf48, buf58, buf59, buf60, buf61, buf63, buf73, buf76, buf78, buf80, buf90, buf91, buf93, buf95, buf105, buf106, buf108, buf109, buf111, buf113, buf123, buf124, buf126, buf128, buf138, buf139, buf141, buf143, buf153, buf154, buf156, buf158, buf168, buf170, buf172, buf174, buf184, buf185, buf187, buf189, buf199, buf200, buf202, buf204, buf214, buf215, buf217, buf219, buf229, buf75, buf231, buf241, buf246, buf248, buf249, buf251, buf261, buf263, buf265, buf275, buf277, buf279, buf281, buf288, buf289, buf291, buf293, buf300, buf301, buf303, buf305, buf307, buf309, buf316, buf317, buf319, buf321, buf328, buf329, buf331, buf332, buf334, buf336, buf343, buf344, buf346, buf348, buf355, buf356, buf358, buf360, buf367, buf368, buf370, buf372, buf379, buf381, buf383, buf385, buf392, buf393, buf395, buf397, buf404, buf405, buf407, buf409, buf416, buf417, buf419, buf421, buf428, buf304, buf430, buf437, buf443, buf445, buf446, buf448, buf455, buf456, buf457, buf459, buf466, buf467, buf468, buf470, buf472, buf479, buf480, buf482, buf484, buf491, buf493, buf494, buf496, buf498, buf505, buf506, buf508, buf510, buf517, buf519, buf521, buf523, buf530, buf531, buf533, buf535, buf542, buf544, buf546, buf553, buf554, buf556, buf558, buf565, buf567, buf569, buf571, buf578, buf579, buf581, buf583, buf590, buf592, buf594, buf601, buf602, buf604, buf606, buf613, buf620, buf627, buf628, buf629, buf631, buf638, buf639, buf640, buf642, buf644, buf651, buf652, buf654, buf656, buf663, buf665, buf666, buf668, buf670, buf677, buf678, buf680, buf682, buf689, buf691, buf693, buf695, buf702, buf703, buf705, buf707, buf714, buf716, buf718, buf725, buf726, buf728, buf730, buf737, buf739, buf741, buf743, buf750, buf751, buf753, buf755, buf762, buf764, buf766, buf773, buf774, buf776, buf778, buf785, buf792, buf799, buf800, buf801, buf803, buf810, buf811, buf812, buf814, buf816, buf823, buf824, buf826, buf828, buf835, buf837, buf838, buf840, buf842, buf849, buf850, buf852, buf854, buf861, buf863, buf865, buf867, buf874, buf875, buf877, buf879, buf886, buf888, buf890, buf897, buf898, buf900, buf902, buf909, buf911, buf913, buf915, buf922, buf923, buf925, buf927, buf934, buf936, buf938, buf945, buf946, buf948, buf950, buf957, buf964, buf971, buf972, buf973, buf975, buf982, buf983, buf984, buf986, buf988, buf995, buf996, buf998, buf1000, buf1007, buf1009, buf1010, buf1012, buf1014, buf1021, buf1022, buf1024, buf1026, buf1033, buf1035, buf1037, buf1039, buf1046, buf1047, buf1049, buf1051, buf1058, buf1060, buf1062, buf1069, buf1070, buf1072, buf1074, buf1081, buf1083, buf1085, buf1087, buf1094, buf1095, buf1097, buf1099, buf1106, buf1108, buf1110, buf1117, buf1118, buf1120, buf1122, buf1129, buf1136, buf1143, buf1145, buf1147, buf1154, buf1156, buf1158, buf1160, buf1167, buf1168, buf1170, buf1172, buf1179, buf1180, buf1182, buf1184, buf1186, buf1188, buf1195, buf1196, buf1198, buf1200, buf1207, buf1208, buf1210, buf1211, buf1213, buf1215, buf1222, buf1223, buf1225, buf1227, buf1234, buf1235, buf1237, buf1239, buf1246, buf1247, buf1249, buf1251, buf1258, buf1260, buf1262, buf1264, buf1271, buf1272, buf1274, buf1276, buf1283, buf1284, buf1286, buf1288, buf1295, buf1296, buf1298, buf1300, buf1307, buf1183, buf1309, buf1316, buf1322, buf1324, buf1325, buf1327, buf1334, buf1335, buf1336, buf1338, buf1345, buf1346, buf1347, buf1349, buf1351, buf1358, buf1359, buf1361, buf1363, buf1370, buf1372, buf1373, buf1375, buf1377, buf1384, buf1385, buf1387, buf1389, buf1396, buf1398, buf1400, buf1402, buf1409, buf1410, buf1412, buf1414, buf1421, buf1423, buf1425, buf1432, buf1433, buf1435, buf1437, buf1444, buf1446, buf1448, buf1450, buf1457, buf1458, buf1460, buf1462, buf1469, buf1471, buf1473, buf1480, buf1481, buf1483, buf1485, buf1492, buf1499, buf1506, buf1507, buf1508, buf1510, buf1517, buf1518, buf1519, buf1521, buf1523, buf1530, buf1531, buf1533, buf1535, buf1542, buf1544, buf1545, buf1547, buf1549, buf1556, buf1557, buf1559, buf1561, buf1568, buf1570, buf1572, buf1574, buf1581, buf1582, buf1584, buf1586, buf1593, buf1595, buf1597, buf1604, buf1605, buf1607, buf1609, buf1616, buf1618, buf1620, buf1622, buf1629, buf1630, buf1632, buf1634, buf1641, buf1643, buf1645, buf1652, buf1653, buf1655, buf1657, buf1664, buf1671, buf1678, buf1679, buf1680, buf1682, buf1689, buf1690, buf1691, buf1693, buf1695, buf1702, buf1703, buf1705, buf1707, buf1714, buf1716, buf1717, buf1719, buf1721, buf1728, buf1729, buf1731, buf1733, buf1740, buf1742, buf1744, buf1746, buf1753, buf1754, buf1756, buf1758, buf1765, buf1767, buf1769, buf1776, buf1777, buf1779, buf1781, buf1788, buf1790, buf1792, buf1794, buf1801, buf1802, buf1804, buf1806, buf1813, buf1815, buf1817, buf1824, buf1825, buf1827, buf1829, buf1836, buf1843, buf1850, buf1852, buf1854, buf1861, buf1863, buf1865, buf1867, buf1874, buf1875, buf1877, buf1879, buf1886, buf1887, buf1889, buf1891, buf1893, buf1895, buf1902, buf1903, buf1905, buf1907, buf1914, buf1915, buf1917, buf1918, buf1920, buf1922, buf1929, buf1930, buf1932, buf1934, buf1941, buf1942, buf1944, buf1946, buf1953, buf1954, buf1956, buf1958, buf1965, buf1967, buf1969, buf1971, buf1978, buf1979, buf1981, buf1983, buf1990, buf1991, buf1993, buf1995, buf2002, buf2003, buf2005, buf2007, buf2014, buf1890, buf2016, buf2023, buf2029, buf2031, buf2032, buf2034, buf2041, buf2042, buf2043, buf2045, buf2052, buf2053, buf2054, buf2056, buf2058, buf2065, buf2066, buf2068, buf2070, buf2077, buf2079, buf2080, buf2082, buf2084, buf2091, buf2092, buf2094, buf2096, buf2103, buf2105, buf2107, buf2109, buf2116, buf2117, buf2119, buf2121, buf2128, buf2130, buf2132, buf2139, buf2140, buf2142, buf2144, buf2151, buf2153, buf2155, buf2157, buf2164, buf2165, buf2167, buf2169, buf2176, buf2178, buf2180, buf2187, buf2188, buf2190, buf2192, buf2199, buf2206, buf2213, buf2214, buf2215, buf2217, buf2224, buf2225, buf2226, buf2228, buf2230, buf2237, buf2238, buf2240, buf2242, buf2249, buf2251, buf2252, buf2254, buf2256, buf2263, buf2264, buf2266, buf2268, buf2275, buf2277, buf2279, buf2281, buf2288, buf2289, buf2291, buf2293, buf2300, buf2302, buf2304, buf2311, buf2312, buf2314, buf2316, buf2323, buf2325, buf2327, buf2329, buf2336, buf2337, buf2339, buf2341, buf2348, buf2350, buf2352, buf2359, buf2360, buf2362, buf2364, buf2371, buf2378, buf2385, buf2386, buf2387, buf2389, buf2396, buf2397, buf2398, buf2400, buf2402, buf2409, buf2410, buf2412, buf2414, buf2421, buf2423, buf2424, buf2426, buf2428, buf2435, buf2436, buf2438, buf2440, buf2447, buf2449, buf2451, buf2453, buf2460, buf2461, buf2463, buf2465, buf2472, buf2474, buf2476, buf2483, buf2484, buf2486, buf2488, buf2495, buf2497, buf2499, buf2501, buf2508, buf2509, buf2511, buf2513, buf2520, buf2522, buf2524, buf2531, buf2532, buf2534, buf2536, buf2543, buf2550, reinterpret_tensor(primals_776, (1000, 4320), (4320, 1), 0), buf2552, reinterpret_tensor(buf2540, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2528, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2517, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2505, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2492, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2480, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2469, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2457, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2444, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2432, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2418, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2406, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2393, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2382, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2368, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2356, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2345, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2333, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2320, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2308, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2297, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2285, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2272, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2260, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2246, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2234, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2221, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2210, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2196, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2184, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2173, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2161, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2148, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2136, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2125, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2113, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2100, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2088, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2074, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2062, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2049, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2038, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf2020, (1, 864, 1, 1), (864, 1, 1, 1), 0), buf2553, reinterpret_tensor(buf2011, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf1999, (1, 864, 1, 1), (864, 1, 1, 1), 0), buf2554, reinterpret_tensor(buf1987, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf1975, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf1962, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf1950, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf1938, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf1926, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf1911, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf1899, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf1883, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf1871, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf1858, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf1847, (1, 864, 1, 1), (864, 1, 1, 1), 0), reinterpret_tensor(buf1833, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1821, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1810, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1798, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1785, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1773, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1762, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1750, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1737, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1725, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1711, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1699, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1686, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1675, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1661, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1649, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1638, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1626, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1613, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1601, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1590, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1578, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1565, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1553, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1539, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1527, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1514, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1503, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1489, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1477, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1466, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1454, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1441, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1429, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1418, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1406, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1393, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1381, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1367, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1355, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1342, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1331, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1313, (1, 432, 1, 1), (432, 1, 1, 1), 0), buf2555, reinterpret_tensor(buf1304, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1292, (1, 432, 1, 1), (432, 1, 1, 1), 0), buf2556, reinterpret_tensor(buf1280, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1268, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1255, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1243, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1231, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1219, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1204, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1192, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1176, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1164, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1151, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1140, (1, 432, 1, 1), (432, 1, 1, 1), 0), reinterpret_tensor(buf1126, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf1114, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf1103, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf1091, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf1078, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf1066, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf1055, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf1043, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf1030, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf1018, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf1004, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf992, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf979, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf968, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf954, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf942, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf931, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf919, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf906, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf894, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf883, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf871, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf858, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf846, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf832, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf820, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf807, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf796, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf782, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf770, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf759, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf747, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf734, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf722, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf711, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf699, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf686, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf674, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf660, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf648, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf635, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf624, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf610, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf598, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf587, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf575, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf562, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf550, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf539, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf527, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf514, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf502, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf488, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf476, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf463, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf452, (1, 216, 1, 1), (216, 1, 1, 1), 0), reinterpret_tensor(buf434, (1, 108, 1, 1), (108, 1, 1, 1), 0), buf2557, reinterpret_tensor(buf425, (1, 108, 1, 1), (108, 1, 1, 1), 0), reinterpret_tensor(buf413, (1, 108, 1, 1), (108, 1, 1, 1), 0), buf2558, reinterpret_tensor(buf401, (1, 108, 1, 1), (108, 1, 1, 1), 0), reinterpret_tensor(buf389, (1, 108, 1, 1), (108, 1, 1, 1), 0), reinterpret_tensor(buf376, (1, 108, 1, 1), (108, 1, 1, 1), 0), reinterpret_tensor(buf364, (1, 108, 1, 1), (108, 1, 1, 1), 0), reinterpret_tensor(buf352, (1, 108, 1, 1), (108, 1, 1, 1), 0), reinterpret_tensor(buf340, (1, 108, 1, 1), (108, 1, 1, 1), 0), reinterpret_tensor(buf325, (1, 108, 1, 1), (108, 1, 1, 1), 0), reinterpret_tensor(buf313, (1, 108, 1, 1), (108, 1, 1, 1), 0), reinterpret_tensor(buf297, (1, 108, 1, 1), (108, 1, 1, 1), 0), reinterpret_tensor(buf285, (1, 108, 1, 1), (108, 1, 1, 1), 0), reinterpret_tensor(buf272, (1, 108, 1, 1), (108, 1, 1, 1), 0), reinterpret_tensor(buf258, (1, 108, 1, 1), (108, 1, 1, 1), 0), reinterpret_tensor(buf238, (1, 54, 1, 1), (54, 1, 1, 1), 0), buf2559, reinterpret_tensor(buf226, (1, 54, 1, 1), (54, 1, 1, 1), 0), reinterpret_tensor(buf211, (1, 54, 1, 1), (54, 1, 1, 1), 0), reinterpret_tensor(buf196, (1, 54, 1, 1), (54, 1, 1, 1), 0), reinterpret_tensor(buf181, (1, 54, 1, 1), (54, 1, 1, 1), 0), reinterpret_tensor(buf165, (1, 54, 1, 1), (54, 1, 1, 1), 0), reinterpret_tensor(buf150, (1, 54, 1, 1), (54, 1, 1, 1), 0), reinterpret_tensor(buf135, (1, 54, 1, 1), (54, 1, 1, 1), 0), reinterpret_tensor(buf120, (1, 54, 1, 1), (54, 1, 1, 1), 0), reinterpret_tensor(buf102, (1, 54, 1, 1), (54, 1, 1, 1), 0), reinterpret_tensor(buf87, (1, 54, 1, 1), (54, 1, 1, 1), 0), reinterpret_tensor(buf70, (1, 54, 1, 1), (54, 1, 1, 1), 0), reinterpret_tensor(buf55, (1, 54, 1, 1), (54, 1, 1, 1), 0), reinterpret_tensor(buf40, (1, 54, 1, 1), (54, 1, 1, 1), 0), reinterpret_tensor(buf24, (1, 54, 1, 1), (54, 1, 1, 1), 0), reinterpret_tensor(buf10, (1, 96, 1, 1), (96, 1, 1, 1), 0), )


def benchmark_compiled_module(times=10, repeat=10):
    from torch._dynamo.testing import rand_strided
    from torch._inductor.utils import print_performance
    primals_1 = rand_strided((96, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_2 = rand_strided((96, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_3 = rand_strided((96, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_4 = rand_strided((54, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_5 = rand_strided((54, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_6 = rand_strided((54, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_7 = rand_strided((96, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_8 = rand_strided((54, 54, 1, 1), (54, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_9 = rand_strided((108, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_10 = rand_strided((108, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_11 = rand_strided((108, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_12 = rand_strided((108, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_13 = rand_strided((108, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_14 = rand_strided((108, 108, 1, 1), (108, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_15 = rand_strided((432, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_16 = rand_strided((432, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_17 = rand_strided((432, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_18 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_19 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_20 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_21 = rand_strided((864, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_22 = rand_strided((864, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_23 = rand_strided((864, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_24 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_25 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_26 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_27 = rand_strided((96, 3, 3, 3), (27, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_28 = rand_strided((54, 96, 1, 1), (96, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_29 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_30 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_31 = rand_strided((54, 96, 1, 1), (96, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_32 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_33 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_34 = rand_strided((54, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_35 = rand_strided((54, 54, 1, 1), (54, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_36 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_37 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_38 = rand_strided((54, 96, 1, 1), (96, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_39 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_40 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_41 = rand_strided((54, 54, 1, 1), (54, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_42 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_43 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_44 = rand_strided((54, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_45 = rand_strided((54, 54, 1, 1), (54, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_46 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_47 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_48 = rand_strided((54, 54, 1, 1), (54, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_49 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_50 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_51 = rand_strided((54, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_52 = rand_strided((54, 54, 1, 1), (54, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_53 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_54 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_55 = rand_strided((54, 54, 1, 1), (54, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_56 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_57 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_58 = rand_strided((54, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_59 = rand_strided((54, 54, 1, 1), (54, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_60 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_61 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_62 = rand_strided((54, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_63 = rand_strided((54, 54, 1, 1), (54, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_64 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_65 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_66 = rand_strided((54, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_67 = rand_strided((54, 54, 1, 1), (54, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_68 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_69 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_70 = rand_strided((54, 96, 1, 1), (96, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_71 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_72 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_73 = rand_strided((54, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_74 = rand_strided((54, 54, 1, 1), (54, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_75 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_76 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_77 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_78 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_79 = rand_strided((54, 96, 1, 1), (96, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_80 = rand_strided((54, 96, 1, 1), (96, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_81 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_82 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_83 = rand_strided((108, 270, 1, 1), (270, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_84 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_85 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_86 = rand_strided((108, 108, 1, 1), (108, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_87 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_88 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_89 = rand_strided((108, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_90 = rand_strided((108, 108, 1, 1), (108, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_91 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_92 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_93 = rand_strided((108, 108, 1, 1), (108, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_94 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_95 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_96 = rand_strided((108, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_97 = rand_strided((108, 108, 1, 1), (108, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_98 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_99 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_100 = rand_strided((108, 108, 1, 1), (108, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_101 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_102 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_103 = rand_strided((108, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_104 = rand_strided((108, 108, 1, 1), (108, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_105 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_106 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_107 = rand_strided((108, 108, 1, 1), (108, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_108 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_109 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_110 = rand_strided((108, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_111 = rand_strided((108, 108, 1, 1), (108, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_112 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_113 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_114 = rand_strided((108, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_115 = rand_strided((108, 108, 1, 1), (108, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_116 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_117 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_118 = rand_strided((108, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_119 = rand_strided((108, 108, 1, 1), (108, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_120 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_121 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_122 = rand_strided((108, 108, 1, 1), (108, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_123 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_124 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_125 = rand_strided((108, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_126 = rand_strided((108, 108, 1, 1), (108, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_127 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_128 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_129 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_130 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_131 = rand_strided((108, 270, 1, 1), (270, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_132 = rand_strided((108, 270, 1, 1), (270, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_133 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_134 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_135 = rand_strided((216, 540, 1, 1), (540, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_136 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_137 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_138 = rand_strided((216, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_139 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_140 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_141 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_142 = rand_strided((216, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_143 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_144 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_145 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_146 = rand_strided((216, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_147 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_148 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_149 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_150 = rand_strided((216, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_151 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_152 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_153 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_154 = rand_strided((216, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_155 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_156 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_157 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_158 = rand_strided((216, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_159 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_160 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_161 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_162 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_163 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_164 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_165 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_166 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_167 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_168 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_169 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_170 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_171 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_172 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_173 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_174 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_175 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_176 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_177 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_178 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_179 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_180 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_181 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_182 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_183 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_184 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_185 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_186 = rand_strided((216, 540, 1, 1), (540, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_187 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_188 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_189 = rand_strided((216, 1080, 1, 1), (1080, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_190 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_191 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_192 = rand_strided((216, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_193 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_194 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_195 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_196 = rand_strided((216, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_197 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_198 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_199 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_200 = rand_strided((216, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_201 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_202 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_203 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_204 = rand_strided((216, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_205 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_206 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_207 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_208 = rand_strided((216, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_209 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_210 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_211 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_212 = rand_strided((216, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_213 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_214 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_215 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_216 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_217 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_218 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_219 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_220 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_221 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_222 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_223 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_224 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_225 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_226 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_227 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_228 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_229 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_230 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_231 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_232 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_233 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_234 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_235 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_236 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_237 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_238 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_239 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_240 = rand_strided((216, 1080, 1, 1), (1080, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_241 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_242 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_243 = rand_strided((216, 1080, 1, 1), (1080, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_244 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_245 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_246 = rand_strided((216, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_247 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_248 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_249 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_250 = rand_strided((216, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_251 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_252 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_253 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_254 = rand_strided((216, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_255 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_256 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_257 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_258 = rand_strided((216, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_259 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_260 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_261 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_262 = rand_strided((216, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_263 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_264 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_265 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_266 = rand_strided((216, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_267 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_268 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_269 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_270 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_271 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_272 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_273 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_274 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_275 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_276 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_277 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_278 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_279 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_280 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_281 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_282 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_283 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_284 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_285 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_286 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_287 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_288 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_289 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_290 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_291 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_292 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_293 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_294 = rand_strided((216, 1080, 1, 1), (1080, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_295 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_296 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_297 = rand_strided((216, 1080, 1, 1), (1080, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_298 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_299 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_300 = rand_strided((216, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_301 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_302 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_303 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_304 = rand_strided((216, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_305 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_306 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_307 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_308 = rand_strided((216, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_309 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_310 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_311 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_312 = rand_strided((216, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_313 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_314 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_315 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_316 = rand_strided((216, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_317 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_318 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_319 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_320 = rand_strided((216, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_321 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_322 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_323 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_324 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_325 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_326 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_327 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_328 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_329 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_330 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_331 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_332 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_333 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_334 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_335 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_336 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_337 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_338 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_339 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_340 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_341 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_342 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_343 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_344 = rand_strided((216, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_345 = rand_strided((216, 216, 1, 1), (216, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_346 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_347 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_348 = rand_strided((432, 1080, 1, 1), (1080, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_349 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_350 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_351 = rand_strided((432, 1080, 1, 1), (1080, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_352 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_353 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_354 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_355 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_356 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_357 = rand_strided((432, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_358 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_359 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_360 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_361 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_362 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_363 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_364 = rand_strided((432, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_365 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_366 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_367 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_368 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_369 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_370 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_371 = rand_strided((432, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_372 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_373 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_374 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_375 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_376 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_377 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_378 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_379 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_380 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_381 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_382 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_383 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_384 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_385 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_386 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_387 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_388 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_389 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_390 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_391 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_392 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_393 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_394 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_395 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_396 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_397 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_398 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_399 = rand_strided((216, 1080, 1, 1), (1080, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_400 = rand_strided((216, 1080, 1, 1), (1080, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_401 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_402 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_403 = rand_strided((432, 2160, 1, 1), (2160, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_404 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_405 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_406 = rand_strided((432, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_407 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_408 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_409 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_410 = rand_strided((432, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_411 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_412 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_413 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_414 = rand_strided((432, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_415 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_416 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_417 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_418 = rand_strided((432, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_419 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_420 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_421 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_422 = rand_strided((432, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_423 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_424 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_425 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_426 = rand_strided((432, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_427 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_428 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_429 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_430 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_431 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_432 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_433 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_434 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_435 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_436 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_437 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_438 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_439 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_440 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_441 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_442 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_443 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_444 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_445 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_446 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_447 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_448 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_449 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_450 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_451 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_452 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_453 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_454 = rand_strided((432, 2160, 1, 1), (2160, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_455 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_456 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_457 = rand_strided((432, 2160, 1, 1), (2160, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_458 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_459 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_460 = rand_strided((432, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_461 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_462 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_463 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_464 = rand_strided((432, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_465 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_466 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_467 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_468 = rand_strided((432, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_469 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_470 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_471 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_472 = rand_strided((432, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_473 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_474 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_475 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_476 = rand_strided((432, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_477 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_478 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_479 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_480 = rand_strided((432, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_481 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_482 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_483 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_484 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_485 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_486 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_487 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_488 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_489 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_490 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_491 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_492 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_493 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_494 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_495 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_496 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_497 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_498 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_499 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_500 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_501 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_502 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_503 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_504 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_505 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_506 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_507 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_508 = rand_strided((432, 2160, 1, 1), (2160, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_509 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_510 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_511 = rand_strided((432, 2160, 1, 1), (2160, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_512 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_513 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_514 = rand_strided((432, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_515 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_516 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_517 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_518 = rand_strided((432, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_519 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_520 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_521 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_522 = rand_strided((432, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_523 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_524 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_525 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_526 = rand_strided((432, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_527 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_528 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_529 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_530 = rand_strided((432, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_531 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_532 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_533 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_534 = rand_strided((432, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_535 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_536 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_537 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_538 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_539 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_540 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_541 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_542 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_543 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_544 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_545 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_546 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_547 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_548 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_549 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_550 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_551 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_552 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_553 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_554 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_555 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_556 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_557 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_558 = rand_strided((432, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_559 = rand_strided((432, 432, 1, 1), (432, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_560 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_561 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_562 = rand_strided((864, 2160, 1, 1), (2160, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_563 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_564 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_565 = rand_strided((864, 2160, 1, 1), (2160, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_566 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_567 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_568 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_569 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_570 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_571 = rand_strided((864, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_572 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_573 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_574 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_575 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_576 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_577 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_578 = rand_strided((864, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_579 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_580 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_581 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_582 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_583 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_584 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_585 = rand_strided((864, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_586 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_587 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_588 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_589 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_590 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_591 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_592 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_593 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_594 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_595 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_596 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_597 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_598 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_599 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_600 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_601 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_602 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_603 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_604 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_605 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_606 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_607 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_608 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_609 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_610 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_611 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_612 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_613 = rand_strided((432, 2160, 1, 1), (2160, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_614 = rand_strided((432, 2160, 1, 1), (2160, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_615 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_616 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_617 = rand_strided((864, 4320, 1, 1), (4320, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_618 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_619 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_620 = rand_strided((864, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_621 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_622 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_623 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_624 = rand_strided((864, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_625 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_626 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_627 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_628 = rand_strided((864, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_629 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_630 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_631 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_632 = rand_strided((864, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_633 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_634 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_635 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_636 = rand_strided((864, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_637 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_638 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_639 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_640 = rand_strided((864, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_641 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_642 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_643 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_644 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_645 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_646 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_647 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_648 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_649 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_650 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_651 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_652 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_653 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_654 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_655 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_656 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_657 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_658 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_659 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_660 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_661 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_662 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_663 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_664 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_665 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_666 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_667 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_668 = rand_strided((864, 4320, 1, 1), (4320, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_669 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_670 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_671 = rand_strided((864, 4320, 1, 1), (4320, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_672 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_673 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_674 = rand_strided((864, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_675 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_676 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_677 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_678 = rand_strided((864, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_679 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_680 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_681 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_682 = rand_strided((864, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_683 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_684 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_685 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_686 = rand_strided((864, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_687 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_688 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_689 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_690 = rand_strided((864, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_691 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_692 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_693 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_694 = rand_strided((864, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_695 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_696 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_697 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_698 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_699 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_700 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_701 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_702 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_703 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_704 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_705 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_706 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_707 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_708 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_709 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_710 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_711 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_712 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_713 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_714 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_715 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_716 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_717 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_718 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_719 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_720 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_721 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_722 = rand_strided((864, 4320, 1, 1), (4320, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_723 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_724 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_725 = rand_strided((864, 4320, 1, 1), (4320, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_726 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_727 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_728 = rand_strided((864, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_729 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_730 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_731 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_732 = rand_strided((864, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_733 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_734 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_735 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_736 = rand_strided((864, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_737 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_738 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_739 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_740 = rand_strided((864, 1, 7, 7), (49, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    primals_741 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_742 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_743 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_744 = rand_strided((864, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_745 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_746 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_747 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_748 = rand_strided((864, 1, 5, 5), (25, 25, 5, 1), device='cuda:0', dtype=torch.float32)
    primals_749 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_750 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_751 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_752 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_753 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_754 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_755 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_756 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_757 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_758 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_759 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_760 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_761 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_762 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_763 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_764 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_765 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_766 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_767 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_768 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_769 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_770 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_771 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_772 = rand_strided((864, 1, 3, 3), (9, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_773 = rand_strided((864, 864, 1, 1), (864, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_774 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_775 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_776 = rand_strided((1000, 4320), (4320, 1), device='cuda:0', dtype=torch.float32)
    primals_777 = rand_strided((1000, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_778 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_779 = rand_strided((96, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_780 = rand_strided((96, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_781 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_782 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_783 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_784 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_785 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_786 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_787 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_788 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_789 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_790 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_791 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_792 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_793 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_794 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_795 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_796 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_797 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_798 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_799 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_800 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_801 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_802 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_803 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_804 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_805 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_806 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_807 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_808 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_809 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_810 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_811 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_812 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_813 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_814 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_815 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_816 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_817 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_818 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_819 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_820 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_821 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_822 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_823 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_824 = rand_strided((54, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_825 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_826 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_827 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_828 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_829 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_830 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_831 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_832 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_833 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_834 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_835 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_836 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_837 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_838 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_839 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_840 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_841 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_842 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_843 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_844 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_845 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_846 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_847 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_848 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_849 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_850 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_851 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_852 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_853 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_854 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_855 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_856 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_857 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_858 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_859 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_860 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_861 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_862 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_863 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_864 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_865 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_866 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_867 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_868 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_869 = rand_strided((108, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_870 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_871 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_872 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_873 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_874 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_875 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_876 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_877 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_878 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_879 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_880 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_881 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_882 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_883 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_884 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_885 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_886 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_887 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_888 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_889 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_890 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_891 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_892 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_893 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_894 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_895 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_896 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_897 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_898 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_899 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_900 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_901 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_902 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_903 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_904 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_905 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_906 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_907 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_908 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_909 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_910 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_911 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_912 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_913 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_914 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_915 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_916 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_917 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_918 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_919 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_920 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_921 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_922 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_923 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_924 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_925 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_926 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_927 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_928 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_929 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_930 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_931 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_932 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_933 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_934 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_935 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_936 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_937 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_938 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_939 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_940 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_941 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_942 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_943 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_944 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_945 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_946 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_947 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_948 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_949 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_950 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_951 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_952 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_953 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_954 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_955 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_956 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_957 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_958 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_959 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_960 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_961 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_962 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_963 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_964 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_965 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_966 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_967 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_968 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_969 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_970 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_971 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_972 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_973 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_974 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_975 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_976 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_977 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_978 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_979 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_980 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_981 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_982 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_983 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_984 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_985 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_986 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_987 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_988 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_989 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_990 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_991 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_992 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_993 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_994 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_995 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_996 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_997 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_998 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_999 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1000 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1001 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1002 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1003 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1004 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1005 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1006 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1007 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1008 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1009 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1010 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1011 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1012 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1013 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1014 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1015 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1016 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1017 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1018 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1019 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1020 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1021 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1022 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1023 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1024 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1025 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1026 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1027 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1028 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1029 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1030 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1031 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1032 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1033 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1034 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1035 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1036 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1037 = rand_strided((216, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1038 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1039 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1040 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1041 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1042 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1043 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1044 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1045 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1046 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1047 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1048 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1049 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1050 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1051 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1052 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1053 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1054 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1055 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1056 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1057 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1058 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1059 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1060 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1061 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1062 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1063 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1064 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1065 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1066 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1067 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1068 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1069 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1070 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1071 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1072 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1073 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1074 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1075 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1076 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1077 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1078 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1079 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1080 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1081 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1082 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1083 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1084 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1085 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1086 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1087 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1088 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1089 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1090 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1091 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1092 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1093 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1094 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1095 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1096 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1097 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1098 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1099 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1100 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1101 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1102 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1103 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1104 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1105 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1106 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1107 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1108 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1109 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1110 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1111 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1112 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1113 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1114 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1115 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1116 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1117 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1118 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1119 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1120 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1121 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1122 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1123 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1124 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1125 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1126 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1127 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1128 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1129 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1130 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1131 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1132 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1133 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1134 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1135 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1136 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1137 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1138 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1139 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1140 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1141 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1142 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1143 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1144 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1145 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1146 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1147 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1148 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1149 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1150 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1151 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1152 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1153 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1154 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1155 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1156 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1157 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1158 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1159 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1160 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1161 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1162 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1163 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1164 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1165 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1166 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1167 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1168 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1169 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1170 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1171 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1172 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1173 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1174 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1175 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1176 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1177 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1178 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1179 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1180 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1181 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1182 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1183 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1184 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1185 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1186 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1187 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1188 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1189 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1190 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1191 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1192 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1193 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1194 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1195 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1196 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1197 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1198 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1199 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1200 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1201 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1202 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1203 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1204 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1205 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1206 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1207 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1208 = rand_strided((432, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1209 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1210 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1211 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1212 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1213 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1214 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1215 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1216 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1217 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1218 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1219 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1220 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1221 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1222 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1223 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1224 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1225 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1226 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1227 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1228 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1229 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1230 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1231 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1232 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1233 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1234 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1235 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1236 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1237 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1238 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1239 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1240 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1241 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1242 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1243 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1244 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1245 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1246 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1247 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1248 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1249 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1250 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1251 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1252 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1253 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1254 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1255 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1256 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1257 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1258 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1259 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1260 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1261 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1262 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1263 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1264 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1265 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1266 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1267 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1268 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1269 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1270 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1271 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1272 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1273 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1274 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1275 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1276 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1277 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1278 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1279 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1280 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1281 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1282 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1283 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1284 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1285 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1286 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1287 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1288 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1289 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1290 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1291 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1292 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1293 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1294 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1295 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1296 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1297 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1298 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1299 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1300 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1301 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1302 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1303 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1304 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1305 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1306 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1307 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1308 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1309 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1310 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1311 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1312 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1313 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1314 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1315 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1316 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1317 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1318 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1319 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1320 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1321 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1322 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1323 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1324 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1325 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1326 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1327 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1328 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1329 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1330 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1331 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1332 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1333 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1334 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1335 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1336 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1337 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1338 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1339 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1340 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1341 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1342 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1343 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1344 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1345 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1346 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1347 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1348 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1349 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1350 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1351 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1352 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1353 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1354 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1355 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1356 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1357 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1358 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1359 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1360 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1361 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1362 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1363 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1364 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1365 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1366 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1367 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1368 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1369 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1370 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1371 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1372 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1373 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1374 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1375 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1376 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1377 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1378 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1379 = rand_strided((864, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1380 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1381 = rand_strided((8, 3, 331, 331), (328683, 109561, 331, 1), device='cuda:0', dtype=torch.float32)
    return print_performance(lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190, primals_191, primals_192, primals_193, primals_194, primals_195, primals_196, primals_197, primals_198, primals_199, primals_200, primals_201, primals_202, primals_203, primals_204, primals_205, primals_206, primals_207, primals_208, primals_209, primals_210, primals_211, primals_212, primals_213, primals_214, primals_215, primals_216, primals_217, primals_218, primals_219, primals_220, primals_221, primals_222, primals_223, primals_224, primals_225, primals_226, primals_227, primals_228, primals_229, primals_230, primals_231, primals_232, primals_233, primals_234, primals_235, primals_236, primals_237, primals_238, primals_239, primals_240, primals_241, primals_242, primals_243, primals_244, primals_245, primals_246, primals_247, primals_248, primals_249, primals_250, primals_251, primals_252, primals_253, primals_254, primals_255, primals_256, primals_257, primals_258, primals_259, primals_260, primals_261, primals_262, primals_263, primals_264, primals_265, primals_266, primals_267, primals_268, primals_269, primals_270, primals_271, primals_272, primals_273, primals_274, primals_275, primals_276, primals_277, primals_278, primals_279, primals_280, primals_281, primals_282, primals_283, primals_284, primals_285, primals_286, primals_287, primals_288, primals_289, primals_290, primals_291, primals_292, primals_293, primals_294, primals_295, primals_296, primals_297, primals_298, primals_299, primals_300, primals_301, primals_302, primals_303, primals_304, primals_305, primals_306, primals_307, primals_308, primals_309, primals_310, primals_311, primals_312, primals_313, primals_314, primals_315, primals_316, primals_317, primals_318, primals_319, primals_320, primals_321, primals_322, primals_323, primals_324, primals_325, primals_326, primals_327, primals_328, primals_329, primals_330, primals_331, primals_332, primals_333, primals_334, primals_335, primals_336, primals_337, primals_338, primals_339, primals_340, primals_341, primals_342, primals_343, primals_344, primals_345, primals_346, primals_347, primals_348, primals_349, primals_350, primals_351, primals_352, primals_353, primals_354, primals_355, primals_356, primals_357, primals_358, primals_359, primals_360, primals_361, primals_362, primals_363, primals_364, primals_365, primals_366, primals_367, primals_368, primals_369, primals_370, primals_371, primals_372, primals_373, primals_374, primals_375, primals_376, primals_377, primals_378, primals_379, primals_380, primals_381, primals_382, primals_383, primals_384, primals_385, primals_386, primals_387, primals_388, primals_389, primals_390, primals_391, primals_392, primals_393, primals_394, primals_395, primals_396, primals_397, primals_398, primals_399, primals_400, primals_401, primals_402, primals_403, primals_404, primals_405, primals_406, primals_407, primals_408, primals_409, primals_410, primals_411, primals_412, primals_413, primals_414, primals_415, primals_416, primals_417, primals_418, primals_419, primals_420, primals_421, primals_422, primals_423, primals_424, primals_425, primals_426, primals_427, primals_428, primals_429, primals_430, primals_431, primals_432, primals_433, primals_434, primals_435, primals_436, primals_437, primals_438, primals_439, primals_440, primals_441, primals_442, primals_443, primals_444, primals_445, primals_446, primals_447, primals_448, primals_449, primals_450, primals_451, primals_452, primals_453, primals_454, primals_455, primals_456, primals_457, primals_458, primals_459, primals_460, primals_461, primals_462, primals_463, primals_464, primals_465, primals_466, primals_467, primals_468, primals_469, primals_470, primals_471, primals_472, primals_473, primals_474, primals_475, primals_476, primals_477, primals_478, primals_479, primals_480, primals_481, primals_482, primals_483, primals_484, primals_485, primals_486, primals_487, primals_488, primals_489, primals_490, primals_491, primals_492, primals_493, primals_494, primals_495, primals_496, primals_497, primals_498, primals_499, primals_500, primals_501, primals_502, primals_503, primals_504, primals_505, primals_506, primals_507, primals_508, primals_509, primals_510, primals_511, primals_512, primals_513, primals_514, primals_515, primals_516, primals_517, primals_518, primals_519, primals_520, primals_521, primals_522, primals_523, primals_524, primals_525, primals_526, primals_527, primals_528, primals_529, primals_530, primals_531, primals_532, primals_533, primals_534, primals_535, primals_536, primals_537, primals_538, primals_539, primals_540, primals_541, primals_542, primals_543, primals_544, primals_545, primals_546, primals_547, primals_548, primals_549, primals_550, primals_551, primals_552, primals_553, primals_554, primals_555, primals_556, primals_557, primals_558, primals_559, primals_560, primals_561, primals_562, primals_563, primals_564, primals_565, primals_566, primals_567, primals_568, primals_569, primals_570, primals_571, primals_572, primals_573, primals_574, primals_575, primals_576, primals_577, primals_578, primals_579, primals_580, primals_581, primals_582, primals_583, primals_584, primals_585, primals_586, primals_587, primals_588, primals_589, primals_590, primals_591, primals_592, primals_593, primals_594, primals_595, primals_596, primals_597, primals_598, primals_599, primals_600, primals_601, primals_602, primals_603, primals_604, primals_605, primals_606, primals_607, primals_608, primals_609, primals_610, primals_611, primals_612, primals_613, primals_614, primals_615, primals_616, primals_617, primals_618, primals_619, primals_620, primals_621, primals_622, primals_623, primals_624, primals_625, primals_626, primals_627, primals_628, primals_629, primals_630, primals_631, primals_632, primals_633, primals_634, primals_635, primals_636, primals_637, primals_638, primals_639, primals_640, primals_641, primals_642, primals_643, primals_644, primals_645, primals_646, primals_647, primals_648, primals_649, primals_650, primals_651, primals_652, primals_653, primals_654, primals_655, primals_656, primals_657, primals_658, primals_659, primals_660, primals_661, primals_662, primals_663, primals_664, primals_665, primals_666, primals_667, primals_668, primals_669, primals_670, primals_671, primals_672, primals_673, primals_674, primals_675, primals_676, primals_677, primals_678, primals_679, primals_680, primals_681, primals_682, primals_683, primals_684, primals_685, primals_686, primals_687, primals_688, primals_689, primals_690, primals_691, primals_692, primals_693, primals_694, primals_695, primals_696, primals_697, primals_698, primals_699, primals_700, primals_701, primals_702, primals_703, primals_704, primals_705, primals_706, primals_707, primals_708, primals_709, primals_710, primals_711, primals_712, primals_713, primals_714, primals_715, primals_716, primals_717, primals_718, primals_719, primals_720, primals_721, primals_722, primals_723, primals_724, primals_725, primals_726, primals_727, primals_728, primals_729, primals_730, primals_731, primals_732, primals_733, primals_734, primals_735, primals_736, primals_737, primals_738, primals_739, primals_740, primals_741, primals_742, primals_743, primals_744, primals_745, primals_746, primals_747, primals_748, primals_749, primals_750, primals_751, primals_752, primals_753, primals_754, primals_755, primals_756, primals_757, primals_758, primals_759, primals_760, primals_761, primals_762, primals_763, primals_764, primals_765, primals_766, primals_767, primals_768, primals_769, primals_770, primals_771, primals_772, primals_773, primals_774, primals_775, primals_776, primals_777, primals_778, primals_779, primals_780, primals_781, primals_782, primals_783, primals_784, primals_785, primals_786, primals_787, primals_788, primals_789, primals_790, primals_791, primals_792, primals_793, primals_794, primals_795, primals_796, primals_797, primals_798, primals_799, primals_800, primals_801, primals_802, primals_803, primals_804, primals_805, primals_806, primals_807, primals_808, primals_809, primals_810, primals_811, primals_812, primals_813, primals_814, primals_815, primals_816, primals_817, primals_818, primals_819, primals_820, primals_821, primals_822, primals_823, primals_824, primals_825, primals_826, primals_827, primals_828, primals_829, primals_830, primals_831, primals_832, primals_833, primals_834, primals_835, primals_836, primals_837, primals_838, primals_839, primals_840, primals_841, primals_842, primals_843, primals_844, primals_845, primals_846, primals_847, primals_848, primals_849, primals_850, primals_851, primals_852, primals_853, primals_854, primals_855, primals_856, primals_857, primals_858, primals_859, primals_860, primals_861, primals_862, primals_863, primals_864, primals_865, primals_866, primals_867, primals_868, primals_869, primals_870, primals_871, primals_872, primals_873, primals_874, primals_875, primals_876, primals_877, primals_878, primals_879, primals_880, primals_881, primals_882, primals_883, primals_884, primals_885, primals_886, primals_887, primals_888, primals_889, primals_890, primals_891, primals_892, primals_893, primals_894, primals_895, primals_896, primals_897, primals_898, primals_899, primals_900, primals_901, primals_902, primals_903, primals_904, primals_905, primals_906, primals_907, primals_908, primals_909, primals_910, primals_911, primals_912, primals_913, primals_914, primals_915, primals_916, primals_917, primals_918, primals_919, primals_920, primals_921, primals_922, primals_923, primals_924, primals_925, primals_926, primals_927, primals_928, primals_929, primals_930, primals_931, primals_932, primals_933, primals_934, primals_935, primals_936, primals_937, primals_938, primals_939, primals_940, primals_941, primals_942, primals_943, primals_944, primals_945, primals_946, primals_947, primals_948, primals_949, primals_950, primals_951, primals_952, primals_953, primals_954, primals_955, primals_956, primals_957, primals_958, primals_959, primals_960, primals_961, primals_962, primals_963, primals_964, primals_965, primals_966, primals_967, primals_968, primals_969, primals_970, primals_971, primals_972, primals_973, primals_974, primals_975, primals_976, primals_977, primals_978, primals_979, primals_980, primals_981, primals_982, primals_983, primals_984, primals_985, primals_986, primals_987, primals_988, primals_989, primals_990, primals_991, primals_992, primals_993, primals_994, primals_995, primals_996, primals_997, primals_998, primals_999, primals_1000, primals_1001, primals_1002, primals_1003, primals_1004, primals_1005, primals_1006, primals_1007, primals_1008, primals_1009, primals_1010, primals_1011, primals_1012, primals_1013, primals_1014, primals_1015, primals_1016, primals_1017, primals_1018, primals_1019, primals_1020, primals_1021, primals_1022, primals_1023, primals_1024, primals_1025, primals_1026, primals_1027, primals_1028, primals_1029, primals_1030, primals_1031, primals_1032, primals_1033, primals_1034, primals_1035, primals_1036, primals_1037, primals_1038, primals_1039, primals_1040, primals_1041, primals_1042, primals_1043, primals_1044, primals_1045, primals_1046, primals_1047, primals_1048, primals_1049, primals_1050, primals_1051, primals_1052, primals_1053, primals_1054, primals_1055, primals_1056, primals_1057, primals_1058, primals_1059, primals_1060, primals_1061, primals_1062, primals_1063, primals_1064, primals_1065, primals_1066, primals_1067, primals_1068, primals_1069, primals_1070, primals_1071, primals_1072, primals_1073, primals_1074, primals_1075, primals_1076, primals_1077, primals_1078, primals_1079, primals_1080, primals_1081, primals_1082, primals_1083, primals_1084, primals_1085, primals_1086, primals_1087, primals_1088, primals_1089, primals_1090, primals_1091, primals_1092, primals_1093, primals_1094, primals_1095, primals_1096, primals_1097, primals_1098, primals_1099, primals_1100, primals_1101, primals_1102, primals_1103, primals_1104, primals_1105, primals_1106, primals_1107, primals_1108, primals_1109, primals_1110, primals_1111, primals_1112, primals_1113, primals_1114, primals_1115, primals_1116, primals_1117, primals_1118, primals_1119, primals_1120, primals_1121, primals_1122, primals_1123, primals_1124, primals_1125, primals_1126, primals_1127, primals_1128, primals_1129, primals_1130, primals_1131, primals_1132, primals_1133, primals_1134, primals_1135, primals_1136, primals_1137, primals_1138, primals_1139, primals_1140, primals_1141, primals_1142, primals_1143, primals_1144, primals_1145, primals_1146, primals_1147, primals_1148, primals_1149, primals_1150, primals_1151, primals_1152, primals_1153, primals_1154, primals_1155, primals_1156, primals_1157, primals_1158, primals_1159, primals_1160, primals_1161, primals_1162, primals_1163, primals_1164, primals_1165, primals_1166, primals_1167, primals_1168, primals_1169, primals_1170, primals_1171, primals_1172, primals_1173, primals_1174, primals_1175, primals_1176, primals_1177, primals_1178, primals_1179, primals_1180, primals_1181, primals_1182, primals_1183, primals_1184, primals_1185, primals_1186, primals_1187, primals_1188, primals_1189, primals_1190, primals_1191, primals_1192, primals_1193, primals_1194, primals_1195, primals_1196, primals_1197, primals_1198, primals_1199, primals_1200, primals_1201, primals_1202, primals_1203, primals_1204, primals_1205, primals_1206, primals_1207, primals_1208, primals_1209, primals_1210, primals_1211, primals_1212, primals_1213, primals_1214, primals_1215, primals_1216, primals_1217, primals_1218, primals_1219, primals_1220, primals_1221, primals_1222, primals_1223, primals_1224, primals_1225, primals_1226, primals_1227, primals_1228, primals_1229, primals_1230, primals_1231, primals_1232, primals_1233, primals_1234, primals_1235, primals_1236, primals_1237, primals_1238, primals_1239, primals_1240, primals_1241, primals_1242, primals_1243, primals_1244, primals_1245, primals_1246, primals_1247, primals_1248, primals_1249, primals_1250, primals_1251, primals_1252, primals_1253, primals_1254, primals_1255, primals_1256, primals_1257, primals_1258, primals_1259, primals_1260, primals_1261, primals_1262, primals_1263, primals_1264, primals_1265, primals_1266, primals_1267, primals_1268, primals_1269, primals_1270, primals_1271, primals_1272, primals_1273, primals_1274, primals_1275, primals_1276, primals_1277, primals_1278, primals_1279, primals_1280, primals_1281, primals_1282, primals_1283, primals_1284, primals_1285, primals_1286, primals_1287, primals_1288, primals_1289, primals_1290, primals_1291, primals_1292, primals_1293, primals_1294, primals_1295, primals_1296, primals_1297, primals_1298, primals_1299, primals_1300, primals_1301, primals_1302, primals_1303, primals_1304, primals_1305, primals_1306, primals_1307, primals_1308, primals_1309, primals_1310, primals_1311, primals_1312, primals_1313, primals_1314, primals_1315, primals_1316, primals_1317, primals_1318, primals_1319, primals_1320, primals_1321, primals_1322, primals_1323, primals_1324, primals_1325, primals_1326, primals_1327, primals_1328, primals_1329, primals_1330, primals_1331, primals_1332, primals_1333, primals_1334, primals_1335, primals_1336, primals_1337, primals_1338, primals_1339, primals_1340, primals_1341, primals_1342, primals_1343, primals_1344, primals_1345, primals_1346, primals_1347, primals_1348, primals_1349, primals_1350, primals_1351, primals_1352, primals_1353, primals_1354, primals_1355, primals_1356, primals_1357, primals_1358, primals_1359, primals_1360, primals_1361, primals_1362, primals_1363, primals_1364, primals_1365, primals_1366, primals_1367, primals_1368, primals_1369, primals_1370, primals_1371, primals_1372, primals_1373, primals_1374, primals_1375, primals_1376, primals_1377, primals_1378, primals_1379, primals_1380, primals_1381]), times=times, repeat=repeat)


if __name__ == "__main__":
    from torch._inductor.wrapper_benchmark import compiled_module_main
    compiled_module_main('pnasnet5large', benchmark_compiled_module)
