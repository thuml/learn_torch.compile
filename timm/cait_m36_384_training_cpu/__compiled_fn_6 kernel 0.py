
from ctypes import c_void_p, c_long
import torch
import math
import random
import os
import tempfile
from math import inf, nan
from torch._inductor.hooks import run_intermediate_hooks
from torch._inductor.utils import maybe_profile
from torch._inductor.codegen.memory_planning import _align as align

from torch import device, empty, empty_strided
from torch._inductor.codecache import AsyncCompile
from torch._inductor.select_algorithm import extern_kernels

aten = torch.ops.aten
inductor_ops = torch.ops.inductor
assert_size_stride = torch._C._dynamo.guards.assert_size_stride
alloc_from_pool = torch.ops.inductor._alloc_from_pool
reinterpret_tensor = torch.ops.inductor._reinterpret_tensor
async_compile = AsyncCompile()


cpp_fused_mul_native_layer_norm_native_layer_norm_backward_select_backward_sum_0 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       const float* in_ptr7,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6,
                       float* out_ptr7)
{
    {
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(1000L); x0+=static_cast<long>(8L))
        {
            {
                #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                float tmp_acc0 = 0;
                at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (1000L*x1)));
                    tmp_acc0_vec = tmp_acc0_vec + tmp0;
                }
                tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
            }
        }
    }
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(577L); x1+=static_cast<long>(1L))
                {
                    {
                        float tmp_acc0 = 0;
                        float tmp_acc1 = 0;
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(768L); x2+=static_cast<long>(1L))
                        {
                            auto tmp3 = in_ptr1[static_cast<long>(x2 + (768L*x0))];
                            auto tmp6 = in_ptr2[static_cast<long>(x2)];
                            auto tmp8 = in_ptr3[static_cast<long>(x2 + (768L*x1) + (443136L*x0))];
                            auto tmp9 = in_ptr4[static_cast<long>(x1 + (577L*x0))];
                            auto tmp11 = in_ptr5[static_cast<long>(x1 + (577L*x0))];
                            auto tmp0 = c10::convert<int>(x1);
                            auto tmp1 = static_cast<int>(0);
                            auto tmp2 = tmp0 == tmp1;
                            auto tmp4 = static_cast<float>(0.0);
                            auto tmp5 = tmp2 ? tmp3 : tmp4;
                            auto tmp7 = decltype(tmp5)(tmp5 * tmp6);
                            auto tmp10 = decltype(tmp8)(tmp8 - tmp9);
                            auto tmp12 = decltype(tmp10)(tmp10 * tmp11);
                            auto tmp13 = decltype(tmp7)(tmp7 * tmp12);
                            tmp_acc0 = tmp_acc0 + tmp7;
                            tmp_acc1 = tmp_acc1 + tmp13;
                        }
                        out_ptr1[static_cast<long>(x1 + (577L*x0))] = tmp_acc0;
                        out_ptr2[static_cast<long>(x1 + (577L*x0))] = tmp_acc1;
                    }
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(577L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(768L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = in_ptr5[static_cast<long>(x1 + (577L*x0))];
                        auto tmp6 = in_ptr1[static_cast<long>(x2 + (768L*x0))];
                        auto tmp9 = in_ptr2[static_cast<long>(x2)];
                        auto tmp12 = out_ptr1[static_cast<long>(x1 + (577L*x0))];
                        auto tmp14 = in_ptr3[static_cast<long>(x2 + (768L*x1) + (443136L*x0))];
                        auto tmp15 = in_ptr4[static_cast<long>(x1 + (577L*x0))];
                        auto tmp18 = out_ptr2[static_cast<long>(x1 + (577L*x0))];
                        auto tmp1 = static_cast<float>(768.0);
                        auto tmp2 = tmp0 / tmp1;
                        auto tmp3 = c10::convert<int>(x1);
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp7 = static_cast<float>(0.0);
                        auto tmp8 = tmp5 ? tmp6 : tmp7;
                        auto tmp10 = decltype(tmp8)(tmp8 * tmp9);
                        auto tmp11 = decltype(tmp10)(tmp10 * tmp1);
                        auto tmp13 = decltype(tmp11)(tmp11 - tmp12);
                        auto tmp16 = decltype(tmp14)(tmp14 - tmp15);
                        auto tmp17 = decltype(tmp16)(tmp16 * tmp0);
                        auto tmp19 = decltype(tmp17)(tmp17 * tmp18);
                        auto tmp20 = decltype(tmp13)(tmp13 - tmp19);
                        auto tmp21 = decltype(tmp2)(tmp2 * tmp20);
                        out_ptr3[static_cast<long>(x2 + (768L*x1) + (443136L*x0))] = tmp21;
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(1L))
            {
                {
                    float tmp_acc0 = 0;
                    float tmp_acc1 = 0;
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(577L); x2+=static_cast<long>(1L))
                        {
                            auto tmp3 = in_ptr1[static_cast<long>(x0 + (768L*x1))];
                            auto tmp6 = in_ptr3[static_cast<long>(x0 + (768L*x2) + (443136L*x1))];
                            auto tmp7 = in_ptr4[static_cast<long>(x2 + (577L*x1))];
                            auto tmp9 = in_ptr5[static_cast<long>(x2 + (577L*x1))];
                            auto tmp0 = c10::convert<int>(x2);
                            auto tmp1 = static_cast<int>(0);
                            auto tmp2 = tmp0 == tmp1;
                            auto tmp4 = static_cast<float>(0.0);
                            auto tmp5 = tmp2 ? tmp3 : tmp4;
                            auto tmp8 = decltype(tmp6)(tmp6 - tmp7);
                            auto tmp10 = decltype(tmp8)(tmp8 * tmp9);
                            auto tmp11 = decltype(tmp5)(tmp5 * tmp10);
                            tmp_acc0 = tmp_acc0 + tmp11;
                            tmp_acc1 = tmp_acc1 + tmp5;
                        }
                    }
                    out_ptr4[static_cast<long>(x0)] = tmp_acc0;
                    out_ptr5[static_cast<long>(x0)] = tmp_acc1;
                }
            }
        }
        #pragma omp single
        {
            {
                for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr3 + static_cast<long>(x0 + (443136L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                    }
                }
            }
        }
        #pragma omp single
        {
            {
                #pragma GCC ivdep
                for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
                {
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr3 + static_cast<long>(x1 + (443136L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr7 + static_cast<long>(x1));
                        auto tmp2 = tmp0 * tmp1;
                        tmp2.store(out_ptr7 + static_cast<long>(x1 + (768L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_1 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    {
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
        {
            {
                #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                float tmp_acc0 = 0;
                at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                    tmp_acc0_vec = tmp_acc0_vec + tmp0;
                }
                tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
            }
        }
    }
    {
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(24576L); x0+=static_cast<long>(8L))
        {
            auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
            auto tmp2 = static_cast<float>(0.7071067811865476);
            auto tmp3 = at::vec::Vectorized<float>(tmp2);
            auto tmp4 = tmp1 * tmp3;
            auto tmp5 = tmp4.erf();
            auto tmp6 = static_cast<float>(1.0);
            auto tmp7 = at::vec::Vectorized<float>(tmp6);
            auto tmp8 = tmp5 + tmp7;
            auto tmp9 = static_cast<float>(0.5);
            auto tmp10 = at::vec::Vectorized<float>(tmp9);
            auto tmp11 = tmp8 * tmp10;
            auto tmp12 = tmp1 * tmp1;
            auto tmp13 = static_cast<float>(-0.5);
            auto tmp14 = at::vec::Vectorized<float>(tmp13);
            auto tmp15 = tmp12 * tmp14;
            auto tmp16 = tmp15.exp();
            auto tmp17 = static_cast<float>(0.3989422804014327);
            auto tmp18 = at::vec::Vectorized<float>(tmp17);
            auto tmp19 = tmp16 * tmp18;
            auto tmp20 = tmp1 * tmp19;
            auto tmp21 = tmp11 + tmp20;
            auto tmp22 = tmp0 * tmp21;
            tmp22.store(in_out_ptr0 + static_cast<long>(x0));
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_2 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5)
{
    auto in_ptr1 = in_out_ptr0;
    {
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
        {
            {
                #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                float tmp_acc0 = 0;
                at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                    tmp_acc0_vec = tmp_acc0_vec + tmp0;
                }
                tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
            }
        }
    }
    {
        #pragma GCC ivdep
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
        {
            {
                #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                float tmp_acc0 = 0;
                at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                float tmp_acc1 = 0;
                at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp2 = tmp0 * tmp1;
                    auto tmp4 = tmp2 * tmp3;
                    tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    tmp_acc1_vec = tmp_acc1_vec + tmp4;
                }
                tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
            }
        }
    }
    {
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
        {
            {
                #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                float tmp_acc0 = 0;
                at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                float tmp_acc1 = 0;
                at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                    auto tmp2 = tmp0 * tmp1;
                    tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    tmp_acc1_vec = tmp_acc1_vec + tmp0;
                }
                tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
            }
        }
    }
    {
        #pragma GCC ivdep
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
        {
            for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1 + (443136L*x0)));
                auto tmp1 = in_ptr5[static_cast<long>(x0)];
                auto tmp2 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                auto tmp8 = out_ptr1[static_cast<long>(x0)];
                auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                auto tmp12 = out_ptr2[static_cast<long>(x0)];
                auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x1));
                auto tmp4 = tmp2 * tmp3;
                auto tmp5 = static_cast<float>(768.0);
                auto tmp6 = at::vec::Vectorized<float>(tmp5);
                auto tmp7 = tmp4 * tmp6;
                auto tmp9 = at::vec::Vectorized<float>(tmp8);
                auto tmp10 = tmp7 - tmp9;
                auto tmp13 = at::vec::Vectorized<float>(tmp12);
                auto tmp14 = tmp11 * tmp13;
                auto tmp15 = tmp10 - tmp14;
                auto tmp16 = at::vec::Vectorized<float>(tmp1);
                auto tmp17 = tmp16 * tmp15;
                auto tmp18 = tmp0 + tmp17;
                auto tmp20 = tmp18 * tmp19;
                tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_native_layer_norm_backward_select_backward_sum_3 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       const float* in_ptr7,
                       const float* in_ptr8,
                       const float* in_ptr9,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(577L); x1+=static_cast<long>(1L))
                {
                    {
                        float tmp_acc0 = 0;
                        float tmp_acc1 = 0;
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(768L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = in_ptr0[static_cast<long>(x2 + (768L*x1) + (443136L*x0))];
                            auto tmp1 = in_ptr1[static_cast<long>(x2 + (768L*x1) + (443136L*x0))];
                            auto tmp6 = in_ptr2[static_cast<long>(x2 + (768L*x0))];
                            auto tmp10 = in_ptr3[static_cast<long>(x2)];
                            auto tmp12 = in_ptr4[static_cast<long>(x2 + (768L*x1) + (443136L*x0))];
                            auto tmp13 = in_ptr5[static_cast<long>(x1 + (577L*x0))];
                            auto tmp15 = in_ptr6[static_cast<long>(x1 + (577L*x0))];
                            auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
                            auto tmp3 = c10::convert<int>(x1);
                            auto tmp4 = static_cast<int>(0);
                            auto tmp5 = tmp3 == tmp4;
                            auto tmp7 = static_cast<float>(0.0);
                            auto tmp8 = tmp5 ? tmp6 : tmp7;
                            auto tmp9 = decltype(tmp2)(tmp2 + tmp8);
                            auto tmp11 = decltype(tmp9)(tmp9 * tmp10);
                            auto tmp14 = decltype(tmp12)(tmp12 - tmp13);
                            auto tmp16 = decltype(tmp14)(tmp14 * tmp15);
                            auto tmp17 = decltype(tmp11)(tmp11 * tmp16);
                            tmp_acc0 = tmp_acc0 + tmp11;
                            tmp_acc1 = tmp_acc1 + tmp17;
                        }
                        out_ptr0[static_cast<long>(x1 + (577L*x0))] = tmp_acc0;
                        out_ptr1[static_cast<long>(x1 + (577L*x0))] = tmp_acc1;
                    }
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(577L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(768L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = in_ptr0[static_cast<long>(x2 + (768L*x1) + (443136L*x0))];
                        auto tmp1 = in_ptr1[static_cast<long>(x2 + (768L*x1) + (443136L*x0))];
                        auto tmp6 = in_ptr2[static_cast<long>(x2 + (768L*x0))];
                        auto tmp10 = in_ptr3[static_cast<long>(x2)];
                        auto tmp14 = out_ptr0[static_cast<long>(x1 + (577L*x0))];
                        auto tmp16 = in_ptr4[static_cast<long>(x2 + (768L*x1) + (443136L*x0))];
                        auto tmp17 = in_ptr5[static_cast<long>(x1 + (577L*x0))];
                        auto tmp19 = in_ptr6[static_cast<long>(x1 + (577L*x0))];
                        auto tmp21 = out_ptr1[static_cast<long>(x1 + (577L*x0))];
                        auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
                        auto tmp3 = c10::convert<int>(x1);
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp7 = static_cast<float>(0.0);
                        auto tmp8 = tmp5 ? tmp6 : tmp7;
                        auto tmp9 = decltype(tmp2)(tmp2 + tmp8);
                        auto tmp11 = decltype(tmp9)(tmp9 * tmp10);
                        auto tmp12 = static_cast<float>(768.0);
                        auto tmp13 = decltype(tmp11)(tmp11 * tmp12);
                        auto tmp15 = decltype(tmp13)(tmp13 - tmp14);
                        auto tmp18 = decltype(tmp16)(tmp16 - tmp17);
                        auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                        auto tmp22 = decltype(tmp20)(tmp20 * tmp21);
                        auto tmp23 = decltype(tmp15)(tmp15 - tmp22);
                        out_ptr2[static_cast<long>(x2 + (768L*x1) + (443136L*x0))] = tmp23;
                    }
                }
            }
        }
        #pragma omp single
        {
            {
                for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        float tmp_acc1 = 0;
                        at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                        for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr7 + static_cast<long>(x0 + (768L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr8 + static_cast<long>(x0 + (768L*x1)));
                            auto tmp3 = in_ptr6[static_cast<long>(577L*x1)];
                            auto tmp6 = at::vec::Vectorized<float>::loadu(out_ptr2 + static_cast<long>(x0 + (443136L*x1)));
                            auto tmp10 = at::vec::Vectorized<float>::loadu(in_ptr9 + static_cast<long>(x0 + (768L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = static_cast<float>(768.0);
                            auto tmp5 = tmp3 / tmp4;
                            auto tmp7 = at::vec::Vectorized<float>(tmp5);
                            auto tmp8 = tmp7 * tmp6;
                            auto tmp9 = tmp0 + tmp8;
                            auto tmp11 = tmp9 * tmp10;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                            tmp_acc1_vec = tmp_acc1_vec + tmp11;
                        }
                        tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                        tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_sum_4 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    {
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
        {
            {
                #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                float tmp_acc0 = 0;
                at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                    tmp_acc0_vec = tmp_acc0_vec + tmp0;
                }
                tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_5 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4616L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_sum_6 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4616L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_native_layer_norm_backward_select_backward_sum_7 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       const float* in_ptr7,
                       const float* in_ptr8,
                       const float* in_ptr9,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3)
{
    {
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
        {
            {
                #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                float tmp_acc0 = 0;
                at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                    tmp_acc0_vec = tmp_acc0_vec + tmp0;
                }
                tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
            }
        }
    }
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(1L))
            {
                {
                    float tmp_acc0 = 0;
                    float tmp_acc1 = 0;
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(577L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = in_ptr1[static_cast<long>(x0 + (768L*x2) + (443136L*x1))];
                            auto tmp1 = in_ptr2[static_cast<long>(x0 + (768L*x2) + (443136L*x1))];
                            auto tmp6 = in_ptr3[static_cast<long>(x0 + (768L*x1))];
                            auto tmp10 = in_ptr4[static_cast<long>(x0 + (768L*x2) + (443136L*x1))];
                            auto tmp11 = in_ptr5[static_cast<long>(x2 + (577L*x1))];
                            auto tmp13 = in_ptr6[static_cast<long>(x2 + (577L*x1))];
                            auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
                            auto tmp3 = c10::convert<int>(x2);
                            auto tmp4 = static_cast<int>(0);
                            auto tmp5 = tmp3 == tmp4;
                            auto tmp7 = static_cast<float>(0.0);
                            auto tmp8 = tmp5 ? tmp6 : tmp7;
                            auto tmp9 = decltype(tmp2)(tmp2 + tmp8);
                            auto tmp12 = decltype(tmp10)(tmp10 - tmp11);
                            auto tmp14 = decltype(tmp12)(tmp12 * tmp13);
                            auto tmp15 = decltype(tmp9)(tmp9 * tmp14);
                            tmp_acc0 = tmp_acc0 + tmp15;
                            tmp_acc1 = tmp_acc1 + tmp9;
                        }
                    }
                    out_ptr1[static_cast<long>(x0)] = tmp_acc0;
                    out_ptr2[static_cast<long>(x0)] = tmp_acc1;
                }
            }
        }
        #pragma omp single
        {
            {
                #pragma GCC ivdep
                for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
                {
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr7 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = in_ptr6[static_cast<long>(577L*x0)];
                        auto tmp4 = at::vec::Vectorized<float>::loadu(in_ptr8 + static_cast<long>(x1 + (443136L*x0)));
                        auto tmp8 = at::vec::Vectorized<float>::loadu(in_ptr9 + static_cast<long>(x1));
                        auto tmp2 = static_cast<float>(768.0);
                        auto tmp3 = tmp1 / tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp3);
                        auto tmp6 = tmp5 * tmp4;
                        auto tmp7 = tmp0 + tmp6;
                        auto tmp9 = tmp7 * tmp8;
                        tmp9.store(out_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_8 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    {
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
        {
            {
                #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                float tmp_acc0 = 0;
                at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                    tmp_acc0_vec = tmp_acc0_vec + tmp0;
                }
                tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
            }
        }
    }
    {
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(24576L); x0+=static_cast<long>(8L))
        {
            auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
            auto tmp2 = static_cast<float>(0.7071067811865476);
            auto tmp3 = at::vec::Vectorized<float>(tmp2);
            auto tmp4 = tmp1 * tmp3;
            auto tmp5 = tmp4.erf();
            auto tmp6 = static_cast<float>(1.0);
            auto tmp7 = at::vec::Vectorized<float>(tmp6);
            auto tmp8 = tmp5 + tmp7;
            auto tmp9 = static_cast<float>(0.5);
            auto tmp10 = at::vec::Vectorized<float>(tmp9);
            auto tmp11 = tmp8 * tmp10;
            auto tmp12 = tmp1 * tmp1;
            auto tmp13 = static_cast<float>(-0.5);
            auto tmp14 = at::vec::Vectorized<float>(tmp13);
            auto tmp15 = tmp12 * tmp14;
            auto tmp16 = tmp15.exp();
            auto tmp17 = static_cast<float>(0.3989422804014327);
            auto tmp18 = at::vec::Vectorized<float>(tmp17);
            auto tmp19 = tmp16 * tmp18;
            auto tmp20 = tmp1 * tmp19;
            auto tmp21 = tmp11 + tmp20;
            auto tmp22 = tmp0 * tmp21;
            tmp22.store(in_out_ptr0 + static_cast<long>(x0));
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_9 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       const float* in_ptr7,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5)
{
    {
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
        {
            {
                #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                float tmp_acc0 = 0;
                at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                    tmp_acc0_vec = tmp_acc0_vec + tmp0;
                }
                tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
            }
        }
    }
    {
        #pragma GCC ivdep
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
        {
            {
                #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                float tmp_acc0 = 0;
                at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                float tmp_acc1 = 0;
                at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp2 = tmp0 * tmp1;
                    auto tmp4 = tmp2 * tmp3;
                    tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    tmp_acc1_vec = tmp_acc1_vec + tmp4;
                }
                tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
            }
        }
    }
    {
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
        {
            {
                #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                float tmp_acc0 = 0;
                at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                float tmp_acc1 = 0;
                at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                    auto tmp2 = tmp0 * tmp1;
                    tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    tmp_acc1_vec = tmp_acc1_vec + tmp0;
                }
                tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
            }
        }
    }
    {
        #pragma GCC ivdep
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
        {
            for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                auto tmp1 = in_ptr4[static_cast<long>(577L*x0)];
                auto tmp4 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1 + (443136L*x0)));
                auto tmp8 = in_ptr6[static_cast<long>(x0)];
                auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                auto tmp10 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                auto tmp14 = out_ptr1[static_cast<long>(x0)];
                auto tmp17 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                auto tmp18 = out_ptr2[static_cast<long>(x0)];
                auto tmp25 = at::vec::Vectorized<float>::loadu(in_ptr7 + static_cast<long>(x1));
                auto tmp2 = static_cast<float>(768.0);
                auto tmp3 = tmp1 / tmp2;
                auto tmp5 = at::vec::Vectorized<float>(tmp3);
                auto tmp6 = tmp5 * tmp4;
                auto tmp7 = tmp0 + tmp6;
                auto tmp11 = tmp9 * tmp10;
                auto tmp12 = at::vec::Vectorized<float>(tmp2);
                auto tmp13 = tmp11 * tmp12;
                auto tmp15 = at::vec::Vectorized<float>(tmp14);
                auto tmp16 = tmp13 - tmp15;
                auto tmp19 = at::vec::Vectorized<float>(tmp18);
                auto tmp20 = tmp17 * tmp19;
                auto tmp21 = tmp16 - tmp20;
                auto tmp22 = at::vec::Vectorized<float>(tmp8);
                auto tmp23 = tmp22 * tmp21;
                auto tmp24 = tmp7 + tmp23;
                auto tmp26 = tmp24 * tmp25;
                tmp24.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                tmp26.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_native_layer_norm_backward_select_backward_sum_10 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       const float* in_ptr7,
                       const float* in_ptr8,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(577L); x1+=static_cast<long>(1L))
                {
                    {
                        float tmp_acc0 = 0;
                        float tmp_acc1 = 0;
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(768L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = in_ptr0[static_cast<long>(x2 + (768L*x1) + (443136L*x0))];
                            auto tmp1 = in_ptr1[static_cast<long>(x2 + (768L*x1) + (443136L*x0))];
                            auto tmp6 = in_ptr2[static_cast<long>(x2 + (768L*x0))];
                            auto tmp10 = in_ptr3[static_cast<long>(x2)];
                            auto tmp12 = in_ptr4[static_cast<long>(x2 + (768L*x1) + (443136L*x0))];
                            auto tmp13 = in_ptr5[static_cast<long>(x1 + (577L*x0))];
                            auto tmp15 = in_ptr6[static_cast<long>(x1 + (577L*x0))];
                            auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
                            auto tmp3 = c10::convert<int>(x1);
                            auto tmp4 = static_cast<int>(0);
                            auto tmp5 = tmp3 == tmp4;
                            auto tmp7 = static_cast<float>(0.0);
                            auto tmp8 = tmp5 ? tmp6 : tmp7;
                            auto tmp9 = decltype(tmp2)(tmp2 + tmp8);
                            auto tmp11 = decltype(tmp9)(tmp9 * tmp10);
                            auto tmp14 = decltype(tmp12)(tmp12 - tmp13);
                            auto tmp16 = decltype(tmp14)(tmp14 * tmp15);
                            auto tmp17 = decltype(tmp11)(tmp11 * tmp16);
                            tmp_acc0 = tmp_acc0 + tmp11;
                            tmp_acc1 = tmp_acc1 + tmp17;
                        }
                        out_ptr0[static_cast<long>(x1 + (577L*x0))] = tmp_acc0;
                        out_ptr1[static_cast<long>(x1 + (577L*x0))] = tmp_acc1;
                    }
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(577L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(768L); x2+=static_cast<long>(1L))
                    {
                        auto tmp0 = in_ptr0[static_cast<long>(x2 + (768L*x1) + (443136L*x0))];
                        auto tmp1 = in_ptr1[static_cast<long>(x2 + (768L*x1) + (443136L*x0))];
                        auto tmp6 = in_ptr2[static_cast<long>(x2 + (768L*x0))];
                        auto tmp10 = in_ptr3[static_cast<long>(x2)];
                        auto tmp14 = out_ptr0[static_cast<long>(x1 + (577L*x0))];
                        auto tmp16 = in_ptr4[static_cast<long>(x2 + (768L*x1) + (443136L*x0))];
                        auto tmp17 = in_ptr5[static_cast<long>(x1 + (577L*x0))];
                        auto tmp19 = in_ptr6[static_cast<long>(x1 + (577L*x0))];
                        auto tmp21 = out_ptr1[static_cast<long>(x1 + (577L*x0))];
                        auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
                        auto tmp3 = c10::convert<int>(x1);
                        auto tmp4 = static_cast<int>(0);
                        auto tmp5 = tmp3 == tmp4;
                        auto tmp7 = static_cast<float>(0.0);
                        auto tmp8 = tmp5 ? tmp6 : tmp7;
                        auto tmp9 = decltype(tmp2)(tmp2 + tmp8);
                        auto tmp11 = decltype(tmp9)(tmp9 * tmp10);
                        auto tmp12 = static_cast<float>(768.0);
                        auto tmp13 = decltype(tmp11)(tmp11 * tmp12);
                        auto tmp15 = decltype(tmp13)(tmp13 - tmp14);
                        auto tmp18 = decltype(tmp16)(tmp16 - tmp17);
                        auto tmp20 = decltype(tmp18)(tmp18 * tmp19);
                        auto tmp22 = decltype(tmp20)(tmp20 * tmp21);
                        auto tmp23 = decltype(tmp15)(tmp15 - tmp22);
                        out_ptr2[static_cast<long>(x2 + (768L*x1) + (443136L*x0))] = tmp23;
                    }
                }
            }
        }
        #pragma omp single
        {
            {
                for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        float tmp_acc1 = 0;
                        at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                        for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr7 + static_cast<long>(x0 + (768L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr8 + static_cast<long>(x0 + (768L*x1)));
                            auto tmp3 = in_ptr6[static_cast<long>(577L*x1)];
                            auto tmp6 = at::vec::Vectorized<float>::loadu(out_ptr2 + static_cast<long>(x0 + (443136L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = static_cast<float>(768.0);
                            auto tmp5 = tmp3 / tmp4;
                            auto tmp7 = at::vec::Vectorized<float>(tmp5);
                            auto tmp8 = tmp7 * tmp6;
                            auto tmp9 = tmp0 + tmp8;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                            tmp_acc1_vec = tmp_acc1_vec + tmp9;
                        }
                        tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                        tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_sum_11 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    {
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
        {
            {
                #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                float tmp_acc0 = 0;
                at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                    tmp_acc0_vec = tmp_acc0_vec + tmp0;
                }
                tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_sum_12 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4616L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_sum_13 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4616L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_native_layer_norm_backward_select_backward_sum_14 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       const float* in_ptr7,
                       const float* in_ptr8,
                       const float* in_ptr9,
                       const float* in_ptr10,
                       const float* in_ptr11,
                       const float* in_ptr12,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5)
{
    {
        for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
        {
            {
                #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                float tmp_acc0 = 0;
                at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                    tmp_acc0_vec = tmp_acc0_vec + tmp0;
                }
                tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
            }
        }
    }
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(1L))
            {
                {
                    float tmp_acc0 = 0;
                    float tmp_acc1 = 0;
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(577L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = in_ptr1[static_cast<long>(x0 + (768L*x2) + (443136L*x1))];
                            auto tmp1 = in_ptr2[static_cast<long>(x0 + (768L*x2) + (443136L*x1))];
                            auto tmp6 = in_ptr3[static_cast<long>(x0 + (768L*x1))];
                            auto tmp10 = in_ptr4[static_cast<long>(x0 + (768L*x2) + (443136L*x1))];
                            auto tmp11 = in_ptr5[static_cast<long>(x2 + (577L*x1))];
                            auto tmp13 = in_ptr6[static_cast<long>(x2 + (577L*x1))];
                            auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
                            auto tmp3 = c10::convert<int>(x2);
                            auto tmp4 = static_cast<int>(0);
                            auto tmp5 = tmp3 == tmp4;
                            auto tmp7 = static_cast<float>(0.0);
                            auto tmp8 = tmp5 ? tmp6 : tmp7;
                            auto tmp9 = decltype(tmp2)(tmp2 + tmp8);
                            auto tmp12 = decltype(tmp10)(tmp10 - tmp11);
                            auto tmp14 = decltype(tmp12)(tmp12 * tmp13);
                            auto tmp15 = decltype(tmp9)(tmp9 * tmp14);
                            tmp_acc0 = tmp_acc0 + tmp15;
                            tmp_acc1 = tmp_acc1 + tmp9;
                        }
                    }
                    out_ptr1[static_cast<long>(x0)] = tmp_acc0;
                    out_ptr2[static_cast<long>(x0)] = tmp_acc1;
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(768L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr7 + static_cast<long>(768L + x2 + (768L*x1) + (443136L*x0)));
                        auto tmp1 = in_ptr8[static_cast<long>(1L + x1 + (577L*x0))];
                        auto tmp4 = at::vec::Vectorized<float>::loadu(in_ptr9 + static_cast<long>(768L + x2 + (768L*x1) + (443136L*x0)));
                        auto tmp8 = in_ptr6[static_cast<long>(1L + x1 + (577L*x0))];
                        auto tmp10 = at::vec::Vectorized<float>::loadu(in_ptr10 + static_cast<long>(768L + x2 + (768L*x1) + (443136L*x0)));
                        auto tmp2 = static_cast<float>(768.0);
                        auto tmp3 = tmp1 / tmp2;
                        auto tmp5 = at::vec::Vectorized<float>(tmp3);
                        auto tmp6 = tmp5 * tmp4;
                        auto tmp7 = tmp0 + tmp6;
                        auto tmp9 = tmp8 / tmp2;
                        auto tmp11 = at::vec::Vectorized<float>(tmp9);
                        auto tmp12 = tmp11 * tmp10;
                        auto tmp13 = tmp7 + tmp12;
                        tmp13.store(out_ptr3 + static_cast<long>(x2 + (768L*x1) + (442368L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr11 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr12 + static_cast<long>(x1));
                    auto tmp2 = tmp0 * tmp1;
                    tmp2.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_15 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_16 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_17 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_18 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_19 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_20 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_21 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_22 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       const float* in_ptr7,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    auto in_ptr1 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr5[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr7 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_23 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_24 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_25 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_26 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_27 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_28 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_29 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_30 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_31 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_32 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_33 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_34 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_35 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_36 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_37 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_38 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_39 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_40 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_41 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_42 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_43 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_44 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_45 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_46 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_47 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_48 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_49 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_50 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_51 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_52 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_53 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_54 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_55 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_56 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_57 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_58 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_59 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_60 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_61 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_62 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_63 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_64 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_65 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_66 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_67 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_68 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_69 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_70 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_71 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_72 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_73 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_74 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_75 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_76 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_77 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_78 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_79 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_80 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_81 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_82 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_83 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_84 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_85 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_86 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_87 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_88 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_89 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_90 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_91 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_92 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_93 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_94 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_95 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_96 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_97 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_98 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_99 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_100 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_101 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_102 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_103 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_104 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_105 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_106 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_107 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_108 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_109 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_110 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_111 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_112 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_113 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_114 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_115 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_116 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_117 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_118 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_119 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_120 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_121 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_122 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_123 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_124 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_125 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_126 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_127 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_128 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_129 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_130 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_131 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_132 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_133 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_134 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_135 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_136 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_137 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_138 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_139 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_140 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_141 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_142 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_143 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_144 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_145 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_146 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_147 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_148 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_149 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_150 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_151 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_152 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_153 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_154 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_155 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_156 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_157 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_158 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_159 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_160 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_161 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_162 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_163 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_164 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_165 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_166 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_167 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_168 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_169 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_170 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_171 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_172 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_173 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_174 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_175 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_176 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_177 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_178 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_179 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_180 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_181 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_182 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_183 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_184 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_185 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_186 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_187 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_188 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_189 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_190 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_191 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_192 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_193 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_194 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_195 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_196 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_197 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_198 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_199 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_200 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_201 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_202 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_203 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_204 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_205 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_206 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_207 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_208 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_209 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_210 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_211 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_212 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_213 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_214 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_215 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_216 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_217 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_218 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_219 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_220 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_221 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_222 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_223 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_224 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_225 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_226 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_227 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_228 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_229 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_230 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_231 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_232 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_233 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_234 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_235 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_236 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_237 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_238 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_239 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_240 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_241 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_242 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_243 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_244 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_245 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_246 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_247 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_248 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_249 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_250 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_251 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_252 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_253 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_254 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_255 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_256 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_257 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_258 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_259 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_260 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_261 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_262 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_263 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_264 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_265 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_266 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_267 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_268 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_269 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_270 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_271 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_272 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_273 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_274 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_275 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_276 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_277 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_278 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_279 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_280 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_281 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_282 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_283 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_284 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_285 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_286 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_287 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_288 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_289 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_290 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_291 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_292 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_293 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_294 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_gelu_gelu_backward_sum_295 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(14155776L); x0+=static_cast<long>(8L))
            {
                auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0));
                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));
                auto tmp2 = static_cast<float>(0.7071067811865476);
                auto tmp3 = at::vec::Vectorized<float>(tmp2);
                auto tmp4 = tmp1 * tmp3;
                auto tmp5 = tmp4.erf();
                auto tmp6 = static_cast<float>(1.0);
                auto tmp7 = at::vec::Vectorized<float>(tmp6);
                auto tmp8 = tmp5 + tmp7;
                auto tmp9 = static_cast<float>(0.5);
                auto tmp10 = at::vec::Vectorized<float>(tmp9);
                auto tmp11 = tmp8 * tmp10;
                auto tmp12 = tmp1 * tmp1;
                auto tmp13 = static_cast<float>(-0.5);
                auto tmp14 = at::vec::Vectorized<float>(tmp13);
                auto tmp15 = tmp12 * tmp14;
                auto tmp16 = tmp15.exp();
                auto tmp17 = static_cast<float>(0.3989422804014327);
                auto tmp18 = at::vec::Vectorized<float>(tmp17);
                auto tmp19 = tmp16 * tmp18;
                auto tmp20 = tmp1 * tmp19;
                auto tmp21 = tmp11 + tmp20;
                auto tmp22 = tmp0 * tmp21;
                tmp22.store(in_out_ptr0 + static_cast<long>(x0));
            }
        }
    }
}
''')


cpp_fused_add_mul_native_layer_norm_backward_sum_296 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       const float* in_ptr5,
                       const float* in_ptr6,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5,
                       float* out_ptr6)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(3072L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (3072L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<long>(x1));
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    auto tmp20 = tmp18 * tmp19;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    tmp20.store(out_ptr5 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                    }
                    tmp_acc0_vec.store(out_ptr6 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


cpp_fused_clone_sum_297 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (768L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                    {
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(48L); x3+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x3 + (48L*x1) + (768L*x2) + (442368L*x0)));
                            tmp0.store(out_ptr1 + static_cast<long>(x3 + (48L*x2) + (27648L*x1) + (442368L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused__unsafe_view_clone_sum_298 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0,
                       float* out_ptr1)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x2 + (331776L*x0) + (5308416L*x1)));
                            tmp_acc0_vec = tmp_acc0_vec + tmp0;
                        }
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr0[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2654208L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = ([&]() { __at_align__ float tmpbuf[8]; for (long x1_inner = 0; x1_inner < 8; x1_inner++) tmpbuf[x1_inner] = in_ptr0[static_cast<long>((331776L*x1) + (331776L*x1_inner) + (5308416L*(c10::div_floor_integer(x0, 331776L))) + (static_cast<long>(x0) % static_cast<long>(331776L)))]; return at::vec::Vectorized<float>::loadu(tmpbuf); })();
                    tmp0.store(out_ptr1 + static_cast<long>(x1 + (16L*x0)));
                }
            }
        }
    }
}
''')


cpp_fused__softmax_backward_data_clone_sum_299 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr1,
                       float* out_ptr0,
                       float* out_ptr1)
{
    auto in_ptr0 = in_out_ptr0;
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    {
                        #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                        float tmp_acc0 = 0;
                        at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (16L*x2) + (9216L*x0)));
                            auto tmp2 = tmp0 * tmp1;
                            tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        }
                        tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x1 + (16L*x0)));
                    }
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(16L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        for(long x2=static_cast<long>(0L); x2<static_cast<long>(576L); x2+=static_cast<long>(1L))
                        {
                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (16L*x2) + (9216L*x1)));
                            auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x0 + (16L*x1)));
                            auto tmp2 = tmp0 * tmp1;
                            auto tmp4 = tmp1 * tmp3;
                            auto tmp5 = tmp2 - tmp4;
                            tmp_acc0_vec = tmp_acc0_vec + tmp5;
                        }
                    }
                    tmp_acc0_vec.store(out_ptr1 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(16L); x2+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<long>(x2 + (16L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp1 * tmp3;
                        auto tmp5 = tmp2 - tmp4;
                        tmp5.store(in_out_ptr0 + static_cast<long>(x2 + (16L*x1) + (9216L*x0)));
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_300 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                #pragma GCC ivdep
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(16L); x1+=static_cast<long>(8L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(331776L); x2+=static_cast<long>(8L))
                    {
                        float tmp0[8*8] __attribute__ ((aligned (8)));
                        at::vec::transpose_mxn<float,8,8>(in_ptr0 + static_cast<long>(x1 + (16L*x2) + (5308416L*x0)), static_cast<long>(16L), tmp0, 8);
                        for (long x1_inner = 0; x1_inner < 8; x1_inner++)
                        {
                            auto tmp1 = at::vec::Vectorized<float>::loadu(tmp0 + static_cast<long>(8L*x1_inner));
                            tmp1.store(out_ptr0 + static_cast<long>(x2 + (331776L*x1) + (331776L*x1_inner) + (5308416L*x0)));
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_clone_301 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       float* out_ptr0)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for  collapse(2)
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(576L); x1+=static_cast<long>(1L))
                {
                    #pragma GCC ivdep
                    for(long x2=static_cast<long>(0L); x2<static_cast<long>(3L); x2+=static_cast<long>(1L))
                    {
                        #pragma GCC ivdep
                        for(long x3=static_cast<long>(0L); x3<static_cast<long>(16L); x3+=static_cast<long>(1L))
                        {
                            #pragma GCC ivdep
                            for(long x4=static_cast<long>(0L); x4<static_cast<long>(48L); x4+=static_cast<long>(1L))
                            {
                                auto tmp3 = in_ptr0[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp8 = in_ptr1[static_cast<long>(x1 + (576L*x4) + (27648L*x3) + (442368L*x0))];
                                auto tmp13 = in_ptr2[static_cast<long>(x4 + (48L*x1) + (27648L*x3) + (442368L*x0))];
                                auto tmp0 = c10::convert<int>(x2);
                                auto tmp1 = static_cast<int>(2);
                                auto tmp2 = tmp0 == tmp1;
                                auto tmp4 = static_cast<float>(0.0);
                                auto tmp5 = tmp2 ? tmp3 : tmp4;
                                auto tmp6 = static_cast<int>(1);
                                auto tmp7 = tmp0 == tmp6;
                                auto tmp9 = tmp7 ? tmp8 : tmp4;
                                auto tmp10 = decltype(tmp5)(tmp5 + tmp9);
                                auto tmp11 = static_cast<int>(0);
                                auto tmp12 = tmp0 == tmp11;
                                auto tmp14 = static_cast<float>(0.14433756729740643);
                                auto tmp15 = decltype(tmp13)(tmp13 * tmp14);
                                auto tmp16 = tmp12 ? tmp15 : tmp4;
                                auto tmp17 = decltype(tmp10)(tmp10 + tmp16);
                                out_ptr0[static_cast<long>(x4 + (48L*x3) + (768L*x2) + (2304L*x1) + (1327104L*x0))] = tmp17;
                            }
                        }
                    }
                }
            }
        }
    }
}
''')


cpp_fused_add_native_layer_norm_backward_sum_302 = async_compile.cpp('''
#include "/tmp/torchinductor_youkaichao/2l/c2ljzlm4sosod7u6lyrroqdba6hmfcyijrric6p4t3fhbcmw6osp.h"
extern "C" void kernel(float* in_out_ptr0,
                       const float* in_ptr0,
                       const float* in_ptr1,
                       const float* in_ptr2,
                       const float* in_ptr3,
                       const float* in_ptr4,
                       float* out_ptr0,
                       float* out_ptr1,
                       float* out_ptr2,
                       float* out_ptr3,
                       float* out_ptr4,
                       float* out_ptr5)
{
    #pragma omp parallel num_threads(28)
    {
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(2304L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0 + (2304L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr0 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                        auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                        auto tmp2 = tmp0 * tmp1;
                        auto tmp4 = tmp2 * tmp3;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp4;
                    }
                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc0_vec);
                    out_ptr1[static_cast<long>(x0)] = static_cast<float>(tmp_acc0);
                    tmp_acc1 = tmp_acc1 + at::vec::vec_reduce_all<float>([](at::vec::Vectorized<float>& x, at::vec::Vectorized<float>& y) { return x + y; }, tmp_acc1_vec);
                    out_ptr2[static_cast<long>(x0)] = static_cast<float>(tmp_acc1);
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(768L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    float tmp_acc1 = 0;
                    at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(4608L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x0 + (768L*x1)));
                        auto tmp2 = tmp0 * tmp1;
                        tmp_acc0_vec = tmp_acc0_vec + tmp2;
                        tmp_acc1_vec = tmp_acc1_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr3 + static_cast<long>(x0));
                    tmp_acc1_vec.store(out_ptr4 + static_cast<long>(x0));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(4608L); x0+=static_cast<long>(1L))
            {
                for(long x1=static_cast<long>(0L); x1<static_cast<long>(768L); x1+=static_cast<long>(8L))
                {
                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp1 = in_ptr4[static_cast<long>(x0)];
                    auto tmp2 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp3 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<long>(x1));
                    auto tmp8 = out_ptr1[static_cast<long>(x0)];
                    auto tmp11 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<long>(x1 + (768L*x0)));
                    auto tmp12 = out_ptr2[static_cast<long>(x0)];
                    auto tmp4 = tmp2 * tmp3;
                    auto tmp5 = static_cast<float>(768.0);
                    auto tmp6 = at::vec::Vectorized<float>(tmp5);
                    auto tmp7 = tmp4 * tmp6;
                    auto tmp9 = at::vec::Vectorized<float>(tmp8);
                    auto tmp10 = tmp7 - tmp9;
                    auto tmp13 = at::vec::Vectorized<float>(tmp12);
                    auto tmp14 = tmp11 * tmp13;
                    auto tmp15 = tmp10 - tmp14;
                    auto tmp16 = at::vec::Vectorized<float>(tmp1);
                    auto tmp17 = tmp16 * tmp15;
                    auto tmp18 = tmp0 + tmp17;
                    tmp18.store(in_out_ptr0 + static_cast<long>(x1 + (768L*x0)));
                }
            }
        }
        {
            #pragma omp for 
            for(long x0=static_cast<long>(0L); x0<static_cast<long>(442368L); x0+=static_cast<long>(8L))
            {
                {
                    #pragma omp declare reduction(+:at::vec::Vectorized<float>:omp_out = omp_out + omp_in) initializer(omp_priv={at::vec::Vectorized<float>(0)})
                    float tmp_acc0 = 0;
                    at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);
                    for(long x1=static_cast<long>(0L); x1<static_cast<long>(8L); x1+=static_cast<long>(1L))
                    {
                        auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<long>(x0 + (442368L*x1)));
                        tmp_acc0_vec = tmp_acc0_vec + tmp0;
                    }
                    tmp_acc0_vec.store(out_ptr5 + static_cast<long>(x0));
                }
            }
        }
    }
}
''')


async_compile.wait(globals())
del async_compile

def call(args):
    primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_75, primals_76, primals_77, primals_78, primals_79, primals_81, primals_91, primals_97, primals_107, primals_113, primals_123, primals_129, primals_139, primals_145, primals_155, primals_161, primals_171, primals_177, primals_187, primals_193, primals_203, primals_209, primals_219, primals_225, primals_235, primals_241, primals_251, primals_257, primals_267, primals_273, primals_283, primals_289, primals_299, primals_305, primals_315, primals_321, primals_331, primals_337, primals_347, primals_353, primals_363, primals_369, primals_379, primals_385, primals_395, primals_401, primals_411, primals_417, primals_427, primals_433, primals_443, primals_449, primals_459, primals_465, primals_475, primals_481, primals_491, primals_497, primals_507, primals_513, primals_523, primals_529, primals_539, primals_545, primals_555, primals_561, primals_571, primals_577, primals_587, primals_593, primals_603, primals_609, primals_619, primals_625, primals_635, primals_641, primals_651, primals_657, primals_667, primals_673, primals_683, primals_689, primals_693, mul, view_1, view_7, view_9, view_15, addmm_1, mul_4, view_17, addmm_2, view_19, addmm_3, mul_10, view_21, view_27, view_29, view_35, addmm_5, mul_14, view_37, addmm_6, view_39, addmm_7, mul_20, view_41, view_47, view_49, view_55, addmm_9, mul_24, view_57, addmm_10, view_59, addmm_11, mul_30, view_61, view_67, view_69, view_75, addmm_13, mul_34, view_77, addmm_14, view_79, addmm_15, mul_40, view_81, view_87, view_89, view_95, addmm_17, mul_44, view_97, addmm_18, view_99, addmm_19, mul_50, view_101, view_107, view_109, view_115, addmm_21, mul_54, view_117, addmm_22, view_119, addmm_23, mul_60, view_121, view_127, view_129, view_135, addmm_25, mul_64, view_137, addmm_26, view_139, addmm_27, mul_70, view_141, view_147, view_149, view_155, addmm_29, mul_74, view_157, addmm_30, view_159, addmm_31, mul_80, view_161, view_167, view_169, view_175, addmm_33, mul_84, view_177, addmm_34, view_179, addmm_35, mul_90, view_181, view_187, view_189, view_195, addmm_37, mul_94, view_197, addmm_38, view_199, addmm_39, mul_100, view_201, view_207, view_209, view_215, addmm_41, mul_104, view_217, addmm_42, view_219, addmm_43, mul_110, view_221, view_227, view_229, view_235, addmm_45, mul_114, view_237, addmm_46, view_239, addmm_47, mul_120, view_241, view_247, view_249, view_255, addmm_49, mul_124, view_257, addmm_50, view_259, addmm_51, mul_130, view_261, view_267, view_269, view_275, addmm_53, mul_134, view_277, addmm_54, view_279, addmm_55, mul_140, view_281, view_287, view_289, view_295, addmm_57, mul_144, view_297, addmm_58, view_299, addmm_59, mul_150, view_301, view_307, view_309, view_315, addmm_61, mul_154, view_317, addmm_62, view_319, addmm_63, mul_160, view_321, view_327, view_329, view_335, addmm_65, mul_164, view_337, addmm_66, view_339, addmm_67, mul_170, view_341, view_347, view_349, view_355, addmm_69, mul_174, view_357, addmm_70, view_359, addmm_71, mul_180, view_361, view_367, view_369, view_375, addmm_73, mul_184, view_377, addmm_74, view_379, addmm_75, mul_190, view_381, view_387, view_389, view_395, addmm_77, mul_194, view_397, addmm_78, view_399, addmm_79, mul_200, view_401, view_407, view_409, view_415, addmm_81, mul_204, view_417, addmm_82, view_419, addmm_83, mul_210, view_421, view_427, view_429, view_435, addmm_85, mul_214, view_437, addmm_86, view_439, addmm_87, mul_220, view_441, view_447, view_449, view_455, addmm_89, mul_224, view_457, addmm_90, view_459, addmm_91, mul_230, view_461, view_467, view_469, view_475, addmm_93, mul_234, view_477, addmm_94, view_479, addmm_95, mul_240, view_481, view_487, view_489, view_495, addmm_97, mul_244, view_497, addmm_98, view_499, addmm_99, mul_250, view_501, view_507, view_509, view_515, addmm_101, mul_254, view_517, addmm_102, view_519, addmm_103, mul_260, view_521, view_527, view_529, view_535, addmm_105, mul_264, view_537, addmm_106, view_539, addmm_107, mul_270, view_541, view_547, view_549, view_555, addmm_109, mul_274, view_557, addmm_110, view_559, addmm_111, mul_280, view_561, view_567, view_569, view_575, addmm_113, mul_284, view_577, addmm_114, view_579, addmm_115, mul_290, view_581, view_587, view_589, view_595, addmm_117, mul_294, view_597, addmm_118, view_599, addmm_119, mul_300, view_601, view_607, view_609, view_615, addmm_121, mul_304, view_617, addmm_122, view_619, addmm_123, mul_310, view_621, view_627, view_629, view_635, addmm_125, mul_314, view_637, addmm_126, view_639, addmm_127, mul_320, view_641, view_647, view_649, view_655, addmm_129, mul_324, view_657, addmm_130, view_659, addmm_131, mul_330, view_661, view_667, view_669, view_675, addmm_133, mul_334, view_677, addmm_134, view_679, addmm_135, mul_340, view_681, view_687, view_689, view_695, addmm_137, mul_344, view_697, addmm_138, view_699, addmm_139, mul_350, view_701, view_707, view_709, view_715, addmm_141, mul_354, view_717, addmm_142, view_719, addmm_143, cat, getitem_145, rsqrt_72, select_108, permute_470, view_722, permute_472, permute_474, getitem_147, getitem_148, getitem_149, getitem_152, getitem_153, view_729, addmm_147, mul_363, view_731, addmm_148, view_733, addmm_149, cat_1, getitem_158, rsqrt_74, select_109, permute_480, view_736, permute_482, permute_484, getitem_160, getitem_161, getitem_162, getitem_165, getitem_166, view_743, addmm_153, mul_372, view_745, addmm_154, view_747, addmm_155, cat_2, getitem_171, rsqrt_76, clone_511, permute_490, permute_494, permute_498, div_37, permute_502, alias_38, permute_508, permute_513, permute_518, permute_522, permute_526, div_39, permute_530, alias_39, permute_536, permute_541, permute_546, permute_550, permute_554, div_41, permute_558, permute_563, permute_564, permute_568, alias_40, permute_574, permute_577, permute_578, permute_581, div_42, permute_585, permute_589, div_43, permute_593, permute_598, permute_599, permute_603, alias_41, permute_609, permute_612, permute_613, permute_616, div_44, permute_620, permute_624, div_45, permute_628, permute_633, permute_634, permute_638, alias_42, permute_644, permute_647, permute_648, permute_651, div_46, permute_655, permute_659, div_47, permute_663, permute_668, permute_669, permute_673, alias_43, permute_679, permute_682, permute_683, permute_686, div_48, permute_690, permute_694, div_49, permute_698, permute_703, permute_704, permute_708, alias_44, permute_714, permute_717, permute_718, permute_721, div_50, permute_725, permute_729, div_51, permute_733, permute_738, permute_739, permute_743, alias_45, permute_749, permute_752, permute_753, permute_756, div_52, permute_760, permute_764, div_53, permute_768, permute_773, permute_774, permute_778, alias_46, permute_784, permute_787, permute_788, permute_791, div_54, permute_795, permute_799, div_55, permute_803, permute_808, permute_809, permute_813, alias_47, permute_819, permute_822, permute_823, permute_826, div_56, permute_830, permute_834, div_57, permute_838, permute_843, permute_844, permute_848, alias_48, permute_854, permute_857, permute_858, permute_861, div_58, permute_865, permute_869, div_59, permute_873, permute_878, permute_879, permute_883, alias_49, permute_889, permute_892, permute_893, permute_896, div_60, permute_900, permute_904, div_61, permute_908, permute_913, permute_914, permute_918, alias_50, permute_924, permute_927, permute_928, permute_931, div_62, permute_935, permute_939, div_63, permute_943, permute_948, permute_949, permute_953, alias_51, permute_959, permute_962, permute_963, permute_966, div_64, permute_970, permute_974, div_65, permute_978, permute_983, permute_984, permute_988, alias_52, permute_994, permute_997, permute_998, permute_1001, div_66, permute_1005, permute_1009, div_67, permute_1013, permute_1018, permute_1019, permute_1023, alias_53, permute_1029, permute_1032, permute_1033, permute_1036, div_68, permute_1040, permute_1044, div_69, permute_1048, permute_1053, permute_1054, permute_1058, alias_54, permute_1064, permute_1067, permute_1068, permute_1071, div_70, permute_1075, permute_1079, div_71, permute_1083, permute_1088, permute_1089, permute_1093, alias_55, permute_1099, permute_1102, permute_1103, permute_1106, div_72, permute_1110, permute_1114, div_73, permute_1118, permute_1123, permute_1124, permute_1128, alias_56, permute_1134, permute_1137, permute_1138, permute_1141, div_74, permute_1145, permute_1149, div_75, permute_1153, permute_1158, permute_1159, permute_1163, alias_57, permute_1169, permute_1172, permute_1173, permute_1176, div_76, permute_1180, permute_1184, div_77, permute_1188, permute_1193, permute_1194, permute_1198, alias_58, permute_1204, permute_1207, permute_1208, permute_1211, div_78, permute_1215, permute_1219, div_79, permute_1223, permute_1228, permute_1229, permute_1233, alias_59, permute_1239, permute_1242, permute_1243, permute_1246, div_80, permute_1250, permute_1254, div_81, permute_1258, permute_1263, permute_1264, permute_1268, alias_60, permute_1274, permute_1277, permute_1278, permute_1281, div_82, permute_1285, permute_1289, div_83, permute_1293, permute_1298, permute_1299, permute_1303, alias_61, permute_1309, permute_1312, permute_1313, permute_1316, div_84, permute_1320, permute_1324, div_85, permute_1328, permute_1333, permute_1334, permute_1338, alias_62, permute_1344, permute_1347, permute_1348, permute_1351, div_86, permute_1355, permute_1359, div_87, permute_1363, permute_1368, permute_1369, permute_1373, alias_63, permute_1379, permute_1382, permute_1383, permute_1386, div_88, permute_1390, permute_1394, div_89, permute_1398, permute_1403, permute_1404, permute_1408, alias_64, permute_1414, permute_1417, permute_1418, permute_1421, div_90, permute_1425, permute_1429, div_91, permute_1433, permute_1438, permute_1439, permute_1443, alias_65, permute_1449, permute_1452, permute_1453, permute_1456, div_92, permute_1460, permute_1464, div_93, permute_1468, permute_1473, permute_1474, permute_1478, alias_66, permute_1484, permute_1487, permute_1488, permute_1491, div_94, permute_1495, permute_1499, div_95, permute_1503, permute_1508, permute_1509, permute_1513, alias_67, permute_1519, permute_1522, permute_1523, permute_1526, div_96, permute_1530, permute_1534, div_97, permute_1538, permute_1543, permute_1544, permute_1548, alias_68, permute_1554, permute_1557, permute_1558, permute_1561, div_98, permute_1565, permute_1569, div_99, permute_1573, permute_1578, permute_1579, permute_1583, alias_69, permute_1589, permute_1592, permute_1593, permute_1596, div_100, permute_1600, permute_1604, div_101, permute_1608, permute_1613, permute_1614, permute_1618, alias_70, permute_1624, permute_1627, permute_1628, permute_1631, div_102, permute_1635, permute_1639, div_103, permute_1643, permute_1648, permute_1649, permute_1653, alias_71, permute_1659, permute_1662, permute_1663, permute_1666, div_104, permute_1670, permute_1674, div_105, permute_1678, permute_1683, permute_1684, permute_1688, alias_72, permute_1694, permute_1697, permute_1698, permute_1701, div_106, permute_1705, permute_1709, div_107, permute_1713, permute_1718, permute_1719, permute_1723, alias_73, permute_1729, permute_1732, permute_1733, permute_1736, div_108, permute_1740, permute_1744, div_109, permute_1748, permute_1753, permute_1754, permute_1758, alias_74, permute_1764, permute_1767, permute_1768, permute_1771, div_110, permute_1775, permute_1779, div_111, permute_1783, permute_1788, permute_1789, permute_1793, alias_75, permute_1799, permute_1802, permute_1803, permute_1806, div_112, tangents_1 = args
    args.clear()
    assert_size_stride(primals_2, (768, ), (1, ))
    assert_size_stride(primals_3, (768, ), (1, ))
    assert_size_stride(primals_4, (768, ), (1, ))
    assert_size_stride(primals_5, (768, ), (1, ))
    assert_size_stride(primals_6, (768, ), (1, ))
    assert_size_stride(primals_7, (768, ), (1, ))
    assert_size_stride(primals_8, (768, ), (1, ))
    assert_size_stride(primals_9, (768, ), (1, ))
    assert_size_stride(primals_10, (768, ), (1, ))
    assert_size_stride(primals_11, (768, ), (1, ))
    assert_size_stride(primals_12, (768, ), (1, ))
    assert_size_stride(primals_13, (768, ), (1, ))
    assert_size_stride(primals_14, (768, ), (1, ))
    assert_size_stride(primals_15, (768, ), (1, ))
    assert_size_stride(primals_16, (768, ), (1, ))
    assert_size_stride(primals_17, (768, ), (1, ))
    assert_size_stride(primals_18, (768, ), (1, ))
    assert_size_stride(primals_19, (768, ), (1, ))
    assert_size_stride(primals_20, (768, ), (1, ))
    assert_size_stride(primals_21, (768, ), (1, ))
    assert_size_stride(primals_22, (768, ), (1, ))
    assert_size_stride(primals_23, (768, ), (1, ))
    assert_size_stride(primals_24, (768, ), (1, ))
    assert_size_stride(primals_25, (768, ), (1, ))
    assert_size_stride(primals_26, (768, ), (1, ))
    assert_size_stride(primals_27, (768, ), (1, ))
    assert_size_stride(primals_28, (768, ), (1, ))
    assert_size_stride(primals_29, (768, ), (1, ))
    assert_size_stride(primals_30, (768, ), (1, ))
    assert_size_stride(primals_31, (768, ), (1, ))
    assert_size_stride(primals_32, (768, ), (1, ))
    assert_size_stride(primals_33, (768, ), (1, ))
    assert_size_stride(primals_34, (768, ), (1, ))
    assert_size_stride(primals_35, (768, ), (1, ))
    assert_size_stride(primals_36, (768, ), (1, ))
    assert_size_stride(primals_37, (768, ), (1, ))
    assert_size_stride(primals_38, (768, ), (1, ))
    assert_size_stride(primals_39, (768, ), (1, ))
    assert_size_stride(primals_40, (768, ), (1, ))
    assert_size_stride(primals_41, (768, ), (1, ))
    assert_size_stride(primals_42, (768, ), (1, ))
    assert_size_stride(primals_43, (768, ), (1, ))
    assert_size_stride(primals_44, (768, ), (1, ))
    assert_size_stride(primals_45, (768, ), (1, ))
    assert_size_stride(primals_46, (768, ), (1, ))
    assert_size_stride(primals_47, (768, ), (1, ))
    assert_size_stride(primals_48, (768, ), (1, ))
    assert_size_stride(primals_49, (768, ), (1, ))
    assert_size_stride(primals_50, (768, ), (1, ))
    assert_size_stride(primals_51, (768, ), (1, ))
    assert_size_stride(primals_52, (768, ), (1, ))
    assert_size_stride(primals_53, (768, ), (1, ))
    assert_size_stride(primals_54, (768, ), (1, ))
    assert_size_stride(primals_55, (768, ), (1, ))
    assert_size_stride(primals_56, (768, ), (1, ))
    assert_size_stride(primals_57, (768, ), (1, ))
    assert_size_stride(primals_58, (768, ), (1, ))
    assert_size_stride(primals_59, (768, ), (1, ))
    assert_size_stride(primals_60, (768, ), (1, ))
    assert_size_stride(primals_61, (768, ), (1, ))
    assert_size_stride(primals_62, (768, ), (1, ))
    assert_size_stride(primals_63, (768, ), (1, ))
    assert_size_stride(primals_64, (768, ), (1, ))
    assert_size_stride(primals_65, (768, ), (1, ))
    assert_size_stride(primals_66, (768, ), (1, ))
    assert_size_stride(primals_67, (768, ), (1, ))
    assert_size_stride(primals_68, (768, ), (1, ))
    assert_size_stride(primals_69, (768, ), (1, ))
    assert_size_stride(primals_70, (768, ), (1, ))
    assert_size_stride(primals_71, (768, ), (1, ))
    assert_size_stride(primals_72, (768, ), (1, ))
    assert_size_stride(primals_73, (768, ), (1, ))
    assert_size_stride(primals_75, (768, ), (1, ))
    assert_size_stride(primals_76, (768, ), (1, ))
    assert_size_stride(primals_77, (768, ), (1, ))
    assert_size_stride(primals_78, (768, ), (1, ))
    assert_size_stride(primals_79, (768, 3, 16, 16), (768, 1, 48, 3))
    assert_size_stride(primals_81, (768, ), (1, ))
    assert_size_stride(primals_91, (768, ), (1, ))
    assert_size_stride(primals_97, (768, ), (1, ))
    assert_size_stride(primals_107, (768, ), (1, ))
    assert_size_stride(primals_113, (768, ), (1, ))
    assert_size_stride(primals_123, (768, ), (1, ))
    assert_size_stride(primals_129, (768, ), (1, ))
    assert_size_stride(primals_139, (768, ), (1, ))
    assert_size_stride(primals_145, (768, ), (1, ))
    assert_size_stride(primals_155, (768, ), (1, ))
    assert_size_stride(primals_161, (768, ), (1, ))
    assert_size_stride(primals_171, (768, ), (1, ))
    assert_size_stride(primals_177, (768, ), (1, ))
    assert_size_stride(primals_187, (768, ), (1, ))
    assert_size_stride(primals_193, (768, ), (1, ))
    assert_size_stride(primals_203, (768, ), (1, ))
    assert_size_stride(primals_209, (768, ), (1, ))
    assert_size_stride(primals_219, (768, ), (1, ))
    assert_size_stride(primals_225, (768, ), (1, ))
    assert_size_stride(primals_235, (768, ), (1, ))
    assert_size_stride(primals_241, (768, ), (1, ))
    assert_size_stride(primals_251, (768, ), (1, ))
    assert_size_stride(primals_257, (768, ), (1, ))
    assert_size_stride(primals_267, (768, ), (1, ))
    assert_size_stride(primals_273, (768, ), (1, ))
    assert_size_stride(primals_283, (768, ), (1, ))
    assert_size_stride(primals_289, (768, ), (1, ))
    assert_size_stride(primals_299, (768, ), (1, ))
    assert_size_stride(primals_305, (768, ), (1, ))
    assert_size_stride(primals_315, (768, ), (1, ))
    assert_size_stride(primals_321, (768, ), (1, ))
    assert_size_stride(primals_331, (768, ), (1, ))
    assert_size_stride(primals_337, (768, ), (1, ))
    assert_size_stride(primals_347, (768, ), (1, ))
    assert_size_stride(primals_353, (768, ), (1, ))
    assert_size_stride(primals_363, (768, ), (1, ))
    assert_size_stride(primals_369, (768, ), (1, ))
    assert_size_stride(primals_379, (768, ), (1, ))
    assert_size_stride(primals_385, (768, ), (1, ))
    assert_size_stride(primals_395, (768, ), (1, ))
    assert_size_stride(primals_401, (768, ), (1, ))
    assert_size_stride(primals_411, (768, ), (1, ))
    assert_size_stride(primals_417, (768, ), (1, ))
    assert_size_stride(primals_427, (768, ), (1, ))
    assert_size_stride(primals_433, (768, ), (1, ))
    assert_size_stride(primals_443, (768, ), (1, ))
    assert_size_stride(primals_449, (768, ), (1, ))
    assert_size_stride(primals_459, (768, ), (1, ))
    assert_size_stride(primals_465, (768, ), (1, ))
    assert_size_stride(primals_475, (768, ), (1, ))
    assert_size_stride(primals_481, (768, ), (1, ))
    assert_size_stride(primals_491, (768, ), (1, ))
    assert_size_stride(primals_497, (768, ), (1, ))
    assert_size_stride(primals_507, (768, ), (1, ))
    assert_size_stride(primals_513, (768, ), (1, ))
    assert_size_stride(primals_523, (768, ), (1, ))
    assert_size_stride(primals_529, (768, ), (1, ))
    assert_size_stride(primals_539, (768, ), (1, ))
    assert_size_stride(primals_545, (768, ), (1, ))
    assert_size_stride(primals_555, (768, ), (1, ))
    assert_size_stride(primals_561, (768, ), (1, ))
    assert_size_stride(primals_571, (768, ), (1, ))
    assert_size_stride(primals_577, (768, ), (1, ))
    assert_size_stride(primals_587, (768, ), (1, ))
    assert_size_stride(primals_593, (768, ), (1, ))
    assert_size_stride(primals_603, (768, ), (1, ))
    assert_size_stride(primals_609, (768, ), (1, ))
    assert_size_stride(primals_619, (768, ), (1, ))
    assert_size_stride(primals_625, (768, ), (1, ))
    assert_size_stride(primals_635, (768, ), (1, ))
    assert_size_stride(primals_641, (768, ), (1, ))
    assert_size_stride(primals_651, (768, ), (1, ))
    assert_size_stride(primals_657, (768, ), (1, ))
    assert_size_stride(primals_667, (768, ), (1, ))
    assert_size_stride(primals_673, (768, ), (1, ))
    assert_size_stride(primals_683, (768, ), (1, ))
    assert_size_stride(primals_689, (768, ), (1, ))
    assert_size_stride(primals_693, (8, 3, 384, 384), (442368, 1, 1152, 3))
    assert_size_stride(mul, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_1, (4608, 768), (768, 1))
    assert_size_stride(view_7, (2654208, 16), (16, 1))
    assert_size_stride(view_9, (2654208, 16), (16, 1))
    assert_size_stride(view_15, (4608, 768), (768, 1))
    assert_size_stride(addmm_1, (4608, 768), (768, 1))
    assert_size_stride(mul_4, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_17, (4608, 768), (768, 1))
    assert_size_stride(addmm_2, (4608, 3072), (3072, 1))
    assert_size_stride(view_19, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_3, (4608, 768), (768, 1))
    assert_size_stride(mul_10, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_21, (4608, 768), (768, 1))
    assert_size_stride(view_27, (2654208, 16), (16, 1))
    assert_size_stride(view_29, (2654208, 16), (16, 1))
    assert_size_stride(view_35, (4608, 768), (768, 1))
    assert_size_stride(addmm_5, (4608, 768), (768, 1))
    assert_size_stride(mul_14, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_37, (4608, 768), (768, 1))
    assert_size_stride(addmm_6, (4608, 3072), (3072, 1))
    assert_size_stride(view_39, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_7, (4608, 768), (768, 1))
    assert_size_stride(mul_20, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_41, (4608, 768), (768, 1))
    assert_size_stride(view_47, (2654208, 16), (16, 1))
    assert_size_stride(view_49, (2654208, 16), (16, 1))
    assert_size_stride(view_55, (4608, 768), (768, 1))
    assert_size_stride(addmm_9, (4608, 768), (768, 1))
    assert_size_stride(mul_24, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_57, (4608, 768), (768, 1))
    assert_size_stride(addmm_10, (4608, 3072), (3072, 1))
    assert_size_stride(view_59, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_11, (4608, 768), (768, 1))
    assert_size_stride(mul_30, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_61, (4608, 768), (768, 1))
    assert_size_stride(view_67, (2654208, 16), (16, 1))
    assert_size_stride(view_69, (2654208, 16), (16, 1))
    assert_size_stride(view_75, (4608, 768), (768, 1))
    assert_size_stride(addmm_13, (4608, 768), (768, 1))
    assert_size_stride(mul_34, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_77, (4608, 768), (768, 1))
    assert_size_stride(addmm_14, (4608, 3072), (3072, 1))
    assert_size_stride(view_79, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_15, (4608, 768), (768, 1))
    assert_size_stride(mul_40, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_81, (4608, 768), (768, 1))
    assert_size_stride(view_87, (2654208, 16), (16, 1))
    assert_size_stride(view_89, (2654208, 16), (16, 1))
    assert_size_stride(view_95, (4608, 768), (768, 1))
    assert_size_stride(addmm_17, (4608, 768), (768, 1))
    assert_size_stride(mul_44, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_97, (4608, 768), (768, 1))
    assert_size_stride(addmm_18, (4608, 3072), (3072, 1))
    assert_size_stride(view_99, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_19, (4608, 768), (768, 1))
    assert_size_stride(mul_50, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_101, (4608, 768), (768, 1))
    assert_size_stride(view_107, (2654208, 16), (16, 1))
    assert_size_stride(view_109, (2654208, 16), (16, 1))
    assert_size_stride(view_115, (4608, 768), (768, 1))
    assert_size_stride(addmm_21, (4608, 768), (768, 1))
    assert_size_stride(mul_54, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_117, (4608, 768), (768, 1))
    assert_size_stride(addmm_22, (4608, 3072), (3072, 1))
    assert_size_stride(view_119, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_23, (4608, 768), (768, 1))
    assert_size_stride(mul_60, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_121, (4608, 768), (768, 1))
    assert_size_stride(view_127, (2654208, 16), (16, 1))
    assert_size_stride(view_129, (2654208, 16), (16, 1))
    assert_size_stride(view_135, (4608, 768), (768, 1))
    assert_size_stride(addmm_25, (4608, 768), (768, 1))
    assert_size_stride(mul_64, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_137, (4608, 768), (768, 1))
    assert_size_stride(addmm_26, (4608, 3072), (3072, 1))
    assert_size_stride(view_139, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_27, (4608, 768), (768, 1))
    assert_size_stride(mul_70, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_141, (4608, 768), (768, 1))
    assert_size_stride(view_147, (2654208, 16), (16, 1))
    assert_size_stride(view_149, (2654208, 16), (16, 1))
    assert_size_stride(view_155, (4608, 768), (768, 1))
    assert_size_stride(addmm_29, (4608, 768), (768, 1))
    assert_size_stride(mul_74, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_157, (4608, 768), (768, 1))
    assert_size_stride(addmm_30, (4608, 3072), (3072, 1))
    assert_size_stride(view_159, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_31, (4608, 768), (768, 1))
    assert_size_stride(mul_80, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_161, (4608, 768), (768, 1))
    assert_size_stride(view_167, (2654208, 16), (16, 1))
    assert_size_stride(view_169, (2654208, 16), (16, 1))
    assert_size_stride(view_175, (4608, 768), (768, 1))
    assert_size_stride(addmm_33, (4608, 768), (768, 1))
    assert_size_stride(mul_84, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_177, (4608, 768), (768, 1))
    assert_size_stride(addmm_34, (4608, 3072), (3072, 1))
    assert_size_stride(view_179, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_35, (4608, 768), (768, 1))
    assert_size_stride(mul_90, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_181, (4608, 768), (768, 1))
    assert_size_stride(view_187, (2654208, 16), (16, 1))
    assert_size_stride(view_189, (2654208, 16), (16, 1))
    assert_size_stride(view_195, (4608, 768), (768, 1))
    assert_size_stride(addmm_37, (4608, 768), (768, 1))
    assert_size_stride(mul_94, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_197, (4608, 768), (768, 1))
    assert_size_stride(addmm_38, (4608, 3072), (3072, 1))
    assert_size_stride(view_199, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_39, (4608, 768), (768, 1))
    assert_size_stride(mul_100, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_201, (4608, 768), (768, 1))
    assert_size_stride(view_207, (2654208, 16), (16, 1))
    assert_size_stride(view_209, (2654208, 16), (16, 1))
    assert_size_stride(view_215, (4608, 768), (768, 1))
    assert_size_stride(addmm_41, (4608, 768), (768, 1))
    assert_size_stride(mul_104, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_217, (4608, 768), (768, 1))
    assert_size_stride(addmm_42, (4608, 3072), (3072, 1))
    assert_size_stride(view_219, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_43, (4608, 768), (768, 1))
    assert_size_stride(mul_110, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_221, (4608, 768), (768, 1))
    assert_size_stride(view_227, (2654208, 16), (16, 1))
    assert_size_stride(view_229, (2654208, 16), (16, 1))
    assert_size_stride(view_235, (4608, 768), (768, 1))
    assert_size_stride(addmm_45, (4608, 768), (768, 1))
    assert_size_stride(mul_114, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_237, (4608, 768), (768, 1))
    assert_size_stride(addmm_46, (4608, 3072), (3072, 1))
    assert_size_stride(view_239, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_47, (4608, 768), (768, 1))
    assert_size_stride(mul_120, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_241, (4608, 768), (768, 1))
    assert_size_stride(view_247, (2654208, 16), (16, 1))
    assert_size_stride(view_249, (2654208, 16), (16, 1))
    assert_size_stride(view_255, (4608, 768), (768, 1))
    assert_size_stride(addmm_49, (4608, 768), (768, 1))
    assert_size_stride(mul_124, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_257, (4608, 768), (768, 1))
    assert_size_stride(addmm_50, (4608, 3072), (3072, 1))
    assert_size_stride(view_259, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_51, (4608, 768), (768, 1))
    assert_size_stride(mul_130, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_261, (4608, 768), (768, 1))
    assert_size_stride(view_267, (2654208, 16), (16, 1))
    assert_size_stride(view_269, (2654208, 16), (16, 1))
    assert_size_stride(view_275, (4608, 768), (768, 1))
    assert_size_stride(addmm_53, (4608, 768), (768, 1))
    assert_size_stride(mul_134, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_277, (4608, 768), (768, 1))
    assert_size_stride(addmm_54, (4608, 3072), (3072, 1))
    assert_size_stride(view_279, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_55, (4608, 768), (768, 1))
    assert_size_stride(mul_140, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_281, (4608, 768), (768, 1))
    assert_size_stride(view_287, (2654208, 16), (16, 1))
    assert_size_stride(view_289, (2654208, 16), (16, 1))
    assert_size_stride(view_295, (4608, 768), (768, 1))
    assert_size_stride(addmm_57, (4608, 768), (768, 1))
    assert_size_stride(mul_144, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_297, (4608, 768), (768, 1))
    assert_size_stride(addmm_58, (4608, 3072), (3072, 1))
    assert_size_stride(view_299, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_59, (4608, 768), (768, 1))
    assert_size_stride(mul_150, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_301, (4608, 768), (768, 1))
    assert_size_stride(view_307, (2654208, 16), (16, 1))
    assert_size_stride(view_309, (2654208, 16), (16, 1))
    assert_size_stride(view_315, (4608, 768), (768, 1))
    assert_size_stride(addmm_61, (4608, 768), (768, 1))
    assert_size_stride(mul_154, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_317, (4608, 768), (768, 1))
    assert_size_stride(addmm_62, (4608, 3072), (3072, 1))
    assert_size_stride(view_319, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_63, (4608, 768), (768, 1))
    assert_size_stride(mul_160, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_321, (4608, 768), (768, 1))
    assert_size_stride(view_327, (2654208, 16), (16, 1))
    assert_size_stride(view_329, (2654208, 16), (16, 1))
    assert_size_stride(view_335, (4608, 768), (768, 1))
    assert_size_stride(addmm_65, (4608, 768), (768, 1))
    assert_size_stride(mul_164, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_337, (4608, 768), (768, 1))
    assert_size_stride(addmm_66, (4608, 3072), (3072, 1))
    assert_size_stride(view_339, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_67, (4608, 768), (768, 1))
    assert_size_stride(mul_170, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_341, (4608, 768), (768, 1))
    assert_size_stride(view_347, (2654208, 16), (16, 1))
    assert_size_stride(view_349, (2654208, 16), (16, 1))
    assert_size_stride(view_355, (4608, 768), (768, 1))
    assert_size_stride(addmm_69, (4608, 768), (768, 1))
    assert_size_stride(mul_174, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_357, (4608, 768), (768, 1))
    assert_size_stride(addmm_70, (4608, 3072), (3072, 1))
    assert_size_stride(view_359, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_71, (4608, 768), (768, 1))
    assert_size_stride(mul_180, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_361, (4608, 768), (768, 1))
    assert_size_stride(view_367, (2654208, 16), (16, 1))
    assert_size_stride(view_369, (2654208, 16), (16, 1))
    assert_size_stride(view_375, (4608, 768), (768, 1))
    assert_size_stride(addmm_73, (4608, 768), (768, 1))
    assert_size_stride(mul_184, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_377, (4608, 768), (768, 1))
    assert_size_stride(addmm_74, (4608, 3072), (3072, 1))
    assert_size_stride(view_379, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_75, (4608, 768), (768, 1))
    assert_size_stride(mul_190, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_381, (4608, 768), (768, 1))
    assert_size_stride(view_387, (2654208, 16), (16, 1))
    assert_size_stride(view_389, (2654208, 16), (16, 1))
    assert_size_stride(view_395, (4608, 768), (768, 1))
    assert_size_stride(addmm_77, (4608, 768), (768, 1))
    assert_size_stride(mul_194, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_397, (4608, 768), (768, 1))
    assert_size_stride(addmm_78, (4608, 3072), (3072, 1))
    assert_size_stride(view_399, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_79, (4608, 768), (768, 1))
    assert_size_stride(mul_200, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_401, (4608, 768), (768, 1))
    assert_size_stride(view_407, (2654208, 16), (16, 1))
    assert_size_stride(view_409, (2654208, 16), (16, 1))
    assert_size_stride(view_415, (4608, 768), (768, 1))
    assert_size_stride(addmm_81, (4608, 768), (768, 1))
    assert_size_stride(mul_204, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_417, (4608, 768), (768, 1))
    assert_size_stride(addmm_82, (4608, 3072), (3072, 1))
    assert_size_stride(view_419, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_83, (4608, 768), (768, 1))
    assert_size_stride(mul_210, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_421, (4608, 768), (768, 1))
    assert_size_stride(view_427, (2654208, 16), (16, 1))
    assert_size_stride(view_429, (2654208, 16), (16, 1))
    assert_size_stride(view_435, (4608, 768), (768, 1))
    assert_size_stride(addmm_85, (4608, 768), (768, 1))
    assert_size_stride(mul_214, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_437, (4608, 768), (768, 1))
    assert_size_stride(addmm_86, (4608, 3072), (3072, 1))
    assert_size_stride(view_439, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_87, (4608, 768), (768, 1))
    assert_size_stride(mul_220, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_441, (4608, 768), (768, 1))
    assert_size_stride(view_447, (2654208, 16), (16, 1))
    assert_size_stride(view_449, (2654208, 16), (16, 1))
    assert_size_stride(view_455, (4608, 768), (768, 1))
    assert_size_stride(addmm_89, (4608, 768), (768, 1))
    assert_size_stride(mul_224, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_457, (4608, 768), (768, 1))
    assert_size_stride(addmm_90, (4608, 3072), (3072, 1))
    assert_size_stride(view_459, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_91, (4608, 768), (768, 1))
    assert_size_stride(mul_230, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_461, (4608, 768), (768, 1))
    assert_size_stride(view_467, (2654208, 16), (16, 1))
    assert_size_stride(view_469, (2654208, 16), (16, 1))
    assert_size_stride(view_475, (4608, 768), (768, 1))
    assert_size_stride(addmm_93, (4608, 768), (768, 1))
    assert_size_stride(mul_234, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_477, (4608, 768), (768, 1))
    assert_size_stride(addmm_94, (4608, 3072), (3072, 1))
    assert_size_stride(view_479, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_95, (4608, 768), (768, 1))
    assert_size_stride(mul_240, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_481, (4608, 768), (768, 1))
    assert_size_stride(view_487, (2654208, 16), (16, 1))
    assert_size_stride(view_489, (2654208, 16), (16, 1))
    assert_size_stride(view_495, (4608, 768), (768, 1))
    assert_size_stride(addmm_97, (4608, 768), (768, 1))
    assert_size_stride(mul_244, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_497, (4608, 768), (768, 1))
    assert_size_stride(addmm_98, (4608, 3072), (3072, 1))
    assert_size_stride(view_499, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_99, (4608, 768), (768, 1))
    assert_size_stride(mul_250, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_501, (4608, 768), (768, 1))
    assert_size_stride(view_507, (2654208, 16), (16, 1))
    assert_size_stride(view_509, (2654208, 16), (16, 1))
    assert_size_stride(view_515, (4608, 768), (768, 1))
    assert_size_stride(addmm_101, (4608, 768), (768, 1))
    assert_size_stride(mul_254, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_517, (4608, 768), (768, 1))
    assert_size_stride(addmm_102, (4608, 3072), (3072, 1))
    assert_size_stride(view_519, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_103, (4608, 768), (768, 1))
    assert_size_stride(mul_260, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_521, (4608, 768), (768, 1))
    assert_size_stride(view_527, (2654208, 16), (16, 1))
    assert_size_stride(view_529, (2654208, 16), (16, 1))
    assert_size_stride(view_535, (4608, 768), (768, 1))
    assert_size_stride(addmm_105, (4608, 768), (768, 1))
    assert_size_stride(mul_264, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_537, (4608, 768), (768, 1))
    assert_size_stride(addmm_106, (4608, 3072), (3072, 1))
    assert_size_stride(view_539, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_107, (4608, 768), (768, 1))
    assert_size_stride(mul_270, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_541, (4608, 768), (768, 1))
    assert_size_stride(view_547, (2654208, 16), (16, 1))
    assert_size_stride(view_549, (2654208, 16), (16, 1))
    assert_size_stride(view_555, (4608, 768), (768, 1))
    assert_size_stride(addmm_109, (4608, 768), (768, 1))
    assert_size_stride(mul_274, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_557, (4608, 768), (768, 1))
    assert_size_stride(addmm_110, (4608, 3072), (3072, 1))
    assert_size_stride(view_559, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_111, (4608, 768), (768, 1))
    assert_size_stride(mul_280, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_561, (4608, 768), (768, 1))
    assert_size_stride(view_567, (2654208, 16), (16, 1))
    assert_size_stride(view_569, (2654208, 16), (16, 1))
    assert_size_stride(view_575, (4608, 768), (768, 1))
    assert_size_stride(addmm_113, (4608, 768), (768, 1))
    assert_size_stride(mul_284, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_577, (4608, 768), (768, 1))
    assert_size_stride(addmm_114, (4608, 3072), (3072, 1))
    assert_size_stride(view_579, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_115, (4608, 768), (768, 1))
    assert_size_stride(mul_290, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_581, (4608, 768), (768, 1))
    assert_size_stride(view_587, (2654208, 16), (16, 1))
    assert_size_stride(view_589, (2654208, 16), (16, 1))
    assert_size_stride(view_595, (4608, 768), (768, 1))
    assert_size_stride(addmm_117, (4608, 768), (768, 1))
    assert_size_stride(mul_294, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_597, (4608, 768), (768, 1))
    assert_size_stride(addmm_118, (4608, 3072), (3072, 1))
    assert_size_stride(view_599, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_119, (4608, 768), (768, 1))
    assert_size_stride(mul_300, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_601, (4608, 768), (768, 1))
    assert_size_stride(view_607, (2654208, 16), (16, 1))
    assert_size_stride(view_609, (2654208, 16), (16, 1))
    assert_size_stride(view_615, (4608, 768), (768, 1))
    assert_size_stride(addmm_121, (4608, 768), (768, 1))
    assert_size_stride(mul_304, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_617, (4608, 768), (768, 1))
    assert_size_stride(addmm_122, (4608, 3072), (3072, 1))
    assert_size_stride(view_619, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_123, (4608, 768), (768, 1))
    assert_size_stride(mul_310, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_621, (4608, 768), (768, 1))
    assert_size_stride(view_627, (2654208, 16), (16, 1))
    assert_size_stride(view_629, (2654208, 16), (16, 1))
    assert_size_stride(view_635, (4608, 768), (768, 1))
    assert_size_stride(addmm_125, (4608, 768), (768, 1))
    assert_size_stride(mul_314, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_637, (4608, 768), (768, 1))
    assert_size_stride(addmm_126, (4608, 3072), (3072, 1))
    assert_size_stride(view_639, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_127, (4608, 768), (768, 1))
    assert_size_stride(mul_320, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_641, (4608, 768), (768, 1))
    assert_size_stride(view_647, (2654208, 16), (16, 1))
    assert_size_stride(view_649, (2654208, 16), (16, 1))
    assert_size_stride(view_655, (4608, 768), (768, 1))
    assert_size_stride(addmm_129, (4608, 768), (768, 1))
    assert_size_stride(mul_324, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_657, (4608, 768), (768, 1))
    assert_size_stride(addmm_130, (4608, 3072), (3072, 1))
    assert_size_stride(view_659, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_131, (4608, 768), (768, 1))
    assert_size_stride(mul_330, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_661, (4608, 768), (768, 1))
    assert_size_stride(view_667, (2654208, 16), (16, 1))
    assert_size_stride(view_669, (2654208, 16), (16, 1))
    assert_size_stride(view_675, (4608, 768), (768, 1))
    assert_size_stride(addmm_133, (4608, 768), (768, 1))
    assert_size_stride(mul_334, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_677, (4608, 768), (768, 1))
    assert_size_stride(addmm_134, (4608, 3072), (3072, 1))
    assert_size_stride(view_679, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_135, (4608, 768), (768, 1))
    assert_size_stride(mul_340, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_681, (4608, 768), (768, 1))
    assert_size_stride(view_687, (2654208, 16), (16, 1))
    assert_size_stride(view_689, (2654208, 16), (16, 1))
    assert_size_stride(view_695, (4608, 768), (768, 1))
    assert_size_stride(addmm_137, (4608, 768), (768, 1))
    assert_size_stride(mul_344, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_697, (4608, 768), (768, 1))
    assert_size_stride(addmm_138, (4608, 3072), (3072, 1))
    assert_size_stride(view_699, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_139, (4608, 768), (768, 1))
    assert_size_stride(mul_350, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_701, (4608, 768), (768, 1))
    assert_size_stride(view_707, (2654208, 16), (16, 1))
    assert_size_stride(view_709, (2654208, 16), (16, 1))
    assert_size_stride(view_715, (4608, 768), (768, 1))
    assert_size_stride(addmm_141, (4608, 768), (768, 1))
    assert_size_stride(mul_354, (8, 576, 768), (442368, 768, 1))
    assert_size_stride(view_717, (4608, 768), (768, 1))
    assert_size_stride(addmm_142, (4608, 3072), (3072, 1))
    assert_size_stride(view_719, (4608, 3072), (3072, 1))
    assert_size_stride(addmm_143, (4608, 768), (768, 1))
    assert_size_stride(cat, (8, 577, 768), (443136, 768, 1))
    assert_size_stride(getitem_145, (8, 577, 1), (577, 1, 1))
    assert_size_stride(rsqrt_72, (8, 577, 1), (577, 1, 1))
    assert_size_stride(select_108, (8, 768), (443136, 1))
    assert_size_stride(permute_470, (8, 16, 1, 48), (768, 1, 768, 16))
    assert_size_stride(view_722, (4616, 768), (768, 1))
    assert_size_stride(permute_472, (8, 16, 577, 48), (443136, 1, 768, 16))
    assert_size_stride(permute_474, (8, 16, 577, 48), (443136, 1, 768, 16))
    assert_size_stride(getitem_147, (8, 16, 1), (16, 1, 16))
    assert_size_stride(getitem_148, (), ())
    assert_size_stride(getitem_149, (), ())
    assert_size_stride(getitem_152, (), ())
    assert_size_stride(getitem_153, (), ())
    assert_size_stride(view_729, (8, 768), (768, 1))
    assert_size_stride(addmm_147, (8, 768), (768, 1))
    assert_size_stride(mul_363, (8, 1, 768), (768, 768, 1))
    assert_size_stride(view_731, (8, 768), (768, 1))
    assert_size_stride(addmm_148, (8, 3072), (3072, 1))
    assert_size_stride(view_733, (8, 3072), (3072, 1))
    assert_size_stride(addmm_149, (8, 768), (768, 1))
    assert_size_stride(cat_1, (8, 577, 768), (443136, 768, 1))
    assert_size_stride(getitem_158, (8, 577, 1), (577, 1, 1))
    assert_size_stride(rsqrt_74, (8, 577, 1), (577, 1, 1))
    assert_size_stride(select_109, (8, 768), (443136, 1))
    assert_size_stride(permute_480, (8, 16, 1, 48), (768, 1, 768, 16))
    assert_size_stride(view_736, (4616, 768), (768, 1))
    assert_size_stride(permute_482, (8, 16, 577, 48), (443136, 1, 768, 16))
    assert_size_stride(permute_484, (8, 16, 577, 48), (443136, 1, 768, 16))
    assert_size_stride(getitem_160, (8, 16, 1), (16, 1, 16))
    assert_size_stride(getitem_161, (), ())
    assert_size_stride(getitem_162, (), ())
    assert_size_stride(getitem_165, (), ())
    assert_size_stride(getitem_166, (), ())
    assert_size_stride(view_743, (8, 768), (768, 1))
    assert_size_stride(addmm_153, (8, 768), (768, 1))
    assert_size_stride(mul_372, (8, 1, 768), (768, 768, 1))
    assert_size_stride(view_745, (8, 768), (768, 1))
    assert_size_stride(addmm_154, (8, 3072), (3072, 1))
    assert_size_stride(view_747, (8, 3072), (3072, 1))
    assert_size_stride(addmm_155, (8, 768), (768, 1))
    assert_size_stride(cat_2, (8, 577, 768), (443136, 768, 1))
    assert_size_stride(getitem_171, (8, 577, 1), (577, 1, 1))
    assert_size_stride(rsqrt_76, (8, 577, 1), (577, 1, 1))
    assert_size_stride(clone_511, (8, 768), (768, 1))
    assert_size_stride(permute_490, (1000, 768), (768, 1))
    assert_size_stride(permute_494, (768, 3072), (3072, 1))
    assert_size_stride(permute_498, (3072, 768), (768, 1))
    assert_size_stride(div_37, (8, 1, 1), (1, 1, 1))
    assert_size_stride(permute_502, (768, 768), (768, 1))
    assert_size_stride(alias_38, (8, 16, 1, 48), (768, 1, 768, 16))
    assert_size_stride(permute_508, (768, 768), (768, 1))
    assert_size_stride(permute_513, (768, 768), (768, 1))
    assert_size_stride(permute_518, (768, 768), (768, 1))
    assert_size_stride(permute_522, (768, 3072), (3072, 1))
    assert_size_stride(permute_526, (3072, 768), (768, 1))
    assert_size_stride(div_39, (8, 1, 1), (1, 1, 1))
    assert_size_stride(permute_530, (768, 768), (768, 1))
    assert_size_stride(alias_39, (8, 16, 1, 48), (768, 1, 768, 16))
    assert_size_stride(permute_536, (768, 768), (768, 1))
    assert_size_stride(permute_541, (768, 768), (768, 1))
    assert_size_stride(permute_546, (768, 768), (768, 1))
    assert_size_stride(permute_550, (768, 3072), (3072, 1))
    assert_size_stride(permute_554, (3072, 768), (768, 1))
    assert_size_stride(div_41, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_558, (768, 768), (768, 1))
    assert_size_stride(permute_563, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_564, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_568, (16, 16), (16, 1))
    assert_size_stride(alias_40, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_574, (16, 16), (16, 1))
    assert_size_stride(permute_577, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_578, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_581, (2304, 768), (768, 1))
    assert_size_stride(div_42, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_585, (768, 3072), (3072, 1))
    assert_size_stride(permute_589, (3072, 768), (768, 1))
    assert_size_stride(div_43, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_593, (768, 768), (768, 1))
    assert_size_stride(permute_598, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_599, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_603, (16, 16), (16, 1))
    assert_size_stride(alias_41, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_609, (16, 16), (16, 1))
    assert_size_stride(permute_612, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_613, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_616, (2304, 768), (768, 1))
    assert_size_stride(div_44, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_620, (768, 3072), (3072, 1))
    assert_size_stride(permute_624, (3072, 768), (768, 1))
    assert_size_stride(div_45, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_628, (768, 768), (768, 1))
    assert_size_stride(permute_633, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_634, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_638, (16, 16), (16, 1))
    assert_size_stride(alias_42, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_644, (16, 16), (16, 1))
    assert_size_stride(permute_647, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_648, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_651, (2304, 768), (768, 1))
    assert_size_stride(div_46, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_655, (768, 3072), (3072, 1))
    assert_size_stride(permute_659, (3072, 768), (768, 1))
    assert_size_stride(div_47, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_663, (768, 768), (768, 1))
    assert_size_stride(permute_668, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_669, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_673, (16, 16), (16, 1))
    assert_size_stride(alias_43, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_679, (16, 16), (16, 1))
    assert_size_stride(permute_682, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_683, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_686, (2304, 768), (768, 1))
    assert_size_stride(div_48, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_690, (768, 3072), (3072, 1))
    assert_size_stride(permute_694, (3072, 768), (768, 1))
    assert_size_stride(div_49, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_698, (768, 768), (768, 1))
    assert_size_stride(permute_703, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_704, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_708, (16, 16), (16, 1))
    assert_size_stride(alias_44, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_714, (16, 16), (16, 1))
    assert_size_stride(permute_717, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_718, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_721, (2304, 768), (768, 1))
    assert_size_stride(div_50, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_725, (768, 3072), (3072, 1))
    assert_size_stride(permute_729, (3072, 768), (768, 1))
    assert_size_stride(div_51, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_733, (768, 768), (768, 1))
    assert_size_stride(permute_738, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_739, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_743, (16, 16), (16, 1))
    assert_size_stride(alias_45, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_749, (16, 16), (16, 1))
    assert_size_stride(permute_752, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_753, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_756, (2304, 768), (768, 1))
    assert_size_stride(div_52, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_760, (768, 3072), (3072, 1))
    assert_size_stride(permute_764, (3072, 768), (768, 1))
    assert_size_stride(div_53, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_768, (768, 768), (768, 1))
    assert_size_stride(permute_773, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_774, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_778, (16, 16), (16, 1))
    assert_size_stride(alias_46, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_784, (16, 16), (16, 1))
    assert_size_stride(permute_787, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_788, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_791, (2304, 768), (768, 1))
    assert_size_stride(div_54, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_795, (768, 3072), (3072, 1))
    assert_size_stride(permute_799, (3072, 768), (768, 1))
    assert_size_stride(div_55, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_803, (768, 768), (768, 1))
    assert_size_stride(permute_808, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_809, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_813, (16, 16), (16, 1))
    assert_size_stride(alias_47, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_819, (16, 16), (16, 1))
    assert_size_stride(permute_822, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_823, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_826, (2304, 768), (768, 1))
    assert_size_stride(div_56, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_830, (768, 3072), (3072, 1))
    assert_size_stride(permute_834, (3072, 768), (768, 1))
    assert_size_stride(div_57, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_838, (768, 768), (768, 1))
    assert_size_stride(permute_843, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_844, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_848, (16, 16), (16, 1))
    assert_size_stride(alias_48, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_854, (16, 16), (16, 1))
    assert_size_stride(permute_857, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_858, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_861, (2304, 768), (768, 1))
    assert_size_stride(div_58, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_865, (768, 3072), (3072, 1))
    assert_size_stride(permute_869, (3072, 768), (768, 1))
    assert_size_stride(div_59, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_873, (768, 768), (768, 1))
    assert_size_stride(permute_878, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_879, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_883, (16, 16), (16, 1))
    assert_size_stride(alias_49, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_889, (16, 16), (16, 1))
    assert_size_stride(permute_892, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_893, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_896, (2304, 768), (768, 1))
    assert_size_stride(div_60, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_900, (768, 3072), (3072, 1))
    assert_size_stride(permute_904, (3072, 768), (768, 1))
    assert_size_stride(div_61, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_908, (768, 768), (768, 1))
    assert_size_stride(permute_913, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_914, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_918, (16, 16), (16, 1))
    assert_size_stride(alias_50, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_924, (16, 16), (16, 1))
    assert_size_stride(permute_927, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_928, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_931, (2304, 768), (768, 1))
    assert_size_stride(div_62, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_935, (768, 3072), (3072, 1))
    assert_size_stride(permute_939, (3072, 768), (768, 1))
    assert_size_stride(div_63, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_943, (768, 768), (768, 1))
    assert_size_stride(permute_948, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_949, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_953, (16, 16), (16, 1))
    assert_size_stride(alias_51, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_959, (16, 16), (16, 1))
    assert_size_stride(permute_962, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_963, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_966, (2304, 768), (768, 1))
    assert_size_stride(div_64, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_970, (768, 3072), (3072, 1))
    assert_size_stride(permute_974, (3072, 768), (768, 1))
    assert_size_stride(div_65, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_978, (768, 768), (768, 1))
    assert_size_stride(permute_983, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_984, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_988, (16, 16), (16, 1))
    assert_size_stride(alias_52, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_994, (16, 16), (16, 1))
    assert_size_stride(permute_997, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_998, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1001, (2304, 768), (768, 1))
    assert_size_stride(div_66, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1005, (768, 3072), (3072, 1))
    assert_size_stride(permute_1009, (3072, 768), (768, 1))
    assert_size_stride(div_67, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1013, (768, 768), (768, 1))
    assert_size_stride(permute_1018, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1019, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1023, (16, 16), (16, 1))
    assert_size_stride(alias_53, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1029, (16, 16), (16, 1))
    assert_size_stride(permute_1032, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1033, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1036, (2304, 768), (768, 1))
    assert_size_stride(div_68, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1040, (768, 3072), (3072, 1))
    assert_size_stride(permute_1044, (3072, 768), (768, 1))
    assert_size_stride(div_69, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1048, (768, 768), (768, 1))
    assert_size_stride(permute_1053, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1054, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1058, (16, 16), (16, 1))
    assert_size_stride(alias_54, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1064, (16, 16), (16, 1))
    assert_size_stride(permute_1067, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1068, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1071, (2304, 768), (768, 1))
    assert_size_stride(div_70, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1075, (768, 3072), (3072, 1))
    assert_size_stride(permute_1079, (3072, 768), (768, 1))
    assert_size_stride(div_71, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1083, (768, 768), (768, 1))
    assert_size_stride(permute_1088, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1089, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1093, (16, 16), (16, 1))
    assert_size_stride(alias_55, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1099, (16, 16), (16, 1))
    assert_size_stride(permute_1102, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1103, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1106, (2304, 768), (768, 1))
    assert_size_stride(div_72, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1110, (768, 3072), (3072, 1))
    assert_size_stride(permute_1114, (3072, 768), (768, 1))
    assert_size_stride(div_73, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1118, (768, 768), (768, 1))
    assert_size_stride(permute_1123, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1124, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1128, (16, 16), (16, 1))
    assert_size_stride(alias_56, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1134, (16, 16), (16, 1))
    assert_size_stride(permute_1137, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1138, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1141, (2304, 768), (768, 1))
    assert_size_stride(div_74, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1145, (768, 3072), (3072, 1))
    assert_size_stride(permute_1149, (3072, 768), (768, 1))
    assert_size_stride(div_75, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1153, (768, 768), (768, 1))
    assert_size_stride(permute_1158, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1159, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1163, (16, 16), (16, 1))
    assert_size_stride(alias_57, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1169, (16, 16), (16, 1))
    assert_size_stride(permute_1172, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1173, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1176, (2304, 768), (768, 1))
    assert_size_stride(div_76, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1180, (768, 3072), (3072, 1))
    assert_size_stride(permute_1184, (3072, 768), (768, 1))
    assert_size_stride(div_77, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1188, (768, 768), (768, 1))
    assert_size_stride(permute_1193, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1194, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1198, (16, 16), (16, 1))
    assert_size_stride(alias_58, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1204, (16, 16), (16, 1))
    assert_size_stride(permute_1207, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1208, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1211, (2304, 768), (768, 1))
    assert_size_stride(div_78, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1215, (768, 3072), (3072, 1))
    assert_size_stride(permute_1219, (3072, 768), (768, 1))
    assert_size_stride(div_79, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1223, (768, 768), (768, 1))
    assert_size_stride(permute_1228, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1229, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1233, (16, 16), (16, 1))
    assert_size_stride(alias_59, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1239, (16, 16), (16, 1))
    assert_size_stride(permute_1242, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1243, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1246, (2304, 768), (768, 1))
    assert_size_stride(div_80, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1250, (768, 3072), (3072, 1))
    assert_size_stride(permute_1254, (3072, 768), (768, 1))
    assert_size_stride(div_81, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1258, (768, 768), (768, 1))
    assert_size_stride(permute_1263, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1264, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1268, (16, 16), (16, 1))
    assert_size_stride(alias_60, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1274, (16, 16), (16, 1))
    assert_size_stride(permute_1277, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1278, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1281, (2304, 768), (768, 1))
    assert_size_stride(div_82, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1285, (768, 3072), (3072, 1))
    assert_size_stride(permute_1289, (3072, 768), (768, 1))
    assert_size_stride(div_83, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1293, (768, 768), (768, 1))
    assert_size_stride(permute_1298, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1299, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1303, (16, 16), (16, 1))
    assert_size_stride(alias_61, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1309, (16, 16), (16, 1))
    assert_size_stride(permute_1312, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1313, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1316, (2304, 768), (768, 1))
    assert_size_stride(div_84, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1320, (768, 3072), (3072, 1))
    assert_size_stride(permute_1324, (3072, 768), (768, 1))
    assert_size_stride(div_85, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1328, (768, 768), (768, 1))
    assert_size_stride(permute_1333, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1334, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1338, (16, 16), (16, 1))
    assert_size_stride(alias_62, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1344, (16, 16), (16, 1))
    assert_size_stride(permute_1347, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1348, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1351, (2304, 768), (768, 1))
    assert_size_stride(div_86, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1355, (768, 3072), (3072, 1))
    assert_size_stride(permute_1359, (3072, 768), (768, 1))
    assert_size_stride(div_87, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1363, (768, 768), (768, 1))
    assert_size_stride(permute_1368, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1369, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1373, (16, 16), (16, 1))
    assert_size_stride(alias_63, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1379, (16, 16), (16, 1))
    assert_size_stride(permute_1382, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1383, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1386, (2304, 768), (768, 1))
    assert_size_stride(div_88, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1390, (768, 3072), (3072, 1))
    assert_size_stride(permute_1394, (3072, 768), (768, 1))
    assert_size_stride(div_89, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1398, (768, 768), (768, 1))
    assert_size_stride(permute_1403, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1404, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1408, (16, 16), (16, 1))
    assert_size_stride(alias_64, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1414, (16, 16), (16, 1))
    assert_size_stride(permute_1417, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1418, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1421, (2304, 768), (768, 1))
    assert_size_stride(div_90, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1425, (768, 3072), (3072, 1))
    assert_size_stride(permute_1429, (3072, 768), (768, 1))
    assert_size_stride(div_91, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1433, (768, 768), (768, 1))
    assert_size_stride(permute_1438, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1439, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1443, (16, 16), (16, 1))
    assert_size_stride(alias_65, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1449, (16, 16), (16, 1))
    assert_size_stride(permute_1452, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1453, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1456, (2304, 768), (768, 1))
    assert_size_stride(div_92, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1460, (768, 3072), (3072, 1))
    assert_size_stride(permute_1464, (3072, 768), (768, 1))
    assert_size_stride(div_93, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1468, (768, 768), (768, 1))
    assert_size_stride(permute_1473, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1474, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1478, (16, 16), (16, 1))
    assert_size_stride(alias_66, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1484, (16, 16), (16, 1))
    assert_size_stride(permute_1487, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1488, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1491, (2304, 768), (768, 1))
    assert_size_stride(div_94, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1495, (768, 3072), (3072, 1))
    assert_size_stride(permute_1499, (3072, 768), (768, 1))
    assert_size_stride(div_95, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1503, (768, 768), (768, 1))
    assert_size_stride(permute_1508, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1509, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1513, (16, 16), (16, 1))
    assert_size_stride(alias_67, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1519, (16, 16), (16, 1))
    assert_size_stride(permute_1522, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1523, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1526, (2304, 768), (768, 1))
    assert_size_stride(div_96, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1530, (768, 3072), (3072, 1))
    assert_size_stride(permute_1534, (3072, 768), (768, 1))
    assert_size_stride(div_97, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1538, (768, 768), (768, 1))
    assert_size_stride(permute_1543, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1544, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1548, (16, 16), (16, 1))
    assert_size_stride(alias_68, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1554, (16, 16), (16, 1))
    assert_size_stride(permute_1557, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1558, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1561, (2304, 768), (768, 1))
    assert_size_stride(div_98, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1565, (768, 3072), (3072, 1))
    assert_size_stride(permute_1569, (3072, 768), (768, 1))
    assert_size_stride(div_99, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1573, (768, 768), (768, 1))
    assert_size_stride(permute_1578, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1579, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1583, (16, 16), (16, 1))
    assert_size_stride(alias_69, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1589, (16, 16), (16, 1))
    assert_size_stride(permute_1592, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1593, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1596, (2304, 768), (768, 1))
    assert_size_stride(div_100, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1600, (768, 3072), (3072, 1))
    assert_size_stride(permute_1604, (3072, 768), (768, 1))
    assert_size_stride(div_101, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1608, (768, 768), (768, 1))
    assert_size_stride(permute_1613, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1614, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1618, (16, 16), (16, 1))
    assert_size_stride(alias_70, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1624, (16, 16), (16, 1))
    assert_size_stride(permute_1627, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1628, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1631, (2304, 768), (768, 1))
    assert_size_stride(div_102, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1635, (768, 3072), (3072, 1))
    assert_size_stride(permute_1639, (3072, 768), (768, 1))
    assert_size_stride(div_103, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1643, (768, 768), (768, 1))
    assert_size_stride(permute_1648, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1649, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1653, (16, 16), (16, 1))
    assert_size_stride(alias_71, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1659, (16, 16), (16, 1))
    assert_size_stride(permute_1662, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1663, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1666, (2304, 768), (768, 1))
    assert_size_stride(div_104, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1670, (768, 3072), (3072, 1))
    assert_size_stride(permute_1674, (3072, 768), (768, 1))
    assert_size_stride(div_105, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1678, (768, 768), (768, 1))
    assert_size_stride(permute_1683, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1684, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1688, (16, 16), (16, 1))
    assert_size_stride(alias_72, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1694, (16, 16), (16, 1))
    assert_size_stride(permute_1697, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1698, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1701, (2304, 768), (768, 1))
    assert_size_stride(div_106, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1705, (768, 3072), (3072, 1))
    assert_size_stride(permute_1709, (3072, 768), (768, 1))
    assert_size_stride(div_107, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1713, (768, 768), (768, 1))
    assert_size_stride(permute_1718, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1719, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1723, (16, 16), (16, 1))
    assert_size_stride(alias_73, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1729, (16, 16), (16, 1))
    assert_size_stride(permute_1732, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1733, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1736, (2304, 768), (768, 1))
    assert_size_stride(div_108, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1740, (768, 3072), (3072, 1))
    assert_size_stride(permute_1744, (3072, 768), (768, 1))
    assert_size_stride(div_109, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1748, (768, 768), (768, 1))
    assert_size_stride(permute_1753, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1754, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1758, (16, 16), (16, 1))
    assert_size_stride(alias_74, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1764, (16, 16), (16, 1))
    assert_size_stride(permute_1767, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1768, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1771, (2304, 768), (768, 1))
    assert_size_stride(div_110, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1775, (768, 3072), (3072, 1))
    assert_size_stride(permute_1779, (3072, 768), (768, 1))
    assert_size_stride(div_111, (8, 576, 1), (576, 1, 1))
    assert_size_stride(permute_1783, (768, 768), (768, 1))
    assert_size_stride(permute_1788, (128, 576, 576), (331776, 1, 576))
    assert_size_stride(permute_1789, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1793, (16, 16), (16, 1))
    assert_size_stride(alias_75, (8, 16, 576, 576), (5308416, 1, 9216, 16))
    assert_size_stride(permute_1799, (16, 16), (16, 1))
    assert_size_stride(permute_1802, (128, 48, 576), (27648, 1, 48))
    assert_size_stride(permute_1803, (128, 576, 48), (27648, 1, 576))
    assert_size_stride(permute_1806, (2304, 768), (768, 1))
    assert_size_stride(div_112, (8, 576, 1), (576, 1, 1))
    assert_size_stride(tangents_1, (8, 1000), (1000, 1))
    buf0 = empty((8, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(tangents_1, permute_490, out=buf0)
    del permute_490
    buf1 = empty((1000, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(tangents_1, (1000, 8), (1, 1000), 0), clone_511, out=buf1)
    del clone_511
    buf2 = empty((1, 1000), device='cpu', dtype=torch.float32)
    buf3 = empty_strided((8, 577, 1), (577, 1, 4616), device='cpu', dtype=torch.float32)
    buf4 = empty_strided((8, 577, 1), (577, 1, 4616), device='cpu', dtype=torch.float32)
    buf5 = empty((8, 577, 768), device='cpu', dtype=torch.float32)
    buf6 = empty((768, ), device='cpu', dtype=torch.float32)
    buf7 = empty((768, ), device='cpu', dtype=torch.float32)
    buf8 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    buf9 = empty((8, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_mul_native_layer_norm_native_layer_norm_backward_select_backward_sum_0(c_void_p(tangents_1.data_ptr()), c_void_p(buf0.data_ptr()), c_void_p(primals_689.data_ptr()), c_void_p(cat_2.data_ptr()), c_void_p(getitem_171.data_ptr()), c_void_p(rsqrt_76.data_ptr()), c_void_p(addmm_155.data_ptr()), c_void_p(primals_78.data_ptr()), c_void_p(buf2.data_ptr()), c_void_p(buf3.data_ptr()), c_void_p(buf4.data_ptr()), c_void_p(buf5.data_ptr()), c_void_p(buf6.data_ptr()), c_void_p(buf7.data_ptr()), c_void_p(buf8.data_ptr()), c_void_p(buf9.data_ptr()))
    del addmm_155
    del cat_2
    del getitem_171
    del primals_689
    del primals_78
    del rsqrt_76
    del tangents_1
    buf10 = empty((8, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf9, (8, 768), (768, 1), 0), permute_494, out=buf10)
    del permute_494
    buf11 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf9, (768, 8), (1, 768), 0), view_747, out=buf11)
    del view_747
    buf12 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf13 = reinterpret_tensor(buf10, (8, 1, 3072), (3072, 3072, 1), 0); del buf10  # reuse
    cpp_fused_gelu_gelu_backward_sum_1(c_void_p(buf13.data_ptr()), c_void_p(buf9.data_ptr()), c_void_p(addmm_154.data_ptr()), c_void_p(buf12.data_ptr()))
    del addmm_154
    buf14 = reinterpret_tensor(buf9, (8, 768), (768, 1), 0); del buf9  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf13, (8, 3072), (3072, 1), 0), permute_498, out=buf14)
    del permute_498
    buf15 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf13, (3072, 8), (1, 3072), 0), view_745, out=buf15)
    del view_745
    buf16 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf17 = empty_strided((8, 1, 1), (1, 8, 8), device='cpu', dtype=torch.float32)
    buf18 = empty_strided((8, 1, 1), (1, 8, 8), device='cpu', dtype=torch.float32)
    buf19 = empty((768, ), device='cpu', dtype=torch.float32)
    buf20 = empty((768, ), device='cpu', dtype=torch.float32)
    buf21 = reinterpret_tensor(buf14, (8, 1, 768), (768, 6144, 1), 0); del buf14  # reuse
    buf23 = reinterpret_tensor(buf0, (8, 1, 768), (768, 768, 1), 0); del buf0  # reuse
    cpp_fused_add_mul_native_layer_norm_backward_sum_2(c_void_p(buf21.data_ptr()), c_void_p(buf13.data_ptr()), c_void_p(primals_683.data_ptr()), c_void_p(mul_372.data_ptr()), c_void_p(buf5.data_ptr()), c_void_p(div_37.data_ptr()), c_void_p(primals_77.data_ptr()), c_void_p(buf16.data_ptr()), c_void_p(buf17.data_ptr()), c_void_p(buf18.data_ptr()), c_void_p(buf19.data_ptr()), c_void_p(buf20.data_ptr()), c_void_p(buf23.data_ptr()))
    del div_37
    del mul_372
    del primals_683
    del primals_77
    buf24 = empty((8, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf23, (8, 768), (768, 1), 0), permute_502, out=buf24)
    del permute_502
    # Source Nodes: [], Original ATen: [aten._scaled_dot_product_flash_attention_backward]
    buf27 = aten._scaled_dot_product_flash_attention_backward(reinterpret_tensor(buf24, (8, 16, 1, 48), (768, 48, 768, 1), 0), permute_480, permute_482, permute_484, alias_38, getitem_160, getitem_161, getitem_162, 0, 0, 0.0, False, getitem_165, getitem_166)
    del alias_38
    del getitem_160
    del getitem_161
    del getitem_162
    del getitem_165
    del getitem_166
    del permute_480
    del permute_482
    del permute_484
    buf30 = buf27[2]
    buf31 = empty((4616, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf30, (4616, 768), (768, 1), 0), permute_508, out=buf31)
    del permute_508
    buf29 = buf27[1]
    buf34 = empty((4616, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf29, (4616, 768), (768, 1), 0), permute_513, out=buf34)
    del permute_513
    buf28 = buf27[0]
    del buf27
    buf37 = buf24; del buf24  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf28, (8, 768), (768, 1), 0), permute_518, out=buf37)
    del permute_518
    buf40 = buf4; del buf4  # reuse
    buf41 = buf3; del buf3  # reuse
    buf42 = empty((8, 577, 768), device='cpu', dtype=torch.float32)
    buf22 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    buf45 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_native_layer_norm_backward_select_backward_sum_3(c_void_p(buf31.data_ptr()), c_void_p(buf34.data_ptr()), c_void_p(buf37.data_ptr()), c_void_p(primals_673.data_ptr()), c_void_p(cat_1.data_ptr()), c_void_p(getitem_158.data_ptr()), c_void_p(rsqrt_74.data_ptr()), c_void_p(buf21.data_ptr()), c_void_p(addmm_153.data_ptr()), c_void_p(addmm_149.data_ptr()), c_void_p(buf40.data_ptr()), c_void_p(buf41.data_ptr()), c_void_p(buf42.data_ptr()), c_void_p(buf22.data_ptr()), c_void_p(buf45.data_ptr()))
    del addmm_149
    del addmm_153
    del primals_673
    buf25 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf23, (768, 8), (1, 768), 0), view_743, out=buf25)
    del view_743
    buf26 = empty((1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_sum_4(c_void_p(buf23.data_ptr()), c_void_p(buf26.data_ptr()))
    buf32 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf30, (768, 4616), (1, 768), 0), view_736, out=buf32)
    buf33 = empty((1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_sum_5(c_void_p(buf30.data_ptr()), c_void_p(buf33.data_ptr()))
    del buf30
    buf35 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf29, (768, 4616), (1, 768), 0), view_736, out=buf35)
    del view_736
    buf36 = empty((1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_sum_6(c_void_p(buf29.data_ptr()), c_void_p(buf36.data_ptr()))
    buf38 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf28, (768, 8), (1, 768), 0), select_109, out=buf38)
    del select_109
    buf39 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf43 = empty((768, ), device='cpu', dtype=torch.float32)
    buf44 = empty((768, ), device='cpu', dtype=torch.float32)
    buf46 = buf23; del buf23  # reuse
    cpp_fused_add_mul_native_layer_norm_native_layer_norm_backward_select_backward_sum_7(c_void_p(buf28.data_ptr()), c_void_p(buf31.data_ptr()), c_void_p(buf34.data_ptr()), c_void_p(buf37.data_ptr()), c_void_p(cat_1.data_ptr()), c_void_p(getitem_158.data_ptr()), c_void_p(rsqrt_74.data_ptr()), c_void_p(buf21.data_ptr()), c_void_p(buf42.data_ptr()), c_void_p(primals_76.data_ptr()), c_void_p(buf39.data_ptr()), c_void_p(buf43.data_ptr()), c_void_p(buf44.data_ptr()), c_void_p(buf46.data_ptr()))
    del buf28
    del cat_1
    del getitem_158
    del primals_76
    buf47 = reinterpret_tensor(buf13, (8, 3072), (3072, 1), 0); del buf13  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf46, (8, 768), (768, 1), 0), permute_522, out=buf47)
    del permute_522
    buf48 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf46, (768, 8), (1, 768), 0), view_733, out=buf48)
    del view_733
    buf49 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf50 = reinterpret_tensor(buf47, (8, 1, 3072), (3072, 3072, 1), 0); del buf47  # reuse
    cpp_fused_gelu_gelu_backward_sum_8(c_void_p(buf50.data_ptr()), c_void_p(buf46.data_ptr()), c_void_p(addmm_148.data_ptr()), c_void_p(buf49.data_ptr()))
    del addmm_148
    buf51 = reinterpret_tensor(buf46, (8, 768), (768, 1), 0); del buf46  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf50, (8, 3072), (3072, 1), 0), permute_526, out=buf51)
    del permute_526
    buf52 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf50, (3072, 8), (1, 3072), 0), view_731, out=buf52)
    del view_731
    buf53 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf54 = buf18; del buf18  # reuse
    buf55 = buf17; del buf17  # reuse
    buf56 = empty((768, ), device='cpu', dtype=torch.float32)
    buf57 = empty((768, ), device='cpu', dtype=torch.float32)
    buf58 = buf21; del buf21  # reuse
    buf60 = reinterpret_tensor(buf37, (8, 1, 768), (768, 768, 1), 0); del buf37  # reuse
    cpp_fused_add_mul_native_layer_norm_backward_sum_9(c_void_p(buf58.data_ptr()), c_void_p(buf50.data_ptr()), c_void_p(buf51.data_ptr()), c_void_p(primals_667.data_ptr()), c_void_p(mul_363.data_ptr()), c_void_p(rsqrt_74.data_ptr()), c_void_p(buf42.data_ptr()), c_void_p(div_39.data_ptr()), c_void_p(primals_75.data_ptr()), c_void_p(buf53.data_ptr()), c_void_p(buf54.data_ptr()), c_void_p(buf55.data_ptr()), c_void_p(buf56.data_ptr()), c_void_p(buf57.data_ptr()), c_void_p(buf60.data_ptr()))
    del buf50
    del buf54
    del buf55
    del div_39
    del mul_363
    del primals_667
    del primals_75
    buf61 = buf51; del buf51  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf60, (8, 768), (768, 1), 0), permute_530, out=buf61)
    del permute_530
    # Source Nodes: [], Original ATen: [aten._scaled_dot_product_flash_attention_backward]
    buf64 = aten._scaled_dot_product_flash_attention_backward(reinterpret_tensor(buf61, (8, 16, 1, 48), (768, 48, 768, 1), 0), permute_470, permute_472, permute_474, alias_39, getitem_147, getitem_148, getitem_149, 0, 0, 0.0, False, getitem_152, getitem_153)
    del alias_39
    del getitem_147
    del getitem_148
    del getitem_149
    del getitem_152
    del getitem_153
    del permute_470
    del permute_472
    del permute_474
    buf67 = buf64[2]
    buf68 = buf34; del buf34  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf67, (4616, 768), (768, 1), 0), permute_536, out=buf68)
    del permute_536
    buf66 = buf64[1]
    buf71 = buf31; del buf31  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf66, (4616, 768), (768, 1), 0), permute_541, out=buf71)
    del permute_541
    buf65 = buf64[0]
    del buf64
    buf74 = buf61; del buf61  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf65, (8, 768), (768, 1), 0), permute_546, out=buf74)
    del permute_546
    buf77 = buf41; del buf41  # reuse
    buf78 = buf40; del buf40  # reuse
    buf79 = reinterpret_tensor(buf29, (8, 577, 768), (443136, 768, 1), 0); del buf29  # reuse
    buf59 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    buf83 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_native_layer_norm_backward_select_backward_sum_10(c_void_p(buf68.data_ptr()), c_void_p(buf71.data_ptr()), c_void_p(buf74.data_ptr()), c_void_p(primals_657.data_ptr()), c_void_p(cat.data_ptr()), c_void_p(getitem_145.data_ptr()), c_void_p(rsqrt_72.data_ptr()), c_void_p(buf58.data_ptr()), c_void_p(addmm_147.data_ptr()), c_void_p(buf77.data_ptr()), c_void_p(buf78.data_ptr()), c_void_p(buf79.data_ptr()), c_void_p(buf59.data_ptr()), c_void_p(buf83.data_ptr()))
    del addmm_147
    del buf58
    del buf77
    del buf78
    del primals_657
    buf62 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf60, (768, 8), (1, 768), 0), view_729, out=buf62)
    del view_729
    buf63 = empty((1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_sum_11(c_void_p(buf60.data_ptr()), c_void_p(buf63.data_ptr()))
    del buf60
    buf69 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf67, (768, 4616), (1, 768), 0), view_722, out=buf69)
    buf70 = empty((1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_sum_12(c_void_p(buf67.data_ptr()), c_void_p(buf70.data_ptr()))
    del buf67
    buf72 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf66, (768, 4616), (1, 768), 0), view_722, out=buf72)
    del view_722
    buf73 = empty((1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_sum_13(c_void_p(buf66.data_ptr()), c_void_p(buf73.data_ptr()))
    del buf66
    buf75 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf65, (768, 8), (1, 768), 0), select_108, out=buf75)
    del select_108
    buf76 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf80 = empty((768, ), device='cpu', dtype=torch.float32)
    buf81 = empty((768, ), device='cpu', dtype=torch.float32)
    buf82 = empty((8, 576, 768), device='cpu', dtype=torch.float32)
    buf84 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    buf85 = empty((8, 576, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_native_layer_norm_backward_select_backward_sum_14(c_void_p(buf65.data_ptr()), c_void_p(buf68.data_ptr()), c_void_p(buf71.data_ptr()), c_void_p(buf74.data_ptr()), c_void_p(cat.data_ptr()), c_void_p(getitem_145.data_ptr()), c_void_p(rsqrt_72.data_ptr()), c_void_p(buf5.data_ptr()), c_void_p(rsqrt_74.data_ptr()), c_void_p(buf42.data_ptr()), c_void_p(buf79.data_ptr()), c_void_p(addmm_143.data_ptr()), c_void_p(primals_73.data_ptr()), c_void_p(buf76.data_ptr()), c_void_p(buf80.data_ptr()), c_void_p(buf81.data_ptr()), c_void_p(buf82.data_ptr()), c_void_p(buf84.data_ptr()), c_void_p(buf85.data_ptr()))
    del addmm_143
    del buf42
    del buf5
    del buf65
    del buf68
    del buf71
    del buf74
    del buf79
    del cat
    del getitem_145
    del primals_73
    del rsqrt_72
    del rsqrt_74
    buf86 = empty((4608, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf85, (4608, 768), (768, 1), 0), permute_550, out=buf86)
    del permute_550
    buf87 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf85, (768, 4608), (1, 768), 0), view_719, out=buf87)
    del view_719
    buf88 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf89 = reinterpret_tensor(buf86, (8, 576, 3072), (1769472, 3072, 1), 0); del buf86  # reuse
    cpp_fused_gelu_gelu_backward_sum_15(c_void_p(buf89.data_ptr()), c_void_p(buf85.data_ptr()), c_void_p(addmm_142.data_ptr()), c_void_p(buf88.data_ptr()))
    del addmm_142
    buf90 = reinterpret_tensor(buf85, (4608, 768), (768, 1), 0); del buf85  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf89, (4608, 3072), (3072, 1), 0), permute_554, out=buf90)
    del permute_554
    buf91 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf89, (3072, 4608), (1, 3072), 0), view_717, out=buf91)
    del view_717
    buf92 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf93 = empty_strided((8, 576, 1), (576, 1, 4608), device='cpu', dtype=torch.float32)
    buf94 = empty_strided((8, 576, 1), (576, 1, 4608), device='cpu', dtype=torch.float32)
    buf95 = empty((768, ), device='cpu', dtype=torch.float32)
    buf96 = empty((768, ), device='cpu', dtype=torch.float32)
    buf97 = buf82; del buf82  # reuse
    buf99 = empty((8, 576, 768), device='cpu', dtype=torch.float32)
    buf98 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_16(c_void_p(buf97.data_ptr()), c_void_p(buf89.data_ptr()), c_void_p(buf90.data_ptr()), c_void_p(primals_651.data_ptr()), c_void_p(mul_354.data_ptr()), c_void_p(div_41.data_ptr()), c_void_p(primals_72.data_ptr()), c_void_p(addmm_141.data_ptr()), c_void_p(buf92.data_ptr()), c_void_p(buf93.data_ptr()), c_void_p(buf94.data_ptr()), c_void_p(buf95.data_ptr()), c_void_p(buf96.data_ptr()), c_void_p(buf99.data_ptr()), c_void_p(buf98.data_ptr()))
    del addmm_141
    del div_41
    del mul_354
    del primals_651
    del primals_72
    buf100 = buf90; del buf90  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf99, (4608, 768), (768, 1), 0), permute_558, out=buf100)
    del permute_558
    buf101 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf99, (768, 4608), (1, 768), 0), view_715, out=buf101)
    del view_715
    buf102 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf103 = empty((8, 16, 576, 48), device='cpu', dtype=torch.float32)
    cpp_fused_clone_sum_17(c_void_p(buf99.data_ptr()), c_void_p(buf100.data_ptr()), c_void_p(buf102.data_ptr()), c_void_p(buf103.data_ptr()))
    buf104 = reinterpret_tensor(buf99, (128, 576, 48), (27648, 48, 1), 0); del buf99  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_563, reinterpret_tensor(buf103, (128, 576, 48), (27648, 48, 1), 0), out=buf104)
    del permute_563
    buf105 = empty((128, 576, 576), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf103, (128, 576, 48), (27648, 48, 1), 0), permute_564, out=buf105)
    del permute_564
    buf106 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf107 = empty((2654208, 16), device='cpu', dtype=torch.float32)
    cpp_fused__unsafe_view_clone_sum_18(c_void_p(buf105.data_ptr()), c_void_p(buf106.data_ptr()), c_void_p(buf107.data_ptr()))
    buf108 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf107, (16, 2654208), (1, 16), 0), view_709, out=buf108)
    del view_709
    buf109 = reinterpret_tensor(buf105, (2654208, 16), (16, 1), 0); del buf105  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf107, permute_568, out=buf109)
    del permute_568
    buf110 = empty_strided((8, 16, 576, 1), (9216, 1, 16, 73728), device='cpu', dtype=torch.float32)
    buf111 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf112 = reinterpret_tensor(buf109, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf109  # reuse
    cpp_fused__softmax_backward_data_clone_sum_19(c_void_p(buf112.data_ptr()), c_void_p(alias_40.data_ptr()), c_void_p(buf110.data_ptr()), c_void_p(buf111.data_ptr()))
    del alias_40
    buf113 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf112, (16, 2654208), (1, 16), 0), view_707, out=buf113)
    del view_707
    buf114 = buf107; del buf107  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf112, (2654208, 16), (16, 1), 0), permute_574, out=buf114)
    del permute_574
    buf115 = reinterpret_tensor(buf112, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf112  # reuse
    cpp_fused_clone_20(c_void_p(buf114.data_ptr()), c_void_p(buf115.data_ptr()))
    buf116 = reinterpret_tensor(buf103, (128, 48, 576), (27648, 576, 1), 0); del buf103  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_577, reinterpret_tensor(buf115, (128, 576, 576), (331776, 576, 1), 0), out=buf116)
    del permute_577
    buf117 = reinterpret_tensor(buf100, (128, 576, 48), (27648, 48, 1), 0); del buf100  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf115, (128, 576, 576), (331776, 576, 1), 0), permute_578, out=buf117)
    del permute_578
    buf118 = empty((8, 576, 3, 16, 48), device='cpu', dtype=torch.float32)
    cpp_fused_clone_21(c_void_p(buf104.data_ptr()), c_void_p(buf116.data_ptr()), c_void_p(buf117.data_ptr()), c_void_p(buf118.data_ptr()))
    buf119 = reinterpret_tensor(buf117, (4608, 768), (768, 1), 0); del buf117  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf118, (4608, 2304), (2304, 1), 0), permute_581, out=buf119)
    del permute_581
    buf120 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf118, (2304, 4608), (1, 2304), 0), view_701, out=buf120)
    del view_701
    buf121 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf122 = buf94; del buf94  # reuse
    buf123 = buf93; del buf93  # reuse
    buf124 = empty((768, ), device='cpu', dtype=torch.float32)
    buf125 = empty((768, ), device='cpu', dtype=torch.float32)
    buf126 = reinterpret_tensor(buf119, (8, 576, 768), (442368, 768, 1), 0); del buf119  # reuse
    buf128 = reinterpret_tensor(buf116, (8, 576, 768), (442368, 768, 1), 0); del buf116  # reuse
    buf127 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_22(c_void_p(buf126.data_ptr()), c_void_p(buf118.data_ptr()), c_void_p(primals_641.data_ptr()), c_void_p(mul_350.data_ptr()), c_void_p(buf97.data_ptr()), c_void_p(div_42.data_ptr()), c_void_p(primals_71.data_ptr()), c_void_p(addmm_139.data_ptr()), c_void_p(buf121.data_ptr()), c_void_p(buf122.data_ptr()), c_void_p(buf123.data_ptr()), c_void_p(buf124.data_ptr()), c_void_p(buf125.data_ptr()), c_void_p(buf128.data_ptr()), c_void_p(buf127.data_ptr()))
    del addmm_139
    del div_42
    del mul_350
    del primals_641
    del primals_71
    buf129 = reinterpret_tensor(buf89, (4608, 3072), (3072, 1), 0); del buf89  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf128, (4608, 768), (768, 1), 0), permute_585, out=buf129)
    del permute_585
    buf130 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf128, (768, 4608), (1, 768), 0), view_699, out=buf130)
    del view_699
    buf131 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf132 = reinterpret_tensor(buf129, (8, 576, 3072), (1769472, 3072, 1), 0); del buf129  # reuse
    cpp_fused_gelu_gelu_backward_sum_23(c_void_p(buf132.data_ptr()), c_void_p(buf128.data_ptr()), c_void_p(addmm_138.data_ptr()), c_void_p(buf131.data_ptr()))
    del addmm_138
    buf133 = reinterpret_tensor(buf128, (4608, 768), (768, 1), 0); del buf128  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf132, (4608, 3072), (3072, 1), 0), permute_589, out=buf133)
    del permute_589
    buf134 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf132, (3072, 4608), (1, 3072), 0), view_697, out=buf134)
    del view_697
    buf135 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf136 = buf123; del buf123  # reuse
    buf137 = buf122; del buf122  # reuse
    buf138 = empty((768, ), device='cpu', dtype=torch.float32)
    buf139 = empty((768, ), device='cpu', dtype=torch.float32)
    buf140 = buf126; del buf126  # reuse
    buf142 = buf97; del buf97  # reuse
    buf141 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_24(c_void_p(buf140.data_ptr()), c_void_p(buf132.data_ptr()), c_void_p(buf133.data_ptr()), c_void_p(primals_635.data_ptr()), c_void_p(mul_344.data_ptr()), c_void_p(div_43.data_ptr()), c_void_p(primals_70.data_ptr()), c_void_p(addmm_137.data_ptr()), c_void_p(buf135.data_ptr()), c_void_p(buf136.data_ptr()), c_void_p(buf137.data_ptr()), c_void_p(buf138.data_ptr()), c_void_p(buf139.data_ptr()), c_void_p(buf142.data_ptr()), c_void_p(buf141.data_ptr()))
    del addmm_137
    del div_43
    del mul_344
    del primals_635
    del primals_70
    buf143 = buf133; del buf133  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf142, (4608, 768), (768, 1), 0), permute_593, out=buf143)
    del permute_593
    buf144 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf142, (768, 4608), (1, 768), 0), view_695, out=buf144)
    del view_695
    buf145 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf146 = reinterpret_tensor(buf104, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf104  # reuse
    cpp_fused_clone_sum_25(c_void_p(buf142.data_ptr()), c_void_p(buf143.data_ptr()), c_void_p(buf145.data_ptr()), c_void_p(buf146.data_ptr()))
    buf147 = reinterpret_tensor(buf143, (128, 576, 48), (27648, 48, 1), 0); del buf143  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_598, reinterpret_tensor(buf146, (128, 576, 48), (27648, 48, 1), 0), out=buf147)
    del permute_598
    buf148 = reinterpret_tensor(buf115, (128, 576, 576), (331776, 576, 1), 0); del buf115  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf146, (128, 576, 48), (27648, 48, 1), 0), permute_599, out=buf148)
    del permute_599
    buf149 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf150 = buf114; del buf114  # reuse
    cpp_fused__unsafe_view_clone_sum_26(c_void_p(buf148.data_ptr()), c_void_p(buf149.data_ptr()), c_void_p(buf150.data_ptr()))
    buf151 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf150, (16, 2654208), (1, 16), 0), view_689, out=buf151)
    del view_689
    buf152 = reinterpret_tensor(buf148, (2654208, 16), (16, 1), 0); del buf148  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf150, permute_603, out=buf152)
    del permute_603
    buf153 = buf110; del buf110  # reuse
    buf154 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf155 = reinterpret_tensor(buf152, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf152  # reuse
    cpp_fused__softmax_backward_data_clone_sum_27(c_void_p(buf155.data_ptr()), c_void_p(alias_41.data_ptr()), c_void_p(buf153.data_ptr()), c_void_p(buf154.data_ptr()))
    del alias_41
    buf156 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf155, (16, 2654208), (1, 16), 0), view_687, out=buf156)
    del view_687
    buf157 = buf150; del buf150  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf155, (2654208, 16), (16, 1), 0), permute_609, out=buf157)
    del permute_609
    buf158 = reinterpret_tensor(buf155, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf155  # reuse
    cpp_fused_clone_28(c_void_p(buf157.data_ptr()), c_void_p(buf158.data_ptr()))
    buf159 = reinterpret_tensor(buf146, (128, 48, 576), (27648, 576, 1), 0); del buf146  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_612, reinterpret_tensor(buf158, (128, 576, 576), (331776, 576, 1), 0), out=buf159)
    del permute_612
    buf160 = reinterpret_tensor(buf142, (128, 576, 48), (27648, 48, 1), 0); del buf142  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf158, (128, 576, 576), (331776, 576, 1), 0), permute_613, out=buf160)
    del permute_613
    buf161 = buf118; del buf118  # reuse
    cpp_fused_clone_29(c_void_p(buf147.data_ptr()), c_void_p(buf159.data_ptr()), c_void_p(buf160.data_ptr()), c_void_p(buf161.data_ptr()))
    buf162 = reinterpret_tensor(buf160, (4608, 768), (768, 1), 0); del buf160  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf161, (4608, 2304), (2304, 1), 0), permute_616, out=buf162)
    del permute_616
    buf163 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf161, (2304, 4608), (1, 2304), 0), view_681, out=buf163)
    del view_681
    buf164 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf165 = buf137; del buf137  # reuse
    buf166 = buf136; del buf136  # reuse
    buf167 = empty((768, ), device='cpu', dtype=torch.float32)
    buf168 = empty((768, ), device='cpu', dtype=torch.float32)
    buf169 = buf140; del buf140  # reuse
    buf171 = reinterpret_tensor(buf159, (8, 576, 768), (442368, 768, 1), 0); del buf159  # reuse
    buf170 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_30(c_void_p(buf169.data_ptr()), c_void_p(buf161.data_ptr()), c_void_p(buf162.data_ptr()), c_void_p(primals_625.data_ptr()), c_void_p(mul_340.data_ptr()), c_void_p(div_44.data_ptr()), c_void_p(primals_69.data_ptr()), c_void_p(addmm_135.data_ptr()), c_void_p(buf164.data_ptr()), c_void_p(buf165.data_ptr()), c_void_p(buf166.data_ptr()), c_void_p(buf167.data_ptr()), c_void_p(buf168.data_ptr()), c_void_p(buf171.data_ptr()), c_void_p(buf170.data_ptr()))
    del addmm_135
    del div_44
    del mul_340
    del primals_625
    del primals_69
    buf172 = reinterpret_tensor(buf132, (4608, 3072), (3072, 1), 0); del buf132  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf171, (4608, 768), (768, 1), 0), permute_620, out=buf172)
    del permute_620
    buf173 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf171, (768, 4608), (1, 768), 0), view_679, out=buf173)
    del view_679
    buf174 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf175 = reinterpret_tensor(buf172, (8, 576, 3072), (1769472, 3072, 1), 0); del buf172  # reuse
    cpp_fused_gelu_gelu_backward_sum_31(c_void_p(buf175.data_ptr()), c_void_p(buf171.data_ptr()), c_void_p(addmm_134.data_ptr()), c_void_p(buf174.data_ptr()))
    del addmm_134
    buf176 = reinterpret_tensor(buf171, (4608, 768), (768, 1), 0); del buf171  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf175, (4608, 3072), (3072, 1), 0), permute_624, out=buf176)
    del permute_624
    buf177 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf175, (3072, 4608), (1, 3072), 0), view_677, out=buf177)
    del view_677
    buf178 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf179 = buf166; del buf166  # reuse
    buf180 = buf165; del buf165  # reuse
    buf181 = empty((768, ), device='cpu', dtype=torch.float32)
    buf182 = empty((768, ), device='cpu', dtype=torch.float32)
    buf183 = buf169; del buf169  # reuse
    buf185 = reinterpret_tensor(buf162, (8, 576, 768), (442368, 768, 1), 0); del buf162  # reuse
    buf184 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_32(c_void_p(buf183.data_ptr()), c_void_p(buf175.data_ptr()), c_void_p(buf176.data_ptr()), c_void_p(primals_619.data_ptr()), c_void_p(mul_334.data_ptr()), c_void_p(div_45.data_ptr()), c_void_p(primals_68.data_ptr()), c_void_p(addmm_133.data_ptr()), c_void_p(buf178.data_ptr()), c_void_p(buf179.data_ptr()), c_void_p(buf180.data_ptr()), c_void_p(buf181.data_ptr()), c_void_p(buf182.data_ptr()), c_void_p(buf185.data_ptr()), c_void_p(buf184.data_ptr()))
    del addmm_133
    del div_45
    del mul_334
    del primals_619
    del primals_68
    buf186 = buf176; del buf176  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf185, (4608, 768), (768, 1), 0), permute_628, out=buf186)
    del permute_628
    buf187 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf185, (768, 4608), (1, 768), 0), view_675, out=buf187)
    del view_675
    buf188 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf189 = reinterpret_tensor(buf147, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf147  # reuse
    cpp_fused_clone_sum_33(c_void_p(buf185.data_ptr()), c_void_p(buf186.data_ptr()), c_void_p(buf188.data_ptr()), c_void_p(buf189.data_ptr()))
    buf190 = reinterpret_tensor(buf186, (128, 576, 48), (27648, 48, 1), 0); del buf186  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_633, reinterpret_tensor(buf189, (128, 576, 48), (27648, 48, 1), 0), out=buf190)
    del permute_633
    buf191 = reinterpret_tensor(buf158, (128, 576, 576), (331776, 576, 1), 0); del buf158  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf189, (128, 576, 48), (27648, 48, 1), 0), permute_634, out=buf191)
    del permute_634
    buf192 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf193 = buf157; del buf157  # reuse
    cpp_fused__unsafe_view_clone_sum_34(c_void_p(buf191.data_ptr()), c_void_p(buf192.data_ptr()), c_void_p(buf193.data_ptr()))
    buf194 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf193, (16, 2654208), (1, 16), 0), view_669, out=buf194)
    del view_669
    buf195 = reinterpret_tensor(buf191, (2654208, 16), (16, 1), 0); del buf191  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf193, permute_638, out=buf195)
    del permute_638
    buf196 = buf153; del buf153  # reuse
    buf197 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf198 = reinterpret_tensor(buf195, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf195  # reuse
    cpp_fused__softmax_backward_data_clone_sum_35(c_void_p(buf198.data_ptr()), c_void_p(alias_42.data_ptr()), c_void_p(buf196.data_ptr()), c_void_p(buf197.data_ptr()))
    del alias_42
    buf199 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf198, (16, 2654208), (1, 16), 0), view_667, out=buf199)
    del view_667
    buf200 = buf193; del buf193  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf198, (2654208, 16), (16, 1), 0), permute_644, out=buf200)
    del permute_644
    buf201 = reinterpret_tensor(buf198, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf198  # reuse
    cpp_fused_clone_36(c_void_p(buf200.data_ptr()), c_void_p(buf201.data_ptr()))
    buf202 = reinterpret_tensor(buf189, (128, 48, 576), (27648, 576, 1), 0); del buf189  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_647, reinterpret_tensor(buf201, (128, 576, 576), (331776, 576, 1), 0), out=buf202)
    del permute_647
    buf203 = reinterpret_tensor(buf185, (128, 576, 48), (27648, 48, 1), 0); del buf185  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf201, (128, 576, 576), (331776, 576, 1), 0), permute_648, out=buf203)
    del permute_648
    buf204 = buf161; del buf161  # reuse
    cpp_fused_clone_37(c_void_p(buf190.data_ptr()), c_void_p(buf202.data_ptr()), c_void_p(buf203.data_ptr()), c_void_p(buf204.data_ptr()))
    buf205 = reinterpret_tensor(buf203, (4608, 768), (768, 1), 0); del buf203  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf204, (4608, 2304), (2304, 1), 0), permute_651, out=buf205)
    del permute_651
    buf206 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf204, (2304, 4608), (1, 2304), 0), view_661, out=buf206)
    del view_661
    buf207 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf208 = buf180; del buf180  # reuse
    buf209 = buf179; del buf179  # reuse
    buf210 = empty((768, ), device='cpu', dtype=torch.float32)
    buf211 = empty((768, ), device='cpu', dtype=torch.float32)
    buf212 = buf183; del buf183  # reuse
    buf214 = reinterpret_tensor(buf202, (8, 576, 768), (442368, 768, 1), 0); del buf202  # reuse
    buf213 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_38(c_void_p(buf212.data_ptr()), c_void_p(buf204.data_ptr()), c_void_p(buf205.data_ptr()), c_void_p(primals_609.data_ptr()), c_void_p(mul_330.data_ptr()), c_void_p(div_46.data_ptr()), c_void_p(primals_67.data_ptr()), c_void_p(addmm_131.data_ptr()), c_void_p(buf207.data_ptr()), c_void_p(buf208.data_ptr()), c_void_p(buf209.data_ptr()), c_void_p(buf210.data_ptr()), c_void_p(buf211.data_ptr()), c_void_p(buf214.data_ptr()), c_void_p(buf213.data_ptr()))
    del addmm_131
    del div_46
    del mul_330
    del primals_609
    del primals_67
    buf215 = reinterpret_tensor(buf175, (4608, 3072), (3072, 1), 0); del buf175  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf214, (4608, 768), (768, 1), 0), permute_655, out=buf215)
    del permute_655
    buf216 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf214, (768, 4608), (1, 768), 0), view_659, out=buf216)
    del view_659
    buf217 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf218 = reinterpret_tensor(buf215, (8, 576, 3072), (1769472, 3072, 1), 0); del buf215  # reuse
    cpp_fused_gelu_gelu_backward_sum_39(c_void_p(buf218.data_ptr()), c_void_p(buf214.data_ptr()), c_void_p(addmm_130.data_ptr()), c_void_p(buf217.data_ptr()))
    del addmm_130
    buf219 = reinterpret_tensor(buf214, (4608, 768), (768, 1), 0); del buf214  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf218, (4608, 3072), (3072, 1), 0), permute_659, out=buf219)
    del permute_659
    buf220 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf218, (3072, 4608), (1, 3072), 0), view_657, out=buf220)
    del view_657
    buf221 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf222 = buf209; del buf209  # reuse
    buf223 = buf208; del buf208  # reuse
    buf224 = empty((768, ), device='cpu', dtype=torch.float32)
    buf225 = empty((768, ), device='cpu', dtype=torch.float32)
    buf226 = buf212; del buf212  # reuse
    buf228 = reinterpret_tensor(buf205, (8, 576, 768), (442368, 768, 1), 0); del buf205  # reuse
    buf227 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_40(c_void_p(buf226.data_ptr()), c_void_p(buf218.data_ptr()), c_void_p(buf219.data_ptr()), c_void_p(primals_603.data_ptr()), c_void_p(mul_324.data_ptr()), c_void_p(div_47.data_ptr()), c_void_p(primals_66.data_ptr()), c_void_p(addmm_129.data_ptr()), c_void_p(buf221.data_ptr()), c_void_p(buf222.data_ptr()), c_void_p(buf223.data_ptr()), c_void_p(buf224.data_ptr()), c_void_p(buf225.data_ptr()), c_void_p(buf228.data_ptr()), c_void_p(buf227.data_ptr()))
    del addmm_129
    del div_47
    del mul_324
    del primals_603
    del primals_66
    buf229 = buf219; del buf219  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf228, (4608, 768), (768, 1), 0), permute_663, out=buf229)
    del permute_663
    buf230 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf228, (768, 4608), (1, 768), 0), view_655, out=buf230)
    del view_655
    buf231 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf232 = reinterpret_tensor(buf190, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf190  # reuse
    cpp_fused_clone_sum_41(c_void_p(buf228.data_ptr()), c_void_p(buf229.data_ptr()), c_void_p(buf231.data_ptr()), c_void_p(buf232.data_ptr()))
    buf233 = reinterpret_tensor(buf229, (128, 576, 48), (27648, 48, 1), 0); del buf229  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_668, reinterpret_tensor(buf232, (128, 576, 48), (27648, 48, 1), 0), out=buf233)
    del permute_668
    buf234 = reinterpret_tensor(buf201, (128, 576, 576), (331776, 576, 1), 0); del buf201  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf232, (128, 576, 48), (27648, 48, 1), 0), permute_669, out=buf234)
    del permute_669
    buf235 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf236 = buf200; del buf200  # reuse
    cpp_fused__unsafe_view_clone_sum_42(c_void_p(buf234.data_ptr()), c_void_p(buf235.data_ptr()), c_void_p(buf236.data_ptr()))
    buf237 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf236, (16, 2654208), (1, 16), 0), view_649, out=buf237)
    del view_649
    buf238 = reinterpret_tensor(buf234, (2654208, 16), (16, 1), 0); del buf234  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf236, permute_673, out=buf238)
    del permute_673
    buf239 = buf196; del buf196  # reuse
    buf240 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf241 = reinterpret_tensor(buf238, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf238  # reuse
    cpp_fused__softmax_backward_data_clone_sum_43(c_void_p(buf241.data_ptr()), c_void_p(alias_43.data_ptr()), c_void_p(buf239.data_ptr()), c_void_p(buf240.data_ptr()))
    del alias_43
    buf242 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf241, (16, 2654208), (1, 16), 0), view_647, out=buf242)
    del view_647
    buf243 = buf236; del buf236  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf241, (2654208, 16), (16, 1), 0), permute_679, out=buf243)
    del permute_679
    buf244 = reinterpret_tensor(buf241, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf241  # reuse
    cpp_fused_clone_44(c_void_p(buf243.data_ptr()), c_void_p(buf244.data_ptr()))
    buf245 = reinterpret_tensor(buf232, (128, 48, 576), (27648, 576, 1), 0); del buf232  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_682, reinterpret_tensor(buf244, (128, 576, 576), (331776, 576, 1), 0), out=buf245)
    del permute_682
    buf246 = reinterpret_tensor(buf228, (128, 576, 48), (27648, 48, 1), 0); del buf228  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf244, (128, 576, 576), (331776, 576, 1), 0), permute_683, out=buf246)
    del permute_683
    buf247 = buf204; del buf204  # reuse
    cpp_fused_clone_45(c_void_p(buf233.data_ptr()), c_void_p(buf245.data_ptr()), c_void_p(buf246.data_ptr()), c_void_p(buf247.data_ptr()))
    buf248 = reinterpret_tensor(buf246, (4608, 768), (768, 1), 0); del buf246  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf247, (4608, 2304), (2304, 1), 0), permute_686, out=buf248)
    del permute_686
    buf249 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf247, (2304, 4608), (1, 2304), 0), view_641, out=buf249)
    del view_641
    buf250 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf251 = buf223; del buf223  # reuse
    buf252 = buf222; del buf222  # reuse
    buf253 = empty((768, ), device='cpu', dtype=torch.float32)
    buf254 = empty((768, ), device='cpu', dtype=torch.float32)
    buf255 = buf226; del buf226  # reuse
    buf257 = reinterpret_tensor(buf245, (8, 576, 768), (442368, 768, 1), 0); del buf245  # reuse
    buf256 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_46(c_void_p(buf255.data_ptr()), c_void_p(buf247.data_ptr()), c_void_p(buf248.data_ptr()), c_void_p(primals_593.data_ptr()), c_void_p(mul_320.data_ptr()), c_void_p(div_48.data_ptr()), c_void_p(primals_65.data_ptr()), c_void_p(addmm_127.data_ptr()), c_void_p(buf250.data_ptr()), c_void_p(buf251.data_ptr()), c_void_p(buf252.data_ptr()), c_void_p(buf253.data_ptr()), c_void_p(buf254.data_ptr()), c_void_p(buf257.data_ptr()), c_void_p(buf256.data_ptr()))
    del addmm_127
    del div_48
    del mul_320
    del primals_593
    del primals_65
    buf258 = reinterpret_tensor(buf218, (4608, 3072), (3072, 1), 0); del buf218  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf257, (4608, 768), (768, 1), 0), permute_690, out=buf258)
    del permute_690
    buf259 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf257, (768, 4608), (1, 768), 0), view_639, out=buf259)
    del view_639
    buf260 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf261 = reinterpret_tensor(buf258, (8, 576, 3072), (1769472, 3072, 1), 0); del buf258  # reuse
    cpp_fused_gelu_gelu_backward_sum_47(c_void_p(buf261.data_ptr()), c_void_p(buf257.data_ptr()), c_void_p(addmm_126.data_ptr()), c_void_p(buf260.data_ptr()))
    del addmm_126
    buf262 = reinterpret_tensor(buf257, (4608, 768), (768, 1), 0); del buf257  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf261, (4608, 3072), (3072, 1), 0), permute_694, out=buf262)
    del permute_694
    buf263 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf261, (3072, 4608), (1, 3072), 0), view_637, out=buf263)
    del view_637
    buf264 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf265 = buf252; del buf252  # reuse
    buf266 = buf251; del buf251  # reuse
    buf267 = empty((768, ), device='cpu', dtype=torch.float32)
    buf268 = empty((768, ), device='cpu', dtype=torch.float32)
    buf269 = buf255; del buf255  # reuse
    buf271 = reinterpret_tensor(buf248, (8, 576, 768), (442368, 768, 1), 0); del buf248  # reuse
    buf270 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_48(c_void_p(buf269.data_ptr()), c_void_p(buf261.data_ptr()), c_void_p(buf262.data_ptr()), c_void_p(primals_587.data_ptr()), c_void_p(mul_314.data_ptr()), c_void_p(div_49.data_ptr()), c_void_p(primals_64.data_ptr()), c_void_p(addmm_125.data_ptr()), c_void_p(buf264.data_ptr()), c_void_p(buf265.data_ptr()), c_void_p(buf266.data_ptr()), c_void_p(buf267.data_ptr()), c_void_p(buf268.data_ptr()), c_void_p(buf271.data_ptr()), c_void_p(buf270.data_ptr()))
    del addmm_125
    del div_49
    del mul_314
    del primals_587
    del primals_64
    buf272 = buf262; del buf262  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf271, (4608, 768), (768, 1), 0), permute_698, out=buf272)
    del permute_698
    buf273 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf271, (768, 4608), (1, 768), 0), view_635, out=buf273)
    del view_635
    buf274 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf275 = reinterpret_tensor(buf233, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf233  # reuse
    cpp_fused_clone_sum_49(c_void_p(buf271.data_ptr()), c_void_p(buf272.data_ptr()), c_void_p(buf274.data_ptr()), c_void_p(buf275.data_ptr()))
    buf276 = reinterpret_tensor(buf272, (128, 576, 48), (27648, 48, 1), 0); del buf272  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_703, reinterpret_tensor(buf275, (128, 576, 48), (27648, 48, 1), 0), out=buf276)
    del permute_703
    buf277 = reinterpret_tensor(buf244, (128, 576, 576), (331776, 576, 1), 0); del buf244  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf275, (128, 576, 48), (27648, 48, 1), 0), permute_704, out=buf277)
    del permute_704
    buf278 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf279 = buf243; del buf243  # reuse
    cpp_fused__unsafe_view_clone_sum_50(c_void_p(buf277.data_ptr()), c_void_p(buf278.data_ptr()), c_void_p(buf279.data_ptr()))
    buf280 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf279, (16, 2654208), (1, 16), 0), view_629, out=buf280)
    del view_629
    buf281 = reinterpret_tensor(buf277, (2654208, 16), (16, 1), 0); del buf277  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf279, permute_708, out=buf281)
    del permute_708
    buf282 = buf239; del buf239  # reuse
    buf283 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf284 = reinterpret_tensor(buf281, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf281  # reuse
    cpp_fused__softmax_backward_data_clone_sum_51(c_void_p(buf284.data_ptr()), c_void_p(alias_44.data_ptr()), c_void_p(buf282.data_ptr()), c_void_p(buf283.data_ptr()))
    del alias_44
    buf285 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf284, (16, 2654208), (1, 16), 0), view_627, out=buf285)
    del view_627
    buf286 = buf279; del buf279  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf284, (2654208, 16), (16, 1), 0), permute_714, out=buf286)
    del permute_714
    buf287 = reinterpret_tensor(buf284, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf284  # reuse
    cpp_fused_clone_52(c_void_p(buf286.data_ptr()), c_void_p(buf287.data_ptr()))
    buf288 = reinterpret_tensor(buf275, (128, 48, 576), (27648, 576, 1), 0); del buf275  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_717, reinterpret_tensor(buf287, (128, 576, 576), (331776, 576, 1), 0), out=buf288)
    del permute_717
    buf289 = reinterpret_tensor(buf271, (128, 576, 48), (27648, 48, 1), 0); del buf271  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf287, (128, 576, 576), (331776, 576, 1), 0), permute_718, out=buf289)
    del permute_718
    buf290 = buf247; del buf247  # reuse
    cpp_fused_clone_53(c_void_p(buf276.data_ptr()), c_void_p(buf288.data_ptr()), c_void_p(buf289.data_ptr()), c_void_p(buf290.data_ptr()))
    buf291 = reinterpret_tensor(buf289, (4608, 768), (768, 1), 0); del buf289  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf290, (4608, 2304), (2304, 1), 0), permute_721, out=buf291)
    del permute_721
    buf292 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf290, (2304, 4608), (1, 2304), 0), view_621, out=buf292)
    del view_621
    buf293 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf294 = buf266; del buf266  # reuse
    buf295 = buf265; del buf265  # reuse
    buf296 = empty((768, ), device='cpu', dtype=torch.float32)
    buf297 = empty((768, ), device='cpu', dtype=torch.float32)
    buf298 = buf269; del buf269  # reuse
    buf300 = reinterpret_tensor(buf288, (8, 576, 768), (442368, 768, 1), 0); del buf288  # reuse
    buf299 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_54(c_void_p(buf298.data_ptr()), c_void_p(buf290.data_ptr()), c_void_p(buf291.data_ptr()), c_void_p(primals_577.data_ptr()), c_void_p(mul_310.data_ptr()), c_void_p(div_50.data_ptr()), c_void_p(primals_63.data_ptr()), c_void_p(addmm_123.data_ptr()), c_void_p(buf293.data_ptr()), c_void_p(buf294.data_ptr()), c_void_p(buf295.data_ptr()), c_void_p(buf296.data_ptr()), c_void_p(buf297.data_ptr()), c_void_p(buf300.data_ptr()), c_void_p(buf299.data_ptr()))
    del addmm_123
    del div_50
    del mul_310
    del primals_577
    del primals_63
    buf301 = reinterpret_tensor(buf261, (4608, 3072), (3072, 1), 0); del buf261  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf300, (4608, 768), (768, 1), 0), permute_725, out=buf301)
    del permute_725
    buf302 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf300, (768, 4608), (1, 768), 0), view_619, out=buf302)
    del view_619
    buf303 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf304 = reinterpret_tensor(buf301, (8, 576, 3072), (1769472, 3072, 1), 0); del buf301  # reuse
    cpp_fused_gelu_gelu_backward_sum_55(c_void_p(buf304.data_ptr()), c_void_p(buf300.data_ptr()), c_void_p(addmm_122.data_ptr()), c_void_p(buf303.data_ptr()))
    del addmm_122
    buf305 = reinterpret_tensor(buf300, (4608, 768), (768, 1), 0); del buf300  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf304, (4608, 3072), (3072, 1), 0), permute_729, out=buf305)
    del permute_729
    buf306 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf304, (3072, 4608), (1, 3072), 0), view_617, out=buf306)
    del view_617
    buf307 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf308 = buf295; del buf295  # reuse
    buf309 = buf294; del buf294  # reuse
    buf310 = empty((768, ), device='cpu', dtype=torch.float32)
    buf311 = empty((768, ), device='cpu', dtype=torch.float32)
    buf312 = buf298; del buf298  # reuse
    buf314 = reinterpret_tensor(buf291, (8, 576, 768), (442368, 768, 1), 0); del buf291  # reuse
    buf313 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_56(c_void_p(buf312.data_ptr()), c_void_p(buf304.data_ptr()), c_void_p(buf305.data_ptr()), c_void_p(primals_571.data_ptr()), c_void_p(mul_304.data_ptr()), c_void_p(div_51.data_ptr()), c_void_p(primals_62.data_ptr()), c_void_p(addmm_121.data_ptr()), c_void_p(buf307.data_ptr()), c_void_p(buf308.data_ptr()), c_void_p(buf309.data_ptr()), c_void_p(buf310.data_ptr()), c_void_p(buf311.data_ptr()), c_void_p(buf314.data_ptr()), c_void_p(buf313.data_ptr()))
    del addmm_121
    del div_51
    del mul_304
    del primals_571
    del primals_62
    buf315 = buf305; del buf305  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf314, (4608, 768), (768, 1), 0), permute_733, out=buf315)
    del permute_733
    buf316 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf314, (768, 4608), (1, 768), 0), view_615, out=buf316)
    del view_615
    buf317 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf318 = reinterpret_tensor(buf276, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf276  # reuse
    cpp_fused_clone_sum_57(c_void_p(buf314.data_ptr()), c_void_p(buf315.data_ptr()), c_void_p(buf317.data_ptr()), c_void_p(buf318.data_ptr()))
    buf319 = reinterpret_tensor(buf315, (128, 576, 48), (27648, 48, 1), 0); del buf315  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_738, reinterpret_tensor(buf318, (128, 576, 48), (27648, 48, 1), 0), out=buf319)
    del permute_738
    buf320 = reinterpret_tensor(buf287, (128, 576, 576), (331776, 576, 1), 0); del buf287  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf318, (128, 576, 48), (27648, 48, 1), 0), permute_739, out=buf320)
    del permute_739
    buf321 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf322 = buf286; del buf286  # reuse
    cpp_fused__unsafe_view_clone_sum_58(c_void_p(buf320.data_ptr()), c_void_p(buf321.data_ptr()), c_void_p(buf322.data_ptr()))
    buf323 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf322, (16, 2654208), (1, 16), 0), view_609, out=buf323)
    del view_609
    buf324 = reinterpret_tensor(buf320, (2654208, 16), (16, 1), 0); del buf320  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf322, permute_743, out=buf324)
    del permute_743
    buf325 = buf282; del buf282  # reuse
    buf326 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf327 = reinterpret_tensor(buf324, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf324  # reuse
    cpp_fused__softmax_backward_data_clone_sum_59(c_void_p(buf327.data_ptr()), c_void_p(alias_45.data_ptr()), c_void_p(buf325.data_ptr()), c_void_p(buf326.data_ptr()))
    del alias_45
    buf328 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf327, (16, 2654208), (1, 16), 0), view_607, out=buf328)
    del view_607
    buf329 = buf322; del buf322  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf327, (2654208, 16), (16, 1), 0), permute_749, out=buf329)
    del permute_749
    buf330 = reinterpret_tensor(buf327, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf327  # reuse
    cpp_fused_clone_60(c_void_p(buf329.data_ptr()), c_void_p(buf330.data_ptr()))
    buf331 = reinterpret_tensor(buf318, (128, 48, 576), (27648, 576, 1), 0); del buf318  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_752, reinterpret_tensor(buf330, (128, 576, 576), (331776, 576, 1), 0), out=buf331)
    del permute_752
    buf332 = reinterpret_tensor(buf314, (128, 576, 48), (27648, 48, 1), 0); del buf314  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf330, (128, 576, 576), (331776, 576, 1), 0), permute_753, out=buf332)
    del permute_753
    buf333 = buf290; del buf290  # reuse
    cpp_fused_clone_61(c_void_p(buf319.data_ptr()), c_void_p(buf331.data_ptr()), c_void_p(buf332.data_ptr()), c_void_p(buf333.data_ptr()))
    buf334 = reinterpret_tensor(buf332, (4608, 768), (768, 1), 0); del buf332  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf333, (4608, 2304), (2304, 1), 0), permute_756, out=buf334)
    del permute_756
    buf335 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf333, (2304, 4608), (1, 2304), 0), view_601, out=buf335)
    del view_601
    buf336 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf337 = buf309; del buf309  # reuse
    buf338 = buf308; del buf308  # reuse
    buf339 = empty((768, ), device='cpu', dtype=torch.float32)
    buf340 = empty((768, ), device='cpu', dtype=torch.float32)
    buf341 = buf312; del buf312  # reuse
    buf343 = reinterpret_tensor(buf331, (8, 576, 768), (442368, 768, 1), 0); del buf331  # reuse
    buf342 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_62(c_void_p(buf341.data_ptr()), c_void_p(buf333.data_ptr()), c_void_p(buf334.data_ptr()), c_void_p(primals_561.data_ptr()), c_void_p(mul_300.data_ptr()), c_void_p(div_52.data_ptr()), c_void_p(primals_61.data_ptr()), c_void_p(addmm_119.data_ptr()), c_void_p(buf336.data_ptr()), c_void_p(buf337.data_ptr()), c_void_p(buf338.data_ptr()), c_void_p(buf339.data_ptr()), c_void_p(buf340.data_ptr()), c_void_p(buf343.data_ptr()), c_void_p(buf342.data_ptr()))
    del addmm_119
    del div_52
    del mul_300
    del primals_561
    del primals_61
    buf344 = reinterpret_tensor(buf304, (4608, 3072), (3072, 1), 0); del buf304  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf343, (4608, 768), (768, 1), 0), permute_760, out=buf344)
    del permute_760
    buf345 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf343, (768, 4608), (1, 768), 0), view_599, out=buf345)
    del view_599
    buf346 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf347 = reinterpret_tensor(buf344, (8, 576, 3072), (1769472, 3072, 1), 0); del buf344  # reuse
    cpp_fused_gelu_gelu_backward_sum_63(c_void_p(buf347.data_ptr()), c_void_p(buf343.data_ptr()), c_void_p(addmm_118.data_ptr()), c_void_p(buf346.data_ptr()))
    del addmm_118
    buf348 = reinterpret_tensor(buf343, (4608, 768), (768, 1), 0); del buf343  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf347, (4608, 3072), (3072, 1), 0), permute_764, out=buf348)
    del permute_764
    buf349 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf347, (3072, 4608), (1, 3072), 0), view_597, out=buf349)
    del view_597
    buf350 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf351 = buf338; del buf338  # reuse
    buf352 = buf337; del buf337  # reuse
    buf353 = empty((768, ), device='cpu', dtype=torch.float32)
    buf354 = empty((768, ), device='cpu', dtype=torch.float32)
    buf355 = buf341; del buf341  # reuse
    buf357 = reinterpret_tensor(buf334, (8, 576, 768), (442368, 768, 1), 0); del buf334  # reuse
    buf356 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_64(c_void_p(buf355.data_ptr()), c_void_p(buf347.data_ptr()), c_void_p(buf348.data_ptr()), c_void_p(primals_555.data_ptr()), c_void_p(mul_294.data_ptr()), c_void_p(div_53.data_ptr()), c_void_p(primals_60.data_ptr()), c_void_p(addmm_117.data_ptr()), c_void_p(buf350.data_ptr()), c_void_p(buf351.data_ptr()), c_void_p(buf352.data_ptr()), c_void_p(buf353.data_ptr()), c_void_p(buf354.data_ptr()), c_void_p(buf357.data_ptr()), c_void_p(buf356.data_ptr()))
    del addmm_117
    del div_53
    del mul_294
    del primals_555
    del primals_60
    buf358 = buf348; del buf348  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf357, (4608, 768), (768, 1), 0), permute_768, out=buf358)
    del permute_768
    buf359 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf357, (768, 4608), (1, 768), 0), view_595, out=buf359)
    del view_595
    buf360 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf361 = reinterpret_tensor(buf319, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf319  # reuse
    cpp_fused_clone_sum_65(c_void_p(buf357.data_ptr()), c_void_p(buf358.data_ptr()), c_void_p(buf360.data_ptr()), c_void_p(buf361.data_ptr()))
    buf362 = reinterpret_tensor(buf358, (128, 576, 48), (27648, 48, 1), 0); del buf358  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_773, reinterpret_tensor(buf361, (128, 576, 48), (27648, 48, 1), 0), out=buf362)
    del permute_773
    buf363 = reinterpret_tensor(buf330, (128, 576, 576), (331776, 576, 1), 0); del buf330  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf361, (128, 576, 48), (27648, 48, 1), 0), permute_774, out=buf363)
    del permute_774
    buf364 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf365 = buf329; del buf329  # reuse
    cpp_fused__unsafe_view_clone_sum_66(c_void_p(buf363.data_ptr()), c_void_p(buf364.data_ptr()), c_void_p(buf365.data_ptr()))
    buf366 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf365, (16, 2654208), (1, 16), 0), view_589, out=buf366)
    del view_589
    buf367 = reinterpret_tensor(buf363, (2654208, 16), (16, 1), 0); del buf363  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf365, permute_778, out=buf367)
    del permute_778
    buf368 = buf325; del buf325  # reuse
    buf369 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf370 = reinterpret_tensor(buf367, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf367  # reuse
    cpp_fused__softmax_backward_data_clone_sum_67(c_void_p(buf370.data_ptr()), c_void_p(alias_46.data_ptr()), c_void_p(buf368.data_ptr()), c_void_p(buf369.data_ptr()))
    del alias_46
    buf371 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf370, (16, 2654208), (1, 16), 0), view_587, out=buf371)
    del view_587
    buf372 = buf365; del buf365  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf370, (2654208, 16), (16, 1), 0), permute_784, out=buf372)
    del permute_784
    buf373 = reinterpret_tensor(buf370, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf370  # reuse
    cpp_fused_clone_68(c_void_p(buf372.data_ptr()), c_void_p(buf373.data_ptr()))
    buf374 = reinterpret_tensor(buf361, (128, 48, 576), (27648, 576, 1), 0); del buf361  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_787, reinterpret_tensor(buf373, (128, 576, 576), (331776, 576, 1), 0), out=buf374)
    del permute_787
    buf375 = reinterpret_tensor(buf357, (128, 576, 48), (27648, 48, 1), 0); del buf357  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf373, (128, 576, 576), (331776, 576, 1), 0), permute_788, out=buf375)
    del permute_788
    buf376 = buf333; del buf333  # reuse
    cpp_fused_clone_69(c_void_p(buf362.data_ptr()), c_void_p(buf374.data_ptr()), c_void_p(buf375.data_ptr()), c_void_p(buf376.data_ptr()))
    buf377 = reinterpret_tensor(buf375, (4608, 768), (768, 1), 0); del buf375  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf376, (4608, 2304), (2304, 1), 0), permute_791, out=buf377)
    del permute_791
    buf378 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf376, (2304, 4608), (1, 2304), 0), view_581, out=buf378)
    del view_581
    buf379 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf380 = buf352; del buf352  # reuse
    buf381 = buf351; del buf351  # reuse
    buf382 = empty((768, ), device='cpu', dtype=torch.float32)
    buf383 = empty((768, ), device='cpu', dtype=torch.float32)
    buf384 = buf355; del buf355  # reuse
    buf386 = reinterpret_tensor(buf374, (8, 576, 768), (442368, 768, 1), 0); del buf374  # reuse
    buf385 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_70(c_void_p(buf384.data_ptr()), c_void_p(buf376.data_ptr()), c_void_p(buf377.data_ptr()), c_void_p(primals_545.data_ptr()), c_void_p(mul_290.data_ptr()), c_void_p(div_54.data_ptr()), c_void_p(primals_59.data_ptr()), c_void_p(addmm_115.data_ptr()), c_void_p(buf379.data_ptr()), c_void_p(buf380.data_ptr()), c_void_p(buf381.data_ptr()), c_void_p(buf382.data_ptr()), c_void_p(buf383.data_ptr()), c_void_p(buf386.data_ptr()), c_void_p(buf385.data_ptr()))
    del addmm_115
    del div_54
    del mul_290
    del primals_545
    del primals_59
    buf387 = reinterpret_tensor(buf347, (4608, 3072), (3072, 1), 0); del buf347  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf386, (4608, 768), (768, 1), 0), permute_795, out=buf387)
    del permute_795
    buf388 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf386, (768, 4608), (1, 768), 0), view_579, out=buf388)
    del view_579
    buf389 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf390 = reinterpret_tensor(buf387, (8, 576, 3072), (1769472, 3072, 1), 0); del buf387  # reuse
    cpp_fused_gelu_gelu_backward_sum_71(c_void_p(buf390.data_ptr()), c_void_p(buf386.data_ptr()), c_void_p(addmm_114.data_ptr()), c_void_p(buf389.data_ptr()))
    del addmm_114
    buf391 = reinterpret_tensor(buf386, (4608, 768), (768, 1), 0); del buf386  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf390, (4608, 3072), (3072, 1), 0), permute_799, out=buf391)
    del permute_799
    buf392 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf390, (3072, 4608), (1, 3072), 0), view_577, out=buf392)
    del view_577
    buf393 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf394 = buf381; del buf381  # reuse
    buf395 = buf380; del buf380  # reuse
    buf396 = empty((768, ), device='cpu', dtype=torch.float32)
    buf397 = empty((768, ), device='cpu', dtype=torch.float32)
    buf398 = buf384; del buf384  # reuse
    buf400 = reinterpret_tensor(buf377, (8, 576, 768), (442368, 768, 1), 0); del buf377  # reuse
    buf399 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_72(c_void_p(buf398.data_ptr()), c_void_p(buf390.data_ptr()), c_void_p(buf391.data_ptr()), c_void_p(primals_539.data_ptr()), c_void_p(mul_284.data_ptr()), c_void_p(div_55.data_ptr()), c_void_p(primals_58.data_ptr()), c_void_p(addmm_113.data_ptr()), c_void_p(buf393.data_ptr()), c_void_p(buf394.data_ptr()), c_void_p(buf395.data_ptr()), c_void_p(buf396.data_ptr()), c_void_p(buf397.data_ptr()), c_void_p(buf400.data_ptr()), c_void_p(buf399.data_ptr()))
    del addmm_113
    del div_55
    del mul_284
    del primals_539
    del primals_58
    buf401 = buf391; del buf391  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf400, (4608, 768), (768, 1), 0), permute_803, out=buf401)
    del permute_803
    buf402 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf400, (768, 4608), (1, 768), 0), view_575, out=buf402)
    del view_575
    buf403 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf404 = reinterpret_tensor(buf362, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf362  # reuse
    cpp_fused_clone_sum_73(c_void_p(buf400.data_ptr()), c_void_p(buf401.data_ptr()), c_void_p(buf403.data_ptr()), c_void_p(buf404.data_ptr()))
    buf405 = reinterpret_tensor(buf401, (128, 576, 48), (27648, 48, 1), 0); del buf401  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_808, reinterpret_tensor(buf404, (128, 576, 48), (27648, 48, 1), 0), out=buf405)
    del permute_808
    buf406 = reinterpret_tensor(buf373, (128, 576, 576), (331776, 576, 1), 0); del buf373  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf404, (128, 576, 48), (27648, 48, 1), 0), permute_809, out=buf406)
    del permute_809
    buf407 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf408 = buf372; del buf372  # reuse
    cpp_fused__unsafe_view_clone_sum_74(c_void_p(buf406.data_ptr()), c_void_p(buf407.data_ptr()), c_void_p(buf408.data_ptr()))
    buf409 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf408, (16, 2654208), (1, 16), 0), view_569, out=buf409)
    del view_569
    buf410 = reinterpret_tensor(buf406, (2654208, 16), (16, 1), 0); del buf406  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf408, permute_813, out=buf410)
    del permute_813
    buf411 = buf368; del buf368  # reuse
    buf412 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf413 = reinterpret_tensor(buf410, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf410  # reuse
    cpp_fused__softmax_backward_data_clone_sum_75(c_void_p(buf413.data_ptr()), c_void_p(alias_47.data_ptr()), c_void_p(buf411.data_ptr()), c_void_p(buf412.data_ptr()))
    del alias_47
    buf414 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf413, (16, 2654208), (1, 16), 0), view_567, out=buf414)
    del view_567
    buf415 = buf408; del buf408  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf413, (2654208, 16), (16, 1), 0), permute_819, out=buf415)
    del permute_819
    buf416 = reinterpret_tensor(buf413, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf413  # reuse
    cpp_fused_clone_76(c_void_p(buf415.data_ptr()), c_void_p(buf416.data_ptr()))
    buf417 = reinterpret_tensor(buf404, (128, 48, 576), (27648, 576, 1), 0); del buf404  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_822, reinterpret_tensor(buf416, (128, 576, 576), (331776, 576, 1), 0), out=buf417)
    del permute_822
    buf418 = reinterpret_tensor(buf400, (128, 576, 48), (27648, 48, 1), 0); del buf400  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf416, (128, 576, 576), (331776, 576, 1), 0), permute_823, out=buf418)
    del permute_823
    buf419 = buf376; del buf376  # reuse
    cpp_fused_clone_77(c_void_p(buf405.data_ptr()), c_void_p(buf417.data_ptr()), c_void_p(buf418.data_ptr()), c_void_p(buf419.data_ptr()))
    buf420 = reinterpret_tensor(buf418, (4608, 768), (768, 1), 0); del buf418  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf419, (4608, 2304), (2304, 1), 0), permute_826, out=buf420)
    del permute_826
    buf421 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf419, (2304, 4608), (1, 2304), 0), view_561, out=buf421)
    del view_561
    buf422 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf423 = buf395; del buf395  # reuse
    buf424 = buf394; del buf394  # reuse
    buf425 = empty((768, ), device='cpu', dtype=torch.float32)
    buf426 = empty((768, ), device='cpu', dtype=torch.float32)
    buf427 = buf398; del buf398  # reuse
    buf429 = reinterpret_tensor(buf417, (8, 576, 768), (442368, 768, 1), 0); del buf417  # reuse
    buf428 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_78(c_void_p(buf427.data_ptr()), c_void_p(buf419.data_ptr()), c_void_p(buf420.data_ptr()), c_void_p(primals_529.data_ptr()), c_void_p(mul_280.data_ptr()), c_void_p(div_56.data_ptr()), c_void_p(primals_57.data_ptr()), c_void_p(addmm_111.data_ptr()), c_void_p(buf422.data_ptr()), c_void_p(buf423.data_ptr()), c_void_p(buf424.data_ptr()), c_void_p(buf425.data_ptr()), c_void_p(buf426.data_ptr()), c_void_p(buf429.data_ptr()), c_void_p(buf428.data_ptr()))
    del addmm_111
    del div_56
    del mul_280
    del primals_529
    del primals_57
    buf430 = reinterpret_tensor(buf390, (4608, 3072), (3072, 1), 0); del buf390  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf429, (4608, 768), (768, 1), 0), permute_830, out=buf430)
    del permute_830
    buf431 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf429, (768, 4608), (1, 768), 0), view_559, out=buf431)
    del view_559
    buf432 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf433 = reinterpret_tensor(buf430, (8, 576, 3072), (1769472, 3072, 1), 0); del buf430  # reuse
    cpp_fused_gelu_gelu_backward_sum_79(c_void_p(buf433.data_ptr()), c_void_p(buf429.data_ptr()), c_void_p(addmm_110.data_ptr()), c_void_p(buf432.data_ptr()))
    del addmm_110
    buf434 = reinterpret_tensor(buf429, (4608, 768), (768, 1), 0); del buf429  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf433, (4608, 3072), (3072, 1), 0), permute_834, out=buf434)
    del permute_834
    buf435 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf433, (3072, 4608), (1, 3072), 0), view_557, out=buf435)
    del view_557
    buf436 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf437 = buf424; del buf424  # reuse
    buf438 = buf423; del buf423  # reuse
    buf439 = empty((768, ), device='cpu', dtype=torch.float32)
    buf440 = empty((768, ), device='cpu', dtype=torch.float32)
    buf441 = buf427; del buf427  # reuse
    buf443 = reinterpret_tensor(buf420, (8, 576, 768), (442368, 768, 1), 0); del buf420  # reuse
    buf442 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_80(c_void_p(buf441.data_ptr()), c_void_p(buf433.data_ptr()), c_void_p(buf434.data_ptr()), c_void_p(primals_523.data_ptr()), c_void_p(mul_274.data_ptr()), c_void_p(div_57.data_ptr()), c_void_p(primals_56.data_ptr()), c_void_p(addmm_109.data_ptr()), c_void_p(buf436.data_ptr()), c_void_p(buf437.data_ptr()), c_void_p(buf438.data_ptr()), c_void_p(buf439.data_ptr()), c_void_p(buf440.data_ptr()), c_void_p(buf443.data_ptr()), c_void_p(buf442.data_ptr()))
    del addmm_109
    del div_57
    del mul_274
    del primals_523
    del primals_56
    buf444 = buf434; del buf434  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf443, (4608, 768), (768, 1), 0), permute_838, out=buf444)
    del permute_838
    buf445 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf443, (768, 4608), (1, 768), 0), view_555, out=buf445)
    del view_555
    buf446 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf447 = reinterpret_tensor(buf405, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf405  # reuse
    cpp_fused_clone_sum_81(c_void_p(buf443.data_ptr()), c_void_p(buf444.data_ptr()), c_void_p(buf446.data_ptr()), c_void_p(buf447.data_ptr()))
    buf448 = reinterpret_tensor(buf444, (128, 576, 48), (27648, 48, 1), 0); del buf444  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_843, reinterpret_tensor(buf447, (128, 576, 48), (27648, 48, 1), 0), out=buf448)
    del permute_843
    buf449 = reinterpret_tensor(buf416, (128, 576, 576), (331776, 576, 1), 0); del buf416  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf447, (128, 576, 48), (27648, 48, 1), 0), permute_844, out=buf449)
    del permute_844
    buf450 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf451 = buf415; del buf415  # reuse
    cpp_fused__unsafe_view_clone_sum_82(c_void_p(buf449.data_ptr()), c_void_p(buf450.data_ptr()), c_void_p(buf451.data_ptr()))
    buf452 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf451, (16, 2654208), (1, 16), 0), view_549, out=buf452)
    del view_549
    buf453 = reinterpret_tensor(buf449, (2654208, 16), (16, 1), 0); del buf449  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf451, permute_848, out=buf453)
    del permute_848
    buf454 = buf411; del buf411  # reuse
    buf455 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf456 = reinterpret_tensor(buf453, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf453  # reuse
    cpp_fused__softmax_backward_data_clone_sum_83(c_void_p(buf456.data_ptr()), c_void_p(alias_48.data_ptr()), c_void_p(buf454.data_ptr()), c_void_p(buf455.data_ptr()))
    del alias_48
    buf457 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf456, (16, 2654208), (1, 16), 0), view_547, out=buf457)
    del view_547
    buf458 = buf451; del buf451  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf456, (2654208, 16), (16, 1), 0), permute_854, out=buf458)
    del permute_854
    buf459 = reinterpret_tensor(buf456, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf456  # reuse
    cpp_fused_clone_84(c_void_p(buf458.data_ptr()), c_void_p(buf459.data_ptr()))
    buf460 = reinterpret_tensor(buf447, (128, 48, 576), (27648, 576, 1), 0); del buf447  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_857, reinterpret_tensor(buf459, (128, 576, 576), (331776, 576, 1), 0), out=buf460)
    del permute_857
    buf461 = reinterpret_tensor(buf443, (128, 576, 48), (27648, 48, 1), 0); del buf443  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf459, (128, 576, 576), (331776, 576, 1), 0), permute_858, out=buf461)
    del permute_858
    buf462 = buf419; del buf419  # reuse
    cpp_fused_clone_85(c_void_p(buf448.data_ptr()), c_void_p(buf460.data_ptr()), c_void_p(buf461.data_ptr()), c_void_p(buf462.data_ptr()))
    buf463 = reinterpret_tensor(buf461, (4608, 768), (768, 1), 0); del buf461  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf462, (4608, 2304), (2304, 1), 0), permute_861, out=buf463)
    del permute_861
    buf464 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf462, (2304, 4608), (1, 2304), 0), view_541, out=buf464)
    del view_541
    buf465 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf466 = buf438; del buf438  # reuse
    buf467 = buf437; del buf437  # reuse
    buf468 = empty((768, ), device='cpu', dtype=torch.float32)
    buf469 = empty((768, ), device='cpu', dtype=torch.float32)
    buf470 = buf441; del buf441  # reuse
    buf472 = reinterpret_tensor(buf460, (8, 576, 768), (442368, 768, 1), 0); del buf460  # reuse
    buf471 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_86(c_void_p(buf470.data_ptr()), c_void_p(buf462.data_ptr()), c_void_p(buf463.data_ptr()), c_void_p(primals_513.data_ptr()), c_void_p(mul_270.data_ptr()), c_void_p(div_58.data_ptr()), c_void_p(primals_55.data_ptr()), c_void_p(addmm_107.data_ptr()), c_void_p(buf465.data_ptr()), c_void_p(buf466.data_ptr()), c_void_p(buf467.data_ptr()), c_void_p(buf468.data_ptr()), c_void_p(buf469.data_ptr()), c_void_p(buf472.data_ptr()), c_void_p(buf471.data_ptr()))
    del addmm_107
    del div_58
    del mul_270
    del primals_513
    del primals_55
    buf473 = reinterpret_tensor(buf433, (4608, 3072), (3072, 1), 0); del buf433  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf472, (4608, 768), (768, 1), 0), permute_865, out=buf473)
    del permute_865
    buf474 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf472, (768, 4608), (1, 768), 0), view_539, out=buf474)
    del view_539
    buf475 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf476 = reinterpret_tensor(buf473, (8, 576, 3072), (1769472, 3072, 1), 0); del buf473  # reuse
    cpp_fused_gelu_gelu_backward_sum_87(c_void_p(buf476.data_ptr()), c_void_p(buf472.data_ptr()), c_void_p(addmm_106.data_ptr()), c_void_p(buf475.data_ptr()))
    del addmm_106
    buf477 = reinterpret_tensor(buf472, (4608, 768), (768, 1), 0); del buf472  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf476, (4608, 3072), (3072, 1), 0), permute_869, out=buf477)
    del permute_869
    buf478 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf476, (3072, 4608), (1, 3072), 0), view_537, out=buf478)
    del view_537
    buf479 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf480 = buf467; del buf467  # reuse
    buf481 = buf466; del buf466  # reuse
    buf482 = empty((768, ), device='cpu', dtype=torch.float32)
    buf483 = empty((768, ), device='cpu', dtype=torch.float32)
    buf484 = buf470; del buf470  # reuse
    buf486 = reinterpret_tensor(buf463, (8, 576, 768), (442368, 768, 1), 0); del buf463  # reuse
    buf485 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_88(c_void_p(buf484.data_ptr()), c_void_p(buf476.data_ptr()), c_void_p(buf477.data_ptr()), c_void_p(primals_507.data_ptr()), c_void_p(mul_264.data_ptr()), c_void_p(div_59.data_ptr()), c_void_p(primals_54.data_ptr()), c_void_p(addmm_105.data_ptr()), c_void_p(buf479.data_ptr()), c_void_p(buf480.data_ptr()), c_void_p(buf481.data_ptr()), c_void_p(buf482.data_ptr()), c_void_p(buf483.data_ptr()), c_void_p(buf486.data_ptr()), c_void_p(buf485.data_ptr()))
    del addmm_105
    del div_59
    del mul_264
    del primals_507
    del primals_54
    buf487 = buf477; del buf477  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf486, (4608, 768), (768, 1), 0), permute_873, out=buf487)
    del permute_873
    buf488 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf486, (768, 4608), (1, 768), 0), view_535, out=buf488)
    del view_535
    buf489 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf490 = reinterpret_tensor(buf448, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf448  # reuse
    cpp_fused_clone_sum_89(c_void_p(buf486.data_ptr()), c_void_p(buf487.data_ptr()), c_void_p(buf489.data_ptr()), c_void_p(buf490.data_ptr()))
    buf491 = reinterpret_tensor(buf487, (128, 576, 48), (27648, 48, 1), 0); del buf487  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_878, reinterpret_tensor(buf490, (128, 576, 48), (27648, 48, 1), 0), out=buf491)
    del permute_878
    buf492 = reinterpret_tensor(buf459, (128, 576, 576), (331776, 576, 1), 0); del buf459  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf490, (128, 576, 48), (27648, 48, 1), 0), permute_879, out=buf492)
    del permute_879
    buf493 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf494 = buf458; del buf458  # reuse
    cpp_fused__unsafe_view_clone_sum_90(c_void_p(buf492.data_ptr()), c_void_p(buf493.data_ptr()), c_void_p(buf494.data_ptr()))
    buf495 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf494, (16, 2654208), (1, 16), 0), view_529, out=buf495)
    del view_529
    buf496 = reinterpret_tensor(buf492, (2654208, 16), (16, 1), 0); del buf492  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf494, permute_883, out=buf496)
    del permute_883
    buf497 = buf454; del buf454  # reuse
    buf498 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf499 = reinterpret_tensor(buf496, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf496  # reuse
    cpp_fused__softmax_backward_data_clone_sum_91(c_void_p(buf499.data_ptr()), c_void_p(alias_49.data_ptr()), c_void_p(buf497.data_ptr()), c_void_p(buf498.data_ptr()))
    del alias_49
    buf500 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf499, (16, 2654208), (1, 16), 0), view_527, out=buf500)
    del view_527
    buf501 = buf494; del buf494  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf499, (2654208, 16), (16, 1), 0), permute_889, out=buf501)
    del permute_889
    buf502 = reinterpret_tensor(buf499, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf499  # reuse
    cpp_fused_clone_92(c_void_p(buf501.data_ptr()), c_void_p(buf502.data_ptr()))
    buf503 = reinterpret_tensor(buf490, (128, 48, 576), (27648, 576, 1), 0); del buf490  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_892, reinterpret_tensor(buf502, (128, 576, 576), (331776, 576, 1), 0), out=buf503)
    del permute_892
    buf504 = reinterpret_tensor(buf486, (128, 576, 48), (27648, 48, 1), 0); del buf486  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf502, (128, 576, 576), (331776, 576, 1), 0), permute_893, out=buf504)
    del permute_893
    buf505 = buf462; del buf462  # reuse
    cpp_fused_clone_93(c_void_p(buf491.data_ptr()), c_void_p(buf503.data_ptr()), c_void_p(buf504.data_ptr()), c_void_p(buf505.data_ptr()))
    buf506 = reinterpret_tensor(buf504, (4608, 768), (768, 1), 0); del buf504  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf505, (4608, 2304), (2304, 1), 0), permute_896, out=buf506)
    del permute_896
    buf507 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf505, (2304, 4608), (1, 2304), 0), view_521, out=buf507)
    del view_521
    buf508 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf509 = buf481; del buf481  # reuse
    buf510 = buf480; del buf480  # reuse
    buf511 = empty((768, ), device='cpu', dtype=torch.float32)
    buf512 = empty((768, ), device='cpu', dtype=torch.float32)
    buf513 = buf484; del buf484  # reuse
    buf515 = reinterpret_tensor(buf503, (8, 576, 768), (442368, 768, 1), 0); del buf503  # reuse
    buf514 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_94(c_void_p(buf513.data_ptr()), c_void_p(buf505.data_ptr()), c_void_p(buf506.data_ptr()), c_void_p(primals_497.data_ptr()), c_void_p(mul_260.data_ptr()), c_void_p(div_60.data_ptr()), c_void_p(primals_53.data_ptr()), c_void_p(addmm_103.data_ptr()), c_void_p(buf508.data_ptr()), c_void_p(buf509.data_ptr()), c_void_p(buf510.data_ptr()), c_void_p(buf511.data_ptr()), c_void_p(buf512.data_ptr()), c_void_p(buf515.data_ptr()), c_void_p(buf514.data_ptr()))
    del addmm_103
    del div_60
    del mul_260
    del primals_497
    del primals_53
    buf516 = reinterpret_tensor(buf476, (4608, 3072), (3072, 1), 0); del buf476  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf515, (4608, 768), (768, 1), 0), permute_900, out=buf516)
    del permute_900
    buf517 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf515, (768, 4608), (1, 768), 0), view_519, out=buf517)
    del view_519
    buf518 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf519 = reinterpret_tensor(buf516, (8, 576, 3072), (1769472, 3072, 1), 0); del buf516  # reuse
    cpp_fused_gelu_gelu_backward_sum_95(c_void_p(buf519.data_ptr()), c_void_p(buf515.data_ptr()), c_void_p(addmm_102.data_ptr()), c_void_p(buf518.data_ptr()))
    del addmm_102
    buf520 = reinterpret_tensor(buf515, (4608, 768), (768, 1), 0); del buf515  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf519, (4608, 3072), (3072, 1), 0), permute_904, out=buf520)
    del permute_904
    buf521 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf519, (3072, 4608), (1, 3072), 0), view_517, out=buf521)
    del view_517
    buf522 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf523 = buf510; del buf510  # reuse
    buf524 = buf509; del buf509  # reuse
    buf525 = empty((768, ), device='cpu', dtype=torch.float32)
    buf526 = empty((768, ), device='cpu', dtype=torch.float32)
    buf527 = buf513; del buf513  # reuse
    buf529 = reinterpret_tensor(buf506, (8, 576, 768), (442368, 768, 1), 0); del buf506  # reuse
    buf528 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_96(c_void_p(buf527.data_ptr()), c_void_p(buf519.data_ptr()), c_void_p(buf520.data_ptr()), c_void_p(primals_491.data_ptr()), c_void_p(mul_254.data_ptr()), c_void_p(div_61.data_ptr()), c_void_p(primals_52.data_ptr()), c_void_p(addmm_101.data_ptr()), c_void_p(buf522.data_ptr()), c_void_p(buf523.data_ptr()), c_void_p(buf524.data_ptr()), c_void_p(buf525.data_ptr()), c_void_p(buf526.data_ptr()), c_void_p(buf529.data_ptr()), c_void_p(buf528.data_ptr()))
    del addmm_101
    del div_61
    del mul_254
    del primals_491
    del primals_52
    buf530 = buf520; del buf520  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf529, (4608, 768), (768, 1), 0), permute_908, out=buf530)
    del permute_908
    buf531 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf529, (768, 4608), (1, 768), 0), view_515, out=buf531)
    del view_515
    buf532 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf533 = reinterpret_tensor(buf491, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf491  # reuse
    cpp_fused_clone_sum_97(c_void_p(buf529.data_ptr()), c_void_p(buf530.data_ptr()), c_void_p(buf532.data_ptr()), c_void_p(buf533.data_ptr()))
    buf534 = reinterpret_tensor(buf530, (128, 576, 48), (27648, 48, 1), 0); del buf530  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_913, reinterpret_tensor(buf533, (128, 576, 48), (27648, 48, 1), 0), out=buf534)
    del permute_913
    buf535 = reinterpret_tensor(buf502, (128, 576, 576), (331776, 576, 1), 0); del buf502  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf533, (128, 576, 48), (27648, 48, 1), 0), permute_914, out=buf535)
    del permute_914
    buf536 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf537 = buf501; del buf501  # reuse
    cpp_fused__unsafe_view_clone_sum_98(c_void_p(buf535.data_ptr()), c_void_p(buf536.data_ptr()), c_void_p(buf537.data_ptr()))
    buf538 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf537, (16, 2654208), (1, 16), 0), view_509, out=buf538)
    del view_509
    buf539 = reinterpret_tensor(buf535, (2654208, 16), (16, 1), 0); del buf535  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf537, permute_918, out=buf539)
    del permute_918
    buf540 = buf497; del buf497  # reuse
    buf541 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf542 = reinterpret_tensor(buf539, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf539  # reuse
    cpp_fused__softmax_backward_data_clone_sum_99(c_void_p(buf542.data_ptr()), c_void_p(alias_50.data_ptr()), c_void_p(buf540.data_ptr()), c_void_p(buf541.data_ptr()))
    del alias_50
    buf543 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf542, (16, 2654208), (1, 16), 0), view_507, out=buf543)
    del view_507
    buf544 = buf537; del buf537  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf542, (2654208, 16), (16, 1), 0), permute_924, out=buf544)
    del permute_924
    buf545 = reinterpret_tensor(buf542, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf542  # reuse
    cpp_fused_clone_100(c_void_p(buf544.data_ptr()), c_void_p(buf545.data_ptr()))
    buf546 = reinterpret_tensor(buf533, (128, 48, 576), (27648, 576, 1), 0); del buf533  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_927, reinterpret_tensor(buf545, (128, 576, 576), (331776, 576, 1), 0), out=buf546)
    del permute_927
    buf547 = reinterpret_tensor(buf529, (128, 576, 48), (27648, 48, 1), 0); del buf529  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf545, (128, 576, 576), (331776, 576, 1), 0), permute_928, out=buf547)
    del permute_928
    buf548 = buf505; del buf505  # reuse
    cpp_fused_clone_101(c_void_p(buf534.data_ptr()), c_void_p(buf546.data_ptr()), c_void_p(buf547.data_ptr()), c_void_p(buf548.data_ptr()))
    buf549 = reinterpret_tensor(buf547, (4608, 768), (768, 1), 0); del buf547  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf548, (4608, 2304), (2304, 1), 0), permute_931, out=buf549)
    del permute_931
    buf550 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf548, (2304, 4608), (1, 2304), 0), view_501, out=buf550)
    del view_501
    buf551 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf552 = buf524; del buf524  # reuse
    buf553 = buf523; del buf523  # reuse
    buf554 = empty((768, ), device='cpu', dtype=torch.float32)
    buf555 = empty((768, ), device='cpu', dtype=torch.float32)
    buf556 = buf527; del buf527  # reuse
    buf558 = reinterpret_tensor(buf546, (8, 576, 768), (442368, 768, 1), 0); del buf546  # reuse
    buf557 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_102(c_void_p(buf556.data_ptr()), c_void_p(buf548.data_ptr()), c_void_p(buf549.data_ptr()), c_void_p(primals_481.data_ptr()), c_void_p(mul_250.data_ptr()), c_void_p(div_62.data_ptr()), c_void_p(primals_51.data_ptr()), c_void_p(addmm_99.data_ptr()), c_void_p(buf551.data_ptr()), c_void_p(buf552.data_ptr()), c_void_p(buf553.data_ptr()), c_void_p(buf554.data_ptr()), c_void_p(buf555.data_ptr()), c_void_p(buf558.data_ptr()), c_void_p(buf557.data_ptr()))
    del addmm_99
    del div_62
    del mul_250
    del primals_481
    del primals_51
    buf559 = reinterpret_tensor(buf519, (4608, 3072), (3072, 1), 0); del buf519  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf558, (4608, 768), (768, 1), 0), permute_935, out=buf559)
    del permute_935
    buf560 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf558, (768, 4608), (1, 768), 0), view_499, out=buf560)
    del view_499
    buf561 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf562 = reinterpret_tensor(buf559, (8, 576, 3072), (1769472, 3072, 1), 0); del buf559  # reuse
    cpp_fused_gelu_gelu_backward_sum_103(c_void_p(buf562.data_ptr()), c_void_p(buf558.data_ptr()), c_void_p(addmm_98.data_ptr()), c_void_p(buf561.data_ptr()))
    del addmm_98
    buf563 = reinterpret_tensor(buf558, (4608, 768), (768, 1), 0); del buf558  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf562, (4608, 3072), (3072, 1), 0), permute_939, out=buf563)
    del permute_939
    buf564 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf562, (3072, 4608), (1, 3072), 0), view_497, out=buf564)
    del view_497
    buf565 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf566 = buf553; del buf553  # reuse
    buf567 = buf552; del buf552  # reuse
    buf568 = empty((768, ), device='cpu', dtype=torch.float32)
    buf569 = empty((768, ), device='cpu', dtype=torch.float32)
    buf570 = buf556; del buf556  # reuse
    buf572 = reinterpret_tensor(buf549, (8, 576, 768), (442368, 768, 1), 0); del buf549  # reuse
    buf571 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_104(c_void_p(buf570.data_ptr()), c_void_p(buf562.data_ptr()), c_void_p(buf563.data_ptr()), c_void_p(primals_475.data_ptr()), c_void_p(mul_244.data_ptr()), c_void_p(div_63.data_ptr()), c_void_p(primals_50.data_ptr()), c_void_p(addmm_97.data_ptr()), c_void_p(buf565.data_ptr()), c_void_p(buf566.data_ptr()), c_void_p(buf567.data_ptr()), c_void_p(buf568.data_ptr()), c_void_p(buf569.data_ptr()), c_void_p(buf572.data_ptr()), c_void_p(buf571.data_ptr()))
    del addmm_97
    del div_63
    del mul_244
    del primals_475
    del primals_50
    buf573 = buf563; del buf563  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf572, (4608, 768), (768, 1), 0), permute_943, out=buf573)
    del permute_943
    buf574 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf572, (768, 4608), (1, 768), 0), view_495, out=buf574)
    del view_495
    buf575 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf576 = reinterpret_tensor(buf534, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf534  # reuse
    cpp_fused_clone_sum_105(c_void_p(buf572.data_ptr()), c_void_p(buf573.data_ptr()), c_void_p(buf575.data_ptr()), c_void_p(buf576.data_ptr()))
    buf577 = reinterpret_tensor(buf573, (128, 576, 48), (27648, 48, 1), 0); del buf573  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_948, reinterpret_tensor(buf576, (128, 576, 48), (27648, 48, 1), 0), out=buf577)
    del permute_948
    buf578 = reinterpret_tensor(buf545, (128, 576, 576), (331776, 576, 1), 0); del buf545  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf576, (128, 576, 48), (27648, 48, 1), 0), permute_949, out=buf578)
    del permute_949
    buf579 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf580 = buf544; del buf544  # reuse
    cpp_fused__unsafe_view_clone_sum_106(c_void_p(buf578.data_ptr()), c_void_p(buf579.data_ptr()), c_void_p(buf580.data_ptr()))
    buf581 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf580, (16, 2654208), (1, 16), 0), view_489, out=buf581)
    del view_489
    buf582 = reinterpret_tensor(buf578, (2654208, 16), (16, 1), 0); del buf578  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf580, permute_953, out=buf582)
    del permute_953
    buf583 = buf540; del buf540  # reuse
    buf584 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf585 = reinterpret_tensor(buf582, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf582  # reuse
    cpp_fused__softmax_backward_data_clone_sum_107(c_void_p(buf585.data_ptr()), c_void_p(alias_51.data_ptr()), c_void_p(buf583.data_ptr()), c_void_p(buf584.data_ptr()))
    del alias_51
    buf586 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf585, (16, 2654208), (1, 16), 0), view_487, out=buf586)
    del view_487
    buf587 = buf580; del buf580  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf585, (2654208, 16), (16, 1), 0), permute_959, out=buf587)
    del permute_959
    buf588 = reinterpret_tensor(buf585, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf585  # reuse
    cpp_fused_clone_108(c_void_p(buf587.data_ptr()), c_void_p(buf588.data_ptr()))
    buf589 = reinterpret_tensor(buf576, (128, 48, 576), (27648, 576, 1), 0); del buf576  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_962, reinterpret_tensor(buf588, (128, 576, 576), (331776, 576, 1), 0), out=buf589)
    del permute_962
    buf590 = reinterpret_tensor(buf572, (128, 576, 48), (27648, 48, 1), 0); del buf572  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf588, (128, 576, 576), (331776, 576, 1), 0), permute_963, out=buf590)
    del permute_963
    buf591 = buf548; del buf548  # reuse
    cpp_fused_clone_109(c_void_p(buf577.data_ptr()), c_void_p(buf589.data_ptr()), c_void_p(buf590.data_ptr()), c_void_p(buf591.data_ptr()))
    buf592 = reinterpret_tensor(buf590, (4608, 768), (768, 1), 0); del buf590  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf591, (4608, 2304), (2304, 1), 0), permute_966, out=buf592)
    del permute_966
    buf593 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf591, (2304, 4608), (1, 2304), 0), view_481, out=buf593)
    del view_481
    buf594 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf595 = buf567; del buf567  # reuse
    buf596 = buf566; del buf566  # reuse
    buf597 = empty((768, ), device='cpu', dtype=torch.float32)
    buf598 = empty((768, ), device='cpu', dtype=torch.float32)
    buf599 = buf570; del buf570  # reuse
    buf601 = reinterpret_tensor(buf589, (8, 576, 768), (442368, 768, 1), 0); del buf589  # reuse
    buf600 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_110(c_void_p(buf599.data_ptr()), c_void_p(buf591.data_ptr()), c_void_p(buf592.data_ptr()), c_void_p(primals_465.data_ptr()), c_void_p(mul_240.data_ptr()), c_void_p(div_64.data_ptr()), c_void_p(primals_49.data_ptr()), c_void_p(addmm_95.data_ptr()), c_void_p(buf594.data_ptr()), c_void_p(buf595.data_ptr()), c_void_p(buf596.data_ptr()), c_void_p(buf597.data_ptr()), c_void_p(buf598.data_ptr()), c_void_p(buf601.data_ptr()), c_void_p(buf600.data_ptr()))
    del addmm_95
    del div_64
    del mul_240
    del primals_465
    del primals_49
    buf602 = reinterpret_tensor(buf562, (4608, 3072), (3072, 1), 0); del buf562  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf601, (4608, 768), (768, 1), 0), permute_970, out=buf602)
    del permute_970
    buf603 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf601, (768, 4608), (1, 768), 0), view_479, out=buf603)
    del view_479
    buf604 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf605 = reinterpret_tensor(buf602, (8, 576, 3072), (1769472, 3072, 1), 0); del buf602  # reuse
    cpp_fused_gelu_gelu_backward_sum_111(c_void_p(buf605.data_ptr()), c_void_p(buf601.data_ptr()), c_void_p(addmm_94.data_ptr()), c_void_p(buf604.data_ptr()))
    del addmm_94
    buf606 = reinterpret_tensor(buf601, (4608, 768), (768, 1), 0); del buf601  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf605, (4608, 3072), (3072, 1), 0), permute_974, out=buf606)
    del permute_974
    buf607 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf605, (3072, 4608), (1, 3072), 0), view_477, out=buf607)
    del view_477
    buf608 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf609 = buf596; del buf596  # reuse
    buf610 = buf595; del buf595  # reuse
    buf611 = empty((768, ), device='cpu', dtype=torch.float32)
    buf612 = empty((768, ), device='cpu', dtype=torch.float32)
    buf613 = buf599; del buf599  # reuse
    buf615 = reinterpret_tensor(buf592, (8, 576, 768), (442368, 768, 1), 0); del buf592  # reuse
    buf614 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_112(c_void_p(buf613.data_ptr()), c_void_p(buf605.data_ptr()), c_void_p(buf606.data_ptr()), c_void_p(primals_459.data_ptr()), c_void_p(mul_234.data_ptr()), c_void_p(div_65.data_ptr()), c_void_p(primals_48.data_ptr()), c_void_p(addmm_93.data_ptr()), c_void_p(buf608.data_ptr()), c_void_p(buf609.data_ptr()), c_void_p(buf610.data_ptr()), c_void_p(buf611.data_ptr()), c_void_p(buf612.data_ptr()), c_void_p(buf615.data_ptr()), c_void_p(buf614.data_ptr()))
    del addmm_93
    del div_65
    del mul_234
    del primals_459
    del primals_48
    buf616 = buf606; del buf606  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf615, (4608, 768), (768, 1), 0), permute_978, out=buf616)
    del permute_978
    buf617 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf615, (768, 4608), (1, 768), 0), view_475, out=buf617)
    del view_475
    buf618 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf619 = reinterpret_tensor(buf577, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf577  # reuse
    cpp_fused_clone_sum_113(c_void_p(buf615.data_ptr()), c_void_p(buf616.data_ptr()), c_void_p(buf618.data_ptr()), c_void_p(buf619.data_ptr()))
    buf620 = reinterpret_tensor(buf616, (128, 576, 48), (27648, 48, 1), 0); del buf616  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_983, reinterpret_tensor(buf619, (128, 576, 48), (27648, 48, 1), 0), out=buf620)
    del permute_983
    buf621 = reinterpret_tensor(buf588, (128, 576, 576), (331776, 576, 1), 0); del buf588  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf619, (128, 576, 48), (27648, 48, 1), 0), permute_984, out=buf621)
    del permute_984
    buf622 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf623 = buf587; del buf587  # reuse
    cpp_fused__unsafe_view_clone_sum_114(c_void_p(buf621.data_ptr()), c_void_p(buf622.data_ptr()), c_void_p(buf623.data_ptr()))
    buf624 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf623, (16, 2654208), (1, 16), 0), view_469, out=buf624)
    del view_469
    buf625 = reinterpret_tensor(buf621, (2654208, 16), (16, 1), 0); del buf621  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf623, permute_988, out=buf625)
    del permute_988
    buf626 = buf583; del buf583  # reuse
    buf627 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf628 = reinterpret_tensor(buf625, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf625  # reuse
    cpp_fused__softmax_backward_data_clone_sum_115(c_void_p(buf628.data_ptr()), c_void_p(alias_52.data_ptr()), c_void_p(buf626.data_ptr()), c_void_p(buf627.data_ptr()))
    del alias_52
    buf629 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf628, (16, 2654208), (1, 16), 0), view_467, out=buf629)
    del view_467
    buf630 = buf623; del buf623  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf628, (2654208, 16), (16, 1), 0), permute_994, out=buf630)
    del permute_994
    buf631 = reinterpret_tensor(buf628, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf628  # reuse
    cpp_fused_clone_116(c_void_p(buf630.data_ptr()), c_void_p(buf631.data_ptr()))
    buf632 = reinterpret_tensor(buf619, (128, 48, 576), (27648, 576, 1), 0); del buf619  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_997, reinterpret_tensor(buf631, (128, 576, 576), (331776, 576, 1), 0), out=buf632)
    del permute_997
    buf633 = reinterpret_tensor(buf615, (128, 576, 48), (27648, 48, 1), 0); del buf615  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf631, (128, 576, 576), (331776, 576, 1), 0), permute_998, out=buf633)
    del permute_998
    buf634 = buf591; del buf591  # reuse
    cpp_fused_clone_117(c_void_p(buf620.data_ptr()), c_void_p(buf632.data_ptr()), c_void_p(buf633.data_ptr()), c_void_p(buf634.data_ptr()))
    buf635 = reinterpret_tensor(buf633, (4608, 768), (768, 1), 0); del buf633  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf634, (4608, 2304), (2304, 1), 0), permute_1001, out=buf635)
    del permute_1001
    buf636 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf634, (2304, 4608), (1, 2304), 0), view_461, out=buf636)
    del view_461
    buf637 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf638 = buf610; del buf610  # reuse
    buf639 = buf609; del buf609  # reuse
    buf640 = empty((768, ), device='cpu', dtype=torch.float32)
    buf641 = empty((768, ), device='cpu', dtype=torch.float32)
    buf642 = buf613; del buf613  # reuse
    buf644 = reinterpret_tensor(buf632, (8, 576, 768), (442368, 768, 1), 0); del buf632  # reuse
    buf643 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_118(c_void_p(buf642.data_ptr()), c_void_p(buf634.data_ptr()), c_void_p(buf635.data_ptr()), c_void_p(primals_449.data_ptr()), c_void_p(mul_230.data_ptr()), c_void_p(div_66.data_ptr()), c_void_p(primals_47.data_ptr()), c_void_p(addmm_91.data_ptr()), c_void_p(buf637.data_ptr()), c_void_p(buf638.data_ptr()), c_void_p(buf639.data_ptr()), c_void_p(buf640.data_ptr()), c_void_p(buf641.data_ptr()), c_void_p(buf644.data_ptr()), c_void_p(buf643.data_ptr()))
    del addmm_91
    del div_66
    del mul_230
    del primals_449
    del primals_47
    buf645 = reinterpret_tensor(buf605, (4608, 3072), (3072, 1), 0); del buf605  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf644, (4608, 768), (768, 1), 0), permute_1005, out=buf645)
    del permute_1005
    buf646 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf644, (768, 4608), (1, 768), 0), view_459, out=buf646)
    del view_459
    buf647 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf648 = reinterpret_tensor(buf645, (8, 576, 3072), (1769472, 3072, 1), 0); del buf645  # reuse
    cpp_fused_gelu_gelu_backward_sum_119(c_void_p(buf648.data_ptr()), c_void_p(buf644.data_ptr()), c_void_p(addmm_90.data_ptr()), c_void_p(buf647.data_ptr()))
    del addmm_90
    buf649 = reinterpret_tensor(buf644, (4608, 768), (768, 1), 0); del buf644  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf648, (4608, 3072), (3072, 1), 0), permute_1009, out=buf649)
    del permute_1009
    buf650 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf648, (3072, 4608), (1, 3072), 0), view_457, out=buf650)
    del view_457
    buf651 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf652 = buf639; del buf639  # reuse
    buf653 = buf638; del buf638  # reuse
    buf654 = empty((768, ), device='cpu', dtype=torch.float32)
    buf655 = empty((768, ), device='cpu', dtype=torch.float32)
    buf656 = buf642; del buf642  # reuse
    buf658 = reinterpret_tensor(buf635, (8, 576, 768), (442368, 768, 1), 0); del buf635  # reuse
    buf657 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_120(c_void_p(buf656.data_ptr()), c_void_p(buf648.data_ptr()), c_void_p(buf649.data_ptr()), c_void_p(primals_443.data_ptr()), c_void_p(mul_224.data_ptr()), c_void_p(div_67.data_ptr()), c_void_p(primals_46.data_ptr()), c_void_p(addmm_89.data_ptr()), c_void_p(buf651.data_ptr()), c_void_p(buf652.data_ptr()), c_void_p(buf653.data_ptr()), c_void_p(buf654.data_ptr()), c_void_p(buf655.data_ptr()), c_void_p(buf658.data_ptr()), c_void_p(buf657.data_ptr()))
    del addmm_89
    del div_67
    del mul_224
    del primals_443
    del primals_46
    buf659 = buf649; del buf649  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf658, (4608, 768), (768, 1), 0), permute_1013, out=buf659)
    del permute_1013
    buf660 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf658, (768, 4608), (1, 768), 0), view_455, out=buf660)
    del view_455
    buf661 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf662 = reinterpret_tensor(buf620, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf620  # reuse
    cpp_fused_clone_sum_121(c_void_p(buf658.data_ptr()), c_void_p(buf659.data_ptr()), c_void_p(buf661.data_ptr()), c_void_p(buf662.data_ptr()))
    buf663 = reinterpret_tensor(buf659, (128, 576, 48), (27648, 48, 1), 0); del buf659  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1018, reinterpret_tensor(buf662, (128, 576, 48), (27648, 48, 1), 0), out=buf663)
    del permute_1018
    buf664 = reinterpret_tensor(buf631, (128, 576, 576), (331776, 576, 1), 0); del buf631  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf662, (128, 576, 48), (27648, 48, 1), 0), permute_1019, out=buf664)
    del permute_1019
    buf665 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf666 = buf630; del buf630  # reuse
    cpp_fused__unsafe_view_clone_sum_122(c_void_p(buf664.data_ptr()), c_void_p(buf665.data_ptr()), c_void_p(buf666.data_ptr()))
    buf667 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf666, (16, 2654208), (1, 16), 0), view_449, out=buf667)
    del view_449
    buf668 = reinterpret_tensor(buf664, (2654208, 16), (16, 1), 0); del buf664  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf666, permute_1023, out=buf668)
    del permute_1023
    buf669 = buf626; del buf626  # reuse
    buf670 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf671 = reinterpret_tensor(buf668, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf668  # reuse
    cpp_fused__softmax_backward_data_clone_sum_123(c_void_p(buf671.data_ptr()), c_void_p(alias_53.data_ptr()), c_void_p(buf669.data_ptr()), c_void_p(buf670.data_ptr()))
    del alias_53
    buf672 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf671, (16, 2654208), (1, 16), 0), view_447, out=buf672)
    del view_447
    buf673 = buf666; del buf666  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf671, (2654208, 16), (16, 1), 0), permute_1029, out=buf673)
    del permute_1029
    buf674 = reinterpret_tensor(buf671, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf671  # reuse
    cpp_fused_clone_124(c_void_p(buf673.data_ptr()), c_void_p(buf674.data_ptr()))
    buf675 = reinterpret_tensor(buf662, (128, 48, 576), (27648, 576, 1), 0); del buf662  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1032, reinterpret_tensor(buf674, (128, 576, 576), (331776, 576, 1), 0), out=buf675)
    del permute_1032
    buf676 = reinterpret_tensor(buf658, (128, 576, 48), (27648, 48, 1), 0); del buf658  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf674, (128, 576, 576), (331776, 576, 1), 0), permute_1033, out=buf676)
    del permute_1033
    buf677 = buf634; del buf634  # reuse
    cpp_fused_clone_125(c_void_p(buf663.data_ptr()), c_void_p(buf675.data_ptr()), c_void_p(buf676.data_ptr()), c_void_p(buf677.data_ptr()))
    buf678 = reinterpret_tensor(buf676, (4608, 768), (768, 1), 0); del buf676  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf677, (4608, 2304), (2304, 1), 0), permute_1036, out=buf678)
    del permute_1036
    buf679 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf677, (2304, 4608), (1, 2304), 0), view_441, out=buf679)
    del view_441
    buf680 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf681 = buf653; del buf653  # reuse
    buf682 = buf652; del buf652  # reuse
    buf683 = empty((768, ), device='cpu', dtype=torch.float32)
    buf684 = empty((768, ), device='cpu', dtype=torch.float32)
    buf685 = buf656; del buf656  # reuse
    buf687 = reinterpret_tensor(buf675, (8, 576, 768), (442368, 768, 1), 0); del buf675  # reuse
    buf686 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_126(c_void_p(buf685.data_ptr()), c_void_p(buf677.data_ptr()), c_void_p(buf678.data_ptr()), c_void_p(primals_433.data_ptr()), c_void_p(mul_220.data_ptr()), c_void_p(div_68.data_ptr()), c_void_p(primals_45.data_ptr()), c_void_p(addmm_87.data_ptr()), c_void_p(buf680.data_ptr()), c_void_p(buf681.data_ptr()), c_void_p(buf682.data_ptr()), c_void_p(buf683.data_ptr()), c_void_p(buf684.data_ptr()), c_void_p(buf687.data_ptr()), c_void_p(buf686.data_ptr()))
    del addmm_87
    del div_68
    del mul_220
    del primals_433
    del primals_45
    buf688 = reinterpret_tensor(buf648, (4608, 3072), (3072, 1), 0); del buf648  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf687, (4608, 768), (768, 1), 0), permute_1040, out=buf688)
    del permute_1040
    buf689 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf687, (768, 4608), (1, 768), 0), view_439, out=buf689)
    del view_439
    buf690 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf691 = reinterpret_tensor(buf688, (8, 576, 3072), (1769472, 3072, 1), 0); del buf688  # reuse
    cpp_fused_gelu_gelu_backward_sum_127(c_void_p(buf691.data_ptr()), c_void_p(buf687.data_ptr()), c_void_p(addmm_86.data_ptr()), c_void_p(buf690.data_ptr()))
    del addmm_86
    buf692 = reinterpret_tensor(buf687, (4608, 768), (768, 1), 0); del buf687  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf691, (4608, 3072), (3072, 1), 0), permute_1044, out=buf692)
    del permute_1044
    buf693 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf691, (3072, 4608), (1, 3072), 0), view_437, out=buf693)
    del view_437
    buf694 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf695 = buf682; del buf682  # reuse
    buf696 = buf681; del buf681  # reuse
    buf697 = empty((768, ), device='cpu', dtype=torch.float32)
    buf698 = empty((768, ), device='cpu', dtype=torch.float32)
    buf699 = buf685; del buf685  # reuse
    buf701 = reinterpret_tensor(buf678, (8, 576, 768), (442368, 768, 1), 0); del buf678  # reuse
    buf700 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_128(c_void_p(buf699.data_ptr()), c_void_p(buf691.data_ptr()), c_void_p(buf692.data_ptr()), c_void_p(primals_427.data_ptr()), c_void_p(mul_214.data_ptr()), c_void_p(div_69.data_ptr()), c_void_p(primals_44.data_ptr()), c_void_p(addmm_85.data_ptr()), c_void_p(buf694.data_ptr()), c_void_p(buf695.data_ptr()), c_void_p(buf696.data_ptr()), c_void_p(buf697.data_ptr()), c_void_p(buf698.data_ptr()), c_void_p(buf701.data_ptr()), c_void_p(buf700.data_ptr()))
    del addmm_85
    del div_69
    del mul_214
    del primals_427
    del primals_44
    buf702 = buf692; del buf692  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf701, (4608, 768), (768, 1), 0), permute_1048, out=buf702)
    del permute_1048
    buf703 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf701, (768, 4608), (1, 768), 0), view_435, out=buf703)
    del view_435
    buf704 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf705 = reinterpret_tensor(buf663, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf663  # reuse
    cpp_fused_clone_sum_129(c_void_p(buf701.data_ptr()), c_void_p(buf702.data_ptr()), c_void_p(buf704.data_ptr()), c_void_p(buf705.data_ptr()))
    buf706 = reinterpret_tensor(buf702, (128, 576, 48), (27648, 48, 1), 0); del buf702  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1053, reinterpret_tensor(buf705, (128, 576, 48), (27648, 48, 1), 0), out=buf706)
    del permute_1053
    buf707 = reinterpret_tensor(buf674, (128, 576, 576), (331776, 576, 1), 0); del buf674  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf705, (128, 576, 48), (27648, 48, 1), 0), permute_1054, out=buf707)
    del permute_1054
    buf708 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf709 = buf673; del buf673  # reuse
    cpp_fused__unsafe_view_clone_sum_130(c_void_p(buf707.data_ptr()), c_void_p(buf708.data_ptr()), c_void_p(buf709.data_ptr()))
    buf710 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf709, (16, 2654208), (1, 16), 0), view_429, out=buf710)
    del view_429
    buf711 = reinterpret_tensor(buf707, (2654208, 16), (16, 1), 0); del buf707  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf709, permute_1058, out=buf711)
    del permute_1058
    buf712 = buf669; del buf669  # reuse
    buf713 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf714 = reinterpret_tensor(buf711, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf711  # reuse
    cpp_fused__softmax_backward_data_clone_sum_131(c_void_p(buf714.data_ptr()), c_void_p(alias_54.data_ptr()), c_void_p(buf712.data_ptr()), c_void_p(buf713.data_ptr()))
    del alias_54
    buf715 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf714, (16, 2654208), (1, 16), 0), view_427, out=buf715)
    del view_427
    buf716 = buf709; del buf709  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf714, (2654208, 16), (16, 1), 0), permute_1064, out=buf716)
    del permute_1064
    buf717 = reinterpret_tensor(buf714, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf714  # reuse
    cpp_fused_clone_132(c_void_p(buf716.data_ptr()), c_void_p(buf717.data_ptr()))
    buf718 = reinterpret_tensor(buf705, (128, 48, 576), (27648, 576, 1), 0); del buf705  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1067, reinterpret_tensor(buf717, (128, 576, 576), (331776, 576, 1), 0), out=buf718)
    del permute_1067
    buf719 = reinterpret_tensor(buf701, (128, 576, 48), (27648, 48, 1), 0); del buf701  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf717, (128, 576, 576), (331776, 576, 1), 0), permute_1068, out=buf719)
    del permute_1068
    buf720 = buf677; del buf677  # reuse
    cpp_fused_clone_133(c_void_p(buf706.data_ptr()), c_void_p(buf718.data_ptr()), c_void_p(buf719.data_ptr()), c_void_p(buf720.data_ptr()))
    buf721 = reinterpret_tensor(buf719, (4608, 768), (768, 1), 0); del buf719  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf720, (4608, 2304), (2304, 1), 0), permute_1071, out=buf721)
    del permute_1071
    buf722 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf720, (2304, 4608), (1, 2304), 0), view_421, out=buf722)
    del view_421
    buf723 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf724 = buf696; del buf696  # reuse
    buf725 = buf695; del buf695  # reuse
    buf726 = empty((768, ), device='cpu', dtype=torch.float32)
    buf727 = empty((768, ), device='cpu', dtype=torch.float32)
    buf728 = buf699; del buf699  # reuse
    buf730 = reinterpret_tensor(buf718, (8, 576, 768), (442368, 768, 1), 0); del buf718  # reuse
    buf729 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_134(c_void_p(buf728.data_ptr()), c_void_p(buf720.data_ptr()), c_void_p(buf721.data_ptr()), c_void_p(primals_417.data_ptr()), c_void_p(mul_210.data_ptr()), c_void_p(div_70.data_ptr()), c_void_p(primals_43.data_ptr()), c_void_p(addmm_83.data_ptr()), c_void_p(buf723.data_ptr()), c_void_p(buf724.data_ptr()), c_void_p(buf725.data_ptr()), c_void_p(buf726.data_ptr()), c_void_p(buf727.data_ptr()), c_void_p(buf730.data_ptr()), c_void_p(buf729.data_ptr()))
    del addmm_83
    del div_70
    del mul_210
    del primals_417
    del primals_43
    buf731 = reinterpret_tensor(buf691, (4608, 3072), (3072, 1), 0); del buf691  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf730, (4608, 768), (768, 1), 0), permute_1075, out=buf731)
    del permute_1075
    buf732 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf730, (768, 4608), (1, 768), 0), view_419, out=buf732)
    del view_419
    buf733 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf734 = reinterpret_tensor(buf731, (8, 576, 3072), (1769472, 3072, 1), 0); del buf731  # reuse
    cpp_fused_gelu_gelu_backward_sum_135(c_void_p(buf734.data_ptr()), c_void_p(buf730.data_ptr()), c_void_p(addmm_82.data_ptr()), c_void_p(buf733.data_ptr()))
    del addmm_82
    buf735 = reinterpret_tensor(buf730, (4608, 768), (768, 1), 0); del buf730  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf734, (4608, 3072), (3072, 1), 0), permute_1079, out=buf735)
    del permute_1079
    buf736 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf734, (3072, 4608), (1, 3072), 0), view_417, out=buf736)
    del view_417
    buf737 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf738 = buf725; del buf725  # reuse
    buf739 = buf724; del buf724  # reuse
    buf740 = empty((768, ), device='cpu', dtype=torch.float32)
    buf741 = empty((768, ), device='cpu', dtype=torch.float32)
    buf742 = buf728; del buf728  # reuse
    buf744 = reinterpret_tensor(buf721, (8, 576, 768), (442368, 768, 1), 0); del buf721  # reuse
    buf743 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_136(c_void_p(buf742.data_ptr()), c_void_p(buf734.data_ptr()), c_void_p(buf735.data_ptr()), c_void_p(primals_411.data_ptr()), c_void_p(mul_204.data_ptr()), c_void_p(div_71.data_ptr()), c_void_p(primals_42.data_ptr()), c_void_p(addmm_81.data_ptr()), c_void_p(buf737.data_ptr()), c_void_p(buf738.data_ptr()), c_void_p(buf739.data_ptr()), c_void_p(buf740.data_ptr()), c_void_p(buf741.data_ptr()), c_void_p(buf744.data_ptr()), c_void_p(buf743.data_ptr()))
    del addmm_81
    del div_71
    del mul_204
    del primals_411
    del primals_42
    buf745 = buf735; del buf735  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf744, (4608, 768), (768, 1), 0), permute_1083, out=buf745)
    del permute_1083
    buf746 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf744, (768, 4608), (1, 768), 0), view_415, out=buf746)
    del view_415
    buf747 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf748 = reinterpret_tensor(buf706, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf706  # reuse
    cpp_fused_clone_sum_137(c_void_p(buf744.data_ptr()), c_void_p(buf745.data_ptr()), c_void_p(buf747.data_ptr()), c_void_p(buf748.data_ptr()))
    buf749 = reinterpret_tensor(buf745, (128, 576, 48), (27648, 48, 1), 0); del buf745  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1088, reinterpret_tensor(buf748, (128, 576, 48), (27648, 48, 1), 0), out=buf749)
    del permute_1088
    buf750 = reinterpret_tensor(buf717, (128, 576, 576), (331776, 576, 1), 0); del buf717  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf748, (128, 576, 48), (27648, 48, 1), 0), permute_1089, out=buf750)
    del permute_1089
    buf751 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf752 = buf716; del buf716  # reuse
    cpp_fused__unsafe_view_clone_sum_138(c_void_p(buf750.data_ptr()), c_void_p(buf751.data_ptr()), c_void_p(buf752.data_ptr()))
    buf753 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf752, (16, 2654208), (1, 16), 0), view_409, out=buf753)
    del view_409
    buf754 = reinterpret_tensor(buf750, (2654208, 16), (16, 1), 0); del buf750  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf752, permute_1093, out=buf754)
    del permute_1093
    buf755 = buf712; del buf712  # reuse
    buf756 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf757 = reinterpret_tensor(buf754, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf754  # reuse
    cpp_fused__softmax_backward_data_clone_sum_139(c_void_p(buf757.data_ptr()), c_void_p(alias_55.data_ptr()), c_void_p(buf755.data_ptr()), c_void_p(buf756.data_ptr()))
    del alias_55
    buf758 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf757, (16, 2654208), (1, 16), 0), view_407, out=buf758)
    del view_407
    buf759 = buf752; del buf752  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf757, (2654208, 16), (16, 1), 0), permute_1099, out=buf759)
    del permute_1099
    buf760 = reinterpret_tensor(buf757, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf757  # reuse
    cpp_fused_clone_140(c_void_p(buf759.data_ptr()), c_void_p(buf760.data_ptr()))
    buf761 = reinterpret_tensor(buf748, (128, 48, 576), (27648, 576, 1), 0); del buf748  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1102, reinterpret_tensor(buf760, (128, 576, 576), (331776, 576, 1), 0), out=buf761)
    del permute_1102
    buf762 = reinterpret_tensor(buf744, (128, 576, 48), (27648, 48, 1), 0); del buf744  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf760, (128, 576, 576), (331776, 576, 1), 0), permute_1103, out=buf762)
    del permute_1103
    buf763 = buf720; del buf720  # reuse
    cpp_fused_clone_141(c_void_p(buf749.data_ptr()), c_void_p(buf761.data_ptr()), c_void_p(buf762.data_ptr()), c_void_p(buf763.data_ptr()))
    buf764 = reinterpret_tensor(buf762, (4608, 768), (768, 1), 0); del buf762  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf763, (4608, 2304), (2304, 1), 0), permute_1106, out=buf764)
    del permute_1106
    buf765 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf763, (2304, 4608), (1, 2304), 0), view_401, out=buf765)
    del view_401
    buf766 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf767 = buf739; del buf739  # reuse
    buf768 = buf738; del buf738  # reuse
    buf769 = empty((768, ), device='cpu', dtype=torch.float32)
    buf770 = empty((768, ), device='cpu', dtype=torch.float32)
    buf771 = buf742; del buf742  # reuse
    buf773 = reinterpret_tensor(buf761, (8, 576, 768), (442368, 768, 1), 0); del buf761  # reuse
    buf772 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_142(c_void_p(buf771.data_ptr()), c_void_p(buf763.data_ptr()), c_void_p(buf764.data_ptr()), c_void_p(primals_401.data_ptr()), c_void_p(mul_200.data_ptr()), c_void_p(div_72.data_ptr()), c_void_p(primals_41.data_ptr()), c_void_p(addmm_79.data_ptr()), c_void_p(buf766.data_ptr()), c_void_p(buf767.data_ptr()), c_void_p(buf768.data_ptr()), c_void_p(buf769.data_ptr()), c_void_p(buf770.data_ptr()), c_void_p(buf773.data_ptr()), c_void_p(buf772.data_ptr()))
    del addmm_79
    del div_72
    del mul_200
    del primals_401
    del primals_41
    buf774 = reinterpret_tensor(buf734, (4608, 3072), (3072, 1), 0); del buf734  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf773, (4608, 768), (768, 1), 0), permute_1110, out=buf774)
    del permute_1110
    buf775 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf773, (768, 4608), (1, 768), 0), view_399, out=buf775)
    del view_399
    buf776 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf777 = reinterpret_tensor(buf774, (8, 576, 3072), (1769472, 3072, 1), 0); del buf774  # reuse
    cpp_fused_gelu_gelu_backward_sum_143(c_void_p(buf777.data_ptr()), c_void_p(buf773.data_ptr()), c_void_p(addmm_78.data_ptr()), c_void_p(buf776.data_ptr()))
    del addmm_78
    buf778 = reinterpret_tensor(buf773, (4608, 768), (768, 1), 0); del buf773  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf777, (4608, 3072), (3072, 1), 0), permute_1114, out=buf778)
    del permute_1114
    buf779 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf777, (3072, 4608), (1, 3072), 0), view_397, out=buf779)
    del view_397
    buf780 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf781 = buf768; del buf768  # reuse
    buf782 = buf767; del buf767  # reuse
    buf783 = empty((768, ), device='cpu', dtype=torch.float32)
    buf784 = empty((768, ), device='cpu', dtype=torch.float32)
    buf785 = buf771; del buf771  # reuse
    buf787 = reinterpret_tensor(buf764, (8, 576, 768), (442368, 768, 1), 0); del buf764  # reuse
    buf786 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_144(c_void_p(buf785.data_ptr()), c_void_p(buf777.data_ptr()), c_void_p(buf778.data_ptr()), c_void_p(primals_395.data_ptr()), c_void_p(mul_194.data_ptr()), c_void_p(div_73.data_ptr()), c_void_p(primals_40.data_ptr()), c_void_p(addmm_77.data_ptr()), c_void_p(buf780.data_ptr()), c_void_p(buf781.data_ptr()), c_void_p(buf782.data_ptr()), c_void_p(buf783.data_ptr()), c_void_p(buf784.data_ptr()), c_void_p(buf787.data_ptr()), c_void_p(buf786.data_ptr()))
    del addmm_77
    del div_73
    del mul_194
    del primals_395
    del primals_40
    buf788 = buf778; del buf778  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf787, (4608, 768), (768, 1), 0), permute_1118, out=buf788)
    del permute_1118
    buf789 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf787, (768, 4608), (1, 768), 0), view_395, out=buf789)
    del view_395
    buf790 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf791 = reinterpret_tensor(buf749, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf749  # reuse
    cpp_fused_clone_sum_145(c_void_p(buf787.data_ptr()), c_void_p(buf788.data_ptr()), c_void_p(buf790.data_ptr()), c_void_p(buf791.data_ptr()))
    buf792 = reinterpret_tensor(buf788, (128, 576, 48), (27648, 48, 1), 0); del buf788  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1123, reinterpret_tensor(buf791, (128, 576, 48), (27648, 48, 1), 0), out=buf792)
    del permute_1123
    buf793 = reinterpret_tensor(buf760, (128, 576, 576), (331776, 576, 1), 0); del buf760  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf791, (128, 576, 48), (27648, 48, 1), 0), permute_1124, out=buf793)
    del permute_1124
    buf794 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf795 = buf759; del buf759  # reuse
    cpp_fused__unsafe_view_clone_sum_146(c_void_p(buf793.data_ptr()), c_void_p(buf794.data_ptr()), c_void_p(buf795.data_ptr()))
    buf796 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf795, (16, 2654208), (1, 16), 0), view_389, out=buf796)
    del view_389
    buf797 = reinterpret_tensor(buf793, (2654208, 16), (16, 1), 0); del buf793  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf795, permute_1128, out=buf797)
    del permute_1128
    buf798 = buf755; del buf755  # reuse
    buf799 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf800 = reinterpret_tensor(buf797, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf797  # reuse
    cpp_fused__softmax_backward_data_clone_sum_147(c_void_p(buf800.data_ptr()), c_void_p(alias_56.data_ptr()), c_void_p(buf798.data_ptr()), c_void_p(buf799.data_ptr()))
    del alias_56
    buf801 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf800, (16, 2654208), (1, 16), 0), view_387, out=buf801)
    del view_387
    buf802 = buf795; del buf795  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf800, (2654208, 16), (16, 1), 0), permute_1134, out=buf802)
    del permute_1134
    buf803 = reinterpret_tensor(buf800, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf800  # reuse
    cpp_fused_clone_148(c_void_p(buf802.data_ptr()), c_void_p(buf803.data_ptr()))
    buf804 = reinterpret_tensor(buf791, (128, 48, 576), (27648, 576, 1), 0); del buf791  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1137, reinterpret_tensor(buf803, (128, 576, 576), (331776, 576, 1), 0), out=buf804)
    del permute_1137
    buf805 = reinterpret_tensor(buf787, (128, 576, 48), (27648, 48, 1), 0); del buf787  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf803, (128, 576, 576), (331776, 576, 1), 0), permute_1138, out=buf805)
    del permute_1138
    buf806 = buf763; del buf763  # reuse
    cpp_fused_clone_149(c_void_p(buf792.data_ptr()), c_void_p(buf804.data_ptr()), c_void_p(buf805.data_ptr()), c_void_p(buf806.data_ptr()))
    buf807 = reinterpret_tensor(buf805, (4608, 768), (768, 1), 0); del buf805  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf806, (4608, 2304), (2304, 1), 0), permute_1141, out=buf807)
    del permute_1141
    buf808 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf806, (2304, 4608), (1, 2304), 0), view_381, out=buf808)
    del view_381
    buf809 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf810 = buf782; del buf782  # reuse
    buf811 = buf781; del buf781  # reuse
    buf812 = empty((768, ), device='cpu', dtype=torch.float32)
    buf813 = empty((768, ), device='cpu', dtype=torch.float32)
    buf814 = buf785; del buf785  # reuse
    buf816 = reinterpret_tensor(buf804, (8, 576, 768), (442368, 768, 1), 0); del buf804  # reuse
    buf815 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_150(c_void_p(buf814.data_ptr()), c_void_p(buf806.data_ptr()), c_void_p(buf807.data_ptr()), c_void_p(primals_385.data_ptr()), c_void_p(mul_190.data_ptr()), c_void_p(div_74.data_ptr()), c_void_p(primals_39.data_ptr()), c_void_p(addmm_75.data_ptr()), c_void_p(buf809.data_ptr()), c_void_p(buf810.data_ptr()), c_void_p(buf811.data_ptr()), c_void_p(buf812.data_ptr()), c_void_p(buf813.data_ptr()), c_void_p(buf816.data_ptr()), c_void_p(buf815.data_ptr()))
    del addmm_75
    del div_74
    del mul_190
    del primals_385
    del primals_39
    buf817 = reinterpret_tensor(buf777, (4608, 3072), (3072, 1), 0); del buf777  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf816, (4608, 768), (768, 1), 0), permute_1145, out=buf817)
    del permute_1145
    buf818 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf816, (768, 4608), (1, 768), 0), view_379, out=buf818)
    del view_379
    buf819 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf820 = reinterpret_tensor(buf817, (8, 576, 3072), (1769472, 3072, 1), 0); del buf817  # reuse
    cpp_fused_gelu_gelu_backward_sum_151(c_void_p(buf820.data_ptr()), c_void_p(buf816.data_ptr()), c_void_p(addmm_74.data_ptr()), c_void_p(buf819.data_ptr()))
    del addmm_74
    buf821 = reinterpret_tensor(buf816, (4608, 768), (768, 1), 0); del buf816  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf820, (4608, 3072), (3072, 1), 0), permute_1149, out=buf821)
    del permute_1149
    buf822 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf820, (3072, 4608), (1, 3072), 0), view_377, out=buf822)
    del view_377
    buf823 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf824 = buf811; del buf811  # reuse
    buf825 = buf810; del buf810  # reuse
    buf826 = empty((768, ), device='cpu', dtype=torch.float32)
    buf827 = empty((768, ), device='cpu', dtype=torch.float32)
    buf828 = buf814; del buf814  # reuse
    buf830 = reinterpret_tensor(buf807, (8, 576, 768), (442368, 768, 1), 0); del buf807  # reuse
    buf829 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_152(c_void_p(buf828.data_ptr()), c_void_p(buf820.data_ptr()), c_void_p(buf821.data_ptr()), c_void_p(primals_379.data_ptr()), c_void_p(mul_184.data_ptr()), c_void_p(div_75.data_ptr()), c_void_p(primals_38.data_ptr()), c_void_p(addmm_73.data_ptr()), c_void_p(buf823.data_ptr()), c_void_p(buf824.data_ptr()), c_void_p(buf825.data_ptr()), c_void_p(buf826.data_ptr()), c_void_p(buf827.data_ptr()), c_void_p(buf830.data_ptr()), c_void_p(buf829.data_ptr()))
    del addmm_73
    del div_75
    del mul_184
    del primals_379
    del primals_38
    buf831 = buf821; del buf821  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf830, (4608, 768), (768, 1), 0), permute_1153, out=buf831)
    del permute_1153
    buf832 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf830, (768, 4608), (1, 768), 0), view_375, out=buf832)
    del view_375
    buf833 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf834 = reinterpret_tensor(buf792, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf792  # reuse
    cpp_fused_clone_sum_153(c_void_p(buf830.data_ptr()), c_void_p(buf831.data_ptr()), c_void_p(buf833.data_ptr()), c_void_p(buf834.data_ptr()))
    buf835 = reinterpret_tensor(buf831, (128, 576, 48), (27648, 48, 1), 0); del buf831  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1158, reinterpret_tensor(buf834, (128, 576, 48), (27648, 48, 1), 0), out=buf835)
    del permute_1158
    buf836 = reinterpret_tensor(buf803, (128, 576, 576), (331776, 576, 1), 0); del buf803  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf834, (128, 576, 48), (27648, 48, 1), 0), permute_1159, out=buf836)
    del permute_1159
    buf837 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf838 = buf802; del buf802  # reuse
    cpp_fused__unsafe_view_clone_sum_154(c_void_p(buf836.data_ptr()), c_void_p(buf837.data_ptr()), c_void_p(buf838.data_ptr()))
    buf839 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf838, (16, 2654208), (1, 16), 0), view_369, out=buf839)
    del view_369
    buf840 = reinterpret_tensor(buf836, (2654208, 16), (16, 1), 0); del buf836  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf838, permute_1163, out=buf840)
    del permute_1163
    buf841 = buf798; del buf798  # reuse
    buf842 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf843 = reinterpret_tensor(buf840, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf840  # reuse
    cpp_fused__softmax_backward_data_clone_sum_155(c_void_p(buf843.data_ptr()), c_void_p(alias_57.data_ptr()), c_void_p(buf841.data_ptr()), c_void_p(buf842.data_ptr()))
    del alias_57
    buf844 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf843, (16, 2654208), (1, 16), 0), view_367, out=buf844)
    del view_367
    buf845 = buf838; del buf838  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf843, (2654208, 16), (16, 1), 0), permute_1169, out=buf845)
    del permute_1169
    buf846 = reinterpret_tensor(buf843, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf843  # reuse
    cpp_fused_clone_156(c_void_p(buf845.data_ptr()), c_void_p(buf846.data_ptr()))
    buf847 = reinterpret_tensor(buf834, (128, 48, 576), (27648, 576, 1), 0); del buf834  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1172, reinterpret_tensor(buf846, (128, 576, 576), (331776, 576, 1), 0), out=buf847)
    del permute_1172
    buf848 = reinterpret_tensor(buf830, (128, 576, 48), (27648, 48, 1), 0); del buf830  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf846, (128, 576, 576), (331776, 576, 1), 0), permute_1173, out=buf848)
    del permute_1173
    buf849 = buf806; del buf806  # reuse
    cpp_fused_clone_157(c_void_p(buf835.data_ptr()), c_void_p(buf847.data_ptr()), c_void_p(buf848.data_ptr()), c_void_p(buf849.data_ptr()))
    buf850 = reinterpret_tensor(buf848, (4608, 768), (768, 1), 0); del buf848  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf849, (4608, 2304), (2304, 1), 0), permute_1176, out=buf850)
    del permute_1176
    buf851 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf849, (2304, 4608), (1, 2304), 0), view_361, out=buf851)
    del view_361
    buf852 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf853 = buf825; del buf825  # reuse
    buf854 = buf824; del buf824  # reuse
    buf855 = empty((768, ), device='cpu', dtype=torch.float32)
    buf856 = empty((768, ), device='cpu', dtype=torch.float32)
    buf857 = buf828; del buf828  # reuse
    buf859 = reinterpret_tensor(buf847, (8, 576, 768), (442368, 768, 1), 0); del buf847  # reuse
    buf858 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_158(c_void_p(buf857.data_ptr()), c_void_p(buf849.data_ptr()), c_void_p(buf850.data_ptr()), c_void_p(primals_369.data_ptr()), c_void_p(mul_180.data_ptr()), c_void_p(div_76.data_ptr()), c_void_p(primals_37.data_ptr()), c_void_p(addmm_71.data_ptr()), c_void_p(buf852.data_ptr()), c_void_p(buf853.data_ptr()), c_void_p(buf854.data_ptr()), c_void_p(buf855.data_ptr()), c_void_p(buf856.data_ptr()), c_void_p(buf859.data_ptr()), c_void_p(buf858.data_ptr()))
    del addmm_71
    del div_76
    del mul_180
    del primals_369
    del primals_37
    buf860 = reinterpret_tensor(buf820, (4608, 3072), (3072, 1), 0); del buf820  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf859, (4608, 768), (768, 1), 0), permute_1180, out=buf860)
    del permute_1180
    buf861 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf859, (768, 4608), (1, 768), 0), view_359, out=buf861)
    del view_359
    buf862 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf863 = reinterpret_tensor(buf860, (8, 576, 3072), (1769472, 3072, 1), 0); del buf860  # reuse
    cpp_fused_gelu_gelu_backward_sum_159(c_void_p(buf863.data_ptr()), c_void_p(buf859.data_ptr()), c_void_p(addmm_70.data_ptr()), c_void_p(buf862.data_ptr()))
    del addmm_70
    buf864 = reinterpret_tensor(buf859, (4608, 768), (768, 1), 0); del buf859  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf863, (4608, 3072), (3072, 1), 0), permute_1184, out=buf864)
    del permute_1184
    buf865 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf863, (3072, 4608), (1, 3072), 0), view_357, out=buf865)
    del view_357
    buf866 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf867 = buf854; del buf854  # reuse
    buf868 = buf853; del buf853  # reuse
    buf869 = empty((768, ), device='cpu', dtype=torch.float32)
    buf870 = empty((768, ), device='cpu', dtype=torch.float32)
    buf871 = buf857; del buf857  # reuse
    buf873 = reinterpret_tensor(buf850, (8, 576, 768), (442368, 768, 1), 0); del buf850  # reuse
    buf872 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_160(c_void_p(buf871.data_ptr()), c_void_p(buf863.data_ptr()), c_void_p(buf864.data_ptr()), c_void_p(primals_363.data_ptr()), c_void_p(mul_174.data_ptr()), c_void_p(div_77.data_ptr()), c_void_p(primals_36.data_ptr()), c_void_p(addmm_69.data_ptr()), c_void_p(buf866.data_ptr()), c_void_p(buf867.data_ptr()), c_void_p(buf868.data_ptr()), c_void_p(buf869.data_ptr()), c_void_p(buf870.data_ptr()), c_void_p(buf873.data_ptr()), c_void_p(buf872.data_ptr()))
    del addmm_69
    del div_77
    del mul_174
    del primals_36
    del primals_363
    buf874 = buf864; del buf864  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf873, (4608, 768), (768, 1), 0), permute_1188, out=buf874)
    del permute_1188
    buf875 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf873, (768, 4608), (1, 768), 0), view_355, out=buf875)
    del view_355
    buf876 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf877 = reinterpret_tensor(buf835, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf835  # reuse
    cpp_fused_clone_sum_161(c_void_p(buf873.data_ptr()), c_void_p(buf874.data_ptr()), c_void_p(buf876.data_ptr()), c_void_p(buf877.data_ptr()))
    buf878 = reinterpret_tensor(buf874, (128, 576, 48), (27648, 48, 1), 0); del buf874  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1193, reinterpret_tensor(buf877, (128, 576, 48), (27648, 48, 1), 0), out=buf878)
    del permute_1193
    buf879 = reinterpret_tensor(buf846, (128, 576, 576), (331776, 576, 1), 0); del buf846  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf877, (128, 576, 48), (27648, 48, 1), 0), permute_1194, out=buf879)
    del permute_1194
    buf880 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf881 = buf845; del buf845  # reuse
    cpp_fused__unsafe_view_clone_sum_162(c_void_p(buf879.data_ptr()), c_void_p(buf880.data_ptr()), c_void_p(buf881.data_ptr()))
    buf882 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf881, (16, 2654208), (1, 16), 0), view_349, out=buf882)
    del view_349
    buf883 = reinterpret_tensor(buf879, (2654208, 16), (16, 1), 0); del buf879  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf881, permute_1198, out=buf883)
    del permute_1198
    buf884 = buf841; del buf841  # reuse
    buf885 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf886 = reinterpret_tensor(buf883, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf883  # reuse
    cpp_fused__softmax_backward_data_clone_sum_163(c_void_p(buf886.data_ptr()), c_void_p(alias_58.data_ptr()), c_void_p(buf884.data_ptr()), c_void_p(buf885.data_ptr()))
    del alias_58
    buf887 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf886, (16, 2654208), (1, 16), 0), view_347, out=buf887)
    del view_347
    buf888 = buf881; del buf881  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf886, (2654208, 16), (16, 1), 0), permute_1204, out=buf888)
    del permute_1204
    buf889 = reinterpret_tensor(buf886, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf886  # reuse
    cpp_fused_clone_164(c_void_p(buf888.data_ptr()), c_void_p(buf889.data_ptr()))
    buf890 = reinterpret_tensor(buf877, (128, 48, 576), (27648, 576, 1), 0); del buf877  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1207, reinterpret_tensor(buf889, (128, 576, 576), (331776, 576, 1), 0), out=buf890)
    del permute_1207
    buf891 = reinterpret_tensor(buf873, (128, 576, 48), (27648, 48, 1), 0); del buf873  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf889, (128, 576, 576), (331776, 576, 1), 0), permute_1208, out=buf891)
    del permute_1208
    buf892 = buf849; del buf849  # reuse
    cpp_fused_clone_165(c_void_p(buf878.data_ptr()), c_void_p(buf890.data_ptr()), c_void_p(buf891.data_ptr()), c_void_p(buf892.data_ptr()))
    buf893 = reinterpret_tensor(buf891, (4608, 768), (768, 1), 0); del buf891  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf892, (4608, 2304), (2304, 1), 0), permute_1211, out=buf893)
    del permute_1211
    buf894 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf892, (2304, 4608), (1, 2304), 0), view_341, out=buf894)
    del view_341
    buf895 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf896 = buf868; del buf868  # reuse
    buf897 = buf867; del buf867  # reuse
    buf898 = empty((768, ), device='cpu', dtype=torch.float32)
    buf899 = empty((768, ), device='cpu', dtype=torch.float32)
    buf900 = buf871; del buf871  # reuse
    buf902 = reinterpret_tensor(buf890, (8, 576, 768), (442368, 768, 1), 0); del buf890  # reuse
    buf901 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_166(c_void_p(buf900.data_ptr()), c_void_p(buf892.data_ptr()), c_void_p(buf893.data_ptr()), c_void_p(primals_353.data_ptr()), c_void_p(mul_170.data_ptr()), c_void_p(div_78.data_ptr()), c_void_p(primals_35.data_ptr()), c_void_p(addmm_67.data_ptr()), c_void_p(buf895.data_ptr()), c_void_p(buf896.data_ptr()), c_void_p(buf897.data_ptr()), c_void_p(buf898.data_ptr()), c_void_p(buf899.data_ptr()), c_void_p(buf902.data_ptr()), c_void_p(buf901.data_ptr()))
    del addmm_67
    del div_78
    del mul_170
    del primals_35
    del primals_353
    buf903 = reinterpret_tensor(buf863, (4608, 3072), (3072, 1), 0); del buf863  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf902, (4608, 768), (768, 1), 0), permute_1215, out=buf903)
    del permute_1215
    buf904 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf902, (768, 4608), (1, 768), 0), view_339, out=buf904)
    del view_339
    buf905 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf906 = reinterpret_tensor(buf903, (8, 576, 3072), (1769472, 3072, 1), 0); del buf903  # reuse
    cpp_fused_gelu_gelu_backward_sum_167(c_void_p(buf906.data_ptr()), c_void_p(buf902.data_ptr()), c_void_p(addmm_66.data_ptr()), c_void_p(buf905.data_ptr()))
    del addmm_66
    buf907 = reinterpret_tensor(buf902, (4608, 768), (768, 1), 0); del buf902  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf906, (4608, 3072), (3072, 1), 0), permute_1219, out=buf907)
    del permute_1219
    buf908 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf906, (3072, 4608), (1, 3072), 0), view_337, out=buf908)
    del view_337
    buf909 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf910 = buf897; del buf897  # reuse
    buf911 = buf896; del buf896  # reuse
    buf912 = empty((768, ), device='cpu', dtype=torch.float32)
    buf913 = empty((768, ), device='cpu', dtype=torch.float32)
    buf914 = buf900; del buf900  # reuse
    buf916 = reinterpret_tensor(buf893, (8, 576, 768), (442368, 768, 1), 0); del buf893  # reuse
    buf915 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_168(c_void_p(buf914.data_ptr()), c_void_p(buf906.data_ptr()), c_void_p(buf907.data_ptr()), c_void_p(primals_347.data_ptr()), c_void_p(mul_164.data_ptr()), c_void_p(div_79.data_ptr()), c_void_p(primals_34.data_ptr()), c_void_p(addmm_65.data_ptr()), c_void_p(buf909.data_ptr()), c_void_p(buf910.data_ptr()), c_void_p(buf911.data_ptr()), c_void_p(buf912.data_ptr()), c_void_p(buf913.data_ptr()), c_void_p(buf916.data_ptr()), c_void_p(buf915.data_ptr()))
    del addmm_65
    del div_79
    del mul_164
    del primals_34
    del primals_347
    buf917 = buf907; del buf907  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf916, (4608, 768), (768, 1), 0), permute_1223, out=buf917)
    del permute_1223
    buf918 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf916, (768, 4608), (1, 768), 0), view_335, out=buf918)
    del view_335
    buf919 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf920 = reinterpret_tensor(buf878, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf878  # reuse
    cpp_fused_clone_sum_169(c_void_p(buf916.data_ptr()), c_void_p(buf917.data_ptr()), c_void_p(buf919.data_ptr()), c_void_p(buf920.data_ptr()))
    buf921 = reinterpret_tensor(buf917, (128, 576, 48), (27648, 48, 1), 0); del buf917  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1228, reinterpret_tensor(buf920, (128, 576, 48), (27648, 48, 1), 0), out=buf921)
    del permute_1228
    buf922 = reinterpret_tensor(buf889, (128, 576, 576), (331776, 576, 1), 0); del buf889  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf920, (128, 576, 48), (27648, 48, 1), 0), permute_1229, out=buf922)
    del permute_1229
    buf923 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf924 = buf888; del buf888  # reuse
    cpp_fused__unsafe_view_clone_sum_170(c_void_p(buf922.data_ptr()), c_void_p(buf923.data_ptr()), c_void_p(buf924.data_ptr()))
    buf925 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf924, (16, 2654208), (1, 16), 0), view_329, out=buf925)
    del view_329
    buf926 = reinterpret_tensor(buf922, (2654208, 16), (16, 1), 0); del buf922  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf924, permute_1233, out=buf926)
    del permute_1233
    buf927 = buf884; del buf884  # reuse
    buf928 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf929 = reinterpret_tensor(buf926, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf926  # reuse
    cpp_fused__softmax_backward_data_clone_sum_171(c_void_p(buf929.data_ptr()), c_void_p(alias_59.data_ptr()), c_void_p(buf927.data_ptr()), c_void_p(buf928.data_ptr()))
    del alias_59
    buf930 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf929, (16, 2654208), (1, 16), 0), view_327, out=buf930)
    del view_327
    buf931 = buf924; del buf924  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf929, (2654208, 16), (16, 1), 0), permute_1239, out=buf931)
    del permute_1239
    buf932 = reinterpret_tensor(buf929, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf929  # reuse
    cpp_fused_clone_172(c_void_p(buf931.data_ptr()), c_void_p(buf932.data_ptr()))
    buf933 = reinterpret_tensor(buf920, (128, 48, 576), (27648, 576, 1), 0); del buf920  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1242, reinterpret_tensor(buf932, (128, 576, 576), (331776, 576, 1), 0), out=buf933)
    del permute_1242
    buf934 = reinterpret_tensor(buf916, (128, 576, 48), (27648, 48, 1), 0); del buf916  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf932, (128, 576, 576), (331776, 576, 1), 0), permute_1243, out=buf934)
    del permute_1243
    buf935 = buf892; del buf892  # reuse
    cpp_fused_clone_173(c_void_p(buf921.data_ptr()), c_void_p(buf933.data_ptr()), c_void_p(buf934.data_ptr()), c_void_p(buf935.data_ptr()))
    buf936 = reinterpret_tensor(buf934, (4608, 768), (768, 1), 0); del buf934  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf935, (4608, 2304), (2304, 1), 0), permute_1246, out=buf936)
    del permute_1246
    buf937 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf935, (2304, 4608), (1, 2304), 0), view_321, out=buf937)
    del view_321
    buf938 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf939 = buf911; del buf911  # reuse
    buf940 = buf910; del buf910  # reuse
    buf941 = empty((768, ), device='cpu', dtype=torch.float32)
    buf942 = empty((768, ), device='cpu', dtype=torch.float32)
    buf943 = buf914; del buf914  # reuse
    buf945 = reinterpret_tensor(buf933, (8, 576, 768), (442368, 768, 1), 0); del buf933  # reuse
    buf944 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_174(c_void_p(buf943.data_ptr()), c_void_p(buf935.data_ptr()), c_void_p(buf936.data_ptr()), c_void_p(primals_337.data_ptr()), c_void_p(mul_160.data_ptr()), c_void_p(div_80.data_ptr()), c_void_p(primals_33.data_ptr()), c_void_p(addmm_63.data_ptr()), c_void_p(buf938.data_ptr()), c_void_p(buf939.data_ptr()), c_void_p(buf940.data_ptr()), c_void_p(buf941.data_ptr()), c_void_p(buf942.data_ptr()), c_void_p(buf945.data_ptr()), c_void_p(buf944.data_ptr()))
    del addmm_63
    del div_80
    del mul_160
    del primals_33
    del primals_337
    buf946 = reinterpret_tensor(buf906, (4608, 3072), (3072, 1), 0); del buf906  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf945, (4608, 768), (768, 1), 0), permute_1250, out=buf946)
    del permute_1250
    buf947 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf945, (768, 4608), (1, 768), 0), view_319, out=buf947)
    del view_319
    buf948 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf949 = reinterpret_tensor(buf946, (8, 576, 3072), (1769472, 3072, 1), 0); del buf946  # reuse
    cpp_fused_gelu_gelu_backward_sum_175(c_void_p(buf949.data_ptr()), c_void_p(buf945.data_ptr()), c_void_p(addmm_62.data_ptr()), c_void_p(buf948.data_ptr()))
    del addmm_62
    buf950 = reinterpret_tensor(buf945, (4608, 768), (768, 1), 0); del buf945  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf949, (4608, 3072), (3072, 1), 0), permute_1254, out=buf950)
    del permute_1254
    buf951 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf949, (3072, 4608), (1, 3072), 0), view_317, out=buf951)
    del view_317
    buf952 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf953 = buf940; del buf940  # reuse
    buf954 = buf939; del buf939  # reuse
    buf955 = empty((768, ), device='cpu', dtype=torch.float32)
    buf956 = empty((768, ), device='cpu', dtype=torch.float32)
    buf957 = buf943; del buf943  # reuse
    buf959 = reinterpret_tensor(buf936, (8, 576, 768), (442368, 768, 1), 0); del buf936  # reuse
    buf958 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_176(c_void_p(buf957.data_ptr()), c_void_p(buf949.data_ptr()), c_void_p(buf950.data_ptr()), c_void_p(primals_331.data_ptr()), c_void_p(mul_154.data_ptr()), c_void_p(div_81.data_ptr()), c_void_p(primals_32.data_ptr()), c_void_p(addmm_61.data_ptr()), c_void_p(buf952.data_ptr()), c_void_p(buf953.data_ptr()), c_void_p(buf954.data_ptr()), c_void_p(buf955.data_ptr()), c_void_p(buf956.data_ptr()), c_void_p(buf959.data_ptr()), c_void_p(buf958.data_ptr()))
    del addmm_61
    del div_81
    del mul_154
    del primals_32
    del primals_331
    buf960 = buf950; del buf950  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf959, (4608, 768), (768, 1), 0), permute_1258, out=buf960)
    del permute_1258
    buf961 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf959, (768, 4608), (1, 768), 0), view_315, out=buf961)
    del view_315
    buf962 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf963 = reinterpret_tensor(buf921, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf921  # reuse
    cpp_fused_clone_sum_177(c_void_p(buf959.data_ptr()), c_void_p(buf960.data_ptr()), c_void_p(buf962.data_ptr()), c_void_p(buf963.data_ptr()))
    buf964 = reinterpret_tensor(buf960, (128, 576, 48), (27648, 48, 1), 0); del buf960  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1263, reinterpret_tensor(buf963, (128, 576, 48), (27648, 48, 1), 0), out=buf964)
    del permute_1263
    buf965 = reinterpret_tensor(buf932, (128, 576, 576), (331776, 576, 1), 0); del buf932  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf963, (128, 576, 48), (27648, 48, 1), 0), permute_1264, out=buf965)
    del permute_1264
    buf966 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf967 = buf931; del buf931  # reuse
    cpp_fused__unsafe_view_clone_sum_178(c_void_p(buf965.data_ptr()), c_void_p(buf966.data_ptr()), c_void_p(buf967.data_ptr()))
    buf968 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf967, (16, 2654208), (1, 16), 0), view_309, out=buf968)
    del view_309
    buf969 = reinterpret_tensor(buf965, (2654208, 16), (16, 1), 0); del buf965  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf967, permute_1268, out=buf969)
    del permute_1268
    buf970 = buf927; del buf927  # reuse
    buf971 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf972 = reinterpret_tensor(buf969, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf969  # reuse
    cpp_fused__softmax_backward_data_clone_sum_179(c_void_p(buf972.data_ptr()), c_void_p(alias_60.data_ptr()), c_void_p(buf970.data_ptr()), c_void_p(buf971.data_ptr()))
    del alias_60
    buf973 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf972, (16, 2654208), (1, 16), 0), view_307, out=buf973)
    del view_307
    buf974 = buf967; del buf967  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf972, (2654208, 16), (16, 1), 0), permute_1274, out=buf974)
    del permute_1274
    buf975 = reinterpret_tensor(buf972, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf972  # reuse
    cpp_fused_clone_180(c_void_p(buf974.data_ptr()), c_void_p(buf975.data_ptr()))
    buf976 = reinterpret_tensor(buf963, (128, 48, 576), (27648, 576, 1), 0); del buf963  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1277, reinterpret_tensor(buf975, (128, 576, 576), (331776, 576, 1), 0), out=buf976)
    del permute_1277
    buf977 = reinterpret_tensor(buf959, (128, 576, 48), (27648, 48, 1), 0); del buf959  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf975, (128, 576, 576), (331776, 576, 1), 0), permute_1278, out=buf977)
    del permute_1278
    buf978 = buf935; del buf935  # reuse
    cpp_fused_clone_181(c_void_p(buf964.data_ptr()), c_void_p(buf976.data_ptr()), c_void_p(buf977.data_ptr()), c_void_p(buf978.data_ptr()))
    buf979 = reinterpret_tensor(buf977, (4608, 768), (768, 1), 0); del buf977  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf978, (4608, 2304), (2304, 1), 0), permute_1281, out=buf979)
    del permute_1281
    buf980 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf978, (2304, 4608), (1, 2304), 0), view_301, out=buf980)
    del view_301
    buf981 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf982 = buf954; del buf954  # reuse
    buf983 = buf953; del buf953  # reuse
    buf984 = empty((768, ), device='cpu', dtype=torch.float32)
    buf985 = empty((768, ), device='cpu', dtype=torch.float32)
    buf986 = buf957; del buf957  # reuse
    buf988 = reinterpret_tensor(buf976, (8, 576, 768), (442368, 768, 1), 0); del buf976  # reuse
    buf987 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_182(c_void_p(buf986.data_ptr()), c_void_p(buf978.data_ptr()), c_void_p(buf979.data_ptr()), c_void_p(primals_321.data_ptr()), c_void_p(mul_150.data_ptr()), c_void_p(div_82.data_ptr()), c_void_p(primals_31.data_ptr()), c_void_p(addmm_59.data_ptr()), c_void_p(buf981.data_ptr()), c_void_p(buf982.data_ptr()), c_void_p(buf983.data_ptr()), c_void_p(buf984.data_ptr()), c_void_p(buf985.data_ptr()), c_void_p(buf988.data_ptr()), c_void_p(buf987.data_ptr()))
    del addmm_59
    del div_82
    del mul_150
    del primals_31
    del primals_321
    buf989 = reinterpret_tensor(buf949, (4608, 3072), (3072, 1), 0); del buf949  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf988, (4608, 768), (768, 1), 0), permute_1285, out=buf989)
    del permute_1285
    buf990 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf988, (768, 4608), (1, 768), 0), view_299, out=buf990)
    del view_299
    buf991 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf992 = reinterpret_tensor(buf989, (8, 576, 3072), (1769472, 3072, 1), 0); del buf989  # reuse
    cpp_fused_gelu_gelu_backward_sum_183(c_void_p(buf992.data_ptr()), c_void_p(buf988.data_ptr()), c_void_p(addmm_58.data_ptr()), c_void_p(buf991.data_ptr()))
    del addmm_58
    buf993 = reinterpret_tensor(buf988, (4608, 768), (768, 1), 0); del buf988  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf992, (4608, 3072), (3072, 1), 0), permute_1289, out=buf993)
    del permute_1289
    buf994 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf992, (3072, 4608), (1, 3072), 0), view_297, out=buf994)
    del view_297
    buf995 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf996 = buf983; del buf983  # reuse
    buf997 = buf982; del buf982  # reuse
    buf998 = empty((768, ), device='cpu', dtype=torch.float32)
    buf999 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1000 = buf986; del buf986  # reuse
    buf1002 = reinterpret_tensor(buf979, (8, 576, 768), (442368, 768, 1), 0); del buf979  # reuse
    buf1001 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_184(c_void_p(buf1000.data_ptr()), c_void_p(buf992.data_ptr()), c_void_p(buf993.data_ptr()), c_void_p(primals_315.data_ptr()), c_void_p(mul_144.data_ptr()), c_void_p(div_83.data_ptr()), c_void_p(primals_30.data_ptr()), c_void_p(addmm_57.data_ptr()), c_void_p(buf995.data_ptr()), c_void_p(buf996.data_ptr()), c_void_p(buf997.data_ptr()), c_void_p(buf998.data_ptr()), c_void_p(buf999.data_ptr()), c_void_p(buf1002.data_ptr()), c_void_p(buf1001.data_ptr()))
    del addmm_57
    del div_83
    del mul_144
    del primals_30
    del primals_315
    buf1003 = buf993; del buf993  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1002, (4608, 768), (768, 1), 0), permute_1293, out=buf1003)
    del permute_1293
    buf1004 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1002, (768, 4608), (1, 768), 0), view_295, out=buf1004)
    del view_295
    buf1005 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1006 = reinterpret_tensor(buf964, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf964  # reuse
    cpp_fused_clone_sum_185(c_void_p(buf1002.data_ptr()), c_void_p(buf1003.data_ptr()), c_void_p(buf1005.data_ptr()), c_void_p(buf1006.data_ptr()))
    buf1007 = reinterpret_tensor(buf1003, (128, 576, 48), (27648, 48, 1), 0); del buf1003  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1298, reinterpret_tensor(buf1006, (128, 576, 48), (27648, 48, 1), 0), out=buf1007)
    del permute_1298
    buf1008 = reinterpret_tensor(buf975, (128, 576, 576), (331776, 576, 1), 0); del buf975  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1006, (128, 576, 48), (27648, 48, 1), 0), permute_1299, out=buf1008)
    del permute_1299
    buf1009 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1010 = buf974; del buf974  # reuse
    cpp_fused__unsafe_view_clone_sum_186(c_void_p(buf1008.data_ptr()), c_void_p(buf1009.data_ptr()), c_void_p(buf1010.data_ptr()))
    buf1011 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1010, (16, 2654208), (1, 16), 0), view_289, out=buf1011)
    del view_289
    buf1012 = reinterpret_tensor(buf1008, (2654208, 16), (16, 1), 0); del buf1008  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf1010, permute_1303, out=buf1012)
    del permute_1303
    buf1013 = buf970; del buf970  # reuse
    buf1014 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1015 = reinterpret_tensor(buf1012, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf1012  # reuse
    cpp_fused__softmax_backward_data_clone_sum_187(c_void_p(buf1015.data_ptr()), c_void_p(alias_61.data_ptr()), c_void_p(buf1013.data_ptr()), c_void_p(buf1014.data_ptr()))
    del alias_61
    buf1016 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1015, (16, 2654208), (1, 16), 0), view_287, out=buf1016)
    del view_287
    buf1017 = buf1010; del buf1010  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1015, (2654208, 16), (16, 1), 0), permute_1309, out=buf1017)
    del permute_1309
    buf1018 = reinterpret_tensor(buf1015, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf1015  # reuse
    cpp_fused_clone_188(c_void_p(buf1017.data_ptr()), c_void_p(buf1018.data_ptr()))
    buf1019 = reinterpret_tensor(buf1006, (128, 48, 576), (27648, 576, 1), 0); del buf1006  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1312, reinterpret_tensor(buf1018, (128, 576, 576), (331776, 576, 1), 0), out=buf1019)
    del permute_1312
    buf1020 = reinterpret_tensor(buf1002, (128, 576, 48), (27648, 48, 1), 0); del buf1002  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1018, (128, 576, 576), (331776, 576, 1), 0), permute_1313, out=buf1020)
    del permute_1313
    buf1021 = buf978; del buf978  # reuse
    cpp_fused_clone_189(c_void_p(buf1007.data_ptr()), c_void_p(buf1019.data_ptr()), c_void_p(buf1020.data_ptr()), c_void_p(buf1021.data_ptr()))
    buf1022 = reinterpret_tensor(buf1020, (4608, 768), (768, 1), 0); del buf1020  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1021, (4608, 2304), (2304, 1), 0), permute_1316, out=buf1022)
    del permute_1316
    buf1023 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1021, (2304, 4608), (1, 2304), 0), view_281, out=buf1023)
    del view_281
    buf1024 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf1025 = buf997; del buf997  # reuse
    buf1026 = buf996; del buf996  # reuse
    buf1027 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1028 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1029 = buf1000; del buf1000  # reuse
    buf1031 = reinterpret_tensor(buf1019, (8, 576, 768), (442368, 768, 1), 0); del buf1019  # reuse
    buf1030 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_190(c_void_p(buf1029.data_ptr()), c_void_p(buf1021.data_ptr()), c_void_p(buf1022.data_ptr()), c_void_p(primals_305.data_ptr()), c_void_p(mul_140.data_ptr()), c_void_p(div_84.data_ptr()), c_void_p(primals_29.data_ptr()), c_void_p(addmm_55.data_ptr()), c_void_p(buf1024.data_ptr()), c_void_p(buf1025.data_ptr()), c_void_p(buf1026.data_ptr()), c_void_p(buf1027.data_ptr()), c_void_p(buf1028.data_ptr()), c_void_p(buf1031.data_ptr()), c_void_p(buf1030.data_ptr()))
    del addmm_55
    del div_84
    del mul_140
    del primals_29
    del primals_305
    buf1032 = reinterpret_tensor(buf992, (4608, 3072), (3072, 1), 0); del buf992  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1031, (4608, 768), (768, 1), 0), permute_1320, out=buf1032)
    del permute_1320
    buf1033 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1031, (768, 4608), (1, 768), 0), view_279, out=buf1033)
    del view_279
    buf1034 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1035 = reinterpret_tensor(buf1032, (8, 576, 3072), (1769472, 3072, 1), 0); del buf1032  # reuse
    cpp_fused_gelu_gelu_backward_sum_191(c_void_p(buf1035.data_ptr()), c_void_p(buf1031.data_ptr()), c_void_p(addmm_54.data_ptr()), c_void_p(buf1034.data_ptr()))
    del addmm_54
    buf1036 = reinterpret_tensor(buf1031, (4608, 768), (768, 1), 0); del buf1031  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1035, (4608, 3072), (3072, 1), 0), permute_1324, out=buf1036)
    del permute_1324
    buf1037 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1035, (3072, 4608), (1, 3072), 0), view_277, out=buf1037)
    del view_277
    buf1038 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf1039 = buf1026; del buf1026  # reuse
    buf1040 = buf1025; del buf1025  # reuse
    buf1041 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1042 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1043 = buf1029; del buf1029  # reuse
    buf1045 = reinterpret_tensor(buf1022, (8, 576, 768), (442368, 768, 1), 0); del buf1022  # reuse
    buf1044 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_192(c_void_p(buf1043.data_ptr()), c_void_p(buf1035.data_ptr()), c_void_p(buf1036.data_ptr()), c_void_p(primals_299.data_ptr()), c_void_p(mul_134.data_ptr()), c_void_p(div_85.data_ptr()), c_void_p(primals_28.data_ptr()), c_void_p(addmm_53.data_ptr()), c_void_p(buf1038.data_ptr()), c_void_p(buf1039.data_ptr()), c_void_p(buf1040.data_ptr()), c_void_p(buf1041.data_ptr()), c_void_p(buf1042.data_ptr()), c_void_p(buf1045.data_ptr()), c_void_p(buf1044.data_ptr()))
    del addmm_53
    del div_85
    del mul_134
    del primals_28
    del primals_299
    buf1046 = buf1036; del buf1036  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1045, (4608, 768), (768, 1), 0), permute_1328, out=buf1046)
    del permute_1328
    buf1047 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1045, (768, 4608), (1, 768), 0), view_275, out=buf1047)
    del view_275
    buf1048 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1049 = reinterpret_tensor(buf1007, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf1007  # reuse
    cpp_fused_clone_sum_193(c_void_p(buf1045.data_ptr()), c_void_p(buf1046.data_ptr()), c_void_p(buf1048.data_ptr()), c_void_p(buf1049.data_ptr()))
    buf1050 = reinterpret_tensor(buf1046, (128, 576, 48), (27648, 48, 1), 0); del buf1046  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1333, reinterpret_tensor(buf1049, (128, 576, 48), (27648, 48, 1), 0), out=buf1050)
    del permute_1333
    buf1051 = reinterpret_tensor(buf1018, (128, 576, 576), (331776, 576, 1), 0); del buf1018  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1049, (128, 576, 48), (27648, 48, 1), 0), permute_1334, out=buf1051)
    del permute_1334
    buf1052 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1053 = buf1017; del buf1017  # reuse
    cpp_fused__unsafe_view_clone_sum_194(c_void_p(buf1051.data_ptr()), c_void_p(buf1052.data_ptr()), c_void_p(buf1053.data_ptr()))
    buf1054 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1053, (16, 2654208), (1, 16), 0), view_269, out=buf1054)
    del view_269
    buf1055 = reinterpret_tensor(buf1051, (2654208, 16), (16, 1), 0); del buf1051  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf1053, permute_1338, out=buf1055)
    del permute_1338
    buf1056 = buf1013; del buf1013  # reuse
    buf1057 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1058 = reinterpret_tensor(buf1055, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf1055  # reuse
    cpp_fused__softmax_backward_data_clone_sum_195(c_void_p(buf1058.data_ptr()), c_void_p(alias_62.data_ptr()), c_void_p(buf1056.data_ptr()), c_void_p(buf1057.data_ptr()))
    del alias_62
    buf1059 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1058, (16, 2654208), (1, 16), 0), view_267, out=buf1059)
    del view_267
    buf1060 = buf1053; del buf1053  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1058, (2654208, 16), (16, 1), 0), permute_1344, out=buf1060)
    del permute_1344
    buf1061 = reinterpret_tensor(buf1058, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf1058  # reuse
    cpp_fused_clone_196(c_void_p(buf1060.data_ptr()), c_void_p(buf1061.data_ptr()))
    buf1062 = reinterpret_tensor(buf1049, (128, 48, 576), (27648, 576, 1), 0); del buf1049  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1347, reinterpret_tensor(buf1061, (128, 576, 576), (331776, 576, 1), 0), out=buf1062)
    del permute_1347
    buf1063 = reinterpret_tensor(buf1045, (128, 576, 48), (27648, 48, 1), 0); del buf1045  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1061, (128, 576, 576), (331776, 576, 1), 0), permute_1348, out=buf1063)
    del permute_1348
    buf1064 = buf1021; del buf1021  # reuse
    cpp_fused_clone_197(c_void_p(buf1050.data_ptr()), c_void_p(buf1062.data_ptr()), c_void_p(buf1063.data_ptr()), c_void_p(buf1064.data_ptr()))
    buf1065 = reinterpret_tensor(buf1063, (4608, 768), (768, 1), 0); del buf1063  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1064, (4608, 2304), (2304, 1), 0), permute_1351, out=buf1065)
    del permute_1351
    buf1066 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1064, (2304, 4608), (1, 2304), 0), view_261, out=buf1066)
    del view_261
    buf1067 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf1068 = buf1040; del buf1040  # reuse
    buf1069 = buf1039; del buf1039  # reuse
    buf1070 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1071 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1072 = buf1043; del buf1043  # reuse
    buf1074 = reinterpret_tensor(buf1062, (8, 576, 768), (442368, 768, 1), 0); del buf1062  # reuse
    buf1073 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_198(c_void_p(buf1072.data_ptr()), c_void_p(buf1064.data_ptr()), c_void_p(buf1065.data_ptr()), c_void_p(primals_289.data_ptr()), c_void_p(mul_130.data_ptr()), c_void_p(div_86.data_ptr()), c_void_p(primals_27.data_ptr()), c_void_p(addmm_51.data_ptr()), c_void_p(buf1067.data_ptr()), c_void_p(buf1068.data_ptr()), c_void_p(buf1069.data_ptr()), c_void_p(buf1070.data_ptr()), c_void_p(buf1071.data_ptr()), c_void_p(buf1074.data_ptr()), c_void_p(buf1073.data_ptr()))
    del addmm_51
    del div_86
    del mul_130
    del primals_27
    del primals_289
    buf1075 = reinterpret_tensor(buf1035, (4608, 3072), (3072, 1), 0); del buf1035  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1074, (4608, 768), (768, 1), 0), permute_1355, out=buf1075)
    del permute_1355
    buf1076 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1074, (768, 4608), (1, 768), 0), view_259, out=buf1076)
    del view_259
    buf1077 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1078 = reinterpret_tensor(buf1075, (8, 576, 3072), (1769472, 3072, 1), 0); del buf1075  # reuse
    cpp_fused_gelu_gelu_backward_sum_199(c_void_p(buf1078.data_ptr()), c_void_p(buf1074.data_ptr()), c_void_p(addmm_50.data_ptr()), c_void_p(buf1077.data_ptr()))
    del addmm_50
    buf1079 = reinterpret_tensor(buf1074, (4608, 768), (768, 1), 0); del buf1074  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1078, (4608, 3072), (3072, 1), 0), permute_1359, out=buf1079)
    del permute_1359
    buf1080 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1078, (3072, 4608), (1, 3072), 0), view_257, out=buf1080)
    del view_257
    buf1081 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf1082 = buf1069; del buf1069  # reuse
    buf1083 = buf1068; del buf1068  # reuse
    buf1084 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1085 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1086 = buf1072; del buf1072  # reuse
    buf1088 = reinterpret_tensor(buf1065, (8, 576, 768), (442368, 768, 1), 0); del buf1065  # reuse
    buf1087 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_200(c_void_p(buf1086.data_ptr()), c_void_p(buf1078.data_ptr()), c_void_p(buf1079.data_ptr()), c_void_p(primals_283.data_ptr()), c_void_p(mul_124.data_ptr()), c_void_p(div_87.data_ptr()), c_void_p(primals_26.data_ptr()), c_void_p(addmm_49.data_ptr()), c_void_p(buf1081.data_ptr()), c_void_p(buf1082.data_ptr()), c_void_p(buf1083.data_ptr()), c_void_p(buf1084.data_ptr()), c_void_p(buf1085.data_ptr()), c_void_p(buf1088.data_ptr()), c_void_p(buf1087.data_ptr()))
    del addmm_49
    del div_87
    del mul_124
    del primals_26
    del primals_283
    buf1089 = buf1079; del buf1079  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1088, (4608, 768), (768, 1), 0), permute_1363, out=buf1089)
    del permute_1363
    buf1090 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1088, (768, 4608), (1, 768), 0), view_255, out=buf1090)
    del view_255
    buf1091 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1092 = reinterpret_tensor(buf1050, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf1050  # reuse
    cpp_fused_clone_sum_201(c_void_p(buf1088.data_ptr()), c_void_p(buf1089.data_ptr()), c_void_p(buf1091.data_ptr()), c_void_p(buf1092.data_ptr()))
    buf1093 = reinterpret_tensor(buf1089, (128, 576, 48), (27648, 48, 1), 0); del buf1089  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1368, reinterpret_tensor(buf1092, (128, 576, 48), (27648, 48, 1), 0), out=buf1093)
    del permute_1368
    buf1094 = reinterpret_tensor(buf1061, (128, 576, 576), (331776, 576, 1), 0); del buf1061  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1092, (128, 576, 48), (27648, 48, 1), 0), permute_1369, out=buf1094)
    del permute_1369
    buf1095 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1096 = buf1060; del buf1060  # reuse
    cpp_fused__unsafe_view_clone_sum_202(c_void_p(buf1094.data_ptr()), c_void_p(buf1095.data_ptr()), c_void_p(buf1096.data_ptr()))
    buf1097 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1096, (16, 2654208), (1, 16), 0), view_249, out=buf1097)
    del view_249
    buf1098 = reinterpret_tensor(buf1094, (2654208, 16), (16, 1), 0); del buf1094  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf1096, permute_1373, out=buf1098)
    del permute_1373
    buf1099 = buf1056; del buf1056  # reuse
    buf1100 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1101 = reinterpret_tensor(buf1098, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf1098  # reuse
    cpp_fused__softmax_backward_data_clone_sum_203(c_void_p(buf1101.data_ptr()), c_void_p(alias_63.data_ptr()), c_void_p(buf1099.data_ptr()), c_void_p(buf1100.data_ptr()))
    del alias_63
    buf1102 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1101, (16, 2654208), (1, 16), 0), view_247, out=buf1102)
    del view_247
    buf1103 = buf1096; del buf1096  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1101, (2654208, 16), (16, 1), 0), permute_1379, out=buf1103)
    del permute_1379
    buf1104 = reinterpret_tensor(buf1101, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf1101  # reuse
    cpp_fused_clone_204(c_void_p(buf1103.data_ptr()), c_void_p(buf1104.data_ptr()))
    buf1105 = reinterpret_tensor(buf1092, (128, 48, 576), (27648, 576, 1), 0); del buf1092  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1382, reinterpret_tensor(buf1104, (128, 576, 576), (331776, 576, 1), 0), out=buf1105)
    del permute_1382
    buf1106 = reinterpret_tensor(buf1088, (128, 576, 48), (27648, 48, 1), 0); del buf1088  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1104, (128, 576, 576), (331776, 576, 1), 0), permute_1383, out=buf1106)
    del permute_1383
    buf1107 = buf1064; del buf1064  # reuse
    cpp_fused_clone_205(c_void_p(buf1093.data_ptr()), c_void_p(buf1105.data_ptr()), c_void_p(buf1106.data_ptr()), c_void_p(buf1107.data_ptr()))
    buf1108 = reinterpret_tensor(buf1106, (4608, 768), (768, 1), 0); del buf1106  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1107, (4608, 2304), (2304, 1), 0), permute_1386, out=buf1108)
    del permute_1386
    buf1109 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1107, (2304, 4608), (1, 2304), 0), view_241, out=buf1109)
    del view_241
    buf1110 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf1111 = buf1083; del buf1083  # reuse
    buf1112 = buf1082; del buf1082  # reuse
    buf1113 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1114 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1115 = buf1086; del buf1086  # reuse
    buf1117 = reinterpret_tensor(buf1105, (8, 576, 768), (442368, 768, 1), 0); del buf1105  # reuse
    buf1116 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_206(c_void_p(buf1115.data_ptr()), c_void_p(buf1107.data_ptr()), c_void_p(buf1108.data_ptr()), c_void_p(primals_273.data_ptr()), c_void_p(mul_120.data_ptr()), c_void_p(div_88.data_ptr()), c_void_p(primals_25.data_ptr()), c_void_p(addmm_47.data_ptr()), c_void_p(buf1110.data_ptr()), c_void_p(buf1111.data_ptr()), c_void_p(buf1112.data_ptr()), c_void_p(buf1113.data_ptr()), c_void_p(buf1114.data_ptr()), c_void_p(buf1117.data_ptr()), c_void_p(buf1116.data_ptr()))
    del addmm_47
    del div_88
    del mul_120
    del primals_25
    del primals_273
    buf1118 = reinterpret_tensor(buf1078, (4608, 3072), (3072, 1), 0); del buf1078  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1117, (4608, 768), (768, 1), 0), permute_1390, out=buf1118)
    del permute_1390
    buf1119 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1117, (768, 4608), (1, 768), 0), view_239, out=buf1119)
    del view_239
    buf1120 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1121 = reinterpret_tensor(buf1118, (8, 576, 3072), (1769472, 3072, 1), 0); del buf1118  # reuse
    cpp_fused_gelu_gelu_backward_sum_207(c_void_p(buf1121.data_ptr()), c_void_p(buf1117.data_ptr()), c_void_p(addmm_46.data_ptr()), c_void_p(buf1120.data_ptr()))
    del addmm_46
    buf1122 = reinterpret_tensor(buf1117, (4608, 768), (768, 1), 0); del buf1117  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1121, (4608, 3072), (3072, 1), 0), permute_1394, out=buf1122)
    del permute_1394
    buf1123 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1121, (3072, 4608), (1, 3072), 0), view_237, out=buf1123)
    del view_237
    buf1124 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf1125 = buf1112; del buf1112  # reuse
    buf1126 = buf1111; del buf1111  # reuse
    buf1127 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1128 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1129 = buf1115; del buf1115  # reuse
    buf1131 = reinterpret_tensor(buf1108, (8, 576, 768), (442368, 768, 1), 0); del buf1108  # reuse
    buf1130 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_208(c_void_p(buf1129.data_ptr()), c_void_p(buf1121.data_ptr()), c_void_p(buf1122.data_ptr()), c_void_p(primals_267.data_ptr()), c_void_p(mul_114.data_ptr()), c_void_p(div_89.data_ptr()), c_void_p(primals_24.data_ptr()), c_void_p(addmm_45.data_ptr()), c_void_p(buf1124.data_ptr()), c_void_p(buf1125.data_ptr()), c_void_p(buf1126.data_ptr()), c_void_p(buf1127.data_ptr()), c_void_p(buf1128.data_ptr()), c_void_p(buf1131.data_ptr()), c_void_p(buf1130.data_ptr()))
    del addmm_45
    del div_89
    del mul_114
    del primals_24
    del primals_267
    buf1132 = buf1122; del buf1122  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1131, (4608, 768), (768, 1), 0), permute_1398, out=buf1132)
    del permute_1398
    buf1133 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1131, (768, 4608), (1, 768), 0), view_235, out=buf1133)
    del view_235
    buf1134 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1135 = reinterpret_tensor(buf1093, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf1093  # reuse
    cpp_fused_clone_sum_209(c_void_p(buf1131.data_ptr()), c_void_p(buf1132.data_ptr()), c_void_p(buf1134.data_ptr()), c_void_p(buf1135.data_ptr()))
    buf1136 = reinterpret_tensor(buf1132, (128, 576, 48), (27648, 48, 1), 0); del buf1132  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1403, reinterpret_tensor(buf1135, (128, 576, 48), (27648, 48, 1), 0), out=buf1136)
    del permute_1403
    buf1137 = reinterpret_tensor(buf1104, (128, 576, 576), (331776, 576, 1), 0); del buf1104  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1135, (128, 576, 48), (27648, 48, 1), 0), permute_1404, out=buf1137)
    del permute_1404
    buf1138 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1139 = buf1103; del buf1103  # reuse
    cpp_fused__unsafe_view_clone_sum_210(c_void_p(buf1137.data_ptr()), c_void_p(buf1138.data_ptr()), c_void_p(buf1139.data_ptr()))
    buf1140 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1139, (16, 2654208), (1, 16), 0), view_229, out=buf1140)
    del view_229
    buf1141 = reinterpret_tensor(buf1137, (2654208, 16), (16, 1), 0); del buf1137  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf1139, permute_1408, out=buf1141)
    del permute_1408
    buf1142 = buf1099; del buf1099  # reuse
    buf1143 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1144 = reinterpret_tensor(buf1141, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf1141  # reuse
    cpp_fused__softmax_backward_data_clone_sum_211(c_void_p(buf1144.data_ptr()), c_void_p(alias_64.data_ptr()), c_void_p(buf1142.data_ptr()), c_void_p(buf1143.data_ptr()))
    del alias_64
    buf1145 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1144, (16, 2654208), (1, 16), 0), view_227, out=buf1145)
    del view_227
    buf1146 = buf1139; del buf1139  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1144, (2654208, 16), (16, 1), 0), permute_1414, out=buf1146)
    del permute_1414
    buf1147 = reinterpret_tensor(buf1144, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf1144  # reuse
    cpp_fused_clone_212(c_void_p(buf1146.data_ptr()), c_void_p(buf1147.data_ptr()))
    buf1148 = reinterpret_tensor(buf1135, (128, 48, 576), (27648, 576, 1), 0); del buf1135  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1417, reinterpret_tensor(buf1147, (128, 576, 576), (331776, 576, 1), 0), out=buf1148)
    del permute_1417
    buf1149 = reinterpret_tensor(buf1131, (128, 576, 48), (27648, 48, 1), 0); del buf1131  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1147, (128, 576, 576), (331776, 576, 1), 0), permute_1418, out=buf1149)
    del permute_1418
    buf1150 = buf1107; del buf1107  # reuse
    cpp_fused_clone_213(c_void_p(buf1136.data_ptr()), c_void_p(buf1148.data_ptr()), c_void_p(buf1149.data_ptr()), c_void_p(buf1150.data_ptr()))
    buf1151 = reinterpret_tensor(buf1149, (4608, 768), (768, 1), 0); del buf1149  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1150, (4608, 2304), (2304, 1), 0), permute_1421, out=buf1151)
    del permute_1421
    buf1152 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1150, (2304, 4608), (1, 2304), 0), view_221, out=buf1152)
    del view_221
    buf1153 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf1154 = buf1126; del buf1126  # reuse
    buf1155 = buf1125; del buf1125  # reuse
    buf1156 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1157 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1158 = buf1129; del buf1129  # reuse
    buf1160 = reinterpret_tensor(buf1148, (8, 576, 768), (442368, 768, 1), 0); del buf1148  # reuse
    buf1159 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_214(c_void_p(buf1158.data_ptr()), c_void_p(buf1150.data_ptr()), c_void_p(buf1151.data_ptr()), c_void_p(primals_257.data_ptr()), c_void_p(mul_110.data_ptr()), c_void_p(div_90.data_ptr()), c_void_p(primals_23.data_ptr()), c_void_p(addmm_43.data_ptr()), c_void_p(buf1153.data_ptr()), c_void_p(buf1154.data_ptr()), c_void_p(buf1155.data_ptr()), c_void_p(buf1156.data_ptr()), c_void_p(buf1157.data_ptr()), c_void_p(buf1160.data_ptr()), c_void_p(buf1159.data_ptr()))
    del addmm_43
    del div_90
    del mul_110
    del primals_23
    del primals_257
    buf1161 = reinterpret_tensor(buf1121, (4608, 3072), (3072, 1), 0); del buf1121  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1160, (4608, 768), (768, 1), 0), permute_1425, out=buf1161)
    del permute_1425
    buf1162 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1160, (768, 4608), (1, 768), 0), view_219, out=buf1162)
    del view_219
    buf1163 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1164 = reinterpret_tensor(buf1161, (8, 576, 3072), (1769472, 3072, 1), 0); del buf1161  # reuse
    cpp_fused_gelu_gelu_backward_sum_215(c_void_p(buf1164.data_ptr()), c_void_p(buf1160.data_ptr()), c_void_p(addmm_42.data_ptr()), c_void_p(buf1163.data_ptr()))
    del addmm_42
    buf1165 = reinterpret_tensor(buf1160, (4608, 768), (768, 1), 0); del buf1160  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1164, (4608, 3072), (3072, 1), 0), permute_1429, out=buf1165)
    del permute_1429
    buf1166 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1164, (3072, 4608), (1, 3072), 0), view_217, out=buf1166)
    del view_217
    buf1167 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf1168 = buf1155; del buf1155  # reuse
    buf1169 = buf1154; del buf1154  # reuse
    buf1170 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1171 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1172 = buf1158; del buf1158  # reuse
    buf1174 = reinterpret_tensor(buf1151, (8, 576, 768), (442368, 768, 1), 0); del buf1151  # reuse
    buf1173 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_216(c_void_p(buf1172.data_ptr()), c_void_p(buf1164.data_ptr()), c_void_p(buf1165.data_ptr()), c_void_p(primals_251.data_ptr()), c_void_p(mul_104.data_ptr()), c_void_p(div_91.data_ptr()), c_void_p(primals_22.data_ptr()), c_void_p(addmm_41.data_ptr()), c_void_p(buf1167.data_ptr()), c_void_p(buf1168.data_ptr()), c_void_p(buf1169.data_ptr()), c_void_p(buf1170.data_ptr()), c_void_p(buf1171.data_ptr()), c_void_p(buf1174.data_ptr()), c_void_p(buf1173.data_ptr()))
    del addmm_41
    del div_91
    del mul_104
    del primals_22
    del primals_251
    buf1175 = buf1165; del buf1165  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1174, (4608, 768), (768, 1), 0), permute_1433, out=buf1175)
    del permute_1433
    buf1176 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1174, (768, 4608), (1, 768), 0), view_215, out=buf1176)
    del view_215
    buf1177 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1178 = reinterpret_tensor(buf1136, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf1136  # reuse
    cpp_fused_clone_sum_217(c_void_p(buf1174.data_ptr()), c_void_p(buf1175.data_ptr()), c_void_p(buf1177.data_ptr()), c_void_p(buf1178.data_ptr()))
    buf1179 = reinterpret_tensor(buf1175, (128, 576, 48), (27648, 48, 1), 0); del buf1175  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1438, reinterpret_tensor(buf1178, (128, 576, 48), (27648, 48, 1), 0), out=buf1179)
    del permute_1438
    buf1180 = reinterpret_tensor(buf1147, (128, 576, 576), (331776, 576, 1), 0); del buf1147  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1178, (128, 576, 48), (27648, 48, 1), 0), permute_1439, out=buf1180)
    del permute_1439
    buf1181 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1182 = buf1146; del buf1146  # reuse
    cpp_fused__unsafe_view_clone_sum_218(c_void_p(buf1180.data_ptr()), c_void_p(buf1181.data_ptr()), c_void_p(buf1182.data_ptr()))
    buf1183 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1182, (16, 2654208), (1, 16), 0), view_209, out=buf1183)
    del view_209
    buf1184 = reinterpret_tensor(buf1180, (2654208, 16), (16, 1), 0); del buf1180  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf1182, permute_1443, out=buf1184)
    del permute_1443
    buf1185 = buf1142; del buf1142  # reuse
    buf1186 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1187 = reinterpret_tensor(buf1184, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf1184  # reuse
    cpp_fused__softmax_backward_data_clone_sum_219(c_void_p(buf1187.data_ptr()), c_void_p(alias_65.data_ptr()), c_void_p(buf1185.data_ptr()), c_void_p(buf1186.data_ptr()))
    del alias_65
    buf1188 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1187, (16, 2654208), (1, 16), 0), view_207, out=buf1188)
    del view_207
    buf1189 = buf1182; del buf1182  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1187, (2654208, 16), (16, 1), 0), permute_1449, out=buf1189)
    del permute_1449
    buf1190 = reinterpret_tensor(buf1187, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf1187  # reuse
    cpp_fused_clone_220(c_void_p(buf1189.data_ptr()), c_void_p(buf1190.data_ptr()))
    buf1191 = reinterpret_tensor(buf1178, (128, 48, 576), (27648, 576, 1), 0); del buf1178  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1452, reinterpret_tensor(buf1190, (128, 576, 576), (331776, 576, 1), 0), out=buf1191)
    del permute_1452
    buf1192 = reinterpret_tensor(buf1174, (128, 576, 48), (27648, 48, 1), 0); del buf1174  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1190, (128, 576, 576), (331776, 576, 1), 0), permute_1453, out=buf1192)
    del permute_1453
    buf1193 = buf1150; del buf1150  # reuse
    cpp_fused_clone_221(c_void_p(buf1179.data_ptr()), c_void_p(buf1191.data_ptr()), c_void_p(buf1192.data_ptr()), c_void_p(buf1193.data_ptr()))
    buf1194 = reinterpret_tensor(buf1192, (4608, 768), (768, 1), 0); del buf1192  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1193, (4608, 2304), (2304, 1), 0), permute_1456, out=buf1194)
    del permute_1456
    buf1195 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1193, (2304, 4608), (1, 2304), 0), view_201, out=buf1195)
    del view_201
    buf1196 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf1197 = buf1169; del buf1169  # reuse
    buf1198 = buf1168; del buf1168  # reuse
    buf1199 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1200 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1201 = buf1172; del buf1172  # reuse
    buf1203 = reinterpret_tensor(buf1191, (8, 576, 768), (442368, 768, 1), 0); del buf1191  # reuse
    buf1202 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_222(c_void_p(buf1201.data_ptr()), c_void_p(buf1193.data_ptr()), c_void_p(buf1194.data_ptr()), c_void_p(primals_241.data_ptr()), c_void_p(mul_100.data_ptr()), c_void_p(div_92.data_ptr()), c_void_p(primals_21.data_ptr()), c_void_p(addmm_39.data_ptr()), c_void_p(buf1196.data_ptr()), c_void_p(buf1197.data_ptr()), c_void_p(buf1198.data_ptr()), c_void_p(buf1199.data_ptr()), c_void_p(buf1200.data_ptr()), c_void_p(buf1203.data_ptr()), c_void_p(buf1202.data_ptr()))
    del addmm_39
    del div_92
    del mul_100
    del primals_21
    del primals_241
    buf1204 = reinterpret_tensor(buf1164, (4608, 3072), (3072, 1), 0); del buf1164  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1203, (4608, 768), (768, 1), 0), permute_1460, out=buf1204)
    del permute_1460
    buf1205 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1203, (768, 4608), (1, 768), 0), view_199, out=buf1205)
    del view_199
    buf1206 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1207 = reinterpret_tensor(buf1204, (8, 576, 3072), (1769472, 3072, 1), 0); del buf1204  # reuse
    cpp_fused_gelu_gelu_backward_sum_223(c_void_p(buf1207.data_ptr()), c_void_p(buf1203.data_ptr()), c_void_p(addmm_38.data_ptr()), c_void_p(buf1206.data_ptr()))
    del addmm_38
    buf1208 = reinterpret_tensor(buf1203, (4608, 768), (768, 1), 0); del buf1203  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1207, (4608, 3072), (3072, 1), 0), permute_1464, out=buf1208)
    del permute_1464
    buf1209 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1207, (3072, 4608), (1, 3072), 0), view_197, out=buf1209)
    del view_197
    buf1210 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf1211 = buf1198; del buf1198  # reuse
    buf1212 = buf1197; del buf1197  # reuse
    buf1213 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1214 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1215 = buf1201; del buf1201  # reuse
    buf1217 = reinterpret_tensor(buf1194, (8, 576, 768), (442368, 768, 1), 0); del buf1194  # reuse
    buf1216 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_224(c_void_p(buf1215.data_ptr()), c_void_p(buf1207.data_ptr()), c_void_p(buf1208.data_ptr()), c_void_p(primals_235.data_ptr()), c_void_p(mul_94.data_ptr()), c_void_p(div_93.data_ptr()), c_void_p(primals_20.data_ptr()), c_void_p(addmm_37.data_ptr()), c_void_p(buf1210.data_ptr()), c_void_p(buf1211.data_ptr()), c_void_p(buf1212.data_ptr()), c_void_p(buf1213.data_ptr()), c_void_p(buf1214.data_ptr()), c_void_p(buf1217.data_ptr()), c_void_p(buf1216.data_ptr()))
    del addmm_37
    del div_93
    del mul_94
    del primals_20
    del primals_235
    buf1218 = buf1208; del buf1208  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1217, (4608, 768), (768, 1), 0), permute_1468, out=buf1218)
    del permute_1468
    buf1219 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1217, (768, 4608), (1, 768), 0), view_195, out=buf1219)
    del view_195
    buf1220 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1221 = reinterpret_tensor(buf1179, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf1179  # reuse
    cpp_fused_clone_sum_225(c_void_p(buf1217.data_ptr()), c_void_p(buf1218.data_ptr()), c_void_p(buf1220.data_ptr()), c_void_p(buf1221.data_ptr()))
    buf1222 = reinterpret_tensor(buf1218, (128, 576, 48), (27648, 48, 1), 0); del buf1218  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1473, reinterpret_tensor(buf1221, (128, 576, 48), (27648, 48, 1), 0), out=buf1222)
    del permute_1473
    buf1223 = reinterpret_tensor(buf1190, (128, 576, 576), (331776, 576, 1), 0); del buf1190  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1221, (128, 576, 48), (27648, 48, 1), 0), permute_1474, out=buf1223)
    del permute_1474
    buf1224 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1225 = buf1189; del buf1189  # reuse
    cpp_fused__unsafe_view_clone_sum_226(c_void_p(buf1223.data_ptr()), c_void_p(buf1224.data_ptr()), c_void_p(buf1225.data_ptr()))
    buf1226 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1225, (16, 2654208), (1, 16), 0), view_189, out=buf1226)
    del view_189
    buf1227 = reinterpret_tensor(buf1223, (2654208, 16), (16, 1), 0); del buf1223  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf1225, permute_1478, out=buf1227)
    del permute_1478
    buf1228 = buf1185; del buf1185  # reuse
    buf1229 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1230 = reinterpret_tensor(buf1227, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf1227  # reuse
    cpp_fused__softmax_backward_data_clone_sum_227(c_void_p(buf1230.data_ptr()), c_void_p(alias_66.data_ptr()), c_void_p(buf1228.data_ptr()), c_void_p(buf1229.data_ptr()))
    del alias_66
    buf1231 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1230, (16, 2654208), (1, 16), 0), view_187, out=buf1231)
    del view_187
    buf1232 = buf1225; del buf1225  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1230, (2654208, 16), (16, 1), 0), permute_1484, out=buf1232)
    del permute_1484
    buf1233 = reinterpret_tensor(buf1230, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf1230  # reuse
    cpp_fused_clone_228(c_void_p(buf1232.data_ptr()), c_void_p(buf1233.data_ptr()))
    buf1234 = reinterpret_tensor(buf1221, (128, 48, 576), (27648, 576, 1), 0); del buf1221  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1487, reinterpret_tensor(buf1233, (128, 576, 576), (331776, 576, 1), 0), out=buf1234)
    del permute_1487
    buf1235 = reinterpret_tensor(buf1217, (128, 576, 48), (27648, 48, 1), 0); del buf1217  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1233, (128, 576, 576), (331776, 576, 1), 0), permute_1488, out=buf1235)
    del permute_1488
    buf1236 = buf1193; del buf1193  # reuse
    cpp_fused_clone_229(c_void_p(buf1222.data_ptr()), c_void_p(buf1234.data_ptr()), c_void_p(buf1235.data_ptr()), c_void_p(buf1236.data_ptr()))
    buf1237 = reinterpret_tensor(buf1235, (4608, 768), (768, 1), 0); del buf1235  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1236, (4608, 2304), (2304, 1), 0), permute_1491, out=buf1237)
    del permute_1491
    buf1238 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1236, (2304, 4608), (1, 2304), 0), view_181, out=buf1238)
    del view_181
    buf1239 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf1240 = buf1212; del buf1212  # reuse
    buf1241 = buf1211; del buf1211  # reuse
    buf1242 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1243 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1244 = buf1215; del buf1215  # reuse
    buf1246 = reinterpret_tensor(buf1234, (8, 576, 768), (442368, 768, 1), 0); del buf1234  # reuse
    buf1245 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_230(c_void_p(buf1244.data_ptr()), c_void_p(buf1236.data_ptr()), c_void_p(buf1237.data_ptr()), c_void_p(primals_225.data_ptr()), c_void_p(mul_90.data_ptr()), c_void_p(div_94.data_ptr()), c_void_p(primals_19.data_ptr()), c_void_p(addmm_35.data_ptr()), c_void_p(buf1239.data_ptr()), c_void_p(buf1240.data_ptr()), c_void_p(buf1241.data_ptr()), c_void_p(buf1242.data_ptr()), c_void_p(buf1243.data_ptr()), c_void_p(buf1246.data_ptr()), c_void_p(buf1245.data_ptr()))
    del addmm_35
    del div_94
    del mul_90
    del primals_19
    del primals_225
    buf1247 = reinterpret_tensor(buf1207, (4608, 3072), (3072, 1), 0); del buf1207  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1246, (4608, 768), (768, 1), 0), permute_1495, out=buf1247)
    del permute_1495
    buf1248 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1246, (768, 4608), (1, 768), 0), view_179, out=buf1248)
    del view_179
    buf1249 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1250 = reinterpret_tensor(buf1247, (8, 576, 3072), (1769472, 3072, 1), 0); del buf1247  # reuse
    cpp_fused_gelu_gelu_backward_sum_231(c_void_p(buf1250.data_ptr()), c_void_p(buf1246.data_ptr()), c_void_p(addmm_34.data_ptr()), c_void_p(buf1249.data_ptr()))
    del addmm_34
    buf1251 = reinterpret_tensor(buf1246, (4608, 768), (768, 1), 0); del buf1246  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1250, (4608, 3072), (3072, 1), 0), permute_1499, out=buf1251)
    del permute_1499
    buf1252 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1250, (3072, 4608), (1, 3072), 0), view_177, out=buf1252)
    del view_177
    buf1253 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf1254 = buf1241; del buf1241  # reuse
    buf1255 = buf1240; del buf1240  # reuse
    buf1256 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1257 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1258 = buf1244; del buf1244  # reuse
    buf1260 = reinterpret_tensor(buf1237, (8, 576, 768), (442368, 768, 1), 0); del buf1237  # reuse
    buf1259 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_232(c_void_p(buf1258.data_ptr()), c_void_p(buf1250.data_ptr()), c_void_p(buf1251.data_ptr()), c_void_p(primals_219.data_ptr()), c_void_p(mul_84.data_ptr()), c_void_p(div_95.data_ptr()), c_void_p(primals_18.data_ptr()), c_void_p(addmm_33.data_ptr()), c_void_p(buf1253.data_ptr()), c_void_p(buf1254.data_ptr()), c_void_p(buf1255.data_ptr()), c_void_p(buf1256.data_ptr()), c_void_p(buf1257.data_ptr()), c_void_p(buf1260.data_ptr()), c_void_p(buf1259.data_ptr()))
    del addmm_33
    del div_95
    del mul_84
    del primals_18
    del primals_219
    buf1261 = buf1251; del buf1251  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1260, (4608, 768), (768, 1), 0), permute_1503, out=buf1261)
    del permute_1503
    buf1262 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1260, (768, 4608), (1, 768), 0), view_175, out=buf1262)
    del view_175
    buf1263 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1264 = reinterpret_tensor(buf1222, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf1222  # reuse
    cpp_fused_clone_sum_233(c_void_p(buf1260.data_ptr()), c_void_p(buf1261.data_ptr()), c_void_p(buf1263.data_ptr()), c_void_p(buf1264.data_ptr()))
    buf1265 = reinterpret_tensor(buf1261, (128, 576, 48), (27648, 48, 1), 0); del buf1261  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1508, reinterpret_tensor(buf1264, (128, 576, 48), (27648, 48, 1), 0), out=buf1265)
    del permute_1508
    buf1266 = reinterpret_tensor(buf1233, (128, 576, 576), (331776, 576, 1), 0); del buf1233  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1264, (128, 576, 48), (27648, 48, 1), 0), permute_1509, out=buf1266)
    del permute_1509
    buf1267 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1268 = buf1232; del buf1232  # reuse
    cpp_fused__unsafe_view_clone_sum_234(c_void_p(buf1266.data_ptr()), c_void_p(buf1267.data_ptr()), c_void_p(buf1268.data_ptr()))
    buf1269 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1268, (16, 2654208), (1, 16), 0), view_169, out=buf1269)
    del view_169
    buf1270 = reinterpret_tensor(buf1266, (2654208, 16), (16, 1), 0); del buf1266  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf1268, permute_1513, out=buf1270)
    del permute_1513
    buf1271 = buf1228; del buf1228  # reuse
    buf1272 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1273 = reinterpret_tensor(buf1270, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf1270  # reuse
    cpp_fused__softmax_backward_data_clone_sum_235(c_void_p(buf1273.data_ptr()), c_void_p(alias_67.data_ptr()), c_void_p(buf1271.data_ptr()), c_void_p(buf1272.data_ptr()))
    del alias_67
    buf1274 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1273, (16, 2654208), (1, 16), 0), view_167, out=buf1274)
    del view_167
    buf1275 = buf1268; del buf1268  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1273, (2654208, 16), (16, 1), 0), permute_1519, out=buf1275)
    del permute_1519
    buf1276 = reinterpret_tensor(buf1273, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf1273  # reuse
    cpp_fused_clone_236(c_void_p(buf1275.data_ptr()), c_void_p(buf1276.data_ptr()))
    buf1277 = reinterpret_tensor(buf1264, (128, 48, 576), (27648, 576, 1), 0); del buf1264  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1522, reinterpret_tensor(buf1276, (128, 576, 576), (331776, 576, 1), 0), out=buf1277)
    del permute_1522
    buf1278 = reinterpret_tensor(buf1260, (128, 576, 48), (27648, 48, 1), 0); del buf1260  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1276, (128, 576, 576), (331776, 576, 1), 0), permute_1523, out=buf1278)
    del permute_1523
    buf1279 = buf1236; del buf1236  # reuse
    cpp_fused_clone_237(c_void_p(buf1265.data_ptr()), c_void_p(buf1277.data_ptr()), c_void_p(buf1278.data_ptr()), c_void_p(buf1279.data_ptr()))
    buf1280 = reinterpret_tensor(buf1278, (4608, 768), (768, 1), 0); del buf1278  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1279, (4608, 2304), (2304, 1), 0), permute_1526, out=buf1280)
    del permute_1526
    buf1281 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1279, (2304, 4608), (1, 2304), 0), view_161, out=buf1281)
    del view_161
    buf1282 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf1283 = buf1255; del buf1255  # reuse
    buf1284 = buf1254; del buf1254  # reuse
    buf1285 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1286 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1287 = buf1258; del buf1258  # reuse
    buf1289 = reinterpret_tensor(buf1277, (8, 576, 768), (442368, 768, 1), 0); del buf1277  # reuse
    buf1288 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_238(c_void_p(buf1287.data_ptr()), c_void_p(buf1279.data_ptr()), c_void_p(buf1280.data_ptr()), c_void_p(primals_209.data_ptr()), c_void_p(mul_80.data_ptr()), c_void_p(div_96.data_ptr()), c_void_p(primals_17.data_ptr()), c_void_p(addmm_31.data_ptr()), c_void_p(buf1282.data_ptr()), c_void_p(buf1283.data_ptr()), c_void_p(buf1284.data_ptr()), c_void_p(buf1285.data_ptr()), c_void_p(buf1286.data_ptr()), c_void_p(buf1289.data_ptr()), c_void_p(buf1288.data_ptr()))
    del addmm_31
    del div_96
    del mul_80
    del primals_17
    del primals_209
    buf1290 = reinterpret_tensor(buf1250, (4608, 3072), (3072, 1), 0); del buf1250  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1289, (4608, 768), (768, 1), 0), permute_1530, out=buf1290)
    del permute_1530
    buf1291 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1289, (768, 4608), (1, 768), 0), view_159, out=buf1291)
    del view_159
    buf1292 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1293 = reinterpret_tensor(buf1290, (8, 576, 3072), (1769472, 3072, 1), 0); del buf1290  # reuse
    cpp_fused_gelu_gelu_backward_sum_239(c_void_p(buf1293.data_ptr()), c_void_p(buf1289.data_ptr()), c_void_p(addmm_30.data_ptr()), c_void_p(buf1292.data_ptr()))
    del addmm_30
    buf1294 = reinterpret_tensor(buf1289, (4608, 768), (768, 1), 0); del buf1289  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1293, (4608, 3072), (3072, 1), 0), permute_1534, out=buf1294)
    del permute_1534
    buf1295 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1293, (3072, 4608), (1, 3072), 0), view_157, out=buf1295)
    del view_157
    buf1296 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf1297 = buf1284; del buf1284  # reuse
    buf1298 = buf1283; del buf1283  # reuse
    buf1299 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1300 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1301 = buf1287; del buf1287  # reuse
    buf1303 = reinterpret_tensor(buf1280, (8, 576, 768), (442368, 768, 1), 0); del buf1280  # reuse
    buf1302 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_240(c_void_p(buf1301.data_ptr()), c_void_p(buf1293.data_ptr()), c_void_p(buf1294.data_ptr()), c_void_p(primals_203.data_ptr()), c_void_p(mul_74.data_ptr()), c_void_p(div_97.data_ptr()), c_void_p(primals_16.data_ptr()), c_void_p(addmm_29.data_ptr()), c_void_p(buf1296.data_ptr()), c_void_p(buf1297.data_ptr()), c_void_p(buf1298.data_ptr()), c_void_p(buf1299.data_ptr()), c_void_p(buf1300.data_ptr()), c_void_p(buf1303.data_ptr()), c_void_p(buf1302.data_ptr()))
    del addmm_29
    del div_97
    del mul_74
    del primals_16
    del primals_203
    buf1304 = buf1294; del buf1294  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1303, (4608, 768), (768, 1), 0), permute_1538, out=buf1304)
    del permute_1538
    buf1305 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1303, (768, 4608), (1, 768), 0), view_155, out=buf1305)
    del view_155
    buf1306 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1307 = reinterpret_tensor(buf1265, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf1265  # reuse
    cpp_fused_clone_sum_241(c_void_p(buf1303.data_ptr()), c_void_p(buf1304.data_ptr()), c_void_p(buf1306.data_ptr()), c_void_p(buf1307.data_ptr()))
    buf1308 = reinterpret_tensor(buf1304, (128, 576, 48), (27648, 48, 1), 0); del buf1304  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1543, reinterpret_tensor(buf1307, (128, 576, 48), (27648, 48, 1), 0), out=buf1308)
    del permute_1543
    buf1309 = reinterpret_tensor(buf1276, (128, 576, 576), (331776, 576, 1), 0); del buf1276  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1307, (128, 576, 48), (27648, 48, 1), 0), permute_1544, out=buf1309)
    del permute_1544
    buf1310 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1311 = buf1275; del buf1275  # reuse
    cpp_fused__unsafe_view_clone_sum_242(c_void_p(buf1309.data_ptr()), c_void_p(buf1310.data_ptr()), c_void_p(buf1311.data_ptr()))
    buf1312 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1311, (16, 2654208), (1, 16), 0), view_149, out=buf1312)
    del view_149
    buf1313 = reinterpret_tensor(buf1309, (2654208, 16), (16, 1), 0); del buf1309  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf1311, permute_1548, out=buf1313)
    del permute_1548
    buf1314 = buf1271; del buf1271  # reuse
    buf1315 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1316 = reinterpret_tensor(buf1313, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf1313  # reuse
    cpp_fused__softmax_backward_data_clone_sum_243(c_void_p(buf1316.data_ptr()), c_void_p(alias_68.data_ptr()), c_void_p(buf1314.data_ptr()), c_void_p(buf1315.data_ptr()))
    del alias_68
    buf1317 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1316, (16, 2654208), (1, 16), 0), view_147, out=buf1317)
    del view_147
    buf1318 = buf1311; del buf1311  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1316, (2654208, 16), (16, 1), 0), permute_1554, out=buf1318)
    del permute_1554
    buf1319 = reinterpret_tensor(buf1316, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf1316  # reuse
    cpp_fused_clone_244(c_void_p(buf1318.data_ptr()), c_void_p(buf1319.data_ptr()))
    buf1320 = reinterpret_tensor(buf1307, (128, 48, 576), (27648, 576, 1), 0); del buf1307  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1557, reinterpret_tensor(buf1319, (128, 576, 576), (331776, 576, 1), 0), out=buf1320)
    del permute_1557
    buf1321 = reinterpret_tensor(buf1303, (128, 576, 48), (27648, 48, 1), 0); del buf1303  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1319, (128, 576, 576), (331776, 576, 1), 0), permute_1558, out=buf1321)
    del permute_1558
    buf1322 = buf1279; del buf1279  # reuse
    cpp_fused_clone_245(c_void_p(buf1308.data_ptr()), c_void_p(buf1320.data_ptr()), c_void_p(buf1321.data_ptr()), c_void_p(buf1322.data_ptr()))
    buf1323 = reinterpret_tensor(buf1321, (4608, 768), (768, 1), 0); del buf1321  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1322, (4608, 2304), (2304, 1), 0), permute_1561, out=buf1323)
    del permute_1561
    buf1324 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1322, (2304, 4608), (1, 2304), 0), view_141, out=buf1324)
    del view_141
    buf1325 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf1326 = buf1298; del buf1298  # reuse
    buf1327 = buf1297; del buf1297  # reuse
    buf1328 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1329 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1330 = buf1301; del buf1301  # reuse
    buf1332 = reinterpret_tensor(buf1320, (8, 576, 768), (442368, 768, 1), 0); del buf1320  # reuse
    buf1331 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_246(c_void_p(buf1330.data_ptr()), c_void_p(buf1322.data_ptr()), c_void_p(buf1323.data_ptr()), c_void_p(primals_193.data_ptr()), c_void_p(mul_70.data_ptr()), c_void_p(div_98.data_ptr()), c_void_p(primals_15.data_ptr()), c_void_p(addmm_27.data_ptr()), c_void_p(buf1325.data_ptr()), c_void_p(buf1326.data_ptr()), c_void_p(buf1327.data_ptr()), c_void_p(buf1328.data_ptr()), c_void_p(buf1329.data_ptr()), c_void_p(buf1332.data_ptr()), c_void_p(buf1331.data_ptr()))
    del addmm_27
    del div_98
    del mul_70
    del primals_15
    del primals_193
    buf1333 = reinterpret_tensor(buf1293, (4608, 3072), (3072, 1), 0); del buf1293  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1332, (4608, 768), (768, 1), 0), permute_1565, out=buf1333)
    del permute_1565
    buf1334 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1332, (768, 4608), (1, 768), 0), view_139, out=buf1334)
    del view_139
    buf1335 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1336 = reinterpret_tensor(buf1333, (8, 576, 3072), (1769472, 3072, 1), 0); del buf1333  # reuse
    cpp_fused_gelu_gelu_backward_sum_247(c_void_p(buf1336.data_ptr()), c_void_p(buf1332.data_ptr()), c_void_p(addmm_26.data_ptr()), c_void_p(buf1335.data_ptr()))
    del addmm_26
    buf1337 = reinterpret_tensor(buf1332, (4608, 768), (768, 1), 0); del buf1332  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1336, (4608, 3072), (3072, 1), 0), permute_1569, out=buf1337)
    del permute_1569
    buf1338 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1336, (3072, 4608), (1, 3072), 0), view_137, out=buf1338)
    del view_137
    buf1339 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf1340 = buf1327; del buf1327  # reuse
    buf1341 = buf1326; del buf1326  # reuse
    buf1342 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1343 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1344 = buf1330; del buf1330  # reuse
    buf1346 = reinterpret_tensor(buf1323, (8, 576, 768), (442368, 768, 1), 0); del buf1323  # reuse
    buf1345 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_248(c_void_p(buf1344.data_ptr()), c_void_p(buf1336.data_ptr()), c_void_p(buf1337.data_ptr()), c_void_p(primals_187.data_ptr()), c_void_p(mul_64.data_ptr()), c_void_p(div_99.data_ptr()), c_void_p(primals_14.data_ptr()), c_void_p(addmm_25.data_ptr()), c_void_p(buf1339.data_ptr()), c_void_p(buf1340.data_ptr()), c_void_p(buf1341.data_ptr()), c_void_p(buf1342.data_ptr()), c_void_p(buf1343.data_ptr()), c_void_p(buf1346.data_ptr()), c_void_p(buf1345.data_ptr()))
    del addmm_25
    del div_99
    del mul_64
    del primals_14
    del primals_187
    buf1347 = buf1337; del buf1337  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1346, (4608, 768), (768, 1), 0), permute_1573, out=buf1347)
    del permute_1573
    buf1348 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1346, (768, 4608), (1, 768), 0), view_135, out=buf1348)
    del view_135
    buf1349 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1350 = reinterpret_tensor(buf1308, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf1308  # reuse
    cpp_fused_clone_sum_249(c_void_p(buf1346.data_ptr()), c_void_p(buf1347.data_ptr()), c_void_p(buf1349.data_ptr()), c_void_p(buf1350.data_ptr()))
    buf1351 = reinterpret_tensor(buf1347, (128, 576, 48), (27648, 48, 1), 0); del buf1347  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1578, reinterpret_tensor(buf1350, (128, 576, 48), (27648, 48, 1), 0), out=buf1351)
    del permute_1578
    buf1352 = reinterpret_tensor(buf1319, (128, 576, 576), (331776, 576, 1), 0); del buf1319  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1350, (128, 576, 48), (27648, 48, 1), 0), permute_1579, out=buf1352)
    del permute_1579
    buf1353 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1354 = buf1318; del buf1318  # reuse
    cpp_fused__unsafe_view_clone_sum_250(c_void_p(buf1352.data_ptr()), c_void_p(buf1353.data_ptr()), c_void_p(buf1354.data_ptr()))
    buf1355 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1354, (16, 2654208), (1, 16), 0), view_129, out=buf1355)
    del view_129
    buf1356 = reinterpret_tensor(buf1352, (2654208, 16), (16, 1), 0); del buf1352  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf1354, permute_1583, out=buf1356)
    del permute_1583
    buf1357 = buf1314; del buf1314  # reuse
    buf1358 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1359 = reinterpret_tensor(buf1356, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf1356  # reuse
    cpp_fused__softmax_backward_data_clone_sum_251(c_void_p(buf1359.data_ptr()), c_void_p(alias_69.data_ptr()), c_void_p(buf1357.data_ptr()), c_void_p(buf1358.data_ptr()))
    del alias_69
    buf1360 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1359, (16, 2654208), (1, 16), 0), view_127, out=buf1360)
    del view_127
    buf1361 = buf1354; del buf1354  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1359, (2654208, 16), (16, 1), 0), permute_1589, out=buf1361)
    del permute_1589
    buf1362 = reinterpret_tensor(buf1359, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf1359  # reuse
    cpp_fused_clone_252(c_void_p(buf1361.data_ptr()), c_void_p(buf1362.data_ptr()))
    buf1363 = reinterpret_tensor(buf1350, (128, 48, 576), (27648, 576, 1), 0); del buf1350  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1592, reinterpret_tensor(buf1362, (128, 576, 576), (331776, 576, 1), 0), out=buf1363)
    del permute_1592
    buf1364 = reinterpret_tensor(buf1346, (128, 576, 48), (27648, 48, 1), 0); del buf1346  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1362, (128, 576, 576), (331776, 576, 1), 0), permute_1593, out=buf1364)
    del permute_1593
    buf1365 = buf1322; del buf1322  # reuse
    cpp_fused_clone_253(c_void_p(buf1351.data_ptr()), c_void_p(buf1363.data_ptr()), c_void_p(buf1364.data_ptr()), c_void_p(buf1365.data_ptr()))
    buf1366 = reinterpret_tensor(buf1364, (4608, 768), (768, 1), 0); del buf1364  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1365, (4608, 2304), (2304, 1), 0), permute_1596, out=buf1366)
    del permute_1596
    buf1367 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1365, (2304, 4608), (1, 2304), 0), view_121, out=buf1367)
    del view_121
    buf1368 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf1369 = buf1341; del buf1341  # reuse
    buf1370 = buf1340; del buf1340  # reuse
    buf1371 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1372 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1373 = buf1344; del buf1344  # reuse
    buf1375 = reinterpret_tensor(buf1363, (8, 576, 768), (442368, 768, 1), 0); del buf1363  # reuse
    buf1374 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_254(c_void_p(buf1373.data_ptr()), c_void_p(buf1365.data_ptr()), c_void_p(buf1366.data_ptr()), c_void_p(primals_177.data_ptr()), c_void_p(mul_60.data_ptr()), c_void_p(div_100.data_ptr()), c_void_p(primals_13.data_ptr()), c_void_p(addmm_23.data_ptr()), c_void_p(buf1368.data_ptr()), c_void_p(buf1369.data_ptr()), c_void_p(buf1370.data_ptr()), c_void_p(buf1371.data_ptr()), c_void_p(buf1372.data_ptr()), c_void_p(buf1375.data_ptr()), c_void_p(buf1374.data_ptr()))
    del addmm_23
    del div_100
    del mul_60
    del primals_13
    del primals_177
    buf1376 = reinterpret_tensor(buf1336, (4608, 3072), (3072, 1), 0); del buf1336  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1375, (4608, 768), (768, 1), 0), permute_1600, out=buf1376)
    del permute_1600
    buf1377 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1375, (768, 4608), (1, 768), 0), view_119, out=buf1377)
    del view_119
    buf1378 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1379 = reinterpret_tensor(buf1376, (8, 576, 3072), (1769472, 3072, 1), 0); del buf1376  # reuse
    cpp_fused_gelu_gelu_backward_sum_255(c_void_p(buf1379.data_ptr()), c_void_p(buf1375.data_ptr()), c_void_p(addmm_22.data_ptr()), c_void_p(buf1378.data_ptr()))
    del addmm_22
    buf1380 = reinterpret_tensor(buf1375, (4608, 768), (768, 1), 0); del buf1375  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1379, (4608, 3072), (3072, 1), 0), permute_1604, out=buf1380)
    del permute_1604
    buf1381 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1379, (3072, 4608), (1, 3072), 0), view_117, out=buf1381)
    del view_117
    buf1382 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf1383 = buf1370; del buf1370  # reuse
    buf1384 = buf1369; del buf1369  # reuse
    buf1385 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1386 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1387 = buf1373; del buf1373  # reuse
    buf1389 = reinterpret_tensor(buf1366, (8, 576, 768), (442368, 768, 1), 0); del buf1366  # reuse
    buf1388 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_256(c_void_p(buf1387.data_ptr()), c_void_p(buf1379.data_ptr()), c_void_p(buf1380.data_ptr()), c_void_p(primals_171.data_ptr()), c_void_p(mul_54.data_ptr()), c_void_p(div_101.data_ptr()), c_void_p(primals_12.data_ptr()), c_void_p(addmm_21.data_ptr()), c_void_p(buf1382.data_ptr()), c_void_p(buf1383.data_ptr()), c_void_p(buf1384.data_ptr()), c_void_p(buf1385.data_ptr()), c_void_p(buf1386.data_ptr()), c_void_p(buf1389.data_ptr()), c_void_p(buf1388.data_ptr()))
    del addmm_21
    del div_101
    del mul_54
    del primals_12
    del primals_171
    buf1390 = buf1380; del buf1380  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1389, (4608, 768), (768, 1), 0), permute_1608, out=buf1390)
    del permute_1608
    buf1391 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1389, (768, 4608), (1, 768), 0), view_115, out=buf1391)
    del view_115
    buf1392 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1393 = reinterpret_tensor(buf1351, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf1351  # reuse
    cpp_fused_clone_sum_257(c_void_p(buf1389.data_ptr()), c_void_p(buf1390.data_ptr()), c_void_p(buf1392.data_ptr()), c_void_p(buf1393.data_ptr()))
    buf1394 = reinterpret_tensor(buf1390, (128, 576, 48), (27648, 48, 1), 0); del buf1390  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1613, reinterpret_tensor(buf1393, (128, 576, 48), (27648, 48, 1), 0), out=buf1394)
    del permute_1613
    buf1395 = reinterpret_tensor(buf1362, (128, 576, 576), (331776, 576, 1), 0); del buf1362  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1393, (128, 576, 48), (27648, 48, 1), 0), permute_1614, out=buf1395)
    del permute_1614
    buf1396 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1397 = buf1361; del buf1361  # reuse
    cpp_fused__unsafe_view_clone_sum_258(c_void_p(buf1395.data_ptr()), c_void_p(buf1396.data_ptr()), c_void_p(buf1397.data_ptr()))
    buf1398 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1397, (16, 2654208), (1, 16), 0), view_109, out=buf1398)
    del view_109
    buf1399 = reinterpret_tensor(buf1395, (2654208, 16), (16, 1), 0); del buf1395  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf1397, permute_1618, out=buf1399)
    del permute_1618
    buf1400 = buf1357; del buf1357  # reuse
    buf1401 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1402 = reinterpret_tensor(buf1399, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf1399  # reuse
    cpp_fused__softmax_backward_data_clone_sum_259(c_void_p(buf1402.data_ptr()), c_void_p(alias_70.data_ptr()), c_void_p(buf1400.data_ptr()), c_void_p(buf1401.data_ptr()))
    del alias_70
    buf1403 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1402, (16, 2654208), (1, 16), 0), view_107, out=buf1403)
    del view_107
    buf1404 = buf1397; del buf1397  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1402, (2654208, 16), (16, 1), 0), permute_1624, out=buf1404)
    del permute_1624
    buf1405 = reinterpret_tensor(buf1402, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf1402  # reuse
    cpp_fused_clone_260(c_void_p(buf1404.data_ptr()), c_void_p(buf1405.data_ptr()))
    buf1406 = reinterpret_tensor(buf1393, (128, 48, 576), (27648, 576, 1), 0); del buf1393  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1627, reinterpret_tensor(buf1405, (128, 576, 576), (331776, 576, 1), 0), out=buf1406)
    del permute_1627
    buf1407 = reinterpret_tensor(buf1389, (128, 576, 48), (27648, 48, 1), 0); del buf1389  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1405, (128, 576, 576), (331776, 576, 1), 0), permute_1628, out=buf1407)
    del permute_1628
    buf1408 = buf1365; del buf1365  # reuse
    cpp_fused_clone_261(c_void_p(buf1394.data_ptr()), c_void_p(buf1406.data_ptr()), c_void_p(buf1407.data_ptr()), c_void_p(buf1408.data_ptr()))
    buf1409 = reinterpret_tensor(buf1407, (4608, 768), (768, 1), 0); del buf1407  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1408, (4608, 2304), (2304, 1), 0), permute_1631, out=buf1409)
    del permute_1631
    buf1410 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1408, (2304, 4608), (1, 2304), 0), view_101, out=buf1410)
    del view_101
    buf1411 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf1412 = buf1384; del buf1384  # reuse
    buf1413 = buf1383; del buf1383  # reuse
    buf1414 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1415 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1416 = buf1387; del buf1387  # reuse
    buf1418 = reinterpret_tensor(buf1406, (8, 576, 768), (442368, 768, 1), 0); del buf1406  # reuse
    buf1417 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_262(c_void_p(buf1416.data_ptr()), c_void_p(buf1408.data_ptr()), c_void_p(buf1409.data_ptr()), c_void_p(primals_161.data_ptr()), c_void_p(mul_50.data_ptr()), c_void_p(div_102.data_ptr()), c_void_p(primals_11.data_ptr()), c_void_p(addmm_19.data_ptr()), c_void_p(buf1411.data_ptr()), c_void_p(buf1412.data_ptr()), c_void_p(buf1413.data_ptr()), c_void_p(buf1414.data_ptr()), c_void_p(buf1415.data_ptr()), c_void_p(buf1418.data_ptr()), c_void_p(buf1417.data_ptr()))
    del addmm_19
    del div_102
    del mul_50
    del primals_11
    del primals_161
    buf1419 = reinterpret_tensor(buf1379, (4608, 3072), (3072, 1), 0); del buf1379  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1418, (4608, 768), (768, 1), 0), permute_1635, out=buf1419)
    del permute_1635
    buf1420 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1418, (768, 4608), (1, 768), 0), view_99, out=buf1420)
    del view_99
    buf1421 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1422 = reinterpret_tensor(buf1419, (8, 576, 3072), (1769472, 3072, 1), 0); del buf1419  # reuse
    cpp_fused_gelu_gelu_backward_sum_263(c_void_p(buf1422.data_ptr()), c_void_p(buf1418.data_ptr()), c_void_p(addmm_18.data_ptr()), c_void_p(buf1421.data_ptr()))
    del addmm_18
    buf1423 = reinterpret_tensor(buf1418, (4608, 768), (768, 1), 0); del buf1418  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1422, (4608, 3072), (3072, 1), 0), permute_1639, out=buf1423)
    del permute_1639
    buf1424 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1422, (3072, 4608), (1, 3072), 0), view_97, out=buf1424)
    del view_97
    buf1425 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf1426 = buf1413; del buf1413  # reuse
    buf1427 = buf1412; del buf1412  # reuse
    buf1428 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1429 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1430 = buf1416; del buf1416  # reuse
    buf1432 = reinterpret_tensor(buf1409, (8, 576, 768), (442368, 768, 1), 0); del buf1409  # reuse
    buf1431 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_264(c_void_p(buf1430.data_ptr()), c_void_p(buf1422.data_ptr()), c_void_p(buf1423.data_ptr()), c_void_p(primals_155.data_ptr()), c_void_p(mul_44.data_ptr()), c_void_p(div_103.data_ptr()), c_void_p(primals_10.data_ptr()), c_void_p(addmm_17.data_ptr()), c_void_p(buf1425.data_ptr()), c_void_p(buf1426.data_ptr()), c_void_p(buf1427.data_ptr()), c_void_p(buf1428.data_ptr()), c_void_p(buf1429.data_ptr()), c_void_p(buf1432.data_ptr()), c_void_p(buf1431.data_ptr()))
    del addmm_17
    del div_103
    del mul_44
    del primals_10
    del primals_155
    buf1433 = buf1423; del buf1423  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1432, (4608, 768), (768, 1), 0), permute_1643, out=buf1433)
    del permute_1643
    buf1434 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1432, (768, 4608), (1, 768), 0), view_95, out=buf1434)
    del view_95
    buf1435 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1436 = reinterpret_tensor(buf1394, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf1394  # reuse
    cpp_fused_clone_sum_265(c_void_p(buf1432.data_ptr()), c_void_p(buf1433.data_ptr()), c_void_p(buf1435.data_ptr()), c_void_p(buf1436.data_ptr()))
    buf1437 = reinterpret_tensor(buf1433, (128, 576, 48), (27648, 48, 1), 0); del buf1433  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1648, reinterpret_tensor(buf1436, (128, 576, 48), (27648, 48, 1), 0), out=buf1437)
    del permute_1648
    buf1438 = reinterpret_tensor(buf1405, (128, 576, 576), (331776, 576, 1), 0); del buf1405  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1436, (128, 576, 48), (27648, 48, 1), 0), permute_1649, out=buf1438)
    del permute_1649
    buf1439 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1440 = buf1404; del buf1404  # reuse
    cpp_fused__unsafe_view_clone_sum_266(c_void_p(buf1438.data_ptr()), c_void_p(buf1439.data_ptr()), c_void_p(buf1440.data_ptr()))
    buf1441 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1440, (16, 2654208), (1, 16), 0), view_89, out=buf1441)
    del view_89
    buf1442 = reinterpret_tensor(buf1438, (2654208, 16), (16, 1), 0); del buf1438  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf1440, permute_1653, out=buf1442)
    del permute_1653
    buf1443 = buf1400; del buf1400  # reuse
    buf1444 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1445 = reinterpret_tensor(buf1442, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf1442  # reuse
    cpp_fused__softmax_backward_data_clone_sum_267(c_void_p(buf1445.data_ptr()), c_void_p(alias_71.data_ptr()), c_void_p(buf1443.data_ptr()), c_void_p(buf1444.data_ptr()))
    del alias_71
    buf1446 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1445, (16, 2654208), (1, 16), 0), view_87, out=buf1446)
    del view_87
    buf1447 = buf1440; del buf1440  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1445, (2654208, 16), (16, 1), 0), permute_1659, out=buf1447)
    del permute_1659
    buf1448 = reinterpret_tensor(buf1445, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf1445  # reuse
    cpp_fused_clone_268(c_void_p(buf1447.data_ptr()), c_void_p(buf1448.data_ptr()))
    buf1449 = reinterpret_tensor(buf1436, (128, 48, 576), (27648, 576, 1), 0); del buf1436  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1662, reinterpret_tensor(buf1448, (128, 576, 576), (331776, 576, 1), 0), out=buf1449)
    del permute_1662
    buf1450 = reinterpret_tensor(buf1432, (128, 576, 48), (27648, 48, 1), 0); del buf1432  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1448, (128, 576, 576), (331776, 576, 1), 0), permute_1663, out=buf1450)
    del permute_1663
    buf1451 = buf1408; del buf1408  # reuse
    cpp_fused_clone_269(c_void_p(buf1437.data_ptr()), c_void_p(buf1449.data_ptr()), c_void_p(buf1450.data_ptr()), c_void_p(buf1451.data_ptr()))
    buf1452 = reinterpret_tensor(buf1450, (4608, 768), (768, 1), 0); del buf1450  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1451, (4608, 2304), (2304, 1), 0), permute_1666, out=buf1452)
    del permute_1666
    buf1453 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1451, (2304, 4608), (1, 2304), 0), view_81, out=buf1453)
    del view_81
    buf1454 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf1455 = buf1427; del buf1427  # reuse
    buf1456 = buf1426; del buf1426  # reuse
    buf1457 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1458 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1459 = buf1430; del buf1430  # reuse
    buf1461 = reinterpret_tensor(buf1449, (8, 576, 768), (442368, 768, 1), 0); del buf1449  # reuse
    buf1460 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_270(c_void_p(buf1459.data_ptr()), c_void_p(buf1451.data_ptr()), c_void_p(buf1452.data_ptr()), c_void_p(primals_145.data_ptr()), c_void_p(mul_40.data_ptr()), c_void_p(div_104.data_ptr()), c_void_p(primals_9.data_ptr()), c_void_p(addmm_15.data_ptr()), c_void_p(buf1454.data_ptr()), c_void_p(buf1455.data_ptr()), c_void_p(buf1456.data_ptr()), c_void_p(buf1457.data_ptr()), c_void_p(buf1458.data_ptr()), c_void_p(buf1461.data_ptr()), c_void_p(buf1460.data_ptr()))
    del addmm_15
    del div_104
    del mul_40
    del primals_145
    del primals_9
    buf1462 = reinterpret_tensor(buf1422, (4608, 3072), (3072, 1), 0); del buf1422  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1461, (4608, 768), (768, 1), 0), permute_1670, out=buf1462)
    del permute_1670
    buf1463 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1461, (768, 4608), (1, 768), 0), view_79, out=buf1463)
    del view_79
    buf1464 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1465 = reinterpret_tensor(buf1462, (8, 576, 3072), (1769472, 3072, 1), 0); del buf1462  # reuse
    cpp_fused_gelu_gelu_backward_sum_271(c_void_p(buf1465.data_ptr()), c_void_p(buf1461.data_ptr()), c_void_p(addmm_14.data_ptr()), c_void_p(buf1464.data_ptr()))
    del addmm_14
    buf1466 = reinterpret_tensor(buf1461, (4608, 768), (768, 1), 0); del buf1461  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1465, (4608, 3072), (3072, 1), 0), permute_1674, out=buf1466)
    del permute_1674
    buf1467 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1465, (3072, 4608), (1, 3072), 0), view_77, out=buf1467)
    del view_77
    buf1468 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf1469 = buf1456; del buf1456  # reuse
    buf1470 = buf1455; del buf1455  # reuse
    buf1471 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1472 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1473 = buf1459; del buf1459  # reuse
    buf1475 = reinterpret_tensor(buf1452, (8, 576, 768), (442368, 768, 1), 0); del buf1452  # reuse
    buf1474 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_272(c_void_p(buf1473.data_ptr()), c_void_p(buf1465.data_ptr()), c_void_p(buf1466.data_ptr()), c_void_p(primals_139.data_ptr()), c_void_p(mul_34.data_ptr()), c_void_p(div_105.data_ptr()), c_void_p(primals_8.data_ptr()), c_void_p(addmm_13.data_ptr()), c_void_p(buf1468.data_ptr()), c_void_p(buf1469.data_ptr()), c_void_p(buf1470.data_ptr()), c_void_p(buf1471.data_ptr()), c_void_p(buf1472.data_ptr()), c_void_p(buf1475.data_ptr()), c_void_p(buf1474.data_ptr()))
    del addmm_13
    del div_105
    del mul_34
    del primals_139
    del primals_8
    buf1476 = buf1466; del buf1466  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1475, (4608, 768), (768, 1), 0), permute_1678, out=buf1476)
    del permute_1678
    buf1477 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1475, (768, 4608), (1, 768), 0), view_75, out=buf1477)
    del view_75
    buf1478 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1479 = reinterpret_tensor(buf1437, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf1437  # reuse
    cpp_fused_clone_sum_273(c_void_p(buf1475.data_ptr()), c_void_p(buf1476.data_ptr()), c_void_p(buf1478.data_ptr()), c_void_p(buf1479.data_ptr()))
    buf1480 = reinterpret_tensor(buf1476, (128, 576, 48), (27648, 48, 1), 0); del buf1476  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1683, reinterpret_tensor(buf1479, (128, 576, 48), (27648, 48, 1), 0), out=buf1480)
    del permute_1683
    buf1481 = reinterpret_tensor(buf1448, (128, 576, 576), (331776, 576, 1), 0); del buf1448  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1479, (128, 576, 48), (27648, 48, 1), 0), permute_1684, out=buf1481)
    del permute_1684
    buf1482 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1483 = buf1447; del buf1447  # reuse
    cpp_fused__unsafe_view_clone_sum_274(c_void_p(buf1481.data_ptr()), c_void_p(buf1482.data_ptr()), c_void_p(buf1483.data_ptr()))
    buf1484 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1483, (16, 2654208), (1, 16), 0), view_69, out=buf1484)
    del view_69
    buf1485 = reinterpret_tensor(buf1481, (2654208, 16), (16, 1), 0); del buf1481  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf1483, permute_1688, out=buf1485)
    del permute_1688
    buf1486 = buf1443; del buf1443  # reuse
    buf1487 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1488 = reinterpret_tensor(buf1485, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf1485  # reuse
    cpp_fused__softmax_backward_data_clone_sum_275(c_void_p(buf1488.data_ptr()), c_void_p(alias_72.data_ptr()), c_void_p(buf1486.data_ptr()), c_void_p(buf1487.data_ptr()))
    del alias_72
    buf1489 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1488, (16, 2654208), (1, 16), 0), view_67, out=buf1489)
    del view_67
    buf1490 = buf1483; del buf1483  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1488, (2654208, 16), (16, 1), 0), permute_1694, out=buf1490)
    del permute_1694
    buf1491 = reinterpret_tensor(buf1488, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf1488  # reuse
    cpp_fused_clone_276(c_void_p(buf1490.data_ptr()), c_void_p(buf1491.data_ptr()))
    buf1492 = reinterpret_tensor(buf1479, (128, 48, 576), (27648, 576, 1), 0); del buf1479  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1697, reinterpret_tensor(buf1491, (128, 576, 576), (331776, 576, 1), 0), out=buf1492)
    del permute_1697
    buf1493 = reinterpret_tensor(buf1475, (128, 576, 48), (27648, 48, 1), 0); del buf1475  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1491, (128, 576, 576), (331776, 576, 1), 0), permute_1698, out=buf1493)
    del permute_1698
    buf1494 = buf1451; del buf1451  # reuse
    cpp_fused_clone_277(c_void_p(buf1480.data_ptr()), c_void_p(buf1492.data_ptr()), c_void_p(buf1493.data_ptr()), c_void_p(buf1494.data_ptr()))
    buf1495 = reinterpret_tensor(buf1493, (4608, 768), (768, 1), 0); del buf1493  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1494, (4608, 2304), (2304, 1), 0), permute_1701, out=buf1495)
    del permute_1701
    buf1496 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1494, (2304, 4608), (1, 2304), 0), view_61, out=buf1496)
    del view_61
    buf1497 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf1498 = buf1470; del buf1470  # reuse
    buf1499 = buf1469; del buf1469  # reuse
    buf1500 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1501 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1502 = buf1473; del buf1473  # reuse
    buf1504 = reinterpret_tensor(buf1492, (8, 576, 768), (442368, 768, 1), 0); del buf1492  # reuse
    buf1503 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_278(c_void_p(buf1502.data_ptr()), c_void_p(buf1494.data_ptr()), c_void_p(buf1495.data_ptr()), c_void_p(primals_129.data_ptr()), c_void_p(mul_30.data_ptr()), c_void_p(div_106.data_ptr()), c_void_p(primals_7.data_ptr()), c_void_p(addmm_11.data_ptr()), c_void_p(buf1497.data_ptr()), c_void_p(buf1498.data_ptr()), c_void_p(buf1499.data_ptr()), c_void_p(buf1500.data_ptr()), c_void_p(buf1501.data_ptr()), c_void_p(buf1504.data_ptr()), c_void_p(buf1503.data_ptr()))
    del addmm_11
    del div_106
    del mul_30
    del primals_129
    del primals_7
    buf1505 = reinterpret_tensor(buf1465, (4608, 3072), (3072, 1), 0); del buf1465  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1504, (4608, 768), (768, 1), 0), permute_1705, out=buf1505)
    del permute_1705
    buf1506 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1504, (768, 4608), (1, 768), 0), view_59, out=buf1506)
    del view_59
    buf1507 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1508 = reinterpret_tensor(buf1505, (8, 576, 3072), (1769472, 3072, 1), 0); del buf1505  # reuse
    cpp_fused_gelu_gelu_backward_sum_279(c_void_p(buf1508.data_ptr()), c_void_p(buf1504.data_ptr()), c_void_p(addmm_10.data_ptr()), c_void_p(buf1507.data_ptr()))
    del addmm_10
    buf1509 = reinterpret_tensor(buf1504, (4608, 768), (768, 1), 0); del buf1504  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1508, (4608, 3072), (3072, 1), 0), permute_1709, out=buf1509)
    del permute_1709
    buf1510 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1508, (3072, 4608), (1, 3072), 0), view_57, out=buf1510)
    del view_57
    buf1511 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf1512 = buf1499; del buf1499  # reuse
    buf1513 = buf1498; del buf1498  # reuse
    buf1514 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1515 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1516 = buf1502; del buf1502  # reuse
    buf1518 = reinterpret_tensor(buf1495, (8, 576, 768), (442368, 768, 1), 0); del buf1495  # reuse
    buf1517 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_280(c_void_p(buf1516.data_ptr()), c_void_p(buf1508.data_ptr()), c_void_p(buf1509.data_ptr()), c_void_p(primals_123.data_ptr()), c_void_p(mul_24.data_ptr()), c_void_p(div_107.data_ptr()), c_void_p(primals_6.data_ptr()), c_void_p(addmm_9.data_ptr()), c_void_p(buf1511.data_ptr()), c_void_p(buf1512.data_ptr()), c_void_p(buf1513.data_ptr()), c_void_p(buf1514.data_ptr()), c_void_p(buf1515.data_ptr()), c_void_p(buf1518.data_ptr()), c_void_p(buf1517.data_ptr()))
    del addmm_9
    del div_107
    del mul_24
    del primals_123
    del primals_6
    buf1519 = buf1509; del buf1509  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1518, (4608, 768), (768, 1), 0), permute_1713, out=buf1519)
    del permute_1713
    buf1520 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1518, (768, 4608), (1, 768), 0), view_55, out=buf1520)
    del view_55
    buf1521 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1522 = reinterpret_tensor(buf1480, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf1480  # reuse
    cpp_fused_clone_sum_281(c_void_p(buf1518.data_ptr()), c_void_p(buf1519.data_ptr()), c_void_p(buf1521.data_ptr()), c_void_p(buf1522.data_ptr()))
    buf1523 = reinterpret_tensor(buf1519, (128, 576, 48), (27648, 48, 1), 0); del buf1519  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1718, reinterpret_tensor(buf1522, (128, 576, 48), (27648, 48, 1), 0), out=buf1523)
    del permute_1718
    buf1524 = reinterpret_tensor(buf1491, (128, 576, 576), (331776, 576, 1), 0); del buf1491  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1522, (128, 576, 48), (27648, 48, 1), 0), permute_1719, out=buf1524)
    del permute_1719
    buf1525 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1526 = buf1490; del buf1490  # reuse
    cpp_fused__unsafe_view_clone_sum_282(c_void_p(buf1524.data_ptr()), c_void_p(buf1525.data_ptr()), c_void_p(buf1526.data_ptr()))
    buf1527 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1526, (16, 2654208), (1, 16), 0), view_49, out=buf1527)
    del view_49
    buf1528 = reinterpret_tensor(buf1524, (2654208, 16), (16, 1), 0); del buf1524  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf1526, permute_1723, out=buf1528)
    del permute_1723
    buf1529 = buf1486; del buf1486  # reuse
    buf1530 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1531 = reinterpret_tensor(buf1528, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf1528  # reuse
    cpp_fused__softmax_backward_data_clone_sum_283(c_void_p(buf1531.data_ptr()), c_void_p(alias_73.data_ptr()), c_void_p(buf1529.data_ptr()), c_void_p(buf1530.data_ptr()))
    del alias_73
    buf1532 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1531, (16, 2654208), (1, 16), 0), view_47, out=buf1532)
    del view_47
    buf1533 = buf1526; del buf1526  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1531, (2654208, 16), (16, 1), 0), permute_1729, out=buf1533)
    del permute_1729
    buf1534 = reinterpret_tensor(buf1531, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf1531  # reuse
    cpp_fused_clone_284(c_void_p(buf1533.data_ptr()), c_void_p(buf1534.data_ptr()))
    buf1535 = reinterpret_tensor(buf1522, (128, 48, 576), (27648, 576, 1), 0); del buf1522  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1732, reinterpret_tensor(buf1534, (128, 576, 576), (331776, 576, 1), 0), out=buf1535)
    del permute_1732
    buf1536 = reinterpret_tensor(buf1518, (128, 576, 48), (27648, 48, 1), 0); del buf1518  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1534, (128, 576, 576), (331776, 576, 1), 0), permute_1733, out=buf1536)
    del permute_1733
    buf1537 = buf1494; del buf1494  # reuse
    cpp_fused_clone_285(c_void_p(buf1523.data_ptr()), c_void_p(buf1535.data_ptr()), c_void_p(buf1536.data_ptr()), c_void_p(buf1537.data_ptr()))
    buf1538 = reinterpret_tensor(buf1536, (4608, 768), (768, 1), 0); del buf1536  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1537, (4608, 2304), (2304, 1), 0), permute_1736, out=buf1538)
    del permute_1736
    buf1539 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1537, (2304, 4608), (1, 2304), 0), view_41, out=buf1539)
    del view_41
    buf1540 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf1541 = buf1513; del buf1513  # reuse
    buf1542 = buf1512; del buf1512  # reuse
    buf1543 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1544 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1545 = buf1516; del buf1516  # reuse
    buf1547 = reinterpret_tensor(buf1535, (8, 576, 768), (442368, 768, 1), 0); del buf1535  # reuse
    buf1546 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_286(c_void_p(buf1545.data_ptr()), c_void_p(buf1537.data_ptr()), c_void_p(buf1538.data_ptr()), c_void_p(primals_113.data_ptr()), c_void_p(mul_20.data_ptr()), c_void_p(div_108.data_ptr()), c_void_p(primals_5.data_ptr()), c_void_p(addmm_7.data_ptr()), c_void_p(buf1540.data_ptr()), c_void_p(buf1541.data_ptr()), c_void_p(buf1542.data_ptr()), c_void_p(buf1543.data_ptr()), c_void_p(buf1544.data_ptr()), c_void_p(buf1547.data_ptr()), c_void_p(buf1546.data_ptr()))
    del addmm_7
    del div_108
    del mul_20
    del primals_113
    del primals_5
    buf1548 = reinterpret_tensor(buf1508, (4608, 3072), (3072, 1), 0); del buf1508  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1547, (4608, 768), (768, 1), 0), permute_1740, out=buf1548)
    del permute_1740
    buf1549 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1547, (768, 4608), (1, 768), 0), view_39, out=buf1549)
    del view_39
    buf1550 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1551 = reinterpret_tensor(buf1548, (8, 576, 3072), (1769472, 3072, 1), 0); del buf1548  # reuse
    cpp_fused_gelu_gelu_backward_sum_287(c_void_p(buf1551.data_ptr()), c_void_p(buf1547.data_ptr()), c_void_p(addmm_6.data_ptr()), c_void_p(buf1550.data_ptr()))
    del addmm_6
    buf1552 = reinterpret_tensor(buf1547, (4608, 768), (768, 1), 0); del buf1547  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1551, (4608, 3072), (3072, 1), 0), permute_1744, out=buf1552)
    del permute_1744
    buf1553 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1551, (3072, 4608), (1, 3072), 0), view_37, out=buf1553)
    del view_37
    buf1554 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf1555 = buf1542; del buf1542  # reuse
    buf1556 = buf1541; del buf1541  # reuse
    buf1557 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1558 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1559 = buf1545; del buf1545  # reuse
    buf1561 = reinterpret_tensor(buf1538, (8, 576, 768), (442368, 768, 1), 0); del buf1538  # reuse
    buf1560 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_288(c_void_p(buf1559.data_ptr()), c_void_p(buf1551.data_ptr()), c_void_p(buf1552.data_ptr()), c_void_p(primals_107.data_ptr()), c_void_p(mul_14.data_ptr()), c_void_p(div_109.data_ptr()), c_void_p(primals_4.data_ptr()), c_void_p(addmm_5.data_ptr()), c_void_p(buf1554.data_ptr()), c_void_p(buf1555.data_ptr()), c_void_p(buf1556.data_ptr()), c_void_p(buf1557.data_ptr()), c_void_p(buf1558.data_ptr()), c_void_p(buf1561.data_ptr()), c_void_p(buf1560.data_ptr()))
    del addmm_5
    del div_109
    del mul_14
    del primals_107
    del primals_4
    buf1562 = buf1552; del buf1552  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1561, (4608, 768), (768, 1), 0), permute_1748, out=buf1562)
    del permute_1748
    buf1563 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1561, (768, 4608), (1, 768), 0), view_35, out=buf1563)
    del view_35
    buf1564 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1565 = reinterpret_tensor(buf1523, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf1523  # reuse
    cpp_fused_clone_sum_289(c_void_p(buf1561.data_ptr()), c_void_p(buf1562.data_ptr()), c_void_p(buf1564.data_ptr()), c_void_p(buf1565.data_ptr()))
    buf1566 = reinterpret_tensor(buf1562, (128, 576, 48), (27648, 48, 1), 0); del buf1562  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1753, reinterpret_tensor(buf1565, (128, 576, 48), (27648, 48, 1), 0), out=buf1566)
    del permute_1753
    buf1567 = reinterpret_tensor(buf1534, (128, 576, 576), (331776, 576, 1), 0); del buf1534  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1565, (128, 576, 48), (27648, 48, 1), 0), permute_1754, out=buf1567)
    del permute_1754
    buf1568 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1569 = buf1533; del buf1533  # reuse
    cpp_fused__unsafe_view_clone_sum_290(c_void_p(buf1567.data_ptr()), c_void_p(buf1568.data_ptr()), c_void_p(buf1569.data_ptr()))
    buf1570 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1569, (16, 2654208), (1, 16), 0), view_29, out=buf1570)
    del view_29
    buf1571 = reinterpret_tensor(buf1567, (2654208, 16), (16, 1), 0); del buf1567  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf1569, permute_1758, out=buf1571)
    del permute_1758
    buf1572 = buf1529; del buf1529  # reuse
    buf1573 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1574 = reinterpret_tensor(buf1571, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf1571  # reuse
    cpp_fused__softmax_backward_data_clone_sum_291(c_void_p(buf1574.data_ptr()), c_void_p(alias_74.data_ptr()), c_void_p(buf1572.data_ptr()), c_void_p(buf1573.data_ptr()))
    del alias_74
    buf1575 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1574, (16, 2654208), (1, 16), 0), view_27, out=buf1575)
    del view_27
    buf1576 = buf1569; del buf1569  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1574, (2654208, 16), (16, 1), 0), permute_1764, out=buf1576)
    del permute_1764
    buf1577 = reinterpret_tensor(buf1574, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf1574  # reuse
    cpp_fused_clone_292(c_void_p(buf1576.data_ptr()), c_void_p(buf1577.data_ptr()))
    buf1578 = reinterpret_tensor(buf1565, (128, 48, 576), (27648, 576, 1), 0); del buf1565  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1767, reinterpret_tensor(buf1577, (128, 576, 576), (331776, 576, 1), 0), out=buf1578)
    del permute_1767
    buf1579 = reinterpret_tensor(buf1561, (128, 576, 48), (27648, 48, 1), 0); del buf1561  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1577, (128, 576, 576), (331776, 576, 1), 0), permute_1768, out=buf1579)
    del permute_1768
    buf1580 = buf1537; del buf1537  # reuse
    cpp_fused_clone_293(c_void_p(buf1566.data_ptr()), c_void_p(buf1578.data_ptr()), c_void_p(buf1579.data_ptr()), c_void_p(buf1580.data_ptr()))
    buf1581 = reinterpret_tensor(buf1579, (4608, 768), (768, 1), 0); del buf1579  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1580, (4608, 2304), (2304, 1), 0), permute_1771, out=buf1581)
    del permute_1771
    buf1582 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1580, (2304, 4608), (1, 2304), 0), view_21, out=buf1582)
    del view_21
    buf1583 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf1584 = buf1556; del buf1556  # reuse
    buf1585 = buf1555; del buf1555  # reuse
    buf1586 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1587 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1588 = buf1559; del buf1559  # reuse
    buf1590 = reinterpret_tensor(buf1578, (8, 576, 768), (442368, 768, 1), 0); del buf1578  # reuse
    buf1589 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_294(c_void_p(buf1588.data_ptr()), c_void_p(buf1580.data_ptr()), c_void_p(buf1581.data_ptr()), c_void_p(primals_97.data_ptr()), c_void_p(mul_10.data_ptr()), c_void_p(div_110.data_ptr()), c_void_p(primals_3.data_ptr()), c_void_p(addmm_3.data_ptr()), c_void_p(buf1583.data_ptr()), c_void_p(buf1584.data_ptr()), c_void_p(buf1585.data_ptr()), c_void_p(buf1586.data_ptr()), c_void_p(buf1587.data_ptr()), c_void_p(buf1590.data_ptr()), c_void_p(buf1589.data_ptr()))
    del addmm_3
    del div_110
    del mul_10
    del primals_3
    del primals_97
    buf1591 = reinterpret_tensor(buf1551, (4608, 3072), (3072, 1), 0); del buf1551  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1590, (4608, 768), (768, 1), 0), permute_1775, out=buf1591)
    del permute_1775
    buf1592 = empty((768, 3072), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1590, (768, 4608), (1, 768), 0), view_19, out=buf1592)
    del view_19
    buf1593 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1594 = reinterpret_tensor(buf1591, (8, 576, 3072), (1769472, 3072, 1), 0); del buf1591  # reuse
    cpp_fused_gelu_gelu_backward_sum_295(c_void_p(buf1594.data_ptr()), c_void_p(buf1590.data_ptr()), c_void_p(addmm_2.data_ptr()), c_void_p(buf1593.data_ptr()))
    del addmm_2
    buf1595 = reinterpret_tensor(buf1590, (4608, 768), (768, 1), 0); del buf1590  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1594, (4608, 3072), (3072, 1), 0), permute_1779, out=buf1595)
    del permute_1779
    buf1596 = empty((3072, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1594, (3072, 4608), (1, 3072), 0), view_17, out=buf1596)
    del view_17
    buf1597 = empty((1, 3072), device='cpu', dtype=torch.float32)
    buf1598 = buf1585; del buf1585  # reuse
    buf1599 = buf1584; del buf1584  # reuse
    buf1600 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1601 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1602 = buf1588; del buf1588  # reuse
    buf1604 = reinterpret_tensor(buf1581, (8, 576, 768), (442368, 768, 1), 0); del buf1581  # reuse
    buf1603 = empty((1, 1, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_mul_native_layer_norm_backward_sum_296(c_void_p(buf1602.data_ptr()), c_void_p(buf1594.data_ptr()), c_void_p(buf1595.data_ptr()), c_void_p(primals_91.data_ptr()), c_void_p(mul_4.data_ptr()), c_void_p(div_111.data_ptr()), c_void_p(primals_2.data_ptr()), c_void_p(addmm_1.data_ptr()), c_void_p(buf1597.data_ptr()), c_void_p(buf1598.data_ptr()), c_void_p(buf1599.data_ptr()), c_void_p(buf1600.data_ptr()), c_void_p(buf1601.data_ptr()), c_void_p(buf1604.data_ptr()), c_void_p(buf1603.data_ptr()))
    del addmm_1
    del buf1594
    del div_111
    del mul_4
    del primals_2
    del primals_91
    buf1605 = buf1595; del buf1595  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1604, (4608, 768), (768, 1), 0), permute_1783, out=buf1605)
    del permute_1783
    buf1606 = empty((768, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1604, (768, 4608), (1, 768), 0), view_15, out=buf1606)
    del view_15
    buf1607 = empty((1, 768), device='cpu', dtype=torch.float32)
    buf1608 = reinterpret_tensor(buf1566, (8, 16, 576, 48), (442368, 27648, 48, 1), 0); del buf1566  # reuse
    cpp_fused_clone_sum_297(c_void_p(buf1604.data_ptr()), c_void_p(buf1605.data_ptr()), c_void_p(buf1607.data_ptr()), c_void_p(buf1608.data_ptr()))
    buf1609 = reinterpret_tensor(buf1605, (128, 576, 48), (27648, 48, 1), 0); del buf1605  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1788, reinterpret_tensor(buf1608, (128, 576, 48), (27648, 48, 1), 0), out=buf1609)
    del permute_1788
    buf1610 = reinterpret_tensor(buf1577, (128, 576, 576), (331776, 576, 1), 0); del buf1577  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1608, (128, 576, 48), (27648, 48, 1), 0), permute_1789, out=buf1610)
    del permute_1789
    buf1611 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1612 = buf1576; del buf1576  # reuse
    cpp_fused__unsafe_view_clone_sum_298(c_void_p(buf1610.data_ptr()), c_void_p(buf1611.data_ptr()), c_void_p(buf1612.data_ptr()))
    buf1613 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1612, (16, 2654208), (1, 16), 0), view_9, out=buf1613)
    del view_9
    buf1614 = reinterpret_tensor(buf1610, (2654208, 16), (16, 1), 0); del buf1610  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(buf1612, permute_1793, out=buf1614)
    del permute_1793
    buf1615 = buf1572; del buf1572  # reuse
    buf1616 = empty((1, 1, 1, 16), device='cpu', dtype=torch.float32)
    buf1617 = reinterpret_tensor(buf1614, (8, 576, 576, 16), (5308416, 9216, 16, 1), 0); del buf1614  # reuse
    cpp_fused__softmax_backward_data_clone_sum_299(c_void_p(buf1617.data_ptr()), c_void_p(alias_75.data_ptr()), c_void_p(buf1615.data_ptr()), c_void_p(buf1616.data_ptr()))
    del alias_75
    del buf1615
    buf1618 = empty((16, 16), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1617, (16, 2654208), (1, 16), 0), view_7, out=buf1618)
    del view_7
    buf1619 = buf1612; del buf1612  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1617, (2654208, 16), (16, 1), 0), permute_1799, out=buf1619)
    del permute_1799
    buf1620 = reinterpret_tensor(buf1617, (8, 16, 576, 576), (5308416, 331776, 576, 1), 0); del buf1617  # reuse
    cpp_fused_clone_300(c_void_p(buf1619.data_ptr()), c_void_p(buf1620.data_ptr()))
    del buf1619
    buf1621 = reinterpret_tensor(buf1608, (128, 48, 576), (27648, 576, 1), 0); del buf1608  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(permute_1802, reinterpret_tensor(buf1620, (128, 576, 576), (331776, 576, 1), 0), out=buf1621)
    del permute_1802
    buf1622 = reinterpret_tensor(buf1604, (128, 576, 48), (27648, 48, 1), 0); del buf1604  # reuse
    # Source Nodes: [], Original ATen: [aten.bmm]
    extern_kernels.bmm(reinterpret_tensor(buf1620, (128, 576, 576), (331776, 576, 1), 0), permute_1803, out=buf1622)
    del buf1620
    del permute_1803
    buf1623 = buf1580; del buf1580  # reuse
    cpp_fused_clone_301(c_void_p(buf1609.data_ptr()), c_void_p(buf1621.data_ptr()), c_void_p(buf1622.data_ptr()), c_void_p(buf1623.data_ptr()))
    del buf1609
    del buf1621
    buf1624 = reinterpret_tensor(buf1622, (4608, 768), (768, 1), 0); del buf1622  # reuse
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1623, (4608, 2304), (2304, 1), 0), permute_1806, out=buf1624)
    del permute_1806
    buf1625 = empty((2304, 768), device='cpu', dtype=torch.float32)
    # Source Nodes: [], Original ATen: [aten.mm]
    extern_kernels.mm(reinterpret_tensor(buf1623, (2304, 4608), (1, 2304), 0), view_1, out=buf1625)
    del view_1
    buf1626 = empty((1, 2304), device='cpu', dtype=torch.float32)
    buf1627 = buf1599; del buf1599  # reuse
    buf1628 = buf1598; del buf1598  # reuse
    buf1629 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1630 = empty((768, ), device='cpu', dtype=torch.float32)
    buf1631 = buf1602; del buf1602  # reuse
    buf1632 = empty((1, 576, 768), device='cpu', dtype=torch.float32)
    cpp_fused_add_native_layer_norm_backward_sum_302(c_void_p(buf1631.data_ptr()), c_void_p(buf1623.data_ptr()), c_void_p(buf1624.data_ptr()), c_void_p(primals_81.data_ptr()), c_void_p(mul.data_ptr()), c_void_p(div_112.data_ptr()), c_void_p(buf1626.data_ptr()), c_void_p(buf1627.data_ptr()), c_void_p(buf1628.data_ptr()), c_void_p(buf1629.data_ptr()), c_void_p(buf1630.data_ptr()), c_void_p(buf1632.data_ptr()))
    del buf1623
    del buf1624
    del buf1627
    del buf1628
    del div_112
    del mul
    del primals_81
    # Source Nodes: [], Original ATen: [aten.convolution_backward]
    buf1633 = aten.convolution_backward(reinterpret_tensor(buf1631, (8, 768, 24, 24), (442368, 1, 18432, 768), 0), primals_693, primals_79, [768], [16, 16], [0, 0], [1, 1], False, [0, 0], 1, [False, True, True])
    del buf1631
    del primals_693
    del primals_79
    buf1634 = buf1633[1]
    buf1635 = buf1633[2]
    return (buf1632, reinterpret_tensor(buf1603, (768, ), (1, ), 0), reinterpret_tensor(buf1589, (768, ), (1, ), 0), reinterpret_tensor(buf1560, (768, ), (1, ), 0), reinterpret_tensor(buf1546, (768, ), (1, ), 0), reinterpret_tensor(buf1517, (768, ), (1, ), 0), reinterpret_tensor(buf1503, (768, ), (1, ), 0), reinterpret_tensor(buf1474, (768, ), (1, ), 0), reinterpret_tensor(buf1460, (768, ), (1, ), 0), reinterpret_tensor(buf1431, (768, ), (1, ), 0), reinterpret_tensor(buf1417, (768, ), (1, ), 0), reinterpret_tensor(buf1388, (768, ), (1, ), 0), reinterpret_tensor(buf1374, (768, ), (1, ), 0), reinterpret_tensor(buf1345, (768, ), (1, ), 0), reinterpret_tensor(buf1331, (768, ), (1, ), 0), reinterpret_tensor(buf1302, (768, ), (1, ), 0), reinterpret_tensor(buf1288, (768, ), (1, ), 0), reinterpret_tensor(buf1259, (768, ), (1, ), 0), reinterpret_tensor(buf1245, (768, ), (1, ), 0), reinterpret_tensor(buf1216, (768, ), (1, ), 0), reinterpret_tensor(buf1202, (768, ), (1, ), 0), reinterpret_tensor(buf1173, (768, ), (1, ), 0), reinterpret_tensor(buf1159, (768, ), (1, ), 0), reinterpret_tensor(buf1130, (768, ), (1, ), 0), reinterpret_tensor(buf1116, (768, ), (1, ), 0), reinterpret_tensor(buf1087, (768, ), (1, ), 0), reinterpret_tensor(buf1073, (768, ), (1, ), 0), reinterpret_tensor(buf1044, (768, ), (1, ), 0), reinterpret_tensor(buf1030, (768, ), (1, ), 0), reinterpret_tensor(buf1001, (768, ), (1, ), 0), reinterpret_tensor(buf987, (768, ), (1, ), 0), reinterpret_tensor(buf958, (768, ), (1, ), 0), reinterpret_tensor(buf944, (768, ), (1, ), 0), reinterpret_tensor(buf915, (768, ), (1, ), 0), reinterpret_tensor(buf901, (768, ), (1, ), 0), reinterpret_tensor(buf872, (768, ), (1, ), 0), reinterpret_tensor(buf858, (768, ), (1, ), 0), reinterpret_tensor(buf829, (768, ), (1, ), 0), reinterpret_tensor(buf815, (768, ), (1, ), 0), reinterpret_tensor(buf786, (768, ), (1, ), 0), reinterpret_tensor(buf772, (768, ), (1, ), 0), reinterpret_tensor(buf743, (768, ), (1, ), 0), reinterpret_tensor(buf729, (768, ), (1, ), 0), reinterpret_tensor(buf700, (768, ), (1, ), 0), reinterpret_tensor(buf686, (768, ), (1, ), 0), reinterpret_tensor(buf657, (768, ), (1, ), 0), reinterpret_tensor(buf643, (768, ), (1, ), 0), reinterpret_tensor(buf614, (768, ), (1, ), 0), reinterpret_tensor(buf600, (768, ), (1, ), 0), reinterpret_tensor(buf571, (768, ), (1, ), 0), reinterpret_tensor(buf557, (768, ), (1, ), 0), reinterpret_tensor(buf528, (768, ), (1, ), 0), reinterpret_tensor(buf514, (768, ), (1, ), 0), reinterpret_tensor(buf485, (768, ), (1, ), 0), reinterpret_tensor(buf471, (768, ), (1, ), 0), reinterpret_tensor(buf442, (768, ), (1, ), 0), reinterpret_tensor(buf428, (768, ), (1, ), 0), reinterpret_tensor(buf399, (768, ), (1, ), 0), reinterpret_tensor(buf385, (768, ), (1, ), 0), reinterpret_tensor(buf356, (768, ), (1, ), 0), reinterpret_tensor(buf342, (768, ), (1, ), 0), reinterpret_tensor(buf313, (768, ), (1, ), 0), reinterpret_tensor(buf299, (768, ), (1, ), 0), reinterpret_tensor(buf270, (768, ), (1, ), 0), reinterpret_tensor(buf256, (768, ), (1, ), 0), reinterpret_tensor(buf227, (768, ), (1, ), 0), reinterpret_tensor(buf213, (768, ), (1, ), 0), reinterpret_tensor(buf184, (768, ), (1, ), 0), reinterpret_tensor(buf170, (768, ), (1, ), 0), reinterpret_tensor(buf141, (768, ), (1, ), 0), reinterpret_tensor(buf127, (768, ), (1, ), 0), reinterpret_tensor(buf98, (768, ), (1, ), 0), reinterpret_tensor(buf84, (768, ), (1, ), 0), buf83, reinterpret_tensor(buf59, (768, ), (1, ), 0), reinterpret_tensor(buf45, (768, ), (1, ), 0), reinterpret_tensor(buf22, (768, ), (1, ), 0), reinterpret_tensor(buf8, (768, ), (1, ), 0), buf1634, buf1635, buf1629, buf1630, reinterpret_tensor(buf1625, (2304, 768), (768, 1), 0), reinterpret_tensor(buf1626, (2304, ), (1, ), 0), reinterpret_tensor(buf1618, (16, 16), (16, 1), 0), reinterpret_tensor(buf1616, (16, ), (1, ), 0), reinterpret_tensor(buf1613, (16, 16), (16, 1), 0), reinterpret_tensor(buf1611, (16, ), (1, ), 0), reinterpret_tensor(buf1606, (768, 768), (768, 1), 0), reinterpret_tensor(buf1607, (768, ), (1, ), 0), buf1600, buf1601, reinterpret_tensor(buf1596, (3072, 768), (768, 1), 0), reinterpret_tensor(buf1597, (3072, ), (1, ), 0), reinterpret_tensor(buf1592, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf1593, (768, ), (1, ), 0), buf1586, buf1587, reinterpret_tensor(buf1582, (2304, 768), (768, 1), 0), reinterpret_tensor(buf1583, (2304, ), (1, ), 0), reinterpret_tensor(buf1575, (16, 16), (16, 1), 0), reinterpret_tensor(buf1573, (16, ), (1, ), 0), reinterpret_tensor(buf1570, (16, 16), (16, 1), 0), reinterpret_tensor(buf1568, (16, ), (1, ), 0), reinterpret_tensor(buf1563, (768, 768), (768, 1), 0), reinterpret_tensor(buf1564, (768, ), (1, ), 0), buf1557, buf1558, reinterpret_tensor(buf1553, (3072, 768), (768, 1), 0), reinterpret_tensor(buf1554, (3072, ), (1, ), 0), reinterpret_tensor(buf1549, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf1550, (768, ), (1, ), 0), buf1543, buf1544, reinterpret_tensor(buf1539, (2304, 768), (768, 1), 0), reinterpret_tensor(buf1540, (2304, ), (1, ), 0), reinterpret_tensor(buf1532, (16, 16), (16, 1), 0), reinterpret_tensor(buf1530, (16, ), (1, ), 0), reinterpret_tensor(buf1527, (16, 16), (16, 1), 0), reinterpret_tensor(buf1525, (16, ), (1, ), 0), reinterpret_tensor(buf1520, (768, 768), (768, 1), 0), reinterpret_tensor(buf1521, (768, ), (1, ), 0), buf1514, buf1515, reinterpret_tensor(buf1510, (3072, 768), (768, 1), 0), reinterpret_tensor(buf1511, (3072, ), (1, ), 0), reinterpret_tensor(buf1506, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf1507, (768, ), (1, ), 0), buf1500, buf1501, reinterpret_tensor(buf1496, (2304, 768), (768, 1), 0), reinterpret_tensor(buf1497, (2304, ), (1, ), 0), reinterpret_tensor(buf1489, (16, 16), (16, 1), 0), reinterpret_tensor(buf1487, (16, ), (1, ), 0), reinterpret_tensor(buf1484, (16, 16), (16, 1), 0), reinterpret_tensor(buf1482, (16, ), (1, ), 0), reinterpret_tensor(buf1477, (768, 768), (768, 1), 0), reinterpret_tensor(buf1478, (768, ), (1, ), 0), buf1471, buf1472, reinterpret_tensor(buf1467, (3072, 768), (768, 1), 0), reinterpret_tensor(buf1468, (3072, ), (1, ), 0), reinterpret_tensor(buf1463, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf1464, (768, ), (1, ), 0), buf1457, buf1458, reinterpret_tensor(buf1453, (2304, 768), (768, 1), 0), reinterpret_tensor(buf1454, (2304, ), (1, ), 0), reinterpret_tensor(buf1446, (16, 16), (16, 1), 0), reinterpret_tensor(buf1444, (16, ), (1, ), 0), reinterpret_tensor(buf1441, (16, 16), (16, 1), 0), reinterpret_tensor(buf1439, (16, ), (1, ), 0), reinterpret_tensor(buf1434, (768, 768), (768, 1), 0), reinterpret_tensor(buf1435, (768, ), (1, ), 0), buf1428, buf1429, reinterpret_tensor(buf1424, (3072, 768), (768, 1), 0), reinterpret_tensor(buf1425, (3072, ), (1, ), 0), reinterpret_tensor(buf1420, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf1421, (768, ), (1, ), 0), buf1414, buf1415, reinterpret_tensor(buf1410, (2304, 768), (768, 1), 0), reinterpret_tensor(buf1411, (2304, ), (1, ), 0), reinterpret_tensor(buf1403, (16, 16), (16, 1), 0), reinterpret_tensor(buf1401, (16, ), (1, ), 0), reinterpret_tensor(buf1398, (16, 16), (16, 1), 0), reinterpret_tensor(buf1396, (16, ), (1, ), 0), reinterpret_tensor(buf1391, (768, 768), (768, 1), 0), reinterpret_tensor(buf1392, (768, ), (1, ), 0), buf1385, buf1386, reinterpret_tensor(buf1381, (3072, 768), (768, 1), 0), reinterpret_tensor(buf1382, (3072, ), (1, ), 0), reinterpret_tensor(buf1377, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf1378, (768, ), (1, ), 0), buf1371, buf1372, reinterpret_tensor(buf1367, (2304, 768), (768, 1), 0), reinterpret_tensor(buf1368, (2304, ), (1, ), 0), reinterpret_tensor(buf1360, (16, 16), (16, 1), 0), reinterpret_tensor(buf1358, (16, ), (1, ), 0), reinterpret_tensor(buf1355, (16, 16), (16, 1), 0), reinterpret_tensor(buf1353, (16, ), (1, ), 0), reinterpret_tensor(buf1348, (768, 768), (768, 1), 0), reinterpret_tensor(buf1349, (768, ), (1, ), 0), buf1342, buf1343, reinterpret_tensor(buf1338, (3072, 768), (768, 1), 0), reinterpret_tensor(buf1339, (3072, ), (1, ), 0), reinterpret_tensor(buf1334, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf1335, (768, ), (1, ), 0), buf1328, buf1329, reinterpret_tensor(buf1324, (2304, 768), (768, 1), 0), reinterpret_tensor(buf1325, (2304, ), (1, ), 0), reinterpret_tensor(buf1317, (16, 16), (16, 1), 0), reinterpret_tensor(buf1315, (16, ), (1, ), 0), reinterpret_tensor(buf1312, (16, 16), (16, 1), 0), reinterpret_tensor(buf1310, (16, ), (1, ), 0), reinterpret_tensor(buf1305, (768, 768), (768, 1), 0), reinterpret_tensor(buf1306, (768, ), (1, ), 0), buf1299, buf1300, reinterpret_tensor(buf1295, (3072, 768), (768, 1), 0), reinterpret_tensor(buf1296, (3072, ), (1, ), 0), reinterpret_tensor(buf1291, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf1292, (768, ), (1, ), 0), buf1285, buf1286, reinterpret_tensor(buf1281, (2304, 768), (768, 1), 0), reinterpret_tensor(buf1282, (2304, ), (1, ), 0), reinterpret_tensor(buf1274, (16, 16), (16, 1), 0), reinterpret_tensor(buf1272, (16, ), (1, ), 0), reinterpret_tensor(buf1269, (16, 16), (16, 1), 0), reinterpret_tensor(buf1267, (16, ), (1, ), 0), reinterpret_tensor(buf1262, (768, 768), (768, 1), 0), reinterpret_tensor(buf1263, (768, ), (1, ), 0), buf1256, buf1257, reinterpret_tensor(buf1252, (3072, 768), (768, 1), 0), reinterpret_tensor(buf1253, (3072, ), (1, ), 0), reinterpret_tensor(buf1248, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf1249, (768, ), (1, ), 0), buf1242, buf1243, reinterpret_tensor(buf1238, (2304, 768), (768, 1), 0), reinterpret_tensor(buf1239, (2304, ), (1, ), 0), reinterpret_tensor(buf1231, (16, 16), (16, 1), 0), reinterpret_tensor(buf1229, (16, ), (1, ), 0), reinterpret_tensor(buf1226, (16, 16), (16, 1), 0), reinterpret_tensor(buf1224, (16, ), (1, ), 0), reinterpret_tensor(buf1219, (768, 768), (768, 1), 0), reinterpret_tensor(buf1220, (768, ), (1, ), 0), buf1213, buf1214, reinterpret_tensor(buf1209, (3072, 768), (768, 1), 0), reinterpret_tensor(buf1210, (3072, ), (1, ), 0), reinterpret_tensor(buf1205, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf1206, (768, ), (1, ), 0), buf1199, buf1200, reinterpret_tensor(buf1195, (2304, 768), (768, 1), 0), reinterpret_tensor(buf1196, (2304, ), (1, ), 0), reinterpret_tensor(buf1188, (16, 16), (16, 1), 0), reinterpret_tensor(buf1186, (16, ), (1, ), 0), reinterpret_tensor(buf1183, (16, 16), (16, 1), 0), reinterpret_tensor(buf1181, (16, ), (1, ), 0), reinterpret_tensor(buf1176, (768, 768), (768, 1), 0), reinterpret_tensor(buf1177, (768, ), (1, ), 0), buf1170, buf1171, reinterpret_tensor(buf1166, (3072, 768), (768, 1), 0), reinterpret_tensor(buf1167, (3072, ), (1, ), 0), reinterpret_tensor(buf1162, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf1163, (768, ), (1, ), 0), buf1156, buf1157, reinterpret_tensor(buf1152, (2304, 768), (768, 1), 0), reinterpret_tensor(buf1153, (2304, ), (1, ), 0), reinterpret_tensor(buf1145, (16, 16), (16, 1), 0), reinterpret_tensor(buf1143, (16, ), (1, ), 0), reinterpret_tensor(buf1140, (16, 16), (16, 1), 0), reinterpret_tensor(buf1138, (16, ), (1, ), 0), reinterpret_tensor(buf1133, (768, 768), (768, 1), 0), reinterpret_tensor(buf1134, (768, ), (1, ), 0), buf1127, buf1128, reinterpret_tensor(buf1123, (3072, 768), (768, 1), 0), reinterpret_tensor(buf1124, (3072, ), (1, ), 0), reinterpret_tensor(buf1119, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf1120, (768, ), (1, ), 0), buf1113, buf1114, reinterpret_tensor(buf1109, (2304, 768), (768, 1), 0), reinterpret_tensor(buf1110, (2304, ), (1, ), 0), reinterpret_tensor(buf1102, (16, 16), (16, 1), 0), reinterpret_tensor(buf1100, (16, ), (1, ), 0), reinterpret_tensor(buf1097, (16, 16), (16, 1), 0), reinterpret_tensor(buf1095, (16, ), (1, ), 0), reinterpret_tensor(buf1090, (768, 768), (768, 1), 0), reinterpret_tensor(buf1091, (768, ), (1, ), 0), buf1084, buf1085, reinterpret_tensor(buf1080, (3072, 768), (768, 1), 0), reinterpret_tensor(buf1081, (3072, ), (1, ), 0), reinterpret_tensor(buf1076, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf1077, (768, ), (1, ), 0), buf1070, buf1071, reinterpret_tensor(buf1066, (2304, 768), (768, 1), 0), reinterpret_tensor(buf1067, (2304, ), (1, ), 0), reinterpret_tensor(buf1059, (16, 16), (16, 1), 0), reinterpret_tensor(buf1057, (16, ), (1, ), 0), reinterpret_tensor(buf1054, (16, 16), (16, 1), 0), reinterpret_tensor(buf1052, (16, ), (1, ), 0), reinterpret_tensor(buf1047, (768, 768), (768, 1), 0), reinterpret_tensor(buf1048, (768, ), (1, ), 0), buf1041, buf1042, reinterpret_tensor(buf1037, (3072, 768), (768, 1), 0), reinterpret_tensor(buf1038, (3072, ), (1, ), 0), reinterpret_tensor(buf1033, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf1034, (768, ), (1, ), 0), buf1027, buf1028, reinterpret_tensor(buf1023, (2304, 768), (768, 1), 0), reinterpret_tensor(buf1024, (2304, ), (1, ), 0), reinterpret_tensor(buf1016, (16, 16), (16, 1), 0), reinterpret_tensor(buf1014, (16, ), (1, ), 0), reinterpret_tensor(buf1011, (16, 16), (16, 1), 0), reinterpret_tensor(buf1009, (16, ), (1, ), 0), reinterpret_tensor(buf1004, (768, 768), (768, 1), 0), reinterpret_tensor(buf1005, (768, ), (1, ), 0), buf998, buf999, reinterpret_tensor(buf994, (3072, 768), (768, 1), 0), reinterpret_tensor(buf995, (3072, ), (1, ), 0), reinterpret_tensor(buf990, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf991, (768, ), (1, ), 0), buf984, buf985, reinterpret_tensor(buf980, (2304, 768), (768, 1), 0), reinterpret_tensor(buf981, (2304, ), (1, ), 0), reinterpret_tensor(buf973, (16, 16), (16, 1), 0), reinterpret_tensor(buf971, (16, ), (1, ), 0), reinterpret_tensor(buf968, (16, 16), (16, 1), 0), reinterpret_tensor(buf966, (16, ), (1, ), 0), reinterpret_tensor(buf961, (768, 768), (768, 1), 0), reinterpret_tensor(buf962, (768, ), (1, ), 0), buf955, buf956, reinterpret_tensor(buf951, (3072, 768), (768, 1), 0), reinterpret_tensor(buf952, (3072, ), (1, ), 0), reinterpret_tensor(buf947, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf948, (768, ), (1, ), 0), buf941, buf942, reinterpret_tensor(buf937, (2304, 768), (768, 1), 0), reinterpret_tensor(buf938, (2304, ), (1, ), 0), reinterpret_tensor(buf930, (16, 16), (16, 1), 0), reinterpret_tensor(buf928, (16, ), (1, ), 0), reinterpret_tensor(buf925, (16, 16), (16, 1), 0), reinterpret_tensor(buf923, (16, ), (1, ), 0), reinterpret_tensor(buf918, (768, 768), (768, 1), 0), reinterpret_tensor(buf919, (768, ), (1, ), 0), buf912, buf913, reinterpret_tensor(buf908, (3072, 768), (768, 1), 0), reinterpret_tensor(buf909, (3072, ), (1, ), 0), reinterpret_tensor(buf904, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf905, (768, ), (1, ), 0), buf898, buf899, reinterpret_tensor(buf894, (2304, 768), (768, 1), 0), reinterpret_tensor(buf895, (2304, ), (1, ), 0), reinterpret_tensor(buf887, (16, 16), (16, 1), 0), reinterpret_tensor(buf885, (16, ), (1, ), 0), reinterpret_tensor(buf882, (16, 16), (16, 1), 0), reinterpret_tensor(buf880, (16, ), (1, ), 0), reinterpret_tensor(buf875, (768, 768), (768, 1), 0), reinterpret_tensor(buf876, (768, ), (1, ), 0), buf869, buf870, reinterpret_tensor(buf865, (3072, 768), (768, 1), 0), reinterpret_tensor(buf866, (3072, ), (1, ), 0), reinterpret_tensor(buf861, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf862, (768, ), (1, ), 0), buf855, buf856, reinterpret_tensor(buf851, (2304, 768), (768, 1), 0), reinterpret_tensor(buf852, (2304, ), (1, ), 0), reinterpret_tensor(buf844, (16, 16), (16, 1), 0), reinterpret_tensor(buf842, (16, ), (1, ), 0), reinterpret_tensor(buf839, (16, 16), (16, 1), 0), reinterpret_tensor(buf837, (16, ), (1, ), 0), reinterpret_tensor(buf832, (768, 768), (768, 1), 0), reinterpret_tensor(buf833, (768, ), (1, ), 0), buf826, buf827, reinterpret_tensor(buf822, (3072, 768), (768, 1), 0), reinterpret_tensor(buf823, (3072, ), (1, ), 0), reinterpret_tensor(buf818, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf819, (768, ), (1, ), 0), buf812, buf813, reinterpret_tensor(buf808, (2304, 768), (768, 1), 0), reinterpret_tensor(buf809, (2304, ), (1, ), 0), reinterpret_tensor(buf801, (16, 16), (16, 1), 0), reinterpret_tensor(buf799, (16, ), (1, ), 0), reinterpret_tensor(buf796, (16, 16), (16, 1), 0), reinterpret_tensor(buf794, (16, ), (1, ), 0), reinterpret_tensor(buf789, (768, 768), (768, 1), 0), reinterpret_tensor(buf790, (768, ), (1, ), 0), buf783, buf784, reinterpret_tensor(buf779, (3072, 768), (768, 1), 0), reinterpret_tensor(buf780, (3072, ), (1, ), 0), reinterpret_tensor(buf775, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf776, (768, ), (1, ), 0), buf769, buf770, reinterpret_tensor(buf765, (2304, 768), (768, 1), 0), reinterpret_tensor(buf766, (2304, ), (1, ), 0), reinterpret_tensor(buf758, (16, 16), (16, 1), 0), reinterpret_tensor(buf756, (16, ), (1, ), 0), reinterpret_tensor(buf753, (16, 16), (16, 1), 0), reinterpret_tensor(buf751, (16, ), (1, ), 0), reinterpret_tensor(buf746, (768, 768), (768, 1), 0), reinterpret_tensor(buf747, (768, ), (1, ), 0), buf740, buf741, reinterpret_tensor(buf736, (3072, 768), (768, 1), 0), reinterpret_tensor(buf737, (3072, ), (1, ), 0), reinterpret_tensor(buf732, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf733, (768, ), (1, ), 0), buf726, buf727, reinterpret_tensor(buf722, (2304, 768), (768, 1), 0), reinterpret_tensor(buf723, (2304, ), (1, ), 0), reinterpret_tensor(buf715, (16, 16), (16, 1), 0), reinterpret_tensor(buf713, (16, ), (1, ), 0), reinterpret_tensor(buf710, (16, 16), (16, 1), 0), reinterpret_tensor(buf708, (16, ), (1, ), 0), reinterpret_tensor(buf703, (768, 768), (768, 1), 0), reinterpret_tensor(buf704, (768, ), (1, ), 0), buf697, buf698, reinterpret_tensor(buf693, (3072, 768), (768, 1), 0), reinterpret_tensor(buf694, (3072, ), (1, ), 0), reinterpret_tensor(buf689, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf690, (768, ), (1, ), 0), buf683, buf684, reinterpret_tensor(buf679, (2304, 768), (768, 1), 0), reinterpret_tensor(buf680, (2304, ), (1, ), 0), reinterpret_tensor(buf672, (16, 16), (16, 1), 0), reinterpret_tensor(buf670, (16, ), (1, ), 0), reinterpret_tensor(buf667, (16, 16), (16, 1), 0), reinterpret_tensor(buf665, (16, ), (1, ), 0), reinterpret_tensor(buf660, (768, 768), (768, 1), 0), reinterpret_tensor(buf661, (768, ), (1, ), 0), buf654, buf655, reinterpret_tensor(buf650, (3072, 768), (768, 1), 0), reinterpret_tensor(buf651, (3072, ), (1, ), 0), reinterpret_tensor(buf646, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf647, (768, ), (1, ), 0), buf640, buf641, reinterpret_tensor(buf636, (2304, 768), (768, 1), 0), reinterpret_tensor(buf637, (2304, ), (1, ), 0), reinterpret_tensor(buf629, (16, 16), (16, 1), 0), reinterpret_tensor(buf627, (16, ), (1, ), 0), reinterpret_tensor(buf624, (16, 16), (16, 1), 0), reinterpret_tensor(buf622, (16, ), (1, ), 0), reinterpret_tensor(buf617, (768, 768), (768, 1), 0), reinterpret_tensor(buf618, (768, ), (1, ), 0), buf611, buf612, reinterpret_tensor(buf607, (3072, 768), (768, 1), 0), reinterpret_tensor(buf608, (3072, ), (1, ), 0), reinterpret_tensor(buf603, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf604, (768, ), (1, ), 0), buf597, buf598, reinterpret_tensor(buf593, (2304, 768), (768, 1), 0), reinterpret_tensor(buf594, (2304, ), (1, ), 0), reinterpret_tensor(buf586, (16, 16), (16, 1), 0), reinterpret_tensor(buf584, (16, ), (1, ), 0), reinterpret_tensor(buf581, (16, 16), (16, 1), 0), reinterpret_tensor(buf579, (16, ), (1, ), 0), reinterpret_tensor(buf574, (768, 768), (768, 1), 0), reinterpret_tensor(buf575, (768, ), (1, ), 0), buf568, buf569, reinterpret_tensor(buf564, (3072, 768), (768, 1), 0), reinterpret_tensor(buf565, (3072, ), (1, ), 0), reinterpret_tensor(buf560, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf561, (768, ), (1, ), 0), buf554, buf555, reinterpret_tensor(buf550, (2304, 768), (768, 1), 0), reinterpret_tensor(buf551, (2304, ), (1, ), 0), reinterpret_tensor(buf543, (16, 16), (16, 1), 0), reinterpret_tensor(buf541, (16, ), (1, ), 0), reinterpret_tensor(buf538, (16, 16), (16, 1), 0), reinterpret_tensor(buf536, (16, ), (1, ), 0), reinterpret_tensor(buf531, (768, 768), (768, 1), 0), reinterpret_tensor(buf532, (768, ), (1, ), 0), buf525, buf526, reinterpret_tensor(buf521, (3072, 768), (768, 1), 0), reinterpret_tensor(buf522, (3072, ), (1, ), 0), reinterpret_tensor(buf517, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf518, (768, ), (1, ), 0), buf511, buf512, reinterpret_tensor(buf507, (2304, 768), (768, 1), 0), reinterpret_tensor(buf508, (2304, ), (1, ), 0), reinterpret_tensor(buf500, (16, 16), (16, 1), 0), reinterpret_tensor(buf498, (16, ), (1, ), 0), reinterpret_tensor(buf495, (16, 16), (16, 1), 0), reinterpret_tensor(buf493, (16, ), (1, ), 0), reinterpret_tensor(buf488, (768, 768), (768, 1), 0), reinterpret_tensor(buf489, (768, ), (1, ), 0), buf482, buf483, reinterpret_tensor(buf478, (3072, 768), (768, 1), 0), reinterpret_tensor(buf479, (3072, ), (1, ), 0), reinterpret_tensor(buf474, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf475, (768, ), (1, ), 0), buf468, buf469, reinterpret_tensor(buf464, (2304, 768), (768, 1), 0), reinterpret_tensor(buf465, (2304, ), (1, ), 0), reinterpret_tensor(buf457, (16, 16), (16, 1), 0), reinterpret_tensor(buf455, (16, ), (1, ), 0), reinterpret_tensor(buf452, (16, 16), (16, 1), 0), reinterpret_tensor(buf450, (16, ), (1, ), 0), reinterpret_tensor(buf445, (768, 768), (768, 1), 0), reinterpret_tensor(buf446, (768, ), (1, ), 0), buf439, buf440, reinterpret_tensor(buf435, (3072, 768), (768, 1), 0), reinterpret_tensor(buf436, (3072, ), (1, ), 0), reinterpret_tensor(buf431, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf432, (768, ), (1, ), 0), buf425, buf426, reinterpret_tensor(buf421, (2304, 768), (768, 1), 0), reinterpret_tensor(buf422, (2304, ), (1, ), 0), reinterpret_tensor(buf414, (16, 16), (16, 1), 0), reinterpret_tensor(buf412, (16, ), (1, ), 0), reinterpret_tensor(buf409, (16, 16), (16, 1), 0), reinterpret_tensor(buf407, (16, ), (1, ), 0), reinterpret_tensor(buf402, (768, 768), (768, 1), 0), reinterpret_tensor(buf403, (768, ), (1, ), 0), buf396, buf397, reinterpret_tensor(buf392, (3072, 768), (768, 1), 0), reinterpret_tensor(buf393, (3072, ), (1, ), 0), reinterpret_tensor(buf388, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf389, (768, ), (1, ), 0), buf382, buf383, reinterpret_tensor(buf378, (2304, 768), (768, 1), 0), reinterpret_tensor(buf379, (2304, ), (1, ), 0), reinterpret_tensor(buf371, (16, 16), (16, 1), 0), reinterpret_tensor(buf369, (16, ), (1, ), 0), reinterpret_tensor(buf366, (16, 16), (16, 1), 0), reinterpret_tensor(buf364, (16, ), (1, ), 0), reinterpret_tensor(buf359, (768, 768), (768, 1), 0), reinterpret_tensor(buf360, (768, ), (1, ), 0), buf353, buf354, reinterpret_tensor(buf349, (3072, 768), (768, 1), 0), reinterpret_tensor(buf350, (3072, ), (1, ), 0), reinterpret_tensor(buf345, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf346, (768, ), (1, ), 0), buf339, buf340, reinterpret_tensor(buf335, (2304, 768), (768, 1), 0), reinterpret_tensor(buf336, (2304, ), (1, ), 0), reinterpret_tensor(buf328, (16, 16), (16, 1), 0), reinterpret_tensor(buf326, (16, ), (1, ), 0), reinterpret_tensor(buf323, (16, 16), (16, 1), 0), reinterpret_tensor(buf321, (16, ), (1, ), 0), reinterpret_tensor(buf316, (768, 768), (768, 1), 0), reinterpret_tensor(buf317, (768, ), (1, ), 0), buf310, buf311, reinterpret_tensor(buf306, (3072, 768), (768, 1), 0), reinterpret_tensor(buf307, (3072, ), (1, ), 0), reinterpret_tensor(buf302, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf303, (768, ), (1, ), 0), buf296, buf297, reinterpret_tensor(buf292, (2304, 768), (768, 1), 0), reinterpret_tensor(buf293, (2304, ), (1, ), 0), reinterpret_tensor(buf285, (16, 16), (16, 1), 0), reinterpret_tensor(buf283, (16, ), (1, ), 0), reinterpret_tensor(buf280, (16, 16), (16, 1), 0), reinterpret_tensor(buf278, (16, ), (1, ), 0), reinterpret_tensor(buf273, (768, 768), (768, 1), 0), reinterpret_tensor(buf274, (768, ), (1, ), 0), buf267, buf268, reinterpret_tensor(buf263, (3072, 768), (768, 1), 0), reinterpret_tensor(buf264, (3072, ), (1, ), 0), reinterpret_tensor(buf259, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf260, (768, ), (1, ), 0), buf253, buf254, reinterpret_tensor(buf249, (2304, 768), (768, 1), 0), reinterpret_tensor(buf250, (2304, ), (1, ), 0), reinterpret_tensor(buf242, (16, 16), (16, 1), 0), reinterpret_tensor(buf240, (16, ), (1, ), 0), reinterpret_tensor(buf237, (16, 16), (16, 1), 0), reinterpret_tensor(buf235, (16, ), (1, ), 0), reinterpret_tensor(buf230, (768, 768), (768, 1), 0), reinterpret_tensor(buf231, (768, ), (1, ), 0), buf224, buf225, reinterpret_tensor(buf220, (3072, 768), (768, 1), 0), reinterpret_tensor(buf221, (3072, ), (1, ), 0), reinterpret_tensor(buf216, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf217, (768, ), (1, ), 0), buf210, buf211, reinterpret_tensor(buf206, (2304, 768), (768, 1), 0), reinterpret_tensor(buf207, (2304, ), (1, ), 0), reinterpret_tensor(buf199, (16, 16), (16, 1), 0), reinterpret_tensor(buf197, (16, ), (1, ), 0), reinterpret_tensor(buf194, (16, 16), (16, 1), 0), reinterpret_tensor(buf192, (16, ), (1, ), 0), reinterpret_tensor(buf187, (768, 768), (768, 1), 0), reinterpret_tensor(buf188, (768, ), (1, ), 0), buf181, buf182, reinterpret_tensor(buf177, (3072, 768), (768, 1), 0), reinterpret_tensor(buf178, (3072, ), (1, ), 0), reinterpret_tensor(buf173, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf174, (768, ), (1, ), 0), buf167, buf168, reinterpret_tensor(buf163, (2304, 768), (768, 1), 0), reinterpret_tensor(buf164, (2304, ), (1, ), 0), reinterpret_tensor(buf156, (16, 16), (16, 1), 0), reinterpret_tensor(buf154, (16, ), (1, ), 0), reinterpret_tensor(buf151, (16, 16), (16, 1), 0), reinterpret_tensor(buf149, (16, ), (1, ), 0), reinterpret_tensor(buf144, (768, 768), (768, 1), 0), reinterpret_tensor(buf145, (768, ), (1, ), 0), buf138, buf139, reinterpret_tensor(buf134, (3072, 768), (768, 1), 0), reinterpret_tensor(buf135, (3072, ), (1, ), 0), reinterpret_tensor(buf130, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf131, (768, ), (1, ), 0), buf124, buf125, reinterpret_tensor(buf120, (2304, 768), (768, 1), 0), reinterpret_tensor(buf121, (2304, ), (1, ), 0), reinterpret_tensor(buf113, (16, 16), (16, 1), 0), reinterpret_tensor(buf111, (16, ), (1, ), 0), reinterpret_tensor(buf108, (16, 16), (16, 1), 0), reinterpret_tensor(buf106, (16, ), (1, ), 0), reinterpret_tensor(buf101, (768, 768), (768, 1), 0), reinterpret_tensor(buf102, (768, ), (1, ), 0), buf95, buf96, reinterpret_tensor(buf91, (3072, 768), (768, 1), 0), reinterpret_tensor(buf92, (3072, ), (1, ), 0), reinterpret_tensor(buf87, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf88, (768, ), (1, ), 0), buf80, buf81, reinterpret_tensor(buf75, (768, 768), (768, 1), 0), reinterpret_tensor(buf76, (768, ), (1, ), 0), reinterpret_tensor(buf72, (768, 768), (768, 1), 0), reinterpret_tensor(buf73, (768, ), (1, ), 0), reinterpret_tensor(buf69, (768, 768), (768, 1), 0), reinterpret_tensor(buf70, (768, ), (1, ), 0), reinterpret_tensor(buf62, (768, 768), (768, 1), 0), reinterpret_tensor(buf63, (768, ), (1, ), 0), buf56, buf57, reinterpret_tensor(buf52, (3072, 768), (768, 1), 0), reinterpret_tensor(buf53, (3072, ), (1, ), 0), reinterpret_tensor(buf48, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf49, (768, ), (1, ), 0), buf43, buf44, reinterpret_tensor(buf38, (768, 768), (768, 1), 0), reinterpret_tensor(buf39, (768, ), (1, ), 0), reinterpret_tensor(buf35, (768, 768), (768, 1), 0), reinterpret_tensor(buf36, (768, ), (1, ), 0), reinterpret_tensor(buf32, (768, 768), (768, 1), 0), reinterpret_tensor(buf33, (768, ), (1, ), 0), reinterpret_tensor(buf25, (768, 768), (768, 1), 0), reinterpret_tensor(buf26, (768, ), (1, ), 0), buf19, buf20, reinterpret_tensor(buf15, (3072, 768), (768, 1), 0), reinterpret_tensor(buf16, (3072, ), (1, ), 0), reinterpret_tensor(buf11, (768, 3072), (3072, 1), 0), reinterpret_tensor(buf12, (768, ), (1, ), 0), buf6, buf7, reinterpret_tensor(buf1, (1000, 768), (768, 1), 0), reinterpret_tensor(buf2, (1000, ), (1, ), 0), None, )


def benchmark_compiled_module(times=10, repeat=10):
    from torch._dynamo.testing import rand_strided
    from torch._inductor.utils import print_performance
    primals_2 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_3 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_4 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_5 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_6 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_7 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_8 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_9 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_10 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_11 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_12 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_13 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_14 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_15 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_16 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_17 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_18 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_19 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_20 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_21 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_22 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_23 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_24 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_25 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_26 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_27 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_28 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_29 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_30 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_31 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_32 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_33 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_34 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_35 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_36 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_37 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_38 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_39 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_40 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_41 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_42 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_43 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_44 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_45 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_46 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_47 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_48 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_49 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_50 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_51 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_52 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_53 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_54 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_55 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_56 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_57 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_58 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_59 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_60 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_61 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_62 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_63 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_64 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_65 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_66 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_67 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_68 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_69 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_70 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_71 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_72 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_73 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_75 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_76 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_77 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_78 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_79 = rand_strided((768, 3, 16, 16), (768, 1, 48, 3), device='cpu', dtype=torch.float32)
    primals_81 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_91 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_97 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_107 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_113 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_123 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_129 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_139 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_145 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_155 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_161 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_171 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_177 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_187 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_193 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_203 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_209 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_219 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_225 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_235 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_241 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_251 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_257 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_267 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_273 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_283 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_289 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_299 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_305 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_315 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_321 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_331 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_337 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_347 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_353 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_363 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_369 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_379 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_385 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_395 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_401 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_411 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_417 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_427 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_433 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_443 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_449 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_459 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_465 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_475 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_481 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_491 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_497 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_507 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_513 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_523 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_529 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_539 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_545 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_555 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_561 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_571 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_577 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_587 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_593 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_603 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_609 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_619 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_625 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_635 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_641 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_651 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_657 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_667 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_673 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_683 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_689 = rand_strided((768, ), (1, ), device='cpu', dtype=torch.float32)
    primals_693 = rand_strided((8, 3, 384, 384), (442368, 1, 1152, 3), device='cpu', dtype=torch.float32)
    mul = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_1 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_7 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_9 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_15 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_1 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_4 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_17 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_2 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_19 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_3 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_10 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_21 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_27 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_29 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_35 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_5 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_14 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_37 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_6 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_39 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_7 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_20 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_41 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_47 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_49 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_55 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_9 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_24 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_57 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_10 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_59 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_11 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_30 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_61 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_67 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_69 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_75 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_13 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_34 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_77 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_14 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_79 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_15 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_40 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_81 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_87 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_89 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_95 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_17 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_44 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_97 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_18 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_99 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_19 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_50 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_101 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_107 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_109 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_115 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_21 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_54 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_117 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_22 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_119 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_23 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_60 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_121 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_127 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_129 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_135 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_25 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_64 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_137 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_26 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_139 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_27 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_70 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_141 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_147 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_149 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_155 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_29 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_74 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_157 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_30 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_159 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_31 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_80 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_161 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_167 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_169 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_175 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_33 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_84 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_177 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_34 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_179 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_35 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_90 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_181 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_187 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_189 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_195 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_37 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_94 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_197 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_38 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_199 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_39 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_100 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_201 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_207 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_209 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_215 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_41 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_104 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_217 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_42 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_219 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_43 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_110 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_221 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_227 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_229 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_235 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_45 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_114 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_237 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_46 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_239 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_47 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_120 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_241 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_247 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_249 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_255 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_49 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_124 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_257 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_50 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_259 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_51 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_130 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_261 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_267 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_269 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_275 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_53 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_134 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_277 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_54 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_279 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_55 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_140 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_281 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_287 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_289 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_295 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_57 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_144 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_297 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_58 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_299 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_59 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_150 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_301 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_307 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_309 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_315 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_61 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_154 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_317 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_62 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_319 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_63 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_160 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_321 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_327 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_329 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_335 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_65 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_164 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_337 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_66 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_339 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_67 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_170 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_341 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_347 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_349 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_355 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_69 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_174 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_357 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_70 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_359 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_71 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_180 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_361 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_367 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_369 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_375 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_73 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_184 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_377 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_74 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_379 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_75 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_190 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_381 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_387 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_389 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_395 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_77 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_194 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_397 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_78 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_399 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_79 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_200 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_401 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_407 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_409 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_415 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_81 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_204 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_417 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_82 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_419 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_83 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_210 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_421 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_427 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_429 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_435 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_85 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_214 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_437 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_86 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_439 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_87 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_220 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_441 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_447 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_449 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_455 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_89 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_224 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_457 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_90 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_459 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_91 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_230 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_461 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_467 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_469 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_475 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_93 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_234 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_477 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_94 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_479 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_95 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_240 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_481 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_487 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_489 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_495 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_97 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_244 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_497 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_98 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_499 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_99 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_250 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_501 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_507 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_509 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_515 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_101 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_254 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_517 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_102 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_519 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_103 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_260 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_521 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_527 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_529 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_535 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_105 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_264 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_537 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_106 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_539 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_107 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_270 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_541 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_547 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_549 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_555 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_109 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_274 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_557 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_110 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_559 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_111 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_280 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_561 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_567 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_569 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_575 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_113 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_284 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_577 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_114 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_579 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_115 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_290 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_581 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_587 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_589 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_595 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_117 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_294 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_597 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_118 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_599 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_119 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_300 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_601 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_607 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_609 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_615 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_121 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_304 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_617 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_122 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_619 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_123 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_310 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_621 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_627 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_629 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_635 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_125 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_314 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_637 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_126 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_639 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_127 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_320 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_641 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_647 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_649 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_655 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_129 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_324 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_657 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_130 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_659 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_131 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_330 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_661 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_667 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_669 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_675 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_133 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_334 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_677 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_134 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_679 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_135 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_340 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_681 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_687 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_689 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_695 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_137 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_344 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_697 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_138 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_699 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_139 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_350 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_701 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    view_707 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_709 = rand_strided((2654208, 16), (16, 1), device='cpu', dtype=torch.float32)
    view_715 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_141 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_354 = rand_strided((8, 576, 768), (442368, 768, 1), device='cpu', dtype=torch.float32)
    view_717 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_142 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_719 = rand_strided((4608, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_143 = rand_strided((4608, 768), (768, 1), device='cpu', dtype=torch.float32)
    cat = rand_strided((8, 577, 768), (443136, 768, 1), device='cpu', dtype=torch.float32)
    getitem_145 = rand_strided((8, 577, 1), (577, 1, 1), device='cpu', dtype=torch.float32)
    rsqrt_72 = rand_strided((8, 577, 1), (577, 1, 1), device='cpu', dtype=torch.float32)
    select_108 = rand_strided((8, 768), (443136, 1), device='cpu', dtype=torch.float32)
    permute_470 = rand_strided((8, 16, 1, 48), (768, 1, 768, 16), device='cpu', dtype=torch.float32)
    view_722 = rand_strided((4616, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_472 = rand_strided((8, 16, 577, 48), (443136, 1, 768, 16), device='cpu', dtype=torch.float32)
    permute_474 = rand_strided((8, 16, 577, 48), (443136, 1, 768, 16), device='cpu', dtype=torch.float32)
    getitem_147 = rand_strided((8, 16, 1), (16, 1, 16), device='cpu', dtype=torch.float32)
    getitem_148 = rand_strided((), (), device='cpu', dtype=torch.int32)
    getitem_149 = rand_strided((), (), device='cpu', dtype=torch.int32)
    getitem_152 = rand_strided((), (), device='cpu', dtype=torch.int64)
    getitem_153 = rand_strided((), (), device='cpu', dtype=torch.int64)
    view_729 = rand_strided((8, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_147 = rand_strided((8, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_363 = rand_strided((8, 1, 768), (768, 768, 1), device='cpu', dtype=torch.float32)
    view_731 = rand_strided((8, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_148 = rand_strided((8, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_733 = rand_strided((8, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_149 = rand_strided((8, 768), (768, 1), device='cpu', dtype=torch.float32)
    cat_1 = rand_strided((8, 577, 768), (443136, 768, 1), device='cpu', dtype=torch.float32)
    getitem_158 = rand_strided((8, 577, 1), (577, 1, 1), device='cpu', dtype=torch.float32)
    rsqrt_74 = rand_strided((8, 577, 1), (577, 1, 1), device='cpu', dtype=torch.float32)
    select_109 = rand_strided((8, 768), (443136, 1), device='cpu', dtype=torch.float32)
    permute_480 = rand_strided((8, 16, 1, 48), (768, 1, 768, 16), device='cpu', dtype=torch.float32)
    view_736 = rand_strided((4616, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_482 = rand_strided((8, 16, 577, 48), (443136, 1, 768, 16), device='cpu', dtype=torch.float32)
    permute_484 = rand_strided((8, 16, 577, 48), (443136, 1, 768, 16), device='cpu', dtype=torch.float32)
    getitem_160 = rand_strided((8, 16, 1), (16, 1, 16), device='cpu', dtype=torch.float32)
    getitem_161 = rand_strided((), (), device='cpu', dtype=torch.int32)
    getitem_162 = rand_strided((), (), device='cpu', dtype=torch.int32)
    getitem_165 = rand_strided((), (), device='cpu', dtype=torch.int64)
    getitem_166 = rand_strided((), (), device='cpu', dtype=torch.int64)
    view_743 = rand_strided((8, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_153 = rand_strided((8, 768), (768, 1), device='cpu', dtype=torch.float32)
    mul_372 = rand_strided((8, 1, 768), (768, 768, 1), device='cpu', dtype=torch.float32)
    view_745 = rand_strided((8, 768), (768, 1), device='cpu', dtype=torch.float32)
    addmm_154 = rand_strided((8, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    view_747 = rand_strided((8, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    addmm_155 = rand_strided((8, 768), (768, 1), device='cpu', dtype=torch.float32)
    cat_2 = rand_strided((8, 577, 768), (443136, 768, 1), device='cpu', dtype=torch.float32)
    getitem_171 = rand_strided((8, 577, 1), (577, 1, 1), device='cpu', dtype=torch.float32)
    rsqrt_76 = rand_strided((8, 577, 1), (577, 1, 1), device='cpu', dtype=torch.float32)
    clone_511 = rand_strided((8, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_490 = rand_strided((1000, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_494 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_498 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_37 = rand_strided((8, 1, 1), (1, 1, 1), device='cpu', dtype=torch.float32)
    permute_502 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    alias_38 = rand_strided((8, 16, 1, 48), (768, 1, 768, 16), device='cpu', dtype=torch.float32)
    permute_508 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_513 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_518 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_522 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_526 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_39 = rand_strided((8, 1, 1), (1, 1, 1), device='cpu', dtype=torch.float32)
    permute_530 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    alias_39 = rand_strided((8, 16, 1, 48), (768, 1, 768, 16), device='cpu', dtype=torch.float32)
    permute_536 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_541 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_546 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_550 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_554 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_41 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_558 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_563 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_564 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_568 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_40 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_574 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_577 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_578 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_581 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_42 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_585 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_589 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_43 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_593 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_598 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_599 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_603 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_41 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_609 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_612 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_613 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_616 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_44 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_620 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_624 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_45 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_628 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_633 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_634 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_638 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_42 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_644 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_647 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_648 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_651 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_46 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_655 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_659 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_47 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_663 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_668 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_669 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_673 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_43 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_679 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_682 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_683 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_686 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_48 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_690 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_694 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_49 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_698 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_703 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_704 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_708 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_44 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_714 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_717 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_718 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_721 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_50 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_725 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_729 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_51 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_733 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_738 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_739 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_743 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_45 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_749 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_752 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_753 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_756 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_52 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_760 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_764 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_53 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_768 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_773 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_774 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_778 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_46 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_784 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_787 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_788 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_791 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_54 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_795 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_799 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_55 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_803 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_808 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_809 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_813 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_47 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_819 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_822 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_823 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_826 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_56 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_830 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_834 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_57 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_838 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_843 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_844 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_848 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_48 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_854 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_857 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_858 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_861 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_58 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_865 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_869 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_59 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_873 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_878 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_879 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_883 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_49 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_889 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_892 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_893 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_896 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_60 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_900 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_904 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_61 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_908 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_913 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_914 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_918 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_50 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_924 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_927 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_928 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_931 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_62 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_935 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_939 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_63 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_943 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_948 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_949 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_953 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_51 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_959 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_962 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_963 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_966 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_64 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_970 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_974 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_65 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_978 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_983 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_984 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_988 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_52 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_994 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_997 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_998 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1001 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_66 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1005 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1009 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_67 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1013 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1018 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1019 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1023 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_53 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1029 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1032 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1033 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1036 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_68 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1040 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1044 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_69 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1048 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1053 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1054 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1058 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_54 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1064 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1067 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1068 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1071 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_70 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1075 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1079 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_71 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1083 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1088 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1089 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1093 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_55 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1099 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1102 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1103 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1106 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_72 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1110 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1114 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_73 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1118 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1123 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1124 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1128 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_56 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1134 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1137 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1138 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1141 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_74 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1145 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1149 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_75 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1153 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1158 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1159 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1163 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_57 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1169 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1172 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1173 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1176 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_76 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1180 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1184 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_77 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1188 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1193 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1194 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1198 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_58 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1204 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1207 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1208 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1211 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_78 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1215 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1219 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_79 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1223 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1228 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1229 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1233 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_59 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1239 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1242 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1243 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1246 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_80 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1250 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1254 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_81 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1258 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1263 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1264 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1268 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_60 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1274 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1277 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1278 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1281 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_82 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1285 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1289 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_83 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1293 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1298 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1299 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1303 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_61 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1309 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1312 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1313 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1316 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_84 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1320 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1324 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_85 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1328 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1333 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1334 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1338 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_62 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1344 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1347 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1348 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1351 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_86 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1355 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1359 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_87 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1363 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1368 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1369 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1373 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_63 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1379 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1382 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1383 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1386 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_88 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1390 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1394 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_89 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1398 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1403 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1404 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1408 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_64 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1414 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1417 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1418 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1421 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_90 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1425 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1429 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_91 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1433 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1438 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1439 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1443 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_65 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1449 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1452 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1453 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1456 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_92 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1460 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1464 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_93 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1468 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1473 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1474 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1478 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_66 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1484 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1487 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1488 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1491 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_94 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1495 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1499 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_95 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1503 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1508 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1509 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1513 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_67 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1519 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1522 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1523 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1526 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_96 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1530 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1534 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_97 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1538 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1543 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1544 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1548 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_68 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1554 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1557 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1558 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1561 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_98 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1565 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1569 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_99 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1573 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1578 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1579 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1583 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_69 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1589 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1592 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1593 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1596 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_100 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1600 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1604 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_101 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1608 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1613 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1614 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1618 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_70 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1624 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1627 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1628 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1631 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_102 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1635 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1639 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_103 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1643 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1648 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1649 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1653 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_71 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1659 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1662 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1663 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1666 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_104 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1670 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1674 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_105 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1678 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1683 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1684 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1688 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_72 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1694 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1697 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1698 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1701 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_106 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1705 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1709 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_107 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1713 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1718 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1719 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1723 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_73 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1729 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1732 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1733 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1736 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_108 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1740 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1744 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_109 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1748 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1753 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1754 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1758 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_74 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1764 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1767 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1768 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1771 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_110 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1775 = rand_strided((768, 3072), (3072, 1), device='cpu', dtype=torch.float32)
    permute_1779 = rand_strided((3072, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_111 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    permute_1783 = rand_strided((768, 768), (768, 1), device='cpu', dtype=torch.float32)
    permute_1788 = rand_strided((128, 576, 576), (331776, 1, 576), device='cpu', dtype=torch.float32)
    permute_1789 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1793 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    alias_75 = rand_strided((8, 16, 576, 576), (5308416, 1, 9216, 16), device='cpu', dtype=torch.float32)
    permute_1799 = rand_strided((16, 16), (16, 1), device='cpu', dtype=torch.float32)
    permute_1802 = rand_strided((128, 48, 576), (27648, 1, 48), device='cpu', dtype=torch.float32)
    permute_1803 = rand_strided((128, 576, 48), (27648, 1, 576), device='cpu', dtype=torch.float32)
    permute_1806 = rand_strided((2304, 768), (768, 1), device='cpu', dtype=torch.float32)
    div_112 = rand_strided((8, 576, 1), (576, 1, 1), device='cpu', dtype=torch.float32)
    tangents_1 = rand_strided((8, 1000), (1000, 1), device='cpu', dtype=torch.float32)
    return print_performance(lambda: call([primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_75, primals_76, primals_77, primals_78, primals_79, primals_81, primals_91, primals_97, primals_107, primals_113, primals_123, primals_129, primals_139, primals_145, primals_155, primals_161, primals_171, primals_177, primals_187, primals_193, primals_203, primals_209, primals_219, primals_225, primals_235, primals_241, primals_251, primals_257, primals_267, primals_273, primals_283, primals_289, primals_299, primals_305, primals_315, primals_321, primals_331, primals_337, primals_347, primals_353, primals_363, primals_369, primals_379, primals_385, primals_395, primals_401, primals_411, primals_417, primals_427, primals_433, primals_443, primals_449, primals_459, primals_465, primals_475, primals_481, primals_491, primals_497, primals_507, primals_513, primals_523, primals_529, primals_539, primals_545, primals_555, primals_561, primals_571, primals_577, primals_587, primals_593, primals_603, primals_609, primals_619, primals_625, primals_635, primals_641, primals_651, primals_657, primals_667, primals_673, primals_683, primals_689, primals_693, mul, view_1, view_7, view_9, view_15, addmm_1, mul_4, view_17, addmm_2, view_19, addmm_3, mul_10, view_21, view_27, view_29, view_35, addmm_5, mul_14, view_37, addmm_6, view_39, addmm_7, mul_20, view_41, view_47, view_49, view_55, addmm_9, mul_24, view_57, addmm_10, view_59, addmm_11, mul_30, view_61, view_67, view_69, view_75, addmm_13, mul_34, view_77, addmm_14, view_79, addmm_15, mul_40, view_81, view_87, view_89, view_95, addmm_17, mul_44, view_97, addmm_18, view_99, addmm_19, mul_50, view_101, view_107, view_109, view_115, addmm_21, mul_54, view_117, addmm_22, view_119, addmm_23, mul_60, view_121, view_127, view_129, view_135, addmm_25, mul_64, view_137, addmm_26, view_139, addmm_27, mul_70, view_141, view_147, view_149, view_155, addmm_29, mul_74, view_157, addmm_30, view_159, addmm_31, mul_80, view_161, view_167, view_169, view_175, addmm_33, mul_84, view_177, addmm_34, view_179, addmm_35, mul_90, view_181, view_187, view_189, view_195, addmm_37, mul_94, view_197, addmm_38, view_199, addmm_39, mul_100, view_201, view_207, view_209, view_215, addmm_41, mul_104, view_217, addmm_42, view_219, addmm_43, mul_110, view_221, view_227, view_229, view_235, addmm_45, mul_114, view_237, addmm_46, view_239, addmm_47, mul_120, view_241, view_247, view_249, view_255, addmm_49, mul_124, view_257, addmm_50, view_259, addmm_51, mul_130, view_261, view_267, view_269, view_275, addmm_53, mul_134, view_277, addmm_54, view_279, addmm_55, mul_140, view_281, view_287, view_289, view_295, addmm_57, mul_144, view_297, addmm_58, view_299, addmm_59, mul_150, view_301, view_307, view_309, view_315, addmm_61, mul_154, view_317, addmm_62, view_319, addmm_63, mul_160, view_321, view_327, view_329, view_335, addmm_65, mul_164, view_337, addmm_66, view_339, addmm_67, mul_170, view_341, view_347, view_349, view_355, addmm_69, mul_174, view_357, addmm_70, view_359, addmm_71, mul_180, view_361, view_367, view_369, view_375, addmm_73, mul_184, view_377, addmm_74, view_379, addmm_75, mul_190, view_381, view_387, view_389, view_395, addmm_77, mul_194, view_397, addmm_78, view_399, addmm_79, mul_200, view_401, view_407, view_409, view_415, addmm_81, mul_204, view_417, addmm_82, view_419, addmm_83, mul_210, view_421, view_427, view_429, view_435, addmm_85, mul_214, view_437, addmm_86, view_439, addmm_87, mul_220, view_441, view_447, view_449, view_455, addmm_89, mul_224, view_457, addmm_90, view_459, addmm_91, mul_230, view_461, view_467, view_469, view_475, addmm_93, mul_234, view_477, addmm_94, view_479, addmm_95, mul_240, view_481, view_487, view_489, view_495, addmm_97, mul_244, view_497, addmm_98, view_499, addmm_99, mul_250, view_501, view_507, view_509, view_515, addmm_101, mul_254, view_517, addmm_102, view_519, addmm_103, mul_260, view_521, view_527, view_529, view_535, addmm_105, mul_264, view_537, addmm_106, view_539, addmm_107, mul_270, view_541, view_547, view_549, view_555, addmm_109, mul_274, view_557, addmm_110, view_559, addmm_111, mul_280, view_561, view_567, view_569, view_575, addmm_113, mul_284, view_577, addmm_114, view_579, addmm_115, mul_290, view_581, view_587, view_589, view_595, addmm_117, mul_294, view_597, addmm_118, view_599, addmm_119, mul_300, view_601, view_607, view_609, view_615, addmm_121, mul_304, view_617, addmm_122, view_619, addmm_123, mul_310, view_621, view_627, view_629, view_635, addmm_125, mul_314, view_637, addmm_126, view_639, addmm_127, mul_320, view_641, view_647, view_649, view_655, addmm_129, mul_324, view_657, addmm_130, view_659, addmm_131, mul_330, view_661, view_667, view_669, view_675, addmm_133, mul_334, view_677, addmm_134, view_679, addmm_135, mul_340, view_681, view_687, view_689, view_695, addmm_137, mul_344, view_697, addmm_138, view_699, addmm_139, mul_350, view_701, view_707, view_709, view_715, addmm_141, mul_354, view_717, addmm_142, view_719, addmm_143, cat, getitem_145, rsqrt_72, select_108, permute_470, view_722, permute_472, permute_474, getitem_147, getitem_148, getitem_149, getitem_152, getitem_153, view_729, addmm_147, mul_363, view_731, addmm_148, view_733, addmm_149, cat_1, getitem_158, rsqrt_74, select_109, permute_480, view_736, permute_482, permute_484, getitem_160, getitem_161, getitem_162, getitem_165, getitem_166, view_743, addmm_153, mul_372, view_745, addmm_154, view_747, addmm_155, cat_2, getitem_171, rsqrt_76, clone_511, permute_490, permute_494, permute_498, div_37, permute_502, alias_38, permute_508, permute_513, permute_518, permute_522, permute_526, div_39, permute_530, alias_39, permute_536, permute_541, permute_546, permute_550, permute_554, div_41, permute_558, permute_563, permute_564, permute_568, alias_40, permute_574, permute_577, permute_578, permute_581, div_42, permute_585, permute_589, div_43, permute_593, permute_598, permute_599, permute_603, alias_41, permute_609, permute_612, permute_613, permute_616, div_44, permute_620, permute_624, div_45, permute_628, permute_633, permute_634, permute_638, alias_42, permute_644, permute_647, permute_648, permute_651, div_46, permute_655, permute_659, div_47, permute_663, permute_668, permute_669, permute_673, alias_43, permute_679, permute_682, permute_683, permute_686, div_48, permute_690, permute_694, div_49, permute_698, permute_703, permute_704, permute_708, alias_44, permute_714, permute_717, permute_718, permute_721, div_50, permute_725, permute_729, div_51, permute_733, permute_738, permute_739, permute_743, alias_45, permute_749, permute_752, permute_753, permute_756, div_52, permute_760, permute_764, div_53, permute_768, permute_773, permute_774, permute_778, alias_46, permute_784, permute_787, permute_788, permute_791, div_54, permute_795, permute_799, div_55, permute_803, permute_808, permute_809, permute_813, alias_47, permute_819, permute_822, permute_823, permute_826, div_56, permute_830, permute_834, div_57, permute_838, permute_843, permute_844, permute_848, alias_48, permute_854, permute_857, permute_858, permute_861, div_58, permute_865, permute_869, div_59, permute_873, permute_878, permute_879, permute_883, alias_49, permute_889, permute_892, permute_893, permute_896, div_60, permute_900, permute_904, div_61, permute_908, permute_913, permute_914, permute_918, alias_50, permute_924, permute_927, permute_928, permute_931, div_62, permute_935, permute_939, div_63, permute_943, permute_948, permute_949, permute_953, alias_51, permute_959, permute_962, permute_963, permute_966, div_64, permute_970, permute_974, div_65, permute_978, permute_983, permute_984, permute_988, alias_52, permute_994, permute_997, permute_998, permute_1001, div_66, permute_1005, permute_1009, div_67, permute_1013, permute_1018, permute_1019, permute_1023, alias_53, permute_1029, permute_1032, permute_1033, permute_1036, div_68, permute_1040, permute_1044, div_69, permute_1048, permute_1053, permute_1054, permute_1058, alias_54, permute_1064, permute_1067, permute_1068, permute_1071, div_70, permute_1075, permute_1079, div_71, permute_1083, permute_1088, permute_1089, permute_1093, alias_55, permute_1099, permute_1102, permute_1103, permute_1106, div_72, permute_1110, permute_1114, div_73, permute_1118, permute_1123, permute_1124, permute_1128, alias_56, permute_1134, permute_1137, permute_1138, permute_1141, div_74, permute_1145, permute_1149, div_75, permute_1153, permute_1158, permute_1159, permute_1163, alias_57, permute_1169, permute_1172, permute_1173, permute_1176, div_76, permute_1180, permute_1184, div_77, permute_1188, permute_1193, permute_1194, permute_1198, alias_58, permute_1204, permute_1207, permute_1208, permute_1211, div_78, permute_1215, permute_1219, div_79, permute_1223, permute_1228, permute_1229, permute_1233, alias_59, permute_1239, permute_1242, permute_1243, permute_1246, div_80, permute_1250, permute_1254, div_81, permute_1258, permute_1263, permute_1264, permute_1268, alias_60, permute_1274, permute_1277, permute_1278, permute_1281, div_82, permute_1285, permute_1289, div_83, permute_1293, permute_1298, permute_1299, permute_1303, alias_61, permute_1309, permute_1312, permute_1313, permute_1316, div_84, permute_1320, permute_1324, div_85, permute_1328, permute_1333, permute_1334, permute_1338, alias_62, permute_1344, permute_1347, permute_1348, permute_1351, div_86, permute_1355, permute_1359, div_87, permute_1363, permute_1368, permute_1369, permute_1373, alias_63, permute_1379, permute_1382, permute_1383, permute_1386, div_88, permute_1390, permute_1394, div_89, permute_1398, permute_1403, permute_1404, permute_1408, alias_64, permute_1414, permute_1417, permute_1418, permute_1421, div_90, permute_1425, permute_1429, div_91, permute_1433, permute_1438, permute_1439, permute_1443, alias_65, permute_1449, permute_1452, permute_1453, permute_1456, div_92, permute_1460, permute_1464, div_93, permute_1468, permute_1473, permute_1474, permute_1478, alias_66, permute_1484, permute_1487, permute_1488, permute_1491, div_94, permute_1495, permute_1499, div_95, permute_1503, permute_1508, permute_1509, permute_1513, alias_67, permute_1519, permute_1522, permute_1523, permute_1526, div_96, permute_1530, permute_1534, div_97, permute_1538, permute_1543, permute_1544, permute_1548, alias_68, permute_1554, permute_1557, permute_1558, permute_1561, div_98, permute_1565, permute_1569, div_99, permute_1573, permute_1578, permute_1579, permute_1583, alias_69, permute_1589, permute_1592, permute_1593, permute_1596, div_100, permute_1600, permute_1604, div_101, permute_1608, permute_1613, permute_1614, permute_1618, alias_70, permute_1624, permute_1627, permute_1628, permute_1631, div_102, permute_1635, permute_1639, div_103, permute_1643, permute_1648, permute_1649, permute_1653, alias_71, permute_1659, permute_1662, permute_1663, permute_1666, div_104, permute_1670, permute_1674, div_105, permute_1678, permute_1683, permute_1684, permute_1688, alias_72, permute_1694, permute_1697, permute_1698, permute_1701, div_106, permute_1705, permute_1709, div_107, permute_1713, permute_1718, permute_1719, permute_1723, alias_73, permute_1729, permute_1732, permute_1733, permute_1736, div_108, permute_1740, permute_1744, div_109, permute_1748, permute_1753, permute_1754, permute_1758, alias_74, permute_1764, permute_1767, permute_1768, permute_1771, div_110, permute_1775, permute_1779, div_111, permute_1783, permute_1788, permute_1789, permute_1793, alias_75, permute_1799, permute_1802, permute_1803, permute_1806, div_112, tangents_1]), times=times, repeat=repeat)


if __name__ == "__main__":
    from torch._inductor.wrapper_benchmark import compiled_module_main
    compiled_module_main('cait_m36_384', benchmark_compiled_module)
