from __future__ import annotations



def forward(self, primals_1: "f32[64, 3, 3, 3]", primals_2: "f32[64]", primals_4: "f32[64, 64, 3, 3]", primals_5: "f32[64]", primals_7: "f32[64, 64, 1, 1]", primals_8: "f32[64]", primals_10: "f32[64, 64, 3, 3]", primals_11: "f32[64]", primals_13: "f32[256, 64, 1, 1]", primals_14: "f32[256]", primals_16: "f32[256, 64, 1, 1]", primals_17: "f32[256]", primals_19: "f32[64, 256, 1, 1]", primals_20: "f32[64]", primals_22: "f32[64, 64, 3, 3]", primals_23: "f32[64]", primals_25: "f32[256, 64, 1, 1]", primals_26: "f32[256]", primals_28: "f32[64, 256, 1, 1]", primals_29: "f32[64]", primals_31: "f32[64, 64, 3, 3]", primals_32: "f32[64]", primals_34: "f32[256, 64, 1, 1]", primals_35: "f32[256]", primals_37: "f32[64, 256, 1, 1]", primals_38: "f32[64]", primals_40: "f32[64, 64, 3, 3]", primals_41: "f32[64]", primals_43: "f32[256, 64, 1, 1]", primals_44: "f32[256]", primals_46: "f32[18, 256, 3, 3]", primals_47: "f32[18]", primals_49: "f32[36, 256, 3, 3]", primals_50: "f32[36]", primals_52: "f32[18, 18, 3, 3]", primals_53: "f32[18]", primals_55: "f32[18, 18, 3, 3]", primals_56: "f32[18]", primals_58: "f32[18, 18, 3, 3]", primals_59: "f32[18]", primals_61: "f32[18, 18, 3, 3]", primals_62: "f32[18]", primals_64: "f32[18, 18, 3, 3]", primals_65: "f32[18]", primals_67: "f32[18, 18, 3, 3]", primals_68: "f32[18]", primals_70: "f32[18, 18, 3, 3]", primals_71: "f32[18]", primals_73: "f32[18, 18, 3, 3]", primals_74: "f32[18]", primals_76: "f32[36, 36, 3, 3]", primals_77: "f32[36]", primals_79: "f32[36, 36, 3, 3]", primals_80: "f32[36]", primals_82: "f32[36, 36, 3, 3]", primals_83: "f32[36]", primals_85: "f32[36, 36, 3, 3]", primals_86: "f32[36]", primals_88: "f32[36, 36, 3, 3]", primals_89: "f32[36]", primals_91: "f32[36, 36, 3, 3]", primals_92: "f32[36]", primals_94: "f32[36, 36, 3, 3]", primals_95: "f32[36]", primals_97: "f32[36, 36, 3, 3]", primals_98: "f32[36]", primals_100: "f32[18, 36, 1, 1]", primals_101: "f32[18]", primals_103: "f32[36, 18, 3, 3]", primals_104: "f32[36]", primals_106: "f32[72, 36, 3, 3]", primals_107: "f32[72]", primals_109: "f32[18, 18, 3, 3]", primals_110: "f32[18]", primals_112: "f32[18, 18, 3, 3]", primals_113: "f32[18]", primals_115: "f32[18, 18, 3, 3]", primals_116: "f32[18]", primals_118: "f32[18, 18, 3, 3]", primals_119: "f32[18]", primals_121: "f32[18, 18, 3, 3]", primals_122: "f32[18]", primals_124: "f32[18, 18, 3, 3]", primals_125: "f32[18]", primals_127: "f32[18, 18, 3, 3]", primals_128: "f32[18]", primals_130: "f32[18, 18, 3, 3]", primals_131: "f32[18]", primals_133: "f32[36, 36, 3, 3]", primals_134: "f32[36]", primals_136: "f32[36, 36, 3, 3]", primals_137: "f32[36]", primals_139: "f32[36, 36, 3, 3]", primals_140: "f32[36]", primals_142: "f32[36, 36, 3, 3]", primals_143: "f32[36]", primals_145: "f32[36, 36, 3, 3]", primals_146: "f32[36]", primals_148: "f32[36, 36, 3, 3]", primals_149: "f32[36]", primals_151: "f32[36, 36, 3, 3]", primals_152: "f32[36]", primals_154: "f32[36, 36, 3, 3]", primals_155: "f32[36]", primals_157: "f32[72, 72, 3, 3]", primals_158: "f32[72]", primals_160: "f32[72, 72, 3, 3]", primals_161: "f32[72]", primals_163: "f32[72, 72, 3, 3]", primals_164: "f32[72]", primals_166: "f32[72, 72, 3, 3]", primals_167: "f32[72]", primals_169: "f32[72, 72, 3, 3]", primals_170: "f32[72]", primals_172: "f32[72, 72, 3, 3]", primals_173: "f32[72]", primals_175: "f32[72, 72, 3, 3]", primals_176: "f32[72]", primals_178: "f32[72, 72, 3, 3]", primals_179: "f32[72]", primals_181: "f32[18, 36, 1, 1]", primals_182: "f32[18]", primals_184: "f32[18, 72, 1, 1]", primals_185: "f32[18]", primals_187: "f32[36, 18, 3, 3]", primals_188: "f32[36]", primals_190: "f32[36, 72, 1, 1]", primals_191: "f32[36]", primals_193: "f32[18, 18, 3, 3]", primals_194: "f32[18]", primals_196: "f32[72, 18, 3, 3]", primals_197: "f32[72]", primals_199: "f32[72, 36, 3, 3]", primals_200: "f32[72]", primals_202: "f32[18, 18, 3, 3]", primals_203: "f32[18]", primals_205: "f32[18, 18, 3, 3]", primals_206: "f32[18]", primals_208: "f32[18, 18, 3, 3]", primals_209: "f32[18]", primals_211: "f32[18, 18, 3, 3]", primals_212: "f32[18]", primals_214: "f32[18, 18, 3, 3]", primals_215: "f32[18]", primals_217: "f32[18, 18, 3, 3]", primals_218: "f32[18]", primals_220: "f32[18, 18, 3, 3]", primals_221: "f32[18]", primals_223: "f32[18, 18, 3, 3]", primals_224: "f32[18]", primals_226: "f32[36, 36, 3, 3]", primals_227: "f32[36]", primals_229: "f32[36, 36, 3, 3]", primals_230: "f32[36]", primals_232: "f32[36, 36, 3, 3]", primals_233: "f32[36]", primals_235: "f32[36, 36, 3, 3]", primals_236: "f32[36]", primals_238: "f32[36, 36, 3, 3]", primals_239: "f32[36]", primals_241: "f32[36, 36, 3, 3]", primals_242: "f32[36]", primals_244: "f32[36, 36, 3, 3]", primals_245: "f32[36]", primals_247: "f32[36, 36, 3, 3]", primals_248: "f32[36]", primals_250: "f32[72, 72, 3, 3]", primals_251: "f32[72]", primals_253: "f32[72, 72, 3, 3]", primals_254: "f32[72]", primals_256: "f32[72, 72, 3, 3]", primals_257: "f32[72]", primals_259: "f32[72, 72, 3, 3]", primals_260: "f32[72]", primals_262: "f32[72, 72, 3, 3]", primals_263: "f32[72]", primals_265: "f32[72, 72, 3, 3]", primals_266: "f32[72]", primals_268: "f32[72, 72, 3, 3]", primals_269: "f32[72]", primals_271: "f32[72, 72, 3, 3]", primals_272: "f32[72]", primals_274: "f32[18, 36, 1, 1]", primals_275: "f32[18]", primals_277: "f32[18, 72, 1, 1]", primals_278: "f32[18]", primals_280: "f32[36, 18, 3, 3]", primals_281: "f32[36]", primals_283: "f32[36, 72, 1, 1]", primals_284: "f32[36]", primals_286: "f32[18, 18, 3, 3]", primals_287: "f32[18]", primals_289: "f32[72, 18, 3, 3]", primals_290: "f32[72]", primals_292: "f32[72, 36, 3, 3]", primals_293: "f32[72]", primals_295: "f32[18, 18, 3, 3]", primals_296: "f32[18]", primals_298: "f32[18, 18, 3, 3]", primals_299: "f32[18]", primals_301: "f32[18, 18, 3, 3]", primals_302: "f32[18]", primals_304: "f32[18, 18, 3, 3]", primals_305: "f32[18]", primals_307: "f32[18, 18, 3, 3]", primals_308: "f32[18]", primals_310: "f32[18, 18, 3, 3]", primals_311: "f32[18]", primals_313: "f32[18, 18, 3, 3]", primals_314: "f32[18]", primals_316: "f32[18, 18, 3, 3]", primals_317: "f32[18]", primals_319: "f32[36, 36, 3, 3]", primals_320: "f32[36]", primals_322: "f32[36, 36, 3, 3]", primals_323: "f32[36]", primals_325: "f32[36, 36, 3, 3]", primals_326: "f32[36]", primals_328: "f32[36, 36, 3, 3]", primals_329: "f32[36]", primals_331: "f32[36, 36, 3, 3]", primals_332: "f32[36]", primals_334: "f32[36, 36, 3, 3]", primals_335: "f32[36]", primals_337: "f32[36, 36, 3, 3]", primals_338: "f32[36]", primals_340: "f32[36, 36, 3, 3]", primals_341: "f32[36]", primals_343: "f32[72, 72, 3, 3]", primals_344: "f32[72]", primals_346: "f32[72, 72, 3, 3]", primals_347: "f32[72]", primals_349: "f32[72, 72, 3, 3]", primals_350: "f32[72]", primals_352: "f32[72, 72, 3, 3]", primals_353: "f32[72]", primals_355: "f32[72, 72, 3, 3]", primals_356: "f32[72]", primals_358: "f32[72, 72, 3, 3]", primals_359: "f32[72]", primals_361: "f32[72, 72, 3, 3]", primals_362: "f32[72]", primals_364: "f32[72, 72, 3, 3]", primals_365: "f32[72]", primals_367: "f32[18, 36, 1, 1]", primals_368: "f32[18]", primals_370: "f32[18, 72, 1, 1]", primals_371: "f32[18]", primals_373: "f32[36, 18, 3, 3]", primals_374: "f32[36]", primals_376: "f32[36, 72, 1, 1]", primals_377: "f32[36]", primals_379: "f32[18, 18, 3, 3]", primals_380: "f32[18]", primals_382: "f32[72, 18, 3, 3]", primals_383: "f32[72]", primals_385: "f32[72, 36, 3, 3]", primals_386: "f32[72]", primals_388: "f32[18, 18, 3, 3]", primals_389: "f32[18]", primals_391: "f32[18, 18, 3, 3]", primals_392: "f32[18]", primals_394: "f32[18, 18, 3, 3]", primals_395: "f32[18]", primals_397: "f32[18, 18, 3, 3]", primals_398: "f32[18]", primals_400: "f32[18, 18, 3, 3]", primals_401: "f32[18]", primals_403: "f32[18, 18, 3, 3]", primals_404: "f32[18]", primals_406: "f32[18, 18, 3, 3]", primals_407: "f32[18]", primals_409: "f32[18, 18, 3, 3]", primals_410: "f32[18]", primals_412: "f32[36, 36, 3, 3]", primals_413: "f32[36]", primals_415: "f32[36, 36, 3, 3]", primals_416: "f32[36]", primals_418: "f32[36, 36, 3, 3]", primals_419: "f32[36]", primals_421: "f32[36, 36, 3, 3]", primals_422: "f32[36]", primals_424: "f32[36, 36, 3, 3]", primals_425: "f32[36]", primals_427: "f32[36, 36, 3, 3]", primals_428: "f32[36]", primals_430: "f32[36, 36, 3, 3]", primals_431: "f32[36]", primals_433: "f32[36, 36, 3, 3]", primals_434: "f32[36]", primals_436: "f32[72, 72, 3, 3]", primals_437: "f32[72]", primals_439: "f32[72, 72, 3, 3]", primals_440: "f32[72]", primals_442: "f32[72, 72, 3, 3]", primals_443: "f32[72]", primals_445: "f32[72, 72, 3, 3]", primals_446: "f32[72]", primals_448: "f32[72, 72, 3, 3]", primals_449: "f32[72]", primals_451: "f32[72, 72, 3, 3]", primals_452: "f32[72]", primals_454: "f32[72, 72, 3, 3]", primals_455: "f32[72]", primals_457: "f32[72, 72, 3, 3]", primals_458: "f32[72]", primals_460: "f32[18, 36, 1, 1]", primals_461: "f32[18]", primals_463: "f32[18, 72, 1, 1]", primals_464: "f32[18]", primals_466: "f32[36, 18, 3, 3]", primals_467: "f32[36]", primals_469: "f32[36, 72, 1, 1]", primals_470: "f32[36]", primals_472: "f32[18, 18, 3, 3]", primals_473: "f32[18]", primals_475: "f32[72, 18, 3, 3]", primals_476: "f32[72]", primals_478: "f32[72, 36, 3, 3]", primals_479: "f32[72]", primals_481: "f32[144, 72, 3, 3]", primals_482: "f32[144]", primals_484: "f32[18, 18, 3, 3]", primals_485: "f32[18]", primals_487: "f32[18, 18, 3, 3]", primals_488: "f32[18]", primals_490: "f32[18, 18, 3, 3]", primals_491: "f32[18]", primals_493: "f32[18, 18, 3, 3]", primals_494: "f32[18]", primals_496: "f32[18, 18, 3, 3]", primals_497: "f32[18]", primals_499: "f32[18, 18, 3, 3]", primals_500: "f32[18]", primals_502: "f32[18, 18, 3, 3]", primals_503: "f32[18]", primals_505: "f32[18, 18, 3, 3]", primals_506: "f32[18]", primals_508: "f32[36, 36, 3, 3]", primals_509: "f32[36]", primals_511: "f32[36, 36, 3, 3]", primals_512: "f32[36]", primals_514: "f32[36, 36, 3, 3]", primals_515: "f32[36]", primals_517: "f32[36, 36, 3, 3]", primals_518: "f32[36]", primals_520: "f32[36, 36, 3, 3]", primals_521: "f32[36]", primals_523: "f32[36, 36, 3, 3]", primals_524: "f32[36]", primals_526: "f32[36, 36, 3, 3]", primals_527: "f32[36]", primals_529: "f32[36, 36, 3, 3]", primals_530: "f32[36]", primals_532: "f32[72, 72, 3, 3]", primals_533: "f32[72]", primals_535: "f32[72, 72, 3, 3]", primals_536: "f32[72]", primals_538: "f32[72, 72, 3, 3]", primals_539: "f32[72]", primals_541: "f32[72, 72, 3, 3]", primals_542: "f32[72]", primals_544: "f32[72, 72, 3, 3]", primals_545: "f32[72]", primals_547: "f32[72, 72, 3, 3]", primals_548: "f32[72]", primals_550: "f32[72, 72, 3, 3]", primals_551: "f32[72]", primals_553: "f32[72, 72, 3, 3]", primals_554: "f32[72]", primals_556: "f32[144, 144, 3, 3]", primals_557: "f32[144]", primals_559: "f32[144, 144, 3, 3]", primals_560: "f32[144]", primals_562: "f32[144, 144, 3, 3]", primals_563: "f32[144]", primals_565: "f32[144, 144, 3, 3]", primals_566: "f32[144]", primals_568: "f32[144, 144, 3, 3]", primals_569: "f32[144]", primals_571: "f32[144, 144, 3, 3]", primals_572: "f32[144]", primals_574: "f32[144, 144, 3, 3]", primals_575: "f32[144]", primals_577: "f32[144, 144, 3, 3]", primals_578: "f32[144]", primals_580: "f32[18, 36, 1, 1]", primals_581: "f32[18]", primals_583: "f32[18, 72, 1, 1]", primals_584: "f32[18]", primals_586: "f32[18, 144, 1, 1]", primals_587: "f32[18]", primals_589: "f32[36, 18, 3, 3]", primals_590: "f32[36]", primals_592: "f32[36, 72, 1, 1]", primals_593: "f32[36]", primals_595: "f32[36, 144, 1, 1]", primals_596: "f32[36]", primals_598: "f32[18, 18, 3, 3]", primals_599: "f32[18]", primals_601: "f32[72, 18, 3, 3]", primals_602: "f32[72]", primals_604: "f32[72, 36, 3, 3]", primals_605: "f32[72]", primals_607: "f32[72, 144, 1, 1]", primals_608: "f32[72]", primals_610: "f32[18, 18, 3, 3]", primals_611: "f32[18]", primals_613: "f32[18, 18, 3, 3]", primals_614: "f32[18]", primals_616: "f32[144, 18, 3, 3]", primals_617: "f32[144]", primals_619: "f32[36, 36, 3, 3]", primals_620: "f32[36]", primals_622: "f32[144, 36, 3, 3]", primals_623: "f32[144]", primals_625: "f32[144, 72, 3, 3]", primals_626: "f32[144]", primals_628: "f32[18, 18, 3, 3]", primals_629: "f32[18]", primals_631: "f32[18, 18, 3, 3]", primals_632: "f32[18]", primals_634: "f32[18, 18, 3, 3]", primals_635: "f32[18]", primals_637: "f32[18, 18, 3, 3]", primals_638: "f32[18]", primals_640: "f32[18, 18, 3, 3]", primals_641: "f32[18]", primals_643: "f32[18, 18, 3, 3]", primals_644: "f32[18]", primals_646: "f32[18, 18, 3, 3]", primals_647: "f32[18]", primals_649: "f32[18, 18, 3, 3]", primals_650: "f32[18]", primals_652: "f32[36, 36, 3, 3]", primals_653: "f32[36]", primals_655: "f32[36, 36, 3, 3]", primals_656: "f32[36]", primals_658: "f32[36, 36, 3, 3]", primals_659: "f32[36]", primals_661: "f32[36, 36, 3, 3]", primals_662: "f32[36]", primals_664: "f32[36, 36, 3, 3]", primals_665: "f32[36]", primals_667: "f32[36, 36, 3, 3]", primals_668: "f32[36]", primals_670: "f32[36, 36, 3, 3]", primals_671: "f32[36]", primals_673: "f32[36, 36, 3, 3]", primals_674: "f32[36]", primals_676: "f32[72, 72, 3, 3]", primals_677: "f32[72]", primals_679: "f32[72, 72, 3, 3]", primals_680: "f32[72]", primals_682: "f32[72, 72, 3, 3]", primals_683: "f32[72]", primals_685: "f32[72, 72, 3, 3]", primals_686: "f32[72]", primals_688: "f32[72, 72, 3, 3]", primals_689: "f32[72]", primals_691: "f32[72, 72, 3, 3]", primals_692: "f32[72]", primals_694: "f32[72, 72, 3, 3]", primals_695: "f32[72]", primals_697: "f32[72, 72, 3, 3]", primals_698: "f32[72]", primals_700: "f32[144, 144, 3, 3]", primals_701: "f32[144]", primals_703: "f32[144, 144, 3, 3]", primals_704: "f32[144]", primals_706: "f32[144, 144, 3, 3]", primals_707: "f32[144]", primals_709: "f32[144, 144, 3, 3]", primals_710: "f32[144]", primals_712: "f32[144, 144, 3, 3]", primals_713: "f32[144]", primals_715: "f32[144, 144, 3, 3]", primals_716: "f32[144]", primals_718: "f32[144, 144, 3, 3]", primals_719: "f32[144]", primals_721: "f32[144, 144, 3, 3]", primals_722: "f32[144]", primals_724: "f32[18, 36, 1, 1]", primals_725: "f32[18]", primals_727: "f32[18, 72, 1, 1]", primals_728: "f32[18]", primals_730: "f32[18, 144, 1, 1]", primals_731: "f32[18]", primals_733: "f32[36, 18, 3, 3]", primals_734: "f32[36]", primals_736: "f32[36, 72, 1, 1]", primals_737: "f32[36]", primals_739: "f32[36, 144, 1, 1]", primals_740: "f32[36]", primals_742: "f32[18, 18, 3, 3]", primals_743: "f32[18]", primals_745: "f32[72, 18, 3, 3]", primals_746: "f32[72]", primals_748: "f32[72, 36, 3, 3]", primals_749: "f32[72]", primals_751: "f32[72, 144, 1, 1]", primals_752: "f32[72]", primals_754: "f32[18, 18, 3, 3]", primals_755: "f32[18]", primals_757: "f32[18, 18, 3, 3]", primals_758: "f32[18]", primals_760: "f32[144, 18, 3, 3]", primals_761: "f32[144]", primals_763: "f32[36, 36, 3, 3]", primals_764: "f32[36]", primals_766: "f32[144, 36, 3, 3]", primals_767: "f32[144]", primals_769: "f32[144, 72, 3, 3]", primals_770: "f32[144]", primals_772: "f32[18, 18, 3, 3]", primals_773: "f32[18]", primals_775: "f32[18, 18, 3, 3]", primals_776: "f32[18]", primals_778: "f32[18, 18, 3, 3]", primals_779: "f32[18]", primals_781: "f32[18, 18, 3, 3]", primals_782: "f32[18]", primals_784: "f32[18, 18, 3, 3]", primals_785: "f32[18]", primals_787: "f32[18, 18, 3, 3]", primals_788: "f32[18]", primals_790: "f32[18, 18, 3, 3]", primals_791: "f32[18]", primals_793: "f32[18, 18, 3, 3]", primals_794: "f32[18]", primals_796: "f32[36, 36, 3, 3]", primals_797: "f32[36]", primals_799: "f32[36, 36, 3, 3]", primals_800: "f32[36]", primals_802: "f32[36, 36, 3, 3]", primals_803: "f32[36]", primals_805: "f32[36, 36, 3, 3]", primals_806: "f32[36]", primals_808: "f32[36, 36, 3, 3]", primals_809: "f32[36]", primals_811: "f32[36, 36, 3, 3]", primals_812: "f32[36]", primals_814: "f32[36, 36, 3, 3]", primals_815: "f32[36]", primals_817: "f32[36, 36, 3, 3]", primals_818: "f32[36]", primals_820: "f32[72, 72, 3, 3]", primals_821: "f32[72]", primals_823: "f32[72, 72, 3, 3]", primals_824: "f32[72]", primals_826: "f32[72, 72, 3, 3]", primals_827: "f32[72]", primals_829: "f32[72, 72, 3, 3]", primals_830: "f32[72]", primals_832: "f32[72, 72, 3, 3]", primals_833: "f32[72]", primals_835: "f32[72, 72, 3, 3]", primals_836: "f32[72]", primals_838: "f32[72, 72, 3, 3]", primals_839: "f32[72]", primals_841: "f32[72, 72, 3, 3]", primals_842: "f32[72]", primals_844: "f32[144, 144, 3, 3]", primals_845: "f32[144]", primals_847: "f32[144, 144, 3, 3]", primals_848: "f32[144]", primals_850: "f32[144, 144, 3, 3]", primals_851: "f32[144]", primals_853: "f32[144, 144, 3, 3]", primals_854: "f32[144]", primals_856: "f32[144, 144, 3, 3]", primals_857: "f32[144]", primals_859: "f32[144, 144, 3, 3]", primals_860: "f32[144]", primals_862: "f32[144, 144, 3, 3]", primals_863: "f32[144]", primals_865: "f32[144, 144, 3, 3]", primals_866: "f32[144]", primals_868: "f32[18, 36, 1, 1]", primals_869: "f32[18]", primals_871: "f32[18, 72, 1, 1]", primals_872: "f32[18]", primals_874: "f32[18, 144, 1, 1]", primals_875: "f32[18]", primals_877: "f32[36, 18, 3, 3]", primals_878: "f32[36]", primals_880: "f32[36, 72, 1, 1]", primals_881: "f32[36]", primals_883: "f32[36, 144, 1, 1]", primals_884: "f32[36]", primals_886: "f32[18, 18, 3, 3]", primals_887: "f32[18]", primals_889: "f32[72, 18, 3, 3]", primals_890: "f32[72]", primals_892: "f32[72, 36, 3, 3]", primals_893: "f32[72]", primals_895: "f32[72, 144, 1, 1]", primals_896: "f32[72]", primals_898: "f32[18, 18, 3, 3]", primals_899: "f32[18]", primals_901: "f32[18, 18, 3, 3]", primals_902: "f32[18]", primals_904: "f32[144, 18, 3, 3]", primals_905: "f32[144]", primals_907: "f32[36, 36, 3, 3]", primals_908: "f32[36]", primals_910: "f32[144, 36, 3, 3]", primals_911: "f32[144]", primals_913: "f32[144, 72, 3, 3]", primals_914: "f32[144]", primals_916: "f32[32, 18, 1, 1]", primals_917: "f32[32]", primals_919: "f32[32, 32, 3, 3]", primals_920: "f32[32]", primals_922: "f32[128, 32, 1, 1]", primals_923: "f32[128]", primals_925: "f32[128, 18, 1, 1]", primals_926: "f32[128]", primals_928: "f32[64, 36, 1, 1]", primals_929: "f32[64]", primals_931: "f32[64, 64, 3, 3]", primals_932: "f32[64]", primals_934: "f32[256, 64, 1, 1]", primals_935: "f32[256]", primals_937: "f32[256, 36, 1, 1]", primals_938: "f32[256]", primals_940: "f32[256, 128, 3, 3]", primals_942: "f32[256]", primals_944: "f32[128, 72, 1, 1]", primals_945: "f32[128]", primals_947: "f32[128, 128, 3, 3]", primals_948: "f32[128]", primals_950: "f32[512, 128, 1, 1]", primals_951: "f32[512]", primals_953: "f32[512, 72, 1, 1]", primals_954: "f32[512]", primals_956: "f32[512, 256, 3, 3]", primals_958: "f32[512]", primals_960: "f32[256, 144, 1, 1]", primals_961: "f32[256]", primals_963: "f32[256, 256, 3, 3]", primals_964: "f32[256]", primals_966: "f32[1024, 256, 1, 1]", primals_967: "f32[1024]", primals_969: "f32[1024, 144, 1, 1]", primals_970: "f32[1024]", primals_972: "f32[1024, 512, 3, 3]", primals_974: "f32[1024]", primals_976: "f32[2048, 1024, 1, 1]", primals_978: "f32[2048]", primals_1957: "f32[8, 3, 224, 224]", convolution: "f32[8, 64, 112, 112]", squeeze_1: "f32[64]", relu: "f32[8, 64, 112, 112]", convolution_1: "f32[8, 64, 56, 56]", squeeze_4: "f32[64]", relu_1: "f32[8, 64, 56, 56]", convolution_2: "f32[8, 64, 56, 56]", squeeze_7: "f32[64]", relu_2: "f32[8, 64, 56, 56]", convolution_3: "f32[8, 64, 56, 56]", squeeze_10: "f32[64]", relu_3: "f32[8, 64, 56, 56]", convolution_4: "f32[8, 256, 56, 56]", squeeze_13: "f32[256]", convolution_5: "f32[8, 256, 56, 56]", squeeze_16: "f32[256]", relu_4: "f32[8, 256, 56, 56]", convolution_6: "f32[8, 64, 56, 56]", squeeze_19: "f32[64]", relu_5: "f32[8, 64, 56, 56]", convolution_7: "f32[8, 64, 56, 56]", squeeze_22: "f32[64]", relu_6: "f32[8, 64, 56, 56]", convolution_8: "f32[8, 256, 56, 56]", squeeze_25: "f32[256]", relu_7: "f32[8, 256, 56, 56]", convolution_9: "f32[8, 64, 56, 56]", squeeze_28: "f32[64]", relu_8: "f32[8, 64, 56, 56]", convolution_10: "f32[8, 64, 56, 56]", squeeze_31: "f32[64]", relu_9: "f32[8, 64, 56, 56]", convolution_11: "f32[8, 256, 56, 56]", squeeze_34: "f32[256]", relu_10: "f32[8, 256, 56, 56]", convolution_12: "f32[8, 64, 56, 56]", squeeze_37: "f32[64]", relu_11: "f32[8, 64, 56, 56]", convolution_13: "f32[8, 64, 56, 56]", squeeze_40: "f32[64]", relu_12: "f32[8, 64, 56, 56]", convolution_14: "f32[8, 256, 56, 56]", squeeze_43: "f32[256]", relu_13: "f32[8, 256, 56, 56]", convolution_15: "f32[8, 18, 56, 56]", squeeze_46: "f32[18]", relu_14: "f32[8, 18, 56, 56]", convolution_16: "f32[8, 36, 28, 28]", squeeze_49: "f32[36]", relu_15: "f32[8, 36, 28, 28]", convolution_17: "f32[8, 18, 56, 56]", squeeze_52: "f32[18]", relu_16: "f32[8, 18, 56, 56]", convolution_18: "f32[8, 18, 56, 56]", squeeze_55: "f32[18]", relu_17: "f32[8, 18, 56, 56]", convolution_19: "f32[8, 18, 56, 56]", squeeze_58: "f32[18]", relu_18: "f32[8, 18, 56, 56]", convolution_20: "f32[8, 18, 56, 56]", squeeze_61: "f32[18]", relu_19: "f32[8, 18, 56, 56]", convolution_21: "f32[8, 18, 56, 56]", squeeze_64: "f32[18]", relu_20: "f32[8, 18, 56, 56]", convolution_22: "f32[8, 18, 56, 56]", squeeze_67: "f32[18]", relu_21: "f32[8, 18, 56, 56]", convolution_23: "f32[8, 18, 56, 56]", squeeze_70: "f32[18]", relu_22: "f32[8, 18, 56, 56]", convolution_24: "f32[8, 18, 56, 56]", squeeze_73: "f32[18]", relu_23: "f32[8, 18, 56, 56]", convolution_25: "f32[8, 36, 28, 28]", squeeze_76: "f32[36]", relu_24: "f32[8, 36, 28, 28]", convolution_26: "f32[8, 36, 28, 28]", squeeze_79: "f32[36]", relu_25: "f32[8, 36, 28, 28]", convolution_27: "f32[8, 36, 28, 28]", squeeze_82: "f32[36]", relu_26: "f32[8, 36, 28, 28]", convolution_28: "f32[8, 36, 28, 28]", squeeze_85: "f32[36]", relu_27: "f32[8, 36, 28, 28]", convolution_29: "f32[8, 36, 28, 28]", squeeze_88: "f32[36]", relu_28: "f32[8, 36, 28, 28]", convolution_30: "f32[8, 36, 28, 28]", squeeze_91: "f32[36]", relu_29: "f32[8, 36, 28, 28]", convolution_31: "f32[8, 36, 28, 28]", squeeze_94: "f32[36]", relu_30: "f32[8, 36, 28, 28]", convolution_32: "f32[8, 36, 28, 28]", squeeze_97: "f32[36]", relu_31: "f32[8, 36, 28, 28]", convolution_33: "f32[8, 18, 28, 28]", squeeze_100: "f32[18]", convert_element_type_2: "i64[56]", unsqueeze_136: "i64[56, 1]", relu_32: "f32[8, 18, 56, 56]", convolution_34: "f32[8, 36, 28, 28]", squeeze_103: "f32[36]", relu_33: "f32[8, 36, 28, 28]", convolution_35: "f32[8, 72, 14, 14]", squeeze_106: "f32[72]", relu_34: "f32[8, 72, 14, 14]", convolution_36: "f32[8, 18, 56, 56]", squeeze_109: "f32[18]", relu_35: "f32[8, 18, 56, 56]", convolution_37: "f32[8, 18, 56, 56]", squeeze_112: "f32[18]", relu_36: "f32[8, 18, 56, 56]", convolution_38: "f32[8, 18, 56, 56]", squeeze_115: "f32[18]", relu_37: "f32[8, 18, 56, 56]", convolution_39: "f32[8, 18, 56, 56]", squeeze_118: "f32[18]", relu_38: "f32[8, 18, 56, 56]", convolution_40: "f32[8, 18, 56, 56]", squeeze_121: "f32[18]", relu_39: "f32[8, 18, 56, 56]", convolution_41: "f32[8, 18, 56, 56]", squeeze_124: "f32[18]", relu_40: "f32[8, 18, 56, 56]", convolution_42: "f32[8, 18, 56, 56]", squeeze_127: "f32[18]", relu_41: "f32[8, 18, 56, 56]", convolution_43: "f32[8, 18, 56, 56]", squeeze_130: "f32[18]", relu_42: "f32[8, 18, 56, 56]", convolution_44: "f32[8, 36, 28, 28]", squeeze_133: "f32[36]", relu_43: "f32[8, 36, 28, 28]", convolution_45: "f32[8, 36, 28, 28]", squeeze_136: "f32[36]", relu_44: "f32[8, 36, 28, 28]", convolution_46: "f32[8, 36, 28, 28]", squeeze_139: "f32[36]", relu_45: "f32[8, 36, 28, 28]", convolution_47: "f32[8, 36, 28, 28]", squeeze_142: "f32[36]", relu_46: "f32[8, 36, 28, 28]", convolution_48: "f32[8, 36, 28, 28]", squeeze_145: "f32[36]", relu_47: "f32[8, 36, 28, 28]", convolution_49: "f32[8, 36, 28, 28]", squeeze_148: "f32[36]", relu_48: "f32[8, 36, 28, 28]", convolution_50: "f32[8, 36, 28, 28]", squeeze_151: "f32[36]", relu_49: "f32[8, 36, 28, 28]", convolution_51: "f32[8, 36, 28, 28]", squeeze_154: "f32[36]", relu_50: "f32[8, 36, 28, 28]", convolution_52: "f32[8, 72, 14, 14]", squeeze_157: "f32[72]", relu_51: "f32[8, 72, 14, 14]", convolution_53: "f32[8, 72, 14, 14]", squeeze_160: "f32[72]", relu_52: "f32[8, 72, 14, 14]", convolution_54: "f32[8, 72, 14, 14]", squeeze_163: "f32[72]", relu_53: "f32[8, 72, 14, 14]", convolution_55: "f32[8, 72, 14, 14]", squeeze_166: "f32[72]", relu_54: "f32[8, 72, 14, 14]", convolution_56: "f32[8, 72, 14, 14]", squeeze_169: "f32[72]", relu_55: "f32[8, 72, 14, 14]", convolution_57: "f32[8, 72, 14, 14]", squeeze_172: "f32[72]", relu_56: "f32[8, 72, 14, 14]", convolution_58: "f32[8, 72, 14, 14]", squeeze_175: "f32[72]", relu_57: "f32[8, 72, 14, 14]", convolution_59: "f32[8, 72, 14, 14]", squeeze_178: "f32[72]", relu_58: "f32[8, 72, 14, 14]", convolution_60: "f32[8, 18, 28, 28]", squeeze_181: "f32[18]", convolution_61: "f32[8, 18, 14, 14]", squeeze_184: "f32[18]", convert_element_type_14: "i64[56]", unsqueeze_250: "i64[56, 1]", relu_59: "f32[8, 18, 56, 56]", convolution_62: "f32[8, 36, 28, 28]", squeeze_187: "f32[36]", convolution_63: "f32[8, 36, 14, 14]", squeeze_190: "f32[36]", convert_element_type_20: "i64[28]", unsqueeze_259: "i64[28, 1]", relu_60: "f32[8, 36, 28, 28]", convolution_64: "f32[8, 18, 28, 28]", squeeze_193: "f32[18]", relu_61: "f32[8, 18, 28, 28]", convolution_65: "f32[8, 72, 14, 14]", squeeze_196: "f32[72]", convolution_66: "f32[8, 72, 14, 14]", squeeze_199: "f32[72]", relu_62: "f32[8, 72, 14, 14]", convolution_67: "f32[8, 18, 56, 56]", squeeze_202: "f32[18]", relu_63: "f32[8, 18, 56, 56]", convolution_68: "f32[8, 18, 56, 56]", squeeze_205: "f32[18]", relu_64: "f32[8, 18, 56, 56]", convolution_69: "f32[8, 18, 56, 56]", squeeze_208: "f32[18]", relu_65: "f32[8, 18, 56, 56]", convolution_70: "f32[8, 18, 56, 56]", squeeze_211: "f32[18]", relu_66: "f32[8, 18, 56, 56]", convolution_71: "f32[8, 18, 56, 56]", squeeze_214: "f32[18]", relu_67: "f32[8, 18, 56, 56]", convolution_72: "f32[8, 18, 56, 56]", squeeze_217: "f32[18]", relu_68: "f32[8, 18, 56, 56]", convolution_73: "f32[8, 18, 56, 56]", squeeze_220: "f32[18]", relu_69: "f32[8, 18, 56, 56]", convolution_74: "f32[8, 18, 56, 56]", squeeze_223: "f32[18]", relu_70: "f32[8, 18, 56, 56]", convolution_75: "f32[8, 36, 28, 28]", squeeze_226: "f32[36]", relu_71: "f32[8, 36, 28, 28]", convolution_76: "f32[8, 36, 28, 28]", squeeze_229: "f32[36]", relu_72: "f32[8, 36, 28, 28]", convolution_77: "f32[8, 36, 28, 28]", squeeze_232: "f32[36]", relu_73: "f32[8, 36, 28, 28]", convolution_78: "f32[8, 36, 28, 28]", squeeze_235: "f32[36]", relu_74: "f32[8, 36, 28, 28]", convolution_79: "f32[8, 36, 28, 28]", squeeze_238: "f32[36]", relu_75: "f32[8, 36, 28, 28]", convolution_80: "f32[8, 36, 28, 28]", squeeze_241: "f32[36]", relu_76: "f32[8, 36, 28, 28]", convolution_81: "f32[8, 36, 28, 28]", squeeze_244: "f32[36]", relu_77: "f32[8, 36, 28, 28]", convolution_82: "f32[8, 36, 28, 28]", squeeze_247: "f32[36]", relu_78: "f32[8, 36, 28, 28]", convolution_83: "f32[8, 72, 14, 14]", squeeze_250: "f32[72]", relu_79: "f32[8, 72, 14, 14]", convolution_84: "f32[8, 72, 14, 14]", squeeze_253: "f32[72]", relu_80: "f32[8, 72, 14, 14]", convolution_85: "f32[8, 72, 14, 14]", squeeze_256: "f32[72]", relu_81: "f32[8, 72, 14, 14]", convolution_86: "f32[8, 72, 14, 14]", squeeze_259: "f32[72]", relu_82: "f32[8, 72, 14, 14]", convolution_87: "f32[8, 72, 14, 14]", squeeze_262: "f32[72]", relu_83: "f32[8, 72, 14, 14]", convolution_88: "f32[8, 72, 14, 14]", squeeze_265: "f32[72]", relu_84: "f32[8, 72, 14, 14]", convolution_89: "f32[8, 72, 14, 14]", squeeze_268: "f32[72]", relu_85: "f32[8, 72, 14, 14]", convolution_90: "f32[8, 72, 14, 14]", squeeze_271: "f32[72]", relu_86: "f32[8, 72, 14, 14]", convolution_91: "f32[8, 18, 28, 28]", squeeze_274: "f32[18]", convolution_92: "f32[8, 18, 14, 14]", squeeze_277: "f32[18]", relu_87: "f32[8, 18, 56, 56]", convolution_93: "f32[8, 36, 28, 28]", squeeze_280: "f32[36]", convolution_94: "f32[8, 36, 14, 14]", squeeze_283: "f32[36]", relu_88: "f32[8, 36, 28, 28]", convolution_95: "f32[8, 18, 28, 28]", squeeze_286: "f32[18]", relu_89: "f32[8, 18, 28, 28]", convolution_96: "f32[8, 72, 14, 14]", squeeze_289: "f32[72]", convolution_97: "f32[8, 72, 14, 14]", squeeze_292: "f32[72]", relu_90: "f32[8, 72, 14, 14]", convolution_98: "f32[8, 18, 56, 56]", squeeze_295: "f32[18]", relu_91: "f32[8, 18, 56, 56]", convolution_99: "f32[8, 18, 56, 56]", squeeze_298: "f32[18]", relu_92: "f32[8, 18, 56, 56]", convolution_100: "f32[8, 18, 56, 56]", squeeze_301: "f32[18]", relu_93: "f32[8, 18, 56, 56]", convolution_101: "f32[8, 18, 56, 56]", squeeze_304: "f32[18]", relu_94: "f32[8, 18, 56, 56]", convolution_102: "f32[8, 18, 56, 56]", squeeze_307: "f32[18]", relu_95: "f32[8, 18, 56, 56]", convolution_103: "f32[8, 18, 56, 56]", squeeze_310: "f32[18]", relu_96: "f32[8, 18, 56, 56]", convolution_104: "f32[8, 18, 56, 56]", squeeze_313: "f32[18]", relu_97: "f32[8, 18, 56, 56]", convolution_105: "f32[8, 18, 56, 56]", squeeze_316: "f32[18]", relu_98: "f32[8, 18, 56, 56]", convolution_106: "f32[8, 36, 28, 28]", squeeze_319: "f32[36]", relu_99: "f32[8, 36, 28, 28]", convolution_107: "f32[8, 36, 28, 28]", squeeze_322: "f32[36]", relu_100: "f32[8, 36, 28, 28]", convolution_108: "f32[8, 36, 28, 28]", squeeze_325: "f32[36]", relu_101: "f32[8, 36, 28, 28]", convolution_109: "f32[8, 36, 28, 28]", squeeze_328: "f32[36]", relu_102: "f32[8, 36, 28, 28]", convolution_110: "f32[8, 36, 28, 28]", squeeze_331: "f32[36]", relu_103: "f32[8, 36, 28, 28]", convolution_111: "f32[8, 36, 28, 28]", squeeze_334: "f32[36]", relu_104: "f32[8, 36, 28, 28]", convolution_112: "f32[8, 36, 28, 28]", squeeze_337: "f32[36]", relu_105: "f32[8, 36, 28, 28]", convolution_113: "f32[8, 36, 28, 28]", squeeze_340: "f32[36]", relu_106: "f32[8, 36, 28, 28]", convolution_114: "f32[8, 72, 14, 14]", squeeze_343: "f32[72]", relu_107: "f32[8, 72, 14, 14]", convolution_115: "f32[8, 72, 14, 14]", squeeze_346: "f32[72]", relu_108: "f32[8, 72, 14, 14]", convolution_116: "f32[8, 72, 14, 14]", squeeze_349: "f32[72]", relu_109: "f32[8, 72, 14, 14]", convolution_117: "f32[8, 72, 14, 14]", squeeze_352: "f32[72]", relu_110: "f32[8, 72, 14, 14]", convolution_118: "f32[8, 72, 14, 14]", squeeze_355: "f32[72]", relu_111: "f32[8, 72, 14, 14]", convolution_119: "f32[8, 72, 14, 14]", squeeze_358: "f32[72]", relu_112: "f32[8, 72, 14, 14]", convolution_120: "f32[8, 72, 14, 14]", squeeze_361: "f32[72]", relu_113: "f32[8, 72, 14, 14]", convolution_121: "f32[8, 72, 14, 14]", squeeze_364: "f32[72]", relu_114: "f32[8, 72, 14, 14]", convolution_122: "f32[8, 18, 28, 28]", squeeze_367: "f32[18]", convolution_123: "f32[8, 18, 14, 14]", squeeze_370: "f32[18]", relu_115: "f32[8, 18, 56, 56]", convolution_124: "f32[8, 36, 28, 28]", squeeze_373: "f32[36]", convolution_125: "f32[8, 36, 14, 14]", squeeze_376: "f32[36]", relu_116: "f32[8, 36, 28, 28]", convolution_126: "f32[8, 18, 28, 28]", squeeze_379: "f32[18]", relu_117: "f32[8, 18, 28, 28]", convolution_127: "f32[8, 72, 14, 14]", squeeze_382: "f32[72]", convolution_128: "f32[8, 72, 14, 14]", squeeze_385: "f32[72]", relu_118: "f32[8, 72, 14, 14]", convolution_129: "f32[8, 18, 56, 56]", squeeze_388: "f32[18]", relu_119: "f32[8, 18, 56, 56]", convolution_130: "f32[8, 18, 56, 56]", squeeze_391: "f32[18]", relu_120: "f32[8, 18, 56, 56]", convolution_131: "f32[8, 18, 56, 56]", squeeze_394: "f32[18]", relu_121: "f32[8, 18, 56, 56]", convolution_132: "f32[8, 18, 56, 56]", squeeze_397: "f32[18]", relu_122: "f32[8, 18, 56, 56]", convolution_133: "f32[8, 18, 56, 56]", squeeze_400: "f32[18]", relu_123: "f32[8, 18, 56, 56]", convolution_134: "f32[8, 18, 56, 56]", squeeze_403: "f32[18]", relu_124: "f32[8, 18, 56, 56]", convolution_135: "f32[8, 18, 56, 56]", squeeze_406: "f32[18]", relu_125: "f32[8, 18, 56, 56]", convolution_136: "f32[8, 18, 56, 56]", squeeze_409: "f32[18]", relu_126: "f32[8, 18, 56, 56]", convolution_137: "f32[8, 36, 28, 28]", squeeze_412: "f32[36]", relu_127: "f32[8, 36, 28, 28]", convolution_138: "f32[8, 36, 28, 28]", squeeze_415: "f32[36]", relu_128: "f32[8, 36, 28, 28]", convolution_139: "f32[8, 36, 28, 28]", squeeze_418: "f32[36]", relu_129: "f32[8, 36, 28, 28]", convolution_140: "f32[8, 36, 28, 28]", squeeze_421: "f32[36]", relu_130: "f32[8, 36, 28, 28]", convolution_141: "f32[8, 36, 28, 28]", squeeze_424: "f32[36]", relu_131: "f32[8, 36, 28, 28]", convolution_142: "f32[8, 36, 28, 28]", squeeze_427: "f32[36]", relu_132: "f32[8, 36, 28, 28]", convolution_143: "f32[8, 36, 28, 28]", squeeze_430: "f32[36]", relu_133: "f32[8, 36, 28, 28]", convolution_144: "f32[8, 36, 28, 28]", squeeze_433: "f32[36]", relu_134: "f32[8, 36, 28, 28]", convolution_145: "f32[8, 72, 14, 14]", squeeze_436: "f32[72]", relu_135: "f32[8, 72, 14, 14]", convolution_146: "f32[8, 72, 14, 14]", squeeze_439: "f32[72]", relu_136: "f32[8, 72, 14, 14]", convolution_147: "f32[8, 72, 14, 14]", squeeze_442: "f32[72]", relu_137: "f32[8, 72, 14, 14]", convolution_148: "f32[8, 72, 14, 14]", squeeze_445: "f32[72]", relu_138: "f32[8, 72, 14, 14]", convolution_149: "f32[8, 72, 14, 14]", squeeze_448: "f32[72]", relu_139: "f32[8, 72, 14, 14]", convolution_150: "f32[8, 72, 14, 14]", squeeze_451: "f32[72]", relu_140: "f32[8, 72, 14, 14]", convolution_151: "f32[8, 72, 14, 14]", squeeze_454: "f32[72]", relu_141: "f32[8, 72, 14, 14]", convolution_152: "f32[8, 72, 14, 14]", squeeze_457: "f32[72]", relu_142: "f32[8, 72, 14, 14]", convolution_153: "f32[8, 18, 28, 28]", squeeze_460: "f32[18]", convolution_154: "f32[8, 18, 14, 14]", squeeze_463: "f32[18]", relu_143: "f32[8, 18, 56, 56]", convolution_155: "f32[8, 36, 28, 28]", squeeze_466: "f32[36]", convolution_156: "f32[8, 36, 14, 14]", squeeze_469: "f32[36]", relu_144: "f32[8, 36, 28, 28]", convolution_157: "f32[8, 18, 28, 28]", squeeze_472: "f32[18]", relu_145: "f32[8, 18, 28, 28]", convolution_158: "f32[8, 72, 14, 14]", squeeze_475: "f32[72]", convolution_159: "f32[8, 72, 14, 14]", squeeze_478: "f32[72]", relu_146: "f32[8, 72, 14, 14]", convolution_160: "f32[8, 144, 7, 7]", squeeze_481: "f32[144]", relu_147: "f32[8, 144, 7, 7]", convolution_161: "f32[8, 18, 56, 56]", squeeze_484: "f32[18]", relu_148: "f32[8, 18, 56, 56]", convolution_162: "f32[8, 18, 56, 56]", squeeze_487: "f32[18]", relu_149: "f32[8, 18, 56, 56]", convolution_163: "f32[8, 18, 56, 56]", squeeze_490: "f32[18]", relu_150: "f32[8, 18, 56, 56]", convolution_164: "f32[8, 18, 56, 56]", squeeze_493: "f32[18]", relu_151: "f32[8, 18, 56, 56]", convolution_165: "f32[8, 18, 56, 56]", squeeze_496: "f32[18]", relu_152: "f32[8, 18, 56, 56]", convolution_166: "f32[8, 18, 56, 56]", squeeze_499: "f32[18]", relu_153: "f32[8, 18, 56, 56]", convolution_167: "f32[8, 18, 56, 56]", squeeze_502: "f32[18]", relu_154: "f32[8, 18, 56, 56]", convolution_168: "f32[8, 18, 56, 56]", squeeze_505: "f32[18]", relu_155: "f32[8, 18, 56, 56]", convolution_169: "f32[8, 36, 28, 28]", squeeze_508: "f32[36]", relu_156: "f32[8, 36, 28, 28]", convolution_170: "f32[8, 36, 28, 28]", squeeze_511: "f32[36]", relu_157: "f32[8, 36, 28, 28]", convolution_171: "f32[8, 36, 28, 28]", squeeze_514: "f32[36]", relu_158: "f32[8, 36, 28, 28]", convolution_172: "f32[8, 36, 28, 28]", squeeze_517: "f32[36]", relu_159: "f32[8, 36, 28, 28]", convolution_173: "f32[8, 36, 28, 28]", squeeze_520: "f32[36]", relu_160: "f32[8, 36, 28, 28]", convolution_174: "f32[8, 36, 28, 28]", squeeze_523: "f32[36]", relu_161: "f32[8, 36, 28, 28]", convolution_175: "f32[8, 36, 28, 28]", squeeze_526: "f32[36]", relu_162: "f32[8, 36, 28, 28]", convolution_176: "f32[8, 36, 28, 28]", squeeze_529: "f32[36]", relu_163: "f32[8, 36, 28, 28]", convolution_177: "f32[8, 72, 14, 14]", squeeze_532: "f32[72]", relu_164: "f32[8, 72, 14, 14]", convolution_178: "f32[8, 72, 14, 14]", squeeze_535: "f32[72]", relu_165: "f32[8, 72, 14, 14]", convolution_179: "f32[8, 72, 14, 14]", squeeze_538: "f32[72]", relu_166: "f32[8, 72, 14, 14]", convolution_180: "f32[8, 72, 14, 14]", squeeze_541: "f32[72]", relu_167: "f32[8, 72, 14, 14]", convolution_181: "f32[8, 72, 14, 14]", squeeze_544: "f32[72]", relu_168: "f32[8, 72, 14, 14]", convolution_182: "f32[8, 72, 14, 14]", squeeze_547: "f32[72]", relu_169: "f32[8, 72, 14, 14]", convolution_183: "f32[8, 72, 14, 14]", squeeze_550: "f32[72]", relu_170: "f32[8, 72, 14, 14]", convolution_184: "f32[8, 72, 14, 14]", squeeze_553: "f32[72]", relu_171: "f32[8, 72, 14, 14]", convolution_185: "f32[8, 144, 7, 7]", squeeze_556: "f32[144]", relu_172: "f32[8, 144, 7, 7]", convolution_186: "f32[8, 144, 7, 7]", squeeze_559: "f32[144]", relu_173: "f32[8, 144, 7, 7]", convolution_187: "f32[8, 144, 7, 7]", squeeze_562: "f32[144]", relu_174: "f32[8, 144, 7, 7]", convolution_188: "f32[8, 144, 7, 7]", squeeze_565: "f32[144]", relu_175: "f32[8, 144, 7, 7]", convolution_189: "f32[8, 144, 7, 7]", squeeze_568: "f32[144]", relu_176: "f32[8, 144, 7, 7]", convolution_190: "f32[8, 144, 7, 7]", squeeze_571: "f32[144]", relu_177: "f32[8, 144, 7, 7]", convolution_191: "f32[8, 144, 7, 7]", squeeze_574: "f32[144]", relu_178: "f32[8, 144, 7, 7]", convolution_192: "f32[8, 144, 7, 7]", squeeze_577: "f32[144]", relu_179: "f32[8, 144, 7, 7]", convolution_193: "f32[8, 18, 28, 28]", squeeze_580: "f32[18]", convolution_194: "f32[8, 18, 14, 14]", squeeze_583: "f32[18]", convolution_195: "f32[8, 18, 7, 7]", squeeze_586: "f32[18]", convert_element_type_92: "i64[56]", unsqueeze_799: "i64[56, 1]", relu_180: "f32[8, 18, 56, 56]", convolution_196: "f32[8, 36, 28, 28]", squeeze_589: "f32[36]", convolution_197: "f32[8, 36, 14, 14]", squeeze_592: "f32[36]", convolution_198: "f32[8, 36, 7, 7]", squeeze_595: "f32[36]", convert_element_type_104: "i64[28]", unsqueeze_813: "i64[28, 1]", relu_181: "f32[8, 36, 28, 28]", convolution_199: "f32[8, 18, 28, 28]", squeeze_598: "f32[18]", relu_182: "f32[8, 18, 28, 28]", convolution_200: "f32[8, 72, 14, 14]", squeeze_601: "f32[72]", convolution_201: "f32[8, 72, 14, 14]", squeeze_604: "f32[72]", convolution_202: "f32[8, 72, 7, 7]", squeeze_607: "f32[72]", convert_element_type_110: "i64[14]", unsqueeze_830: "i64[14, 1]", relu_183: "f32[8, 72, 14, 14]", convolution_203: "f32[8, 18, 28, 28]", squeeze_610: "f32[18]", relu_184: "f32[8, 18, 28, 28]", convolution_204: "f32[8, 18, 14, 14]", squeeze_613: "f32[18]", relu_185: "f32[8, 18, 14, 14]", convolution_205: "f32[8, 144, 7, 7]", squeeze_616: "f32[144]", convolution_206: "f32[8, 36, 14, 14]", squeeze_619: "f32[36]", relu_186: "f32[8, 36, 14, 14]", convolution_207: "f32[8, 144, 7, 7]", squeeze_622: "f32[144]", convolution_208: "f32[8, 144, 7, 7]", squeeze_625: "f32[144]", relu_187: "f32[8, 144, 7, 7]", convolution_209: "f32[8, 18, 56, 56]", squeeze_628: "f32[18]", relu_188: "f32[8, 18, 56, 56]", convolution_210: "f32[8, 18, 56, 56]", squeeze_631: "f32[18]", relu_189: "f32[8, 18, 56, 56]", convolution_211: "f32[8, 18, 56, 56]", squeeze_634: "f32[18]", relu_190: "f32[8, 18, 56, 56]", convolution_212: "f32[8, 18, 56, 56]", squeeze_637: "f32[18]", relu_191: "f32[8, 18, 56, 56]", convolution_213: "f32[8, 18, 56, 56]", squeeze_640: "f32[18]", relu_192: "f32[8, 18, 56, 56]", convolution_214: "f32[8, 18, 56, 56]", squeeze_643: "f32[18]", relu_193: "f32[8, 18, 56, 56]", convolution_215: "f32[8, 18, 56, 56]", squeeze_646: "f32[18]", relu_194: "f32[8, 18, 56, 56]", convolution_216: "f32[8, 18, 56, 56]", squeeze_649: "f32[18]", relu_195: "f32[8, 18, 56, 56]", convolution_217: "f32[8, 36, 28, 28]", squeeze_652: "f32[36]", relu_196: "f32[8, 36, 28, 28]", convolution_218: "f32[8, 36, 28, 28]", squeeze_655: "f32[36]", relu_197: "f32[8, 36, 28, 28]", convolution_219: "f32[8, 36, 28, 28]", squeeze_658: "f32[36]", relu_198: "f32[8, 36, 28, 28]", convolution_220: "f32[8, 36, 28, 28]", squeeze_661: "f32[36]", relu_199: "f32[8, 36, 28, 28]", convolution_221: "f32[8, 36, 28, 28]", squeeze_664: "f32[36]", relu_200: "f32[8, 36, 28, 28]", convolution_222: "f32[8, 36, 28, 28]", squeeze_667: "f32[36]", relu_201: "f32[8, 36, 28, 28]", convolution_223: "f32[8, 36, 28, 28]", squeeze_670: "f32[36]", relu_202: "f32[8, 36, 28, 28]", convolution_224: "f32[8, 36, 28, 28]", squeeze_673: "f32[36]", relu_203: "f32[8, 36, 28, 28]", convolution_225: "f32[8, 72, 14, 14]", squeeze_676: "f32[72]", relu_204: "f32[8, 72, 14, 14]", convolution_226: "f32[8, 72, 14, 14]", squeeze_679: "f32[72]", relu_205: "f32[8, 72, 14, 14]", convolution_227: "f32[8, 72, 14, 14]", squeeze_682: "f32[72]", relu_206: "f32[8, 72, 14, 14]", convolution_228: "f32[8, 72, 14, 14]", squeeze_685: "f32[72]", relu_207: "f32[8, 72, 14, 14]", convolution_229: "f32[8, 72, 14, 14]", squeeze_688: "f32[72]", relu_208: "f32[8, 72, 14, 14]", convolution_230: "f32[8, 72, 14, 14]", squeeze_691: "f32[72]", relu_209: "f32[8, 72, 14, 14]", convolution_231: "f32[8, 72, 14, 14]", squeeze_694: "f32[72]", relu_210: "f32[8, 72, 14, 14]", convolution_232: "f32[8, 72, 14, 14]", squeeze_697: "f32[72]", relu_211: "f32[8, 72, 14, 14]", convolution_233: "f32[8, 144, 7, 7]", squeeze_700: "f32[144]", relu_212: "f32[8, 144, 7, 7]", convolution_234: "f32[8, 144, 7, 7]", squeeze_703: "f32[144]", relu_213: "f32[8, 144, 7, 7]", convolution_235: "f32[8, 144, 7, 7]", squeeze_706: "f32[144]", relu_214: "f32[8, 144, 7, 7]", convolution_236: "f32[8, 144, 7, 7]", squeeze_709: "f32[144]", relu_215: "f32[8, 144, 7, 7]", convolution_237: "f32[8, 144, 7, 7]", squeeze_712: "f32[144]", relu_216: "f32[8, 144, 7, 7]", convolution_238: "f32[8, 144, 7, 7]", squeeze_715: "f32[144]", relu_217: "f32[8, 144, 7, 7]", convolution_239: "f32[8, 144, 7, 7]", squeeze_718: "f32[144]", relu_218: "f32[8, 144, 7, 7]", convolution_240: "f32[8, 144, 7, 7]", squeeze_721: "f32[144]", relu_219: "f32[8, 144, 7, 7]", convolution_241: "f32[8, 18, 28, 28]", squeeze_724: "f32[18]", convolution_242: "f32[8, 18, 14, 14]", squeeze_727: "f32[18]", convolution_243: "f32[8, 18, 7, 7]", squeeze_730: "f32[18]", relu_220: "f32[8, 18, 56, 56]", convolution_244: "f32[8, 36, 28, 28]", squeeze_733: "f32[36]", convolution_245: "f32[8, 36, 14, 14]", squeeze_736: "f32[36]", convolution_246: "f32[8, 36, 7, 7]", squeeze_739: "f32[36]", relu_221: "f32[8, 36, 28, 28]", convolution_247: "f32[8, 18, 28, 28]", squeeze_742: "f32[18]", relu_222: "f32[8, 18, 28, 28]", convolution_248: "f32[8, 72, 14, 14]", squeeze_745: "f32[72]", convolution_249: "f32[8, 72, 14, 14]", squeeze_748: "f32[72]", convolution_250: "f32[8, 72, 7, 7]", squeeze_751: "f32[72]", relu_223: "f32[8, 72, 14, 14]", convolution_251: "f32[8, 18, 28, 28]", squeeze_754: "f32[18]", relu_224: "f32[8, 18, 28, 28]", convolution_252: "f32[8, 18, 14, 14]", squeeze_757: "f32[18]", relu_225: "f32[8, 18, 14, 14]", convolution_253: "f32[8, 144, 7, 7]", squeeze_760: "f32[144]", convolution_254: "f32[8, 36, 14, 14]", squeeze_763: "f32[36]", relu_226: "f32[8, 36, 14, 14]", convolution_255: "f32[8, 144, 7, 7]", squeeze_766: "f32[144]", convolution_256: "f32[8, 144, 7, 7]", squeeze_769: "f32[144]", relu_227: "f32[8, 144, 7, 7]", convolution_257: "f32[8, 18, 56, 56]", squeeze_772: "f32[18]", relu_228: "f32[8, 18, 56, 56]", convolution_258: "f32[8, 18, 56, 56]", squeeze_775: "f32[18]", relu_229: "f32[8, 18, 56, 56]", convolution_259: "f32[8, 18, 56, 56]", squeeze_778: "f32[18]", relu_230: "f32[8, 18, 56, 56]", convolution_260: "f32[8, 18, 56, 56]", squeeze_781: "f32[18]", relu_231: "f32[8, 18, 56, 56]", convolution_261: "f32[8, 18, 56, 56]", squeeze_784: "f32[18]", relu_232: "f32[8, 18, 56, 56]", convolution_262: "f32[8, 18, 56, 56]", squeeze_787: "f32[18]", relu_233: "f32[8, 18, 56, 56]", convolution_263: "f32[8, 18, 56, 56]", squeeze_790: "f32[18]", relu_234: "f32[8, 18, 56, 56]", convolution_264: "f32[8, 18, 56, 56]", squeeze_793: "f32[18]", relu_235: "f32[8, 18, 56, 56]", convolution_265: "f32[8, 36, 28, 28]", squeeze_796: "f32[36]", relu_236: "f32[8, 36, 28, 28]", convolution_266: "f32[8, 36, 28, 28]", squeeze_799: "f32[36]", relu_237: "f32[8, 36, 28, 28]", convolution_267: "f32[8, 36, 28, 28]", squeeze_802: "f32[36]", relu_238: "f32[8, 36, 28, 28]", convolution_268: "f32[8, 36, 28, 28]", squeeze_805: "f32[36]", relu_239: "f32[8, 36, 28, 28]", convolution_269: "f32[8, 36, 28, 28]", squeeze_808: "f32[36]", relu_240: "f32[8, 36, 28, 28]", convolution_270: "f32[8, 36, 28, 28]", squeeze_811: "f32[36]", relu_241: "f32[8, 36, 28, 28]", convolution_271: "f32[8, 36, 28, 28]", squeeze_814: "f32[36]", relu_242: "f32[8, 36, 28, 28]", convolution_272: "f32[8, 36, 28, 28]", squeeze_817: "f32[36]", relu_243: "f32[8, 36, 28, 28]", convolution_273: "f32[8, 72, 14, 14]", squeeze_820: "f32[72]", relu_244: "f32[8, 72, 14, 14]", convolution_274: "f32[8, 72, 14, 14]", squeeze_823: "f32[72]", relu_245: "f32[8, 72, 14, 14]", convolution_275: "f32[8, 72, 14, 14]", squeeze_826: "f32[72]", relu_246: "f32[8, 72, 14, 14]", convolution_276: "f32[8, 72, 14, 14]", squeeze_829: "f32[72]", relu_247: "f32[8, 72, 14, 14]", convolution_277: "f32[8, 72, 14, 14]", squeeze_832: "f32[72]", relu_248: "f32[8, 72, 14, 14]", convolution_278: "f32[8, 72, 14, 14]", squeeze_835: "f32[72]", relu_249: "f32[8, 72, 14, 14]", convolution_279: "f32[8, 72, 14, 14]", squeeze_838: "f32[72]", relu_250: "f32[8, 72, 14, 14]", convolution_280: "f32[8, 72, 14, 14]", squeeze_841: "f32[72]", relu_251: "f32[8, 72, 14, 14]", convolution_281: "f32[8, 144, 7, 7]", squeeze_844: "f32[144]", relu_252: "f32[8, 144, 7, 7]", convolution_282: "f32[8, 144, 7, 7]", squeeze_847: "f32[144]", relu_253: "f32[8, 144, 7, 7]", convolution_283: "f32[8, 144, 7, 7]", squeeze_850: "f32[144]", relu_254: "f32[8, 144, 7, 7]", convolution_284: "f32[8, 144, 7, 7]", squeeze_853: "f32[144]", relu_255: "f32[8, 144, 7, 7]", convolution_285: "f32[8, 144, 7, 7]", squeeze_856: "f32[144]", relu_256: "f32[8, 144, 7, 7]", convolution_286: "f32[8, 144, 7, 7]", squeeze_859: "f32[144]", relu_257: "f32[8, 144, 7, 7]", convolution_287: "f32[8, 144, 7, 7]", squeeze_862: "f32[144]", relu_258: "f32[8, 144, 7, 7]", convolution_288: "f32[8, 144, 7, 7]", squeeze_865: "f32[144]", relu_259: "f32[8, 144, 7, 7]", convolution_289: "f32[8, 18, 28, 28]", squeeze_868: "f32[18]", convolution_290: "f32[8, 18, 14, 14]", squeeze_871: "f32[18]", convolution_291: "f32[8, 18, 7, 7]", squeeze_874: "f32[18]", relu_260: "f32[8, 18, 56, 56]", convolution_292: "f32[8, 36, 28, 28]", squeeze_877: "f32[36]", convolution_293: "f32[8, 36, 14, 14]", squeeze_880: "f32[36]", convolution_294: "f32[8, 36, 7, 7]", squeeze_883: "f32[36]", relu_261: "f32[8, 36, 28, 28]", convolution_295: "f32[8, 18, 28, 28]", squeeze_886: "f32[18]", relu_262: "f32[8, 18, 28, 28]", convolution_296: "f32[8, 72, 14, 14]", squeeze_889: "f32[72]", convolution_297: "f32[8, 72, 14, 14]", squeeze_892: "f32[72]", convolution_298: "f32[8, 72, 7, 7]", squeeze_895: "f32[72]", relu_263: "f32[8, 72, 14, 14]", convolution_299: "f32[8, 18, 28, 28]", squeeze_898: "f32[18]", relu_264: "f32[8, 18, 28, 28]", convolution_300: "f32[8, 18, 14, 14]", squeeze_901: "f32[18]", relu_265: "f32[8, 18, 14, 14]", convolution_301: "f32[8, 144, 7, 7]", squeeze_904: "f32[144]", convolution_302: "f32[8, 36, 14, 14]", squeeze_907: "f32[36]", relu_266: "f32[8, 36, 14, 14]", convolution_303: "f32[8, 144, 7, 7]", squeeze_910: "f32[144]", convolution_304: "f32[8, 144, 7, 7]", squeeze_913: "f32[144]", relu_267: "f32[8, 144, 7, 7]", convolution_305: "f32[8, 32, 56, 56]", squeeze_916: "f32[32]", relu_268: "f32[8, 32, 56, 56]", convolution_306: "f32[8, 32, 56, 56]", squeeze_919: "f32[32]", relu_269: "f32[8, 32, 56, 56]", convolution_307: "f32[8, 128, 56, 56]", squeeze_922: "f32[128]", convolution_308: "f32[8, 128, 56, 56]", squeeze_925: "f32[128]", relu_270: "f32[8, 128, 56, 56]", convolution_309: "f32[8, 64, 28, 28]", squeeze_928: "f32[64]", relu_271: "f32[8, 64, 28, 28]", convolution_310: "f32[8, 64, 28, 28]", squeeze_931: "f32[64]", relu_272: "f32[8, 64, 28, 28]", convolution_311: "f32[8, 256, 28, 28]", squeeze_934: "f32[256]", convolution_312: "f32[8, 256, 28, 28]", squeeze_937: "f32[256]", convolution_313: "f32[8, 256, 28, 28]", squeeze_940: "f32[256]", add_1866: "f32[8, 256, 28, 28]", convolution_314: "f32[8, 128, 14, 14]", squeeze_943: "f32[128]", relu_275: "f32[8, 128, 14, 14]", convolution_315: "f32[8, 128, 14, 14]", squeeze_946: "f32[128]", relu_276: "f32[8, 128, 14, 14]", convolution_316: "f32[8, 512, 14, 14]", squeeze_949: "f32[512]", convolution_317: "f32[8, 512, 14, 14]", squeeze_952: "f32[512]", convolution_318: "f32[8, 512, 14, 14]", squeeze_955: "f32[512]", add_1893: "f32[8, 512, 14, 14]", convolution_319: "f32[8, 256, 7, 7]", squeeze_958: "f32[256]", relu_279: "f32[8, 256, 7, 7]", convolution_320: "f32[8, 256, 7, 7]", squeeze_961: "f32[256]", relu_280: "f32[8, 256, 7, 7]", convolution_321: "f32[8, 1024, 7, 7]", squeeze_964: "f32[1024]", convolution_322: "f32[8, 1024, 7, 7]", squeeze_967: "f32[1024]", convolution_323: "f32[8, 1024, 7, 7]", squeeze_970: "f32[1024]", add_1920: "f32[8, 1024, 7, 7]", convolution_324: "f32[8, 2048, 7, 7]", squeeze_973: "f32[2048]", clone: "f32[8, 2048]", permute_1: "f32[1000, 2048]", le: "b8[8, 2048, 7, 7]", unsqueeze_1333: "f32[1, 2048, 1, 1]", le_1: "b8[8, 1024, 7, 7]", unsqueeze_1345: "f32[1, 1024, 1, 1]", le_2: "b8[8, 1024, 7, 7]", unsqueeze_1357: "f32[1, 1024, 1, 1]", unsqueeze_1369: "f32[1, 1024, 1, 1]", unsqueeze_1381: "f32[1, 256, 1, 1]", unsqueeze_1393: "f32[1, 256, 1, 1]", le_5: "b8[8, 512, 14, 14]", unsqueeze_1405: "f32[1, 512, 1, 1]", le_6: "b8[8, 512, 14, 14]", unsqueeze_1417: "f32[1, 512, 1, 1]", unsqueeze_1429: "f32[1, 512, 1, 1]", unsqueeze_1441: "f32[1, 128, 1, 1]", unsqueeze_1453: "f32[1, 128, 1, 1]", le_9: "b8[8, 256, 28, 28]", unsqueeze_1465: "f32[1, 256, 1, 1]", le_10: "b8[8, 256, 28, 28]", unsqueeze_1477: "f32[1, 256, 1, 1]", unsqueeze_1489: "f32[1, 256, 1, 1]", unsqueeze_1501: "f32[1, 64, 1, 1]", unsqueeze_1513: "f32[1, 64, 1, 1]", unsqueeze_1525: "f32[1, 128, 1, 1]", unsqueeze_1537: "f32[1, 128, 1, 1]", unsqueeze_1549: "f32[1, 32, 1, 1]", unsqueeze_1561: "f32[1, 32, 1, 1]", unsqueeze_1573: "f32[1, 144, 1, 1]", unsqueeze_1585: "f32[1, 144, 1, 1]", unsqueeze_1597: "f32[1, 36, 1, 1]", unsqueeze_1609: "f32[1, 144, 1, 1]", unsqueeze_1621: "f32[1, 18, 1, 1]", unsqueeze_1633: "f32[1, 18, 1, 1]", unsqueeze_1645: "f32[1, 72, 1, 1]", unsqueeze_1657: "f32[1, 72, 1, 1]", unsqueeze_1669: "f32[1, 72, 1, 1]", unsqueeze_1681: "f32[1, 18, 1, 1]", unsqueeze_1693: "f32[1, 36, 1, 1]", unsqueeze_1705: "f32[1, 36, 1, 1]", unsqueeze_1717: "f32[1, 36, 1, 1]", unsqueeze_1729: "f32[1, 18, 1, 1]", unsqueeze_1741: "f32[1, 18, 1, 1]", unsqueeze_1753: "f32[1, 18, 1, 1]", unsqueeze_1765: "f32[1, 144, 1, 1]", unsqueeze_1777: "f32[1, 144, 1, 1]", unsqueeze_1789: "f32[1, 144, 1, 1]", unsqueeze_1801: "f32[1, 144, 1, 1]", unsqueeze_1813: "f32[1, 144, 1, 1]", unsqueeze_1825: "f32[1, 144, 1, 1]", unsqueeze_1837: "f32[1, 144, 1, 1]", unsqueeze_1849: "f32[1, 144, 1, 1]", unsqueeze_1861: "f32[1, 72, 1, 1]", unsqueeze_1873: "f32[1, 72, 1, 1]", unsqueeze_1885: "f32[1, 72, 1, 1]", unsqueeze_1897: "f32[1, 72, 1, 1]", unsqueeze_1909: "f32[1, 72, 1, 1]", unsqueeze_1921: "f32[1, 72, 1, 1]", unsqueeze_1933: "f32[1, 72, 1, 1]", unsqueeze_1945: "f32[1, 72, 1, 1]", unsqueeze_1957: "f32[1, 36, 1, 1]", unsqueeze_1969: "f32[1, 36, 1, 1]", unsqueeze_1981: "f32[1, 36, 1, 1]", unsqueeze_1993: "f32[1, 36, 1, 1]", unsqueeze_2005: "f32[1, 36, 1, 1]", unsqueeze_2017: "f32[1, 36, 1, 1]", unsqueeze_2029: "f32[1, 36, 1, 1]", unsqueeze_2041: "f32[1, 36, 1, 1]", unsqueeze_2053: "f32[1, 18, 1, 1]", unsqueeze_2065: "f32[1, 18, 1, 1]", unsqueeze_2077: "f32[1, 18, 1, 1]", unsqueeze_2089: "f32[1, 18, 1, 1]", unsqueeze_2101: "f32[1, 18, 1, 1]", unsqueeze_2113: "f32[1, 18, 1, 1]", unsqueeze_2125: "f32[1, 18, 1, 1]", unsqueeze_2137: "f32[1, 18, 1, 1]", unsqueeze_2149: "f32[1, 144, 1, 1]", unsqueeze_2161: "f32[1, 144, 1, 1]", unsqueeze_2173: "f32[1, 36, 1, 1]", unsqueeze_2185: "f32[1, 144, 1, 1]", unsqueeze_2197: "f32[1, 18, 1, 1]", unsqueeze_2209: "f32[1, 18, 1, 1]", unsqueeze_2221: "f32[1, 72, 1, 1]", unsqueeze_2233: "f32[1, 72, 1, 1]", unsqueeze_2245: "f32[1, 72, 1, 1]", unsqueeze_2257: "f32[1, 18, 1, 1]", unsqueeze_2269: "f32[1, 36, 1, 1]", unsqueeze_2281: "f32[1, 36, 1, 1]", unsqueeze_2293: "f32[1, 36, 1, 1]", unsqueeze_2305: "f32[1, 18, 1, 1]", unsqueeze_2317: "f32[1, 18, 1, 1]", unsqueeze_2329: "f32[1, 18, 1, 1]", unsqueeze_2341: "f32[1, 144, 1, 1]", unsqueeze_2353: "f32[1, 144, 1, 1]", unsqueeze_2365: "f32[1, 144, 1, 1]", unsqueeze_2377: "f32[1, 144, 1, 1]", unsqueeze_2389: "f32[1, 144, 1, 1]", unsqueeze_2401: "f32[1, 144, 1, 1]", unsqueeze_2413: "f32[1, 144, 1, 1]", unsqueeze_2425: "f32[1, 144, 1, 1]", unsqueeze_2437: "f32[1, 72, 1, 1]", unsqueeze_2449: "f32[1, 72, 1, 1]", unsqueeze_2461: "f32[1, 72, 1, 1]", unsqueeze_2473: "f32[1, 72, 1, 1]", unsqueeze_2485: "f32[1, 72, 1, 1]", unsqueeze_2497: "f32[1, 72, 1, 1]", unsqueeze_2509: "f32[1, 72, 1, 1]", unsqueeze_2521: "f32[1, 72, 1, 1]", unsqueeze_2533: "f32[1, 36, 1, 1]", unsqueeze_2545: "f32[1, 36, 1, 1]", unsqueeze_2557: "f32[1, 36, 1, 1]", unsqueeze_2569: "f32[1, 36, 1, 1]", unsqueeze_2581: "f32[1, 36, 1, 1]", unsqueeze_2593: "f32[1, 36, 1, 1]", unsqueeze_2605: "f32[1, 36, 1, 1]", unsqueeze_2617: "f32[1, 36, 1, 1]", unsqueeze_2629: "f32[1, 18, 1, 1]", unsqueeze_2641: "f32[1, 18, 1, 1]", unsqueeze_2653: "f32[1, 18, 1, 1]", unsqueeze_2665: "f32[1, 18, 1, 1]", unsqueeze_2677: "f32[1, 18, 1, 1]", unsqueeze_2689: "f32[1, 18, 1, 1]", unsqueeze_2701: "f32[1, 18, 1, 1]", unsqueeze_2713: "f32[1, 18, 1, 1]", unsqueeze_2725: "f32[1, 144, 1, 1]", unsqueeze_2737: "f32[1, 144, 1, 1]", unsqueeze_2749: "f32[1, 36, 1, 1]", unsqueeze_2761: "f32[1, 144, 1, 1]", unsqueeze_2773: "f32[1, 18, 1, 1]", unsqueeze_2785: "f32[1, 18, 1, 1]", unsqueeze_2797: "f32[1, 72, 1, 1]", unsqueeze_2809: "f32[1, 72, 1, 1]", unsqueeze_2821: "f32[1, 72, 1, 1]", unsqueeze_2833: "f32[1, 18, 1, 1]", unsqueeze_2845: "f32[1, 36, 1, 1]", unsqueeze_2857: "f32[1, 36, 1, 1]", unsqueeze_2869: "f32[1, 36, 1, 1]", unsqueeze_2881: "f32[1, 18, 1, 1]", unsqueeze_2893: "f32[1, 18, 1, 1]", unsqueeze_2905: "f32[1, 18, 1, 1]", unsqueeze_2917: "f32[1, 144, 1, 1]", unsqueeze_2929: "f32[1, 144, 1, 1]", unsqueeze_2941: "f32[1, 144, 1, 1]", unsqueeze_2953: "f32[1, 144, 1, 1]", unsqueeze_2965: "f32[1, 144, 1, 1]", unsqueeze_2977: "f32[1, 144, 1, 1]", unsqueeze_2989: "f32[1, 144, 1, 1]", unsqueeze_3001: "f32[1, 144, 1, 1]", unsqueeze_3013: "f32[1, 72, 1, 1]", unsqueeze_3025: "f32[1, 72, 1, 1]", unsqueeze_3037: "f32[1, 72, 1, 1]", unsqueeze_3049: "f32[1, 72, 1, 1]", unsqueeze_3061: "f32[1, 72, 1, 1]", unsqueeze_3073: "f32[1, 72, 1, 1]", unsqueeze_3085: "f32[1, 72, 1, 1]", unsqueeze_3097: "f32[1, 72, 1, 1]", unsqueeze_3109: "f32[1, 36, 1, 1]", unsqueeze_3121: "f32[1, 36, 1, 1]", unsqueeze_3133: "f32[1, 36, 1, 1]", unsqueeze_3145: "f32[1, 36, 1, 1]", unsqueeze_3157: "f32[1, 36, 1, 1]", unsqueeze_3169: "f32[1, 36, 1, 1]", unsqueeze_3181: "f32[1, 36, 1, 1]", unsqueeze_3193: "f32[1, 36, 1, 1]", unsqueeze_3205: "f32[1, 18, 1, 1]", unsqueeze_3217: "f32[1, 18, 1, 1]", unsqueeze_3229: "f32[1, 18, 1, 1]", unsqueeze_3241: "f32[1, 18, 1, 1]", unsqueeze_3253: "f32[1, 18, 1, 1]", unsqueeze_3265: "f32[1, 18, 1, 1]", unsqueeze_3277: "f32[1, 18, 1, 1]", unsqueeze_3289: "f32[1, 18, 1, 1]", unsqueeze_3301: "f32[1, 144, 1, 1]", unsqueeze_3313: "f32[1, 72, 1, 1]", unsqueeze_3325: "f32[1, 72, 1, 1]", unsqueeze_3337: "f32[1, 18, 1, 1]", unsqueeze_3349: "f32[1, 36, 1, 1]", unsqueeze_3361: "f32[1, 36, 1, 1]", unsqueeze_3373: "f32[1, 18, 1, 1]", unsqueeze_3385: "f32[1, 18, 1, 1]", unsqueeze_3397: "f32[1, 72, 1, 1]", unsqueeze_3409: "f32[1, 72, 1, 1]", unsqueeze_3421: "f32[1, 72, 1, 1]", unsqueeze_3433: "f32[1, 72, 1, 1]", unsqueeze_3445: "f32[1, 72, 1, 1]", unsqueeze_3457: "f32[1, 72, 1, 1]", unsqueeze_3469: "f32[1, 72, 1, 1]", unsqueeze_3481: "f32[1, 72, 1, 1]", unsqueeze_3493: "f32[1, 36, 1, 1]", unsqueeze_3505: "f32[1, 36, 1, 1]", unsqueeze_3517: "f32[1, 36, 1, 1]", unsqueeze_3529: "f32[1, 36, 1, 1]", unsqueeze_3541: "f32[1, 36, 1, 1]", unsqueeze_3553: "f32[1, 36, 1, 1]", unsqueeze_3565: "f32[1, 36, 1, 1]", unsqueeze_3577: "f32[1, 36, 1, 1]", unsqueeze_3589: "f32[1, 18, 1, 1]", unsqueeze_3601: "f32[1, 18, 1, 1]", unsqueeze_3613: "f32[1, 18, 1, 1]", unsqueeze_3625: "f32[1, 18, 1, 1]", unsqueeze_3637: "f32[1, 18, 1, 1]", unsqueeze_3649: "f32[1, 18, 1, 1]", unsqueeze_3661: "f32[1, 18, 1, 1]", unsqueeze_3673: "f32[1, 18, 1, 1]", unsqueeze_3685: "f32[1, 72, 1, 1]", unsqueeze_3697: "f32[1, 72, 1, 1]", unsqueeze_3709: "f32[1, 18, 1, 1]", unsqueeze_3721: "f32[1, 36, 1, 1]", unsqueeze_3733: "f32[1, 36, 1, 1]", unsqueeze_3745: "f32[1, 18, 1, 1]", unsqueeze_3757: "f32[1, 18, 1, 1]", unsqueeze_3769: "f32[1, 72, 1, 1]", unsqueeze_3781: "f32[1, 72, 1, 1]", unsqueeze_3793: "f32[1, 72, 1, 1]", unsqueeze_3805: "f32[1, 72, 1, 1]", unsqueeze_3817: "f32[1, 72, 1, 1]", unsqueeze_3829: "f32[1, 72, 1, 1]", unsqueeze_3841: "f32[1, 72, 1, 1]", unsqueeze_3853: "f32[1, 72, 1, 1]", unsqueeze_3865: "f32[1, 36, 1, 1]", unsqueeze_3877: "f32[1, 36, 1, 1]", unsqueeze_3889: "f32[1, 36, 1, 1]", unsqueeze_3901: "f32[1, 36, 1, 1]", unsqueeze_3913: "f32[1, 36, 1, 1]", unsqueeze_3925: "f32[1, 36, 1, 1]", unsqueeze_3937: "f32[1, 36, 1, 1]", unsqueeze_3949: "f32[1, 36, 1, 1]", unsqueeze_3961: "f32[1, 18, 1, 1]", unsqueeze_3973: "f32[1, 18, 1, 1]", unsqueeze_3985: "f32[1, 18, 1, 1]", unsqueeze_3997: "f32[1, 18, 1, 1]", unsqueeze_4009: "f32[1, 18, 1, 1]", unsqueeze_4021: "f32[1, 18, 1, 1]", unsqueeze_4033: "f32[1, 18, 1, 1]", unsqueeze_4045: "f32[1, 18, 1, 1]", unsqueeze_4057: "f32[1, 72, 1, 1]", unsqueeze_4069: "f32[1, 72, 1, 1]", unsqueeze_4081: "f32[1, 18, 1, 1]", unsqueeze_4093: "f32[1, 36, 1, 1]", unsqueeze_4105: "f32[1, 36, 1, 1]", unsqueeze_4117: "f32[1, 18, 1, 1]", unsqueeze_4129: "f32[1, 18, 1, 1]", unsqueeze_4141: "f32[1, 72, 1, 1]", unsqueeze_4153: "f32[1, 72, 1, 1]", unsqueeze_4165: "f32[1, 72, 1, 1]", unsqueeze_4177: "f32[1, 72, 1, 1]", unsqueeze_4189: "f32[1, 72, 1, 1]", unsqueeze_4201: "f32[1, 72, 1, 1]", unsqueeze_4213: "f32[1, 72, 1, 1]", unsqueeze_4225: "f32[1, 72, 1, 1]", unsqueeze_4237: "f32[1, 36, 1, 1]", unsqueeze_4249: "f32[1, 36, 1, 1]", unsqueeze_4261: "f32[1, 36, 1, 1]", unsqueeze_4273: "f32[1, 36, 1, 1]", unsqueeze_4285: "f32[1, 36, 1, 1]", unsqueeze_4297: "f32[1, 36, 1, 1]", unsqueeze_4309: "f32[1, 36, 1, 1]", unsqueeze_4321: "f32[1, 36, 1, 1]", unsqueeze_4333: "f32[1, 18, 1, 1]", unsqueeze_4345: "f32[1, 18, 1, 1]", unsqueeze_4357: "f32[1, 18, 1, 1]", unsqueeze_4369: "f32[1, 18, 1, 1]", unsqueeze_4381: "f32[1, 18, 1, 1]", unsqueeze_4393: "f32[1, 18, 1, 1]", unsqueeze_4405: "f32[1, 18, 1, 1]", unsqueeze_4417: "f32[1, 18, 1, 1]", unsqueeze_4429: "f32[1, 72, 1, 1]", unsqueeze_4441: "f32[1, 72, 1, 1]", unsqueeze_4453: "f32[1, 18, 1, 1]", unsqueeze_4465: "f32[1, 36, 1, 1]", unsqueeze_4477: "f32[1, 36, 1, 1]", unsqueeze_4489: "f32[1, 18, 1, 1]", unsqueeze_4501: "f32[1, 18, 1, 1]", unsqueeze_4513: "f32[1, 72, 1, 1]", unsqueeze_4525: "f32[1, 72, 1, 1]", unsqueeze_4537: "f32[1, 72, 1, 1]", unsqueeze_4549: "f32[1, 72, 1, 1]", unsqueeze_4561: "f32[1, 72, 1, 1]", unsqueeze_4573: "f32[1, 72, 1, 1]", unsqueeze_4585: "f32[1, 72, 1, 1]", unsqueeze_4597: "f32[1, 72, 1, 1]", unsqueeze_4609: "f32[1, 36, 1, 1]", unsqueeze_4621: "f32[1, 36, 1, 1]", unsqueeze_4633: "f32[1, 36, 1, 1]", unsqueeze_4645: "f32[1, 36, 1, 1]", unsqueeze_4657: "f32[1, 36, 1, 1]", unsqueeze_4669: "f32[1, 36, 1, 1]", unsqueeze_4681: "f32[1, 36, 1, 1]", unsqueeze_4693: "f32[1, 36, 1, 1]", unsqueeze_4705: "f32[1, 18, 1, 1]", unsqueeze_4717: "f32[1, 18, 1, 1]", unsqueeze_4729: "f32[1, 18, 1, 1]", unsqueeze_4741: "f32[1, 18, 1, 1]", unsqueeze_4753: "f32[1, 18, 1, 1]", unsqueeze_4765: "f32[1, 18, 1, 1]", unsqueeze_4777: "f32[1, 18, 1, 1]", unsqueeze_4789: "f32[1, 18, 1, 1]", unsqueeze_4801: "f32[1, 72, 1, 1]", unsqueeze_4813: "f32[1, 36, 1, 1]", unsqueeze_4825: "f32[1, 18, 1, 1]", unsqueeze_4837: "f32[1, 36, 1, 1]", unsqueeze_4849: "f32[1, 36, 1, 1]", unsqueeze_4861: "f32[1, 36, 1, 1]", unsqueeze_4873: "f32[1, 36, 1, 1]", unsqueeze_4885: "f32[1, 36, 1, 1]", unsqueeze_4897: "f32[1, 36, 1, 1]", unsqueeze_4909: "f32[1, 36, 1, 1]", unsqueeze_4921: "f32[1, 36, 1, 1]", unsqueeze_4933: "f32[1, 18, 1, 1]", unsqueeze_4945: "f32[1, 18, 1, 1]", unsqueeze_4957: "f32[1, 18, 1, 1]", unsqueeze_4969: "f32[1, 18, 1, 1]", unsqueeze_4981: "f32[1, 18, 1, 1]", unsqueeze_4993: "f32[1, 18, 1, 1]", unsqueeze_5005: "f32[1, 18, 1, 1]", unsqueeze_5017: "f32[1, 18, 1, 1]", unsqueeze_5029: "f32[1, 36, 1, 1]", unsqueeze_5041: "f32[1, 18, 1, 1]", unsqueeze_5053: "f32[1, 256, 1, 1]", unsqueeze_5065: "f32[1, 64, 1, 1]", unsqueeze_5077: "f32[1, 64, 1, 1]", unsqueeze_5089: "f32[1, 256, 1, 1]", unsqueeze_5101: "f32[1, 64, 1, 1]", unsqueeze_5113: "f32[1, 64, 1, 1]", unsqueeze_5125: "f32[1, 256, 1, 1]", unsqueeze_5137: "f32[1, 64, 1, 1]", unsqueeze_5149: "f32[1, 64, 1, 1]", unsqueeze_5161: "f32[1, 256, 1, 1]", unsqueeze_5173: "f32[1, 256, 1, 1]", unsqueeze_5185: "f32[1, 64, 1, 1]", unsqueeze_5197: "f32[1, 64, 1, 1]", unsqueeze_5209: "f32[1, 64, 1, 1]", unsqueeze_5221: "f32[1, 64, 1, 1]", tangents_1: "f32[8, 1000]"):
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:789, code: return x if pre_logits else self.classifier(x)
    mm: "f32[8, 2048]" = torch.ops.aten.mm.default(tangents_1, permute_1);  permute_1 = None
    permute_2: "f32[1000, 8]" = torch.ops.aten.permute.default(tangents_1, [1, 0])
    mm_1: "f32[1000, 2048]" = torch.ops.aten.mm.default(permute_2, clone);  permute_2 = clone = None
    permute_3: "f32[2048, 1000]" = torch.ops.aten.permute.default(mm_1, [1, 0]);  mm_1 = None
    sum_1: "f32[1, 1000]" = torch.ops.aten.sum.dim_IntList(tangents_1, [0], True);  tangents_1 = None
    view_1: "f32[1000]" = torch.ops.aten.reshape.default(sum_1, [1000]);  sum_1 = None
    permute_4: "f32[1000, 2048]" = torch.ops.aten.permute.default(permute_3, [1, 0]);  permute_3 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/layers/adaptive_avgmax_pool.py:168, code: x = self.flatten(x)
    view_2: "f32[8, 2048, 1, 1]" = torch.ops.aten.reshape.default(mm, [8, 2048, 1, 1]);  mm = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/layers/adaptive_avgmax_pool.py:167, code: x = self.pool(x)
    expand: "f32[8, 2048, 7, 7]" = torch.ops.aten.expand.default(view_2, [8, 2048, 7, 7]);  view_2 = None
    div: "f32[8, 2048, 7, 7]" = torch.ops.aten.div.Scalar(expand, 49);  expand = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:782, code: y = self.final_layer(y)
    full_default: "f32[]" = torch.ops.aten.full.default([], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
    where: "f32[8, 2048, 7, 7]" = torch.ops.aten.where.self(le, full_default, div);  le = div = None
    sum_2: "f32[2048]" = torch.ops.aten.sum.dim_IntList(where, [0, 2, 3])
    sub_325: "f32[8, 2048, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_324, unsqueeze_1333);  convolution_324 = unsqueeze_1333 = None
    mul_2399: "f32[8, 2048, 7, 7]" = torch.ops.aten.mul.Tensor(where, sub_325)
    sum_3: "f32[2048]" = torch.ops.aten.sum.dim_IntList(mul_2399, [0, 2, 3]);  mul_2399 = None
    mul_2400: "f32[2048]" = torch.ops.aten.mul.Tensor(sum_2, 0.002551020408163265)
    unsqueeze_1334: "f32[1, 2048]" = torch.ops.aten.unsqueeze.default(mul_2400, 0);  mul_2400 = None
    unsqueeze_1335: "f32[1, 2048, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1334, 2);  unsqueeze_1334 = None
    unsqueeze_1336: "f32[1, 2048, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1335, 3);  unsqueeze_1335 = None
    mul_2401: "f32[2048]" = torch.ops.aten.mul.Tensor(sum_3, 0.002551020408163265)
    mul_2402: "f32[2048]" = torch.ops.aten.mul.Tensor(squeeze_973, squeeze_973)
    mul_2403: "f32[2048]" = torch.ops.aten.mul.Tensor(mul_2401, mul_2402);  mul_2401 = mul_2402 = None
    unsqueeze_1337: "f32[1, 2048]" = torch.ops.aten.unsqueeze.default(mul_2403, 0);  mul_2403 = None
    unsqueeze_1338: "f32[1, 2048, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1337, 2);  unsqueeze_1337 = None
    unsqueeze_1339: "f32[1, 2048, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1338, 3);  unsqueeze_1338 = None
    mul_2404: "f32[2048]" = torch.ops.aten.mul.Tensor(squeeze_973, primals_978);  primals_978 = None
    unsqueeze_1340: "f32[1, 2048]" = torch.ops.aten.unsqueeze.default(mul_2404, 0);  mul_2404 = None
    unsqueeze_1341: "f32[1, 2048, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1340, 2);  unsqueeze_1340 = None
    unsqueeze_1342: "f32[1, 2048, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1341, 3);  unsqueeze_1341 = None
    mul_2405: "f32[8, 2048, 7, 7]" = torch.ops.aten.mul.Tensor(sub_325, unsqueeze_1339);  sub_325 = unsqueeze_1339 = None
    sub_327: "f32[8, 2048, 7, 7]" = torch.ops.aten.sub.Tensor(where, mul_2405);  where = mul_2405 = None
    sub_328: "f32[8, 2048, 7, 7]" = torch.ops.aten.sub.Tensor(sub_327, unsqueeze_1336);  sub_327 = unsqueeze_1336 = None
    mul_2406: "f32[8, 2048, 7, 7]" = torch.ops.aten.mul.Tensor(sub_328, unsqueeze_1342);  sub_328 = unsqueeze_1342 = None
    mul_2407: "f32[2048]" = torch.ops.aten.mul.Tensor(sum_3, squeeze_973);  sum_3 = squeeze_973 = None
    convolution_backward = torch.ops.aten.convolution_backward.default(mul_2406, add_1920, primals_976, [2048], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, True]);  mul_2406 = add_1920 = primals_976 = None
    getitem_650: "f32[8, 1024, 7, 7]" = convolution_backward[0]
    getitem_651: "f32[2048, 1024, 1, 1]" = convolution_backward[1]
    getitem_652: "f32[2048]" = convolution_backward[2];  convolution_backward = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:780, code: y = incre(yl[i]) + down.forward(y)
    where_1: "f32[8, 1024, 7, 7]" = torch.ops.aten.where.self(le_1, full_default, getitem_650);  le_1 = None
    sum_4: "f32[1024]" = torch.ops.aten.sum.dim_IntList(where_1, [0, 2, 3])
    sub_329: "f32[8, 1024, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_323, unsqueeze_1345);  convolution_323 = unsqueeze_1345 = None
    mul_2408: "f32[8, 1024, 7, 7]" = torch.ops.aten.mul.Tensor(where_1, sub_329)
    sum_5: "f32[1024]" = torch.ops.aten.sum.dim_IntList(mul_2408, [0, 2, 3]);  mul_2408 = None
    mul_2409: "f32[1024]" = torch.ops.aten.mul.Tensor(sum_4, 0.002551020408163265)
    unsqueeze_1346: "f32[1, 1024]" = torch.ops.aten.unsqueeze.default(mul_2409, 0);  mul_2409 = None
    unsqueeze_1347: "f32[1, 1024, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1346, 2);  unsqueeze_1346 = None
    unsqueeze_1348: "f32[1, 1024, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1347, 3);  unsqueeze_1347 = None
    mul_2410: "f32[1024]" = torch.ops.aten.mul.Tensor(sum_5, 0.002551020408163265)
    mul_2411: "f32[1024]" = torch.ops.aten.mul.Tensor(squeeze_970, squeeze_970)
    mul_2412: "f32[1024]" = torch.ops.aten.mul.Tensor(mul_2410, mul_2411);  mul_2410 = mul_2411 = None
    unsqueeze_1349: "f32[1, 1024]" = torch.ops.aten.unsqueeze.default(mul_2412, 0);  mul_2412 = None
    unsqueeze_1350: "f32[1, 1024, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1349, 2);  unsqueeze_1349 = None
    unsqueeze_1351: "f32[1, 1024, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1350, 3);  unsqueeze_1350 = None
    mul_2413: "f32[1024]" = torch.ops.aten.mul.Tensor(squeeze_970, primals_974);  primals_974 = None
    unsqueeze_1352: "f32[1, 1024]" = torch.ops.aten.unsqueeze.default(mul_2413, 0);  mul_2413 = None
    unsqueeze_1353: "f32[1, 1024, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1352, 2);  unsqueeze_1352 = None
    unsqueeze_1354: "f32[1, 1024, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1353, 3);  unsqueeze_1353 = None
    mul_2414: "f32[8, 1024, 7, 7]" = torch.ops.aten.mul.Tensor(sub_329, unsqueeze_1351);  sub_329 = unsqueeze_1351 = None
    sub_331: "f32[8, 1024, 7, 7]" = torch.ops.aten.sub.Tensor(where_1, mul_2414);  where_1 = mul_2414 = None
    sub_332: "f32[8, 1024, 7, 7]" = torch.ops.aten.sub.Tensor(sub_331, unsqueeze_1348);  sub_331 = unsqueeze_1348 = None
    mul_2415: "f32[8, 1024, 7, 7]" = torch.ops.aten.mul.Tensor(sub_332, unsqueeze_1354);  sub_332 = unsqueeze_1354 = None
    mul_2416: "f32[1024]" = torch.ops.aten.mul.Tensor(sum_5, squeeze_970);  sum_5 = squeeze_970 = None
    convolution_backward_1 = torch.ops.aten.convolution_backward.default(mul_2415, add_1893, primals_972, [1024], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, True]);  mul_2415 = add_1893 = primals_972 = None
    getitem_653: "f32[8, 512, 14, 14]" = convolution_backward_1[0]
    getitem_654: "f32[1024, 512, 3, 3]" = convolution_backward_1[1]
    getitem_655: "f32[1024]" = convolution_backward_1[2];  convolution_backward_1 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:202, code: x = self.act3(x)
    where_2: "f32[8, 1024, 7, 7]" = torch.ops.aten.where.self(le_2, full_default, getitem_650);  le_2 = getitem_650 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:200, code: shortcut = self.downsample(shortcut)
    sum_6: "f32[1024]" = torch.ops.aten.sum.dim_IntList(where_2, [0, 2, 3])
    sub_333: "f32[8, 1024, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_322, unsqueeze_1357);  convolution_322 = unsqueeze_1357 = None
    mul_2417: "f32[8, 1024, 7, 7]" = torch.ops.aten.mul.Tensor(where_2, sub_333)
    sum_7: "f32[1024]" = torch.ops.aten.sum.dim_IntList(mul_2417, [0, 2, 3]);  mul_2417 = None
    mul_2418: "f32[1024]" = torch.ops.aten.mul.Tensor(sum_6, 0.002551020408163265)
    unsqueeze_1358: "f32[1, 1024]" = torch.ops.aten.unsqueeze.default(mul_2418, 0);  mul_2418 = None
    unsqueeze_1359: "f32[1, 1024, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1358, 2);  unsqueeze_1358 = None
    unsqueeze_1360: "f32[1, 1024, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1359, 3);  unsqueeze_1359 = None
    mul_2419: "f32[1024]" = torch.ops.aten.mul.Tensor(sum_7, 0.002551020408163265)
    mul_2420: "f32[1024]" = torch.ops.aten.mul.Tensor(squeeze_967, squeeze_967)
    mul_2421: "f32[1024]" = torch.ops.aten.mul.Tensor(mul_2419, mul_2420);  mul_2419 = mul_2420 = None
    unsqueeze_1361: "f32[1, 1024]" = torch.ops.aten.unsqueeze.default(mul_2421, 0);  mul_2421 = None
    unsqueeze_1362: "f32[1, 1024, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1361, 2);  unsqueeze_1361 = None
    unsqueeze_1363: "f32[1, 1024, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1362, 3);  unsqueeze_1362 = None
    mul_2422: "f32[1024]" = torch.ops.aten.mul.Tensor(squeeze_967, primals_970);  primals_970 = None
    unsqueeze_1364: "f32[1, 1024]" = torch.ops.aten.unsqueeze.default(mul_2422, 0);  mul_2422 = None
    unsqueeze_1365: "f32[1, 1024, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1364, 2);  unsqueeze_1364 = None
    unsqueeze_1366: "f32[1, 1024, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1365, 3);  unsqueeze_1365 = None
    mul_2423: "f32[8, 1024, 7, 7]" = torch.ops.aten.mul.Tensor(sub_333, unsqueeze_1363);  sub_333 = unsqueeze_1363 = None
    sub_335: "f32[8, 1024, 7, 7]" = torch.ops.aten.sub.Tensor(where_2, mul_2423);  mul_2423 = None
    sub_336: "f32[8, 1024, 7, 7]" = torch.ops.aten.sub.Tensor(sub_335, unsqueeze_1360);  sub_335 = None
    mul_2424: "f32[8, 1024, 7, 7]" = torch.ops.aten.mul.Tensor(sub_336, unsqueeze_1366);  sub_336 = unsqueeze_1366 = None
    mul_2425: "f32[1024]" = torch.ops.aten.mul.Tensor(sum_7, squeeze_967);  sum_7 = squeeze_967 = None
    convolution_backward_2 = torch.ops.aten.convolution_backward.default(mul_2424, relu_267, primals_969, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2424 = primals_969 = None
    getitem_656: "f32[8, 144, 7, 7]" = convolution_backward_2[0]
    getitem_657: "f32[1024, 144, 1, 1]" = convolution_backward_2[1];  convolution_backward_2 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:191, code: x = self.bn3(x)
    sub_337: "f32[8, 1024, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_321, unsqueeze_1369);  convolution_321 = unsqueeze_1369 = None
    mul_2426: "f32[8, 1024, 7, 7]" = torch.ops.aten.mul.Tensor(where_2, sub_337)
    sum_9: "f32[1024]" = torch.ops.aten.sum.dim_IntList(mul_2426, [0, 2, 3]);  mul_2426 = None
    mul_2428: "f32[1024]" = torch.ops.aten.mul.Tensor(sum_9, 0.002551020408163265)
    mul_2429: "f32[1024]" = torch.ops.aten.mul.Tensor(squeeze_964, squeeze_964)
    mul_2430: "f32[1024]" = torch.ops.aten.mul.Tensor(mul_2428, mul_2429);  mul_2428 = mul_2429 = None
    unsqueeze_1373: "f32[1, 1024]" = torch.ops.aten.unsqueeze.default(mul_2430, 0);  mul_2430 = None
    unsqueeze_1374: "f32[1, 1024, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1373, 2);  unsqueeze_1373 = None
    unsqueeze_1375: "f32[1, 1024, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1374, 3);  unsqueeze_1374 = None
    mul_2431: "f32[1024]" = torch.ops.aten.mul.Tensor(squeeze_964, primals_967);  primals_967 = None
    unsqueeze_1376: "f32[1, 1024]" = torch.ops.aten.unsqueeze.default(mul_2431, 0);  mul_2431 = None
    unsqueeze_1377: "f32[1, 1024, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1376, 2);  unsqueeze_1376 = None
    unsqueeze_1378: "f32[1, 1024, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1377, 3);  unsqueeze_1377 = None
    mul_2432: "f32[8, 1024, 7, 7]" = torch.ops.aten.mul.Tensor(sub_337, unsqueeze_1375);  sub_337 = unsqueeze_1375 = None
    sub_339: "f32[8, 1024, 7, 7]" = torch.ops.aten.sub.Tensor(where_2, mul_2432);  where_2 = mul_2432 = None
    sub_340: "f32[8, 1024, 7, 7]" = torch.ops.aten.sub.Tensor(sub_339, unsqueeze_1360);  sub_339 = unsqueeze_1360 = None
    mul_2433: "f32[8, 1024, 7, 7]" = torch.ops.aten.mul.Tensor(sub_340, unsqueeze_1378);  sub_340 = unsqueeze_1378 = None
    mul_2434: "f32[1024]" = torch.ops.aten.mul.Tensor(sum_9, squeeze_964);  sum_9 = squeeze_964 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:190, code: x = self.conv3(x)
    convolution_backward_3 = torch.ops.aten.convolution_backward.default(mul_2433, relu_280, primals_966, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2433 = primals_966 = None
    getitem_659: "f32[8, 256, 7, 7]" = convolution_backward_3[0]
    getitem_660: "f32[1024, 256, 1, 1]" = convolution_backward_3[1];  convolution_backward_3 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:187, code: x = self.act2(x)
    le_3: "b8[8, 256, 7, 7]" = torch.ops.aten.le.Scalar(relu_280, 0);  relu_280 = None
    where_3: "f32[8, 256, 7, 7]" = torch.ops.aten.where.self(le_3, full_default, getitem_659);  le_3 = getitem_659 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:185, code: x = self.bn2(x)
    sum_10: "f32[256]" = torch.ops.aten.sum.dim_IntList(where_3, [0, 2, 3])
    sub_341: "f32[8, 256, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_320, unsqueeze_1381);  convolution_320 = unsqueeze_1381 = None
    mul_2435: "f32[8, 256, 7, 7]" = torch.ops.aten.mul.Tensor(where_3, sub_341)
    sum_11: "f32[256]" = torch.ops.aten.sum.dim_IntList(mul_2435, [0, 2, 3]);  mul_2435 = None
    mul_2436: "f32[256]" = torch.ops.aten.mul.Tensor(sum_10, 0.002551020408163265)
    unsqueeze_1382: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_2436, 0);  mul_2436 = None
    unsqueeze_1383: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1382, 2);  unsqueeze_1382 = None
    unsqueeze_1384: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1383, 3);  unsqueeze_1383 = None
    mul_2437: "f32[256]" = torch.ops.aten.mul.Tensor(sum_11, 0.002551020408163265)
    mul_2438: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_961, squeeze_961)
    mul_2439: "f32[256]" = torch.ops.aten.mul.Tensor(mul_2437, mul_2438);  mul_2437 = mul_2438 = None
    unsqueeze_1385: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_2439, 0);  mul_2439 = None
    unsqueeze_1386: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1385, 2);  unsqueeze_1385 = None
    unsqueeze_1387: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1386, 3);  unsqueeze_1386 = None
    mul_2440: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_961, primals_964);  primals_964 = None
    unsqueeze_1388: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_2440, 0);  mul_2440 = None
    unsqueeze_1389: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1388, 2);  unsqueeze_1388 = None
    unsqueeze_1390: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1389, 3);  unsqueeze_1389 = None
    mul_2441: "f32[8, 256, 7, 7]" = torch.ops.aten.mul.Tensor(sub_341, unsqueeze_1387);  sub_341 = unsqueeze_1387 = None
    sub_343: "f32[8, 256, 7, 7]" = torch.ops.aten.sub.Tensor(where_3, mul_2441);  where_3 = mul_2441 = None
    sub_344: "f32[8, 256, 7, 7]" = torch.ops.aten.sub.Tensor(sub_343, unsqueeze_1384);  sub_343 = unsqueeze_1384 = None
    mul_2442: "f32[8, 256, 7, 7]" = torch.ops.aten.mul.Tensor(sub_344, unsqueeze_1390);  sub_344 = unsqueeze_1390 = None
    mul_2443: "f32[256]" = torch.ops.aten.mul.Tensor(sum_11, squeeze_961);  sum_11 = squeeze_961 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:184, code: x = self.conv2(x)
    convolution_backward_4 = torch.ops.aten.convolution_backward.default(mul_2442, relu_279, primals_963, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2442 = primals_963 = None
    getitem_662: "f32[8, 256, 7, 7]" = convolution_backward_4[0]
    getitem_663: "f32[256, 256, 3, 3]" = convolution_backward_4[1];  convolution_backward_4 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:182, code: x = self.act1(x)
    le_4: "b8[8, 256, 7, 7]" = torch.ops.aten.le.Scalar(relu_279, 0);  relu_279 = None
    where_4: "f32[8, 256, 7, 7]" = torch.ops.aten.where.self(le_4, full_default, getitem_662);  le_4 = getitem_662 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:181, code: x = self.bn1(x)
    sum_12: "f32[256]" = torch.ops.aten.sum.dim_IntList(where_4, [0, 2, 3])
    sub_345: "f32[8, 256, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_319, unsqueeze_1393);  convolution_319 = unsqueeze_1393 = None
    mul_2444: "f32[8, 256, 7, 7]" = torch.ops.aten.mul.Tensor(where_4, sub_345)
    sum_13: "f32[256]" = torch.ops.aten.sum.dim_IntList(mul_2444, [0, 2, 3]);  mul_2444 = None
    mul_2445: "f32[256]" = torch.ops.aten.mul.Tensor(sum_12, 0.002551020408163265)
    unsqueeze_1394: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_2445, 0);  mul_2445 = None
    unsqueeze_1395: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1394, 2);  unsqueeze_1394 = None
    unsqueeze_1396: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1395, 3);  unsqueeze_1395 = None
    mul_2446: "f32[256]" = torch.ops.aten.mul.Tensor(sum_13, 0.002551020408163265)
    mul_2447: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_958, squeeze_958)
    mul_2448: "f32[256]" = torch.ops.aten.mul.Tensor(mul_2446, mul_2447);  mul_2446 = mul_2447 = None
    unsqueeze_1397: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_2448, 0);  mul_2448 = None
    unsqueeze_1398: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1397, 2);  unsqueeze_1397 = None
    unsqueeze_1399: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1398, 3);  unsqueeze_1398 = None
    mul_2449: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_958, primals_961);  primals_961 = None
    unsqueeze_1400: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_2449, 0);  mul_2449 = None
    unsqueeze_1401: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1400, 2);  unsqueeze_1400 = None
    unsqueeze_1402: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1401, 3);  unsqueeze_1401 = None
    mul_2450: "f32[8, 256, 7, 7]" = torch.ops.aten.mul.Tensor(sub_345, unsqueeze_1399);  sub_345 = unsqueeze_1399 = None
    sub_347: "f32[8, 256, 7, 7]" = torch.ops.aten.sub.Tensor(where_4, mul_2450);  where_4 = mul_2450 = None
    sub_348: "f32[8, 256, 7, 7]" = torch.ops.aten.sub.Tensor(sub_347, unsqueeze_1396);  sub_347 = unsqueeze_1396 = None
    mul_2451: "f32[8, 256, 7, 7]" = torch.ops.aten.mul.Tensor(sub_348, unsqueeze_1402);  sub_348 = unsqueeze_1402 = None
    mul_2452: "f32[256]" = torch.ops.aten.mul.Tensor(sum_13, squeeze_958);  sum_13 = squeeze_958 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:180, code: x = self.conv1(x)
    convolution_backward_5 = torch.ops.aten.convolution_backward.default(mul_2451, relu_267, primals_960, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2451 = primals_960 = None
    getitem_665: "f32[8, 144, 7, 7]" = convolution_backward_5[0]
    getitem_666: "f32[256, 144, 1, 1]" = convolution_backward_5[1];  convolution_backward_5 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:180, code: x = self.conv1(x)
    add_1926: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(getitem_656, getitem_665);  getitem_656 = getitem_665 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:780, code: y = incre(yl[i]) + down.forward(y)
    where_5: "f32[8, 512, 14, 14]" = torch.ops.aten.where.self(le_5, full_default, getitem_653);  le_5 = None
    sum_14: "f32[512]" = torch.ops.aten.sum.dim_IntList(where_5, [0, 2, 3])
    sub_349: "f32[8, 512, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_318, unsqueeze_1405);  convolution_318 = unsqueeze_1405 = None
    mul_2453: "f32[8, 512, 14, 14]" = torch.ops.aten.mul.Tensor(where_5, sub_349)
    sum_15: "f32[512]" = torch.ops.aten.sum.dim_IntList(mul_2453, [0, 2, 3]);  mul_2453 = None
    mul_2454: "f32[512]" = torch.ops.aten.mul.Tensor(sum_14, 0.0006377551020408163)
    unsqueeze_1406: "f32[1, 512]" = torch.ops.aten.unsqueeze.default(mul_2454, 0);  mul_2454 = None
    unsqueeze_1407: "f32[1, 512, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1406, 2);  unsqueeze_1406 = None
    unsqueeze_1408: "f32[1, 512, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1407, 3);  unsqueeze_1407 = None
    mul_2455: "f32[512]" = torch.ops.aten.mul.Tensor(sum_15, 0.0006377551020408163)
    mul_2456: "f32[512]" = torch.ops.aten.mul.Tensor(squeeze_955, squeeze_955)
    mul_2457: "f32[512]" = torch.ops.aten.mul.Tensor(mul_2455, mul_2456);  mul_2455 = mul_2456 = None
    unsqueeze_1409: "f32[1, 512]" = torch.ops.aten.unsqueeze.default(mul_2457, 0);  mul_2457 = None
    unsqueeze_1410: "f32[1, 512, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1409, 2);  unsqueeze_1409 = None
    unsqueeze_1411: "f32[1, 512, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1410, 3);  unsqueeze_1410 = None
    mul_2458: "f32[512]" = torch.ops.aten.mul.Tensor(squeeze_955, primals_958);  primals_958 = None
    unsqueeze_1412: "f32[1, 512]" = torch.ops.aten.unsqueeze.default(mul_2458, 0);  mul_2458 = None
    unsqueeze_1413: "f32[1, 512, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1412, 2);  unsqueeze_1412 = None
    unsqueeze_1414: "f32[1, 512, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1413, 3);  unsqueeze_1413 = None
    mul_2459: "f32[8, 512, 14, 14]" = torch.ops.aten.mul.Tensor(sub_349, unsqueeze_1411);  sub_349 = unsqueeze_1411 = None
    sub_351: "f32[8, 512, 14, 14]" = torch.ops.aten.sub.Tensor(where_5, mul_2459);  where_5 = mul_2459 = None
    sub_352: "f32[8, 512, 14, 14]" = torch.ops.aten.sub.Tensor(sub_351, unsqueeze_1408);  sub_351 = unsqueeze_1408 = None
    mul_2460: "f32[8, 512, 14, 14]" = torch.ops.aten.mul.Tensor(sub_352, unsqueeze_1414);  sub_352 = unsqueeze_1414 = None
    mul_2461: "f32[512]" = torch.ops.aten.mul.Tensor(sum_15, squeeze_955);  sum_15 = squeeze_955 = None
    convolution_backward_6 = torch.ops.aten.convolution_backward.default(mul_2460, add_1866, primals_956, [512], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, True]);  mul_2460 = add_1866 = primals_956 = None
    getitem_668: "f32[8, 256, 28, 28]" = convolution_backward_6[0]
    getitem_669: "f32[512, 256, 3, 3]" = convolution_backward_6[1]
    getitem_670: "f32[512]" = convolution_backward_6[2];  convolution_backward_6 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:202, code: x = self.act3(x)
    where_6: "f32[8, 512, 14, 14]" = torch.ops.aten.where.self(le_6, full_default, getitem_653);  le_6 = getitem_653 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:200, code: shortcut = self.downsample(shortcut)
    sum_16: "f32[512]" = torch.ops.aten.sum.dim_IntList(where_6, [0, 2, 3])
    sub_353: "f32[8, 512, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_317, unsqueeze_1417);  convolution_317 = unsqueeze_1417 = None
    mul_2462: "f32[8, 512, 14, 14]" = torch.ops.aten.mul.Tensor(where_6, sub_353)
    sum_17: "f32[512]" = torch.ops.aten.sum.dim_IntList(mul_2462, [0, 2, 3]);  mul_2462 = None
    mul_2463: "f32[512]" = torch.ops.aten.mul.Tensor(sum_16, 0.0006377551020408163)
    unsqueeze_1418: "f32[1, 512]" = torch.ops.aten.unsqueeze.default(mul_2463, 0);  mul_2463 = None
    unsqueeze_1419: "f32[1, 512, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1418, 2);  unsqueeze_1418 = None
    unsqueeze_1420: "f32[1, 512, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1419, 3);  unsqueeze_1419 = None
    mul_2464: "f32[512]" = torch.ops.aten.mul.Tensor(sum_17, 0.0006377551020408163)
    mul_2465: "f32[512]" = torch.ops.aten.mul.Tensor(squeeze_952, squeeze_952)
    mul_2466: "f32[512]" = torch.ops.aten.mul.Tensor(mul_2464, mul_2465);  mul_2464 = mul_2465 = None
    unsqueeze_1421: "f32[1, 512]" = torch.ops.aten.unsqueeze.default(mul_2466, 0);  mul_2466 = None
    unsqueeze_1422: "f32[1, 512, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1421, 2);  unsqueeze_1421 = None
    unsqueeze_1423: "f32[1, 512, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1422, 3);  unsqueeze_1422 = None
    mul_2467: "f32[512]" = torch.ops.aten.mul.Tensor(squeeze_952, primals_954);  primals_954 = None
    unsqueeze_1424: "f32[1, 512]" = torch.ops.aten.unsqueeze.default(mul_2467, 0);  mul_2467 = None
    unsqueeze_1425: "f32[1, 512, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1424, 2);  unsqueeze_1424 = None
    unsqueeze_1426: "f32[1, 512, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1425, 3);  unsqueeze_1425 = None
    mul_2468: "f32[8, 512, 14, 14]" = torch.ops.aten.mul.Tensor(sub_353, unsqueeze_1423);  sub_353 = unsqueeze_1423 = None
    sub_355: "f32[8, 512, 14, 14]" = torch.ops.aten.sub.Tensor(where_6, mul_2468);  mul_2468 = None
    sub_356: "f32[8, 512, 14, 14]" = torch.ops.aten.sub.Tensor(sub_355, unsqueeze_1420);  sub_355 = None
    mul_2469: "f32[8, 512, 14, 14]" = torch.ops.aten.mul.Tensor(sub_356, unsqueeze_1426);  sub_356 = unsqueeze_1426 = None
    mul_2470: "f32[512]" = torch.ops.aten.mul.Tensor(sum_17, squeeze_952);  sum_17 = squeeze_952 = None
    convolution_backward_7 = torch.ops.aten.convolution_backward.default(mul_2469, relu_263, primals_953, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2469 = primals_953 = None
    getitem_671: "f32[8, 72, 14, 14]" = convolution_backward_7[0]
    getitem_672: "f32[512, 72, 1, 1]" = convolution_backward_7[1];  convolution_backward_7 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:191, code: x = self.bn3(x)
    sub_357: "f32[8, 512, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_316, unsqueeze_1429);  convolution_316 = unsqueeze_1429 = None
    mul_2471: "f32[8, 512, 14, 14]" = torch.ops.aten.mul.Tensor(where_6, sub_357)
    sum_19: "f32[512]" = torch.ops.aten.sum.dim_IntList(mul_2471, [0, 2, 3]);  mul_2471 = None
    mul_2473: "f32[512]" = torch.ops.aten.mul.Tensor(sum_19, 0.0006377551020408163)
    mul_2474: "f32[512]" = torch.ops.aten.mul.Tensor(squeeze_949, squeeze_949)
    mul_2475: "f32[512]" = torch.ops.aten.mul.Tensor(mul_2473, mul_2474);  mul_2473 = mul_2474 = None
    unsqueeze_1433: "f32[1, 512]" = torch.ops.aten.unsqueeze.default(mul_2475, 0);  mul_2475 = None
    unsqueeze_1434: "f32[1, 512, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1433, 2);  unsqueeze_1433 = None
    unsqueeze_1435: "f32[1, 512, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1434, 3);  unsqueeze_1434 = None
    mul_2476: "f32[512]" = torch.ops.aten.mul.Tensor(squeeze_949, primals_951);  primals_951 = None
    unsqueeze_1436: "f32[1, 512]" = torch.ops.aten.unsqueeze.default(mul_2476, 0);  mul_2476 = None
    unsqueeze_1437: "f32[1, 512, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1436, 2);  unsqueeze_1436 = None
    unsqueeze_1438: "f32[1, 512, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1437, 3);  unsqueeze_1437 = None
    mul_2477: "f32[8, 512, 14, 14]" = torch.ops.aten.mul.Tensor(sub_357, unsqueeze_1435);  sub_357 = unsqueeze_1435 = None
    sub_359: "f32[8, 512, 14, 14]" = torch.ops.aten.sub.Tensor(where_6, mul_2477);  where_6 = mul_2477 = None
    sub_360: "f32[8, 512, 14, 14]" = torch.ops.aten.sub.Tensor(sub_359, unsqueeze_1420);  sub_359 = unsqueeze_1420 = None
    mul_2478: "f32[8, 512, 14, 14]" = torch.ops.aten.mul.Tensor(sub_360, unsqueeze_1438);  sub_360 = unsqueeze_1438 = None
    mul_2479: "f32[512]" = torch.ops.aten.mul.Tensor(sum_19, squeeze_949);  sum_19 = squeeze_949 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:190, code: x = self.conv3(x)
    convolution_backward_8 = torch.ops.aten.convolution_backward.default(mul_2478, relu_276, primals_950, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2478 = primals_950 = None
    getitem_674: "f32[8, 128, 14, 14]" = convolution_backward_8[0]
    getitem_675: "f32[512, 128, 1, 1]" = convolution_backward_8[1];  convolution_backward_8 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:187, code: x = self.act2(x)
    le_7: "b8[8, 128, 14, 14]" = torch.ops.aten.le.Scalar(relu_276, 0);  relu_276 = None
    where_7: "f32[8, 128, 14, 14]" = torch.ops.aten.where.self(le_7, full_default, getitem_674);  le_7 = getitem_674 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:185, code: x = self.bn2(x)
    sum_20: "f32[128]" = torch.ops.aten.sum.dim_IntList(where_7, [0, 2, 3])
    sub_361: "f32[8, 128, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_315, unsqueeze_1441);  convolution_315 = unsqueeze_1441 = None
    mul_2480: "f32[8, 128, 14, 14]" = torch.ops.aten.mul.Tensor(where_7, sub_361)
    sum_21: "f32[128]" = torch.ops.aten.sum.dim_IntList(mul_2480, [0, 2, 3]);  mul_2480 = None
    mul_2481: "f32[128]" = torch.ops.aten.mul.Tensor(sum_20, 0.0006377551020408163)
    unsqueeze_1442: "f32[1, 128]" = torch.ops.aten.unsqueeze.default(mul_2481, 0);  mul_2481 = None
    unsqueeze_1443: "f32[1, 128, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1442, 2);  unsqueeze_1442 = None
    unsqueeze_1444: "f32[1, 128, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1443, 3);  unsqueeze_1443 = None
    mul_2482: "f32[128]" = torch.ops.aten.mul.Tensor(sum_21, 0.0006377551020408163)
    mul_2483: "f32[128]" = torch.ops.aten.mul.Tensor(squeeze_946, squeeze_946)
    mul_2484: "f32[128]" = torch.ops.aten.mul.Tensor(mul_2482, mul_2483);  mul_2482 = mul_2483 = None
    unsqueeze_1445: "f32[1, 128]" = torch.ops.aten.unsqueeze.default(mul_2484, 0);  mul_2484 = None
    unsqueeze_1446: "f32[1, 128, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1445, 2);  unsqueeze_1445 = None
    unsqueeze_1447: "f32[1, 128, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1446, 3);  unsqueeze_1446 = None
    mul_2485: "f32[128]" = torch.ops.aten.mul.Tensor(squeeze_946, primals_948);  primals_948 = None
    unsqueeze_1448: "f32[1, 128]" = torch.ops.aten.unsqueeze.default(mul_2485, 0);  mul_2485 = None
    unsqueeze_1449: "f32[1, 128, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1448, 2);  unsqueeze_1448 = None
    unsqueeze_1450: "f32[1, 128, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1449, 3);  unsqueeze_1449 = None
    mul_2486: "f32[8, 128, 14, 14]" = torch.ops.aten.mul.Tensor(sub_361, unsqueeze_1447);  sub_361 = unsqueeze_1447 = None
    sub_363: "f32[8, 128, 14, 14]" = torch.ops.aten.sub.Tensor(where_7, mul_2486);  where_7 = mul_2486 = None
    sub_364: "f32[8, 128, 14, 14]" = torch.ops.aten.sub.Tensor(sub_363, unsqueeze_1444);  sub_363 = unsqueeze_1444 = None
    mul_2487: "f32[8, 128, 14, 14]" = torch.ops.aten.mul.Tensor(sub_364, unsqueeze_1450);  sub_364 = unsqueeze_1450 = None
    mul_2488: "f32[128]" = torch.ops.aten.mul.Tensor(sum_21, squeeze_946);  sum_21 = squeeze_946 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:184, code: x = self.conv2(x)
    convolution_backward_9 = torch.ops.aten.convolution_backward.default(mul_2487, relu_275, primals_947, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2487 = primals_947 = None
    getitem_677: "f32[8, 128, 14, 14]" = convolution_backward_9[0]
    getitem_678: "f32[128, 128, 3, 3]" = convolution_backward_9[1];  convolution_backward_9 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:182, code: x = self.act1(x)
    le_8: "b8[8, 128, 14, 14]" = torch.ops.aten.le.Scalar(relu_275, 0);  relu_275 = None
    where_8: "f32[8, 128, 14, 14]" = torch.ops.aten.where.self(le_8, full_default, getitem_677);  le_8 = getitem_677 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:181, code: x = self.bn1(x)
    sum_22: "f32[128]" = torch.ops.aten.sum.dim_IntList(where_8, [0, 2, 3])
    sub_365: "f32[8, 128, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_314, unsqueeze_1453);  convolution_314 = unsqueeze_1453 = None
    mul_2489: "f32[8, 128, 14, 14]" = torch.ops.aten.mul.Tensor(where_8, sub_365)
    sum_23: "f32[128]" = torch.ops.aten.sum.dim_IntList(mul_2489, [0, 2, 3]);  mul_2489 = None
    mul_2490: "f32[128]" = torch.ops.aten.mul.Tensor(sum_22, 0.0006377551020408163)
    unsqueeze_1454: "f32[1, 128]" = torch.ops.aten.unsqueeze.default(mul_2490, 0);  mul_2490 = None
    unsqueeze_1455: "f32[1, 128, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1454, 2);  unsqueeze_1454 = None
    unsqueeze_1456: "f32[1, 128, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1455, 3);  unsqueeze_1455 = None
    mul_2491: "f32[128]" = torch.ops.aten.mul.Tensor(sum_23, 0.0006377551020408163)
    mul_2492: "f32[128]" = torch.ops.aten.mul.Tensor(squeeze_943, squeeze_943)
    mul_2493: "f32[128]" = torch.ops.aten.mul.Tensor(mul_2491, mul_2492);  mul_2491 = mul_2492 = None
    unsqueeze_1457: "f32[1, 128]" = torch.ops.aten.unsqueeze.default(mul_2493, 0);  mul_2493 = None
    unsqueeze_1458: "f32[1, 128, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1457, 2);  unsqueeze_1457 = None
    unsqueeze_1459: "f32[1, 128, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1458, 3);  unsqueeze_1458 = None
    mul_2494: "f32[128]" = torch.ops.aten.mul.Tensor(squeeze_943, primals_945);  primals_945 = None
    unsqueeze_1460: "f32[1, 128]" = torch.ops.aten.unsqueeze.default(mul_2494, 0);  mul_2494 = None
    unsqueeze_1461: "f32[1, 128, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1460, 2);  unsqueeze_1460 = None
    unsqueeze_1462: "f32[1, 128, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1461, 3);  unsqueeze_1461 = None
    mul_2495: "f32[8, 128, 14, 14]" = torch.ops.aten.mul.Tensor(sub_365, unsqueeze_1459);  sub_365 = unsqueeze_1459 = None
    sub_367: "f32[8, 128, 14, 14]" = torch.ops.aten.sub.Tensor(where_8, mul_2495);  where_8 = mul_2495 = None
    sub_368: "f32[8, 128, 14, 14]" = torch.ops.aten.sub.Tensor(sub_367, unsqueeze_1456);  sub_367 = unsqueeze_1456 = None
    mul_2496: "f32[8, 128, 14, 14]" = torch.ops.aten.mul.Tensor(sub_368, unsqueeze_1462);  sub_368 = unsqueeze_1462 = None
    mul_2497: "f32[128]" = torch.ops.aten.mul.Tensor(sum_23, squeeze_943);  sum_23 = squeeze_943 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:180, code: x = self.conv1(x)
    convolution_backward_10 = torch.ops.aten.convolution_backward.default(mul_2496, relu_263, primals_944, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2496 = primals_944 = None
    getitem_680: "f32[8, 72, 14, 14]" = convolution_backward_10[0]
    getitem_681: "f32[128, 72, 1, 1]" = convolution_backward_10[1];  convolution_backward_10 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:180, code: x = self.conv1(x)
    add_1927: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(getitem_671, getitem_680);  getitem_671 = getitem_680 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:780, code: y = incre(yl[i]) + down.forward(y)
    where_9: "f32[8, 256, 28, 28]" = torch.ops.aten.where.self(le_9, full_default, getitem_668);  le_9 = None
    sum_24: "f32[256]" = torch.ops.aten.sum.dim_IntList(where_9, [0, 2, 3])
    sub_369: "f32[8, 256, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_313, unsqueeze_1465);  convolution_313 = unsqueeze_1465 = None
    mul_2498: "f32[8, 256, 28, 28]" = torch.ops.aten.mul.Tensor(where_9, sub_369)
    sum_25: "f32[256]" = torch.ops.aten.sum.dim_IntList(mul_2498, [0, 2, 3]);  mul_2498 = None
    mul_2499: "f32[256]" = torch.ops.aten.mul.Tensor(sum_24, 0.00015943877551020407)
    unsqueeze_1466: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_2499, 0);  mul_2499 = None
    unsqueeze_1467: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1466, 2);  unsqueeze_1466 = None
    unsqueeze_1468: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1467, 3);  unsqueeze_1467 = None
    mul_2500: "f32[256]" = torch.ops.aten.mul.Tensor(sum_25, 0.00015943877551020407)
    mul_2501: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_940, squeeze_940)
    mul_2502: "f32[256]" = torch.ops.aten.mul.Tensor(mul_2500, mul_2501);  mul_2500 = mul_2501 = None
    unsqueeze_1469: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_2502, 0);  mul_2502 = None
    unsqueeze_1470: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1469, 2);  unsqueeze_1469 = None
    unsqueeze_1471: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1470, 3);  unsqueeze_1470 = None
    mul_2503: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_940, primals_942);  primals_942 = None
    unsqueeze_1472: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_2503, 0);  mul_2503 = None
    unsqueeze_1473: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1472, 2);  unsqueeze_1472 = None
    unsqueeze_1474: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1473, 3);  unsqueeze_1473 = None
    mul_2504: "f32[8, 256, 28, 28]" = torch.ops.aten.mul.Tensor(sub_369, unsqueeze_1471);  sub_369 = unsqueeze_1471 = None
    sub_371: "f32[8, 256, 28, 28]" = torch.ops.aten.sub.Tensor(where_9, mul_2504);  where_9 = mul_2504 = None
    sub_372: "f32[8, 256, 28, 28]" = torch.ops.aten.sub.Tensor(sub_371, unsqueeze_1468);  sub_371 = unsqueeze_1468 = None
    mul_2505: "f32[8, 256, 28, 28]" = torch.ops.aten.mul.Tensor(sub_372, unsqueeze_1474);  sub_372 = unsqueeze_1474 = None
    mul_2506: "f32[256]" = torch.ops.aten.mul.Tensor(sum_25, squeeze_940);  sum_25 = squeeze_940 = None
    convolution_backward_11 = torch.ops.aten.convolution_backward.default(mul_2505, relu_270, primals_940, [256], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, True]);  mul_2505 = primals_940 = None
    getitem_683: "f32[8, 128, 56, 56]" = convolution_backward_11[0]
    getitem_684: "f32[256, 128, 3, 3]" = convolution_backward_11[1]
    getitem_685: "f32[256]" = convolution_backward_11[2];  convolution_backward_11 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:202, code: x = self.act3(x)
    where_10: "f32[8, 256, 28, 28]" = torch.ops.aten.where.self(le_10, full_default, getitem_668);  le_10 = getitem_668 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:200, code: shortcut = self.downsample(shortcut)
    sum_26: "f32[256]" = torch.ops.aten.sum.dim_IntList(where_10, [0, 2, 3])
    sub_373: "f32[8, 256, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_312, unsqueeze_1477);  convolution_312 = unsqueeze_1477 = None
    mul_2507: "f32[8, 256, 28, 28]" = torch.ops.aten.mul.Tensor(where_10, sub_373)
    sum_27: "f32[256]" = torch.ops.aten.sum.dim_IntList(mul_2507, [0, 2, 3]);  mul_2507 = None
    mul_2508: "f32[256]" = torch.ops.aten.mul.Tensor(sum_26, 0.00015943877551020407)
    unsqueeze_1478: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_2508, 0);  mul_2508 = None
    unsqueeze_1479: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1478, 2);  unsqueeze_1478 = None
    unsqueeze_1480: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1479, 3);  unsqueeze_1479 = None
    mul_2509: "f32[256]" = torch.ops.aten.mul.Tensor(sum_27, 0.00015943877551020407)
    mul_2510: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_937, squeeze_937)
    mul_2511: "f32[256]" = torch.ops.aten.mul.Tensor(mul_2509, mul_2510);  mul_2509 = mul_2510 = None
    unsqueeze_1481: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_2511, 0);  mul_2511 = None
    unsqueeze_1482: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1481, 2);  unsqueeze_1481 = None
    unsqueeze_1483: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1482, 3);  unsqueeze_1482 = None
    mul_2512: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_937, primals_938);  primals_938 = None
    unsqueeze_1484: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_2512, 0);  mul_2512 = None
    unsqueeze_1485: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1484, 2);  unsqueeze_1484 = None
    unsqueeze_1486: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1485, 3);  unsqueeze_1485 = None
    mul_2513: "f32[8, 256, 28, 28]" = torch.ops.aten.mul.Tensor(sub_373, unsqueeze_1483);  sub_373 = unsqueeze_1483 = None
    sub_375: "f32[8, 256, 28, 28]" = torch.ops.aten.sub.Tensor(where_10, mul_2513);  mul_2513 = None
    sub_376: "f32[8, 256, 28, 28]" = torch.ops.aten.sub.Tensor(sub_375, unsqueeze_1480);  sub_375 = None
    mul_2514: "f32[8, 256, 28, 28]" = torch.ops.aten.mul.Tensor(sub_376, unsqueeze_1486);  sub_376 = unsqueeze_1486 = None
    mul_2515: "f32[256]" = torch.ops.aten.mul.Tensor(sum_27, squeeze_937);  sum_27 = squeeze_937 = None
    convolution_backward_12 = torch.ops.aten.convolution_backward.default(mul_2514, relu_261, primals_937, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2514 = primals_937 = None
    getitem_686: "f32[8, 36, 28, 28]" = convolution_backward_12[0]
    getitem_687: "f32[256, 36, 1, 1]" = convolution_backward_12[1];  convolution_backward_12 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:191, code: x = self.bn3(x)
    sub_377: "f32[8, 256, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_311, unsqueeze_1489);  convolution_311 = unsqueeze_1489 = None
    mul_2516: "f32[8, 256, 28, 28]" = torch.ops.aten.mul.Tensor(where_10, sub_377)
    sum_29: "f32[256]" = torch.ops.aten.sum.dim_IntList(mul_2516, [0, 2, 3]);  mul_2516 = None
    mul_2518: "f32[256]" = torch.ops.aten.mul.Tensor(sum_29, 0.00015943877551020407)
    mul_2519: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_934, squeeze_934)
    mul_2520: "f32[256]" = torch.ops.aten.mul.Tensor(mul_2518, mul_2519);  mul_2518 = mul_2519 = None
    unsqueeze_1493: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_2520, 0);  mul_2520 = None
    unsqueeze_1494: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1493, 2);  unsqueeze_1493 = None
    unsqueeze_1495: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1494, 3);  unsqueeze_1494 = None
    mul_2521: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_934, primals_935);  primals_935 = None
    unsqueeze_1496: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_2521, 0);  mul_2521 = None
    unsqueeze_1497: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1496, 2);  unsqueeze_1496 = None
    unsqueeze_1498: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1497, 3);  unsqueeze_1497 = None
    mul_2522: "f32[8, 256, 28, 28]" = torch.ops.aten.mul.Tensor(sub_377, unsqueeze_1495);  sub_377 = unsqueeze_1495 = None
    sub_379: "f32[8, 256, 28, 28]" = torch.ops.aten.sub.Tensor(where_10, mul_2522);  where_10 = mul_2522 = None
    sub_380: "f32[8, 256, 28, 28]" = torch.ops.aten.sub.Tensor(sub_379, unsqueeze_1480);  sub_379 = unsqueeze_1480 = None
    mul_2523: "f32[8, 256, 28, 28]" = torch.ops.aten.mul.Tensor(sub_380, unsqueeze_1498);  sub_380 = unsqueeze_1498 = None
    mul_2524: "f32[256]" = torch.ops.aten.mul.Tensor(sum_29, squeeze_934);  sum_29 = squeeze_934 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:190, code: x = self.conv3(x)
    convolution_backward_13 = torch.ops.aten.convolution_backward.default(mul_2523, relu_272, primals_934, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2523 = primals_934 = None
    getitem_689: "f32[8, 64, 28, 28]" = convolution_backward_13[0]
    getitem_690: "f32[256, 64, 1, 1]" = convolution_backward_13[1];  convolution_backward_13 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:187, code: x = self.act2(x)
    le_11: "b8[8, 64, 28, 28]" = torch.ops.aten.le.Scalar(relu_272, 0);  relu_272 = None
    where_11: "f32[8, 64, 28, 28]" = torch.ops.aten.where.self(le_11, full_default, getitem_689);  le_11 = getitem_689 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:185, code: x = self.bn2(x)
    sum_30: "f32[64]" = torch.ops.aten.sum.dim_IntList(where_11, [0, 2, 3])
    sub_381: "f32[8, 64, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_310, unsqueeze_1501);  convolution_310 = unsqueeze_1501 = None
    mul_2525: "f32[8, 64, 28, 28]" = torch.ops.aten.mul.Tensor(where_11, sub_381)
    sum_31: "f32[64]" = torch.ops.aten.sum.dim_IntList(mul_2525, [0, 2, 3]);  mul_2525 = None
    mul_2526: "f32[64]" = torch.ops.aten.mul.Tensor(sum_30, 0.00015943877551020407)
    unsqueeze_1502: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_2526, 0);  mul_2526 = None
    unsqueeze_1503: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1502, 2);  unsqueeze_1502 = None
    unsqueeze_1504: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1503, 3);  unsqueeze_1503 = None
    mul_2527: "f32[64]" = torch.ops.aten.mul.Tensor(sum_31, 0.00015943877551020407)
    mul_2528: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_931, squeeze_931)
    mul_2529: "f32[64]" = torch.ops.aten.mul.Tensor(mul_2527, mul_2528);  mul_2527 = mul_2528 = None
    unsqueeze_1505: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_2529, 0);  mul_2529 = None
    unsqueeze_1506: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1505, 2);  unsqueeze_1505 = None
    unsqueeze_1507: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1506, 3);  unsqueeze_1506 = None
    mul_2530: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_931, primals_932);  primals_932 = None
    unsqueeze_1508: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_2530, 0);  mul_2530 = None
    unsqueeze_1509: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1508, 2);  unsqueeze_1508 = None
    unsqueeze_1510: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1509, 3);  unsqueeze_1509 = None
    mul_2531: "f32[8, 64, 28, 28]" = torch.ops.aten.mul.Tensor(sub_381, unsqueeze_1507);  sub_381 = unsqueeze_1507 = None
    sub_383: "f32[8, 64, 28, 28]" = torch.ops.aten.sub.Tensor(where_11, mul_2531);  where_11 = mul_2531 = None
    sub_384: "f32[8, 64, 28, 28]" = torch.ops.aten.sub.Tensor(sub_383, unsqueeze_1504);  sub_383 = unsqueeze_1504 = None
    mul_2532: "f32[8, 64, 28, 28]" = torch.ops.aten.mul.Tensor(sub_384, unsqueeze_1510);  sub_384 = unsqueeze_1510 = None
    mul_2533: "f32[64]" = torch.ops.aten.mul.Tensor(sum_31, squeeze_931);  sum_31 = squeeze_931 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:184, code: x = self.conv2(x)
    convolution_backward_14 = torch.ops.aten.convolution_backward.default(mul_2532, relu_271, primals_931, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2532 = primals_931 = None
    getitem_692: "f32[8, 64, 28, 28]" = convolution_backward_14[0]
    getitem_693: "f32[64, 64, 3, 3]" = convolution_backward_14[1];  convolution_backward_14 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:182, code: x = self.act1(x)
    le_12: "b8[8, 64, 28, 28]" = torch.ops.aten.le.Scalar(relu_271, 0);  relu_271 = None
    where_12: "f32[8, 64, 28, 28]" = torch.ops.aten.where.self(le_12, full_default, getitem_692);  le_12 = getitem_692 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:181, code: x = self.bn1(x)
    sum_32: "f32[64]" = torch.ops.aten.sum.dim_IntList(where_12, [0, 2, 3])
    sub_385: "f32[8, 64, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_309, unsqueeze_1513);  convolution_309 = unsqueeze_1513 = None
    mul_2534: "f32[8, 64, 28, 28]" = torch.ops.aten.mul.Tensor(where_12, sub_385)
    sum_33: "f32[64]" = torch.ops.aten.sum.dim_IntList(mul_2534, [0, 2, 3]);  mul_2534 = None
    mul_2535: "f32[64]" = torch.ops.aten.mul.Tensor(sum_32, 0.00015943877551020407)
    unsqueeze_1514: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_2535, 0);  mul_2535 = None
    unsqueeze_1515: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1514, 2);  unsqueeze_1514 = None
    unsqueeze_1516: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1515, 3);  unsqueeze_1515 = None
    mul_2536: "f32[64]" = torch.ops.aten.mul.Tensor(sum_33, 0.00015943877551020407)
    mul_2537: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_928, squeeze_928)
    mul_2538: "f32[64]" = torch.ops.aten.mul.Tensor(mul_2536, mul_2537);  mul_2536 = mul_2537 = None
    unsqueeze_1517: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_2538, 0);  mul_2538 = None
    unsqueeze_1518: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1517, 2);  unsqueeze_1517 = None
    unsqueeze_1519: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1518, 3);  unsqueeze_1518 = None
    mul_2539: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_928, primals_929);  primals_929 = None
    unsqueeze_1520: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_2539, 0);  mul_2539 = None
    unsqueeze_1521: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1520, 2);  unsqueeze_1520 = None
    unsqueeze_1522: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1521, 3);  unsqueeze_1521 = None
    mul_2540: "f32[8, 64, 28, 28]" = torch.ops.aten.mul.Tensor(sub_385, unsqueeze_1519);  sub_385 = unsqueeze_1519 = None
    sub_387: "f32[8, 64, 28, 28]" = torch.ops.aten.sub.Tensor(where_12, mul_2540);  where_12 = mul_2540 = None
    sub_388: "f32[8, 64, 28, 28]" = torch.ops.aten.sub.Tensor(sub_387, unsqueeze_1516);  sub_387 = unsqueeze_1516 = None
    mul_2541: "f32[8, 64, 28, 28]" = torch.ops.aten.mul.Tensor(sub_388, unsqueeze_1522);  sub_388 = unsqueeze_1522 = None
    mul_2542: "f32[64]" = torch.ops.aten.mul.Tensor(sum_33, squeeze_928);  sum_33 = squeeze_928 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:180, code: x = self.conv1(x)
    convolution_backward_15 = torch.ops.aten.convolution_backward.default(mul_2541, relu_261, primals_928, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2541 = primals_928 = None
    getitem_695: "f32[8, 36, 28, 28]" = convolution_backward_15[0]
    getitem_696: "f32[64, 36, 1, 1]" = convolution_backward_15[1];  convolution_backward_15 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:180, code: x = self.conv1(x)
    add_1928: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(getitem_686, getitem_695);  getitem_686 = getitem_695 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:202, code: x = self.act3(x)
    le_13: "b8[8, 128, 56, 56]" = torch.ops.aten.le.Scalar(relu_270, 0);  relu_270 = None
    where_13: "f32[8, 128, 56, 56]" = torch.ops.aten.where.self(le_13, full_default, getitem_683);  le_13 = getitem_683 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:200, code: shortcut = self.downsample(shortcut)
    sum_34: "f32[128]" = torch.ops.aten.sum.dim_IntList(where_13, [0, 2, 3])
    sub_389: "f32[8, 128, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_308, unsqueeze_1525);  convolution_308 = unsqueeze_1525 = None
    mul_2543: "f32[8, 128, 56, 56]" = torch.ops.aten.mul.Tensor(where_13, sub_389)
    sum_35: "f32[128]" = torch.ops.aten.sum.dim_IntList(mul_2543, [0, 2, 3]);  mul_2543 = None
    mul_2544: "f32[128]" = torch.ops.aten.mul.Tensor(sum_34, 3.985969387755102e-05)
    unsqueeze_1526: "f32[1, 128]" = torch.ops.aten.unsqueeze.default(mul_2544, 0);  mul_2544 = None
    unsqueeze_1527: "f32[1, 128, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1526, 2);  unsqueeze_1526 = None
    unsqueeze_1528: "f32[1, 128, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1527, 3);  unsqueeze_1527 = None
    mul_2545: "f32[128]" = torch.ops.aten.mul.Tensor(sum_35, 3.985969387755102e-05)
    mul_2546: "f32[128]" = torch.ops.aten.mul.Tensor(squeeze_925, squeeze_925)
    mul_2547: "f32[128]" = torch.ops.aten.mul.Tensor(mul_2545, mul_2546);  mul_2545 = mul_2546 = None
    unsqueeze_1529: "f32[1, 128]" = torch.ops.aten.unsqueeze.default(mul_2547, 0);  mul_2547 = None
    unsqueeze_1530: "f32[1, 128, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1529, 2);  unsqueeze_1529 = None
    unsqueeze_1531: "f32[1, 128, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1530, 3);  unsqueeze_1530 = None
    mul_2548: "f32[128]" = torch.ops.aten.mul.Tensor(squeeze_925, primals_926);  primals_926 = None
    unsqueeze_1532: "f32[1, 128]" = torch.ops.aten.unsqueeze.default(mul_2548, 0);  mul_2548 = None
    unsqueeze_1533: "f32[1, 128, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1532, 2);  unsqueeze_1532 = None
    unsqueeze_1534: "f32[1, 128, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1533, 3);  unsqueeze_1533 = None
    mul_2549: "f32[8, 128, 56, 56]" = torch.ops.aten.mul.Tensor(sub_389, unsqueeze_1531);  sub_389 = unsqueeze_1531 = None
    sub_391: "f32[8, 128, 56, 56]" = torch.ops.aten.sub.Tensor(where_13, mul_2549);  mul_2549 = None
    sub_392: "f32[8, 128, 56, 56]" = torch.ops.aten.sub.Tensor(sub_391, unsqueeze_1528);  sub_391 = None
    mul_2550: "f32[8, 128, 56, 56]" = torch.ops.aten.mul.Tensor(sub_392, unsqueeze_1534);  sub_392 = unsqueeze_1534 = None
    mul_2551: "f32[128]" = torch.ops.aten.mul.Tensor(sum_35, squeeze_925);  sum_35 = squeeze_925 = None
    convolution_backward_16 = torch.ops.aten.convolution_backward.default(mul_2550, relu_260, primals_925, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2550 = primals_925 = None
    getitem_698: "f32[8, 18, 56, 56]" = convolution_backward_16[0]
    getitem_699: "f32[128, 18, 1, 1]" = convolution_backward_16[1];  convolution_backward_16 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:191, code: x = self.bn3(x)
    sub_393: "f32[8, 128, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_307, unsqueeze_1537);  convolution_307 = unsqueeze_1537 = None
    mul_2552: "f32[8, 128, 56, 56]" = torch.ops.aten.mul.Tensor(where_13, sub_393)
    sum_37: "f32[128]" = torch.ops.aten.sum.dim_IntList(mul_2552, [0, 2, 3]);  mul_2552 = None
    mul_2554: "f32[128]" = torch.ops.aten.mul.Tensor(sum_37, 3.985969387755102e-05)
    mul_2555: "f32[128]" = torch.ops.aten.mul.Tensor(squeeze_922, squeeze_922)
    mul_2556: "f32[128]" = torch.ops.aten.mul.Tensor(mul_2554, mul_2555);  mul_2554 = mul_2555 = None
    unsqueeze_1541: "f32[1, 128]" = torch.ops.aten.unsqueeze.default(mul_2556, 0);  mul_2556 = None
    unsqueeze_1542: "f32[1, 128, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1541, 2);  unsqueeze_1541 = None
    unsqueeze_1543: "f32[1, 128, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1542, 3);  unsqueeze_1542 = None
    mul_2557: "f32[128]" = torch.ops.aten.mul.Tensor(squeeze_922, primals_923);  primals_923 = None
    unsqueeze_1544: "f32[1, 128]" = torch.ops.aten.unsqueeze.default(mul_2557, 0);  mul_2557 = None
    unsqueeze_1545: "f32[1, 128, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1544, 2);  unsqueeze_1544 = None
    unsqueeze_1546: "f32[1, 128, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1545, 3);  unsqueeze_1545 = None
    mul_2558: "f32[8, 128, 56, 56]" = torch.ops.aten.mul.Tensor(sub_393, unsqueeze_1543);  sub_393 = unsqueeze_1543 = None
    sub_395: "f32[8, 128, 56, 56]" = torch.ops.aten.sub.Tensor(where_13, mul_2558);  where_13 = mul_2558 = None
    sub_396: "f32[8, 128, 56, 56]" = torch.ops.aten.sub.Tensor(sub_395, unsqueeze_1528);  sub_395 = unsqueeze_1528 = None
    mul_2559: "f32[8, 128, 56, 56]" = torch.ops.aten.mul.Tensor(sub_396, unsqueeze_1546);  sub_396 = unsqueeze_1546 = None
    mul_2560: "f32[128]" = torch.ops.aten.mul.Tensor(sum_37, squeeze_922);  sum_37 = squeeze_922 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:190, code: x = self.conv3(x)
    convolution_backward_17 = torch.ops.aten.convolution_backward.default(mul_2559, relu_269, primals_922, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2559 = primals_922 = None
    getitem_701: "f32[8, 32, 56, 56]" = convolution_backward_17[0]
    getitem_702: "f32[128, 32, 1, 1]" = convolution_backward_17[1];  convolution_backward_17 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:187, code: x = self.act2(x)
    le_14: "b8[8, 32, 56, 56]" = torch.ops.aten.le.Scalar(relu_269, 0);  relu_269 = None
    where_14: "f32[8, 32, 56, 56]" = torch.ops.aten.where.self(le_14, full_default, getitem_701);  le_14 = getitem_701 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:185, code: x = self.bn2(x)
    sum_38: "f32[32]" = torch.ops.aten.sum.dim_IntList(where_14, [0, 2, 3])
    sub_397: "f32[8, 32, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_306, unsqueeze_1549);  convolution_306 = unsqueeze_1549 = None
    mul_2561: "f32[8, 32, 56, 56]" = torch.ops.aten.mul.Tensor(where_14, sub_397)
    sum_39: "f32[32]" = torch.ops.aten.sum.dim_IntList(mul_2561, [0, 2, 3]);  mul_2561 = None
    mul_2562: "f32[32]" = torch.ops.aten.mul.Tensor(sum_38, 3.985969387755102e-05)
    unsqueeze_1550: "f32[1, 32]" = torch.ops.aten.unsqueeze.default(mul_2562, 0);  mul_2562 = None
    unsqueeze_1551: "f32[1, 32, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1550, 2);  unsqueeze_1550 = None
    unsqueeze_1552: "f32[1, 32, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1551, 3);  unsqueeze_1551 = None
    mul_2563: "f32[32]" = torch.ops.aten.mul.Tensor(sum_39, 3.985969387755102e-05)
    mul_2564: "f32[32]" = torch.ops.aten.mul.Tensor(squeeze_919, squeeze_919)
    mul_2565: "f32[32]" = torch.ops.aten.mul.Tensor(mul_2563, mul_2564);  mul_2563 = mul_2564 = None
    unsqueeze_1553: "f32[1, 32]" = torch.ops.aten.unsqueeze.default(mul_2565, 0);  mul_2565 = None
    unsqueeze_1554: "f32[1, 32, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1553, 2);  unsqueeze_1553 = None
    unsqueeze_1555: "f32[1, 32, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1554, 3);  unsqueeze_1554 = None
    mul_2566: "f32[32]" = torch.ops.aten.mul.Tensor(squeeze_919, primals_920);  primals_920 = None
    unsqueeze_1556: "f32[1, 32]" = torch.ops.aten.unsqueeze.default(mul_2566, 0);  mul_2566 = None
    unsqueeze_1557: "f32[1, 32, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1556, 2);  unsqueeze_1556 = None
    unsqueeze_1558: "f32[1, 32, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1557, 3);  unsqueeze_1557 = None
    mul_2567: "f32[8, 32, 56, 56]" = torch.ops.aten.mul.Tensor(sub_397, unsqueeze_1555);  sub_397 = unsqueeze_1555 = None
    sub_399: "f32[8, 32, 56, 56]" = torch.ops.aten.sub.Tensor(where_14, mul_2567);  where_14 = mul_2567 = None
    sub_400: "f32[8, 32, 56, 56]" = torch.ops.aten.sub.Tensor(sub_399, unsqueeze_1552);  sub_399 = unsqueeze_1552 = None
    mul_2568: "f32[8, 32, 56, 56]" = torch.ops.aten.mul.Tensor(sub_400, unsqueeze_1558);  sub_400 = unsqueeze_1558 = None
    mul_2569: "f32[32]" = torch.ops.aten.mul.Tensor(sum_39, squeeze_919);  sum_39 = squeeze_919 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:184, code: x = self.conv2(x)
    convolution_backward_18 = torch.ops.aten.convolution_backward.default(mul_2568, relu_268, primals_919, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2568 = primals_919 = None
    getitem_704: "f32[8, 32, 56, 56]" = convolution_backward_18[0]
    getitem_705: "f32[32, 32, 3, 3]" = convolution_backward_18[1];  convolution_backward_18 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:182, code: x = self.act1(x)
    le_15: "b8[8, 32, 56, 56]" = torch.ops.aten.le.Scalar(relu_268, 0);  relu_268 = None
    where_15: "f32[8, 32, 56, 56]" = torch.ops.aten.where.self(le_15, full_default, getitem_704);  le_15 = getitem_704 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:181, code: x = self.bn1(x)
    sum_40: "f32[32]" = torch.ops.aten.sum.dim_IntList(where_15, [0, 2, 3])
    sub_401: "f32[8, 32, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_305, unsqueeze_1561);  convolution_305 = unsqueeze_1561 = None
    mul_2570: "f32[8, 32, 56, 56]" = torch.ops.aten.mul.Tensor(where_15, sub_401)
    sum_41: "f32[32]" = torch.ops.aten.sum.dim_IntList(mul_2570, [0, 2, 3]);  mul_2570 = None
    mul_2571: "f32[32]" = torch.ops.aten.mul.Tensor(sum_40, 3.985969387755102e-05)
    unsqueeze_1562: "f32[1, 32]" = torch.ops.aten.unsqueeze.default(mul_2571, 0);  mul_2571 = None
    unsqueeze_1563: "f32[1, 32, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1562, 2);  unsqueeze_1562 = None
    unsqueeze_1564: "f32[1, 32, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1563, 3);  unsqueeze_1563 = None
    mul_2572: "f32[32]" = torch.ops.aten.mul.Tensor(sum_41, 3.985969387755102e-05)
    mul_2573: "f32[32]" = torch.ops.aten.mul.Tensor(squeeze_916, squeeze_916)
    mul_2574: "f32[32]" = torch.ops.aten.mul.Tensor(mul_2572, mul_2573);  mul_2572 = mul_2573 = None
    unsqueeze_1565: "f32[1, 32]" = torch.ops.aten.unsqueeze.default(mul_2574, 0);  mul_2574 = None
    unsqueeze_1566: "f32[1, 32, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1565, 2);  unsqueeze_1565 = None
    unsqueeze_1567: "f32[1, 32, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1566, 3);  unsqueeze_1566 = None
    mul_2575: "f32[32]" = torch.ops.aten.mul.Tensor(squeeze_916, primals_917);  primals_917 = None
    unsqueeze_1568: "f32[1, 32]" = torch.ops.aten.unsqueeze.default(mul_2575, 0);  mul_2575 = None
    unsqueeze_1569: "f32[1, 32, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1568, 2);  unsqueeze_1568 = None
    unsqueeze_1570: "f32[1, 32, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1569, 3);  unsqueeze_1569 = None
    mul_2576: "f32[8, 32, 56, 56]" = torch.ops.aten.mul.Tensor(sub_401, unsqueeze_1567);  sub_401 = unsqueeze_1567 = None
    sub_403: "f32[8, 32, 56, 56]" = torch.ops.aten.sub.Tensor(where_15, mul_2576);  where_15 = mul_2576 = None
    sub_404: "f32[8, 32, 56, 56]" = torch.ops.aten.sub.Tensor(sub_403, unsqueeze_1564);  sub_403 = unsqueeze_1564 = None
    mul_2577: "f32[8, 32, 56, 56]" = torch.ops.aten.mul.Tensor(sub_404, unsqueeze_1570);  sub_404 = unsqueeze_1570 = None
    mul_2578: "f32[32]" = torch.ops.aten.mul.Tensor(sum_41, squeeze_916);  sum_41 = squeeze_916 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:180, code: x = self.conv1(x)
    convolution_backward_19 = torch.ops.aten.convolution_backward.default(mul_2577, relu_260, primals_916, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2577 = primals_916 = None
    getitem_707: "f32[8, 18, 56, 56]" = convolution_backward_19[0]
    getitem_708: "f32[32, 18, 1, 1]" = convolution_backward_19[1];  convolution_backward_19 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:180, code: x = self.conv1(x)
    add_1929: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(getitem_698, getitem_707);  getitem_698 = getitem_707 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_16: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_267, 0);  relu_267 = None
    where_16: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_16, full_default, add_1926);  le_16 = add_1926 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    sum_42: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_16, [0, 2, 3])
    sub_405: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_304, unsqueeze_1573);  convolution_304 = unsqueeze_1573 = None
    mul_2579: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_16, sub_405)
    sum_43: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_2579, [0, 2, 3]);  mul_2579 = None
    mul_2580: "f32[144]" = torch.ops.aten.mul.Tensor(sum_42, 0.002551020408163265)
    unsqueeze_1574: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2580, 0);  mul_2580 = None
    unsqueeze_1575: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1574, 2);  unsqueeze_1574 = None
    unsqueeze_1576: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1575, 3);  unsqueeze_1575 = None
    mul_2581: "f32[144]" = torch.ops.aten.mul.Tensor(sum_43, 0.002551020408163265)
    mul_2582: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_913, squeeze_913)
    mul_2583: "f32[144]" = torch.ops.aten.mul.Tensor(mul_2581, mul_2582);  mul_2581 = mul_2582 = None
    unsqueeze_1577: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2583, 0);  mul_2583 = None
    unsqueeze_1578: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1577, 2);  unsqueeze_1577 = None
    unsqueeze_1579: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1578, 3);  unsqueeze_1578 = None
    mul_2584: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_913, primals_914);  primals_914 = None
    unsqueeze_1580: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2584, 0);  mul_2584 = None
    unsqueeze_1581: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1580, 2);  unsqueeze_1580 = None
    unsqueeze_1582: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1581, 3);  unsqueeze_1581 = None
    mul_2585: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_405, unsqueeze_1579);  sub_405 = unsqueeze_1579 = None
    sub_407: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_16, mul_2585);  mul_2585 = None
    sub_408: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_407, unsqueeze_1576);  sub_407 = None
    mul_2586: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_408, unsqueeze_1582);  sub_408 = unsqueeze_1582 = None
    mul_2587: "f32[144]" = torch.ops.aten.mul.Tensor(sum_43, squeeze_913);  sum_43 = squeeze_913 = None
    convolution_backward_20 = torch.ops.aten.convolution_backward.default(mul_2586, relu_251, primals_913, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2586 = primals_913 = None
    getitem_710: "f32[8, 72, 14, 14]" = convolution_backward_20[0]
    getitem_711: "f32[144, 72, 3, 3]" = convolution_backward_20[1];  convolution_backward_20 = None
    sub_409: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_303, unsqueeze_1585);  convolution_303 = unsqueeze_1585 = None
    mul_2588: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_16, sub_409)
    sum_45: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_2588, [0, 2, 3]);  mul_2588 = None
    mul_2590: "f32[144]" = torch.ops.aten.mul.Tensor(sum_45, 0.002551020408163265)
    mul_2591: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_910, squeeze_910)
    mul_2592: "f32[144]" = torch.ops.aten.mul.Tensor(mul_2590, mul_2591);  mul_2590 = mul_2591 = None
    unsqueeze_1589: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2592, 0);  mul_2592 = None
    unsqueeze_1590: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1589, 2);  unsqueeze_1589 = None
    unsqueeze_1591: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1590, 3);  unsqueeze_1590 = None
    mul_2593: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_910, primals_911);  primals_911 = None
    unsqueeze_1592: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2593, 0);  mul_2593 = None
    unsqueeze_1593: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1592, 2);  unsqueeze_1592 = None
    unsqueeze_1594: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1593, 3);  unsqueeze_1593 = None
    mul_2594: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_409, unsqueeze_1591);  sub_409 = unsqueeze_1591 = None
    sub_411: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_16, mul_2594);  mul_2594 = None
    sub_412: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_411, unsqueeze_1576);  sub_411 = None
    mul_2595: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_412, unsqueeze_1594);  sub_412 = unsqueeze_1594 = None
    mul_2596: "f32[144]" = torch.ops.aten.mul.Tensor(sum_45, squeeze_910);  sum_45 = squeeze_910 = None
    convolution_backward_21 = torch.ops.aten.convolution_backward.default(mul_2595, relu_266, primals_910, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2595 = primals_910 = None
    getitem_713: "f32[8, 36, 14, 14]" = convolution_backward_21[0]
    getitem_714: "f32[144, 36, 3, 3]" = convolution_backward_21[1];  convolution_backward_21 = None
    le_17: "b8[8, 36, 14, 14]" = torch.ops.aten.le.Scalar(relu_266, 0);  relu_266 = None
    where_17: "f32[8, 36, 14, 14]" = torch.ops.aten.where.self(le_17, full_default, getitem_713);  le_17 = getitem_713 = None
    sum_46: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_17, [0, 2, 3])
    sub_413: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_302, unsqueeze_1597);  convolution_302 = unsqueeze_1597 = None
    mul_2597: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(where_17, sub_413)
    sum_47: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_2597, [0, 2, 3]);  mul_2597 = None
    mul_2598: "f32[36]" = torch.ops.aten.mul.Tensor(sum_46, 0.0006377551020408163)
    unsqueeze_1598: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2598, 0);  mul_2598 = None
    unsqueeze_1599: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1598, 2);  unsqueeze_1598 = None
    unsqueeze_1600: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1599, 3);  unsqueeze_1599 = None
    mul_2599: "f32[36]" = torch.ops.aten.mul.Tensor(sum_47, 0.0006377551020408163)
    mul_2600: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_907, squeeze_907)
    mul_2601: "f32[36]" = torch.ops.aten.mul.Tensor(mul_2599, mul_2600);  mul_2599 = mul_2600 = None
    unsqueeze_1601: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2601, 0);  mul_2601 = None
    unsqueeze_1602: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1601, 2);  unsqueeze_1601 = None
    unsqueeze_1603: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1602, 3);  unsqueeze_1602 = None
    mul_2602: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_907, primals_908);  primals_908 = None
    unsqueeze_1604: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2602, 0);  mul_2602 = None
    unsqueeze_1605: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1604, 2);  unsqueeze_1604 = None
    unsqueeze_1606: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1605, 3);  unsqueeze_1605 = None
    mul_2603: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_413, unsqueeze_1603);  sub_413 = unsqueeze_1603 = None
    sub_415: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(where_17, mul_2603);  where_17 = mul_2603 = None
    sub_416: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(sub_415, unsqueeze_1600);  sub_415 = unsqueeze_1600 = None
    mul_2604: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_416, unsqueeze_1606);  sub_416 = unsqueeze_1606 = None
    mul_2605: "f32[36]" = torch.ops.aten.mul.Tensor(sum_47, squeeze_907);  sum_47 = squeeze_907 = None
    convolution_backward_22 = torch.ops.aten.convolution_backward.default(mul_2604, relu_243, primals_907, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2604 = primals_907 = None
    getitem_716: "f32[8, 36, 28, 28]" = convolution_backward_22[0]
    getitem_717: "f32[36, 36, 3, 3]" = convolution_backward_22[1];  convolution_backward_22 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sub_417: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_301, unsqueeze_1609);  convolution_301 = unsqueeze_1609 = None
    mul_2606: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_16, sub_417)
    sum_49: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_2606, [0, 2, 3]);  mul_2606 = None
    mul_2608: "f32[144]" = torch.ops.aten.mul.Tensor(sum_49, 0.002551020408163265)
    mul_2609: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_904, squeeze_904)
    mul_2610: "f32[144]" = torch.ops.aten.mul.Tensor(mul_2608, mul_2609);  mul_2608 = mul_2609 = None
    unsqueeze_1613: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2610, 0);  mul_2610 = None
    unsqueeze_1614: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1613, 2);  unsqueeze_1613 = None
    unsqueeze_1615: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1614, 3);  unsqueeze_1614 = None
    mul_2611: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_904, primals_905);  primals_905 = None
    unsqueeze_1616: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2611, 0);  mul_2611 = None
    unsqueeze_1617: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1616, 2);  unsqueeze_1616 = None
    unsqueeze_1618: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1617, 3);  unsqueeze_1617 = None
    mul_2612: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_417, unsqueeze_1615);  sub_417 = unsqueeze_1615 = None
    sub_419: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_16, mul_2612);  mul_2612 = None
    sub_420: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_419, unsqueeze_1576);  sub_419 = unsqueeze_1576 = None
    mul_2613: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_420, unsqueeze_1618);  sub_420 = unsqueeze_1618 = None
    mul_2614: "f32[144]" = torch.ops.aten.mul.Tensor(sum_49, squeeze_904);  sum_49 = squeeze_904 = None
    convolution_backward_23 = torch.ops.aten.convolution_backward.default(mul_2613, relu_265, primals_904, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2613 = primals_904 = None
    getitem_719: "f32[8, 18, 14, 14]" = convolution_backward_23[0]
    getitem_720: "f32[144, 18, 3, 3]" = convolution_backward_23[1];  convolution_backward_23 = None
    le_18: "b8[8, 18, 14, 14]" = torch.ops.aten.le.Scalar(relu_265, 0);  relu_265 = None
    where_18: "f32[8, 18, 14, 14]" = torch.ops.aten.where.self(le_18, full_default, getitem_719);  le_18 = getitem_719 = None
    sum_50: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_18, [0, 2, 3])
    sub_421: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_300, unsqueeze_1621);  convolution_300 = unsqueeze_1621 = None
    mul_2615: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(where_18, sub_421)
    sum_51: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_2615, [0, 2, 3]);  mul_2615 = None
    mul_2616: "f32[18]" = torch.ops.aten.mul.Tensor(sum_50, 0.0006377551020408163)
    unsqueeze_1622: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2616, 0);  mul_2616 = None
    unsqueeze_1623: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1622, 2);  unsqueeze_1622 = None
    unsqueeze_1624: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1623, 3);  unsqueeze_1623 = None
    mul_2617: "f32[18]" = torch.ops.aten.mul.Tensor(sum_51, 0.0006377551020408163)
    mul_2618: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_901, squeeze_901)
    mul_2619: "f32[18]" = torch.ops.aten.mul.Tensor(mul_2617, mul_2618);  mul_2617 = mul_2618 = None
    unsqueeze_1625: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2619, 0);  mul_2619 = None
    unsqueeze_1626: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1625, 2);  unsqueeze_1625 = None
    unsqueeze_1627: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1626, 3);  unsqueeze_1626 = None
    mul_2620: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_901, primals_902);  primals_902 = None
    unsqueeze_1628: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2620, 0);  mul_2620 = None
    unsqueeze_1629: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1628, 2);  unsqueeze_1628 = None
    unsqueeze_1630: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1629, 3);  unsqueeze_1629 = None
    mul_2621: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_421, unsqueeze_1627);  sub_421 = unsqueeze_1627 = None
    sub_423: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(where_18, mul_2621);  where_18 = mul_2621 = None
    sub_424: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(sub_423, unsqueeze_1624);  sub_423 = unsqueeze_1624 = None
    mul_2622: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_424, unsqueeze_1630);  sub_424 = unsqueeze_1630 = None
    mul_2623: "f32[18]" = torch.ops.aten.mul.Tensor(sum_51, squeeze_901);  sum_51 = squeeze_901 = None
    convolution_backward_24 = torch.ops.aten.convolution_backward.default(mul_2622, relu_264, primals_901, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2622 = primals_901 = None
    getitem_722: "f32[8, 18, 28, 28]" = convolution_backward_24[0]
    getitem_723: "f32[18, 18, 3, 3]" = convolution_backward_24[1];  convolution_backward_24 = None
    le_19: "b8[8, 18, 28, 28]" = torch.ops.aten.le.Scalar(relu_264, 0);  relu_264 = None
    where_19: "f32[8, 18, 28, 28]" = torch.ops.aten.where.self(le_19, full_default, getitem_722);  le_19 = getitem_722 = None
    sum_52: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_19, [0, 2, 3])
    sub_425: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_299, unsqueeze_1633);  convolution_299 = unsqueeze_1633 = None
    mul_2624: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(where_19, sub_425)
    sum_53: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_2624, [0, 2, 3]);  mul_2624 = None
    mul_2625: "f32[18]" = torch.ops.aten.mul.Tensor(sum_52, 0.00015943877551020407)
    unsqueeze_1634: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2625, 0);  mul_2625 = None
    unsqueeze_1635: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1634, 2);  unsqueeze_1634 = None
    unsqueeze_1636: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1635, 3);  unsqueeze_1635 = None
    mul_2626: "f32[18]" = torch.ops.aten.mul.Tensor(sum_53, 0.00015943877551020407)
    mul_2627: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_898, squeeze_898)
    mul_2628: "f32[18]" = torch.ops.aten.mul.Tensor(mul_2626, mul_2627);  mul_2626 = mul_2627 = None
    unsqueeze_1637: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2628, 0);  mul_2628 = None
    unsqueeze_1638: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1637, 2);  unsqueeze_1637 = None
    unsqueeze_1639: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1638, 3);  unsqueeze_1638 = None
    mul_2629: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_898, primals_899);  primals_899 = None
    unsqueeze_1640: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2629, 0);  mul_2629 = None
    unsqueeze_1641: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1640, 2);  unsqueeze_1640 = None
    unsqueeze_1642: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1641, 3);  unsqueeze_1641 = None
    mul_2630: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_425, unsqueeze_1639);  sub_425 = unsqueeze_1639 = None
    sub_427: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(where_19, mul_2630);  where_19 = mul_2630 = None
    sub_428: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_427, unsqueeze_1636);  sub_427 = unsqueeze_1636 = None
    mul_2631: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_428, unsqueeze_1642);  sub_428 = unsqueeze_1642 = None
    mul_2632: "f32[18]" = torch.ops.aten.mul.Tensor(sum_53, squeeze_898);  sum_53 = squeeze_898 = None
    convolution_backward_25 = torch.ops.aten.convolution_backward.default(mul_2631, relu_235, primals_898, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2631 = primals_898 = None
    getitem_725: "f32[8, 18, 56, 56]" = convolution_backward_25[0]
    getitem_726: "f32[18, 18, 3, 3]" = convolution_backward_25[1];  convolution_backward_25 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_20: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_263, 0);  relu_263 = None
    where_20: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_20, full_default, add_1927);  le_20 = add_1927 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    full_default_21: "f32[8, 72, 7, 7]" = torch.ops.aten.full.default([8, 72, 7, 7], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
    _unsafe_index_put: "f32[8, 72, 7, 7]" = torch.ops.aten._unsafe_index_put.default(full_default_21, [None, None, unsqueeze_830, convert_element_type_110], where_20, True)
    sum_54: "f32[72]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put, [0, 2, 3])
    sub_429: "f32[8, 72, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_298, unsqueeze_1645);  convolution_298 = unsqueeze_1645 = None
    mul_2633: "f32[8, 72, 7, 7]" = torch.ops.aten.mul.Tensor(_unsafe_index_put, sub_429)
    sum_55: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_2633, [0, 2, 3]);  mul_2633 = None
    mul_2634: "f32[72]" = torch.ops.aten.mul.Tensor(sum_54, 0.002551020408163265)
    unsqueeze_1646: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2634, 0);  mul_2634 = None
    unsqueeze_1647: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1646, 2);  unsqueeze_1646 = None
    unsqueeze_1648: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1647, 3);  unsqueeze_1647 = None
    mul_2635: "f32[72]" = torch.ops.aten.mul.Tensor(sum_55, 0.002551020408163265)
    mul_2636: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_895, squeeze_895)
    mul_2637: "f32[72]" = torch.ops.aten.mul.Tensor(mul_2635, mul_2636);  mul_2635 = mul_2636 = None
    unsqueeze_1649: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2637, 0);  mul_2637 = None
    unsqueeze_1650: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1649, 2);  unsqueeze_1649 = None
    unsqueeze_1651: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1650, 3);  unsqueeze_1650 = None
    mul_2638: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_895, primals_896);  primals_896 = None
    unsqueeze_1652: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2638, 0);  mul_2638 = None
    unsqueeze_1653: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1652, 2);  unsqueeze_1652 = None
    unsqueeze_1654: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1653, 3);  unsqueeze_1653 = None
    mul_2639: "f32[8, 72, 7, 7]" = torch.ops.aten.mul.Tensor(sub_429, unsqueeze_1651);  sub_429 = unsqueeze_1651 = None
    sub_431: "f32[8, 72, 7, 7]" = torch.ops.aten.sub.Tensor(_unsafe_index_put, mul_2639);  _unsafe_index_put = mul_2639 = None
    sub_432: "f32[8, 72, 7, 7]" = torch.ops.aten.sub.Tensor(sub_431, unsqueeze_1648);  sub_431 = unsqueeze_1648 = None
    mul_2640: "f32[8, 72, 7, 7]" = torch.ops.aten.mul.Tensor(sub_432, unsqueeze_1654);  sub_432 = unsqueeze_1654 = None
    mul_2641: "f32[72]" = torch.ops.aten.mul.Tensor(sum_55, squeeze_895);  sum_55 = squeeze_895 = None
    convolution_backward_26 = torch.ops.aten.convolution_backward.default(mul_2640, relu_259, primals_895, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2640 = primals_895 = None
    getitem_728: "f32[8, 144, 7, 7]" = convolution_backward_26[0]
    getitem_729: "f32[72, 144, 1, 1]" = convolution_backward_26[1];  convolution_backward_26 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1930: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(where_16, getitem_728);  where_16 = getitem_728 = None
    add_1931: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(getitem_710, where_20);  getitem_710 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    sum_56: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_20, [0, 2, 3])
    sub_433: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_297, unsqueeze_1657);  convolution_297 = unsqueeze_1657 = None
    mul_2642: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_20, sub_433)
    sum_57: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_2642, [0, 2, 3]);  mul_2642 = None
    mul_2643: "f32[72]" = torch.ops.aten.mul.Tensor(sum_56, 0.0006377551020408163)
    unsqueeze_1658: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2643, 0);  mul_2643 = None
    unsqueeze_1659: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1658, 2);  unsqueeze_1658 = None
    unsqueeze_1660: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1659, 3);  unsqueeze_1659 = None
    mul_2644: "f32[72]" = torch.ops.aten.mul.Tensor(sum_57, 0.0006377551020408163)
    mul_2645: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_892, squeeze_892)
    mul_2646: "f32[72]" = torch.ops.aten.mul.Tensor(mul_2644, mul_2645);  mul_2644 = mul_2645 = None
    unsqueeze_1661: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2646, 0);  mul_2646 = None
    unsqueeze_1662: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1661, 2);  unsqueeze_1661 = None
    unsqueeze_1663: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1662, 3);  unsqueeze_1662 = None
    mul_2647: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_892, primals_893);  primals_893 = None
    unsqueeze_1664: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2647, 0);  mul_2647 = None
    unsqueeze_1665: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1664, 2);  unsqueeze_1664 = None
    unsqueeze_1666: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1665, 3);  unsqueeze_1665 = None
    mul_2648: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_433, unsqueeze_1663);  sub_433 = unsqueeze_1663 = None
    sub_435: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_20, mul_2648);  mul_2648 = None
    sub_436: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_435, unsqueeze_1660);  sub_435 = None
    mul_2649: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_436, unsqueeze_1666);  sub_436 = unsqueeze_1666 = None
    mul_2650: "f32[72]" = torch.ops.aten.mul.Tensor(sum_57, squeeze_892);  sum_57 = squeeze_892 = None
    convolution_backward_27 = torch.ops.aten.convolution_backward.default(mul_2649, relu_243, primals_892, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2649 = primals_892 = None
    getitem_731: "f32[8, 36, 28, 28]" = convolution_backward_27[0]
    getitem_732: "f32[72, 36, 3, 3]" = convolution_backward_27[1];  convolution_backward_27 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1932: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(getitem_716, getitem_731);  getitem_716 = getitem_731 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sub_437: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_296, unsqueeze_1669);  convolution_296 = unsqueeze_1669 = None
    mul_2651: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_20, sub_437)
    sum_59: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_2651, [0, 2, 3]);  mul_2651 = None
    mul_2653: "f32[72]" = torch.ops.aten.mul.Tensor(sum_59, 0.0006377551020408163)
    mul_2654: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_889, squeeze_889)
    mul_2655: "f32[72]" = torch.ops.aten.mul.Tensor(mul_2653, mul_2654);  mul_2653 = mul_2654 = None
    unsqueeze_1673: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2655, 0);  mul_2655 = None
    unsqueeze_1674: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1673, 2);  unsqueeze_1673 = None
    unsqueeze_1675: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1674, 3);  unsqueeze_1674 = None
    mul_2656: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_889, primals_890);  primals_890 = None
    unsqueeze_1676: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2656, 0);  mul_2656 = None
    unsqueeze_1677: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1676, 2);  unsqueeze_1676 = None
    unsqueeze_1678: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1677, 3);  unsqueeze_1677 = None
    mul_2657: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_437, unsqueeze_1675);  sub_437 = unsqueeze_1675 = None
    sub_439: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_20, mul_2657);  where_20 = mul_2657 = None
    sub_440: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_439, unsqueeze_1660);  sub_439 = unsqueeze_1660 = None
    mul_2658: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_440, unsqueeze_1678);  sub_440 = unsqueeze_1678 = None
    mul_2659: "f32[72]" = torch.ops.aten.mul.Tensor(sum_59, squeeze_889);  sum_59 = squeeze_889 = None
    convolution_backward_28 = torch.ops.aten.convolution_backward.default(mul_2658, relu_262, primals_889, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2658 = primals_889 = None
    getitem_734: "f32[8, 18, 28, 28]" = convolution_backward_28[0]
    getitem_735: "f32[72, 18, 3, 3]" = convolution_backward_28[1];  convolution_backward_28 = None
    le_21: "b8[8, 18, 28, 28]" = torch.ops.aten.le.Scalar(relu_262, 0);  relu_262 = None
    where_21: "f32[8, 18, 28, 28]" = torch.ops.aten.where.self(le_21, full_default, getitem_734);  le_21 = getitem_734 = None
    sum_60: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_21, [0, 2, 3])
    sub_441: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_295, unsqueeze_1681);  convolution_295 = unsqueeze_1681 = None
    mul_2660: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(where_21, sub_441)
    sum_61: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_2660, [0, 2, 3]);  mul_2660 = None
    mul_2661: "f32[18]" = torch.ops.aten.mul.Tensor(sum_60, 0.00015943877551020407)
    unsqueeze_1682: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2661, 0);  mul_2661 = None
    unsqueeze_1683: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1682, 2);  unsqueeze_1682 = None
    unsqueeze_1684: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1683, 3);  unsqueeze_1683 = None
    mul_2662: "f32[18]" = torch.ops.aten.mul.Tensor(sum_61, 0.00015943877551020407)
    mul_2663: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_886, squeeze_886)
    mul_2664: "f32[18]" = torch.ops.aten.mul.Tensor(mul_2662, mul_2663);  mul_2662 = mul_2663 = None
    unsqueeze_1685: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2664, 0);  mul_2664 = None
    unsqueeze_1686: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1685, 2);  unsqueeze_1685 = None
    unsqueeze_1687: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1686, 3);  unsqueeze_1686 = None
    mul_2665: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_886, primals_887);  primals_887 = None
    unsqueeze_1688: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2665, 0);  mul_2665 = None
    unsqueeze_1689: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1688, 2);  unsqueeze_1688 = None
    unsqueeze_1690: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1689, 3);  unsqueeze_1689 = None
    mul_2666: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_441, unsqueeze_1687);  sub_441 = unsqueeze_1687 = None
    sub_443: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(where_21, mul_2666);  where_21 = mul_2666 = None
    sub_444: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_443, unsqueeze_1684);  sub_443 = unsqueeze_1684 = None
    mul_2667: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_444, unsqueeze_1690);  sub_444 = unsqueeze_1690 = None
    mul_2668: "f32[18]" = torch.ops.aten.mul.Tensor(sum_61, squeeze_886);  sum_61 = squeeze_886 = None
    convolution_backward_29 = torch.ops.aten.convolution_backward.default(mul_2667, relu_235, primals_886, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2667 = primals_886 = None
    getitem_737: "f32[8, 18, 56, 56]" = convolution_backward_29[0]
    getitem_738: "f32[18, 18, 3, 3]" = convolution_backward_29[1];  convolution_backward_29 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    add_1933: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(getitem_725, getitem_737);  getitem_725 = getitem_737 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_22: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_261, 0);  relu_261 = None
    where_22: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_22, full_default, add_1928);  le_22 = add_1928 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    full_default_24: "f32[8, 36, 7, 7]" = torch.ops.aten.full.default([8, 36, 7, 7], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
    _unsafe_index_put_1: "f32[8, 36, 7, 7]" = torch.ops.aten._unsafe_index_put.default(full_default_24, [None, None, unsqueeze_813, convert_element_type_104], where_22, True)
    sum_62: "f32[36]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_1, [0, 2, 3])
    sub_445: "f32[8, 36, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_294, unsqueeze_1693);  convolution_294 = unsqueeze_1693 = None
    mul_2669: "f32[8, 36, 7, 7]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_1, sub_445)
    sum_63: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_2669, [0, 2, 3]);  mul_2669 = None
    mul_2670: "f32[36]" = torch.ops.aten.mul.Tensor(sum_62, 0.002551020408163265)
    unsqueeze_1694: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2670, 0);  mul_2670 = None
    unsqueeze_1695: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1694, 2);  unsqueeze_1694 = None
    unsqueeze_1696: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1695, 3);  unsqueeze_1695 = None
    mul_2671: "f32[36]" = torch.ops.aten.mul.Tensor(sum_63, 0.002551020408163265)
    mul_2672: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_883, squeeze_883)
    mul_2673: "f32[36]" = torch.ops.aten.mul.Tensor(mul_2671, mul_2672);  mul_2671 = mul_2672 = None
    unsqueeze_1697: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2673, 0);  mul_2673 = None
    unsqueeze_1698: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1697, 2);  unsqueeze_1697 = None
    unsqueeze_1699: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1698, 3);  unsqueeze_1698 = None
    mul_2674: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_883, primals_884);  primals_884 = None
    unsqueeze_1700: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2674, 0);  mul_2674 = None
    unsqueeze_1701: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1700, 2);  unsqueeze_1700 = None
    unsqueeze_1702: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1701, 3);  unsqueeze_1701 = None
    mul_2675: "f32[8, 36, 7, 7]" = torch.ops.aten.mul.Tensor(sub_445, unsqueeze_1699);  sub_445 = unsqueeze_1699 = None
    sub_447: "f32[8, 36, 7, 7]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_1, mul_2675);  _unsafe_index_put_1 = mul_2675 = None
    sub_448: "f32[8, 36, 7, 7]" = torch.ops.aten.sub.Tensor(sub_447, unsqueeze_1696);  sub_447 = unsqueeze_1696 = None
    mul_2676: "f32[8, 36, 7, 7]" = torch.ops.aten.mul.Tensor(sub_448, unsqueeze_1702);  sub_448 = unsqueeze_1702 = None
    mul_2677: "f32[36]" = torch.ops.aten.mul.Tensor(sum_63, squeeze_883);  sum_63 = squeeze_883 = None
    convolution_backward_30 = torch.ops.aten.convolution_backward.default(mul_2676, relu_259, primals_883, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2676 = primals_883 = None
    getitem_740: "f32[8, 144, 7, 7]" = convolution_backward_30[0]
    getitem_741: "f32[36, 144, 1, 1]" = convolution_backward_30[1];  convolution_backward_30 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1934: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(add_1930, getitem_740);  add_1930 = getitem_740 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    full_default_25: "f32[8, 36, 14, 14]" = torch.ops.aten.full.default([8, 36, 14, 14], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
    _unsafe_index_put_2: "f32[8, 36, 14, 14]" = torch.ops.aten._unsafe_index_put.default(full_default_25, [None, None, unsqueeze_259, convert_element_type_20], where_22, True)
    sum_64: "f32[36]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_2, [0, 2, 3])
    sub_449: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_293, unsqueeze_1705);  convolution_293 = unsqueeze_1705 = None
    mul_2678: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_2, sub_449)
    sum_65: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_2678, [0, 2, 3]);  mul_2678 = None
    mul_2679: "f32[36]" = torch.ops.aten.mul.Tensor(sum_64, 0.0006377551020408163)
    unsqueeze_1706: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2679, 0);  mul_2679 = None
    unsqueeze_1707: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1706, 2);  unsqueeze_1706 = None
    unsqueeze_1708: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1707, 3);  unsqueeze_1707 = None
    mul_2680: "f32[36]" = torch.ops.aten.mul.Tensor(sum_65, 0.0006377551020408163)
    mul_2681: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_880, squeeze_880)
    mul_2682: "f32[36]" = torch.ops.aten.mul.Tensor(mul_2680, mul_2681);  mul_2680 = mul_2681 = None
    unsqueeze_1709: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2682, 0);  mul_2682 = None
    unsqueeze_1710: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1709, 2);  unsqueeze_1709 = None
    unsqueeze_1711: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1710, 3);  unsqueeze_1710 = None
    mul_2683: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_880, primals_881);  primals_881 = None
    unsqueeze_1712: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2683, 0);  mul_2683 = None
    unsqueeze_1713: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1712, 2);  unsqueeze_1712 = None
    unsqueeze_1714: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1713, 3);  unsqueeze_1713 = None
    mul_2684: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_449, unsqueeze_1711);  sub_449 = unsqueeze_1711 = None
    sub_451: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_2, mul_2684);  _unsafe_index_put_2 = mul_2684 = None
    sub_452: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(sub_451, unsqueeze_1708);  sub_451 = unsqueeze_1708 = None
    mul_2685: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_452, unsqueeze_1714);  sub_452 = unsqueeze_1714 = None
    mul_2686: "f32[36]" = torch.ops.aten.mul.Tensor(sum_65, squeeze_880);  sum_65 = squeeze_880 = None
    convolution_backward_31 = torch.ops.aten.convolution_backward.default(mul_2685, relu_251, primals_880, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2685 = primals_880 = None
    getitem_743: "f32[8, 72, 14, 14]" = convolution_backward_31[0]
    getitem_744: "f32[36, 72, 1, 1]" = convolution_backward_31[1];  convolution_backward_31 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1935: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(add_1931, getitem_743);  add_1931 = getitem_743 = None
    add_1936: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(add_1932, where_22);  add_1932 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sum_66: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_22, [0, 2, 3])
    sub_453: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_292, unsqueeze_1717);  convolution_292 = unsqueeze_1717 = None
    mul_2687: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_22, sub_453)
    sum_67: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_2687, [0, 2, 3]);  mul_2687 = None
    mul_2688: "f32[36]" = torch.ops.aten.mul.Tensor(sum_66, 0.00015943877551020407)
    unsqueeze_1718: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2688, 0);  mul_2688 = None
    unsqueeze_1719: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1718, 2);  unsqueeze_1718 = None
    unsqueeze_1720: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1719, 3);  unsqueeze_1719 = None
    mul_2689: "f32[36]" = torch.ops.aten.mul.Tensor(sum_67, 0.00015943877551020407)
    mul_2690: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_877, squeeze_877)
    mul_2691: "f32[36]" = torch.ops.aten.mul.Tensor(mul_2689, mul_2690);  mul_2689 = mul_2690 = None
    unsqueeze_1721: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2691, 0);  mul_2691 = None
    unsqueeze_1722: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1721, 2);  unsqueeze_1721 = None
    unsqueeze_1723: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1722, 3);  unsqueeze_1722 = None
    mul_2692: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_877, primals_878);  primals_878 = None
    unsqueeze_1724: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2692, 0);  mul_2692 = None
    unsqueeze_1725: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1724, 2);  unsqueeze_1724 = None
    unsqueeze_1726: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1725, 3);  unsqueeze_1725 = None
    mul_2693: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_453, unsqueeze_1723);  sub_453 = unsqueeze_1723 = None
    sub_455: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_22, mul_2693);  where_22 = mul_2693 = None
    sub_456: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_455, unsqueeze_1720);  sub_455 = unsqueeze_1720 = None
    mul_2694: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_456, unsqueeze_1726);  sub_456 = unsqueeze_1726 = None
    mul_2695: "f32[36]" = torch.ops.aten.mul.Tensor(sum_67, squeeze_877);  sum_67 = squeeze_877 = None
    convolution_backward_32 = torch.ops.aten.convolution_backward.default(mul_2694, relu_235, primals_877, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2694 = primals_877 = None
    getitem_746: "f32[8, 18, 56, 56]" = convolution_backward_32[0]
    getitem_747: "f32[36, 18, 3, 3]" = convolution_backward_32[1];  convolution_backward_32 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    add_1937: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(add_1933, getitem_746);  add_1933 = getitem_746 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_23: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_260, 0);  relu_260 = None
    where_23: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_23, full_default, add_1929);  le_23 = add_1929 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    full_default_27: "f32[8, 18, 7, 7]" = torch.ops.aten.full.default([8, 18, 7, 7], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
    _unsafe_index_put_3: "f32[8, 18, 7, 7]" = torch.ops.aten._unsafe_index_put.default(full_default_27, [None, None, unsqueeze_799, convert_element_type_92], where_23, True)
    sum_68: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_3, [0, 2, 3])
    sub_457: "f32[8, 18, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_291, unsqueeze_1729);  convolution_291 = unsqueeze_1729 = None
    mul_2696: "f32[8, 18, 7, 7]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_3, sub_457)
    sum_69: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_2696, [0, 2, 3]);  mul_2696 = None
    mul_2697: "f32[18]" = torch.ops.aten.mul.Tensor(sum_68, 0.002551020408163265)
    unsqueeze_1730: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2697, 0);  mul_2697 = None
    unsqueeze_1731: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1730, 2);  unsqueeze_1730 = None
    unsqueeze_1732: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1731, 3);  unsqueeze_1731 = None
    mul_2698: "f32[18]" = torch.ops.aten.mul.Tensor(sum_69, 0.002551020408163265)
    mul_2699: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_874, squeeze_874)
    mul_2700: "f32[18]" = torch.ops.aten.mul.Tensor(mul_2698, mul_2699);  mul_2698 = mul_2699 = None
    unsqueeze_1733: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2700, 0);  mul_2700 = None
    unsqueeze_1734: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1733, 2);  unsqueeze_1733 = None
    unsqueeze_1735: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1734, 3);  unsqueeze_1734 = None
    mul_2701: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_874, primals_875);  primals_875 = None
    unsqueeze_1736: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2701, 0);  mul_2701 = None
    unsqueeze_1737: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1736, 2);  unsqueeze_1736 = None
    unsqueeze_1738: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1737, 3);  unsqueeze_1737 = None
    mul_2702: "f32[8, 18, 7, 7]" = torch.ops.aten.mul.Tensor(sub_457, unsqueeze_1735);  sub_457 = unsqueeze_1735 = None
    sub_459: "f32[8, 18, 7, 7]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_3, mul_2702);  _unsafe_index_put_3 = mul_2702 = None
    sub_460: "f32[8, 18, 7, 7]" = torch.ops.aten.sub.Tensor(sub_459, unsqueeze_1732);  sub_459 = unsqueeze_1732 = None
    mul_2703: "f32[8, 18, 7, 7]" = torch.ops.aten.mul.Tensor(sub_460, unsqueeze_1738);  sub_460 = unsqueeze_1738 = None
    mul_2704: "f32[18]" = torch.ops.aten.mul.Tensor(sum_69, squeeze_874);  sum_69 = squeeze_874 = None
    convolution_backward_33 = torch.ops.aten.convolution_backward.default(mul_2703, relu_259, primals_874, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2703 = primals_874 = None
    getitem_749: "f32[8, 144, 7, 7]" = convolution_backward_33[0]
    getitem_750: "f32[18, 144, 1, 1]" = convolution_backward_33[1];  convolution_backward_33 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1938: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(add_1934, getitem_749);  add_1934 = getitem_749 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    full_default_28: "f32[8, 18, 14, 14]" = torch.ops.aten.full.default([8, 18, 14, 14], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
    _unsafe_index_put_4: "f32[8, 18, 14, 14]" = torch.ops.aten._unsafe_index_put.default(full_default_28, [None, None, unsqueeze_250, convert_element_type_14], where_23, True)
    sum_70: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_4, [0, 2, 3])
    sub_461: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_290, unsqueeze_1741);  convolution_290 = unsqueeze_1741 = None
    mul_2705: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_4, sub_461)
    sum_71: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_2705, [0, 2, 3]);  mul_2705 = None
    mul_2706: "f32[18]" = torch.ops.aten.mul.Tensor(sum_70, 0.0006377551020408163)
    unsqueeze_1742: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2706, 0);  mul_2706 = None
    unsqueeze_1743: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1742, 2);  unsqueeze_1742 = None
    unsqueeze_1744: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1743, 3);  unsqueeze_1743 = None
    mul_2707: "f32[18]" = torch.ops.aten.mul.Tensor(sum_71, 0.0006377551020408163)
    mul_2708: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_871, squeeze_871)
    mul_2709: "f32[18]" = torch.ops.aten.mul.Tensor(mul_2707, mul_2708);  mul_2707 = mul_2708 = None
    unsqueeze_1745: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2709, 0);  mul_2709 = None
    unsqueeze_1746: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1745, 2);  unsqueeze_1745 = None
    unsqueeze_1747: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1746, 3);  unsqueeze_1746 = None
    mul_2710: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_871, primals_872);  primals_872 = None
    unsqueeze_1748: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2710, 0);  mul_2710 = None
    unsqueeze_1749: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1748, 2);  unsqueeze_1748 = None
    unsqueeze_1750: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1749, 3);  unsqueeze_1749 = None
    mul_2711: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_461, unsqueeze_1747);  sub_461 = unsqueeze_1747 = None
    sub_463: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_4, mul_2711);  _unsafe_index_put_4 = mul_2711 = None
    sub_464: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(sub_463, unsqueeze_1744);  sub_463 = unsqueeze_1744 = None
    mul_2712: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_464, unsqueeze_1750);  sub_464 = unsqueeze_1750 = None
    mul_2713: "f32[18]" = torch.ops.aten.mul.Tensor(sum_71, squeeze_871);  sum_71 = squeeze_871 = None
    convolution_backward_34 = torch.ops.aten.convolution_backward.default(mul_2712, relu_251, primals_871, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2712 = primals_871 = None
    getitem_752: "f32[8, 72, 14, 14]" = convolution_backward_34[0]
    getitem_753: "f32[18, 72, 1, 1]" = convolution_backward_34[1];  convolution_backward_34 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1939: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(add_1935, getitem_752);  add_1935 = getitem_752 = None
    add_1940: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(add_1937, where_23);  add_1937 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    full_default_29: "f32[8, 18, 28, 28]" = torch.ops.aten.full.default([8, 18, 28, 28], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
    _unsafe_index_put_5: "f32[8, 18, 28, 28]" = torch.ops.aten._unsafe_index_put.default(full_default_29, [None, None, unsqueeze_136, convert_element_type_2], where_23, True);  where_23 = None
    sum_72: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_5, [0, 2, 3])
    sub_465: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_289, unsqueeze_1753);  convolution_289 = unsqueeze_1753 = None
    mul_2714: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_5, sub_465)
    sum_73: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_2714, [0, 2, 3]);  mul_2714 = None
    mul_2715: "f32[18]" = torch.ops.aten.mul.Tensor(sum_72, 0.00015943877551020407)
    unsqueeze_1754: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2715, 0);  mul_2715 = None
    unsqueeze_1755: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1754, 2);  unsqueeze_1754 = None
    unsqueeze_1756: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1755, 3);  unsqueeze_1755 = None
    mul_2716: "f32[18]" = torch.ops.aten.mul.Tensor(sum_73, 0.00015943877551020407)
    mul_2717: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_868, squeeze_868)
    mul_2718: "f32[18]" = torch.ops.aten.mul.Tensor(mul_2716, mul_2717);  mul_2716 = mul_2717 = None
    unsqueeze_1757: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2718, 0);  mul_2718 = None
    unsqueeze_1758: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1757, 2);  unsqueeze_1757 = None
    unsqueeze_1759: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1758, 3);  unsqueeze_1758 = None
    mul_2719: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_868, primals_869);  primals_869 = None
    unsqueeze_1760: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2719, 0);  mul_2719 = None
    unsqueeze_1761: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1760, 2);  unsqueeze_1760 = None
    unsqueeze_1762: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1761, 3);  unsqueeze_1761 = None
    mul_2720: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_465, unsqueeze_1759);  sub_465 = unsqueeze_1759 = None
    sub_467: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_5, mul_2720);  _unsafe_index_put_5 = mul_2720 = None
    sub_468: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_467, unsqueeze_1756);  sub_467 = unsqueeze_1756 = None
    mul_2721: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_468, unsqueeze_1762);  sub_468 = unsqueeze_1762 = None
    mul_2722: "f32[18]" = torch.ops.aten.mul.Tensor(sum_73, squeeze_868);  sum_73 = squeeze_868 = None
    convolution_backward_35 = torch.ops.aten.convolution_backward.default(mul_2721, relu_243, primals_868, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2721 = primals_868 = None
    getitem_755: "f32[8, 36, 28, 28]" = convolution_backward_35[0]
    getitem_756: "f32[18, 36, 1, 1]" = convolution_backward_35[1];  convolution_backward_35 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1941: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(add_1936, getitem_755);  add_1936 = getitem_755 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_24: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_259, 0);  relu_259 = None
    where_24: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_24, full_default, add_1938);  le_24 = add_1938 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_74: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_24, [0, 2, 3])
    sub_469: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_288, unsqueeze_1765);  convolution_288 = unsqueeze_1765 = None
    mul_2723: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_24, sub_469)
    sum_75: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_2723, [0, 2, 3]);  mul_2723 = None
    mul_2724: "f32[144]" = torch.ops.aten.mul.Tensor(sum_74, 0.002551020408163265)
    unsqueeze_1766: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2724, 0);  mul_2724 = None
    unsqueeze_1767: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1766, 2);  unsqueeze_1766 = None
    unsqueeze_1768: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1767, 3);  unsqueeze_1767 = None
    mul_2725: "f32[144]" = torch.ops.aten.mul.Tensor(sum_75, 0.002551020408163265)
    mul_2726: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_865, squeeze_865)
    mul_2727: "f32[144]" = torch.ops.aten.mul.Tensor(mul_2725, mul_2726);  mul_2725 = mul_2726 = None
    unsqueeze_1769: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2727, 0);  mul_2727 = None
    unsqueeze_1770: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1769, 2);  unsqueeze_1769 = None
    unsqueeze_1771: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1770, 3);  unsqueeze_1770 = None
    mul_2728: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_865, primals_866);  primals_866 = None
    unsqueeze_1772: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2728, 0);  mul_2728 = None
    unsqueeze_1773: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1772, 2);  unsqueeze_1772 = None
    unsqueeze_1774: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1773, 3);  unsqueeze_1773 = None
    mul_2729: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_469, unsqueeze_1771);  sub_469 = unsqueeze_1771 = None
    sub_471: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_24, mul_2729);  mul_2729 = None
    sub_472: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_471, unsqueeze_1768);  sub_471 = unsqueeze_1768 = None
    mul_2730: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_472, unsqueeze_1774);  sub_472 = unsqueeze_1774 = None
    mul_2731: "f32[144]" = torch.ops.aten.mul.Tensor(sum_75, squeeze_865);  sum_75 = squeeze_865 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_36 = torch.ops.aten.convolution_backward.default(mul_2730, relu_258, primals_865, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2730 = primals_865 = None
    getitem_758: "f32[8, 144, 7, 7]" = convolution_backward_36[0]
    getitem_759: "f32[144, 144, 3, 3]" = convolution_backward_36[1];  convolution_backward_36 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_25: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_258, 0);  relu_258 = None
    where_25: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_25, full_default, getitem_758);  le_25 = getitem_758 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_76: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_25, [0, 2, 3])
    sub_473: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_287, unsqueeze_1777);  convolution_287 = unsqueeze_1777 = None
    mul_2732: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_25, sub_473)
    sum_77: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_2732, [0, 2, 3]);  mul_2732 = None
    mul_2733: "f32[144]" = torch.ops.aten.mul.Tensor(sum_76, 0.002551020408163265)
    unsqueeze_1778: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2733, 0);  mul_2733 = None
    unsqueeze_1779: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1778, 2);  unsqueeze_1778 = None
    unsqueeze_1780: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1779, 3);  unsqueeze_1779 = None
    mul_2734: "f32[144]" = torch.ops.aten.mul.Tensor(sum_77, 0.002551020408163265)
    mul_2735: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_862, squeeze_862)
    mul_2736: "f32[144]" = torch.ops.aten.mul.Tensor(mul_2734, mul_2735);  mul_2734 = mul_2735 = None
    unsqueeze_1781: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2736, 0);  mul_2736 = None
    unsqueeze_1782: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1781, 2);  unsqueeze_1781 = None
    unsqueeze_1783: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1782, 3);  unsqueeze_1782 = None
    mul_2737: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_862, primals_863);  primals_863 = None
    unsqueeze_1784: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2737, 0);  mul_2737 = None
    unsqueeze_1785: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1784, 2);  unsqueeze_1784 = None
    unsqueeze_1786: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1785, 3);  unsqueeze_1785 = None
    mul_2738: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_473, unsqueeze_1783);  sub_473 = unsqueeze_1783 = None
    sub_475: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_25, mul_2738);  where_25 = mul_2738 = None
    sub_476: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_475, unsqueeze_1780);  sub_475 = unsqueeze_1780 = None
    mul_2739: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_476, unsqueeze_1786);  sub_476 = unsqueeze_1786 = None
    mul_2740: "f32[144]" = torch.ops.aten.mul.Tensor(sum_77, squeeze_862);  sum_77 = squeeze_862 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_37 = torch.ops.aten.convolution_backward.default(mul_2739, relu_257, primals_862, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2739 = primals_862 = None
    getitem_761: "f32[8, 144, 7, 7]" = convolution_backward_37[0]
    getitem_762: "f32[144, 144, 3, 3]" = convolution_backward_37[1];  convolution_backward_37 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1942: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(where_24, getitem_761);  where_24 = getitem_761 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_26: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_257, 0);  relu_257 = None
    where_26: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_26, full_default, add_1942);  le_26 = add_1942 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_78: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_26, [0, 2, 3])
    sub_477: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_286, unsqueeze_1789);  convolution_286 = unsqueeze_1789 = None
    mul_2741: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_26, sub_477)
    sum_79: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_2741, [0, 2, 3]);  mul_2741 = None
    mul_2742: "f32[144]" = torch.ops.aten.mul.Tensor(sum_78, 0.002551020408163265)
    unsqueeze_1790: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2742, 0);  mul_2742 = None
    unsqueeze_1791: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1790, 2);  unsqueeze_1790 = None
    unsqueeze_1792: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1791, 3);  unsqueeze_1791 = None
    mul_2743: "f32[144]" = torch.ops.aten.mul.Tensor(sum_79, 0.002551020408163265)
    mul_2744: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_859, squeeze_859)
    mul_2745: "f32[144]" = torch.ops.aten.mul.Tensor(mul_2743, mul_2744);  mul_2743 = mul_2744 = None
    unsqueeze_1793: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2745, 0);  mul_2745 = None
    unsqueeze_1794: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1793, 2);  unsqueeze_1793 = None
    unsqueeze_1795: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1794, 3);  unsqueeze_1794 = None
    mul_2746: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_859, primals_860);  primals_860 = None
    unsqueeze_1796: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2746, 0);  mul_2746 = None
    unsqueeze_1797: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1796, 2);  unsqueeze_1796 = None
    unsqueeze_1798: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1797, 3);  unsqueeze_1797 = None
    mul_2747: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_477, unsqueeze_1795);  sub_477 = unsqueeze_1795 = None
    sub_479: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_26, mul_2747);  mul_2747 = None
    sub_480: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_479, unsqueeze_1792);  sub_479 = unsqueeze_1792 = None
    mul_2748: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_480, unsqueeze_1798);  sub_480 = unsqueeze_1798 = None
    mul_2749: "f32[144]" = torch.ops.aten.mul.Tensor(sum_79, squeeze_859);  sum_79 = squeeze_859 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_38 = torch.ops.aten.convolution_backward.default(mul_2748, relu_256, primals_859, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2748 = primals_859 = None
    getitem_764: "f32[8, 144, 7, 7]" = convolution_backward_38[0]
    getitem_765: "f32[144, 144, 3, 3]" = convolution_backward_38[1];  convolution_backward_38 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_27: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_256, 0);  relu_256 = None
    where_27: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_27, full_default, getitem_764);  le_27 = getitem_764 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_80: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_27, [0, 2, 3])
    sub_481: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_285, unsqueeze_1801);  convolution_285 = unsqueeze_1801 = None
    mul_2750: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_27, sub_481)
    sum_81: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_2750, [0, 2, 3]);  mul_2750 = None
    mul_2751: "f32[144]" = torch.ops.aten.mul.Tensor(sum_80, 0.002551020408163265)
    unsqueeze_1802: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2751, 0);  mul_2751 = None
    unsqueeze_1803: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1802, 2);  unsqueeze_1802 = None
    unsqueeze_1804: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1803, 3);  unsqueeze_1803 = None
    mul_2752: "f32[144]" = torch.ops.aten.mul.Tensor(sum_81, 0.002551020408163265)
    mul_2753: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_856, squeeze_856)
    mul_2754: "f32[144]" = torch.ops.aten.mul.Tensor(mul_2752, mul_2753);  mul_2752 = mul_2753 = None
    unsqueeze_1805: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2754, 0);  mul_2754 = None
    unsqueeze_1806: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1805, 2);  unsqueeze_1805 = None
    unsqueeze_1807: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1806, 3);  unsqueeze_1806 = None
    mul_2755: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_856, primals_857);  primals_857 = None
    unsqueeze_1808: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2755, 0);  mul_2755 = None
    unsqueeze_1809: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1808, 2);  unsqueeze_1808 = None
    unsqueeze_1810: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1809, 3);  unsqueeze_1809 = None
    mul_2756: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_481, unsqueeze_1807);  sub_481 = unsqueeze_1807 = None
    sub_483: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_27, mul_2756);  where_27 = mul_2756 = None
    sub_484: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_483, unsqueeze_1804);  sub_483 = unsqueeze_1804 = None
    mul_2757: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_484, unsqueeze_1810);  sub_484 = unsqueeze_1810 = None
    mul_2758: "f32[144]" = torch.ops.aten.mul.Tensor(sum_81, squeeze_856);  sum_81 = squeeze_856 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_39 = torch.ops.aten.convolution_backward.default(mul_2757, relu_255, primals_856, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2757 = primals_856 = None
    getitem_767: "f32[8, 144, 7, 7]" = convolution_backward_39[0]
    getitem_768: "f32[144, 144, 3, 3]" = convolution_backward_39[1];  convolution_backward_39 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1943: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(where_26, getitem_767);  where_26 = getitem_767 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_28: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_255, 0);  relu_255 = None
    where_28: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_28, full_default, add_1943);  le_28 = add_1943 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_82: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_28, [0, 2, 3])
    sub_485: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_284, unsqueeze_1813);  convolution_284 = unsqueeze_1813 = None
    mul_2759: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_28, sub_485)
    sum_83: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_2759, [0, 2, 3]);  mul_2759 = None
    mul_2760: "f32[144]" = torch.ops.aten.mul.Tensor(sum_82, 0.002551020408163265)
    unsqueeze_1814: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2760, 0);  mul_2760 = None
    unsqueeze_1815: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1814, 2);  unsqueeze_1814 = None
    unsqueeze_1816: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1815, 3);  unsqueeze_1815 = None
    mul_2761: "f32[144]" = torch.ops.aten.mul.Tensor(sum_83, 0.002551020408163265)
    mul_2762: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_853, squeeze_853)
    mul_2763: "f32[144]" = torch.ops.aten.mul.Tensor(mul_2761, mul_2762);  mul_2761 = mul_2762 = None
    unsqueeze_1817: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2763, 0);  mul_2763 = None
    unsqueeze_1818: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1817, 2);  unsqueeze_1817 = None
    unsqueeze_1819: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1818, 3);  unsqueeze_1818 = None
    mul_2764: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_853, primals_854);  primals_854 = None
    unsqueeze_1820: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2764, 0);  mul_2764 = None
    unsqueeze_1821: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1820, 2);  unsqueeze_1820 = None
    unsqueeze_1822: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1821, 3);  unsqueeze_1821 = None
    mul_2765: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_485, unsqueeze_1819);  sub_485 = unsqueeze_1819 = None
    sub_487: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_28, mul_2765);  mul_2765 = None
    sub_488: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_487, unsqueeze_1816);  sub_487 = unsqueeze_1816 = None
    mul_2766: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_488, unsqueeze_1822);  sub_488 = unsqueeze_1822 = None
    mul_2767: "f32[144]" = torch.ops.aten.mul.Tensor(sum_83, squeeze_853);  sum_83 = squeeze_853 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_40 = torch.ops.aten.convolution_backward.default(mul_2766, relu_254, primals_853, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2766 = primals_853 = None
    getitem_770: "f32[8, 144, 7, 7]" = convolution_backward_40[0]
    getitem_771: "f32[144, 144, 3, 3]" = convolution_backward_40[1];  convolution_backward_40 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_29: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_254, 0);  relu_254 = None
    where_29: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_29, full_default, getitem_770);  le_29 = getitem_770 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_84: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_29, [0, 2, 3])
    sub_489: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_283, unsqueeze_1825);  convolution_283 = unsqueeze_1825 = None
    mul_2768: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_29, sub_489)
    sum_85: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_2768, [0, 2, 3]);  mul_2768 = None
    mul_2769: "f32[144]" = torch.ops.aten.mul.Tensor(sum_84, 0.002551020408163265)
    unsqueeze_1826: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2769, 0);  mul_2769 = None
    unsqueeze_1827: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1826, 2);  unsqueeze_1826 = None
    unsqueeze_1828: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1827, 3);  unsqueeze_1827 = None
    mul_2770: "f32[144]" = torch.ops.aten.mul.Tensor(sum_85, 0.002551020408163265)
    mul_2771: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_850, squeeze_850)
    mul_2772: "f32[144]" = torch.ops.aten.mul.Tensor(mul_2770, mul_2771);  mul_2770 = mul_2771 = None
    unsqueeze_1829: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2772, 0);  mul_2772 = None
    unsqueeze_1830: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1829, 2);  unsqueeze_1829 = None
    unsqueeze_1831: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1830, 3);  unsqueeze_1830 = None
    mul_2773: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_850, primals_851);  primals_851 = None
    unsqueeze_1832: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2773, 0);  mul_2773 = None
    unsqueeze_1833: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1832, 2);  unsqueeze_1832 = None
    unsqueeze_1834: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1833, 3);  unsqueeze_1833 = None
    mul_2774: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_489, unsqueeze_1831);  sub_489 = unsqueeze_1831 = None
    sub_491: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_29, mul_2774);  where_29 = mul_2774 = None
    sub_492: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_491, unsqueeze_1828);  sub_491 = unsqueeze_1828 = None
    mul_2775: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_492, unsqueeze_1834);  sub_492 = unsqueeze_1834 = None
    mul_2776: "f32[144]" = torch.ops.aten.mul.Tensor(sum_85, squeeze_850);  sum_85 = squeeze_850 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_41 = torch.ops.aten.convolution_backward.default(mul_2775, relu_253, primals_850, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2775 = primals_850 = None
    getitem_773: "f32[8, 144, 7, 7]" = convolution_backward_41[0]
    getitem_774: "f32[144, 144, 3, 3]" = convolution_backward_41[1];  convolution_backward_41 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1944: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(where_28, getitem_773);  where_28 = getitem_773 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_30: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_253, 0);  relu_253 = None
    where_30: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_30, full_default, add_1944);  le_30 = add_1944 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_86: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_30, [0, 2, 3])
    sub_493: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_282, unsqueeze_1837);  convolution_282 = unsqueeze_1837 = None
    mul_2777: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_30, sub_493)
    sum_87: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_2777, [0, 2, 3]);  mul_2777 = None
    mul_2778: "f32[144]" = torch.ops.aten.mul.Tensor(sum_86, 0.002551020408163265)
    unsqueeze_1838: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2778, 0);  mul_2778 = None
    unsqueeze_1839: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1838, 2);  unsqueeze_1838 = None
    unsqueeze_1840: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1839, 3);  unsqueeze_1839 = None
    mul_2779: "f32[144]" = torch.ops.aten.mul.Tensor(sum_87, 0.002551020408163265)
    mul_2780: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_847, squeeze_847)
    mul_2781: "f32[144]" = torch.ops.aten.mul.Tensor(mul_2779, mul_2780);  mul_2779 = mul_2780 = None
    unsqueeze_1841: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2781, 0);  mul_2781 = None
    unsqueeze_1842: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1841, 2);  unsqueeze_1841 = None
    unsqueeze_1843: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1842, 3);  unsqueeze_1842 = None
    mul_2782: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_847, primals_848);  primals_848 = None
    unsqueeze_1844: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2782, 0);  mul_2782 = None
    unsqueeze_1845: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1844, 2);  unsqueeze_1844 = None
    unsqueeze_1846: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1845, 3);  unsqueeze_1845 = None
    mul_2783: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_493, unsqueeze_1843);  sub_493 = unsqueeze_1843 = None
    sub_495: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_30, mul_2783);  mul_2783 = None
    sub_496: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_495, unsqueeze_1840);  sub_495 = unsqueeze_1840 = None
    mul_2784: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_496, unsqueeze_1846);  sub_496 = unsqueeze_1846 = None
    mul_2785: "f32[144]" = torch.ops.aten.mul.Tensor(sum_87, squeeze_847);  sum_87 = squeeze_847 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_42 = torch.ops.aten.convolution_backward.default(mul_2784, relu_252, primals_847, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2784 = primals_847 = None
    getitem_776: "f32[8, 144, 7, 7]" = convolution_backward_42[0]
    getitem_777: "f32[144, 144, 3, 3]" = convolution_backward_42[1];  convolution_backward_42 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_31: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_252, 0);  relu_252 = None
    where_31: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_31, full_default, getitem_776);  le_31 = getitem_776 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_88: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_31, [0, 2, 3])
    sub_497: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_281, unsqueeze_1849);  convolution_281 = unsqueeze_1849 = None
    mul_2786: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_31, sub_497)
    sum_89: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_2786, [0, 2, 3]);  mul_2786 = None
    mul_2787: "f32[144]" = torch.ops.aten.mul.Tensor(sum_88, 0.002551020408163265)
    unsqueeze_1850: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2787, 0);  mul_2787 = None
    unsqueeze_1851: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1850, 2);  unsqueeze_1850 = None
    unsqueeze_1852: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1851, 3);  unsqueeze_1851 = None
    mul_2788: "f32[144]" = torch.ops.aten.mul.Tensor(sum_89, 0.002551020408163265)
    mul_2789: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_844, squeeze_844)
    mul_2790: "f32[144]" = torch.ops.aten.mul.Tensor(mul_2788, mul_2789);  mul_2788 = mul_2789 = None
    unsqueeze_1853: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2790, 0);  mul_2790 = None
    unsqueeze_1854: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1853, 2);  unsqueeze_1853 = None
    unsqueeze_1855: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1854, 3);  unsqueeze_1854 = None
    mul_2791: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_844, primals_845);  primals_845 = None
    unsqueeze_1856: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_2791, 0);  mul_2791 = None
    unsqueeze_1857: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1856, 2);  unsqueeze_1856 = None
    unsqueeze_1858: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1857, 3);  unsqueeze_1857 = None
    mul_2792: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_497, unsqueeze_1855);  sub_497 = unsqueeze_1855 = None
    sub_499: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_31, mul_2792);  where_31 = mul_2792 = None
    sub_500: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_499, unsqueeze_1852);  sub_499 = unsqueeze_1852 = None
    mul_2793: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_500, unsqueeze_1858);  sub_500 = unsqueeze_1858 = None
    mul_2794: "f32[144]" = torch.ops.aten.mul.Tensor(sum_89, squeeze_844);  sum_89 = squeeze_844 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_43 = torch.ops.aten.convolution_backward.default(mul_2793, relu_227, primals_844, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2793 = primals_844 = None
    getitem_779: "f32[8, 144, 7, 7]" = convolution_backward_43[0]
    getitem_780: "f32[144, 144, 3, 3]" = convolution_backward_43[1];  convolution_backward_43 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1945: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(where_30, getitem_779);  where_30 = getitem_779 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_32: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_251, 0);  relu_251 = None
    where_32: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_32, full_default, add_1939);  le_32 = add_1939 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_90: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_32, [0, 2, 3])
    sub_501: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_280, unsqueeze_1861);  convolution_280 = unsqueeze_1861 = None
    mul_2795: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_32, sub_501)
    sum_91: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_2795, [0, 2, 3]);  mul_2795 = None
    mul_2796: "f32[72]" = torch.ops.aten.mul.Tensor(sum_90, 0.0006377551020408163)
    unsqueeze_1862: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2796, 0);  mul_2796 = None
    unsqueeze_1863: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1862, 2);  unsqueeze_1862 = None
    unsqueeze_1864: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1863, 3);  unsqueeze_1863 = None
    mul_2797: "f32[72]" = torch.ops.aten.mul.Tensor(sum_91, 0.0006377551020408163)
    mul_2798: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_841, squeeze_841)
    mul_2799: "f32[72]" = torch.ops.aten.mul.Tensor(mul_2797, mul_2798);  mul_2797 = mul_2798 = None
    unsqueeze_1865: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2799, 0);  mul_2799 = None
    unsqueeze_1866: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1865, 2);  unsqueeze_1865 = None
    unsqueeze_1867: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1866, 3);  unsqueeze_1866 = None
    mul_2800: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_841, primals_842);  primals_842 = None
    unsqueeze_1868: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2800, 0);  mul_2800 = None
    unsqueeze_1869: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1868, 2);  unsqueeze_1868 = None
    unsqueeze_1870: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1869, 3);  unsqueeze_1869 = None
    mul_2801: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_501, unsqueeze_1867);  sub_501 = unsqueeze_1867 = None
    sub_503: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_32, mul_2801);  mul_2801 = None
    sub_504: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_503, unsqueeze_1864);  sub_503 = unsqueeze_1864 = None
    mul_2802: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_504, unsqueeze_1870);  sub_504 = unsqueeze_1870 = None
    mul_2803: "f32[72]" = torch.ops.aten.mul.Tensor(sum_91, squeeze_841);  sum_91 = squeeze_841 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_44 = torch.ops.aten.convolution_backward.default(mul_2802, relu_250, primals_841, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2802 = primals_841 = None
    getitem_782: "f32[8, 72, 14, 14]" = convolution_backward_44[0]
    getitem_783: "f32[72, 72, 3, 3]" = convolution_backward_44[1];  convolution_backward_44 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_33: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_250, 0);  relu_250 = None
    where_33: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_33, full_default, getitem_782);  le_33 = getitem_782 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_92: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_33, [0, 2, 3])
    sub_505: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_279, unsqueeze_1873);  convolution_279 = unsqueeze_1873 = None
    mul_2804: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_33, sub_505)
    sum_93: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_2804, [0, 2, 3]);  mul_2804 = None
    mul_2805: "f32[72]" = torch.ops.aten.mul.Tensor(sum_92, 0.0006377551020408163)
    unsqueeze_1874: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2805, 0);  mul_2805 = None
    unsqueeze_1875: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1874, 2);  unsqueeze_1874 = None
    unsqueeze_1876: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1875, 3);  unsqueeze_1875 = None
    mul_2806: "f32[72]" = torch.ops.aten.mul.Tensor(sum_93, 0.0006377551020408163)
    mul_2807: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_838, squeeze_838)
    mul_2808: "f32[72]" = torch.ops.aten.mul.Tensor(mul_2806, mul_2807);  mul_2806 = mul_2807 = None
    unsqueeze_1877: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2808, 0);  mul_2808 = None
    unsqueeze_1878: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1877, 2);  unsqueeze_1877 = None
    unsqueeze_1879: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1878, 3);  unsqueeze_1878 = None
    mul_2809: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_838, primals_839);  primals_839 = None
    unsqueeze_1880: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2809, 0);  mul_2809 = None
    unsqueeze_1881: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1880, 2);  unsqueeze_1880 = None
    unsqueeze_1882: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1881, 3);  unsqueeze_1881 = None
    mul_2810: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_505, unsqueeze_1879);  sub_505 = unsqueeze_1879 = None
    sub_507: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_33, mul_2810);  where_33 = mul_2810 = None
    sub_508: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_507, unsqueeze_1876);  sub_507 = unsqueeze_1876 = None
    mul_2811: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_508, unsqueeze_1882);  sub_508 = unsqueeze_1882 = None
    mul_2812: "f32[72]" = torch.ops.aten.mul.Tensor(sum_93, squeeze_838);  sum_93 = squeeze_838 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_45 = torch.ops.aten.convolution_backward.default(mul_2811, relu_249, primals_838, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2811 = primals_838 = None
    getitem_785: "f32[8, 72, 14, 14]" = convolution_backward_45[0]
    getitem_786: "f32[72, 72, 3, 3]" = convolution_backward_45[1];  convolution_backward_45 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1946: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_32, getitem_785);  where_32 = getitem_785 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_34: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_249, 0);  relu_249 = None
    where_34: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_34, full_default, add_1946);  le_34 = add_1946 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_94: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_34, [0, 2, 3])
    sub_509: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_278, unsqueeze_1885);  convolution_278 = unsqueeze_1885 = None
    mul_2813: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_34, sub_509)
    sum_95: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_2813, [0, 2, 3]);  mul_2813 = None
    mul_2814: "f32[72]" = torch.ops.aten.mul.Tensor(sum_94, 0.0006377551020408163)
    unsqueeze_1886: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2814, 0);  mul_2814 = None
    unsqueeze_1887: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1886, 2);  unsqueeze_1886 = None
    unsqueeze_1888: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1887, 3);  unsqueeze_1887 = None
    mul_2815: "f32[72]" = torch.ops.aten.mul.Tensor(sum_95, 0.0006377551020408163)
    mul_2816: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_835, squeeze_835)
    mul_2817: "f32[72]" = torch.ops.aten.mul.Tensor(mul_2815, mul_2816);  mul_2815 = mul_2816 = None
    unsqueeze_1889: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2817, 0);  mul_2817 = None
    unsqueeze_1890: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1889, 2);  unsqueeze_1889 = None
    unsqueeze_1891: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1890, 3);  unsqueeze_1890 = None
    mul_2818: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_835, primals_836);  primals_836 = None
    unsqueeze_1892: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2818, 0);  mul_2818 = None
    unsqueeze_1893: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1892, 2);  unsqueeze_1892 = None
    unsqueeze_1894: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1893, 3);  unsqueeze_1893 = None
    mul_2819: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_509, unsqueeze_1891);  sub_509 = unsqueeze_1891 = None
    sub_511: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_34, mul_2819);  mul_2819 = None
    sub_512: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_511, unsqueeze_1888);  sub_511 = unsqueeze_1888 = None
    mul_2820: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_512, unsqueeze_1894);  sub_512 = unsqueeze_1894 = None
    mul_2821: "f32[72]" = torch.ops.aten.mul.Tensor(sum_95, squeeze_835);  sum_95 = squeeze_835 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_46 = torch.ops.aten.convolution_backward.default(mul_2820, relu_248, primals_835, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2820 = primals_835 = None
    getitem_788: "f32[8, 72, 14, 14]" = convolution_backward_46[0]
    getitem_789: "f32[72, 72, 3, 3]" = convolution_backward_46[1];  convolution_backward_46 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_35: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_248, 0);  relu_248 = None
    where_35: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_35, full_default, getitem_788);  le_35 = getitem_788 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_96: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_35, [0, 2, 3])
    sub_513: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_277, unsqueeze_1897);  convolution_277 = unsqueeze_1897 = None
    mul_2822: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_35, sub_513)
    sum_97: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_2822, [0, 2, 3]);  mul_2822 = None
    mul_2823: "f32[72]" = torch.ops.aten.mul.Tensor(sum_96, 0.0006377551020408163)
    unsqueeze_1898: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2823, 0);  mul_2823 = None
    unsqueeze_1899: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1898, 2);  unsqueeze_1898 = None
    unsqueeze_1900: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1899, 3);  unsqueeze_1899 = None
    mul_2824: "f32[72]" = torch.ops.aten.mul.Tensor(sum_97, 0.0006377551020408163)
    mul_2825: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_832, squeeze_832)
    mul_2826: "f32[72]" = torch.ops.aten.mul.Tensor(mul_2824, mul_2825);  mul_2824 = mul_2825 = None
    unsqueeze_1901: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2826, 0);  mul_2826 = None
    unsqueeze_1902: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1901, 2);  unsqueeze_1901 = None
    unsqueeze_1903: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1902, 3);  unsqueeze_1902 = None
    mul_2827: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_832, primals_833);  primals_833 = None
    unsqueeze_1904: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2827, 0);  mul_2827 = None
    unsqueeze_1905: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1904, 2);  unsqueeze_1904 = None
    unsqueeze_1906: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1905, 3);  unsqueeze_1905 = None
    mul_2828: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_513, unsqueeze_1903);  sub_513 = unsqueeze_1903 = None
    sub_515: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_35, mul_2828);  where_35 = mul_2828 = None
    sub_516: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_515, unsqueeze_1900);  sub_515 = unsqueeze_1900 = None
    mul_2829: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_516, unsqueeze_1906);  sub_516 = unsqueeze_1906 = None
    mul_2830: "f32[72]" = torch.ops.aten.mul.Tensor(sum_97, squeeze_832);  sum_97 = squeeze_832 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_47 = torch.ops.aten.convolution_backward.default(mul_2829, relu_247, primals_832, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2829 = primals_832 = None
    getitem_791: "f32[8, 72, 14, 14]" = convolution_backward_47[0]
    getitem_792: "f32[72, 72, 3, 3]" = convolution_backward_47[1];  convolution_backward_47 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1947: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_34, getitem_791);  where_34 = getitem_791 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_36: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_247, 0);  relu_247 = None
    where_36: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_36, full_default, add_1947);  le_36 = add_1947 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_98: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_36, [0, 2, 3])
    sub_517: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_276, unsqueeze_1909);  convolution_276 = unsqueeze_1909 = None
    mul_2831: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_36, sub_517)
    sum_99: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_2831, [0, 2, 3]);  mul_2831 = None
    mul_2832: "f32[72]" = torch.ops.aten.mul.Tensor(sum_98, 0.0006377551020408163)
    unsqueeze_1910: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2832, 0);  mul_2832 = None
    unsqueeze_1911: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1910, 2);  unsqueeze_1910 = None
    unsqueeze_1912: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1911, 3);  unsqueeze_1911 = None
    mul_2833: "f32[72]" = torch.ops.aten.mul.Tensor(sum_99, 0.0006377551020408163)
    mul_2834: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_829, squeeze_829)
    mul_2835: "f32[72]" = torch.ops.aten.mul.Tensor(mul_2833, mul_2834);  mul_2833 = mul_2834 = None
    unsqueeze_1913: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2835, 0);  mul_2835 = None
    unsqueeze_1914: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1913, 2);  unsqueeze_1913 = None
    unsqueeze_1915: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1914, 3);  unsqueeze_1914 = None
    mul_2836: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_829, primals_830);  primals_830 = None
    unsqueeze_1916: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2836, 0);  mul_2836 = None
    unsqueeze_1917: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1916, 2);  unsqueeze_1916 = None
    unsqueeze_1918: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1917, 3);  unsqueeze_1917 = None
    mul_2837: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_517, unsqueeze_1915);  sub_517 = unsqueeze_1915 = None
    sub_519: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_36, mul_2837);  mul_2837 = None
    sub_520: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_519, unsqueeze_1912);  sub_519 = unsqueeze_1912 = None
    mul_2838: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_520, unsqueeze_1918);  sub_520 = unsqueeze_1918 = None
    mul_2839: "f32[72]" = torch.ops.aten.mul.Tensor(sum_99, squeeze_829);  sum_99 = squeeze_829 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_48 = torch.ops.aten.convolution_backward.default(mul_2838, relu_246, primals_829, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2838 = primals_829 = None
    getitem_794: "f32[8, 72, 14, 14]" = convolution_backward_48[0]
    getitem_795: "f32[72, 72, 3, 3]" = convolution_backward_48[1];  convolution_backward_48 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_37: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_246, 0);  relu_246 = None
    where_37: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_37, full_default, getitem_794);  le_37 = getitem_794 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_100: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_37, [0, 2, 3])
    sub_521: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_275, unsqueeze_1921);  convolution_275 = unsqueeze_1921 = None
    mul_2840: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_37, sub_521)
    sum_101: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_2840, [0, 2, 3]);  mul_2840 = None
    mul_2841: "f32[72]" = torch.ops.aten.mul.Tensor(sum_100, 0.0006377551020408163)
    unsqueeze_1922: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2841, 0);  mul_2841 = None
    unsqueeze_1923: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1922, 2);  unsqueeze_1922 = None
    unsqueeze_1924: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1923, 3);  unsqueeze_1923 = None
    mul_2842: "f32[72]" = torch.ops.aten.mul.Tensor(sum_101, 0.0006377551020408163)
    mul_2843: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_826, squeeze_826)
    mul_2844: "f32[72]" = torch.ops.aten.mul.Tensor(mul_2842, mul_2843);  mul_2842 = mul_2843 = None
    unsqueeze_1925: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2844, 0);  mul_2844 = None
    unsqueeze_1926: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1925, 2);  unsqueeze_1925 = None
    unsqueeze_1927: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1926, 3);  unsqueeze_1926 = None
    mul_2845: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_826, primals_827);  primals_827 = None
    unsqueeze_1928: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2845, 0);  mul_2845 = None
    unsqueeze_1929: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1928, 2);  unsqueeze_1928 = None
    unsqueeze_1930: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1929, 3);  unsqueeze_1929 = None
    mul_2846: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_521, unsqueeze_1927);  sub_521 = unsqueeze_1927 = None
    sub_523: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_37, mul_2846);  where_37 = mul_2846 = None
    sub_524: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_523, unsqueeze_1924);  sub_523 = unsqueeze_1924 = None
    mul_2847: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_524, unsqueeze_1930);  sub_524 = unsqueeze_1930 = None
    mul_2848: "f32[72]" = torch.ops.aten.mul.Tensor(sum_101, squeeze_826);  sum_101 = squeeze_826 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_49 = torch.ops.aten.convolution_backward.default(mul_2847, relu_245, primals_826, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2847 = primals_826 = None
    getitem_797: "f32[8, 72, 14, 14]" = convolution_backward_49[0]
    getitem_798: "f32[72, 72, 3, 3]" = convolution_backward_49[1];  convolution_backward_49 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1948: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_36, getitem_797);  where_36 = getitem_797 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_38: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_245, 0);  relu_245 = None
    where_38: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_38, full_default, add_1948);  le_38 = add_1948 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_102: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_38, [0, 2, 3])
    sub_525: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_274, unsqueeze_1933);  convolution_274 = unsqueeze_1933 = None
    mul_2849: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_38, sub_525)
    sum_103: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_2849, [0, 2, 3]);  mul_2849 = None
    mul_2850: "f32[72]" = torch.ops.aten.mul.Tensor(sum_102, 0.0006377551020408163)
    unsqueeze_1934: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2850, 0);  mul_2850 = None
    unsqueeze_1935: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1934, 2);  unsqueeze_1934 = None
    unsqueeze_1936: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1935, 3);  unsqueeze_1935 = None
    mul_2851: "f32[72]" = torch.ops.aten.mul.Tensor(sum_103, 0.0006377551020408163)
    mul_2852: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_823, squeeze_823)
    mul_2853: "f32[72]" = torch.ops.aten.mul.Tensor(mul_2851, mul_2852);  mul_2851 = mul_2852 = None
    unsqueeze_1937: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2853, 0);  mul_2853 = None
    unsqueeze_1938: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1937, 2);  unsqueeze_1937 = None
    unsqueeze_1939: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1938, 3);  unsqueeze_1938 = None
    mul_2854: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_823, primals_824);  primals_824 = None
    unsqueeze_1940: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2854, 0);  mul_2854 = None
    unsqueeze_1941: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1940, 2);  unsqueeze_1940 = None
    unsqueeze_1942: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1941, 3);  unsqueeze_1941 = None
    mul_2855: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_525, unsqueeze_1939);  sub_525 = unsqueeze_1939 = None
    sub_527: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_38, mul_2855);  mul_2855 = None
    sub_528: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_527, unsqueeze_1936);  sub_527 = unsqueeze_1936 = None
    mul_2856: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_528, unsqueeze_1942);  sub_528 = unsqueeze_1942 = None
    mul_2857: "f32[72]" = torch.ops.aten.mul.Tensor(sum_103, squeeze_823);  sum_103 = squeeze_823 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_50 = torch.ops.aten.convolution_backward.default(mul_2856, relu_244, primals_823, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2856 = primals_823 = None
    getitem_800: "f32[8, 72, 14, 14]" = convolution_backward_50[0]
    getitem_801: "f32[72, 72, 3, 3]" = convolution_backward_50[1];  convolution_backward_50 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_39: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_244, 0);  relu_244 = None
    where_39: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_39, full_default, getitem_800);  le_39 = getitem_800 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_104: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_39, [0, 2, 3])
    sub_529: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_273, unsqueeze_1945);  convolution_273 = unsqueeze_1945 = None
    mul_2858: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_39, sub_529)
    sum_105: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_2858, [0, 2, 3]);  mul_2858 = None
    mul_2859: "f32[72]" = torch.ops.aten.mul.Tensor(sum_104, 0.0006377551020408163)
    unsqueeze_1946: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2859, 0);  mul_2859 = None
    unsqueeze_1947: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1946, 2);  unsqueeze_1946 = None
    unsqueeze_1948: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1947, 3);  unsqueeze_1947 = None
    mul_2860: "f32[72]" = torch.ops.aten.mul.Tensor(sum_105, 0.0006377551020408163)
    mul_2861: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_820, squeeze_820)
    mul_2862: "f32[72]" = torch.ops.aten.mul.Tensor(mul_2860, mul_2861);  mul_2860 = mul_2861 = None
    unsqueeze_1949: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2862, 0);  mul_2862 = None
    unsqueeze_1950: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1949, 2);  unsqueeze_1949 = None
    unsqueeze_1951: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1950, 3);  unsqueeze_1950 = None
    mul_2863: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_820, primals_821);  primals_821 = None
    unsqueeze_1952: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_2863, 0);  mul_2863 = None
    unsqueeze_1953: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1952, 2);  unsqueeze_1952 = None
    unsqueeze_1954: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1953, 3);  unsqueeze_1953 = None
    mul_2864: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_529, unsqueeze_1951);  sub_529 = unsqueeze_1951 = None
    sub_531: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_39, mul_2864);  where_39 = mul_2864 = None
    sub_532: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_531, unsqueeze_1948);  sub_531 = unsqueeze_1948 = None
    mul_2865: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_532, unsqueeze_1954);  sub_532 = unsqueeze_1954 = None
    mul_2866: "f32[72]" = torch.ops.aten.mul.Tensor(sum_105, squeeze_820);  sum_105 = squeeze_820 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_51 = torch.ops.aten.convolution_backward.default(mul_2865, relu_223, primals_820, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2865 = primals_820 = None
    getitem_803: "f32[8, 72, 14, 14]" = convolution_backward_51[0]
    getitem_804: "f32[72, 72, 3, 3]" = convolution_backward_51[1];  convolution_backward_51 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1949: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_38, getitem_803);  where_38 = getitem_803 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_40: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_243, 0);  relu_243 = None
    where_40: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_40, full_default, add_1941);  le_40 = add_1941 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_106: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_40, [0, 2, 3])
    sub_533: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_272, unsqueeze_1957);  convolution_272 = unsqueeze_1957 = None
    mul_2867: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_40, sub_533)
    sum_107: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_2867, [0, 2, 3]);  mul_2867 = None
    mul_2868: "f32[36]" = torch.ops.aten.mul.Tensor(sum_106, 0.00015943877551020407)
    unsqueeze_1958: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2868, 0);  mul_2868 = None
    unsqueeze_1959: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1958, 2);  unsqueeze_1958 = None
    unsqueeze_1960: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1959, 3);  unsqueeze_1959 = None
    mul_2869: "f32[36]" = torch.ops.aten.mul.Tensor(sum_107, 0.00015943877551020407)
    mul_2870: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_817, squeeze_817)
    mul_2871: "f32[36]" = torch.ops.aten.mul.Tensor(mul_2869, mul_2870);  mul_2869 = mul_2870 = None
    unsqueeze_1961: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2871, 0);  mul_2871 = None
    unsqueeze_1962: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1961, 2);  unsqueeze_1961 = None
    unsqueeze_1963: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1962, 3);  unsqueeze_1962 = None
    mul_2872: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_817, primals_818);  primals_818 = None
    unsqueeze_1964: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2872, 0);  mul_2872 = None
    unsqueeze_1965: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1964, 2);  unsqueeze_1964 = None
    unsqueeze_1966: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1965, 3);  unsqueeze_1965 = None
    mul_2873: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_533, unsqueeze_1963);  sub_533 = unsqueeze_1963 = None
    sub_535: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_40, mul_2873);  mul_2873 = None
    sub_536: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_535, unsqueeze_1960);  sub_535 = unsqueeze_1960 = None
    mul_2874: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_536, unsqueeze_1966);  sub_536 = unsqueeze_1966 = None
    mul_2875: "f32[36]" = torch.ops.aten.mul.Tensor(sum_107, squeeze_817);  sum_107 = squeeze_817 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_52 = torch.ops.aten.convolution_backward.default(mul_2874, relu_242, primals_817, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2874 = primals_817 = None
    getitem_806: "f32[8, 36, 28, 28]" = convolution_backward_52[0]
    getitem_807: "f32[36, 36, 3, 3]" = convolution_backward_52[1];  convolution_backward_52 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_41: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_242, 0);  relu_242 = None
    where_41: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_41, full_default, getitem_806);  le_41 = getitem_806 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_108: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_41, [0, 2, 3])
    sub_537: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_271, unsqueeze_1969);  convolution_271 = unsqueeze_1969 = None
    mul_2876: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_41, sub_537)
    sum_109: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_2876, [0, 2, 3]);  mul_2876 = None
    mul_2877: "f32[36]" = torch.ops.aten.mul.Tensor(sum_108, 0.00015943877551020407)
    unsqueeze_1970: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2877, 0);  mul_2877 = None
    unsqueeze_1971: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1970, 2);  unsqueeze_1970 = None
    unsqueeze_1972: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1971, 3);  unsqueeze_1971 = None
    mul_2878: "f32[36]" = torch.ops.aten.mul.Tensor(sum_109, 0.00015943877551020407)
    mul_2879: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_814, squeeze_814)
    mul_2880: "f32[36]" = torch.ops.aten.mul.Tensor(mul_2878, mul_2879);  mul_2878 = mul_2879 = None
    unsqueeze_1973: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2880, 0);  mul_2880 = None
    unsqueeze_1974: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1973, 2);  unsqueeze_1973 = None
    unsqueeze_1975: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1974, 3);  unsqueeze_1974 = None
    mul_2881: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_814, primals_815);  primals_815 = None
    unsqueeze_1976: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2881, 0);  mul_2881 = None
    unsqueeze_1977: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1976, 2);  unsqueeze_1976 = None
    unsqueeze_1978: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1977, 3);  unsqueeze_1977 = None
    mul_2882: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_537, unsqueeze_1975);  sub_537 = unsqueeze_1975 = None
    sub_539: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_41, mul_2882);  where_41 = mul_2882 = None
    sub_540: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_539, unsqueeze_1972);  sub_539 = unsqueeze_1972 = None
    mul_2883: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_540, unsqueeze_1978);  sub_540 = unsqueeze_1978 = None
    mul_2884: "f32[36]" = torch.ops.aten.mul.Tensor(sum_109, squeeze_814);  sum_109 = squeeze_814 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_53 = torch.ops.aten.convolution_backward.default(mul_2883, relu_241, primals_814, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2883 = primals_814 = None
    getitem_809: "f32[8, 36, 28, 28]" = convolution_backward_53[0]
    getitem_810: "f32[36, 36, 3, 3]" = convolution_backward_53[1];  convolution_backward_53 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1950: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_40, getitem_809);  where_40 = getitem_809 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_42: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_241, 0);  relu_241 = None
    where_42: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_42, full_default, add_1950);  le_42 = add_1950 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_110: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_42, [0, 2, 3])
    sub_541: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_270, unsqueeze_1981);  convolution_270 = unsqueeze_1981 = None
    mul_2885: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_42, sub_541)
    sum_111: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_2885, [0, 2, 3]);  mul_2885 = None
    mul_2886: "f32[36]" = torch.ops.aten.mul.Tensor(sum_110, 0.00015943877551020407)
    unsqueeze_1982: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2886, 0);  mul_2886 = None
    unsqueeze_1983: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1982, 2);  unsqueeze_1982 = None
    unsqueeze_1984: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1983, 3);  unsqueeze_1983 = None
    mul_2887: "f32[36]" = torch.ops.aten.mul.Tensor(sum_111, 0.00015943877551020407)
    mul_2888: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_811, squeeze_811)
    mul_2889: "f32[36]" = torch.ops.aten.mul.Tensor(mul_2887, mul_2888);  mul_2887 = mul_2888 = None
    unsqueeze_1985: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2889, 0);  mul_2889 = None
    unsqueeze_1986: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1985, 2);  unsqueeze_1985 = None
    unsqueeze_1987: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1986, 3);  unsqueeze_1986 = None
    mul_2890: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_811, primals_812);  primals_812 = None
    unsqueeze_1988: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2890, 0);  mul_2890 = None
    unsqueeze_1989: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1988, 2);  unsqueeze_1988 = None
    unsqueeze_1990: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1989, 3);  unsqueeze_1989 = None
    mul_2891: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_541, unsqueeze_1987);  sub_541 = unsqueeze_1987 = None
    sub_543: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_42, mul_2891);  mul_2891 = None
    sub_544: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_543, unsqueeze_1984);  sub_543 = unsqueeze_1984 = None
    mul_2892: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_544, unsqueeze_1990);  sub_544 = unsqueeze_1990 = None
    mul_2893: "f32[36]" = torch.ops.aten.mul.Tensor(sum_111, squeeze_811);  sum_111 = squeeze_811 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_54 = torch.ops.aten.convolution_backward.default(mul_2892, relu_240, primals_811, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2892 = primals_811 = None
    getitem_812: "f32[8, 36, 28, 28]" = convolution_backward_54[0]
    getitem_813: "f32[36, 36, 3, 3]" = convolution_backward_54[1];  convolution_backward_54 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_43: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_240, 0);  relu_240 = None
    where_43: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_43, full_default, getitem_812);  le_43 = getitem_812 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_112: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_43, [0, 2, 3])
    sub_545: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_269, unsqueeze_1993);  convolution_269 = unsqueeze_1993 = None
    mul_2894: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_43, sub_545)
    sum_113: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_2894, [0, 2, 3]);  mul_2894 = None
    mul_2895: "f32[36]" = torch.ops.aten.mul.Tensor(sum_112, 0.00015943877551020407)
    unsqueeze_1994: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2895, 0);  mul_2895 = None
    unsqueeze_1995: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1994, 2);  unsqueeze_1994 = None
    unsqueeze_1996: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1995, 3);  unsqueeze_1995 = None
    mul_2896: "f32[36]" = torch.ops.aten.mul.Tensor(sum_113, 0.00015943877551020407)
    mul_2897: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_808, squeeze_808)
    mul_2898: "f32[36]" = torch.ops.aten.mul.Tensor(mul_2896, mul_2897);  mul_2896 = mul_2897 = None
    unsqueeze_1997: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2898, 0);  mul_2898 = None
    unsqueeze_1998: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1997, 2);  unsqueeze_1997 = None
    unsqueeze_1999: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_1998, 3);  unsqueeze_1998 = None
    mul_2899: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_808, primals_809);  primals_809 = None
    unsqueeze_2000: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2899, 0);  mul_2899 = None
    unsqueeze_2001: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2000, 2);  unsqueeze_2000 = None
    unsqueeze_2002: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2001, 3);  unsqueeze_2001 = None
    mul_2900: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_545, unsqueeze_1999);  sub_545 = unsqueeze_1999 = None
    sub_547: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_43, mul_2900);  where_43 = mul_2900 = None
    sub_548: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_547, unsqueeze_1996);  sub_547 = unsqueeze_1996 = None
    mul_2901: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_548, unsqueeze_2002);  sub_548 = unsqueeze_2002 = None
    mul_2902: "f32[36]" = torch.ops.aten.mul.Tensor(sum_113, squeeze_808);  sum_113 = squeeze_808 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_55 = torch.ops.aten.convolution_backward.default(mul_2901, relu_239, primals_808, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2901 = primals_808 = None
    getitem_815: "f32[8, 36, 28, 28]" = convolution_backward_55[0]
    getitem_816: "f32[36, 36, 3, 3]" = convolution_backward_55[1];  convolution_backward_55 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1951: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_42, getitem_815);  where_42 = getitem_815 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_44: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_239, 0);  relu_239 = None
    where_44: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_44, full_default, add_1951);  le_44 = add_1951 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_114: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_44, [0, 2, 3])
    sub_549: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_268, unsqueeze_2005);  convolution_268 = unsqueeze_2005 = None
    mul_2903: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_44, sub_549)
    sum_115: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_2903, [0, 2, 3]);  mul_2903 = None
    mul_2904: "f32[36]" = torch.ops.aten.mul.Tensor(sum_114, 0.00015943877551020407)
    unsqueeze_2006: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2904, 0);  mul_2904 = None
    unsqueeze_2007: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2006, 2);  unsqueeze_2006 = None
    unsqueeze_2008: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2007, 3);  unsqueeze_2007 = None
    mul_2905: "f32[36]" = torch.ops.aten.mul.Tensor(sum_115, 0.00015943877551020407)
    mul_2906: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_805, squeeze_805)
    mul_2907: "f32[36]" = torch.ops.aten.mul.Tensor(mul_2905, mul_2906);  mul_2905 = mul_2906 = None
    unsqueeze_2009: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2907, 0);  mul_2907 = None
    unsqueeze_2010: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2009, 2);  unsqueeze_2009 = None
    unsqueeze_2011: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2010, 3);  unsqueeze_2010 = None
    mul_2908: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_805, primals_806);  primals_806 = None
    unsqueeze_2012: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2908, 0);  mul_2908 = None
    unsqueeze_2013: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2012, 2);  unsqueeze_2012 = None
    unsqueeze_2014: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2013, 3);  unsqueeze_2013 = None
    mul_2909: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_549, unsqueeze_2011);  sub_549 = unsqueeze_2011 = None
    sub_551: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_44, mul_2909);  mul_2909 = None
    sub_552: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_551, unsqueeze_2008);  sub_551 = unsqueeze_2008 = None
    mul_2910: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_552, unsqueeze_2014);  sub_552 = unsqueeze_2014 = None
    mul_2911: "f32[36]" = torch.ops.aten.mul.Tensor(sum_115, squeeze_805);  sum_115 = squeeze_805 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_56 = torch.ops.aten.convolution_backward.default(mul_2910, relu_238, primals_805, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2910 = primals_805 = None
    getitem_818: "f32[8, 36, 28, 28]" = convolution_backward_56[0]
    getitem_819: "f32[36, 36, 3, 3]" = convolution_backward_56[1];  convolution_backward_56 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_45: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_238, 0);  relu_238 = None
    where_45: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_45, full_default, getitem_818);  le_45 = getitem_818 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_116: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_45, [0, 2, 3])
    sub_553: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_267, unsqueeze_2017);  convolution_267 = unsqueeze_2017 = None
    mul_2912: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_45, sub_553)
    sum_117: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_2912, [0, 2, 3]);  mul_2912 = None
    mul_2913: "f32[36]" = torch.ops.aten.mul.Tensor(sum_116, 0.00015943877551020407)
    unsqueeze_2018: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2913, 0);  mul_2913 = None
    unsqueeze_2019: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2018, 2);  unsqueeze_2018 = None
    unsqueeze_2020: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2019, 3);  unsqueeze_2019 = None
    mul_2914: "f32[36]" = torch.ops.aten.mul.Tensor(sum_117, 0.00015943877551020407)
    mul_2915: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_802, squeeze_802)
    mul_2916: "f32[36]" = torch.ops.aten.mul.Tensor(mul_2914, mul_2915);  mul_2914 = mul_2915 = None
    unsqueeze_2021: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2916, 0);  mul_2916 = None
    unsqueeze_2022: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2021, 2);  unsqueeze_2021 = None
    unsqueeze_2023: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2022, 3);  unsqueeze_2022 = None
    mul_2917: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_802, primals_803);  primals_803 = None
    unsqueeze_2024: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2917, 0);  mul_2917 = None
    unsqueeze_2025: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2024, 2);  unsqueeze_2024 = None
    unsqueeze_2026: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2025, 3);  unsqueeze_2025 = None
    mul_2918: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_553, unsqueeze_2023);  sub_553 = unsqueeze_2023 = None
    sub_555: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_45, mul_2918);  where_45 = mul_2918 = None
    sub_556: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_555, unsqueeze_2020);  sub_555 = unsqueeze_2020 = None
    mul_2919: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_556, unsqueeze_2026);  sub_556 = unsqueeze_2026 = None
    mul_2920: "f32[36]" = torch.ops.aten.mul.Tensor(sum_117, squeeze_802);  sum_117 = squeeze_802 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_57 = torch.ops.aten.convolution_backward.default(mul_2919, relu_237, primals_802, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2919 = primals_802 = None
    getitem_821: "f32[8, 36, 28, 28]" = convolution_backward_57[0]
    getitem_822: "f32[36, 36, 3, 3]" = convolution_backward_57[1];  convolution_backward_57 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1952: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_44, getitem_821);  where_44 = getitem_821 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_46: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_237, 0);  relu_237 = None
    where_46: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_46, full_default, add_1952);  le_46 = add_1952 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_118: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_46, [0, 2, 3])
    sub_557: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_266, unsqueeze_2029);  convolution_266 = unsqueeze_2029 = None
    mul_2921: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_46, sub_557)
    sum_119: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_2921, [0, 2, 3]);  mul_2921 = None
    mul_2922: "f32[36]" = torch.ops.aten.mul.Tensor(sum_118, 0.00015943877551020407)
    unsqueeze_2030: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2922, 0);  mul_2922 = None
    unsqueeze_2031: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2030, 2);  unsqueeze_2030 = None
    unsqueeze_2032: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2031, 3);  unsqueeze_2031 = None
    mul_2923: "f32[36]" = torch.ops.aten.mul.Tensor(sum_119, 0.00015943877551020407)
    mul_2924: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_799, squeeze_799)
    mul_2925: "f32[36]" = torch.ops.aten.mul.Tensor(mul_2923, mul_2924);  mul_2923 = mul_2924 = None
    unsqueeze_2033: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2925, 0);  mul_2925 = None
    unsqueeze_2034: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2033, 2);  unsqueeze_2033 = None
    unsqueeze_2035: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2034, 3);  unsqueeze_2034 = None
    mul_2926: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_799, primals_800);  primals_800 = None
    unsqueeze_2036: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2926, 0);  mul_2926 = None
    unsqueeze_2037: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2036, 2);  unsqueeze_2036 = None
    unsqueeze_2038: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2037, 3);  unsqueeze_2037 = None
    mul_2927: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_557, unsqueeze_2035);  sub_557 = unsqueeze_2035 = None
    sub_559: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_46, mul_2927);  mul_2927 = None
    sub_560: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_559, unsqueeze_2032);  sub_559 = unsqueeze_2032 = None
    mul_2928: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_560, unsqueeze_2038);  sub_560 = unsqueeze_2038 = None
    mul_2929: "f32[36]" = torch.ops.aten.mul.Tensor(sum_119, squeeze_799);  sum_119 = squeeze_799 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_58 = torch.ops.aten.convolution_backward.default(mul_2928, relu_236, primals_799, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2928 = primals_799 = None
    getitem_824: "f32[8, 36, 28, 28]" = convolution_backward_58[0]
    getitem_825: "f32[36, 36, 3, 3]" = convolution_backward_58[1];  convolution_backward_58 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_47: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_236, 0);  relu_236 = None
    where_47: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_47, full_default, getitem_824);  le_47 = getitem_824 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_120: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_47, [0, 2, 3])
    sub_561: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_265, unsqueeze_2041);  convolution_265 = unsqueeze_2041 = None
    mul_2930: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_47, sub_561)
    sum_121: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_2930, [0, 2, 3]);  mul_2930 = None
    mul_2931: "f32[36]" = torch.ops.aten.mul.Tensor(sum_120, 0.00015943877551020407)
    unsqueeze_2042: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2931, 0);  mul_2931 = None
    unsqueeze_2043: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2042, 2);  unsqueeze_2042 = None
    unsqueeze_2044: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2043, 3);  unsqueeze_2043 = None
    mul_2932: "f32[36]" = torch.ops.aten.mul.Tensor(sum_121, 0.00015943877551020407)
    mul_2933: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_796, squeeze_796)
    mul_2934: "f32[36]" = torch.ops.aten.mul.Tensor(mul_2932, mul_2933);  mul_2932 = mul_2933 = None
    unsqueeze_2045: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2934, 0);  mul_2934 = None
    unsqueeze_2046: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2045, 2);  unsqueeze_2045 = None
    unsqueeze_2047: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2046, 3);  unsqueeze_2046 = None
    mul_2935: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_796, primals_797);  primals_797 = None
    unsqueeze_2048: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_2935, 0);  mul_2935 = None
    unsqueeze_2049: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2048, 2);  unsqueeze_2048 = None
    unsqueeze_2050: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2049, 3);  unsqueeze_2049 = None
    mul_2936: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_561, unsqueeze_2047);  sub_561 = unsqueeze_2047 = None
    sub_563: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_47, mul_2936);  where_47 = mul_2936 = None
    sub_564: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_563, unsqueeze_2044);  sub_563 = unsqueeze_2044 = None
    mul_2937: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_564, unsqueeze_2050);  sub_564 = unsqueeze_2050 = None
    mul_2938: "f32[36]" = torch.ops.aten.mul.Tensor(sum_121, squeeze_796);  sum_121 = squeeze_796 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_59 = torch.ops.aten.convolution_backward.default(mul_2937, relu_221, primals_796, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2937 = primals_796 = None
    getitem_827: "f32[8, 36, 28, 28]" = convolution_backward_59[0]
    getitem_828: "f32[36, 36, 3, 3]" = convolution_backward_59[1];  convolution_backward_59 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1953: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_46, getitem_827);  where_46 = getitem_827 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_48: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_235, 0);  relu_235 = None
    where_48: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_48, full_default, add_1940);  le_48 = add_1940 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_122: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_48, [0, 2, 3])
    sub_565: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_264, unsqueeze_2053);  convolution_264 = unsqueeze_2053 = None
    mul_2939: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_48, sub_565)
    sum_123: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_2939, [0, 2, 3]);  mul_2939 = None
    mul_2940: "f32[18]" = torch.ops.aten.mul.Tensor(sum_122, 3.985969387755102e-05)
    unsqueeze_2054: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2940, 0);  mul_2940 = None
    unsqueeze_2055: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2054, 2);  unsqueeze_2054 = None
    unsqueeze_2056: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2055, 3);  unsqueeze_2055 = None
    mul_2941: "f32[18]" = torch.ops.aten.mul.Tensor(sum_123, 3.985969387755102e-05)
    mul_2942: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_793, squeeze_793)
    mul_2943: "f32[18]" = torch.ops.aten.mul.Tensor(mul_2941, mul_2942);  mul_2941 = mul_2942 = None
    unsqueeze_2057: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2943, 0);  mul_2943 = None
    unsqueeze_2058: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2057, 2);  unsqueeze_2057 = None
    unsqueeze_2059: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2058, 3);  unsqueeze_2058 = None
    mul_2944: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_793, primals_794);  primals_794 = None
    unsqueeze_2060: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2944, 0);  mul_2944 = None
    unsqueeze_2061: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2060, 2);  unsqueeze_2060 = None
    unsqueeze_2062: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2061, 3);  unsqueeze_2061 = None
    mul_2945: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_565, unsqueeze_2059);  sub_565 = unsqueeze_2059 = None
    sub_567: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_48, mul_2945);  mul_2945 = None
    sub_568: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_567, unsqueeze_2056);  sub_567 = unsqueeze_2056 = None
    mul_2946: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_568, unsqueeze_2062);  sub_568 = unsqueeze_2062 = None
    mul_2947: "f32[18]" = torch.ops.aten.mul.Tensor(sum_123, squeeze_793);  sum_123 = squeeze_793 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_60 = torch.ops.aten.convolution_backward.default(mul_2946, relu_234, primals_793, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2946 = primals_793 = None
    getitem_830: "f32[8, 18, 56, 56]" = convolution_backward_60[0]
    getitem_831: "f32[18, 18, 3, 3]" = convolution_backward_60[1];  convolution_backward_60 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_49: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_234, 0);  relu_234 = None
    where_49: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_49, full_default, getitem_830);  le_49 = getitem_830 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_124: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_49, [0, 2, 3])
    sub_569: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_263, unsqueeze_2065);  convolution_263 = unsqueeze_2065 = None
    mul_2948: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_49, sub_569)
    sum_125: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_2948, [0, 2, 3]);  mul_2948 = None
    mul_2949: "f32[18]" = torch.ops.aten.mul.Tensor(sum_124, 3.985969387755102e-05)
    unsqueeze_2066: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2949, 0);  mul_2949 = None
    unsqueeze_2067: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2066, 2);  unsqueeze_2066 = None
    unsqueeze_2068: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2067, 3);  unsqueeze_2067 = None
    mul_2950: "f32[18]" = torch.ops.aten.mul.Tensor(sum_125, 3.985969387755102e-05)
    mul_2951: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_790, squeeze_790)
    mul_2952: "f32[18]" = torch.ops.aten.mul.Tensor(mul_2950, mul_2951);  mul_2950 = mul_2951 = None
    unsqueeze_2069: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2952, 0);  mul_2952 = None
    unsqueeze_2070: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2069, 2);  unsqueeze_2069 = None
    unsqueeze_2071: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2070, 3);  unsqueeze_2070 = None
    mul_2953: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_790, primals_791);  primals_791 = None
    unsqueeze_2072: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2953, 0);  mul_2953 = None
    unsqueeze_2073: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2072, 2);  unsqueeze_2072 = None
    unsqueeze_2074: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2073, 3);  unsqueeze_2073 = None
    mul_2954: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_569, unsqueeze_2071);  sub_569 = unsqueeze_2071 = None
    sub_571: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_49, mul_2954);  where_49 = mul_2954 = None
    sub_572: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_571, unsqueeze_2068);  sub_571 = unsqueeze_2068 = None
    mul_2955: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_572, unsqueeze_2074);  sub_572 = unsqueeze_2074 = None
    mul_2956: "f32[18]" = torch.ops.aten.mul.Tensor(sum_125, squeeze_790);  sum_125 = squeeze_790 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_61 = torch.ops.aten.convolution_backward.default(mul_2955, relu_233, primals_790, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2955 = primals_790 = None
    getitem_833: "f32[8, 18, 56, 56]" = convolution_backward_61[0]
    getitem_834: "f32[18, 18, 3, 3]" = convolution_backward_61[1];  convolution_backward_61 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1954: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_48, getitem_833);  where_48 = getitem_833 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_50: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_233, 0);  relu_233 = None
    where_50: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_50, full_default, add_1954);  le_50 = add_1954 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_126: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_50, [0, 2, 3])
    sub_573: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_262, unsqueeze_2077);  convolution_262 = unsqueeze_2077 = None
    mul_2957: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_50, sub_573)
    sum_127: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_2957, [0, 2, 3]);  mul_2957 = None
    mul_2958: "f32[18]" = torch.ops.aten.mul.Tensor(sum_126, 3.985969387755102e-05)
    unsqueeze_2078: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2958, 0);  mul_2958 = None
    unsqueeze_2079: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2078, 2);  unsqueeze_2078 = None
    unsqueeze_2080: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2079, 3);  unsqueeze_2079 = None
    mul_2959: "f32[18]" = torch.ops.aten.mul.Tensor(sum_127, 3.985969387755102e-05)
    mul_2960: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_787, squeeze_787)
    mul_2961: "f32[18]" = torch.ops.aten.mul.Tensor(mul_2959, mul_2960);  mul_2959 = mul_2960 = None
    unsqueeze_2081: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2961, 0);  mul_2961 = None
    unsqueeze_2082: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2081, 2);  unsqueeze_2081 = None
    unsqueeze_2083: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2082, 3);  unsqueeze_2082 = None
    mul_2962: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_787, primals_788);  primals_788 = None
    unsqueeze_2084: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2962, 0);  mul_2962 = None
    unsqueeze_2085: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2084, 2);  unsqueeze_2084 = None
    unsqueeze_2086: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2085, 3);  unsqueeze_2085 = None
    mul_2963: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_573, unsqueeze_2083);  sub_573 = unsqueeze_2083 = None
    sub_575: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_50, mul_2963);  mul_2963 = None
    sub_576: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_575, unsqueeze_2080);  sub_575 = unsqueeze_2080 = None
    mul_2964: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_576, unsqueeze_2086);  sub_576 = unsqueeze_2086 = None
    mul_2965: "f32[18]" = torch.ops.aten.mul.Tensor(sum_127, squeeze_787);  sum_127 = squeeze_787 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_62 = torch.ops.aten.convolution_backward.default(mul_2964, relu_232, primals_787, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2964 = primals_787 = None
    getitem_836: "f32[8, 18, 56, 56]" = convolution_backward_62[0]
    getitem_837: "f32[18, 18, 3, 3]" = convolution_backward_62[1];  convolution_backward_62 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_51: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_232, 0);  relu_232 = None
    where_51: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_51, full_default, getitem_836);  le_51 = getitem_836 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_128: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_51, [0, 2, 3])
    sub_577: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_261, unsqueeze_2089);  convolution_261 = unsqueeze_2089 = None
    mul_2966: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_51, sub_577)
    sum_129: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_2966, [0, 2, 3]);  mul_2966 = None
    mul_2967: "f32[18]" = torch.ops.aten.mul.Tensor(sum_128, 3.985969387755102e-05)
    unsqueeze_2090: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2967, 0);  mul_2967 = None
    unsqueeze_2091: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2090, 2);  unsqueeze_2090 = None
    unsqueeze_2092: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2091, 3);  unsqueeze_2091 = None
    mul_2968: "f32[18]" = torch.ops.aten.mul.Tensor(sum_129, 3.985969387755102e-05)
    mul_2969: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_784, squeeze_784)
    mul_2970: "f32[18]" = torch.ops.aten.mul.Tensor(mul_2968, mul_2969);  mul_2968 = mul_2969 = None
    unsqueeze_2093: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2970, 0);  mul_2970 = None
    unsqueeze_2094: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2093, 2);  unsqueeze_2093 = None
    unsqueeze_2095: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2094, 3);  unsqueeze_2094 = None
    mul_2971: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_784, primals_785);  primals_785 = None
    unsqueeze_2096: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2971, 0);  mul_2971 = None
    unsqueeze_2097: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2096, 2);  unsqueeze_2096 = None
    unsqueeze_2098: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2097, 3);  unsqueeze_2097 = None
    mul_2972: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_577, unsqueeze_2095);  sub_577 = unsqueeze_2095 = None
    sub_579: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_51, mul_2972);  where_51 = mul_2972 = None
    sub_580: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_579, unsqueeze_2092);  sub_579 = unsqueeze_2092 = None
    mul_2973: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_580, unsqueeze_2098);  sub_580 = unsqueeze_2098 = None
    mul_2974: "f32[18]" = torch.ops.aten.mul.Tensor(sum_129, squeeze_784);  sum_129 = squeeze_784 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_63 = torch.ops.aten.convolution_backward.default(mul_2973, relu_231, primals_784, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2973 = primals_784 = None
    getitem_839: "f32[8, 18, 56, 56]" = convolution_backward_63[0]
    getitem_840: "f32[18, 18, 3, 3]" = convolution_backward_63[1];  convolution_backward_63 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1955: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_50, getitem_839);  where_50 = getitem_839 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_52: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_231, 0);  relu_231 = None
    where_52: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_52, full_default, add_1955);  le_52 = add_1955 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_130: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_52, [0, 2, 3])
    sub_581: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_260, unsqueeze_2101);  convolution_260 = unsqueeze_2101 = None
    mul_2975: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_52, sub_581)
    sum_131: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_2975, [0, 2, 3]);  mul_2975 = None
    mul_2976: "f32[18]" = torch.ops.aten.mul.Tensor(sum_130, 3.985969387755102e-05)
    unsqueeze_2102: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2976, 0);  mul_2976 = None
    unsqueeze_2103: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2102, 2);  unsqueeze_2102 = None
    unsqueeze_2104: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2103, 3);  unsqueeze_2103 = None
    mul_2977: "f32[18]" = torch.ops.aten.mul.Tensor(sum_131, 3.985969387755102e-05)
    mul_2978: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_781, squeeze_781)
    mul_2979: "f32[18]" = torch.ops.aten.mul.Tensor(mul_2977, mul_2978);  mul_2977 = mul_2978 = None
    unsqueeze_2105: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2979, 0);  mul_2979 = None
    unsqueeze_2106: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2105, 2);  unsqueeze_2105 = None
    unsqueeze_2107: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2106, 3);  unsqueeze_2106 = None
    mul_2980: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_781, primals_782);  primals_782 = None
    unsqueeze_2108: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2980, 0);  mul_2980 = None
    unsqueeze_2109: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2108, 2);  unsqueeze_2108 = None
    unsqueeze_2110: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2109, 3);  unsqueeze_2109 = None
    mul_2981: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_581, unsqueeze_2107);  sub_581 = unsqueeze_2107 = None
    sub_583: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_52, mul_2981);  mul_2981 = None
    sub_584: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_583, unsqueeze_2104);  sub_583 = unsqueeze_2104 = None
    mul_2982: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_584, unsqueeze_2110);  sub_584 = unsqueeze_2110 = None
    mul_2983: "f32[18]" = torch.ops.aten.mul.Tensor(sum_131, squeeze_781);  sum_131 = squeeze_781 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_64 = torch.ops.aten.convolution_backward.default(mul_2982, relu_230, primals_781, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2982 = primals_781 = None
    getitem_842: "f32[8, 18, 56, 56]" = convolution_backward_64[0]
    getitem_843: "f32[18, 18, 3, 3]" = convolution_backward_64[1];  convolution_backward_64 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_53: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_230, 0);  relu_230 = None
    where_53: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_53, full_default, getitem_842);  le_53 = getitem_842 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_132: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_53, [0, 2, 3])
    sub_585: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_259, unsqueeze_2113);  convolution_259 = unsqueeze_2113 = None
    mul_2984: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_53, sub_585)
    sum_133: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_2984, [0, 2, 3]);  mul_2984 = None
    mul_2985: "f32[18]" = torch.ops.aten.mul.Tensor(sum_132, 3.985969387755102e-05)
    unsqueeze_2114: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2985, 0);  mul_2985 = None
    unsqueeze_2115: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2114, 2);  unsqueeze_2114 = None
    unsqueeze_2116: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2115, 3);  unsqueeze_2115 = None
    mul_2986: "f32[18]" = torch.ops.aten.mul.Tensor(sum_133, 3.985969387755102e-05)
    mul_2987: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_778, squeeze_778)
    mul_2988: "f32[18]" = torch.ops.aten.mul.Tensor(mul_2986, mul_2987);  mul_2986 = mul_2987 = None
    unsqueeze_2117: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2988, 0);  mul_2988 = None
    unsqueeze_2118: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2117, 2);  unsqueeze_2117 = None
    unsqueeze_2119: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2118, 3);  unsqueeze_2118 = None
    mul_2989: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_778, primals_779);  primals_779 = None
    unsqueeze_2120: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2989, 0);  mul_2989 = None
    unsqueeze_2121: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2120, 2);  unsqueeze_2120 = None
    unsqueeze_2122: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2121, 3);  unsqueeze_2121 = None
    mul_2990: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_585, unsqueeze_2119);  sub_585 = unsqueeze_2119 = None
    sub_587: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_53, mul_2990);  where_53 = mul_2990 = None
    sub_588: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_587, unsqueeze_2116);  sub_587 = unsqueeze_2116 = None
    mul_2991: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_588, unsqueeze_2122);  sub_588 = unsqueeze_2122 = None
    mul_2992: "f32[18]" = torch.ops.aten.mul.Tensor(sum_133, squeeze_778);  sum_133 = squeeze_778 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_65 = torch.ops.aten.convolution_backward.default(mul_2991, relu_229, primals_778, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_2991 = primals_778 = None
    getitem_845: "f32[8, 18, 56, 56]" = convolution_backward_65[0]
    getitem_846: "f32[18, 18, 3, 3]" = convolution_backward_65[1];  convolution_backward_65 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1956: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_52, getitem_845);  where_52 = getitem_845 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_54: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_229, 0);  relu_229 = None
    where_54: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_54, full_default, add_1956);  le_54 = add_1956 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_134: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_54, [0, 2, 3])
    sub_589: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_258, unsqueeze_2125);  convolution_258 = unsqueeze_2125 = None
    mul_2993: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_54, sub_589)
    sum_135: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_2993, [0, 2, 3]);  mul_2993 = None
    mul_2994: "f32[18]" = torch.ops.aten.mul.Tensor(sum_134, 3.985969387755102e-05)
    unsqueeze_2126: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2994, 0);  mul_2994 = None
    unsqueeze_2127: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2126, 2);  unsqueeze_2126 = None
    unsqueeze_2128: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2127, 3);  unsqueeze_2127 = None
    mul_2995: "f32[18]" = torch.ops.aten.mul.Tensor(sum_135, 3.985969387755102e-05)
    mul_2996: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_775, squeeze_775)
    mul_2997: "f32[18]" = torch.ops.aten.mul.Tensor(mul_2995, mul_2996);  mul_2995 = mul_2996 = None
    unsqueeze_2129: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2997, 0);  mul_2997 = None
    unsqueeze_2130: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2129, 2);  unsqueeze_2129 = None
    unsqueeze_2131: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2130, 3);  unsqueeze_2130 = None
    mul_2998: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_775, primals_776);  primals_776 = None
    unsqueeze_2132: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_2998, 0);  mul_2998 = None
    unsqueeze_2133: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2132, 2);  unsqueeze_2132 = None
    unsqueeze_2134: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2133, 3);  unsqueeze_2133 = None
    mul_2999: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_589, unsqueeze_2131);  sub_589 = unsqueeze_2131 = None
    sub_591: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_54, mul_2999);  mul_2999 = None
    sub_592: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_591, unsqueeze_2128);  sub_591 = unsqueeze_2128 = None
    mul_3000: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_592, unsqueeze_2134);  sub_592 = unsqueeze_2134 = None
    mul_3001: "f32[18]" = torch.ops.aten.mul.Tensor(sum_135, squeeze_775);  sum_135 = squeeze_775 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_66 = torch.ops.aten.convolution_backward.default(mul_3000, relu_228, primals_775, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3000 = primals_775 = None
    getitem_848: "f32[8, 18, 56, 56]" = convolution_backward_66[0]
    getitem_849: "f32[18, 18, 3, 3]" = convolution_backward_66[1];  convolution_backward_66 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_55: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_228, 0);  relu_228 = None
    where_55: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_55, full_default, getitem_848);  le_55 = getitem_848 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_136: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_55, [0, 2, 3])
    sub_593: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_257, unsqueeze_2137);  convolution_257 = unsqueeze_2137 = None
    mul_3002: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_55, sub_593)
    sum_137: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3002, [0, 2, 3]);  mul_3002 = None
    mul_3003: "f32[18]" = torch.ops.aten.mul.Tensor(sum_136, 3.985969387755102e-05)
    unsqueeze_2138: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3003, 0);  mul_3003 = None
    unsqueeze_2139: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2138, 2);  unsqueeze_2138 = None
    unsqueeze_2140: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2139, 3);  unsqueeze_2139 = None
    mul_3004: "f32[18]" = torch.ops.aten.mul.Tensor(sum_137, 3.985969387755102e-05)
    mul_3005: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_772, squeeze_772)
    mul_3006: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3004, mul_3005);  mul_3004 = mul_3005 = None
    unsqueeze_2141: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3006, 0);  mul_3006 = None
    unsqueeze_2142: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2141, 2);  unsqueeze_2141 = None
    unsqueeze_2143: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2142, 3);  unsqueeze_2142 = None
    mul_3007: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_772, primals_773);  primals_773 = None
    unsqueeze_2144: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3007, 0);  mul_3007 = None
    unsqueeze_2145: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2144, 2);  unsqueeze_2144 = None
    unsqueeze_2146: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2145, 3);  unsqueeze_2145 = None
    mul_3008: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_593, unsqueeze_2143);  sub_593 = unsqueeze_2143 = None
    sub_595: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_55, mul_3008);  where_55 = mul_3008 = None
    sub_596: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_595, unsqueeze_2140);  sub_595 = unsqueeze_2140 = None
    mul_3009: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_596, unsqueeze_2146);  sub_596 = unsqueeze_2146 = None
    mul_3010: "f32[18]" = torch.ops.aten.mul.Tensor(sum_137, squeeze_772);  sum_137 = squeeze_772 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_67 = torch.ops.aten.convolution_backward.default(mul_3009, relu_220, primals_772, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3009 = primals_772 = None
    getitem_851: "f32[8, 18, 56, 56]" = convolution_backward_67[0]
    getitem_852: "f32[18, 18, 3, 3]" = convolution_backward_67[1];  convolution_backward_67 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1957: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_54, getitem_851);  where_54 = getitem_851 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_56: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_227, 0);  relu_227 = None
    where_56: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_56, full_default, add_1945);  le_56 = add_1945 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    sum_138: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_56, [0, 2, 3])
    sub_597: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_256, unsqueeze_2149);  convolution_256 = unsqueeze_2149 = None
    mul_3011: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_56, sub_597)
    sum_139: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3011, [0, 2, 3]);  mul_3011 = None
    mul_3012: "f32[144]" = torch.ops.aten.mul.Tensor(sum_138, 0.002551020408163265)
    unsqueeze_2150: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3012, 0);  mul_3012 = None
    unsqueeze_2151: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2150, 2);  unsqueeze_2150 = None
    unsqueeze_2152: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2151, 3);  unsqueeze_2151 = None
    mul_3013: "f32[144]" = torch.ops.aten.mul.Tensor(sum_139, 0.002551020408163265)
    mul_3014: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_769, squeeze_769)
    mul_3015: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3013, mul_3014);  mul_3013 = mul_3014 = None
    unsqueeze_2153: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3015, 0);  mul_3015 = None
    unsqueeze_2154: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2153, 2);  unsqueeze_2153 = None
    unsqueeze_2155: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2154, 3);  unsqueeze_2154 = None
    mul_3016: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_769, primals_770);  primals_770 = None
    unsqueeze_2156: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3016, 0);  mul_3016 = None
    unsqueeze_2157: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2156, 2);  unsqueeze_2156 = None
    unsqueeze_2158: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2157, 3);  unsqueeze_2157 = None
    mul_3017: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_597, unsqueeze_2155);  sub_597 = unsqueeze_2155 = None
    sub_599: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_56, mul_3017);  mul_3017 = None
    sub_600: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_599, unsqueeze_2152);  sub_599 = None
    mul_3018: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_600, unsqueeze_2158);  sub_600 = unsqueeze_2158 = None
    mul_3019: "f32[144]" = torch.ops.aten.mul.Tensor(sum_139, squeeze_769);  sum_139 = squeeze_769 = None
    convolution_backward_68 = torch.ops.aten.convolution_backward.default(mul_3018, relu_211, primals_769, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3018 = primals_769 = None
    getitem_854: "f32[8, 72, 14, 14]" = convolution_backward_68[0]
    getitem_855: "f32[144, 72, 3, 3]" = convolution_backward_68[1];  convolution_backward_68 = None
    sub_601: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_255, unsqueeze_2161);  convolution_255 = unsqueeze_2161 = None
    mul_3020: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_56, sub_601)
    sum_141: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3020, [0, 2, 3]);  mul_3020 = None
    mul_3022: "f32[144]" = torch.ops.aten.mul.Tensor(sum_141, 0.002551020408163265)
    mul_3023: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_766, squeeze_766)
    mul_3024: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3022, mul_3023);  mul_3022 = mul_3023 = None
    unsqueeze_2165: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3024, 0);  mul_3024 = None
    unsqueeze_2166: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2165, 2);  unsqueeze_2165 = None
    unsqueeze_2167: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2166, 3);  unsqueeze_2166 = None
    mul_3025: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_766, primals_767);  primals_767 = None
    unsqueeze_2168: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3025, 0);  mul_3025 = None
    unsqueeze_2169: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2168, 2);  unsqueeze_2168 = None
    unsqueeze_2170: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2169, 3);  unsqueeze_2169 = None
    mul_3026: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_601, unsqueeze_2167);  sub_601 = unsqueeze_2167 = None
    sub_603: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_56, mul_3026);  mul_3026 = None
    sub_604: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_603, unsqueeze_2152);  sub_603 = None
    mul_3027: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_604, unsqueeze_2170);  sub_604 = unsqueeze_2170 = None
    mul_3028: "f32[144]" = torch.ops.aten.mul.Tensor(sum_141, squeeze_766);  sum_141 = squeeze_766 = None
    convolution_backward_69 = torch.ops.aten.convolution_backward.default(mul_3027, relu_226, primals_766, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3027 = primals_766 = None
    getitem_857: "f32[8, 36, 14, 14]" = convolution_backward_69[0]
    getitem_858: "f32[144, 36, 3, 3]" = convolution_backward_69[1];  convolution_backward_69 = None
    le_57: "b8[8, 36, 14, 14]" = torch.ops.aten.le.Scalar(relu_226, 0);  relu_226 = None
    where_57: "f32[8, 36, 14, 14]" = torch.ops.aten.where.self(le_57, full_default, getitem_857);  le_57 = getitem_857 = None
    sum_142: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_57, [0, 2, 3])
    sub_605: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_254, unsqueeze_2173);  convolution_254 = unsqueeze_2173 = None
    mul_3029: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(where_57, sub_605)
    sum_143: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3029, [0, 2, 3]);  mul_3029 = None
    mul_3030: "f32[36]" = torch.ops.aten.mul.Tensor(sum_142, 0.0006377551020408163)
    unsqueeze_2174: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3030, 0);  mul_3030 = None
    unsqueeze_2175: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2174, 2);  unsqueeze_2174 = None
    unsqueeze_2176: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2175, 3);  unsqueeze_2175 = None
    mul_3031: "f32[36]" = torch.ops.aten.mul.Tensor(sum_143, 0.0006377551020408163)
    mul_3032: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_763, squeeze_763)
    mul_3033: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3031, mul_3032);  mul_3031 = mul_3032 = None
    unsqueeze_2177: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3033, 0);  mul_3033 = None
    unsqueeze_2178: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2177, 2);  unsqueeze_2177 = None
    unsqueeze_2179: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2178, 3);  unsqueeze_2178 = None
    mul_3034: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_763, primals_764);  primals_764 = None
    unsqueeze_2180: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3034, 0);  mul_3034 = None
    unsqueeze_2181: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2180, 2);  unsqueeze_2180 = None
    unsqueeze_2182: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2181, 3);  unsqueeze_2181 = None
    mul_3035: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_605, unsqueeze_2179);  sub_605 = unsqueeze_2179 = None
    sub_607: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(where_57, mul_3035);  where_57 = mul_3035 = None
    sub_608: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(sub_607, unsqueeze_2176);  sub_607 = unsqueeze_2176 = None
    mul_3036: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_608, unsqueeze_2182);  sub_608 = unsqueeze_2182 = None
    mul_3037: "f32[36]" = torch.ops.aten.mul.Tensor(sum_143, squeeze_763);  sum_143 = squeeze_763 = None
    convolution_backward_70 = torch.ops.aten.convolution_backward.default(mul_3036, relu_203, primals_763, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3036 = primals_763 = None
    getitem_860: "f32[8, 36, 28, 28]" = convolution_backward_70[0]
    getitem_861: "f32[36, 36, 3, 3]" = convolution_backward_70[1];  convolution_backward_70 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sub_609: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_253, unsqueeze_2185);  convolution_253 = unsqueeze_2185 = None
    mul_3038: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_56, sub_609)
    sum_145: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3038, [0, 2, 3]);  mul_3038 = None
    mul_3040: "f32[144]" = torch.ops.aten.mul.Tensor(sum_145, 0.002551020408163265)
    mul_3041: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_760, squeeze_760)
    mul_3042: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3040, mul_3041);  mul_3040 = mul_3041 = None
    unsqueeze_2189: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3042, 0);  mul_3042 = None
    unsqueeze_2190: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2189, 2);  unsqueeze_2189 = None
    unsqueeze_2191: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2190, 3);  unsqueeze_2190 = None
    mul_3043: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_760, primals_761);  primals_761 = None
    unsqueeze_2192: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3043, 0);  mul_3043 = None
    unsqueeze_2193: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2192, 2);  unsqueeze_2192 = None
    unsqueeze_2194: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2193, 3);  unsqueeze_2193 = None
    mul_3044: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_609, unsqueeze_2191);  sub_609 = unsqueeze_2191 = None
    sub_611: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_56, mul_3044);  mul_3044 = None
    sub_612: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_611, unsqueeze_2152);  sub_611 = unsqueeze_2152 = None
    mul_3045: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_612, unsqueeze_2194);  sub_612 = unsqueeze_2194 = None
    mul_3046: "f32[144]" = torch.ops.aten.mul.Tensor(sum_145, squeeze_760);  sum_145 = squeeze_760 = None
    convolution_backward_71 = torch.ops.aten.convolution_backward.default(mul_3045, relu_225, primals_760, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3045 = primals_760 = None
    getitem_863: "f32[8, 18, 14, 14]" = convolution_backward_71[0]
    getitem_864: "f32[144, 18, 3, 3]" = convolution_backward_71[1];  convolution_backward_71 = None
    le_58: "b8[8, 18, 14, 14]" = torch.ops.aten.le.Scalar(relu_225, 0);  relu_225 = None
    where_58: "f32[8, 18, 14, 14]" = torch.ops.aten.where.self(le_58, full_default, getitem_863);  le_58 = getitem_863 = None
    sum_146: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_58, [0, 2, 3])
    sub_613: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_252, unsqueeze_2197);  convolution_252 = unsqueeze_2197 = None
    mul_3047: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(where_58, sub_613)
    sum_147: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3047, [0, 2, 3]);  mul_3047 = None
    mul_3048: "f32[18]" = torch.ops.aten.mul.Tensor(sum_146, 0.0006377551020408163)
    unsqueeze_2198: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3048, 0);  mul_3048 = None
    unsqueeze_2199: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2198, 2);  unsqueeze_2198 = None
    unsqueeze_2200: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2199, 3);  unsqueeze_2199 = None
    mul_3049: "f32[18]" = torch.ops.aten.mul.Tensor(sum_147, 0.0006377551020408163)
    mul_3050: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_757, squeeze_757)
    mul_3051: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3049, mul_3050);  mul_3049 = mul_3050 = None
    unsqueeze_2201: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3051, 0);  mul_3051 = None
    unsqueeze_2202: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2201, 2);  unsqueeze_2201 = None
    unsqueeze_2203: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2202, 3);  unsqueeze_2202 = None
    mul_3052: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_757, primals_758);  primals_758 = None
    unsqueeze_2204: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3052, 0);  mul_3052 = None
    unsqueeze_2205: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2204, 2);  unsqueeze_2204 = None
    unsqueeze_2206: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2205, 3);  unsqueeze_2205 = None
    mul_3053: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_613, unsqueeze_2203);  sub_613 = unsqueeze_2203 = None
    sub_615: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(where_58, mul_3053);  where_58 = mul_3053 = None
    sub_616: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(sub_615, unsqueeze_2200);  sub_615 = unsqueeze_2200 = None
    mul_3054: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_616, unsqueeze_2206);  sub_616 = unsqueeze_2206 = None
    mul_3055: "f32[18]" = torch.ops.aten.mul.Tensor(sum_147, squeeze_757);  sum_147 = squeeze_757 = None
    convolution_backward_72 = torch.ops.aten.convolution_backward.default(mul_3054, relu_224, primals_757, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3054 = primals_757 = None
    getitem_866: "f32[8, 18, 28, 28]" = convolution_backward_72[0]
    getitem_867: "f32[18, 18, 3, 3]" = convolution_backward_72[1];  convolution_backward_72 = None
    le_59: "b8[8, 18, 28, 28]" = torch.ops.aten.le.Scalar(relu_224, 0);  relu_224 = None
    where_59: "f32[8, 18, 28, 28]" = torch.ops.aten.where.self(le_59, full_default, getitem_866);  le_59 = getitem_866 = None
    sum_148: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_59, [0, 2, 3])
    sub_617: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_251, unsqueeze_2209);  convolution_251 = unsqueeze_2209 = None
    mul_3056: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(where_59, sub_617)
    sum_149: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3056, [0, 2, 3]);  mul_3056 = None
    mul_3057: "f32[18]" = torch.ops.aten.mul.Tensor(sum_148, 0.00015943877551020407)
    unsqueeze_2210: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3057, 0);  mul_3057 = None
    unsqueeze_2211: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2210, 2);  unsqueeze_2210 = None
    unsqueeze_2212: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2211, 3);  unsqueeze_2211 = None
    mul_3058: "f32[18]" = torch.ops.aten.mul.Tensor(sum_149, 0.00015943877551020407)
    mul_3059: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_754, squeeze_754)
    mul_3060: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3058, mul_3059);  mul_3058 = mul_3059 = None
    unsqueeze_2213: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3060, 0);  mul_3060 = None
    unsqueeze_2214: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2213, 2);  unsqueeze_2213 = None
    unsqueeze_2215: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2214, 3);  unsqueeze_2214 = None
    mul_3061: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_754, primals_755);  primals_755 = None
    unsqueeze_2216: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3061, 0);  mul_3061 = None
    unsqueeze_2217: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2216, 2);  unsqueeze_2216 = None
    unsqueeze_2218: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2217, 3);  unsqueeze_2217 = None
    mul_3062: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_617, unsqueeze_2215);  sub_617 = unsqueeze_2215 = None
    sub_619: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(where_59, mul_3062);  where_59 = mul_3062 = None
    sub_620: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_619, unsqueeze_2212);  sub_619 = unsqueeze_2212 = None
    mul_3063: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_620, unsqueeze_2218);  sub_620 = unsqueeze_2218 = None
    mul_3064: "f32[18]" = torch.ops.aten.mul.Tensor(sum_149, squeeze_754);  sum_149 = squeeze_754 = None
    convolution_backward_73 = torch.ops.aten.convolution_backward.default(mul_3063, relu_195, primals_754, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3063 = primals_754 = None
    getitem_869: "f32[8, 18, 56, 56]" = convolution_backward_73[0]
    getitem_870: "f32[18, 18, 3, 3]" = convolution_backward_73[1];  convolution_backward_73 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_60: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_223, 0);  relu_223 = None
    where_60: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_60, full_default, add_1949);  le_60 = add_1949 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_6: "f32[8, 72, 7, 7]" = torch.ops.aten._unsafe_index_put.default(full_default_21, [None, None, unsqueeze_830, convert_element_type_110], where_60, True)
    sum_150: "f32[72]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_6, [0, 2, 3])
    sub_621: "f32[8, 72, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_250, unsqueeze_2221);  convolution_250 = unsqueeze_2221 = None
    mul_3065: "f32[8, 72, 7, 7]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_6, sub_621)
    sum_151: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3065, [0, 2, 3]);  mul_3065 = None
    mul_3066: "f32[72]" = torch.ops.aten.mul.Tensor(sum_150, 0.002551020408163265)
    unsqueeze_2222: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3066, 0);  mul_3066 = None
    unsqueeze_2223: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2222, 2);  unsqueeze_2222 = None
    unsqueeze_2224: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2223, 3);  unsqueeze_2223 = None
    mul_3067: "f32[72]" = torch.ops.aten.mul.Tensor(sum_151, 0.002551020408163265)
    mul_3068: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_751, squeeze_751)
    mul_3069: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3067, mul_3068);  mul_3067 = mul_3068 = None
    unsqueeze_2225: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3069, 0);  mul_3069 = None
    unsqueeze_2226: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2225, 2);  unsqueeze_2225 = None
    unsqueeze_2227: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2226, 3);  unsqueeze_2226 = None
    mul_3070: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_751, primals_752);  primals_752 = None
    unsqueeze_2228: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3070, 0);  mul_3070 = None
    unsqueeze_2229: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2228, 2);  unsqueeze_2228 = None
    unsqueeze_2230: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2229, 3);  unsqueeze_2229 = None
    mul_3071: "f32[8, 72, 7, 7]" = torch.ops.aten.mul.Tensor(sub_621, unsqueeze_2227);  sub_621 = unsqueeze_2227 = None
    sub_623: "f32[8, 72, 7, 7]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_6, mul_3071);  _unsafe_index_put_6 = mul_3071 = None
    sub_624: "f32[8, 72, 7, 7]" = torch.ops.aten.sub.Tensor(sub_623, unsqueeze_2224);  sub_623 = unsqueeze_2224 = None
    mul_3072: "f32[8, 72, 7, 7]" = torch.ops.aten.mul.Tensor(sub_624, unsqueeze_2230);  sub_624 = unsqueeze_2230 = None
    mul_3073: "f32[72]" = torch.ops.aten.mul.Tensor(sum_151, squeeze_751);  sum_151 = squeeze_751 = None
    convolution_backward_74 = torch.ops.aten.convolution_backward.default(mul_3072, relu_219, primals_751, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3072 = primals_751 = None
    getitem_872: "f32[8, 144, 7, 7]" = convolution_backward_74[0]
    getitem_873: "f32[72, 144, 1, 1]" = convolution_backward_74[1];  convolution_backward_74 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1958: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(where_56, getitem_872);  where_56 = getitem_872 = None
    add_1959: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(getitem_854, where_60);  getitem_854 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    sum_152: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_60, [0, 2, 3])
    sub_625: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_249, unsqueeze_2233);  convolution_249 = unsqueeze_2233 = None
    mul_3074: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_60, sub_625)
    sum_153: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3074, [0, 2, 3]);  mul_3074 = None
    mul_3075: "f32[72]" = torch.ops.aten.mul.Tensor(sum_152, 0.0006377551020408163)
    unsqueeze_2234: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3075, 0);  mul_3075 = None
    unsqueeze_2235: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2234, 2);  unsqueeze_2234 = None
    unsqueeze_2236: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2235, 3);  unsqueeze_2235 = None
    mul_3076: "f32[72]" = torch.ops.aten.mul.Tensor(sum_153, 0.0006377551020408163)
    mul_3077: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_748, squeeze_748)
    mul_3078: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3076, mul_3077);  mul_3076 = mul_3077 = None
    unsqueeze_2237: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3078, 0);  mul_3078 = None
    unsqueeze_2238: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2237, 2);  unsqueeze_2237 = None
    unsqueeze_2239: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2238, 3);  unsqueeze_2238 = None
    mul_3079: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_748, primals_749);  primals_749 = None
    unsqueeze_2240: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3079, 0);  mul_3079 = None
    unsqueeze_2241: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2240, 2);  unsqueeze_2240 = None
    unsqueeze_2242: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2241, 3);  unsqueeze_2241 = None
    mul_3080: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_625, unsqueeze_2239);  sub_625 = unsqueeze_2239 = None
    sub_627: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_60, mul_3080);  mul_3080 = None
    sub_628: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_627, unsqueeze_2236);  sub_627 = None
    mul_3081: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_628, unsqueeze_2242);  sub_628 = unsqueeze_2242 = None
    mul_3082: "f32[72]" = torch.ops.aten.mul.Tensor(sum_153, squeeze_748);  sum_153 = squeeze_748 = None
    convolution_backward_75 = torch.ops.aten.convolution_backward.default(mul_3081, relu_203, primals_748, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3081 = primals_748 = None
    getitem_875: "f32[8, 36, 28, 28]" = convolution_backward_75[0]
    getitem_876: "f32[72, 36, 3, 3]" = convolution_backward_75[1];  convolution_backward_75 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1960: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(getitem_860, getitem_875);  getitem_860 = getitem_875 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sub_629: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_248, unsqueeze_2245);  convolution_248 = unsqueeze_2245 = None
    mul_3083: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_60, sub_629)
    sum_155: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3083, [0, 2, 3]);  mul_3083 = None
    mul_3085: "f32[72]" = torch.ops.aten.mul.Tensor(sum_155, 0.0006377551020408163)
    mul_3086: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_745, squeeze_745)
    mul_3087: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3085, mul_3086);  mul_3085 = mul_3086 = None
    unsqueeze_2249: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3087, 0);  mul_3087 = None
    unsqueeze_2250: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2249, 2);  unsqueeze_2249 = None
    unsqueeze_2251: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2250, 3);  unsqueeze_2250 = None
    mul_3088: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_745, primals_746);  primals_746 = None
    unsqueeze_2252: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3088, 0);  mul_3088 = None
    unsqueeze_2253: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2252, 2);  unsqueeze_2252 = None
    unsqueeze_2254: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2253, 3);  unsqueeze_2253 = None
    mul_3089: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_629, unsqueeze_2251);  sub_629 = unsqueeze_2251 = None
    sub_631: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_60, mul_3089);  where_60 = mul_3089 = None
    sub_632: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_631, unsqueeze_2236);  sub_631 = unsqueeze_2236 = None
    mul_3090: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_632, unsqueeze_2254);  sub_632 = unsqueeze_2254 = None
    mul_3091: "f32[72]" = torch.ops.aten.mul.Tensor(sum_155, squeeze_745);  sum_155 = squeeze_745 = None
    convolution_backward_76 = torch.ops.aten.convolution_backward.default(mul_3090, relu_222, primals_745, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3090 = primals_745 = None
    getitem_878: "f32[8, 18, 28, 28]" = convolution_backward_76[0]
    getitem_879: "f32[72, 18, 3, 3]" = convolution_backward_76[1];  convolution_backward_76 = None
    le_61: "b8[8, 18, 28, 28]" = torch.ops.aten.le.Scalar(relu_222, 0);  relu_222 = None
    where_61: "f32[8, 18, 28, 28]" = torch.ops.aten.where.self(le_61, full_default, getitem_878);  le_61 = getitem_878 = None
    sum_156: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_61, [0, 2, 3])
    sub_633: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_247, unsqueeze_2257);  convolution_247 = unsqueeze_2257 = None
    mul_3092: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(where_61, sub_633)
    sum_157: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3092, [0, 2, 3]);  mul_3092 = None
    mul_3093: "f32[18]" = torch.ops.aten.mul.Tensor(sum_156, 0.00015943877551020407)
    unsqueeze_2258: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3093, 0);  mul_3093 = None
    unsqueeze_2259: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2258, 2);  unsqueeze_2258 = None
    unsqueeze_2260: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2259, 3);  unsqueeze_2259 = None
    mul_3094: "f32[18]" = torch.ops.aten.mul.Tensor(sum_157, 0.00015943877551020407)
    mul_3095: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_742, squeeze_742)
    mul_3096: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3094, mul_3095);  mul_3094 = mul_3095 = None
    unsqueeze_2261: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3096, 0);  mul_3096 = None
    unsqueeze_2262: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2261, 2);  unsqueeze_2261 = None
    unsqueeze_2263: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2262, 3);  unsqueeze_2262 = None
    mul_3097: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_742, primals_743);  primals_743 = None
    unsqueeze_2264: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3097, 0);  mul_3097 = None
    unsqueeze_2265: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2264, 2);  unsqueeze_2264 = None
    unsqueeze_2266: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2265, 3);  unsqueeze_2265 = None
    mul_3098: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_633, unsqueeze_2263);  sub_633 = unsqueeze_2263 = None
    sub_635: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(where_61, mul_3098);  where_61 = mul_3098 = None
    sub_636: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_635, unsqueeze_2260);  sub_635 = unsqueeze_2260 = None
    mul_3099: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_636, unsqueeze_2266);  sub_636 = unsqueeze_2266 = None
    mul_3100: "f32[18]" = torch.ops.aten.mul.Tensor(sum_157, squeeze_742);  sum_157 = squeeze_742 = None
    convolution_backward_77 = torch.ops.aten.convolution_backward.default(mul_3099, relu_195, primals_742, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3099 = primals_742 = None
    getitem_881: "f32[8, 18, 56, 56]" = convolution_backward_77[0]
    getitem_882: "f32[18, 18, 3, 3]" = convolution_backward_77[1];  convolution_backward_77 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    add_1961: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(getitem_869, getitem_881);  getitem_869 = getitem_881 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_62: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_221, 0);  relu_221 = None
    where_62: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_62, full_default, add_1953);  le_62 = add_1953 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_7: "f32[8, 36, 7, 7]" = torch.ops.aten._unsafe_index_put.default(full_default_24, [None, None, unsqueeze_813, convert_element_type_104], where_62, True)
    sum_158: "f32[36]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_7, [0, 2, 3])
    sub_637: "f32[8, 36, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_246, unsqueeze_2269);  convolution_246 = unsqueeze_2269 = None
    mul_3101: "f32[8, 36, 7, 7]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_7, sub_637)
    sum_159: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3101, [0, 2, 3]);  mul_3101 = None
    mul_3102: "f32[36]" = torch.ops.aten.mul.Tensor(sum_158, 0.002551020408163265)
    unsqueeze_2270: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3102, 0);  mul_3102 = None
    unsqueeze_2271: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2270, 2);  unsqueeze_2270 = None
    unsqueeze_2272: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2271, 3);  unsqueeze_2271 = None
    mul_3103: "f32[36]" = torch.ops.aten.mul.Tensor(sum_159, 0.002551020408163265)
    mul_3104: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_739, squeeze_739)
    mul_3105: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3103, mul_3104);  mul_3103 = mul_3104 = None
    unsqueeze_2273: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3105, 0);  mul_3105 = None
    unsqueeze_2274: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2273, 2);  unsqueeze_2273 = None
    unsqueeze_2275: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2274, 3);  unsqueeze_2274 = None
    mul_3106: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_739, primals_740);  primals_740 = None
    unsqueeze_2276: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3106, 0);  mul_3106 = None
    unsqueeze_2277: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2276, 2);  unsqueeze_2276 = None
    unsqueeze_2278: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2277, 3);  unsqueeze_2277 = None
    mul_3107: "f32[8, 36, 7, 7]" = torch.ops.aten.mul.Tensor(sub_637, unsqueeze_2275);  sub_637 = unsqueeze_2275 = None
    sub_639: "f32[8, 36, 7, 7]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_7, mul_3107);  _unsafe_index_put_7 = mul_3107 = None
    sub_640: "f32[8, 36, 7, 7]" = torch.ops.aten.sub.Tensor(sub_639, unsqueeze_2272);  sub_639 = unsqueeze_2272 = None
    mul_3108: "f32[8, 36, 7, 7]" = torch.ops.aten.mul.Tensor(sub_640, unsqueeze_2278);  sub_640 = unsqueeze_2278 = None
    mul_3109: "f32[36]" = torch.ops.aten.mul.Tensor(sum_159, squeeze_739);  sum_159 = squeeze_739 = None
    convolution_backward_78 = torch.ops.aten.convolution_backward.default(mul_3108, relu_219, primals_739, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3108 = primals_739 = None
    getitem_884: "f32[8, 144, 7, 7]" = convolution_backward_78[0]
    getitem_885: "f32[36, 144, 1, 1]" = convolution_backward_78[1];  convolution_backward_78 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1962: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(add_1958, getitem_884);  add_1958 = getitem_884 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_8: "f32[8, 36, 14, 14]" = torch.ops.aten._unsafe_index_put.default(full_default_25, [None, None, unsqueeze_259, convert_element_type_20], where_62, True)
    sum_160: "f32[36]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_8, [0, 2, 3])
    sub_641: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_245, unsqueeze_2281);  convolution_245 = unsqueeze_2281 = None
    mul_3110: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_8, sub_641)
    sum_161: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3110, [0, 2, 3]);  mul_3110 = None
    mul_3111: "f32[36]" = torch.ops.aten.mul.Tensor(sum_160, 0.0006377551020408163)
    unsqueeze_2282: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3111, 0);  mul_3111 = None
    unsqueeze_2283: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2282, 2);  unsqueeze_2282 = None
    unsqueeze_2284: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2283, 3);  unsqueeze_2283 = None
    mul_3112: "f32[36]" = torch.ops.aten.mul.Tensor(sum_161, 0.0006377551020408163)
    mul_3113: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_736, squeeze_736)
    mul_3114: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3112, mul_3113);  mul_3112 = mul_3113 = None
    unsqueeze_2285: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3114, 0);  mul_3114 = None
    unsqueeze_2286: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2285, 2);  unsqueeze_2285 = None
    unsqueeze_2287: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2286, 3);  unsqueeze_2286 = None
    mul_3115: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_736, primals_737);  primals_737 = None
    unsqueeze_2288: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3115, 0);  mul_3115 = None
    unsqueeze_2289: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2288, 2);  unsqueeze_2288 = None
    unsqueeze_2290: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2289, 3);  unsqueeze_2289 = None
    mul_3116: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_641, unsqueeze_2287);  sub_641 = unsqueeze_2287 = None
    sub_643: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_8, mul_3116);  _unsafe_index_put_8 = mul_3116 = None
    sub_644: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(sub_643, unsqueeze_2284);  sub_643 = unsqueeze_2284 = None
    mul_3117: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_644, unsqueeze_2290);  sub_644 = unsqueeze_2290 = None
    mul_3118: "f32[36]" = torch.ops.aten.mul.Tensor(sum_161, squeeze_736);  sum_161 = squeeze_736 = None
    convolution_backward_79 = torch.ops.aten.convolution_backward.default(mul_3117, relu_211, primals_736, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3117 = primals_736 = None
    getitem_887: "f32[8, 72, 14, 14]" = convolution_backward_79[0]
    getitem_888: "f32[36, 72, 1, 1]" = convolution_backward_79[1];  convolution_backward_79 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1963: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(add_1959, getitem_887);  add_1959 = getitem_887 = None
    add_1964: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(add_1960, where_62);  add_1960 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sum_162: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_62, [0, 2, 3])
    sub_645: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_244, unsqueeze_2293);  convolution_244 = unsqueeze_2293 = None
    mul_3119: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_62, sub_645)
    sum_163: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3119, [0, 2, 3]);  mul_3119 = None
    mul_3120: "f32[36]" = torch.ops.aten.mul.Tensor(sum_162, 0.00015943877551020407)
    unsqueeze_2294: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3120, 0);  mul_3120 = None
    unsqueeze_2295: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2294, 2);  unsqueeze_2294 = None
    unsqueeze_2296: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2295, 3);  unsqueeze_2295 = None
    mul_3121: "f32[36]" = torch.ops.aten.mul.Tensor(sum_163, 0.00015943877551020407)
    mul_3122: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_733, squeeze_733)
    mul_3123: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3121, mul_3122);  mul_3121 = mul_3122 = None
    unsqueeze_2297: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3123, 0);  mul_3123 = None
    unsqueeze_2298: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2297, 2);  unsqueeze_2297 = None
    unsqueeze_2299: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2298, 3);  unsqueeze_2298 = None
    mul_3124: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_733, primals_734);  primals_734 = None
    unsqueeze_2300: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3124, 0);  mul_3124 = None
    unsqueeze_2301: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2300, 2);  unsqueeze_2300 = None
    unsqueeze_2302: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2301, 3);  unsqueeze_2301 = None
    mul_3125: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_645, unsqueeze_2299);  sub_645 = unsqueeze_2299 = None
    sub_647: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_62, mul_3125);  where_62 = mul_3125 = None
    sub_648: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_647, unsqueeze_2296);  sub_647 = unsqueeze_2296 = None
    mul_3126: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_648, unsqueeze_2302);  sub_648 = unsqueeze_2302 = None
    mul_3127: "f32[36]" = torch.ops.aten.mul.Tensor(sum_163, squeeze_733);  sum_163 = squeeze_733 = None
    convolution_backward_80 = torch.ops.aten.convolution_backward.default(mul_3126, relu_195, primals_733, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3126 = primals_733 = None
    getitem_890: "f32[8, 18, 56, 56]" = convolution_backward_80[0]
    getitem_891: "f32[36, 18, 3, 3]" = convolution_backward_80[1];  convolution_backward_80 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    add_1965: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(add_1961, getitem_890);  add_1961 = getitem_890 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_63: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_220, 0);  relu_220 = None
    where_63: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_63, full_default, add_1957);  le_63 = add_1957 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_9: "f32[8, 18, 7, 7]" = torch.ops.aten._unsafe_index_put.default(full_default_27, [None, None, unsqueeze_799, convert_element_type_92], where_63, True)
    sum_164: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_9, [0, 2, 3])
    sub_649: "f32[8, 18, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_243, unsqueeze_2305);  convolution_243 = unsqueeze_2305 = None
    mul_3128: "f32[8, 18, 7, 7]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_9, sub_649)
    sum_165: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3128, [0, 2, 3]);  mul_3128 = None
    mul_3129: "f32[18]" = torch.ops.aten.mul.Tensor(sum_164, 0.002551020408163265)
    unsqueeze_2306: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3129, 0);  mul_3129 = None
    unsqueeze_2307: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2306, 2);  unsqueeze_2306 = None
    unsqueeze_2308: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2307, 3);  unsqueeze_2307 = None
    mul_3130: "f32[18]" = torch.ops.aten.mul.Tensor(sum_165, 0.002551020408163265)
    mul_3131: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_730, squeeze_730)
    mul_3132: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3130, mul_3131);  mul_3130 = mul_3131 = None
    unsqueeze_2309: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3132, 0);  mul_3132 = None
    unsqueeze_2310: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2309, 2);  unsqueeze_2309 = None
    unsqueeze_2311: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2310, 3);  unsqueeze_2310 = None
    mul_3133: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_730, primals_731);  primals_731 = None
    unsqueeze_2312: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3133, 0);  mul_3133 = None
    unsqueeze_2313: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2312, 2);  unsqueeze_2312 = None
    unsqueeze_2314: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2313, 3);  unsqueeze_2313 = None
    mul_3134: "f32[8, 18, 7, 7]" = torch.ops.aten.mul.Tensor(sub_649, unsqueeze_2311);  sub_649 = unsqueeze_2311 = None
    sub_651: "f32[8, 18, 7, 7]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_9, mul_3134);  _unsafe_index_put_9 = mul_3134 = None
    sub_652: "f32[8, 18, 7, 7]" = torch.ops.aten.sub.Tensor(sub_651, unsqueeze_2308);  sub_651 = unsqueeze_2308 = None
    mul_3135: "f32[8, 18, 7, 7]" = torch.ops.aten.mul.Tensor(sub_652, unsqueeze_2314);  sub_652 = unsqueeze_2314 = None
    mul_3136: "f32[18]" = torch.ops.aten.mul.Tensor(sum_165, squeeze_730);  sum_165 = squeeze_730 = None
    convolution_backward_81 = torch.ops.aten.convolution_backward.default(mul_3135, relu_219, primals_730, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3135 = primals_730 = None
    getitem_893: "f32[8, 144, 7, 7]" = convolution_backward_81[0]
    getitem_894: "f32[18, 144, 1, 1]" = convolution_backward_81[1];  convolution_backward_81 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1966: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(add_1962, getitem_893);  add_1962 = getitem_893 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_10: "f32[8, 18, 14, 14]" = torch.ops.aten._unsafe_index_put.default(full_default_28, [None, None, unsqueeze_250, convert_element_type_14], where_63, True)
    sum_166: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_10, [0, 2, 3])
    sub_653: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_242, unsqueeze_2317);  convolution_242 = unsqueeze_2317 = None
    mul_3137: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_10, sub_653)
    sum_167: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3137, [0, 2, 3]);  mul_3137 = None
    mul_3138: "f32[18]" = torch.ops.aten.mul.Tensor(sum_166, 0.0006377551020408163)
    unsqueeze_2318: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3138, 0);  mul_3138 = None
    unsqueeze_2319: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2318, 2);  unsqueeze_2318 = None
    unsqueeze_2320: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2319, 3);  unsqueeze_2319 = None
    mul_3139: "f32[18]" = torch.ops.aten.mul.Tensor(sum_167, 0.0006377551020408163)
    mul_3140: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_727, squeeze_727)
    mul_3141: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3139, mul_3140);  mul_3139 = mul_3140 = None
    unsqueeze_2321: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3141, 0);  mul_3141 = None
    unsqueeze_2322: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2321, 2);  unsqueeze_2321 = None
    unsqueeze_2323: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2322, 3);  unsqueeze_2322 = None
    mul_3142: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_727, primals_728);  primals_728 = None
    unsqueeze_2324: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3142, 0);  mul_3142 = None
    unsqueeze_2325: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2324, 2);  unsqueeze_2324 = None
    unsqueeze_2326: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2325, 3);  unsqueeze_2325 = None
    mul_3143: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_653, unsqueeze_2323);  sub_653 = unsqueeze_2323 = None
    sub_655: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_10, mul_3143);  _unsafe_index_put_10 = mul_3143 = None
    sub_656: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(sub_655, unsqueeze_2320);  sub_655 = unsqueeze_2320 = None
    mul_3144: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_656, unsqueeze_2326);  sub_656 = unsqueeze_2326 = None
    mul_3145: "f32[18]" = torch.ops.aten.mul.Tensor(sum_167, squeeze_727);  sum_167 = squeeze_727 = None
    convolution_backward_82 = torch.ops.aten.convolution_backward.default(mul_3144, relu_211, primals_727, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3144 = primals_727 = None
    getitem_896: "f32[8, 72, 14, 14]" = convolution_backward_82[0]
    getitem_897: "f32[18, 72, 1, 1]" = convolution_backward_82[1];  convolution_backward_82 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1967: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(add_1963, getitem_896);  add_1963 = getitem_896 = None
    add_1968: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(add_1965, where_63);  add_1965 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_11: "f32[8, 18, 28, 28]" = torch.ops.aten._unsafe_index_put.default(full_default_29, [None, None, unsqueeze_136, convert_element_type_2], where_63, True);  where_63 = None
    sum_168: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_11, [0, 2, 3])
    sub_657: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_241, unsqueeze_2329);  convolution_241 = unsqueeze_2329 = None
    mul_3146: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_11, sub_657)
    sum_169: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3146, [0, 2, 3]);  mul_3146 = None
    mul_3147: "f32[18]" = torch.ops.aten.mul.Tensor(sum_168, 0.00015943877551020407)
    unsqueeze_2330: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3147, 0);  mul_3147 = None
    unsqueeze_2331: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2330, 2);  unsqueeze_2330 = None
    unsqueeze_2332: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2331, 3);  unsqueeze_2331 = None
    mul_3148: "f32[18]" = torch.ops.aten.mul.Tensor(sum_169, 0.00015943877551020407)
    mul_3149: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_724, squeeze_724)
    mul_3150: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3148, mul_3149);  mul_3148 = mul_3149 = None
    unsqueeze_2333: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3150, 0);  mul_3150 = None
    unsqueeze_2334: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2333, 2);  unsqueeze_2333 = None
    unsqueeze_2335: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2334, 3);  unsqueeze_2334 = None
    mul_3151: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_724, primals_725);  primals_725 = None
    unsqueeze_2336: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3151, 0);  mul_3151 = None
    unsqueeze_2337: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2336, 2);  unsqueeze_2336 = None
    unsqueeze_2338: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2337, 3);  unsqueeze_2337 = None
    mul_3152: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_657, unsqueeze_2335);  sub_657 = unsqueeze_2335 = None
    sub_659: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_11, mul_3152);  _unsafe_index_put_11 = mul_3152 = None
    sub_660: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_659, unsqueeze_2332);  sub_659 = unsqueeze_2332 = None
    mul_3153: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_660, unsqueeze_2338);  sub_660 = unsqueeze_2338 = None
    mul_3154: "f32[18]" = torch.ops.aten.mul.Tensor(sum_169, squeeze_724);  sum_169 = squeeze_724 = None
    convolution_backward_83 = torch.ops.aten.convolution_backward.default(mul_3153, relu_203, primals_724, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3153 = primals_724 = None
    getitem_899: "f32[8, 36, 28, 28]" = convolution_backward_83[0]
    getitem_900: "f32[18, 36, 1, 1]" = convolution_backward_83[1];  convolution_backward_83 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1969: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(add_1964, getitem_899);  add_1964 = getitem_899 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_64: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_219, 0);  relu_219 = None
    where_64: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_64, full_default, add_1966);  le_64 = add_1966 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_170: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_64, [0, 2, 3])
    sub_661: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_240, unsqueeze_2341);  convolution_240 = unsqueeze_2341 = None
    mul_3155: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_64, sub_661)
    sum_171: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3155, [0, 2, 3]);  mul_3155 = None
    mul_3156: "f32[144]" = torch.ops.aten.mul.Tensor(sum_170, 0.002551020408163265)
    unsqueeze_2342: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3156, 0);  mul_3156 = None
    unsqueeze_2343: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2342, 2);  unsqueeze_2342 = None
    unsqueeze_2344: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2343, 3);  unsqueeze_2343 = None
    mul_3157: "f32[144]" = torch.ops.aten.mul.Tensor(sum_171, 0.002551020408163265)
    mul_3158: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_721, squeeze_721)
    mul_3159: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3157, mul_3158);  mul_3157 = mul_3158 = None
    unsqueeze_2345: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3159, 0);  mul_3159 = None
    unsqueeze_2346: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2345, 2);  unsqueeze_2345 = None
    unsqueeze_2347: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2346, 3);  unsqueeze_2346 = None
    mul_3160: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_721, primals_722);  primals_722 = None
    unsqueeze_2348: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3160, 0);  mul_3160 = None
    unsqueeze_2349: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2348, 2);  unsqueeze_2348 = None
    unsqueeze_2350: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2349, 3);  unsqueeze_2349 = None
    mul_3161: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_661, unsqueeze_2347);  sub_661 = unsqueeze_2347 = None
    sub_663: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_64, mul_3161);  mul_3161 = None
    sub_664: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_663, unsqueeze_2344);  sub_663 = unsqueeze_2344 = None
    mul_3162: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_664, unsqueeze_2350);  sub_664 = unsqueeze_2350 = None
    mul_3163: "f32[144]" = torch.ops.aten.mul.Tensor(sum_171, squeeze_721);  sum_171 = squeeze_721 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_84 = torch.ops.aten.convolution_backward.default(mul_3162, relu_218, primals_721, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3162 = primals_721 = None
    getitem_902: "f32[8, 144, 7, 7]" = convolution_backward_84[0]
    getitem_903: "f32[144, 144, 3, 3]" = convolution_backward_84[1];  convolution_backward_84 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_65: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_218, 0);  relu_218 = None
    where_65: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_65, full_default, getitem_902);  le_65 = getitem_902 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_172: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_65, [0, 2, 3])
    sub_665: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_239, unsqueeze_2353);  convolution_239 = unsqueeze_2353 = None
    mul_3164: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_65, sub_665)
    sum_173: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3164, [0, 2, 3]);  mul_3164 = None
    mul_3165: "f32[144]" = torch.ops.aten.mul.Tensor(sum_172, 0.002551020408163265)
    unsqueeze_2354: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3165, 0);  mul_3165 = None
    unsqueeze_2355: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2354, 2);  unsqueeze_2354 = None
    unsqueeze_2356: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2355, 3);  unsqueeze_2355 = None
    mul_3166: "f32[144]" = torch.ops.aten.mul.Tensor(sum_173, 0.002551020408163265)
    mul_3167: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_718, squeeze_718)
    mul_3168: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3166, mul_3167);  mul_3166 = mul_3167 = None
    unsqueeze_2357: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3168, 0);  mul_3168 = None
    unsqueeze_2358: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2357, 2);  unsqueeze_2357 = None
    unsqueeze_2359: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2358, 3);  unsqueeze_2358 = None
    mul_3169: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_718, primals_719);  primals_719 = None
    unsqueeze_2360: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3169, 0);  mul_3169 = None
    unsqueeze_2361: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2360, 2);  unsqueeze_2360 = None
    unsqueeze_2362: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2361, 3);  unsqueeze_2361 = None
    mul_3170: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_665, unsqueeze_2359);  sub_665 = unsqueeze_2359 = None
    sub_667: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_65, mul_3170);  where_65 = mul_3170 = None
    sub_668: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_667, unsqueeze_2356);  sub_667 = unsqueeze_2356 = None
    mul_3171: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_668, unsqueeze_2362);  sub_668 = unsqueeze_2362 = None
    mul_3172: "f32[144]" = torch.ops.aten.mul.Tensor(sum_173, squeeze_718);  sum_173 = squeeze_718 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_85 = torch.ops.aten.convolution_backward.default(mul_3171, relu_217, primals_718, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3171 = primals_718 = None
    getitem_905: "f32[8, 144, 7, 7]" = convolution_backward_85[0]
    getitem_906: "f32[144, 144, 3, 3]" = convolution_backward_85[1];  convolution_backward_85 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1970: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(where_64, getitem_905);  where_64 = getitem_905 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_66: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_217, 0);  relu_217 = None
    where_66: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_66, full_default, add_1970);  le_66 = add_1970 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_174: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_66, [0, 2, 3])
    sub_669: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_238, unsqueeze_2365);  convolution_238 = unsqueeze_2365 = None
    mul_3173: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_66, sub_669)
    sum_175: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3173, [0, 2, 3]);  mul_3173 = None
    mul_3174: "f32[144]" = torch.ops.aten.mul.Tensor(sum_174, 0.002551020408163265)
    unsqueeze_2366: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3174, 0);  mul_3174 = None
    unsqueeze_2367: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2366, 2);  unsqueeze_2366 = None
    unsqueeze_2368: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2367, 3);  unsqueeze_2367 = None
    mul_3175: "f32[144]" = torch.ops.aten.mul.Tensor(sum_175, 0.002551020408163265)
    mul_3176: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_715, squeeze_715)
    mul_3177: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3175, mul_3176);  mul_3175 = mul_3176 = None
    unsqueeze_2369: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3177, 0);  mul_3177 = None
    unsqueeze_2370: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2369, 2);  unsqueeze_2369 = None
    unsqueeze_2371: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2370, 3);  unsqueeze_2370 = None
    mul_3178: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_715, primals_716);  primals_716 = None
    unsqueeze_2372: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3178, 0);  mul_3178 = None
    unsqueeze_2373: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2372, 2);  unsqueeze_2372 = None
    unsqueeze_2374: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2373, 3);  unsqueeze_2373 = None
    mul_3179: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_669, unsqueeze_2371);  sub_669 = unsqueeze_2371 = None
    sub_671: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_66, mul_3179);  mul_3179 = None
    sub_672: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_671, unsqueeze_2368);  sub_671 = unsqueeze_2368 = None
    mul_3180: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_672, unsqueeze_2374);  sub_672 = unsqueeze_2374 = None
    mul_3181: "f32[144]" = torch.ops.aten.mul.Tensor(sum_175, squeeze_715);  sum_175 = squeeze_715 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_86 = torch.ops.aten.convolution_backward.default(mul_3180, relu_216, primals_715, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3180 = primals_715 = None
    getitem_908: "f32[8, 144, 7, 7]" = convolution_backward_86[0]
    getitem_909: "f32[144, 144, 3, 3]" = convolution_backward_86[1];  convolution_backward_86 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_67: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_216, 0);  relu_216 = None
    where_67: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_67, full_default, getitem_908);  le_67 = getitem_908 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_176: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_67, [0, 2, 3])
    sub_673: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_237, unsqueeze_2377);  convolution_237 = unsqueeze_2377 = None
    mul_3182: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_67, sub_673)
    sum_177: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3182, [0, 2, 3]);  mul_3182 = None
    mul_3183: "f32[144]" = torch.ops.aten.mul.Tensor(sum_176, 0.002551020408163265)
    unsqueeze_2378: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3183, 0);  mul_3183 = None
    unsqueeze_2379: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2378, 2);  unsqueeze_2378 = None
    unsqueeze_2380: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2379, 3);  unsqueeze_2379 = None
    mul_3184: "f32[144]" = torch.ops.aten.mul.Tensor(sum_177, 0.002551020408163265)
    mul_3185: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_712, squeeze_712)
    mul_3186: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3184, mul_3185);  mul_3184 = mul_3185 = None
    unsqueeze_2381: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3186, 0);  mul_3186 = None
    unsqueeze_2382: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2381, 2);  unsqueeze_2381 = None
    unsqueeze_2383: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2382, 3);  unsqueeze_2382 = None
    mul_3187: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_712, primals_713);  primals_713 = None
    unsqueeze_2384: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3187, 0);  mul_3187 = None
    unsqueeze_2385: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2384, 2);  unsqueeze_2384 = None
    unsqueeze_2386: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2385, 3);  unsqueeze_2385 = None
    mul_3188: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_673, unsqueeze_2383);  sub_673 = unsqueeze_2383 = None
    sub_675: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_67, mul_3188);  where_67 = mul_3188 = None
    sub_676: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_675, unsqueeze_2380);  sub_675 = unsqueeze_2380 = None
    mul_3189: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_676, unsqueeze_2386);  sub_676 = unsqueeze_2386 = None
    mul_3190: "f32[144]" = torch.ops.aten.mul.Tensor(sum_177, squeeze_712);  sum_177 = squeeze_712 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_87 = torch.ops.aten.convolution_backward.default(mul_3189, relu_215, primals_712, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3189 = primals_712 = None
    getitem_911: "f32[8, 144, 7, 7]" = convolution_backward_87[0]
    getitem_912: "f32[144, 144, 3, 3]" = convolution_backward_87[1];  convolution_backward_87 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1971: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(where_66, getitem_911);  where_66 = getitem_911 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_68: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_215, 0);  relu_215 = None
    where_68: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_68, full_default, add_1971);  le_68 = add_1971 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_178: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_68, [0, 2, 3])
    sub_677: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_236, unsqueeze_2389);  convolution_236 = unsqueeze_2389 = None
    mul_3191: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_68, sub_677)
    sum_179: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3191, [0, 2, 3]);  mul_3191 = None
    mul_3192: "f32[144]" = torch.ops.aten.mul.Tensor(sum_178, 0.002551020408163265)
    unsqueeze_2390: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3192, 0);  mul_3192 = None
    unsqueeze_2391: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2390, 2);  unsqueeze_2390 = None
    unsqueeze_2392: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2391, 3);  unsqueeze_2391 = None
    mul_3193: "f32[144]" = torch.ops.aten.mul.Tensor(sum_179, 0.002551020408163265)
    mul_3194: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_709, squeeze_709)
    mul_3195: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3193, mul_3194);  mul_3193 = mul_3194 = None
    unsqueeze_2393: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3195, 0);  mul_3195 = None
    unsqueeze_2394: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2393, 2);  unsqueeze_2393 = None
    unsqueeze_2395: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2394, 3);  unsqueeze_2394 = None
    mul_3196: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_709, primals_710);  primals_710 = None
    unsqueeze_2396: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3196, 0);  mul_3196 = None
    unsqueeze_2397: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2396, 2);  unsqueeze_2396 = None
    unsqueeze_2398: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2397, 3);  unsqueeze_2397 = None
    mul_3197: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_677, unsqueeze_2395);  sub_677 = unsqueeze_2395 = None
    sub_679: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_68, mul_3197);  mul_3197 = None
    sub_680: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_679, unsqueeze_2392);  sub_679 = unsqueeze_2392 = None
    mul_3198: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_680, unsqueeze_2398);  sub_680 = unsqueeze_2398 = None
    mul_3199: "f32[144]" = torch.ops.aten.mul.Tensor(sum_179, squeeze_709);  sum_179 = squeeze_709 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_88 = torch.ops.aten.convolution_backward.default(mul_3198, relu_214, primals_709, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3198 = primals_709 = None
    getitem_914: "f32[8, 144, 7, 7]" = convolution_backward_88[0]
    getitem_915: "f32[144, 144, 3, 3]" = convolution_backward_88[1];  convolution_backward_88 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_69: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_214, 0);  relu_214 = None
    where_69: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_69, full_default, getitem_914);  le_69 = getitem_914 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_180: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_69, [0, 2, 3])
    sub_681: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_235, unsqueeze_2401);  convolution_235 = unsqueeze_2401 = None
    mul_3200: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_69, sub_681)
    sum_181: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3200, [0, 2, 3]);  mul_3200 = None
    mul_3201: "f32[144]" = torch.ops.aten.mul.Tensor(sum_180, 0.002551020408163265)
    unsqueeze_2402: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3201, 0);  mul_3201 = None
    unsqueeze_2403: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2402, 2);  unsqueeze_2402 = None
    unsqueeze_2404: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2403, 3);  unsqueeze_2403 = None
    mul_3202: "f32[144]" = torch.ops.aten.mul.Tensor(sum_181, 0.002551020408163265)
    mul_3203: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_706, squeeze_706)
    mul_3204: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3202, mul_3203);  mul_3202 = mul_3203 = None
    unsqueeze_2405: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3204, 0);  mul_3204 = None
    unsqueeze_2406: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2405, 2);  unsqueeze_2405 = None
    unsqueeze_2407: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2406, 3);  unsqueeze_2406 = None
    mul_3205: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_706, primals_707);  primals_707 = None
    unsqueeze_2408: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3205, 0);  mul_3205 = None
    unsqueeze_2409: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2408, 2);  unsqueeze_2408 = None
    unsqueeze_2410: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2409, 3);  unsqueeze_2409 = None
    mul_3206: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_681, unsqueeze_2407);  sub_681 = unsqueeze_2407 = None
    sub_683: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_69, mul_3206);  where_69 = mul_3206 = None
    sub_684: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_683, unsqueeze_2404);  sub_683 = unsqueeze_2404 = None
    mul_3207: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_684, unsqueeze_2410);  sub_684 = unsqueeze_2410 = None
    mul_3208: "f32[144]" = torch.ops.aten.mul.Tensor(sum_181, squeeze_706);  sum_181 = squeeze_706 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_89 = torch.ops.aten.convolution_backward.default(mul_3207, relu_213, primals_706, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3207 = primals_706 = None
    getitem_917: "f32[8, 144, 7, 7]" = convolution_backward_89[0]
    getitem_918: "f32[144, 144, 3, 3]" = convolution_backward_89[1];  convolution_backward_89 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1972: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(where_68, getitem_917);  where_68 = getitem_917 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_70: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_213, 0);  relu_213 = None
    where_70: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_70, full_default, add_1972);  le_70 = add_1972 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_182: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_70, [0, 2, 3])
    sub_685: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_234, unsqueeze_2413);  convolution_234 = unsqueeze_2413 = None
    mul_3209: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_70, sub_685)
    sum_183: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3209, [0, 2, 3]);  mul_3209 = None
    mul_3210: "f32[144]" = torch.ops.aten.mul.Tensor(sum_182, 0.002551020408163265)
    unsqueeze_2414: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3210, 0);  mul_3210 = None
    unsqueeze_2415: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2414, 2);  unsqueeze_2414 = None
    unsqueeze_2416: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2415, 3);  unsqueeze_2415 = None
    mul_3211: "f32[144]" = torch.ops.aten.mul.Tensor(sum_183, 0.002551020408163265)
    mul_3212: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_703, squeeze_703)
    mul_3213: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3211, mul_3212);  mul_3211 = mul_3212 = None
    unsqueeze_2417: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3213, 0);  mul_3213 = None
    unsqueeze_2418: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2417, 2);  unsqueeze_2417 = None
    unsqueeze_2419: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2418, 3);  unsqueeze_2418 = None
    mul_3214: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_703, primals_704);  primals_704 = None
    unsqueeze_2420: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3214, 0);  mul_3214 = None
    unsqueeze_2421: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2420, 2);  unsqueeze_2420 = None
    unsqueeze_2422: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2421, 3);  unsqueeze_2421 = None
    mul_3215: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_685, unsqueeze_2419);  sub_685 = unsqueeze_2419 = None
    sub_687: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_70, mul_3215);  mul_3215 = None
    sub_688: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_687, unsqueeze_2416);  sub_687 = unsqueeze_2416 = None
    mul_3216: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_688, unsqueeze_2422);  sub_688 = unsqueeze_2422 = None
    mul_3217: "f32[144]" = torch.ops.aten.mul.Tensor(sum_183, squeeze_703);  sum_183 = squeeze_703 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_90 = torch.ops.aten.convolution_backward.default(mul_3216, relu_212, primals_703, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3216 = primals_703 = None
    getitem_920: "f32[8, 144, 7, 7]" = convolution_backward_90[0]
    getitem_921: "f32[144, 144, 3, 3]" = convolution_backward_90[1];  convolution_backward_90 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_71: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_212, 0);  relu_212 = None
    where_71: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_71, full_default, getitem_920);  le_71 = getitem_920 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_184: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_71, [0, 2, 3])
    sub_689: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_233, unsqueeze_2425);  convolution_233 = unsqueeze_2425 = None
    mul_3218: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_71, sub_689)
    sum_185: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3218, [0, 2, 3]);  mul_3218 = None
    mul_3219: "f32[144]" = torch.ops.aten.mul.Tensor(sum_184, 0.002551020408163265)
    unsqueeze_2426: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3219, 0);  mul_3219 = None
    unsqueeze_2427: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2426, 2);  unsqueeze_2426 = None
    unsqueeze_2428: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2427, 3);  unsqueeze_2427 = None
    mul_3220: "f32[144]" = torch.ops.aten.mul.Tensor(sum_185, 0.002551020408163265)
    mul_3221: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_700, squeeze_700)
    mul_3222: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3220, mul_3221);  mul_3220 = mul_3221 = None
    unsqueeze_2429: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3222, 0);  mul_3222 = None
    unsqueeze_2430: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2429, 2);  unsqueeze_2429 = None
    unsqueeze_2431: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2430, 3);  unsqueeze_2430 = None
    mul_3223: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_700, primals_701);  primals_701 = None
    unsqueeze_2432: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3223, 0);  mul_3223 = None
    unsqueeze_2433: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2432, 2);  unsqueeze_2432 = None
    unsqueeze_2434: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2433, 3);  unsqueeze_2433 = None
    mul_3224: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_689, unsqueeze_2431);  sub_689 = unsqueeze_2431 = None
    sub_691: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_71, mul_3224);  where_71 = mul_3224 = None
    sub_692: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_691, unsqueeze_2428);  sub_691 = unsqueeze_2428 = None
    mul_3225: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_692, unsqueeze_2434);  sub_692 = unsqueeze_2434 = None
    mul_3226: "f32[144]" = torch.ops.aten.mul.Tensor(sum_185, squeeze_700);  sum_185 = squeeze_700 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_91 = torch.ops.aten.convolution_backward.default(mul_3225, relu_187, primals_700, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3225 = primals_700 = None
    getitem_923: "f32[8, 144, 7, 7]" = convolution_backward_91[0]
    getitem_924: "f32[144, 144, 3, 3]" = convolution_backward_91[1];  convolution_backward_91 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1973: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(where_70, getitem_923);  where_70 = getitem_923 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_72: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_211, 0);  relu_211 = None
    where_72: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_72, full_default, add_1967);  le_72 = add_1967 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_186: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_72, [0, 2, 3])
    sub_693: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_232, unsqueeze_2437);  convolution_232 = unsqueeze_2437 = None
    mul_3227: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_72, sub_693)
    sum_187: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3227, [0, 2, 3]);  mul_3227 = None
    mul_3228: "f32[72]" = torch.ops.aten.mul.Tensor(sum_186, 0.0006377551020408163)
    unsqueeze_2438: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3228, 0);  mul_3228 = None
    unsqueeze_2439: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2438, 2);  unsqueeze_2438 = None
    unsqueeze_2440: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2439, 3);  unsqueeze_2439 = None
    mul_3229: "f32[72]" = torch.ops.aten.mul.Tensor(sum_187, 0.0006377551020408163)
    mul_3230: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_697, squeeze_697)
    mul_3231: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3229, mul_3230);  mul_3229 = mul_3230 = None
    unsqueeze_2441: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3231, 0);  mul_3231 = None
    unsqueeze_2442: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2441, 2);  unsqueeze_2441 = None
    unsqueeze_2443: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2442, 3);  unsqueeze_2442 = None
    mul_3232: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_697, primals_698);  primals_698 = None
    unsqueeze_2444: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3232, 0);  mul_3232 = None
    unsqueeze_2445: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2444, 2);  unsqueeze_2444 = None
    unsqueeze_2446: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2445, 3);  unsqueeze_2445 = None
    mul_3233: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_693, unsqueeze_2443);  sub_693 = unsqueeze_2443 = None
    sub_695: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_72, mul_3233);  mul_3233 = None
    sub_696: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_695, unsqueeze_2440);  sub_695 = unsqueeze_2440 = None
    mul_3234: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_696, unsqueeze_2446);  sub_696 = unsqueeze_2446 = None
    mul_3235: "f32[72]" = torch.ops.aten.mul.Tensor(sum_187, squeeze_697);  sum_187 = squeeze_697 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_92 = torch.ops.aten.convolution_backward.default(mul_3234, relu_210, primals_697, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3234 = primals_697 = None
    getitem_926: "f32[8, 72, 14, 14]" = convolution_backward_92[0]
    getitem_927: "f32[72, 72, 3, 3]" = convolution_backward_92[1];  convolution_backward_92 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_73: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_210, 0);  relu_210 = None
    where_73: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_73, full_default, getitem_926);  le_73 = getitem_926 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_188: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_73, [0, 2, 3])
    sub_697: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_231, unsqueeze_2449);  convolution_231 = unsqueeze_2449 = None
    mul_3236: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_73, sub_697)
    sum_189: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3236, [0, 2, 3]);  mul_3236 = None
    mul_3237: "f32[72]" = torch.ops.aten.mul.Tensor(sum_188, 0.0006377551020408163)
    unsqueeze_2450: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3237, 0);  mul_3237 = None
    unsqueeze_2451: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2450, 2);  unsqueeze_2450 = None
    unsqueeze_2452: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2451, 3);  unsqueeze_2451 = None
    mul_3238: "f32[72]" = torch.ops.aten.mul.Tensor(sum_189, 0.0006377551020408163)
    mul_3239: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_694, squeeze_694)
    mul_3240: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3238, mul_3239);  mul_3238 = mul_3239 = None
    unsqueeze_2453: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3240, 0);  mul_3240 = None
    unsqueeze_2454: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2453, 2);  unsqueeze_2453 = None
    unsqueeze_2455: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2454, 3);  unsqueeze_2454 = None
    mul_3241: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_694, primals_695);  primals_695 = None
    unsqueeze_2456: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3241, 0);  mul_3241 = None
    unsqueeze_2457: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2456, 2);  unsqueeze_2456 = None
    unsqueeze_2458: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2457, 3);  unsqueeze_2457 = None
    mul_3242: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_697, unsqueeze_2455);  sub_697 = unsqueeze_2455 = None
    sub_699: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_73, mul_3242);  where_73 = mul_3242 = None
    sub_700: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_699, unsqueeze_2452);  sub_699 = unsqueeze_2452 = None
    mul_3243: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_700, unsqueeze_2458);  sub_700 = unsqueeze_2458 = None
    mul_3244: "f32[72]" = torch.ops.aten.mul.Tensor(sum_189, squeeze_694);  sum_189 = squeeze_694 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_93 = torch.ops.aten.convolution_backward.default(mul_3243, relu_209, primals_694, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3243 = primals_694 = None
    getitem_929: "f32[8, 72, 14, 14]" = convolution_backward_93[0]
    getitem_930: "f32[72, 72, 3, 3]" = convolution_backward_93[1];  convolution_backward_93 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1974: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_72, getitem_929);  where_72 = getitem_929 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_74: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_209, 0);  relu_209 = None
    where_74: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_74, full_default, add_1974);  le_74 = add_1974 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_190: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_74, [0, 2, 3])
    sub_701: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_230, unsqueeze_2461);  convolution_230 = unsqueeze_2461 = None
    mul_3245: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_74, sub_701)
    sum_191: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3245, [0, 2, 3]);  mul_3245 = None
    mul_3246: "f32[72]" = torch.ops.aten.mul.Tensor(sum_190, 0.0006377551020408163)
    unsqueeze_2462: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3246, 0);  mul_3246 = None
    unsqueeze_2463: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2462, 2);  unsqueeze_2462 = None
    unsqueeze_2464: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2463, 3);  unsqueeze_2463 = None
    mul_3247: "f32[72]" = torch.ops.aten.mul.Tensor(sum_191, 0.0006377551020408163)
    mul_3248: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_691, squeeze_691)
    mul_3249: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3247, mul_3248);  mul_3247 = mul_3248 = None
    unsqueeze_2465: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3249, 0);  mul_3249 = None
    unsqueeze_2466: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2465, 2);  unsqueeze_2465 = None
    unsqueeze_2467: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2466, 3);  unsqueeze_2466 = None
    mul_3250: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_691, primals_692);  primals_692 = None
    unsqueeze_2468: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3250, 0);  mul_3250 = None
    unsqueeze_2469: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2468, 2);  unsqueeze_2468 = None
    unsqueeze_2470: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2469, 3);  unsqueeze_2469 = None
    mul_3251: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_701, unsqueeze_2467);  sub_701 = unsqueeze_2467 = None
    sub_703: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_74, mul_3251);  mul_3251 = None
    sub_704: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_703, unsqueeze_2464);  sub_703 = unsqueeze_2464 = None
    mul_3252: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_704, unsqueeze_2470);  sub_704 = unsqueeze_2470 = None
    mul_3253: "f32[72]" = torch.ops.aten.mul.Tensor(sum_191, squeeze_691);  sum_191 = squeeze_691 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_94 = torch.ops.aten.convolution_backward.default(mul_3252, relu_208, primals_691, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3252 = primals_691 = None
    getitem_932: "f32[8, 72, 14, 14]" = convolution_backward_94[0]
    getitem_933: "f32[72, 72, 3, 3]" = convolution_backward_94[1];  convolution_backward_94 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_75: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_208, 0);  relu_208 = None
    where_75: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_75, full_default, getitem_932);  le_75 = getitem_932 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_192: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_75, [0, 2, 3])
    sub_705: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_229, unsqueeze_2473);  convolution_229 = unsqueeze_2473 = None
    mul_3254: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_75, sub_705)
    sum_193: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3254, [0, 2, 3]);  mul_3254 = None
    mul_3255: "f32[72]" = torch.ops.aten.mul.Tensor(sum_192, 0.0006377551020408163)
    unsqueeze_2474: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3255, 0);  mul_3255 = None
    unsqueeze_2475: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2474, 2);  unsqueeze_2474 = None
    unsqueeze_2476: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2475, 3);  unsqueeze_2475 = None
    mul_3256: "f32[72]" = torch.ops.aten.mul.Tensor(sum_193, 0.0006377551020408163)
    mul_3257: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_688, squeeze_688)
    mul_3258: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3256, mul_3257);  mul_3256 = mul_3257 = None
    unsqueeze_2477: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3258, 0);  mul_3258 = None
    unsqueeze_2478: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2477, 2);  unsqueeze_2477 = None
    unsqueeze_2479: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2478, 3);  unsqueeze_2478 = None
    mul_3259: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_688, primals_689);  primals_689 = None
    unsqueeze_2480: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3259, 0);  mul_3259 = None
    unsqueeze_2481: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2480, 2);  unsqueeze_2480 = None
    unsqueeze_2482: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2481, 3);  unsqueeze_2481 = None
    mul_3260: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_705, unsqueeze_2479);  sub_705 = unsqueeze_2479 = None
    sub_707: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_75, mul_3260);  where_75 = mul_3260 = None
    sub_708: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_707, unsqueeze_2476);  sub_707 = unsqueeze_2476 = None
    mul_3261: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_708, unsqueeze_2482);  sub_708 = unsqueeze_2482 = None
    mul_3262: "f32[72]" = torch.ops.aten.mul.Tensor(sum_193, squeeze_688);  sum_193 = squeeze_688 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_95 = torch.ops.aten.convolution_backward.default(mul_3261, relu_207, primals_688, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3261 = primals_688 = None
    getitem_935: "f32[8, 72, 14, 14]" = convolution_backward_95[0]
    getitem_936: "f32[72, 72, 3, 3]" = convolution_backward_95[1];  convolution_backward_95 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1975: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_74, getitem_935);  where_74 = getitem_935 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_76: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_207, 0);  relu_207 = None
    where_76: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_76, full_default, add_1975);  le_76 = add_1975 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_194: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_76, [0, 2, 3])
    sub_709: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_228, unsqueeze_2485);  convolution_228 = unsqueeze_2485 = None
    mul_3263: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_76, sub_709)
    sum_195: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3263, [0, 2, 3]);  mul_3263 = None
    mul_3264: "f32[72]" = torch.ops.aten.mul.Tensor(sum_194, 0.0006377551020408163)
    unsqueeze_2486: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3264, 0);  mul_3264 = None
    unsqueeze_2487: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2486, 2);  unsqueeze_2486 = None
    unsqueeze_2488: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2487, 3);  unsqueeze_2487 = None
    mul_3265: "f32[72]" = torch.ops.aten.mul.Tensor(sum_195, 0.0006377551020408163)
    mul_3266: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_685, squeeze_685)
    mul_3267: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3265, mul_3266);  mul_3265 = mul_3266 = None
    unsqueeze_2489: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3267, 0);  mul_3267 = None
    unsqueeze_2490: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2489, 2);  unsqueeze_2489 = None
    unsqueeze_2491: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2490, 3);  unsqueeze_2490 = None
    mul_3268: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_685, primals_686);  primals_686 = None
    unsqueeze_2492: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3268, 0);  mul_3268 = None
    unsqueeze_2493: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2492, 2);  unsqueeze_2492 = None
    unsqueeze_2494: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2493, 3);  unsqueeze_2493 = None
    mul_3269: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_709, unsqueeze_2491);  sub_709 = unsqueeze_2491 = None
    sub_711: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_76, mul_3269);  mul_3269 = None
    sub_712: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_711, unsqueeze_2488);  sub_711 = unsqueeze_2488 = None
    mul_3270: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_712, unsqueeze_2494);  sub_712 = unsqueeze_2494 = None
    mul_3271: "f32[72]" = torch.ops.aten.mul.Tensor(sum_195, squeeze_685);  sum_195 = squeeze_685 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_96 = torch.ops.aten.convolution_backward.default(mul_3270, relu_206, primals_685, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3270 = primals_685 = None
    getitem_938: "f32[8, 72, 14, 14]" = convolution_backward_96[0]
    getitem_939: "f32[72, 72, 3, 3]" = convolution_backward_96[1];  convolution_backward_96 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_77: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_206, 0);  relu_206 = None
    where_77: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_77, full_default, getitem_938);  le_77 = getitem_938 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_196: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_77, [0, 2, 3])
    sub_713: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_227, unsqueeze_2497);  convolution_227 = unsqueeze_2497 = None
    mul_3272: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_77, sub_713)
    sum_197: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3272, [0, 2, 3]);  mul_3272 = None
    mul_3273: "f32[72]" = torch.ops.aten.mul.Tensor(sum_196, 0.0006377551020408163)
    unsqueeze_2498: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3273, 0);  mul_3273 = None
    unsqueeze_2499: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2498, 2);  unsqueeze_2498 = None
    unsqueeze_2500: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2499, 3);  unsqueeze_2499 = None
    mul_3274: "f32[72]" = torch.ops.aten.mul.Tensor(sum_197, 0.0006377551020408163)
    mul_3275: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_682, squeeze_682)
    mul_3276: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3274, mul_3275);  mul_3274 = mul_3275 = None
    unsqueeze_2501: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3276, 0);  mul_3276 = None
    unsqueeze_2502: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2501, 2);  unsqueeze_2501 = None
    unsqueeze_2503: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2502, 3);  unsqueeze_2502 = None
    mul_3277: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_682, primals_683);  primals_683 = None
    unsqueeze_2504: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3277, 0);  mul_3277 = None
    unsqueeze_2505: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2504, 2);  unsqueeze_2504 = None
    unsqueeze_2506: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2505, 3);  unsqueeze_2505 = None
    mul_3278: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_713, unsqueeze_2503);  sub_713 = unsqueeze_2503 = None
    sub_715: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_77, mul_3278);  where_77 = mul_3278 = None
    sub_716: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_715, unsqueeze_2500);  sub_715 = unsqueeze_2500 = None
    mul_3279: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_716, unsqueeze_2506);  sub_716 = unsqueeze_2506 = None
    mul_3280: "f32[72]" = torch.ops.aten.mul.Tensor(sum_197, squeeze_682);  sum_197 = squeeze_682 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_97 = torch.ops.aten.convolution_backward.default(mul_3279, relu_205, primals_682, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3279 = primals_682 = None
    getitem_941: "f32[8, 72, 14, 14]" = convolution_backward_97[0]
    getitem_942: "f32[72, 72, 3, 3]" = convolution_backward_97[1];  convolution_backward_97 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1976: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_76, getitem_941);  where_76 = getitem_941 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_78: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_205, 0);  relu_205 = None
    where_78: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_78, full_default, add_1976);  le_78 = add_1976 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_198: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_78, [0, 2, 3])
    sub_717: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_226, unsqueeze_2509);  convolution_226 = unsqueeze_2509 = None
    mul_3281: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_78, sub_717)
    sum_199: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3281, [0, 2, 3]);  mul_3281 = None
    mul_3282: "f32[72]" = torch.ops.aten.mul.Tensor(sum_198, 0.0006377551020408163)
    unsqueeze_2510: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3282, 0);  mul_3282 = None
    unsqueeze_2511: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2510, 2);  unsqueeze_2510 = None
    unsqueeze_2512: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2511, 3);  unsqueeze_2511 = None
    mul_3283: "f32[72]" = torch.ops.aten.mul.Tensor(sum_199, 0.0006377551020408163)
    mul_3284: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_679, squeeze_679)
    mul_3285: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3283, mul_3284);  mul_3283 = mul_3284 = None
    unsqueeze_2513: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3285, 0);  mul_3285 = None
    unsqueeze_2514: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2513, 2);  unsqueeze_2513 = None
    unsqueeze_2515: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2514, 3);  unsqueeze_2514 = None
    mul_3286: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_679, primals_680);  primals_680 = None
    unsqueeze_2516: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3286, 0);  mul_3286 = None
    unsqueeze_2517: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2516, 2);  unsqueeze_2516 = None
    unsqueeze_2518: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2517, 3);  unsqueeze_2517 = None
    mul_3287: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_717, unsqueeze_2515);  sub_717 = unsqueeze_2515 = None
    sub_719: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_78, mul_3287);  mul_3287 = None
    sub_720: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_719, unsqueeze_2512);  sub_719 = unsqueeze_2512 = None
    mul_3288: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_720, unsqueeze_2518);  sub_720 = unsqueeze_2518 = None
    mul_3289: "f32[72]" = torch.ops.aten.mul.Tensor(sum_199, squeeze_679);  sum_199 = squeeze_679 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_98 = torch.ops.aten.convolution_backward.default(mul_3288, relu_204, primals_679, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3288 = primals_679 = None
    getitem_944: "f32[8, 72, 14, 14]" = convolution_backward_98[0]
    getitem_945: "f32[72, 72, 3, 3]" = convolution_backward_98[1];  convolution_backward_98 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_79: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_204, 0);  relu_204 = None
    where_79: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_79, full_default, getitem_944);  le_79 = getitem_944 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_200: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_79, [0, 2, 3])
    sub_721: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_225, unsqueeze_2521);  convolution_225 = unsqueeze_2521 = None
    mul_3290: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_79, sub_721)
    sum_201: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3290, [0, 2, 3]);  mul_3290 = None
    mul_3291: "f32[72]" = torch.ops.aten.mul.Tensor(sum_200, 0.0006377551020408163)
    unsqueeze_2522: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3291, 0);  mul_3291 = None
    unsqueeze_2523: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2522, 2);  unsqueeze_2522 = None
    unsqueeze_2524: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2523, 3);  unsqueeze_2523 = None
    mul_3292: "f32[72]" = torch.ops.aten.mul.Tensor(sum_201, 0.0006377551020408163)
    mul_3293: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_676, squeeze_676)
    mul_3294: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3292, mul_3293);  mul_3292 = mul_3293 = None
    unsqueeze_2525: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3294, 0);  mul_3294 = None
    unsqueeze_2526: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2525, 2);  unsqueeze_2525 = None
    unsqueeze_2527: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2526, 3);  unsqueeze_2526 = None
    mul_3295: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_676, primals_677);  primals_677 = None
    unsqueeze_2528: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3295, 0);  mul_3295 = None
    unsqueeze_2529: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2528, 2);  unsqueeze_2528 = None
    unsqueeze_2530: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2529, 3);  unsqueeze_2529 = None
    mul_3296: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_721, unsqueeze_2527);  sub_721 = unsqueeze_2527 = None
    sub_723: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_79, mul_3296);  where_79 = mul_3296 = None
    sub_724: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_723, unsqueeze_2524);  sub_723 = unsqueeze_2524 = None
    mul_3297: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_724, unsqueeze_2530);  sub_724 = unsqueeze_2530 = None
    mul_3298: "f32[72]" = torch.ops.aten.mul.Tensor(sum_201, squeeze_676);  sum_201 = squeeze_676 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_99 = torch.ops.aten.convolution_backward.default(mul_3297, relu_183, primals_676, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3297 = primals_676 = None
    getitem_947: "f32[8, 72, 14, 14]" = convolution_backward_99[0]
    getitem_948: "f32[72, 72, 3, 3]" = convolution_backward_99[1];  convolution_backward_99 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1977: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_78, getitem_947);  where_78 = getitem_947 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_80: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_203, 0);  relu_203 = None
    where_80: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_80, full_default, add_1969);  le_80 = add_1969 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_202: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_80, [0, 2, 3])
    sub_725: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_224, unsqueeze_2533);  convolution_224 = unsqueeze_2533 = None
    mul_3299: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_80, sub_725)
    sum_203: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3299, [0, 2, 3]);  mul_3299 = None
    mul_3300: "f32[36]" = torch.ops.aten.mul.Tensor(sum_202, 0.00015943877551020407)
    unsqueeze_2534: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3300, 0);  mul_3300 = None
    unsqueeze_2535: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2534, 2);  unsqueeze_2534 = None
    unsqueeze_2536: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2535, 3);  unsqueeze_2535 = None
    mul_3301: "f32[36]" = torch.ops.aten.mul.Tensor(sum_203, 0.00015943877551020407)
    mul_3302: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_673, squeeze_673)
    mul_3303: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3301, mul_3302);  mul_3301 = mul_3302 = None
    unsqueeze_2537: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3303, 0);  mul_3303 = None
    unsqueeze_2538: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2537, 2);  unsqueeze_2537 = None
    unsqueeze_2539: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2538, 3);  unsqueeze_2538 = None
    mul_3304: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_673, primals_674);  primals_674 = None
    unsqueeze_2540: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3304, 0);  mul_3304 = None
    unsqueeze_2541: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2540, 2);  unsqueeze_2540 = None
    unsqueeze_2542: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2541, 3);  unsqueeze_2541 = None
    mul_3305: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_725, unsqueeze_2539);  sub_725 = unsqueeze_2539 = None
    sub_727: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_80, mul_3305);  mul_3305 = None
    sub_728: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_727, unsqueeze_2536);  sub_727 = unsqueeze_2536 = None
    mul_3306: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_728, unsqueeze_2542);  sub_728 = unsqueeze_2542 = None
    mul_3307: "f32[36]" = torch.ops.aten.mul.Tensor(sum_203, squeeze_673);  sum_203 = squeeze_673 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_100 = torch.ops.aten.convolution_backward.default(mul_3306, relu_202, primals_673, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3306 = primals_673 = None
    getitem_950: "f32[8, 36, 28, 28]" = convolution_backward_100[0]
    getitem_951: "f32[36, 36, 3, 3]" = convolution_backward_100[1];  convolution_backward_100 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_81: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_202, 0);  relu_202 = None
    where_81: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_81, full_default, getitem_950);  le_81 = getitem_950 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_204: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_81, [0, 2, 3])
    sub_729: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_223, unsqueeze_2545);  convolution_223 = unsqueeze_2545 = None
    mul_3308: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_81, sub_729)
    sum_205: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3308, [0, 2, 3]);  mul_3308 = None
    mul_3309: "f32[36]" = torch.ops.aten.mul.Tensor(sum_204, 0.00015943877551020407)
    unsqueeze_2546: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3309, 0);  mul_3309 = None
    unsqueeze_2547: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2546, 2);  unsqueeze_2546 = None
    unsqueeze_2548: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2547, 3);  unsqueeze_2547 = None
    mul_3310: "f32[36]" = torch.ops.aten.mul.Tensor(sum_205, 0.00015943877551020407)
    mul_3311: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_670, squeeze_670)
    mul_3312: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3310, mul_3311);  mul_3310 = mul_3311 = None
    unsqueeze_2549: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3312, 0);  mul_3312 = None
    unsqueeze_2550: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2549, 2);  unsqueeze_2549 = None
    unsqueeze_2551: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2550, 3);  unsqueeze_2550 = None
    mul_3313: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_670, primals_671);  primals_671 = None
    unsqueeze_2552: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3313, 0);  mul_3313 = None
    unsqueeze_2553: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2552, 2);  unsqueeze_2552 = None
    unsqueeze_2554: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2553, 3);  unsqueeze_2553 = None
    mul_3314: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_729, unsqueeze_2551);  sub_729 = unsqueeze_2551 = None
    sub_731: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_81, mul_3314);  where_81 = mul_3314 = None
    sub_732: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_731, unsqueeze_2548);  sub_731 = unsqueeze_2548 = None
    mul_3315: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_732, unsqueeze_2554);  sub_732 = unsqueeze_2554 = None
    mul_3316: "f32[36]" = torch.ops.aten.mul.Tensor(sum_205, squeeze_670);  sum_205 = squeeze_670 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_101 = torch.ops.aten.convolution_backward.default(mul_3315, relu_201, primals_670, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3315 = primals_670 = None
    getitem_953: "f32[8, 36, 28, 28]" = convolution_backward_101[0]
    getitem_954: "f32[36, 36, 3, 3]" = convolution_backward_101[1];  convolution_backward_101 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1978: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_80, getitem_953);  where_80 = getitem_953 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_82: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_201, 0);  relu_201 = None
    where_82: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_82, full_default, add_1978);  le_82 = add_1978 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_206: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_82, [0, 2, 3])
    sub_733: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_222, unsqueeze_2557);  convolution_222 = unsqueeze_2557 = None
    mul_3317: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_82, sub_733)
    sum_207: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3317, [0, 2, 3]);  mul_3317 = None
    mul_3318: "f32[36]" = torch.ops.aten.mul.Tensor(sum_206, 0.00015943877551020407)
    unsqueeze_2558: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3318, 0);  mul_3318 = None
    unsqueeze_2559: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2558, 2);  unsqueeze_2558 = None
    unsqueeze_2560: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2559, 3);  unsqueeze_2559 = None
    mul_3319: "f32[36]" = torch.ops.aten.mul.Tensor(sum_207, 0.00015943877551020407)
    mul_3320: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_667, squeeze_667)
    mul_3321: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3319, mul_3320);  mul_3319 = mul_3320 = None
    unsqueeze_2561: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3321, 0);  mul_3321 = None
    unsqueeze_2562: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2561, 2);  unsqueeze_2561 = None
    unsqueeze_2563: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2562, 3);  unsqueeze_2562 = None
    mul_3322: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_667, primals_668);  primals_668 = None
    unsqueeze_2564: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3322, 0);  mul_3322 = None
    unsqueeze_2565: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2564, 2);  unsqueeze_2564 = None
    unsqueeze_2566: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2565, 3);  unsqueeze_2565 = None
    mul_3323: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_733, unsqueeze_2563);  sub_733 = unsqueeze_2563 = None
    sub_735: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_82, mul_3323);  mul_3323 = None
    sub_736: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_735, unsqueeze_2560);  sub_735 = unsqueeze_2560 = None
    mul_3324: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_736, unsqueeze_2566);  sub_736 = unsqueeze_2566 = None
    mul_3325: "f32[36]" = torch.ops.aten.mul.Tensor(sum_207, squeeze_667);  sum_207 = squeeze_667 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_102 = torch.ops.aten.convolution_backward.default(mul_3324, relu_200, primals_667, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3324 = primals_667 = None
    getitem_956: "f32[8, 36, 28, 28]" = convolution_backward_102[0]
    getitem_957: "f32[36, 36, 3, 3]" = convolution_backward_102[1];  convolution_backward_102 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_83: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_200, 0);  relu_200 = None
    where_83: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_83, full_default, getitem_956);  le_83 = getitem_956 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_208: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_83, [0, 2, 3])
    sub_737: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_221, unsqueeze_2569);  convolution_221 = unsqueeze_2569 = None
    mul_3326: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_83, sub_737)
    sum_209: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3326, [0, 2, 3]);  mul_3326 = None
    mul_3327: "f32[36]" = torch.ops.aten.mul.Tensor(sum_208, 0.00015943877551020407)
    unsqueeze_2570: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3327, 0);  mul_3327 = None
    unsqueeze_2571: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2570, 2);  unsqueeze_2570 = None
    unsqueeze_2572: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2571, 3);  unsqueeze_2571 = None
    mul_3328: "f32[36]" = torch.ops.aten.mul.Tensor(sum_209, 0.00015943877551020407)
    mul_3329: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_664, squeeze_664)
    mul_3330: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3328, mul_3329);  mul_3328 = mul_3329 = None
    unsqueeze_2573: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3330, 0);  mul_3330 = None
    unsqueeze_2574: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2573, 2);  unsqueeze_2573 = None
    unsqueeze_2575: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2574, 3);  unsqueeze_2574 = None
    mul_3331: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_664, primals_665);  primals_665 = None
    unsqueeze_2576: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3331, 0);  mul_3331 = None
    unsqueeze_2577: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2576, 2);  unsqueeze_2576 = None
    unsqueeze_2578: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2577, 3);  unsqueeze_2577 = None
    mul_3332: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_737, unsqueeze_2575);  sub_737 = unsqueeze_2575 = None
    sub_739: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_83, mul_3332);  where_83 = mul_3332 = None
    sub_740: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_739, unsqueeze_2572);  sub_739 = unsqueeze_2572 = None
    mul_3333: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_740, unsqueeze_2578);  sub_740 = unsqueeze_2578 = None
    mul_3334: "f32[36]" = torch.ops.aten.mul.Tensor(sum_209, squeeze_664);  sum_209 = squeeze_664 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_103 = torch.ops.aten.convolution_backward.default(mul_3333, relu_199, primals_664, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3333 = primals_664 = None
    getitem_959: "f32[8, 36, 28, 28]" = convolution_backward_103[0]
    getitem_960: "f32[36, 36, 3, 3]" = convolution_backward_103[1];  convolution_backward_103 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1979: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_82, getitem_959);  where_82 = getitem_959 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_84: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_199, 0);  relu_199 = None
    where_84: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_84, full_default, add_1979);  le_84 = add_1979 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_210: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_84, [0, 2, 3])
    sub_741: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_220, unsqueeze_2581);  convolution_220 = unsqueeze_2581 = None
    mul_3335: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_84, sub_741)
    sum_211: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3335, [0, 2, 3]);  mul_3335 = None
    mul_3336: "f32[36]" = torch.ops.aten.mul.Tensor(sum_210, 0.00015943877551020407)
    unsqueeze_2582: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3336, 0);  mul_3336 = None
    unsqueeze_2583: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2582, 2);  unsqueeze_2582 = None
    unsqueeze_2584: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2583, 3);  unsqueeze_2583 = None
    mul_3337: "f32[36]" = torch.ops.aten.mul.Tensor(sum_211, 0.00015943877551020407)
    mul_3338: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_661, squeeze_661)
    mul_3339: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3337, mul_3338);  mul_3337 = mul_3338 = None
    unsqueeze_2585: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3339, 0);  mul_3339 = None
    unsqueeze_2586: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2585, 2);  unsqueeze_2585 = None
    unsqueeze_2587: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2586, 3);  unsqueeze_2586 = None
    mul_3340: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_661, primals_662);  primals_662 = None
    unsqueeze_2588: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3340, 0);  mul_3340 = None
    unsqueeze_2589: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2588, 2);  unsqueeze_2588 = None
    unsqueeze_2590: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2589, 3);  unsqueeze_2589 = None
    mul_3341: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_741, unsqueeze_2587);  sub_741 = unsqueeze_2587 = None
    sub_743: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_84, mul_3341);  mul_3341 = None
    sub_744: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_743, unsqueeze_2584);  sub_743 = unsqueeze_2584 = None
    mul_3342: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_744, unsqueeze_2590);  sub_744 = unsqueeze_2590 = None
    mul_3343: "f32[36]" = torch.ops.aten.mul.Tensor(sum_211, squeeze_661);  sum_211 = squeeze_661 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_104 = torch.ops.aten.convolution_backward.default(mul_3342, relu_198, primals_661, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3342 = primals_661 = None
    getitem_962: "f32[8, 36, 28, 28]" = convolution_backward_104[0]
    getitem_963: "f32[36, 36, 3, 3]" = convolution_backward_104[1];  convolution_backward_104 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_85: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_198, 0);  relu_198 = None
    where_85: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_85, full_default, getitem_962);  le_85 = getitem_962 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_212: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_85, [0, 2, 3])
    sub_745: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_219, unsqueeze_2593);  convolution_219 = unsqueeze_2593 = None
    mul_3344: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_85, sub_745)
    sum_213: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3344, [0, 2, 3]);  mul_3344 = None
    mul_3345: "f32[36]" = torch.ops.aten.mul.Tensor(sum_212, 0.00015943877551020407)
    unsqueeze_2594: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3345, 0);  mul_3345 = None
    unsqueeze_2595: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2594, 2);  unsqueeze_2594 = None
    unsqueeze_2596: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2595, 3);  unsqueeze_2595 = None
    mul_3346: "f32[36]" = torch.ops.aten.mul.Tensor(sum_213, 0.00015943877551020407)
    mul_3347: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_658, squeeze_658)
    mul_3348: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3346, mul_3347);  mul_3346 = mul_3347 = None
    unsqueeze_2597: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3348, 0);  mul_3348 = None
    unsqueeze_2598: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2597, 2);  unsqueeze_2597 = None
    unsqueeze_2599: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2598, 3);  unsqueeze_2598 = None
    mul_3349: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_658, primals_659);  primals_659 = None
    unsqueeze_2600: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3349, 0);  mul_3349 = None
    unsqueeze_2601: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2600, 2);  unsqueeze_2600 = None
    unsqueeze_2602: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2601, 3);  unsqueeze_2601 = None
    mul_3350: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_745, unsqueeze_2599);  sub_745 = unsqueeze_2599 = None
    sub_747: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_85, mul_3350);  where_85 = mul_3350 = None
    sub_748: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_747, unsqueeze_2596);  sub_747 = unsqueeze_2596 = None
    mul_3351: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_748, unsqueeze_2602);  sub_748 = unsqueeze_2602 = None
    mul_3352: "f32[36]" = torch.ops.aten.mul.Tensor(sum_213, squeeze_658);  sum_213 = squeeze_658 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_105 = torch.ops.aten.convolution_backward.default(mul_3351, relu_197, primals_658, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3351 = primals_658 = None
    getitem_965: "f32[8, 36, 28, 28]" = convolution_backward_105[0]
    getitem_966: "f32[36, 36, 3, 3]" = convolution_backward_105[1];  convolution_backward_105 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1980: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_84, getitem_965);  where_84 = getitem_965 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_86: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_197, 0);  relu_197 = None
    where_86: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_86, full_default, add_1980);  le_86 = add_1980 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_214: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_86, [0, 2, 3])
    sub_749: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_218, unsqueeze_2605);  convolution_218 = unsqueeze_2605 = None
    mul_3353: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_86, sub_749)
    sum_215: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3353, [0, 2, 3]);  mul_3353 = None
    mul_3354: "f32[36]" = torch.ops.aten.mul.Tensor(sum_214, 0.00015943877551020407)
    unsqueeze_2606: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3354, 0);  mul_3354 = None
    unsqueeze_2607: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2606, 2);  unsqueeze_2606 = None
    unsqueeze_2608: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2607, 3);  unsqueeze_2607 = None
    mul_3355: "f32[36]" = torch.ops.aten.mul.Tensor(sum_215, 0.00015943877551020407)
    mul_3356: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_655, squeeze_655)
    mul_3357: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3355, mul_3356);  mul_3355 = mul_3356 = None
    unsqueeze_2609: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3357, 0);  mul_3357 = None
    unsqueeze_2610: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2609, 2);  unsqueeze_2609 = None
    unsqueeze_2611: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2610, 3);  unsqueeze_2610 = None
    mul_3358: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_655, primals_656);  primals_656 = None
    unsqueeze_2612: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3358, 0);  mul_3358 = None
    unsqueeze_2613: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2612, 2);  unsqueeze_2612 = None
    unsqueeze_2614: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2613, 3);  unsqueeze_2613 = None
    mul_3359: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_749, unsqueeze_2611);  sub_749 = unsqueeze_2611 = None
    sub_751: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_86, mul_3359);  mul_3359 = None
    sub_752: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_751, unsqueeze_2608);  sub_751 = unsqueeze_2608 = None
    mul_3360: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_752, unsqueeze_2614);  sub_752 = unsqueeze_2614 = None
    mul_3361: "f32[36]" = torch.ops.aten.mul.Tensor(sum_215, squeeze_655);  sum_215 = squeeze_655 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_106 = torch.ops.aten.convolution_backward.default(mul_3360, relu_196, primals_655, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3360 = primals_655 = None
    getitem_968: "f32[8, 36, 28, 28]" = convolution_backward_106[0]
    getitem_969: "f32[36, 36, 3, 3]" = convolution_backward_106[1];  convolution_backward_106 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_87: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_196, 0);  relu_196 = None
    where_87: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_87, full_default, getitem_968);  le_87 = getitem_968 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_216: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_87, [0, 2, 3])
    sub_753: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_217, unsqueeze_2617);  convolution_217 = unsqueeze_2617 = None
    mul_3362: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_87, sub_753)
    sum_217: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3362, [0, 2, 3]);  mul_3362 = None
    mul_3363: "f32[36]" = torch.ops.aten.mul.Tensor(sum_216, 0.00015943877551020407)
    unsqueeze_2618: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3363, 0);  mul_3363 = None
    unsqueeze_2619: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2618, 2);  unsqueeze_2618 = None
    unsqueeze_2620: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2619, 3);  unsqueeze_2619 = None
    mul_3364: "f32[36]" = torch.ops.aten.mul.Tensor(sum_217, 0.00015943877551020407)
    mul_3365: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_652, squeeze_652)
    mul_3366: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3364, mul_3365);  mul_3364 = mul_3365 = None
    unsqueeze_2621: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3366, 0);  mul_3366 = None
    unsqueeze_2622: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2621, 2);  unsqueeze_2621 = None
    unsqueeze_2623: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2622, 3);  unsqueeze_2622 = None
    mul_3367: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_652, primals_653);  primals_653 = None
    unsqueeze_2624: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3367, 0);  mul_3367 = None
    unsqueeze_2625: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2624, 2);  unsqueeze_2624 = None
    unsqueeze_2626: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2625, 3);  unsqueeze_2625 = None
    mul_3368: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_753, unsqueeze_2623);  sub_753 = unsqueeze_2623 = None
    sub_755: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_87, mul_3368);  where_87 = mul_3368 = None
    sub_756: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_755, unsqueeze_2620);  sub_755 = unsqueeze_2620 = None
    mul_3369: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_756, unsqueeze_2626);  sub_756 = unsqueeze_2626 = None
    mul_3370: "f32[36]" = torch.ops.aten.mul.Tensor(sum_217, squeeze_652);  sum_217 = squeeze_652 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_107 = torch.ops.aten.convolution_backward.default(mul_3369, relu_181, primals_652, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3369 = primals_652 = None
    getitem_971: "f32[8, 36, 28, 28]" = convolution_backward_107[0]
    getitem_972: "f32[36, 36, 3, 3]" = convolution_backward_107[1];  convolution_backward_107 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1981: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_86, getitem_971);  where_86 = getitem_971 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_88: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_195, 0);  relu_195 = None
    where_88: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_88, full_default, add_1968);  le_88 = add_1968 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_218: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_88, [0, 2, 3])
    sub_757: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_216, unsqueeze_2629);  convolution_216 = unsqueeze_2629 = None
    mul_3371: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_88, sub_757)
    sum_219: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3371, [0, 2, 3]);  mul_3371 = None
    mul_3372: "f32[18]" = torch.ops.aten.mul.Tensor(sum_218, 3.985969387755102e-05)
    unsqueeze_2630: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3372, 0);  mul_3372 = None
    unsqueeze_2631: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2630, 2);  unsqueeze_2630 = None
    unsqueeze_2632: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2631, 3);  unsqueeze_2631 = None
    mul_3373: "f32[18]" = torch.ops.aten.mul.Tensor(sum_219, 3.985969387755102e-05)
    mul_3374: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_649, squeeze_649)
    mul_3375: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3373, mul_3374);  mul_3373 = mul_3374 = None
    unsqueeze_2633: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3375, 0);  mul_3375 = None
    unsqueeze_2634: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2633, 2);  unsqueeze_2633 = None
    unsqueeze_2635: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2634, 3);  unsqueeze_2634 = None
    mul_3376: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_649, primals_650);  primals_650 = None
    unsqueeze_2636: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3376, 0);  mul_3376 = None
    unsqueeze_2637: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2636, 2);  unsqueeze_2636 = None
    unsqueeze_2638: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2637, 3);  unsqueeze_2637 = None
    mul_3377: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_757, unsqueeze_2635);  sub_757 = unsqueeze_2635 = None
    sub_759: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_88, mul_3377);  mul_3377 = None
    sub_760: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_759, unsqueeze_2632);  sub_759 = unsqueeze_2632 = None
    mul_3378: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_760, unsqueeze_2638);  sub_760 = unsqueeze_2638 = None
    mul_3379: "f32[18]" = torch.ops.aten.mul.Tensor(sum_219, squeeze_649);  sum_219 = squeeze_649 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_108 = torch.ops.aten.convolution_backward.default(mul_3378, relu_194, primals_649, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3378 = primals_649 = None
    getitem_974: "f32[8, 18, 56, 56]" = convolution_backward_108[0]
    getitem_975: "f32[18, 18, 3, 3]" = convolution_backward_108[1];  convolution_backward_108 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_89: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_194, 0);  relu_194 = None
    where_89: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_89, full_default, getitem_974);  le_89 = getitem_974 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_220: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_89, [0, 2, 3])
    sub_761: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_215, unsqueeze_2641);  convolution_215 = unsqueeze_2641 = None
    mul_3380: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_89, sub_761)
    sum_221: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3380, [0, 2, 3]);  mul_3380 = None
    mul_3381: "f32[18]" = torch.ops.aten.mul.Tensor(sum_220, 3.985969387755102e-05)
    unsqueeze_2642: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3381, 0);  mul_3381 = None
    unsqueeze_2643: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2642, 2);  unsqueeze_2642 = None
    unsqueeze_2644: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2643, 3);  unsqueeze_2643 = None
    mul_3382: "f32[18]" = torch.ops.aten.mul.Tensor(sum_221, 3.985969387755102e-05)
    mul_3383: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_646, squeeze_646)
    mul_3384: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3382, mul_3383);  mul_3382 = mul_3383 = None
    unsqueeze_2645: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3384, 0);  mul_3384 = None
    unsqueeze_2646: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2645, 2);  unsqueeze_2645 = None
    unsqueeze_2647: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2646, 3);  unsqueeze_2646 = None
    mul_3385: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_646, primals_647);  primals_647 = None
    unsqueeze_2648: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3385, 0);  mul_3385 = None
    unsqueeze_2649: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2648, 2);  unsqueeze_2648 = None
    unsqueeze_2650: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2649, 3);  unsqueeze_2649 = None
    mul_3386: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_761, unsqueeze_2647);  sub_761 = unsqueeze_2647 = None
    sub_763: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_89, mul_3386);  where_89 = mul_3386 = None
    sub_764: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_763, unsqueeze_2644);  sub_763 = unsqueeze_2644 = None
    mul_3387: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_764, unsqueeze_2650);  sub_764 = unsqueeze_2650 = None
    mul_3388: "f32[18]" = torch.ops.aten.mul.Tensor(sum_221, squeeze_646);  sum_221 = squeeze_646 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_109 = torch.ops.aten.convolution_backward.default(mul_3387, relu_193, primals_646, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3387 = primals_646 = None
    getitem_977: "f32[8, 18, 56, 56]" = convolution_backward_109[0]
    getitem_978: "f32[18, 18, 3, 3]" = convolution_backward_109[1];  convolution_backward_109 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1982: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_88, getitem_977);  where_88 = getitem_977 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_90: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_193, 0);  relu_193 = None
    where_90: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_90, full_default, add_1982);  le_90 = add_1982 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_222: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_90, [0, 2, 3])
    sub_765: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_214, unsqueeze_2653);  convolution_214 = unsqueeze_2653 = None
    mul_3389: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_90, sub_765)
    sum_223: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3389, [0, 2, 3]);  mul_3389 = None
    mul_3390: "f32[18]" = torch.ops.aten.mul.Tensor(sum_222, 3.985969387755102e-05)
    unsqueeze_2654: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3390, 0);  mul_3390 = None
    unsqueeze_2655: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2654, 2);  unsqueeze_2654 = None
    unsqueeze_2656: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2655, 3);  unsqueeze_2655 = None
    mul_3391: "f32[18]" = torch.ops.aten.mul.Tensor(sum_223, 3.985969387755102e-05)
    mul_3392: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_643, squeeze_643)
    mul_3393: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3391, mul_3392);  mul_3391 = mul_3392 = None
    unsqueeze_2657: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3393, 0);  mul_3393 = None
    unsqueeze_2658: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2657, 2);  unsqueeze_2657 = None
    unsqueeze_2659: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2658, 3);  unsqueeze_2658 = None
    mul_3394: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_643, primals_644);  primals_644 = None
    unsqueeze_2660: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3394, 0);  mul_3394 = None
    unsqueeze_2661: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2660, 2);  unsqueeze_2660 = None
    unsqueeze_2662: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2661, 3);  unsqueeze_2661 = None
    mul_3395: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_765, unsqueeze_2659);  sub_765 = unsqueeze_2659 = None
    sub_767: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_90, mul_3395);  mul_3395 = None
    sub_768: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_767, unsqueeze_2656);  sub_767 = unsqueeze_2656 = None
    mul_3396: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_768, unsqueeze_2662);  sub_768 = unsqueeze_2662 = None
    mul_3397: "f32[18]" = torch.ops.aten.mul.Tensor(sum_223, squeeze_643);  sum_223 = squeeze_643 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_110 = torch.ops.aten.convolution_backward.default(mul_3396, relu_192, primals_643, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3396 = primals_643 = None
    getitem_980: "f32[8, 18, 56, 56]" = convolution_backward_110[0]
    getitem_981: "f32[18, 18, 3, 3]" = convolution_backward_110[1];  convolution_backward_110 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_91: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_192, 0);  relu_192 = None
    where_91: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_91, full_default, getitem_980);  le_91 = getitem_980 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_224: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_91, [0, 2, 3])
    sub_769: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_213, unsqueeze_2665);  convolution_213 = unsqueeze_2665 = None
    mul_3398: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_91, sub_769)
    sum_225: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3398, [0, 2, 3]);  mul_3398 = None
    mul_3399: "f32[18]" = torch.ops.aten.mul.Tensor(sum_224, 3.985969387755102e-05)
    unsqueeze_2666: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3399, 0);  mul_3399 = None
    unsqueeze_2667: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2666, 2);  unsqueeze_2666 = None
    unsqueeze_2668: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2667, 3);  unsqueeze_2667 = None
    mul_3400: "f32[18]" = torch.ops.aten.mul.Tensor(sum_225, 3.985969387755102e-05)
    mul_3401: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_640, squeeze_640)
    mul_3402: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3400, mul_3401);  mul_3400 = mul_3401 = None
    unsqueeze_2669: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3402, 0);  mul_3402 = None
    unsqueeze_2670: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2669, 2);  unsqueeze_2669 = None
    unsqueeze_2671: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2670, 3);  unsqueeze_2670 = None
    mul_3403: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_640, primals_641);  primals_641 = None
    unsqueeze_2672: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3403, 0);  mul_3403 = None
    unsqueeze_2673: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2672, 2);  unsqueeze_2672 = None
    unsqueeze_2674: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2673, 3);  unsqueeze_2673 = None
    mul_3404: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_769, unsqueeze_2671);  sub_769 = unsqueeze_2671 = None
    sub_771: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_91, mul_3404);  where_91 = mul_3404 = None
    sub_772: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_771, unsqueeze_2668);  sub_771 = unsqueeze_2668 = None
    mul_3405: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_772, unsqueeze_2674);  sub_772 = unsqueeze_2674 = None
    mul_3406: "f32[18]" = torch.ops.aten.mul.Tensor(sum_225, squeeze_640);  sum_225 = squeeze_640 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_111 = torch.ops.aten.convolution_backward.default(mul_3405, relu_191, primals_640, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3405 = primals_640 = None
    getitem_983: "f32[8, 18, 56, 56]" = convolution_backward_111[0]
    getitem_984: "f32[18, 18, 3, 3]" = convolution_backward_111[1];  convolution_backward_111 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1983: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_90, getitem_983);  where_90 = getitem_983 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_92: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_191, 0);  relu_191 = None
    where_92: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_92, full_default, add_1983);  le_92 = add_1983 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_226: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_92, [0, 2, 3])
    sub_773: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_212, unsqueeze_2677);  convolution_212 = unsqueeze_2677 = None
    mul_3407: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_92, sub_773)
    sum_227: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3407, [0, 2, 3]);  mul_3407 = None
    mul_3408: "f32[18]" = torch.ops.aten.mul.Tensor(sum_226, 3.985969387755102e-05)
    unsqueeze_2678: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3408, 0);  mul_3408 = None
    unsqueeze_2679: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2678, 2);  unsqueeze_2678 = None
    unsqueeze_2680: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2679, 3);  unsqueeze_2679 = None
    mul_3409: "f32[18]" = torch.ops.aten.mul.Tensor(sum_227, 3.985969387755102e-05)
    mul_3410: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_637, squeeze_637)
    mul_3411: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3409, mul_3410);  mul_3409 = mul_3410 = None
    unsqueeze_2681: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3411, 0);  mul_3411 = None
    unsqueeze_2682: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2681, 2);  unsqueeze_2681 = None
    unsqueeze_2683: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2682, 3);  unsqueeze_2682 = None
    mul_3412: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_637, primals_638);  primals_638 = None
    unsqueeze_2684: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3412, 0);  mul_3412 = None
    unsqueeze_2685: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2684, 2);  unsqueeze_2684 = None
    unsqueeze_2686: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2685, 3);  unsqueeze_2685 = None
    mul_3413: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_773, unsqueeze_2683);  sub_773 = unsqueeze_2683 = None
    sub_775: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_92, mul_3413);  mul_3413 = None
    sub_776: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_775, unsqueeze_2680);  sub_775 = unsqueeze_2680 = None
    mul_3414: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_776, unsqueeze_2686);  sub_776 = unsqueeze_2686 = None
    mul_3415: "f32[18]" = torch.ops.aten.mul.Tensor(sum_227, squeeze_637);  sum_227 = squeeze_637 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_112 = torch.ops.aten.convolution_backward.default(mul_3414, relu_190, primals_637, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3414 = primals_637 = None
    getitem_986: "f32[8, 18, 56, 56]" = convolution_backward_112[0]
    getitem_987: "f32[18, 18, 3, 3]" = convolution_backward_112[1];  convolution_backward_112 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_93: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_190, 0);  relu_190 = None
    where_93: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_93, full_default, getitem_986);  le_93 = getitem_986 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_228: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_93, [0, 2, 3])
    sub_777: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_211, unsqueeze_2689);  convolution_211 = unsqueeze_2689 = None
    mul_3416: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_93, sub_777)
    sum_229: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3416, [0, 2, 3]);  mul_3416 = None
    mul_3417: "f32[18]" = torch.ops.aten.mul.Tensor(sum_228, 3.985969387755102e-05)
    unsqueeze_2690: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3417, 0);  mul_3417 = None
    unsqueeze_2691: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2690, 2);  unsqueeze_2690 = None
    unsqueeze_2692: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2691, 3);  unsqueeze_2691 = None
    mul_3418: "f32[18]" = torch.ops.aten.mul.Tensor(sum_229, 3.985969387755102e-05)
    mul_3419: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_634, squeeze_634)
    mul_3420: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3418, mul_3419);  mul_3418 = mul_3419 = None
    unsqueeze_2693: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3420, 0);  mul_3420 = None
    unsqueeze_2694: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2693, 2);  unsqueeze_2693 = None
    unsqueeze_2695: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2694, 3);  unsqueeze_2694 = None
    mul_3421: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_634, primals_635);  primals_635 = None
    unsqueeze_2696: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3421, 0);  mul_3421 = None
    unsqueeze_2697: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2696, 2);  unsqueeze_2696 = None
    unsqueeze_2698: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2697, 3);  unsqueeze_2697 = None
    mul_3422: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_777, unsqueeze_2695);  sub_777 = unsqueeze_2695 = None
    sub_779: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_93, mul_3422);  where_93 = mul_3422 = None
    sub_780: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_779, unsqueeze_2692);  sub_779 = unsqueeze_2692 = None
    mul_3423: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_780, unsqueeze_2698);  sub_780 = unsqueeze_2698 = None
    mul_3424: "f32[18]" = torch.ops.aten.mul.Tensor(sum_229, squeeze_634);  sum_229 = squeeze_634 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_113 = torch.ops.aten.convolution_backward.default(mul_3423, relu_189, primals_634, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3423 = primals_634 = None
    getitem_989: "f32[8, 18, 56, 56]" = convolution_backward_113[0]
    getitem_990: "f32[18, 18, 3, 3]" = convolution_backward_113[1];  convolution_backward_113 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1984: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_92, getitem_989);  where_92 = getitem_989 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_94: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_189, 0);  relu_189 = None
    where_94: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_94, full_default, add_1984);  le_94 = add_1984 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_230: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_94, [0, 2, 3])
    sub_781: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_210, unsqueeze_2701);  convolution_210 = unsqueeze_2701 = None
    mul_3425: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_94, sub_781)
    sum_231: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3425, [0, 2, 3]);  mul_3425 = None
    mul_3426: "f32[18]" = torch.ops.aten.mul.Tensor(sum_230, 3.985969387755102e-05)
    unsqueeze_2702: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3426, 0);  mul_3426 = None
    unsqueeze_2703: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2702, 2);  unsqueeze_2702 = None
    unsqueeze_2704: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2703, 3);  unsqueeze_2703 = None
    mul_3427: "f32[18]" = torch.ops.aten.mul.Tensor(sum_231, 3.985969387755102e-05)
    mul_3428: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_631, squeeze_631)
    mul_3429: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3427, mul_3428);  mul_3427 = mul_3428 = None
    unsqueeze_2705: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3429, 0);  mul_3429 = None
    unsqueeze_2706: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2705, 2);  unsqueeze_2705 = None
    unsqueeze_2707: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2706, 3);  unsqueeze_2706 = None
    mul_3430: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_631, primals_632);  primals_632 = None
    unsqueeze_2708: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3430, 0);  mul_3430 = None
    unsqueeze_2709: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2708, 2);  unsqueeze_2708 = None
    unsqueeze_2710: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2709, 3);  unsqueeze_2709 = None
    mul_3431: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_781, unsqueeze_2707);  sub_781 = unsqueeze_2707 = None
    sub_783: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_94, mul_3431);  mul_3431 = None
    sub_784: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_783, unsqueeze_2704);  sub_783 = unsqueeze_2704 = None
    mul_3432: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_784, unsqueeze_2710);  sub_784 = unsqueeze_2710 = None
    mul_3433: "f32[18]" = torch.ops.aten.mul.Tensor(sum_231, squeeze_631);  sum_231 = squeeze_631 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_114 = torch.ops.aten.convolution_backward.default(mul_3432, relu_188, primals_631, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3432 = primals_631 = None
    getitem_992: "f32[8, 18, 56, 56]" = convolution_backward_114[0]
    getitem_993: "f32[18, 18, 3, 3]" = convolution_backward_114[1];  convolution_backward_114 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_95: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_188, 0);  relu_188 = None
    where_95: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_95, full_default, getitem_992);  le_95 = getitem_992 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_232: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_95, [0, 2, 3])
    sub_785: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_209, unsqueeze_2713);  convolution_209 = unsqueeze_2713 = None
    mul_3434: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_95, sub_785)
    sum_233: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3434, [0, 2, 3]);  mul_3434 = None
    mul_3435: "f32[18]" = torch.ops.aten.mul.Tensor(sum_232, 3.985969387755102e-05)
    unsqueeze_2714: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3435, 0);  mul_3435 = None
    unsqueeze_2715: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2714, 2);  unsqueeze_2714 = None
    unsqueeze_2716: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2715, 3);  unsqueeze_2715 = None
    mul_3436: "f32[18]" = torch.ops.aten.mul.Tensor(sum_233, 3.985969387755102e-05)
    mul_3437: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_628, squeeze_628)
    mul_3438: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3436, mul_3437);  mul_3436 = mul_3437 = None
    unsqueeze_2717: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3438, 0);  mul_3438 = None
    unsqueeze_2718: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2717, 2);  unsqueeze_2717 = None
    unsqueeze_2719: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2718, 3);  unsqueeze_2718 = None
    mul_3439: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_628, primals_629);  primals_629 = None
    unsqueeze_2720: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3439, 0);  mul_3439 = None
    unsqueeze_2721: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2720, 2);  unsqueeze_2720 = None
    unsqueeze_2722: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2721, 3);  unsqueeze_2721 = None
    mul_3440: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_785, unsqueeze_2719);  sub_785 = unsqueeze_2719 = None
    sub_787: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_95, mul_3440);  where_95 = mul_3440 = None
    sub_788: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_787, unsqueeze_2716);  sub_787 = unsqueeze_2716 = None
    mul_3441: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_788, unsqueeze_2722);  sub_788 = unsqueeze_2722 = None
    mul_3442: "f32[18]" = torch.ops.aten.mul.Tensor(sum_233, squeeze_628);  sum_233 = squeeze_628 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_115 = torch.ops.aten.convolution_backward.default(mul_3441, relu_180, primals_628, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3441 = primals_628 = None
    getitem_995: "f32[8, 18, 56, 56]" = convolution_backward_115[0]
    getitem_996: "f32[18, 18, 3, 3]" = convolution_backward_115[1];  convolution_backward_115 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1985: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_94, getitem_995);  where_94 = getitem_995 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_96: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_187, 0);  relu_187 = None
    where_96: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_96, full_default, add_1973);  le_96 = add_1973 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    sum_234: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_96, [0, 2, 3])
    sub_789: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_208, unsqueeze_2725);  convolution_208 = unsqueeze_2725 = None
    mul_3443: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_96, sub_789)
    sum_235: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3443, [0, 2, 3]);  mul_3443 = None
    mul_3444: "f32[144]" = torch.ops.aten.mul.Tensor(sum_234, 0.002551020408163265)
    unsqueeze_2726: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3444, 0);  mul_3444 = None
    unsqueeze_2727: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2726, 2);  unsqueeze_2726 = None
    unsqueeze_2728: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2727, 3);  unsqueeze_2727 = None
    mul_3445: "f32[144]" = torch.ops.aten.mul.Tensor(sum_235, 0.002551020408163265)
    mul_3446: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_625, squeeze_625)
    mul_3447: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3445, mul_3446);  mul_3445 = mul_3446 = None
    unsqueeze_2729: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3447, 0);  mul_3447 = None
    unsqueeze_2730: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2729, 2);  unsqueeze_2729 = None
    unsqueeze_2731: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2730, 3);  unsqueeze_2730 = None
    mul_3448: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_625, primals_626);  primals_626 = None
    unsqueeze_2732: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3448, 0);  mul_3448 = None
    unsqueeze_2733: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2732, 2);  unsqueeze_2732 = None
    unsqueeze_2734: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2733, 3);  unsqueeze_2733 = None
    mul_3449: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_789, unsqueeze_2731);  sub_789 = unsqueeze_2731 = None
    sub_791: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_96, mul_3449);  mul_3449 = None
    sub_792: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_791, unsqueeze_2728);  sub_791 = None
    mul_3450: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_792, unsqueeze_2734);  sub_792 = unsqueeze_2734 = None
    mul_3451: "f32[144]" = torch.ops.aten.mul.Tensor(sum_235, squeeze_625);  sum_235 = squeeze_625 = None
    convolution_backward_116 = torch.ops.aten.convolution_backward.default(mul_3450, relu_171, primals_625, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3450 = primals_625 = None
    getitem_998: "f32[8, 72, 14, 14]" = convolution_backward_116[0]
    getitem_999: "f32[144, 72, 3, 3]" = convolution_backward_116[1];  convolution_backward_116 = None
    sub_793: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_207, unsqueeze_2737);  convolution_207 = unsqueeze_2737 = None
    mul_3452: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_96, sub_793)
    sum_237: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3452, [0, 2, 3]);  mul_3452 = None
    mul_3454: "f32[144]" = torch.ops.aten.mul.Tensor(sum_237, 0.002551020408163265)
    mul_3455: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_622, squeeze_622)
    mul_3456: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3454, mul_3455);  mul_3454 = mul_3455 = None
    unsqueeze_2741: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3456, 0);  mul_3456 = None
    unsqueeze_2742: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2741, 2);  unsqueeze_2741 = None
    unsqueeze_2743: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2742, 3);  unsqueeze_2742 = None
    mul_3457: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_622, primals_623);  primals_623 = None
    unsqueeze_2744: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3457, 0);  mul_3457 = None
    unsqueeze_2745: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2744, 2);  unsqueeze_2744 = None
    unsqueeze_2746: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2745, 3);  unsqueeze_2745 = None
    mul_3458: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_793, unsqueeze_2743);  sub_793 = unsqueeze_2743 = None
    sub_795: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_96, mul_3458);  mul_3458 = None
    sub_796: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_795, unsqueeze_2728);  sub_795 = None
    mul_3459: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_796, unsqueeze_2746);  sub_796 = unsqueeze_2746 = None
    mul_3460: "f32[144]" = torch.ops.aten.mul.Tensor(sum_237, squeeze_622);  sum_237 = squeeze_622 = None
    convolution_backward_117 = torch.ops.aten.convolution_backward.default(mul_3459, relu_186, primals_622, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3459 = primals_622 = None
    getitem_1001: "f32[8, 36, 14, 14]" = convolution_backward_117[0]
    getitem_1002: "f32[144, 36, 3, 3]" = convolution_backward_117[1];  convolution_backward_117 = None
    le_97: "b8[8, 36, 14, 14]" = torch.ops.aten.le.Scalar(relu_186, 0);  relu_186 = None
    where_97: "f32[8, 36, 14, 14]" = torch.ops.aten.where.self(le_97, full_default, getitem_1001);  le_97 = getitem_1001 = None
    sum_238: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_97, [0, 2, 3])
    sub_797: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_206, unsqueeze_2749);  convolution_206 = unsqueeze_2749 = None
    mul_3461: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(where_97, sub_797)
    sum_239: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3461, [0, 2, 3]);  mul_3461 = None
    mul_3462: "f32[36]" = torch.ops.aten.mul.Tensor(sum_238, 0.0006377551020408163)
    unsqueeze_2750: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3462, 0);  mul_3462 = None
    unsqueeze_2751: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2750, 2);  unsqueeze_2750 = None
    unsqueeze_2752: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2751, 3);  unsqueeze_2751 = None
    mul_3463: "f32[36]" = torch.ops.aten.mul.Tensor(sum_239, 0.0006377551020408163)
    mul_3464: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_619, squeeze_619)
    mul_3465: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3463, mul_3464);  mul_3463 = mul_3464 = None
    unsqueeze_2753: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3465, 0);  mul_3465 = None
    unsqueeze_2754: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2753, 2);  unsqueeze_2753 = None
    unsqueeze_2755: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2754, 3);  unsqueeze_2754 = None
    mul_3466: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_619, primals_620);  primals_620 = None
    unsqueeze_2756: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3466, 0);  mul_3466 = None
    unsqueeze_2757: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2756, 2);  unsqueeze_2756 = None
    unsqueeze_2758: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2757, 3);  unsqueeze_2757 = None
    mul_3467: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_797, unsqueeze_2755);  sub_797 = unsqueeze_2755 = None
    sub_799: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(where_97, mul_3467);  where_97 = mul_3467 = None
    sub_800: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(sub_799, unsqueeze_2752);  sub_799 = unsqueeze_2752 = None
    mul_3468: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_800, unsqueeze_2758);  sub_800 = unsqueeze_2758 = None
    mul_3469: "f32[36]" = torch.ops.aten.mul.Tensor(sum_239, squeeze_619);  sum_239 = squeeze_619 = None
    convolution_backward_118 = torch.ops.aten.convolution_backward.default(mul_3468, relu_163, primals_619, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3468 = primals_619 = None
    getitem_1004: "f32[8, 36, 28, 28]" = convolution_backward_118[0]
    getitem_1005: "f32[36, 36, 3, 3]" = convolution_backward_118[1];  convolution_backward_118 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sub_801: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_205, unsqueeze_2761);  convolution_205 = unsqueeze_2761 = None
    mul_3470: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_96, sub_801)
    sum_241: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3470, [0, 2, 3]);  mul_3470 = None
    mul_3472: "f32[144]" = torch.ops.aten.mul.Tensor(sum_241, 0.002551020408163265)
    mul_3473: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_616, squeeze_616)
    mul_3474: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3472, mul_3473);  mul_3472 = mul_3473 = None
    unsqueeze_2765: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3474, 0);  mul_3474 = None
    unsqueeze_2766: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2765, 2);  unsqueeze_2765 = None
    unsqueeze_2767: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2766, 3);  unsqueeze_2766 = None
    mul_3475: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_616, primals_617);  primals_617 = None
    unsqueeze_2768: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3475, 0);  mul_3475 = None
    unsqueeze_2769: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2768, 2);  unsqueeze_2768 = None
    unsqueeze_2770: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2769, 3);  unsqueeze_2769 = None
    mul_3476: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_801, unsqueeze_2767);  sub_801 = unsqueeze_2767 = None
    sub_803: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_96, mul_3476);  mul_3476 = None
    sub_804: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_803, unsqueeze_2728);  sub_803 = unsqueeze_2728 = None
    mul_3477: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_804, unsqueeze_2770);  sub_804 = unsqueeze_2770 = None
    mul_3478: "f32[144]" = torch.ops.aten.mul.Tensor(sum_241, squeeze_616);  sum_241 = squeeze_616 = None
    convolution_backward_119 = torch.ops.aten.convolution_backward.default(mul_3477, relu_185, primals_616, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3477 = primals_616 = None
    getitem_1007: "f32[8, 18, 14, 14]" = convolution_backward_119[0]
    getitem_1008: "f32[144, 18, 3, 3]" = convolution_backward_119[1];  convolution_backward_119 = None
    le_98: "b8[8, 18, 14, 14]" = torch.ops.aten.le.Scalar(relu_185, 0);  relu_185 = None
    where_98: "f32[8, 18, 14, 14]" = torch.ops.aten.where.self(le_98, full_default, getitem_1007);  le_98 = getitem_1007 = None
    sum_242: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_98, [0, 2, 3])
    sub_805: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_204, unsqueeze_2773);  convolution_204 = unsqueeze_2773 = None
    mul_3479: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(where_98, sub_805)
    sum_243: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3479, [0, 2, 3]);  mul_3479 = None
    mul_3480: "f32[18]" = torch.ops.aten.mul.Tensor(sum_242, 0.0006377551020408163)
    unsqueeze_2774: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3480, 0);  mul_3480 = None
    unsqueeze_2775: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2774, 2);  unsqueeze_2774 = None
    unsqueeze_2776: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2775, 3);  unsqueeze_2775 = None
    mul_3481: "f32[18]" = torch.ops.aten.mul.Tensor(sum_243, 0.0006377551020408163)
    mul_3482: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_613, squeeze_613)
    mul_3483: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3481, mul_3482);  mul_3481 = mul_3482 = None
    unsqueeze_2777: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3483, 0);  mul_3483 = None
    unsqueeze_2778: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2777, 2);  unsqueeze_2777 = None
    unsqueeze_2779: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2778, 3);  unsqueeze_2778 = None
    mul_3484: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_613, primals_614);  primals_614 = None
    unsqueeze_2780: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3484, 0);  mul_3484 = None
    unsqueeze_2781: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2780, 2);  unsqueeze_2780 = None
    unsqueeze_2782: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2781, 3);  unsqueeze_2781 = None
    mul_3485: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_805, unsqueeze_2779);  sub_805 = unsqueeze_2779 = None
    sub_807: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(where_98, mul_3485);  where_98 = mul_3485 = None
    sub_808: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(sub_807, unsqueeze_2776);  sub_807 = unsqueeze_2776 = None
    mul_3486: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_808, unsqueeze_2782);  sub_808 = unsqueeze_2782 = None
    mul_3487: "f32[18]" = torch.ops.aten.mul.Tensor(sum_243, squeeze_613);  sum_243 = squeeze_613 = None
    convolution_backward_120 = torch.ops.aten.convolution_backward.default(mul_3486, relu_184, primals_613, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3486 = primals_613 = None
    getitem_1010: "f32[8, 18, 28, 28]" = convolution_backward_120[0]
    getitem_1011: "f32[18, 18, 3, 3]" = convolution_backward_120[1];  convolution_backward_120 = None
    le_99: "b8[8, 18, 28, 28]" = torch.ops.aten.le.Scalar(relu_184, 0);  relu_184 = None
    where_99: "f32[8, 18, 28, 28]" = torch.ops.aten.where.self(le_99, full_default, getitem_1010);  le_99 = getitem_1010 = None
    sum_244: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_99, [0, 2, 3])
    sub_809: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_203, unsqueeze_2785);  convolution_203 = unsqueeze_2785 = None
    mul_3488: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(where_99, sub_809)
    sum_245: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3488, [0, 2, 3]);  mul_3488 = None
    mul_3489: "f32[18]" = torch.ops.aten.mul.Tensor(sum_244, 0.00015943877551020407)
    unsqueeze_2786: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3489, 0);  mul_3489 = None
    unsqueeze_2787: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2786, 2);  unsqueeze_2786 = None
    unsqueeze_2788: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2787, 3);  unsqueeze_2787 = None
    mul_3490: "f32[18]" = torch.ops.aten.mul.Tensor(sum_245, 0.00015943877551020407)
    mul_3491: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_610, squeeze_610)
    mul_3492: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3490, mul_3491);  mul_3490 = mul_3491 = None
    unsqueeze_2789: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3492, 0);  mul_3492 = None
    unsqueeze_2790: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2789, 2);  unsqueeze_2789 = None
    unsqueeze_2791: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2790, 3);  unsqueeze_2790 = None
    mul_3493: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_610, primals_611);  primals_611 = None
    unsqueeze_2792: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3493, 0);  mul_3493 = None
    unsqueeze_2793: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2792, 2);  unsqueeze_2792 = None
    unsqueeze_2794: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2793, 3);  unsqueeze_2793 = None
    mul_3494: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_809, unsqueeze_2791);  sub_809 = unsqueeze_2791 = None
    sub_811: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(where_99, mul_3494);  where_99 = mul_3494 = None
    sub_812: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_811, unsqueeze_2788);  sub_811 = unsqueeze_2788 = None
    mul_3495: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_812, unsqueeze_2794);  sub_812 = unsqueeze_2794 = None
    mul_3496: "f32[18]" = torch.ops.aten.mul.Tensor(sum_245, squeeze_610);  sum_245 = squeeze_610 = None
    convolution_backward_121 = torch.ops.aten.convolution_backward.default(mul_3495, relu_155, primals_610, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3495 = primals_610 = None
    getitem_1013: "f32[8, 18, 56, 56]" = convolution_backward_121[0]
    getitem_1014: "f32[18, 18, 3, 3]" = convolution_backward_121[1];  convolution_backward_121 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_100: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_183, 0);  relu_183 = None
    where_100: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_100, full_default, add_1977);  le_100 = add_1977 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_12: "f32[8, 72, 7, 7]" = torch.ops.prims._unsafe_index_put_.default(full_default_21, [None, None, unsqueeze_830, convert_element_type_110], where_100, True);  full_default_21 = unsqueeze_830 = convert_element_type_110 = None
    sum_246: "f32[72]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_12, [0, 2, 3])
    sub_813: "f32[8, 72, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_202, unsqueeze_2797);  convolution_202 = unsqueeze_2797 = None
    mul_3497: "f32[8, 72, 7, 7]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_12, sub_813)
    sum_247: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3497, [0, 2, 3]);  mul_3497 = None
    mul_3498: "f32[72]" = torch.ops.aten.mul.Tensor(sum_246, 0.002551020408163265)
    unsqueeze_2798: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3498, 0);  mul_3498 = None
    unsqueeze_2799: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2798, 2);  unsqueeze_2798 = None
    unsqueeze_2800: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2799, 3);  unsqueeze_2799 = None
    mul_3499: "f32[72]" = torch.ops.aten.mul.Tensor(sum_247, 0.002551020408163265)
    mul_3500: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_607, squeeze_607)
    mul_3501: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3499, mul_3500);  mul_3499 = mul_3500 = None
    unsqueeze_2801: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3501, 0);  mul_3501 = None
    unsqueeze_2802: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2801, 2);  unsqueeze_2801 = None
    unsqueeze_2803: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2802, 3);  unsqueeze_2802 = None
    mul_3502: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_607, primals_608);  primals_608 = None
    unsqueeze_2804: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3502, 0);  mul_3502 = None
    unsqueeze_2805: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2804, 2);  unsqueeze_2804 = None
    unsqueeze_2806: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2805, 3);  unsqueeze_2805 = None
    mul_3503: "f32[8, 72, 7, 7]" = torch.ops.aten.mul.Tensor(sub_813, unsqueeze_2803);  sub_813 = unsqueeze_2803 = None
    sub_815: "f32[8, 72, 7, 7]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_12, mul_3503);  _unsafe_index_put_12 = mul_3503 = None
    sub_816: "f32[8, 72, 7, 7]" = torch.ops.aten.sub.Tensor(sub_815, unsqueeze_2800);  sub_815 = unsqueeze_2800 = None
    mul_3504: "f32[8, 72, 7, 7]" = torch.ops.aten.mul.Tensor(sub_816, unsqueeze_2806);  sub_816 = unsqueeze_2806 = None
    mul_3505: "f32[72]" = torch.ops.aten.mul.Tensor(sum_247, squeeze_607);  sum_247 = squeeze_607 = None
    convolution_backward_122 = torch.ops.aten.convolution_backward.default(mul_3504, relu_179, primals_607, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3504 = primals_607 = None
    getitem_1016: "f32[8, 144, 7, 7]" = convolution_backward_122[0]
    getitem_1017: "f32[72, 144, 1, 1]" = convolution_backward_122[1];  convolution_backward_122 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1986: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(where_96, getitem_1016);  where_96 = getitem_1016 = None
    add_1987: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(getitem_998, where_100);  getitem_998 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    sum_248: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_100, [0, 2, 3])
    sub_817: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_201, unsqueeze_2809);  convolution_201 = unsqueeze_2809 = None
    mul_3506: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_100, sub_817)
    sum_249: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3506, [0, 2, 3]);  mul_3506 = None
    mul_3507: "f32[72]" = torch.ops.aten.mul.Tensor(sum_248, 0.0006377551020408163)
    unsqueeze_2810: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3507, 0);  mul_3507 = None
    unsqueeze_2811: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2810, 2);  unsqueeze_2810 = None
    unsqueeze_2812: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2811, 3);  unsqueeze_2811 = None
    mul_3508: "f32[72]" = torch.ops.aten.mul.Tensor(sum_249, 0.0006377551020408163)
    mul_3509: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_604, squeeze_604)
    mul_3510: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3508, mul_3509);  mul_3508 = mul_3509 = None
    unsqueeze_2813: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3510, 0);  mul_3510 = None
    unsqueeze_2814: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2813, 2);  unsqueeze_2813 = None
    unsqueeze_2815: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2814, 3);  unsqueeze_2814 = None
    mul_3511: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_604, primals_605);  primals_605 = None
    unsqueeze_2816: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3511, 0);  mul_3511 = None
    unsqueeze_2817: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2816, 2);  unsqueeze_2816 = None
    unsqueeze_2818: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2817, 3);  unsqueeze_2817 = None
    mul_3512: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_817, unsqueeze_2815);  sub_817 = unsqueeze_2815 = None
    sub_819: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_100, mul_3512);  mul_3512 = None
    sub_820: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_819, unsqueeze_2812);  sub_819 = None
    mul_3513: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_820, unsqueeze_2818);  sub_820 = unsqueeze_2818 = None
    mul_3514: "f32[72]" = torch.ops.aten.mul.Tensor(sum_249, squeeze_604);  sum_249 = squeeze_604 = None
    convolution_backward_123 = torch.ops.aten.convolution_backward.default(mul_3513, relu_163, primals_604, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3513 = primals_604 = None
    getitem_1019: "f32[8, 36, 28, 28]" = convolution_backward_123[0]
    getitem_1020: "f32[72, 36, 3, 3]" = convolution_backward_123[1];  convolution_backward_123 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1988: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(getitem_1004, getitem_1019);  getitem_1004 = getitem_1019 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sub_821: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_200, unsqueeze_2821);  convolution_200 = unsqueeze_2821 = None
    mul_3515: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_100, sub_821)
    sum_251: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3515, [0, 2, 3]);  mul_3515 = None
    mul_3517: "f32[72]" = torch.ops.aten.mul.Tensor(sum_251, 0.0006377551020408163)
    mul_3518: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_601, squeeze_601)
    mul_3519: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3517, mul_3518);  mul_3517 = mul_3518 = None
    unsqueeze_2825: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3519, 0);  mul_3519 = None
    unsqueeze_2826: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2825, 2);  unsqueeze_2825 = None
    unsqueeze_2827: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2826, 3);  unsqueeze_2826 = None
    mul_3520: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_601, primals_602);  primals_602 = None
    unsqueeze_2828: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3520, 0);  mul_3520 = None
    unsqueeze_2829: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2828, 2);  unsqueeze_2828 = None
    unsqueeze_2830: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2829, 3);  unsqueeze_2829 = None
    mul_3521: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_821, unsqueeze_2827);  sub_821 = unsqueeze_2827 = None
    sub_823: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_100, mul_3521);  where_100 = mul_3521 = None
    sub_824: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_823, unsqueeze_2812);  sub_823 = unsqueeze_2812 = None
    mul_3522: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_824, unsqueeze_2830);  sub_824 = unsqueeze_2830 = None
    mul_3523: "f32[72]" = torch.ops.aten.mul.Tensor(sum_251, squeeze_601);  sum_251 = squeeze_601 = None
    convolution_backward_124 = torch.ops.aten.convolution_backward.default(mul_3522, relu_182, primals_601, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3522 = primals_601 = None
    getitem_1022: "f32[8, 18, 28, 28]" = convolution_backward_124[0]
    getitem_1023: "f32[72, 18, 3, 3]" = convolution_backward_124[1];  convolution_backward_124 = None
    le_101: "b8[8, 18, 28, 28]" = torch.ops.aten.le.Scalar(relu_182, 0);  relu_182 = None
    where_101: "f32[8, 18, 28, 28]" = torch.ops.aten.where.self(le_101, full_default, getitem_1022);  le_101 = getitem_1022 = None
    sum_252: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_101, [0, 2, 3])
    sub_825: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_199, unsqueeze_2833);  convolution_199 = unsqueeze_2833 = None
    mul_3524: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(where_101, sub_825)
    sum_253: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3524, [0, 2, 3]);  mul_3524 = None
    mul_3525: "f32[18]" = torch.ops.aten.mul.Tensor(sum_252, 0.00015943877551020407)
    unsqueeze_2834: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3525, 0);  mul_3525 = None
    unsqueeze_2835: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2834, 2);  unsqueeze_2834 = None
    unsqueeze_2836: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2835, 3);  unsqueeze_2835 = None
    mul_3526: "f32[18]" = torch.ops.aten.mul.Tensor(sum_253, 0.00015943877551020407)
    mul_3527: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_598, squeeze_598)
    mul_3528: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3526, mul_3527);  mul_3526 = mul_3527 = None
    unsqueeze_2837: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3528, 0);  mul_3528 = None
    unsqueeze_2838: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2837, 2);  unsqueeze_2837 = None
    unsqueeze_2839: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2838, 3);  unsqueeze_2838 = None
    mul_3529: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_598, primals_599);  primals_599 = None
    unsqueeze_2840: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3529, 0);  mul_3529 = None
    unsqueeze_2841: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2840, 2);  unsqueeze_2840 = None
    unsqueeze_2842: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2841, 3);  unsqueeze_2841 = None
    mul_3530: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_825, unsqueeze_2839);  sub_825 = unsqueeze_2839 = None
    sub_827: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(where_101, mul_3530);  where_101 = mul_3530 = None
    sub_828: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_827, unsqueeze_2836);  sub_827 = unsqueeze_2836 = None
    mul_3531: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_828, unsqueeze_2842);  sub_828 = unsqueeze_2842 = None
    mul_3532: "f32[18]" = torch.ops.aten.mul.Tensor(sum_253, squeeze_598);  sum_253 = squeeze_598 = None
    convolution_backward_125 = torch.ops.aten.convolution_backward.default(mul_3531, relu_155, primals_598, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3531 = primals_598 = None
    getitem_1025: "f32[8, 18, 56, 56]" = convolution_backward_125[0]
    getitem_1026: "f32[18, 18, 3, 3]" = convolution_backward_125[1];  convolution_backward_125 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    add_1989: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(getitem_1013, getitem_1025);  getitem_1013 = getitem_1025 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_102: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_181, 0);  relu_181 = None
    where_102: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_102, full_default, add_1981);  le_102 = add_1981 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_13: "f32[8, 36, 7, 7]" = torch.ops.prims._unsafe_index_put_.default(full_default_24, [None, None, unsqueeze_813, convert_element_type_104], where_102, True);  full_default_24 = unsqueeze_813 = convert_element_type_104 = None
    sum_254: "f32[36]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_13, [0, 2, 3])
    sub_829: "f32[8, 36, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_198, unsqueeze_2845);  convolution_198 = unsqueeze_2845 = None
    mul_3533: "f32[8, 36, 7, 7]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_13, sub_829)
    sum_255: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3533, [0, 2, 3]);  mul_3533 = None
    mul_3534: "f32[36]" = torch.ops.aten.mul.Tensor(sum_254, 0.002551020408163265)
    unsqueeze_2846: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3534, 0);  mul_3534 = None
    unsqueeze_2847: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2846, 2);  unsqueeze_2846 = None
    unsqueeze_2848: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2847, 3);  unsqueeze_2847 = None
    mul_3535: "f32[36]" = torch.ops.aten.mul.Tensor(sum_255, 0.002551020408163265)
    mul_3536: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_595, squeeze_595)
    mul_3537: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3535, mul_3536);  mul_3535 = mul_3536 = None
    unsqueeze_2849: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3537, 0);  mul_3537 = None
    unsqueeze_2850: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2849, 2);  unsqueeze_2849 = None
    unsqueeze_2851: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2850, 3);  unsqueeze_2850 = None
    mul_3538: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_595, primals_596);  primals_596 = None
    unsqueeze_2852: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3538, 0);  mul_3538 = None
    unsqueeze_2853: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2852, 2);  unsqueeze_2852 = None
    unsqueeze_2854: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2853, 3);  unsqueeze_2853 = None
    mul_3539: "f32[8, 36, 7, 7]" = torch.ops.aten.mul.Tensor(sub_829, unsqueeze_2851);  sub_829 = unsqueeze_2851 = None
    sub_831: "f32[8, 36, 7, 7]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_13, mul_3539);  _unsafe_index_put_13 = mul_3539 = None
    sub_832: "f32[8, 36, 7, 7]" = torch.ops.aten.sub.Tensor(sub_831, unsqueeze_2848);  sub_831 = unsqueeze_2848 = None
    mul_3540: "f32[8, 36, 7, 7]" = torch.ops.aten.mul.Tensor(sub_832, unsqueeze_2854);  sub_832 = unsqueeze_2854 = None
    mul_3541: "f32[36]" = torch.ops.aten.mul.Tensor(sum_255, squeeze_595);  sum_255 = squeeze_595 = None
    convolution_backward_126 = torch.ops.aten.convolution_backward.default(mul_3540, relu_179, primals_595, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3540 = primals_595 = None
    getitem_1028: "f32[8, 144, 7, 7]" = convolution_backward_126[0]
    getitem_1029: "f32[36, 144, 1, 1]" = convolution_backward_126[1];  convolution_backward_126 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1990: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(add_1986, getitem_1028);  add_1986 = getitem_1028 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_14: "f32[8, 36, 14, 14]" = torch.ops.aten._unsafe_index_put.default(full_default_25, [None, None, unsqueeze_259, convert_element_type_20], where_102, True)
    sum_256: "f32[36]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_14, [0, 2, 3])
    sub_833: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_197, unsqueeze_2857);  convolution_197 = unsqueeze_2857 = None
    mul_3542: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_14, sub_833)
    sum_257: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3542, [0, 2, 3]);  mul_3542 = None
    mul_3543: "f32[36]" = torch.ops.aten.mul.Tensor(sum_256, 0.0006377551020408163)
    unsqueeze_2858: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3543, 0);  mul_3543 = None
    unsqueeze_2859: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2858, 2);  unsqueeze_2858 = None
    unsqueeze_2860: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2859, 3);  unsqueeze_2859 = None
    mul_3544: "f32[36]" = torch.ops.aten.mul.Tensor(sum_257, 0.0006377551020408163)
    mul_3545: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_592, squeeze_592)
    mul_3546: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3544, mul_3545);  mul_3544 = mul_3545 = None
    unsqueeze_2861: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3546, 0);  mul_3546 = None
    unsqueeze_2862: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2861, 2);  unsqueeze_2861 = None
    unsqueeze_2863: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2862, 3);  unsqueeze_2862 = None
    mul_3547: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_592, primals_593);  primals_593 = None
    unsqueeze_2864: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3547, 0);  mul_3547 = None
    unsqueeze_2865: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2864, 2);  unsqueeze_2864 = None
    unsqueeze_2866: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2865, 3);  unsqueeze_2865 = None
    mul_3548: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_833, unsqueeze_2863);  sub_833 = unsqueeze_2863 = None
    sub_835: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_14, mul_3548);  _unsafe_index_put_14 = mul_3548 = None
    sub_836: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(sub_835, unsqueeze_2860);  sub_835 = unsqueeze_2860 = None
    mul_3549: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_836, unsqueeze_2866);  sub_836 = unsqueeze_2866 = None
    mul_3550: "f32[36]" = torch.ops.aten.mul.Tensor(sum_257, squeeze_592);  sum_257 = squeeze_592 = None
    convolution_backward_127 = torch.ops.aten.convolution_backward.default(mul_3549, relu_171, primals_592, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3549 = primals_592 = None
    getitem_1031: "f32[8, 72, 14, 14]" = convolution_backward_127[0]
    getitem_1032: "f32[36, 72, 1, 1]" = convolution_backward_127[1];  convolution_backward_127 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1991: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(add_1987, getitem_1031);  add_1987 = getitem_1031 = None
    add_1992: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(add_1988, where_102);  add_1988 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sum_258: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_102, [0, 2, 3])
    sub_837: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_196, unsqueeze_2869);  convolution_196 = unsqueeze_2869 = None
    mul_3551: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_102, sub_837)
    sum_259: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3551, [0, 2, 3]);  mul_3551 = None
    mul_3552: "f32[36]" = torch.ops.aten.mul.Tensor(sum_258, 0.00015943877551020407)
    unsqueeze_2870: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3552, 0);  mul_3552 = None
    unsqueeze_2871: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2870, 2);  unsqueeze_2870 = None
    unsqueeze_2872: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2871, 3);  unsqueeze_2871 = None
    mul_3553: "f32[36]" = torch.ops.aten.mul.Tensor(sum_259, 0.00015943877551020407)
    mul_3554: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_589, squeeze_589)
    mul_3555: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3553, mul_3554);  mul_3553 = mul_3554 = None
    unsqueeze_2873: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3555, 0);  mul_3555 = None
    unsqueeze_2874: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2873, 2);  unsqueeze_2873 = None
    unsqueeze_2875: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2874, 3);  unsqueeze_2874 = None
    mul_3556: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_589, primals_590);  primals_590 = None
    unsqueeze_2876: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3556, 0);  mul_3556 = None
    unsqueeze_2877: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2876, 2);  unsqueeze_2876 = None
    unsqueeze_2878: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2877, 3);  unsqueeze_2877 = None
    mul_3557: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_837, unsqueeze_2875);  sub_837 = unsqueeze_2875 = None
    sub_839: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_102, mul_3557);  where_102 = mul_3557 = None
    sub_840: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_839, unsqueeze_2872);  sub_839 = unsqueeze_2872 = None
    mul_3558: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_840, unsqueeze_2878);  sub_840 = unsqueeze_2878 = None
    mul_3559: "f32[36]" = torch.ops.aten.mul.Tensor(sum_259, squeeze_589);  sum_259 = squeeze_589 = None
    convolution_backward_128 = torch.ops.aten.convolution_backward.default(mul_3558, relu_155, primals_589, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3558 = primals_589 = None
    getitem_1034: "f32[8, 18, 56, 56]" = convolution_backward_128[0]
    getitem_1035: "f32[36, 18, 3, 3]" = convolution_backward_128[1];  convolution_backward_128 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    add_1993: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(add_1989, getitem_1034);  add_1989 = getitem_1034 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_103: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_180, 0);  relu_180 = None
    where_103: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_103, full_default, add_1985);  le_103 = add_1985 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_15: "f32[8, 18, 7, 7]" = torch.ops.prims._unsafe_index_put_.default(full_default_27, [None, None, unsqueeze_799, convert_element_type_92], where_103, True);  full_default_27 = unsqueeze_799 = convert_element_type_92 = None
    sum_260: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_15, [0, 2, 3])
    sub_841: "f32[8, 18, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_195, unsqueeze_2881);  convolution_195 = unsqueeze_2881 = None
    mul_3560: "f32[8, 18, 7, 7]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_15, sub_841)
    sum_261: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3560, [0, 2, 3]);  mul_3560 = None
    mul_3561: "f32[18]" = torch.ops.aten.mul.Tensor(sum_260, 0.002551020408163265)
    unsqueeze_2882: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3561, 0);  mul_3561 = None
    unsqueeze_2883: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2882, 2);  unsqueeze_2882 = None
    unsqueeze_2884: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2883, 3);  unsqueeze_2883 = None
    mul_3562: "f32[18]" = torch.ops.aten.mul.Tensor(sum_261, 0.002551020408163265)
    mul_3563: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_586, squeeze_586)
    mul_3564: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3562, mul_3563);  mul_3562 = mul_3563 = None
    unsqueeze_2885: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3564, 0);  mul_3564 = None
    unsqueeze_2886: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2885, 2);  unsqueeze_2885 = None
    unsqueeze_2887: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2886, 3);  unsqueeze_2886 = None
    mul_3565: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_586, primals_587);  primals_587 = None
    unsqueeze_2888: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3565, 0);  mul_3565 = None
    unsqueeze_2889: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2888, 2);  unsqueeze_2888 = None
    unsqueeze_2890: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2889, 3);  unsqueeze_2889 = None
    mul_3566: "f32[8, 18, 7, 7]" = torch.ops.aten.mul.Tensor(sub_841, unsqueeze_2887);  sub_841 = unsqueeze_2887 = None
    sub_843: "f32[8, 18, 7, 7]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_15, mul_3566);  _unsafe_index_put_15 = mul_3566 = None
    sub_844: "f32[8, 18, 7, 7]" = torch.ops.aten.sub.Tensor(sub_843, unsqueeze_2884);  sub_843 = unsqueeze_2884 = None
    mul_3567: "f32[8, 18, 7, 7]" = torch.ops.aten.mul.Tensor(sub_844, unsqueeze_2890);  sub_844 = unsqueeze_2890 = None
    mul_3568: "f32[18]" = torch.ops.aten.mul.Tensor(sum_261, squeeze_586);  sum_261 = squeeze_586 = None
    convolution_backward_129 = torch.ops.aten.convolution_backward.default(mul_3567, relu_179, primals_586, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3567 = primals_586 = None
    getitem_1037: "f32[8, 144, 7, 7]" = convolution_backward_129[0]
    getitem_1038: "f32[18, 144, 1, 1]" = convolution_backward_129[1];  convolution_backward_129 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1994: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(add_1990, getitem_1037);  add_1990 = getitem_1037 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_16: "f32[8, 18, 14, 14]" = torch.ops.aten._unsafe_index_put.default(full_default_28, [None, None, unsqueeze_250, convert_element_type_14], where_103, True)
    sum_262: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_16, [0, 2, 3])
    sub_845: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_194, unsqueeze_2893);  convolution_194 = unsqueeze_2893 = None
    mul_3569: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_16, sub_845)
    sum_263: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3569, [0, 2, 3]);  mul_3569 = None
    mul_3570: "f32[18]" = torch.ops.aten.mul.Tensor(sum_262, 0.0006377551020408163)
    unsqueeze_2894: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3570, 0);  mul_3570 = None
    unsqueeze_2895: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2894, 2);  unsqueeze_2894 = None
    unsqueeze_2896: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2895, 3);  unsqueeze_2895 = None
    mul_3571: "f32[18]" = torch.ops.aten.mul.Tensor(sum_263, 0.0006377551020408163)
    mul_3572: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_583, squeeze_583)
    mul_3573: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3571, mul_3572);  mul_3571 = mul_3572 = None
    unsqueeze_2897: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3573, 0);  mul_3573 = None
    unsqueeze_2898: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2897, 2);  unsqueeze_2897 = None
    unsqueeze_2899: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2898, 3);  unsqueeze_2898 = None
    mul_3574: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_583, primals_584);  primals_584 = None
    unsqueeze_2900: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3574, 0);  mul_3574 = None
    unsqueeze_2901: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2900, 2);  unsqueeze_2900 = None
    unsqueeze_2902: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2901, 3);  unsqueeze_2901 = None
    mul_3575: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_845, unsqueeze_2899);  sub_845 = unsqueeze_2899 = None
    sub_847: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_16, mul_3575);  _unsafe_index_put_16 = mul_3575 = None
    sub_848: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(sub_847, unsqueeze_2896);  sub_847 = unsqueeze_2896 = None
    mul_3576: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_848, unsqueeze_2902);  sub_848 = unsqueeze_2902 = None
    mul_3577: "f32[18]" = torch.ops.aten.mul.Tensor(sum_263, squeeze_583);  sum_263 = squeeze_583 = None
    convolution_backward_130 = torch.ops.aten.convolution_backward.default(mul_3576, relu_171, primals_583, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3576 = primals_583 = None
    getitem_1040: "f32[8, 72, 14, 14]" = convolution_backward_130[0]
    getitem_1041: "f32[18, 72, 1, 1]" = convolution_backward_130[1];  convolution_backward_130 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1995: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(add_1991, getitem_1040);  add_1991 = getitem_1040 = None
    add_1996: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(add_1993, where_103);  add_1993 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_17: "f32[8, 18, 28, 28]" = torch.ops.aten._unsafe_index_put.default(full_default_29, [None, None, unsqueeze_136, convert_element_type_2], where_103, True);  where_103 = None
    sum_264: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_17, [0, 2, 3])
    sub_849: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_193, unsqueeze_2905);  convolution_193 = unsqueeze_2905 = None
    mul_3578: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_17, sub_849)
    sum_265: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3578, [0, 2, 3]);  mul_3578 = None
    mul_3579: "f32[18]" = torch.ops.aten.mul.Tensor(sum_264, 0.00015943877551020407)
    unsqueeze_2906: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3579, 0);  mul_3579 = None
    unsqueeze_2907: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2906, 2);  unsqueeze_2906 = None
    unsqueeze_2908: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2907, 3);  unsqueeze_2907 = None
    mul_3580: "f32[18]" = torch.ops.aten.mul.Tensor(sum_265, 0.00015943877551020407)
    mul_3581: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_580, squeeze_580)
    mul_3582: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3580, mul_3581);  mul_3580 = mul_3581 = None
    unsqueeze_2909: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3582, 0);  mul_3582 = None
    unsqueeze_2910: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2909, 2);  unsqueeze_2909 = None
    unsqueeze_2911: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2910, 3);  unsqueeze_2910 = None
    mul_3583: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_580, primals_581);  primals_581 = None
    unsqueeze_2912: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3583, 0);  mul_3583 = None
    unsqueeze_2913: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2912, 2);  unsqueeze_2912 = None
    unsqueeze_2914: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2913, 3);  unsqueeze_2913 = None
    mul_3584: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_849, unsqueeze_2911);  sub_849 = unsqueeze_2911 = None
    sub_851: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_17, mul_3584);  _unsafe_index_put_17 = mul_3584 = None
    sub_852: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_851, unsqueeze_2908);  sub_851 = unsqueeze_2908 = None
    mul_3585: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_852, unsqueeze_2914);  sub_852 = unsqueeze_2914 = None
    mul_3586: "f32[18]" = torch.ops.aten.mul.Tensor(sum_265, squeeze_580);  sum_265 = squeeze_580 = None
    convolution_backward_131 = torch.ops.aten.convolution_backward.default(mul_3585, relu_163, primals_580, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3585 = primals_580 = None
    getitem_1043: "f32[8, 36, 28, 28]" = convolution_backward_131[0]
    getitem_1044: "f32[18, 36, 1, 1]" = convolution_backward_131[1];  convolution_backward_131 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_1997: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(add_1992, getitem_1043);  add_1992 = getitem_1043 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_104: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_179, 0);  relu_179 = None
    where_104: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_104, full_default, add_1994);  le_104 = add_1994 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_266: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_104, [0, 2, 3])
    sub_853: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_192, unsqueeze_2917);  convolution_192 = unsqueeze_2917 = None
    mul_3587: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_104, sub_853)
    sum_267: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3587, [0, 2, 3]);  mul_3587 = None
    mul_3588: "f32[144]" = torch.ops.aten.mul.Tensor(sum_266, 0.002551020408163265)
    unsqueeze_2918: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3588, 0);  mul_3588 = None
    unsqueeze_2919: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2918, 2);  unsqueeze_2918 = None
    unsqueeze_2920: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2919, 3);  unsqueeze_2919 = None
    mul_3589: "f32[144]" = torch.ops.aten.mul.Tensor(sum_267, 0.002551020408163265)
    mul_3590: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_577, squeeze_577)
    mul_3591: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3589, mul_3590);  mul_3589 = mul_3590 = None
    unsqueeze_2921: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3591, 0);  mul_3591 = None
    unsqueeze_2922: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2921, 2);  unsqueeze_2921 = None
    unsqueeze_2923: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2922, 3);  unsqueeze_2922 = None
    mul_3592: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_577, primals_578);  primals_578 = None
    unsqueeze_2924: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3592, 0);  mul_3592 = None
    unsqueeze_2925: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2924, 2);  unsqueeze_2924 = None
    unsqueeze_2926: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2925, 3);  unsqueeze_2925 = None
    mul_3593: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_853, unsqueeze_2923);  sub_853 = unsqueeze_2923 = None
    sub_855: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_104, mul_3593);  mul_3593 = None
    sub_856: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_855, unsqueeze_2920);  sub_855 = unsqueeze_2920 = None
    mul_3594: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_856, unsqueeze_2926);  sub_856 = unsqueeze_2926 = None
    mul_3595: "f32[144]" = torch.ops.aten.mul.Tensor(sum_267, squeeze_577);  sum_267 = squeeze_577 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_132 = torch.ops.aten.convolution_backward.default(mul_3594, relu_178, primals_577, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3594 = primals_577 = None
    getitem_1046: "f32[8, 144, 7, 7]" = convolution_backward_132[0]
    getitem_1047: "f32[144, 144, 3, 3]" = convolution_backward_132[1];  convolution_backward_132 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_105: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_178, 0);  relu_178 = None
    where_105: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_105, full_default, getitem_1046);  le_105 = getitem_1046 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_268: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_105, [0, 2, 3])
    sub_857: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_191, unsqueeze_2929);  convolution_191 = unsqueeze_2929 = None
    mul_3596: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_105, sub_857)
    sum_269: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3596, [0, 2, 3]);  mul_3596 = None
    mul_3597: "f32[144]" = torch.ops.aten.mul.Tensor(sum_268, 0.002551020408163265)
    unsqueeze_2930: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3597, 0);  mul_3597 = None
    unsqueeze_2931: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2930, 2);  unsqueeze_2930 = None
    unsqueeze_2932: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2931, 3);  unsqueeze_2931 = None
    mul_3598: "f32[144]" = torch.ops.aten.mul.Tensor(sum_269, 0.002551020408163265)
    mul_3599: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_574, squeeze_574)
    mul_3600: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3598, mul_3599);  mul_3598 = mul_3599 = None
    unsqueeze_2933: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3600, 0);  mul_3600 = None
    unsqueeze_2934: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2933, 2);  unsqueeze_2933 = None
    unsqueeze_2935: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2934, 3);  unsqueeze_2934 = None
    mul_3601: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_574, primals_575);  primals_575 = None
    unsqueeze_2936: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3601, 0);  mul_3601 = None
    unsqueeze_2937: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2936, 2);  unsqueeze_2936 = None
    unsqueeze_2938: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2937, 3);  unsqueeze_2937 = None
    mul_3602: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_857, unsqueeze_2935);  sub_857 = unsqueeze_2935 = None
    sub_859: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_105, mul_3602);  where_105 = mul_3602 = None
    sub_860: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_859, unsqueeze_2932);  sub_859 = unsqueeze_2932 = None
    mul_3603: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_860, unsqueeze_2938);  sub_860 = unsqueeze_2938 = None
    mul_3604: "f32[144]" = torch.ops.aten.mul.Tensor(sum_269, squeeze_574);  sum_269 = squeeze_574 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_133 = torch.ops.aten.convolution_backward.default(mul_3603, relu_177, primals_574, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3603 = primals_574 = None
    getitem_1049: "f32[8, 144, 7, 7]" = convolution_backward_133[0]
    getitem_1050: "f32[144, 144, 3, 3]" = convolution_backward_133[1];  convolution_backward_133 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1998: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(where_104, getitem_1049);  where_104 = getitem_1049 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_106: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_177, 0);  relu_177 = None
    where_106: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_106, full_default, add_1998);  le_106 = add_1998 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_270: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_106, [0, 2, 3])
    sub_861: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_190, unsqueeze_2941);  convolution_190 = unsqueeze_2941 = None
    mul_3605: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_106, sub_861)
    sum_271: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3605, [0, 2, 3]);  mul_3605 = None
    mul_3606: "f32[144]" = torch.ops.aten.mul.Tensor(sum_270, 0.002551020408163265)
    unsqueeze_2942: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3606, 0);  mul_3606 = None
    unsqueeze_2943: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2942, 2);  unsqueeze_2942 = None
    unsqueeze_2944: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2943, 3);  unsqueeze_2943 = None
    mul_3607: "f32[144]" = torch.ops.aten.mul.Tensor(sum_271, 0.002551020408163265)
    mul_3608: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_571, squeeze_571)
    mul_3609: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3607, mul_3608);  mul_3607 = mul_3608 = None
    unsqueeze_2945: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3609, 0);  mul_3609 = None
    unsqueeze_2946: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2945, 2);  unsqueeze_2945 = None
    unsqueeze_2947: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2946, 3);  unsqueeze_2946 = None
    mul_3610: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_571, primals_572);  primals_572 = None
    unsqueeze_2948: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3610, 0);  mul_3610 = None
    unsqueeze_2949: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2948, 2);  unsqueeze_2948 = None
    unsqueeze_2950: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2949, 3);  unsqueeze_2949 = None
    mul_3611: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_861, unsqueeze_2947);  sub_861 = unsqueeze_2947 = None
    sub_863: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_106, mul_3611);  mul_3611 = None
    sub_864: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_863, unsqueeze_2944);  sub_863 = unsqueeze_2944 = None
    mul_3612: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_864, unsqueeze_2950);  sub_864 = unsqueeze_2950 = None
    mul_3613: "f32[144]" = torch.ops.aten.mul.Tensor(sum_271, squeeze_571);  sum_271 = squeeze_571 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_134 = torch.ops.aten.convolution_backward.default(mul_3612, relu_176, primals_571, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3612 = primals_571 = None
    getitem_1052: "f32[8, 144, 7, 7]" = convolution_backward_134[0]
    getitem_1053: "f32[144, 144, 3, 3]" = convolution_backward_134[1];  convolution_backward_134 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_107: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_176, 0);  relu_176 = None
    where_107: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_107, full_default, getitem_1052);  le_107 = getitem_1052 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_272: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_107, [0, 2, 3])
    sub_865: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_189, unsqueeze_2953);  convolution_189 = unsqueeze_2953 = None
    mul_3614: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_107, sub_865)
    sum_273: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3614, [0, 2, 3]);  mul_3614 = None
    mul_3615: "f32[144]" = torch.ops.aten.mul.Tensor(sum_272, 0.002551020408163265)
    unsqueeze_2954: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3615, 0);  mul_3615 = None
    unsqueeze_2955: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2954, 2);  unsqueeze_2954 = None
    unsqueeze_2956: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2955, 3);  unsqueeze_2955 = None
    mul_3616: "f32[144]" = torch.ops.aten.mul.Tensor(sum_273, 0.002551020408163265)
    mul_3617: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_568, squeeze_568)
    mul_3618: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3616, mul_3617);  mul_3616 = mul_3617 = None
    unsqueeze_2957: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3618, 0);  mul_3618 = None
    unsqueeze_2958: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2957, 2);  unsqueeze_2957 = None
    unsqueeze_2959: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2958, 3);  unsqueeze_2958 = None
    mul_3619: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_568, primals_569);  primals_569 = None
    unsqueeze_2960: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3619, 0);  mul_3619 = None
    unsqueeze_2961: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2960, 2);  unsqueeze_2960 = None
    unsqueeze_2962: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2961, 3);  unsqueeze_2961 = None
    mul_3620: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_865, unsqueeze_2959);  sub_865 = unsqueeze_2959 = None
    sub_867: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_107, mul_3620);  where_107 = mul_3620 = None
    sub_868: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_867, unsqueeze_2956);  sub_867 = unsqueeze_2956 = None
    mul_3621: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_868, unsqueeze_2962);  sub_868 = unsqueeze_2962 = None
    mul_3622: "f32[144]" = torch.ops.aten.mul.Tensor(sum_273, squeeze_568);  sum_273 = squeeze_568 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_135 = torch.ops.aten.convolution_backward.default(mul_3621, relu_175, primals_568, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3621 = primals_568 = None
    getitem_1055: "f32[8, 144, 7, 7]" = convolution_backward_135[0]
    getitem_1056: "f32[144, 144, 3, 3]" = convolution_backward_135[1];  convolution_backward_135 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_1999: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(where_106, getitem_1055);  where_106 = getitem_1055 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_108: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_175, 0);  relu_175 = None
    where_108: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_108, full_default, add_1999);  le_108 = add_1999 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_274: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_108, [0, 2, 3])
    sub_869: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_188, unsqueeze_2965);  convolution_188 = unsqueeze_2965 = None
    mul_3623: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_108, sub_869)
    sum_275: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3623, [0, 2, 3]);  mul_3623 = None
    mul_3624: "f32[144]" = torch.ops.aten.mul.Tensor(sum_274, 0.002551020408163265)
    unsqueeze_2966: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3624, 0);  mul_3624 = None
    unsqueeze_2967: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2966, 2);  unsqueeze_2966 = None
    unsqueeze_2968: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2967, 3);  unsqueeze_2967 = None
    mul_3625: "f32[144]" = torch.ops.aten.mul.Tensor(sum_275, 0.002551020408163265)
    mul_3626: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_565, squeeze_565)
    mul_3627: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3625, mul_3626);  mul_3625 = mul_3626 = None
    unsqueeze_2969: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3627, 0);  mul_3627 = None
    unsqueeze_2970: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2969, 2);  unsqueeze_2969 = None
    unsqueeze_2971: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2970, 3);  unsqueeze_2970 = None
    mul_3628: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_565, primals_566);  primals_566 = None
    unsqueeze_2972: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3628, 0);  mul_3628 = None
    unsqueeze_2973: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2972, 2);  unsqueeze_2972 = None
    unsqueeze_2974: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2973, 3);  unsqueeze_2973 = None
    mul_3629: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_869, unsqueeze_2971);  sub_869 = unsqueeze_2971 = None
    sub_871: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_108, mul_3629);  mul_3629 = None
    sub_872: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_871, unsqueeze_2968);  sub_871 = unsqueeze_2968 = None
    mul_3630: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_872, unsqueeze_2974);  sub_872 = unsqueeze_2974 = None
    mul_3631: "f32[144]" = torch.ops.aten.mul.Tensor(sum_275, squeeze_565);  sum_275 = squeeze_565 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_136 = torch.ops.aten.convolution_backward.default(mul_3630, relu_174, primals_565, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3630 = primals_565 = None
    getitem_1058: "f32[8, 144, 7, 7]" = convolution_backward_136[0]
    getitem_1059: "f32[144, 144, 3, 3]" = convolution_backward_136[1];  convolution_backward_136 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_109: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_174, 0);  relu_174 = None
    where_109: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_109, full_default, getitem_1058);  le_109 = getitem_1058 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_276: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_109, [0, 2, 3])
    sub_873: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_187, unsqueeze_2977);  convolution_187 = unsqueeze_2977 = None
    mul_3632: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_109, sub_873)
    sum_277: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3632, [0, 2, 3]);  mul_3632 = None
    mul_3633: "f32[144]" = torch.ops.aten.mul.Tensor(sum_276, 0.002551020408163265)
    unsqueeze_2978: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3633, 0);  mul_3633 = None
    unsqueeze_2979: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2978, 2);  unsqueeze_2978 = None
    unsqueeze_2980: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2979, 3);  unsqueeze_2979 = None
    mul_3634: "f32[144]" = torch.ops.aten.mul.Tensor(sum_277, 0.002551020408163265)
    mul_3635: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_562, squeeze_562)
    mul_3636: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3634, mul_3635);  mul_3634 = mul_3635 = None
    unsqueeze_2981: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3636, 0);  mul_3636 = None
    unsqueeze_2982: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2981, 2);  unsqueeze_2981 = None
    unsqueeze_2983: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2982, 3);  unsqueeze_2982 = None
    mul_3637: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_562, primals_563);  primals_563 = None
    unsqueeze_2984: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3637, 0);  mul_3637 = None
    unsqueeze_2985: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2984, 2);  unsqueeze_2984 = None
    unsqueeze_2986: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2985, 3);  unsqueeze_2985 = None
    mul_3638: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_873, unsqueeze_2983);  sub_873 = unsqueeze_2983 = None
    sub_875: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_109, mul_3638);  where_109 = mul_3638 = None
    sub_876: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_875, unsqueeze_2980);  sub_875 = unsqueeze_2980 = None
    mul_3639: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_876, unsqueeze_2986);  sub_876 = unsqueeze_2986 = None
    mul_3640: "f32[144]" = torch.ops.aten.mul.Tensor(sum_277, squeeze_562);  sum_277 = squeeze_562 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_137 = torch.ops.aten.convolution_backward.default(mul_3639, relu_173, primals_562, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3639 = primals_562 = None
    getitem_1061: "f32[8, 144, 7, 7]" = convolution_backward_137[0]
    getitem_1062: "f32[144, 144, 3, 3]" = convolution_backward_137[1];  convolution_backward_137 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2000: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(where_108, getitem_1061);  where_108 = getitem_1061 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_110: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_173, 0);  relu_173 = None
    where_110: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_110, full_default, add_2000);  le_110 = add_2000 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_278: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_110, [0, 2, 3])
    sub_877: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_186, unsqueeze_2989);  convolution_186 = unsqueeze_2989 = None
    mul_3641: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_110, sub_877)
    sum_279: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3641, [0, 2, 3]);  mul_3641 = None
    mul_3642: "f32[144]" = torch.ops.aten.mul.Tensor(sum_278, 0.002551020408163265)
    unsqueeze_2990: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3642, 0);  mul_3642 = None
    unsqueeze_2991: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2990, 2);  unsqueeze_2990 = None
    unsqueeze_2992: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2991, 3);  unsqueeze_2991 = None
    mul_3643: "f32[144]" = torch.ops.aten.mul.Tensor(sum_279, 0.002551020408163265)
    mul_3644: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_559, squeeze_559)
    mul_3645: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3643, mul_3644);  mul_3643 = mul_3644 = None
    unsqueeze_2993: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3645, 0);  mul_3645 = None
    unsqueeze_2994: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2993, 2);  unsqueeze_2993 = None
    unsqueeze_2995: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2994, 3);  unsqueeze_2994 = None
    mul_3646: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_559, primals_560);  primals_560 = None
    unsqueeze_2996: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3646, 0);  mul_3646 = None
    unsqueeze_2997: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2996, 2);  unsqueeze_2996 = None
    unsqueeze_2998: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_2997, 3);  unsqueeze_2997 = None
    mul_3647: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_877, unsqueeze_2995);  sub_877 = unsqueeze_2995 = None
    sub_879: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_110, mul_3647);  mul_3647 = None
    sub_880: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_879, unsqueeze_2992);  sub_879 = unsqueeze_2992 = None
    mul_3648: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_880, unsqueeze_2998);  sub_880 = unsqueeze_2998 = None
    mul_3649: "f32[144]" = torch.ops.aten.mul.Tensor(sum_279, squeeze_559);  sum_279 = squeeze_559 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_138 = torch.ops.aten.convolution_backward.default(mul_3648, relu_172, primals_559, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3648 = primals_559 = None
    getitem_1064: "f32[8, 144, 7, 7]" = convolution_backward_138[0]
    getitem_1065: "f32[144, 144, 3, 3]" = convolution_backward_138[1];  convolution_backward_138 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_111: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_172, 0);  relu_172 = None
    where_111: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_111, full_default, getitem_1064);  le_111 = getitem_1064 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_280: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_111, [0, 2, 3])
    sub_881: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_185, unsqueeze_3001);  convolution_185 = unsqueeze_3001 = None
    mul_3650: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_111, sub_881)
    sum_281: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3650, [0, 2, 3]);  mul_3650 = None
    mul_3651: "f32[144]" = torch.ops.aten.mul.Tensor(sum_280, 0.002551020408163265)
    unsqueeze_3002: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3651, 0);  mul_3651 = None
    unsqueeze_3003: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3002, 2);  unsqueeze_3002 = None
    unsqueeze_3004: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3003, 3);  unsqueeze_3003 = None
    mul_3652: "f32[144]" = torch.ops.aten.mul.Tensor(sum_281, 0.002551020408163265)
    mul_3653: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_556, squeeze_556)
    mul_3654: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3652, mul_3653);  mul_3652 = mul_3653 = None
    unsqueeze_3005: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3654, 0);  mul_3654 = None
    unsqueeze_3006: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3005, 2);  unsqueeze_3005 = None
    unsqueeze_3007: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3006, 3);  unsqueeze_3006 = None
    mul_3655: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_556, primals_557);  primals_557 = None
    unsqueeze_3008: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3655, 0);  mul_3655 = None
    unsqueeze_3009: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3008, 2);  unsqueeze_3008 = None
    unsqueeze_3010: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3009, 3);  unsqueeze_3009 = None
    mul_3656: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_881, unsqueeze_3007);  sub_881 = unsqueeze_3007 = None
    sub_883: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_111, mul_3656);  where_111 = mul_3656 = None
    sub_884: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_883, unsqueeze_3004);  sub_883 = unsqueeze_3004 = None
    mul_3657: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_884, unsqueeze_3010);  sub_884 = unsqueeze_3010 = None
    mul_3658: "f32[144]" = torch.ops.aten.mul.Tensor(sum_281, squeeze_556);  sum_281 = squeeze_556 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_139 = torch.ops.aten.convolution_backward.default(mul_3657, relu_147, primals_556, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3657 = primals_556 = None
    getitem_1067: "f32[8, 144, 7, 7]" = convolution_backward_139[0]
    getitem_1068: "f32[144, 144, 3, 3]" = convolution_backward_139[1];  convolution_backward_139 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2001: "f32[8, 144, 7, 7]" = torch.ops.aten.add.Tensor(where_110, getitem_1067);  where_110 = getitem_1067 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_112: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_171, 0);  relu_171 = None
    where_112: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_112, full_default, add_1995);  le_112 = add_1995 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_282: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_112, [0, 2, 3])
    sub_885: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_184, unsqueeze_3013);  convolution_184 = unsqueeze_3013 = None
    mul_3659: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_112, sub_885)
    sum_283: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3659, [0, 2, 3]);  mul_3659 = None
    mul_3660: "f32[72]" = torch.ops.aten.mul.Tensor(sum_282, 0.0006377551020408163)
    unsqueeze_3014: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3660, 0);  mul_3660 = None
    unsqueeze_3015: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3014, 2);  unsqueeze_3014 = None
    unsqueeze_3016: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3015, 3);  unsqueeze_3015 = None
    mul_3661: "f32[72]" = torch.ops.aten.mul.Tensor(sum_283, 0.0006377551020408163)
    mul_3662: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_553, squeeze_553)
    mul_3663: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3661, mul_3662);  mul_3661 = mul_3662 = None
    unsqueeze_3017: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3663, 0);  mul_3663 = None
    unsqueeze_3018: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3017, 2);  unsqueeze_3017 = None
    unsqueeze_3019: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3018, 3);  unsqueeze_3018 = None
    mul_3664: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_553, primals_554);  primals_554 = None
    unsqueeze_3020: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3664, 0);  mul_3664 = None
    unsqueeze_3021: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3020, 2);  unsqueeze_3020 = None
    unsqueeze_3022: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3021, 3);  unsqueeze_3021 = None
    mul_3665: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_885, unsqueeze_3019);  sub_885 = unsqueeze_3019 = None
    sub_887: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_112, mul_3665);  mul_3665 = None
    sub_888: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_887, unsqueeze_3016);  sub_887 = unsqueeze_3016 = None
    mul_3666: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_888, unsqueeze_3022);  sub_888 = unsqueeze_3022 = None
    mul_3667: "f32[72]" = torch.ops.aten.mul.Tensor(sum_283, squeeze_553);  sum_283 = squeeze_553 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_140 = torch.ops.aten.convolution_backward.default(mul_3666, relu_170, primals_553, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3666 = primals_553 = None
    getitem_1070: "f32[8, 72, 14, 14]" = convolution_backward_140[0]
    getitem_1071: "f32[72, 72, 3, 3]" = convolution_backward_140[1];  convolution_backward_140 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_113: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_170, 0);  relu_170 = None
    where_113: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_113, full_default, getitem_1070);  le_113 = getitem_1070 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_284: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_113, [0, 2, 3])
    sub_889: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_183, unsqueeze_3025);  convolution_183 = unsqueeze_3025 = None
    mul_3668: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_113, sub_889)
    sum_285: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3668, [0, 2, 3]);  mul_3668 = None
    mul_3669: "f32[72]" = torch.ops.aten.mul.Tensor(sum_284, 0.0006377551020408163)
    unsqueeze_3026: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3669, 0);  mul_3669 = None
    unsqueeze_3027: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3026, 2);  unsqueeze_3026 = None
    unsqueeze_3028: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3027, 3);  unsqueeze_3027 = None
    mul_3670: "f32[72]" = torch.ops.aten.mul.Tensor(sum_285, 0.0006377551020408163)
    mul_3671: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_550, squeeze_550)
    mul_3672: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3670, mul_3671);  mul_3670 = mul_3671 = None
    unsqueeze_3029: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3672, 0);  mul_3672 = None
    unsqueeze_3030: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3029, 2);  unsqueeze_3029 = None
    unsqueeze_3031: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3030, 3);  unsqueeze_3030 = None
    mul_3673: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_550, primals_551);  primals_551 = None
    unsqueeze_3032: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3673, 0);  mul_3673 = None
    unsqueeze_3033: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3032, 2);  unsqueeze_3032 = None
    unsqueeze_3034: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3033, 3);  unsqueeze_3033 = None
    mul_3674: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_889, unsqueeze_3031);  sub_889 = unsqueeze_3031 = None
    sub_891: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_113, mul_3674);  where_113 = mul_3674 = None
    sub_892: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_891, unsqueeze_3028);  sub_891 = unsqueeze_3028 = None
    mul_3675: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_892, unsqueeze_3034);  sub_892 = unsqueeze_3034 = None
    mul_3676: "f32[72]" = torch.ops.aten.mul.Tensor(sum_285, squeeze_550);  sum_285 = squeeze_550 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_141 = torch.ops.aten.convolution_backward.default(mul_3675, relu_169, primals_550, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3675 = primals_550 = None
    getitem_1073: "f32[8, 72, 14, 14]" = convolution_backward_141[0]
    getitem_1074: "f32[72, 72, 3, 3]" = convolution_backward_141[1];  convolution_backward_141 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2002: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_112, getitem_1073);  where_112 = getitem_1073 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_114: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_169, 0);  relu_169 = None
    where_114: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_114, full_default, add_2002);  le_114 = add_2002 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_286: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_114, [0, 2, 3])
    sub_893: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_182, unsqueeze_3037);  convolution_182 = unsqueeze_3037 = None
    mul_3677: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_114, sub_893)
    sum_287: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3677, [0, 2, 3]);  mul_3677 = None
    mul_3678: "f32[72]" = torch.ops.aten.mul.Tensor(sum_286, 0.0006377551020408163)
    unsqueeze_3038: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3678, 0);  mul_3678 = None
    unsqueeze_3039: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3038, 2);  unsqueeze_3038 = None
    unsqueeze_3040: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3039, 3);  unsqueeze_3039 = None
    mul_3679: "f32[72]" = torch.ops.aten.mul.Tensor(sum_287, 0.0006377551020408163)
    mul_3680: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_547, squeeze_547)
    mul_3681: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3679, mul_3680);  mul_3679 = mul_3680 = None
    unsqueeze_3041: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3681, 0);  mul_3681 = None
    unsqueeze_3042: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3041, 2);  unsqueeze_3041 = None
    unsqueeze_3043: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3042, 3);  unsqueeze_3042 = None
    mul_3682: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_547, primals_548);  primals_548 = None
    unsqueeze_3044: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3682, 0);  mul_3682 = None
    unsqueeze_3045: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3044, 2);  unsqueeze_3044 = None
    unsqueeze_3046: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3045, 3);  unsqueeze_3045 = None
    mul_3683: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_893, unsqueeze_3043);  sub_893 = unsqueeze_3043 = None
    sub_895: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_114, mul_3683);  mul_3683 = None
    sub_896: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_895, unsqueeze_3040);  sub_895 = unsqueeze_3040 = None
    mul_3684: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_896, unsqueeze_3046);  sub_896 = unsqueeze_3046 = None
    mul_3685: "f32[72]" = torch.ops.aten.mul.Tensor(sum_287, squeeze_547);  sum_287 = squeeze_547 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_142 = torch.ops.aten.convolution_backward.default(mul_3684, relu_168, primals_547, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3684 = primals_547 = None
    getitem_1076: "f32[8, 72, 14, 14]" = convolution_backward_142[0]
    getitem_1077: "f32[72, 72, 3, 3]" = convolution_backward_142[1];  convolution_backward_142 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_115: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_168, 0);  relu_168 = None
    where_115: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_115, full_default, getitem_1076);  le_115 = getitem_1076 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_288: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_115, [0, 2, 3])
    sub_897: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_181, unsqueeze_3049);  convolution_181 = unsqueeze_3049 = None
    mul_3686: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_115, sub_897)
    sum_289: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3686, [0, 2, 3]);  mul_3686 = None
    mul_3687: "f32[72]" = torch.ops.aten.mul.Tensor(sum_288, 0.0006377551020408163)
    unsqueeze_3050: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3687, 0);  mul_3687 = None
    unsqueeze_3051: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3050, 2);  unsqueeze_3050 = None
    unsqueeze_3052: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3051, 3);  unsqueeze_3051 = None
    mul_3688: "f32[72]" = torch.ops.aten.mul.Tensor(sum_289, 0.0006377551020408163)
    mul_3689: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_544, squeeze_544)
    mul_3690: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3688, mul_3689);  mul_3688 = mul_3689 = None
    unsqueeze_3053: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3690, 0);  mul_3690 = None
    unsqueeze_3054: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3053, 2);  unsqueeze_3053 = None
    unsqueeze_3055: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3054, 3);  unsqueeze_3054 = None
    mul_3691: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_544, primals_545);  primals_545 = None
    unsqueeze_3056: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3691, 0);  mul_3691 = None
    unsqueeze_3057: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3056, 2);  unsqueeze_3056 = None
    unsqueeze_3058: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3057, 3);  unsqueeze_3057 = None
    mul_3692: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_897, unsqueeze_3055);  sub_897 = unsqueeze_3055 = None
    sub_899: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_115, mul_3692);  where_115 = mul_3692 = None
    sub_900: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_899, unsqueeze_3052);  sub_899 = unsqueeze_3052 = None
    mul_3693: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_900, unsqueeze_3058);  sub_900 = unsqueeze_3058 = None
    mul_3694: "f32[72]" = torch.ops.aten.mul.Tensor(sum_289, squeeze_544);  sum_289 = squeeze_544 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_143 = torch.ops.aten.convolution_backward.default(mul_3693, relu_167, primals_544, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3693 = primals_544 = None
    getitem_1079: "f32[8, 72, 14, 14]" = convolution_backward_143[0]
    getitem_1080: "f32[72, 72, 3, 3]" = convolution_backward_143[1];  convolution_backward_143 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2003: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_114, getitem_1079);  where_114 = getitem_1079 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_116: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_167, 0);  relu_167 = None
    where_116: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_116, full_default, add_2003);  le_116 = add_2003 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_290: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_116, [0, 2, 3])
    sub_901: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_180, unsqueeze_3061);  convolution_180 = unsqueeze_3061 = None
    mul_3695: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_116, sub_901)
    sum_291: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3695, [0, 2, 3]);  mul_3695 = None
    mul_3696: "f32[72]" = torch.ops.aten.mul.Tensor(sum_290, 0.0006377551020408163)
    unsqueeze_3062: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3696, 0);  mul_3696 = None
    unsqueeze_3063: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3062, 2);  unsqueeze_3062 = None
    unsqueeze_3064: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3063, 3);  unsqueeze_3063 = None
    mul_3697: "f32[72]" = torch.ops.aten.mul.Tensor(sum_291, 0.0006377551020408163)
    mul_3698: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_541, squeeze_541)
    mul_3699: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3697, mul_3698);  mul_3697 = mul_3698 = None
    unsqueeze_3065: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3699, 0);  mul_3699 = None
    unsqueeze_3066: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3065, 2);  unsqueeze_3065 = None
    unsqueeze_3067: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3066, 3);  unsqueeze_3066 = None
    mul_3700: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_541, primals_542);  primals_542 = None
    unsqueeze_3068: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3700, 0);  mul_3700 = None
    unsqueeze_3069: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3068, 2);  unsqueeze_3068 = None
    unsqueeze_3070: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3069, 3);  unsqueeze_3069 = None
    mul_3701: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_901, unsqueeze_3067);  sub_901 = unsqueeze_3067 = None
    sub_903: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_116, mul_3701);  mul_3701 = None
    sub_904: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_903, unsqueeze_3064);  sub_903 = unsqueeze_3064 = None
    mul_3702: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_904, unsqueeze_3070);  sub_904 = unsqueeze_3070 = None
    mul_3703: "f32[72]" = torch.ops.aten.mul.Tensor(sum_291, squeeze_541);  sum_291 = squeeze_541 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_144 = torch.ops.aten.convolution_backward.default(mul_3702, relu_166, primals_541, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3702 = primals_541 = None
    getitem_1082: "f32[8, 72, 14, 14]" = convolution_backward_144[0]
    getitem_1083: "f32[72, 72, 3, 3]" = convolution_backward_144[1];  convolution_backward_144 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_117: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_166, 0);  relu_166 = None
    where_117: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_117, full_default, getitem_1082);  le_117 = getitem_1082 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_292: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_117, [0, 2, 3])
    sub_905: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_179, unsqueeze_3073);  convolution_179 = unsqueeze_3073 = None
    mul_3704: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_117, sub_905)
    sum_293: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3704, [0, 2, 3]);  mul_3704 = None
    mul_3705: "f32[72]" = torch.ops.aten.mul.Tensor(sum_292, 0.0006377551020408163)
    unsqueeze_3074: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3705, 0);  mul_3705 = None
    unsqueeze_3075: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3074, 2);  unsqueeze_3074 = None
    unsqueeze_3076: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3075, 3);  unsqueeze_3075 = None
    mul_3706: "f32[72]" = torch.ops.aten.mul.Tensor(sum_293, 0.0006377551020408163)
    mul_3707: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_538, squeeze_538)
    mul_3708: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3706, mul_3707);  mul_3706 = mul_3707 = None
    unsqueeze_3077: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3708, 0);  mul_3708 = None
    unsqueeze_3078: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3077, 2);  unsqueeze_3077 = None
    unsqueeze_3079: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3078, 3);  unsqueeze_3078 = None
    mul_3709: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_538, primals_539);  primals_539 = None
    unsqueeze_3080: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3709, 0);  mul_3709 = None
    unsqueeze_3081: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3080, 2);  unsqueeze_3080 = None
    unsqueeze_3082: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3081, 3);  unsqueeze_3081 = None
    mul_3710: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_905, unsqueeze_3079);  sub_905 = unsqueeze_3079 = None
    sub_907: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_117, mul_3710);  where_117 = mul_3710 = None
    sub_908: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_907, unsqueeze_3076);  sub_907 = unsqueeze_3076 = None
    mul_3711: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_908, unsqueeze_3082);  sub_908 = unsqueeze_3082 = None
    mul_3712: "f32[72]" = torch.ops.aten.mul.Tensor(sum_293, squeeze_538);  sum_293 = squeeze_538 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_145 = torch.ops.aten.convolution_backward.default(mul_3711, relu_165, primals_538, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3711 = primals_538 = None
    getitem_1085: "f32[8, 72, 14, 14]" = convolution_backward_145[0]
    getitem_1086: "f32[72, 72, 3, 3]" = convolution_backward_145[1];  convolution_backward_145 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2004: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_116, getitem_1085);  where_116 = getitem_1085 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_118: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_165, 0);  relu_165 = None
    where_118: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_118, full_default, add_2004);  le_118 = add_2004 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_294: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_118, [0, 2, 3])
    sub_909: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_178, unsqueeze_3085);  convolution_178 = unsqueeze_3085 = None
    mul_3713: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_118, sub_909)
    sum_295: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3713, [0, 2, 3]);  mul_3713 = None
    mul_3714: "f32[72]" = torch.ops.aten.mul.Tensor(sum_294, 0.0006377551020408163)
    unsqueeze_3086: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3714, 0);  mul_3714 = None
    unsqueeze_3087: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3086, 2);  unsqueeze_3086 = None
    unsqueeze_3088: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3087, 3);  unsqueeze_3087 = None
    mul_3715: "f32[72]" = torch.ops.aten.mul.Tensor(sum_295, 0.0006377551020408163)
    mul_3716: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_535, squeeze_535)
    mul_3717: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3715, mul_3716);  mul_3715 = mul_3716 = None
    unsqueeze_3089: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3717, 0);  mul_3717 = None
    unsqueeze_3090: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3089, 2);  unsqueeze_3089 = None
    unsqueeze_3091: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3090, 3);  unsqueeze_3090 = None
    mul_3718: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_535, primals_536);  primals_536 = None
    unsqueeze_3092: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3718, 0);  mul_3718 = None
    unsqueeze_3093: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3092, 2);  unsqueeze_3092 = None
    unsqueeze_3094: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3093, 3);  unsqueeze_3093 = None
    mul_3719: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_909, unsqueeze_3091);  sub_909 = unsqueeze_3091 = None
    sub_911: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_118, mul_3719);  mul_3719 = None
    sub_912: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_911, unsqueeze_3088);  sub_911 = unsqueeze_3088 = None
    mul_3720: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_912, unsqueeze_3094);  sub_912 = unsqueeze_3094 = None
    mul_3721: "f32[72]" = torch.ops.aten.mul.Tensor(sum_295, squeeze_535);  sum_295 = squeeze_535 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_146 = torch.ops.aten.convolution_backward.default(mul_3720, relu_164, primals_535, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3720 = primals_535 = None
    getitem_1088: "f32[8, 72, 14, 14]" = convolution_backward_146[0]
    getitem_1089: "f32[72, 72, 3, 3]" = convolution_backward_146[1];  convolution_backward_146 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_119: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_164, 0);  relu_164 = None
    where_119: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_119, full_default, getitem_1088);  le_119 = getitem_1088 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_296: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_119, [0, 2, 3])
    sub_913: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_177, unsqueeze_3097);  convolution_177 = unsqueeze_3097 = None
    mul_3722: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_119, sub_913)
    sum_297: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3722, [0, 2, 3]);  mul_3722 = None
    mul_3723: "f32[72]" = torch.ops.aten.mul.Tensor(sum_296, 0.0006377551020408163)
    unsqueeze_3098: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3723, 0);  mul_3723 = None
    unsqueeze_3099: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3098, 2);  unsqueeze_3098 = None
    unsqueeze_3100: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3099, 3);  unsqueeze_3099 = None
    mul_3724: "f32[72]" = torch.ops.aten.mul.Tensor(sum_297, 0.0006377551020408163)
    mul_3725: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_532, squeeze_532)
    mul_3726: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3724, mul_3725);  mul_3724 = mul_3725 = None
    unsqueeze_3101: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3726, 0);  mul_3726 = None
    unsqueeze_3102: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3101, 2);  unsqueeze_3101 = None
    unsqueeze_3103: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3102, 3);  unsqueeze_3102 = None
    mul_3727: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_532, primals_533);  primals_533 = None
    unsqueeze_3104: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3727, 0);  mul_3727 = None
    unsqueeze_3105: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3104, 2);  unsqueeze_3104 = None
    unsqueeze_3106: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3105, 3);  unsqueeze_3105 = None
    mul_3728: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_913, unsqueeze_3103);  sub_913 = unsqueeze_3103 = None
    sub_915: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_119, mul_3728);  where_119 = mul_3728 = None
    sub_916: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_915, unsqueeze_3100);  sub_915 = unsqueeze_3100 = None
    mul_3729: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_916, unsqueeze_3106);  sub_916 = unsqueeze_3106 = None
    mul_3730: "f32[72]" = torch.ops.aten.mul.Tensor(sum_297, squeeze_532);  sum_297 = squeeze_532 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_147 = torch.ops.aten.convolution_backward.default(mul_3729, relu_146, primals_532, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3729 = primals_532 = None
    getitem_1091: "f32[8, 72, 14, 14]" = convolution_backward_147[0]
    getitem_1092: "f32[72, 72, 3, 3]" = convolution_backward_147[1];  convolution_backward_147 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2005: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_118, getitem_1091);  where_118 = getitem_1091 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_120: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_163, 0);  relu_163 = None
    where_120: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_120, full_default, add_1997);  le_120 = add_1997 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_298: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_120, [0, 2, 3])
    sub_917: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_176, unsqueeze_3109);  convolution_176 = unsqueeze_3109 = None
    mul_3731: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_120, sub_917)
    sum_299: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3731, [0, 2, 3]);  mul_3731 = None
    mul_3732: "f32[36]" = torch.ops.aten.mul.Tensor(sum_298, 0.00015943877551020407)
    unsqueeze_3110: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3732, 0);  mul_3732 = None
    unsqueeze_3111: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3110, 2);  unsqueeze_3110 = None
    unsqueeze_3112: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3111, 3);  unsqueeze_3111 = None
    mul_3733: "f32[36]" = torch.ops.aten.mul.Tensor(sum_299, 0.00015943877551020407)
    mul_3734: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_529, squeeze_529)
    mul_3735: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3733, mul_3734);  mul_3733 = mul_3734 = None
    unsqueeze_3113: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3735, 0);  mul_3735 = None
    unsqueeze_3114: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3113, 2);  unsqueeze_3113 = None
    unsqueeze_3115: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3114, 3);  unsqueeze_3114 = None
    mul_3736: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_529, primals_530);  primals_530 = None
    unsqueeze_3116: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3736, 0);  mul_3736 = None
    unsqueeze_3117: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3116, 2);  unsqueeze_3116 = None
    unsqueeze_3118: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3117, 3);  unsqueeze_3117 = None
    mul_3737: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_917, unsqueeze_3115);  sub_917 = unsqueeze_3115 = None
    sub_919: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_120, mul_3737);  mul_3737 = None
    sub_920: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_919, unsqueeze_3112);  sub_919 = unsqueeze_3112 = None
    mul_3738: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_920, unsqueeze_3118);  sub_920 = unsqueeze_3118 = None
    mul_3739: "f32[36]" = torch.ops.aten.mul.Tensor(sum_299, squeeze_529);  sum_299 = squeeze_529 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_148 = torch.ops.aten.convolution_backward.default(mul_3738, relu_162, primals_529, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3738 = primals_529 = None
    getitem_1094: "f32[8, 36, 28, 28]" = convolution_backward_148[0]
    getitem_1095: "f32[36, 36, 3, 3]" = convolution_backward_148[1];  convolution_backward_148 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_121: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_162, 0);  relu_162 = None
    where_121: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_121, full_default, getitem_1094);  le_121 = getitem_1094 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_300: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_121, [0, 2, 3])
    sub_921: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_175, unsqueeze_3121);  convolution_175 = unsqueeze_3121 = None
    mul_3740: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_121, sub_921)
    sum_301: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3740, [0, 2, 3]);  mul_3740 = None
    mul_3741: "f32[36]" = torch.ops.aten.mul.Tensor(sum_300, 0.00015943877551020407)
    unsqueeze_3122: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3741, 0);  mul_3741 = None
    unsqueeze_3123: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3122, 2);  unsqueeze_3122 = None
    unsqueeze_3124: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3123, 3);  unsqueeze_3123 = None
    mul_3742: "f32[36]" = torch.ops.aten.mul.Tensor(sum_301, 0.00015943877551020407)
    mul_3743: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_526, squeeze_526)
    mul_3744: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3742, mul_3743);  mul_3742 = mul_3743 = None
    unsqueeze_3125: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3744, 0);  mul_3744 = None
    unsqueeze_3126: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3125, 2);  unsqueeze_3125 = None
    unsqueeze_3127: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3126, 3);  unsqueeze_3126 = None
    mul_3745: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_526, primals_527);  primals_527 = None
    unsqueeze_3128: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3745, 0);  mul_3745 = None
    unsqueeze_3129: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3128, 2);  unsqueeze_3128 = None
    unsqueeze_3130: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3129, 3);  unsqueeze_3129 = None
    mul_3746: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_921, unsqueeze_3127);  sub_921 = unsqueeze_3127 = None
    sub_923: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_121, mul_3746);  where_121 = mul_3746 = None
    sub_924: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_923, unsqueeze_3124);  sub_923 = unsqueeze_3124 = None
    mul_3747: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_924, unsqueeze_3130);  sub_924 = unsqueeze_3130 = None
    mul_3748: "f32[36]" = torch.ops.aten.mul.Tensor(sum_301, squeeze_526);  sum_301 = squeeze_526 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_149 = torch.ops.aten.convolution_backward.default(mul_3747, relu_161, primals_526, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3747 = primals_526 = None
    getitem_1097: "f32[8, 36, 28, 28]" = convolution_backward_149[0]
    getitem_1098: "f32[36, 36, 3, 3]" = convolution_backward_149[1];  convolution_backward_149 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2006: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_120, getitem_1097);  where_120 = getitem_1097 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_122: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_161, 0);  relu_161 = None
    where_122: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_122, full_default, add_2006);  le_122 = add_2006 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_302: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_122, [0, 2, 3])
    sub_925: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_174, unsqueeze_3133);  convolution_174 = unsqueeze_3133 = None
    mul_3749: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_122, sub_925)
    sum_303: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3749, [0, 2, 3]);  mul_3749 = None
    mul_3750: "f32[36]" = torch.ops.aten.mul.Tensor(sum_302, 0.00015943877551020407)
    unsqueeze_3134: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3750, 0);  mul_3750 = None
    unsqueeze_3135: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3134, 2);  unsqueeze_3134 = None
    unsqueeze_3136: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3135, 3);  unsqueeze_3135 = None
    mul_3751: "f32[36]" = torch.ops.aten.mul.Tensor(sum_303, 0.00015943877551020407)
    mul_3752: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_523, squeeze_523)
    mul_3753: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3751, mul_3752);  mul_3751 = mul_3752 = None
    unsqueeze_3137: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3753, 0);  mul_3753 = None
    unsqueeze_3138: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3137, 2);  unsqueeze_3137 = None
    unsqueeze_3139: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3138, 3);  unsqueeze_3138 = None
    mul_3754: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_523, primals_524);  primals_524 = None
    unsqueeze_3140: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3754, 0);  mul_3754 = None
    unsqueeze_3141: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3140, 2);  unsqueeze_3140 = None
    unsqueeze_3142: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3141, 3);  unsqueeze_3141 = None
    mul_3755: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_925, unsqueeze_3139);  sub_925 = unsqueeze_3139 = None
    sub_927: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_122, mul_3755);  mul_3755 = None
    sub_928: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_927, unsqueeze_3136);  sub_927 = unsqueeze_3136 = None
    mul_3756: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_928, unsqueeze_3142);  sub_928 = unsqueeze_3142 = None
    mul_3757: "f32[36]" = torch.ops.aten.mul.Tensor(sum_303, squeeze_523);  sum_303 = squeeze_523 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_150 = torch.ops.aten.convolution_backward.default(mul_3756, relu_160, primals_523, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3756 = primals_523 = None
    getitem_1100: "f32[8, 36, 28, 28]" = convolution_backward_150[0]
    getitem_1101: "f32[36, 36, 3, 3]" = convolution_backward_150[1];  convolution_backward_150 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_123: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_160, 0);  relu_160 = None
    where_123: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_123, full_default, getitem_1100);  le_123 = getitem_1100 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_304: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_123, [0, 2, 3])
    sub_929: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_173, unsqueeze_3145);  convolution_173 = unsqueeze_3145 = None
    mul_3758: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_123, sub_929)
    sum_305: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3758, [0, 2, 3]);  mul_3758 = None
    mul_3759: "f32[36]" = torch.ops.aten.mul.Tensor(sum_304, 0.00015943877551020407)
    unsqueeze_3146: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3759, 0);  mul_3759 = None
    unsqueeze_3147: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3146, 2);  unsqueeze_3146 = None
    unsqueeze_3148: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3147, 3);  unsqueeze_3147 = None
    mul_3760: "f32[36]" = torch.ops.aten.mul.Tensor(sum_305, 0.00015943877551020407)
    mul_3761: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_520, squeeze_520)
    mul_3762: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3760, mul_3761);  mul_3760 = mul_3761 = None
    unsqueeze_3149: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3762, 0);  mul_3762 = None
    unsqueeze_3150: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3149, 2);  unsqueeze_3149 = None
    unsqueeze_3151: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3150, 3);  unsqueeze_3150 = None
    mul_3763: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_520, primals_521);  primals_521 = None
    unsqueeze_3152: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3763, 0);  mul_3763 = None
    unsqueeze_3153: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3152, 2);  unsqueeze_3152 = None
    unsqueeze_3154: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3153, 3);  unsqueeze_3153 = None
    mul_3764: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_929, unsqueeze_3151);  sub_929 = unsqueeze_3151 = None
    sub_931: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_123, mul_3764);  where_123 = mul_3764 = None
    sub_932: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_931, unsqueeze_3148);  sub_931 = unsqueeze_3148 = None
    mul_3765: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_932, unsqueeze_3154);  sub_932 = unsqueeze_3154 = None
    mul_3766: "f32[36]" = torch.ops.aten.mul.Tensor(sum_305, squeeze_520);  sum_305 = squeeze_520 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_151 = torch.ops.aten.convolution_backward.default(mul_3765, relu_159, primals_520, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3765 = primals_520 = None
    getitem_1103: "f32[8, 36, 28, 28]" = convolution_backward_151[0]
    getitem_1104: "f32[36, 36, 3, 3]" = convolution_backward_151[1];  convolution_backward_151 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2007: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_122, getitem_1103);  where_122 = getitem_1103 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_124: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_159, 0);  relu_159 = None
    where_124: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_124, full_default, add_2007);  le_124 = add_2007 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_306: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_124, [0, 2, 3])
    sub_933: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_172, unsqueeze_3157);  convolution_172 = unsqueeze_3157 = None
    mul_3767: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_124, sub_933)
    sum_307: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3767, [0, 2, 3]);  mul_3767 = None
    mul_3768: "f32[36]" = torch.ops.aten.mul.Tensor(sum_306, 0.00015943877551020407)
    unsqueeze_3158: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3768, 0);  mul_3768 = None
    unsqueeze_3159: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3158, 2);  unsqueeze_3158 = None
    unsqueeze_3160: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3159, 3);  unsqueeze_3159 = None
    mul_3769: "f32[36]" = torch.ops.aten.mul.Tensor(sum_307, 0.00015943877551020407)
    mul_3770: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_517, squeeze_517)
    mul_3771: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3769, mul_3770);  mul_3769 = mul_3770 = None
    unsqueeze_3161: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3771, 0);  mul_3771 = None
    unsqueeze_3162: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3161, 2);  unsqueeze_3161 = None
    unsqueeze_3163: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3162, 3);  unsqueeze_3162 = None
    mul_3772: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_517, primals_518);  primals_518 = None
    unsqueeze_3164: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3772, 0);  mul_3772 = None
    unsqueeze_3165: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3164, 2);  unsqueeze_3164 = None
    unsqueeze_3166: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3165, 3);  unsqueeze_3165 = None
    mul_3773: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_933, unsqueeze_3163);  sub_933 = unsqueeze_3163 = None
    sub_935: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_124, mul_3773);  mul_3773 = None
    sub_936: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_935, unsqueeze_3160);  sub_935 = unsqueeze_3160 = None
    mul_3774: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_936, unsqueeze_3166);  sub_936 = unsqueeze_3166 = None
    mul_3775: "f32[36]" = torch.ops.aten.mul.Tensor(sum_307, squeeze_517);  sum_307 = squeeze_517 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_152 = torch.ops.aten.convolution_backward.default(mul_3774, relu_158, primals_517, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3774 = primals_517 = None
    getitem_1106: "f32[8, 36, 28, 28]" = convolution_backward_152[0]
    getitem_1107: "f32[36, 36, 3, 3]" = convolution_backward_152[1];  convolution_backward_152 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_125: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_158, 0);  relu_158 = None
    where_125: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_125, full_default, getitem_1106);  le_125 = getitem_1106 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_308: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_125, [0, 2, 3])
    sub_937: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_171, unsqueeze_3169);  convolution_171 = unsqueeze_3169 = None
    mul_3776: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_125, sub_937)
    sum_309: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3776, [0, 2, 3]);  mul_3776 = None
    mul_3777: "f32[36]" = torch.ops.aten.mul.Tensor(sum_308, 0.00015943877551020407)
    unsqueeze_3170: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3777, 0);  mul_3777 = None
    unsqueeze_3171: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3170, 2);  unsqueeze_3170 = None
    unsqueeze_3172: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3171, 3);  unsqueeze_3171 = None
    mul_3778: "f32[36]" = torch.ops.aten.mul.Tensor(sum_309, 0.00015943877551020407)
    mul_3779: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_514, squeeze_514)
    mul_3780: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3778, mul_3779);  mul_3778 = mul_3779 = None
    unsqueeze_3173: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3780, 0);  mul_3780 = None
    unsqueeze_3174: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3173, 2);  unsqueeze_3173 = None
    unsqueeze_3175: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3174, 3);  unsqueeze_3174 = None
    mul_3781: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_514, primals_515);  primals_515 = None
    unsqueeze_3176: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3781, 0);  mul_3781 = None
    unsqueeze_3177: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3176, 2);  unsqueeze_3176 = None
    unsqueeze_3178: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3177, 3);  unsqueeze_3177 = None
    mul_3782: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_937, unsqueeze_3175);  sub_937 = unsqueeze_3175 = None
    sub_939: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_125, mul_3782);  where_125 = mul_3782 = None
    sub_940: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_939, unsqueeze_3172);  sub_939 = unsqueeze_3172 = None
    mul_3783: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_940, unsqueeze_3178);  sub_940 = unsqueeze_3178 = None
    mul_3784: "f32[36]" = torch.ops.aten.mul.Tensor(sum_309, squeeze_514);  sum_309 = squeeze_514 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_153 = torch.ops.aten.convolution_backward.default(mul_3783, relu_157, primals_514, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3783 = primals_514 = None
    getitem_1109: "f32[8, 36, 28, 28]" = convolution_backward_153[0]
    getitem_1110: "f32[36, 36, 3, 3]" = convolution_backward_153[1];  convolution_backward_153 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2008: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_124, getitem_1109);  where_124 = getitem_1109 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_126: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_157, 0);  relu_157 = None
    where_126: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_126, full_default, add_2008);  le_126 = add_2008 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_310: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_126, [0, 2, 3])
    sub_941: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_170, unsqueeze_3181);  convolution_170 = unsqueeze_3181 = None
    mul_3785: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_126, sub_941)
    sum_311: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3785, [0, 2, 3]);  mul_3785 = None
    mul_3786: "f32[36]" = torch.ops.aten.mul.Tensor(sum_310, 0.00015943877551020407)
    unsqueeze_3182: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3786, 0);  mul_3786 = None
    unsqueeze_3183: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3182, 2);  unsqueeze_3182 = None
    unsqueeze_3184: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3183, 3);  unsqueeze_3183 = None
    mul_3787: "f32[36]" = torch.ops.aten.mul.Tensor(sum_311, 0.00015943877551020407)
    mul_3788: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_511, squeeze_511)
    mul_3789: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3787, mul_3788);  mul_3787 = mul_3788 = None
    unsqueeze_3185: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3789, 0);  mul_3789 = None
    unsqueeze_3186: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3185, 2);  unsqueeze_3185 = None
    unsqueeze_3187: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3186, 3);  unsqueeze_3186 = None
    mul_3790: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_511, primals_512);  primals_512 = None
    unsqueeze_3188: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3790, 0);  mul_3790 = None
    unsqueeze_3189: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3188, 2);  unsqueeze_3188 = None
    unsqueeze_3190: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3189, 3);  unsqueeze_3189 = None
    mul_3791: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_941, unsqueeze_3187);  sub_941 = unsqueeze_3187 = None
    sub_943: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_126, mul_3791);  mul_3791 = None
    sub_944: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_943, unsqueeze_3184);  sub_943 = unsqueeze_3184 = None
    mul_3792: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_944, unsqueeze_3190);  sub_944 = unsqueeze_3190 = None
    mul_3793: "f32[36]" = torch.ops.aten.mul.Tensor(sum_311, squeeze_511);  sum_311 = squeeze_511 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_154 = torch.ops.aten.convolution_backward.default(mul_3792, relu_156, primals_511, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3792 = primals_511 = None
    getitem_1112: "f32[8, 36, 28, 28]" = convolution_backward_154[0]
    getitem_1113: "f32[36, 36, 3, 3]" = convolution_backward_154[1];  convolution_backward_154 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_127: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_156, 0);  relu_156 = None
    where_127: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_127, full_default, getitem_1112);  le_127 = getitem_1112 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_312: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_127, [0, 2, 3])
    sub_945: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_169, unsqueeze_3193);  convolution_169 = unsqueeze_3193 = None
    mul_3794: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_127, sub_945)
    sum_313: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3794, [0, 2, 3]);  mul_3794 = None
    mul_3795: "f32[36]" = torch.ops.aten.mul.Tensor(sum_312, 0.00015943877551020407)
    unsqueeze_3194: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3795, 0);  mul_3795 = None
    unsqueeze_3195: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3194, 2);  unsqueeze_3194 = None
    unsqueeze_3196: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3195, 3);  unsqueeze_3195 = None
    mul_3796: "f32[36]" = torch.ops.aten.mul.Tensor(sum_313, 0.00015943877551020407)
    mul_3797: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_508, squeeze_508)
    mul_3798: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3796, mul_3797);  mul_3796 = mul_3797 = None
    unsqueeze_3197: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3798, 0);  mul_3798 = None
    unsqueeze_3198: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3197, 2);  unsqueeze_3197 = None
    unsqueeze_3199: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3198, 3);  unsqueeze_3198 = None
    mul_3799: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_508, primals_509);  primals_509 = None
    unsqueeze_3200: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3799, 0);  mul_3799 = None
    unsqueeze_3201: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3200, 2);  unsqueeze_3200 = None
    unsqueeze_3202: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3201, 3);  unsqueeze_3201 = None
    mul_3800: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_945, unsqueeze_3199);  sub_945 = unsqueeze_3199 = None
    sub_947: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_127, mul_3800);  where_127 = mul_3800 = None
    sub_948: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_947, unsqueeze_3196);  sub_947 = unsqueeze_3196 = None
    mul_3801: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_948, unsqueeze_3202);  sub_948 = unsqueeze_3202 = None
    mul_3802: "f32[36]" = torch.ops.aten.mul.Tensor(sum_313, squeeze_508);  sum_313 = squeeze_508 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_155 = torch.ops.aten.convolution_backward.default(mul_3801, relu_144, primals_508, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3801 = primals_508 = None
    getitem_1115: "f32[8, 36, 28, 28]" = convolution_backward_155[0]
    getitem_1116: "f32[36, 36, 3, 3]" = convolution_backward_155[1];  convolution_backward_155 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2009: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_126, getitem_1115);  where_126 = getitem_1115 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_128: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_155, 0);  relu_155 = None
    where_128: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_128, full_default, add_1996);  le_128 = add_1996 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_314: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_128, [0, 2, 3])
    sub_949: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_168, unsqueeze_3205);  convolution_168 = unsqueeze_3205 = None
    mul_3803: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_128, sub_949)
    sum_315: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3803, [0, 2, 3]);  mul_3803 = None
    mul_3804: "f32[18]" = torch.ops.aten.mul.Tensor(sum_314, 3.985969387755102e-05)
    unsqueeze_3206: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3804, 0);  mul_3804 = None
    unsqueeze_3207: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3206, 2);  unsqueeze_3206 = None
    unsqueeze_3208: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3207, 3);  unsqueeze_3207 = None
    mul_3805: "f32[18]" = torch.ops.aten.mul.Tensor(sum_315, 3.985969387755102e-05)
    mul_3806: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_505, squeeze_505)
    mul_3807: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3805, mul_3806);  mul_3805 = mul_3806 = None
    unsqueeze_3209: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3807, 0);  mul_3807 = None
    unsqueeze_3210: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3209, 2);  unsqueeze_3209 = None
    unsqueeze_3211: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3210, 3);  unsqueeze_3210 = None
    mul_3808: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_505, primals_506);  primals_506 = None
    unsqueeze_3212: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3808, 0);  mul_3808 = None
    unsqueeze_3213: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3212, 2);  unsqueeze_3212 = None
    unsqueeze_3214: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3213, 3);  unsqueeze_3213 = None
    mul_3809: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_949, unsqueeze_3211);  sub_949 = unsqueeze_3211 = None
    sub_951: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_128, mul_3809);  mul_3809 = None
    sub_952: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_951, unsqueeze_3208);  sub_951 = unsqueeze_3208 = None
    mul_3810: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_952, unsqueeze_3214);  sub_952 = unsqueeze_3214 = None
    mul_3811: "f32[18]" = torch.ops.aten.mul.Tensor(sum_315, squeeze_505);  sum_315 = squeeze_505 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_156 = torch.ops.aten.convolution_backward.default(mul_3810, relu_154, primals_505, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3810 = primals_505 = None
    getitem_1118: "f32[8, 18, 56, 56]" = convolution_backward_156[0]
    getitem_1119: "f32[18, 18, 3, 3]" = convolution_backward_156[1];  convolution_backward_156 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_129: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_154, 0);  relu_154 = None
    where_129: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_129, full_default, getitem_1118);  le_129 = getitem_1118 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_316: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_129, [0, 2, 3])
    sub_953: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_167, unsqueeze_3217);  convolution_167 = unsqueeze_3217 = None
    mul_3812: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_129, sub_953)
    sum_317: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3812, [0, 2, 3]);  mul_3812 = None
    mul_3813: "f32[18]" = torch.ops.aten.mul.Tensor(sum_316, 3.985969387755102e-05)
    unsqueeze_3218: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3813, 0);  mul_3813 = None
    unsqueeze_3219: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3218, 2);  unsqueeze_3218 = None
    unsqueeze_3220: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3219, 3);  unsqueeze_3219 = None
    mul_3814: "f32[18]" = torch.ops.aten.mul.Tensor(sum_317, 3.985969387755102e-05)
    mul_3815: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_502, squeeze_502)
    mul_3816: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3814, mul_3815);  mul_3814 = mul_3815 = None
    unsqueeze_3221: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3816, 0);  mul_3816 = None
    unsqueeze_3222: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3221, 2);  unsqueeze_3221 = None
    unsqueeze_3223: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3222, 3);  unsqueeze_3222 = None
    mul_3817: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_502, primals_503);  primals_503 = None
    unsqueeze_3224: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3817, 0);  mul_3817 = None
    unsqueeze_3225: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3224, 2);  unsqueeze_3224 = None
    unsqueeze_3226: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3225, 3);  unsqueeze_3225 = None
    mul_3818: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_953, unsqueeze_3223);  sub_953 = unsqueeze_3223 = None
    sub_955: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_129, mul_3818);  where_129 = mul_3818 = None
    sub_956: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_955, unsqueeze_3220);  sub_955 = unsqueeze_3220 = None
    mul_3819: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_956, unsqueeze_3226);  sub_956 = unsqueeze_3226 = None
    mul_3820: "f32[18]" = torch.ops.aten.mul.Tensor(sum_317, squeeze_502);  sum_317 = squeeze_502 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_157 = torch.ops.aten.convolution_backward.default(mul_3819, relu_153, primals_502, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3819 = primals_502 = None
    getitem_1121: "f32[8, 18, 56, 56]" = convolution_backward_157[0]
    getitem_1122: "f32[18, 18, 3, 3]" = convolution_backward_157[1];  convolution_backward_157 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2010: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_128, getitem_1121);  where_128 = getitem_1121 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_130: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_153, 0);  relu_153 = None
    where_130: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_130, full_default, add_2010);  le_130 = add_2010 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_318: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_130, [0, 2, 3])
    sub_957: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_166, unsqueeze_3229);  convolution_166 = unsqueeze_3229 = None
    mul_3821: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_130, sub_957)
    sum_319: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3821, [0, 2, 3]);  mul_3821 = None
    mul_3822: "f32[18]" = torch.ops.aten.mul.Tensor(sum_318, 3.985969387755102e-05)
    unsqueeze_3230: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3822, 0);  mul_3822 = None
    unsqueeze_3231: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3230, 2);  unsqueeze_3230 = None
    unsqueeze_3232: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3231, 3);  unsqueeze_3231 = None
    mul_3823: "f32[18]" = torch.ops.aten.mul.Tensor(sum_319, 3.985969387755102e-05)
    mul_3824: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_499, squeeze_499)
    mul_3825: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3823, mul_3824);  mul_3823 = mul_3824 = None
    unsqueeze_3233: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3825, 0);  mul_3825 = None
    unsqueeze_3234: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3233, 2);  unsqueeze_3233 = None
    unsqueeze_3235: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3234, 3);  unsqueeze_3234 = None
    mul_3826: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_499, primals_500);  primals_500 = None
    unsqueeze_3236: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3826, 0);  mul_3826 = None
    unsqueeze_3237: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3236, 2);  unsqueeze_3236 = None
    unsqueeze_3238: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3237, 3);  unsqueeze_3237 = None
    mul_3827: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_957, unsqueeze_3235);  sub_957 = unsqueeze_3235 = None
    sub_959: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_130, mul_3827);  mul_3827 = None
    sub_960: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_959, unsqueeze_3232);  sub_959 = unsqueeze_3232 = None
    mul_3828: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_960, unsqueeze_3238);  sub_960 = unsqueeze_3238 = None
    mul_3829: "f32[18]" = torch.ops.aten.mul.Tensor(sum_319, squeeze_499);  sum_319 = squeeze_499 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_158 = torch.ops.aten.convolution_backward.default(mul_3828, relu_152, primals_499, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3828 = primals_499 = None
    getitem_1124: "f32[8, 18, 56, 56]" = convolution_backward_158[0]
    getitem_1125: "f32[18, 18, 3, 3]" = convolution_backward_158[1];  convolution_backward_158 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_131: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_152, 0);  relu_152 = None
    where_131: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_131, full_default, getitem_1124);  le_131 = getitem_1124 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_320: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_131, [0, 2, 3])
    sub_961: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_165, unsqueeze_3241);  convolution_165 = unsqueeze_3241 = None
    mul_3830: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_131, sub_961)
    sum_321: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3830, [0, 2, 3]);  mul_3830 = None
    mul_3831: "f32[18]" = torch.ops.aten.mul.Tensor(sum_320, 3.985969387755102e-05)
    unsqueeze_3242: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3831, 0);  mul_3831 = None
    unsqueeze_3243: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3242, 2);  unsqueeze_3242 = None
    unsqueeze_3244: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3243, 3);  unsqueeze_3243 = None
    mul_3832: "f32[18]" = torch.ops.aten.mul.Tensor(sum_321, 3.985969387755102e-05)
    mul_3833: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_496, squeeze_496)
    mul_3834: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3832, mul_3833);  mul_3832 = mul_3833 = None
    unsqueeze_3245: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3834, 0);  mul_3834 = None
    unsqueeze_3246: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3245, 2);  unsqueeze_3245 = None
    unsqueeze_3247: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3246, 3);  unsqueeze_3246 = None
    mul_3835: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_496, primals_497);  primals_497 = None
    unsqueeze_3248: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3835, 0);  mul_3835 = None
    unsqueeze_3249: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3248, 2);  unsqueeze_3248 = None
    unsqueeze_3250: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3249, 3);  unsqueeze_3249 = None
    mul_3836: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_961, unsqueeze_3247);  sub_961 = unsqueeze_3247 = None
    sub_963: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_131, mul_3836);  where_131 = mul_3836 = None
    sub_964: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_963, unsqueeze_3244);  sub_963 = unsqueeze_3244 = None
    mul_3837: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_964, unsqueeze_3250);  sub_964 = unsqueeze_3250 = None
    mul_3838: "f32[18]" = torch.ops.aten.mul.Tensor(sum_321, squeeze_496);  sum_321 = squeeze_496 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_159 = torch.ops.aten.convolution_backward.default(mul_3837, relu_151, primals_496, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3837 = primals_496 = None
    getitem_1127: "f32[8, 18, 56, 56]" = convolution_backward_159[0]
    getitem_1128: "f32[18, 18, 3, 3]" = convolution_backward_159[1];  convolution_backward_159 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2011: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_130, getitem_1127);  where_130 = getitem_1127 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_132: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_151, 0);  relu_151 = None
    where_132: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_132, full_default, add_2011);  le_132 = add_2011 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_322: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_132, [0, 2, 3])
    sub_965: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_164, unsqueeze_3253);  convolution_164 = unsqueeze_3253 = None
    mul_3839: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_132, sub_965)
    sum_323: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3839, [0, 2, 3]);  mul_3839 = None
    mul_3840: "f32[18]" = torch.ops.aten.mul.Tensor(sum_322, 3.985969387755102e-05)
    unsqueeze_3254: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3840, 0);  mul_3840 = None
    unsqueeze_3255: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3254, 2);  unsqueeze_3254 = None
    unsqueeze_3256: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3255, 3);  unsqueeze_3255 = None
    mul_3841: "f32[18]" = torch.ops.aten.mul.Tensor(sum_323, 3.985969387755102e-05)
    mul_3842: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_493, squeeze_493)
    mul_3843: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3841, mul_3842);  mul_3841 = mul_3842 = None
    unsqueeze_3257: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3843, 0);  mul_3843 = None
    unsqueeze_3258: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3257, 2);  unsqueeze_3257 = None
    unsqueeze_3259: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3258, 3);  unsqueeze_3258 = None
    mul_3844: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_493, primals_494);  primals_494 = None
    unsqueeze_3260: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3844, 0);  mul_3844 = None
    unsqueeze_3261: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3260, 2);  unsqueeze_3260 = None
    unsqueeze_3262: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3261, 3);  unsqueeze_3261 = None
    mul_3845: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_965, unsqueeze_3259);  sub_965 = unsqueeze_3259 = None
    sub_967: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_132, mul_3845);  mul_3845 = None
    sub_968: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_967, unsqueeze_3256);  sub_967 = unsqueeze_3256 = None
    mul_3846: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_968, unsqueeze_3262);  sub_968 = unsqueeze_3262 = None
    mul_3847: "f32[18]" = torch.ops.aten.mul.Tensor(sum_323, squeeze_493);  sum_323 = squeeze_493 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_160 = torch.ops.aten.convolution_backward.default(mul_3846, relu_150, primals_493, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3846 = primals_493 = None
    getitem_1130: "f32[8, 18, 56, 56]" = convolution_backward_160[0]
    getitem_1131: "f32[18, 18, 3, 3]" = convolution_backward_160[1];  convolution_backward_160 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_133: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_150, 0);  relu_150 = None
    where_133: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_133, full_default, getitem_1130);  le_133 = getitem_1130 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_324: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_133, [0, 2, 3])
    sub_969: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_163, unsqueeze_3265);  convolution_163 = unsqueeze_3265 = None
    mul_3848: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_133, sub_969)
    sum_325: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3848, [0, 2, 3]);  mul_3848 = None
    mul_3849: "f32[18]" = torch.ops.aten.mul.Tensor(sum_324, 3.985969387755102e-05)
    unsqueeze_3266: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3849, 0);  mul_3849 = None
    unsqueeze_3267: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3266, 2);  unsqueeze_3266 = None
    unsqueeze_3268: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3267, 3);  unsqueeze_3267 = None
    mul_3850: "f32[18]" = torch.ops.aten.mul.Tensor(sum_325, 3.985969387755102e-05)
    mul_3851: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_490, squeeze_490)
    mul_3852: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3850, mul_3851);  mul_3850 = mul_3851 = None
    unsqueeze_3269: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3852, 0);  mul_3852 = None
    unsqueeze_3270: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3269, 2);  unsqueeze_3269 = None
    unsqueeze_3271: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3270, 3);  unsqueeze_3270 = None
    mul_3853: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_490, primals_491);  primals_491 = None
    unsqueeze_3272: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3853, 0);  mul_3853 = None
    unsqueeze_3273: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3272, 2);  unsqueeze_3272 = None
    unsqueeze_3274: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3273, 3);  unsqueeze_3273 = None
    mul_3854: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_969, unsqueeze_3271);  sub_969 = unsqueeze_3271 = None
    sub_971: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_133, mul_3854);  where_133 = mul_3854 = None
    sub_972: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_971, unsqueeze_3268);  sub_971 = unsqueeze_3268 = None
    mul_3855: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_972, unsqueeze_3274);  sub_972 = unsqueeze_3274 = None
    mul_3856: "f32[18]" = torch.ops.aten.mul.Tensor(sum_325, squeeze_490);  sum_325 = squeeze_490 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_161 = torch.ops.aten.convolution_backward.default(mul_3855, relu_149, primals_490, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3855 = primals_490 = None
    getitem_1133: "f32[8, 18, 56, 56]" = convolution_backward_161[0]
    getitem_1134: "f32[18, 18, 3, 3]" = convolution_backward_161[1];  convolution_backward_161 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2012: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_132, getitem_1133);  where_132 = getitem_1133 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_134: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_149, 0);  relu_149 = None
    where_134: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_134, full_default, add_2012);  le_134 = add_2012 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_326: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_134, [0, 2, 3])
    sub_973: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_162, unsqueeze_3277);  convolution_162 = unsqueeze_3277 = None
    mul_3857: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_134, sub_973)
    sum_327: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3857, [0, 2, 3]);  mul_3857 = None
    mul_3858: "f32[18]" = torch.ops.aten.mul.Tensor(sum_326, 3.985969387755102e-05)
    unsqueeze_3278: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3858, 0);  mul_3858 = None
    unsqueeze_3279: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3278, 2);  unsqueeze_3278 = None
    unsqueeze_3280: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3279, 3);  unsqueeze_3279 = None
    mul_3859: "f32[18]" = torch.ops.aten.mul.Tensor(sum_327, 3.985969387755102e-05)
    mul_3860: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_487, squeeze_487)
    mul_3861: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3859, mul_3860);  mul_3859 = mul_3860 = None
    unsqueeze_3281: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3861, 0);  mul_3861 = None
    unsqueeze_3282: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3281, 2);  unsqueeze_3281 = None
    unsqueeze_3283: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3282, 3);  unsqueeze_3282 = None
    mul_3862: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_487, primals_488);  primals_488 = None
    unsqueeze_3284: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3862, 0);  mul_3862 = None
    unsqueeze_3285: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3284, 2);  unsqueeze_3284 = None
    unsqueeze_3286: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3285, 3);  unsqueeze_3285 = None
    mul_3863: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_973, unsqueeze_3283);  sub_973 = unsqueeze_3283 = None
    sub_975: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_134, mul_3863);  mul_3863 = None
    sub_976: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_975, unsqueeze_3280);  sub_975 = unsqueeze_3280 = None
    mul_3864: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_976, unsqueeze_3286);  sub_976 = unsqueeze_3286 = None
    mul_3865: "f32[18]" = torch.ops.aten.mul.Tensor(sum_327, squeeze_487);  sum_327 = squeeze_487 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_162 = torch.ops.aten.convolution_backward.default(mul_3864, relu_148, primals_487, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3864 = primals_487 = None
    getitem_1136: "f32[8, 18, 56, 56]" = convolution_backward_162[0]
    getitem_1137: "f32[18, 18, 3, 3]" = convolution_backward_162[1];  convolution_backward_162 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_135: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_148, 0);  relu_148 = None
    where_135: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_135, full_default, getitem_1136);  le_135 = getitem_1136 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_328: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_135, [0, 2, 3])
    sub_977: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_161, unsqueeze_3289);  convolution_161 = unsqueeze_3289 = None
    mul_3866: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_135, sub_977)
    sum_329: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3866, [0, 2, 3]);  mul_3866 = None
    mul_3867: "f32[18]" = torch.ops.aten.mul.Tensor(sum_328, 3.985969387755102e-05)
    unsqueeze_3290: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3867, 0);  mul_3867 = None
    unsqueeze_3291: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3290, 2);  unsqueeze_3290 = None
    unsqueeze_3292: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3291, 3);  unsqueeze_3291 = None
    mul_3868: "f32[18]" = torch.ops.aten.mul.Tensor(sum_329, 3.985969387755102e-05)
    mul_3869: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_484, squeeze_484)
    mul_3870: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3868, mul_3869);  mul_3868 = mul_3869 = None
    unsqueeze_3293: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3870, 0);  mul_3870 = None
    unsqueeze_3294: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3293, 2);  unsqueeze_3293 = None
    unsqueeze_3295: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3294, 3);  unsqueeze_3294 = None
    mul_3871: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_484, primals_485);  primals_485 = None
    unsqueeze_3296: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3871, 0);  mul_3871 = None
    unsqueeze_3297: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3296, 2);  unsqueeze_3296 = None
    unsqueeze_3298: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3297, 3);  unsqueeze_3297 = None
    mul_3872: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_977, unsqueeze_3295);  sub_977 = unsqueeze_3295 = None
    sub_979: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_135, mul_3872);  where_135 = mul_3872 = None
    sub_980: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_979, unsqueeze_3292);  sub_979 = unsqueeze_3292 = None
    mul_3873: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_980, unsqueeze_3298);  sub_980 = unsqueeze_3298 = None
    mul_3874: "f32[18]" = torch.ops.aten.mul.Tensor(sum_329, squeeze_484);  sum_329 = squeeze_484 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_163 = torch.ops.aten.convolution_backward.default(mul_3873, relu_143, primals_484, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3873 = primals_484 = None
    getitem_1139: "f32[8, 18, 56, 56]" = convolution_backward_163[0]
    getitem_1140: "f32[18, 18, 3, 3]" = convolution_backward_163[1];  convolution_backward_163 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2013: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_134, getitem_1139);  where_134 = getitem_1139 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:756, code: xl = [t(yl[-1]) if not isinstance(t, nn.Identity) else yl[i] for i, t in enumerate(self.transition3)]
    le_136: "b8[8, 144, 7, 7]" = torch.ops.aten.le.Scalar(relu_147, 0);  relu_147 = None
    where_136: "f32[8, 144, 7, 7]" = torch.ops.aten.where.self(le_136, full_default, add_2001);  le_136 = add_2001 = None
    sum_330: "f32[144]" = torch.ops.aten.sum.dim_IntList(where_136, [0, 2, 3])
    sub_981: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(convolution_160, unsqueeze_3301);  convolution_160 = unsqueeze_3301 = None
    mul_3875: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(where_136, sub_981)
    sum_331: "f32[144]" = torch.ops.aten.sum.dim_IntList(mul_3875, [0, 2, 3]);  mul_3875 = None
    mul_3876: "f32[144]" = torch.ops.aten.mul.Tensor(sum_330, 0.002551020408163265)
    unsqueeze_3302: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3876, 0);  mul_3876 = None
    unsqueeze_3303: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3302, 2);  unsqueeze_3302 = None
    unsqueeze_3304: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3303, 3);  unsqueeze_3303 = None
    mul_3877: "f32[144]" = torch.ops.aten.mul.Tensor(sum_331, 0.002551020408163265)
    mul_3878: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_481, squeeze_481)
    mul_3879: "f32[144]" = torch.ops.aten.mul.Tensor(mul_3877, mul_3878);  mul_3877 = mul_3878 = None
    unsqueeze_3305: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3879, 0);  mul_3879 = None
    unsqueeze_3306: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3305, 2);  unsqueeze_3305 = None
    unsqueeze_3307: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3306, 3);  unsqueeze_3306 = None
    mul_3880: "f32[144]" = torch.ops.aten.mul.Tensor(squeeze_481, primals_482);  primals_482 = None
    unsqueeze_3308: "f32[1, 144]" = torch.ops.aten.unsqueeze.default(mul_3880, 0);  mul_3880 = None
    unsqueeze_3309: "f32[1, 144, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3308, 2);  unsqueeze_3308 = None
    unsqueeze_3310: "f32[1, 144, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3309, 3);  unsqueeze_3309 = None
    mul_3881: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_981, unsqueeze_3307);  sub_981 = unsqueeze_3307 = None
    sub_983: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(where_136, mul_3881);  where_136 = mul_3881 = None
    sub_984: "f32[8, 144, 7, 7]" = torch.ops.aten.sub.Tensor(sub_983, unsqueeze_3304);  sub_983 = unsqueeze_3304 = None
    mul_3882: "f32[8, 144, 7, 7]" = torch.ops.aten.mul.Tensor(sub_984, unsqueeze_3310);  sub_984 = unsqueeze_3310 = None
    mul_3883: "f32[144]" = torch.ops.aten.mul.Tensor(sum_331, squeeze_481);  sum_331 = squeeze_481 = None
    convolution_backward_164 = torch.ops.aten.convolution_backward.default(mul_3882, relu_146, primals_481, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3882 = primals_481 = None
    getitem_1142: "f32[8, 72, 14, 14]" = convolution_backward_164[0]
    getitem_1143: "f32[144, 72, 3, 3]" = convolution_backward_164[1];  convolution_backward_164 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:756, code: xl = [t(yl[-1]) if not isinstance(t, nn.Identity) else yl[i] for i, t in enumerate(self.transition3)]
    add_2014: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(add_2005, getitem_1142);  add_2005 = getitem_1142 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_137: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_146, 0);  relu_146 = None
    where_137: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_137, full_default, add_2014);  le_137 = add_2014 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    sum_332: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_137, [0, 2, 3])
    sub_985: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_159, unsqueeze_3313);  convolution_159 = unsqueeze_3313 = None
    mul_3884: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_137, sub_985)
    sum_333: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3884, [0, 2, 3]);  mul_3884 = None
    mul_3885: "f32[72]" = torch.ops.aten.mul.Tensor(sum_332, 0.0006377551020408163)
    unsqueeze_3314: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3885, 0);  mul_3885 = None
    unsqueeze_3315: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3314, 2);  unsqueeze_3314 = None
    unsqueeze_3316: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3315, 3);  unsqueeze_3315 = None
    mul_3886: "f32[72]" = torch.ops.aten.mul.Tensor(sum_333, 0.0006377551020408163)
    mul_3887: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_478, squeeze_478)
    mul_3888: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3886, mul_3887);  mul_3886 = mul_3887 = None
    unsqueeze_3317: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3888, 0);  mul_3888 = None
    unsqueeze_3318: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3317, 2);  unsqueeze_3317 = None
    unsqueeze_3319: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3318, 3);  unsqueeze_3318 = None
    mul_3889: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_478, primals_479);  primals_479 = None
    unsqueeze_3320: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3889, 0);  mul_3889 = None
    unsqueeze_3321: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3320, 2);  unsqueeze_3320 = None
    unsqueeze_3322: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3321, 3);  unsqueeze_3321 = None
    mul_3890: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_985, unsqueeze_3319);  sub_985 = unsqueeze_3319 = None
    sub_987: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_137, mul_3890);  mul_3890 = None
    sub_988: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_987, unsqueeze_3316);  sub_987 = None
    mul_3891: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_988, unsqueeze_3322);  sub_988 = unsqueeze_3322 = None
    mul_3892: "f32[72]" = torch.ops.aten.mul.Tensor(sum_333, squeeze_478);  sum_333 = squeeze_478 = None
    convolution_backward_165 = torch.ops.aten.convolution_backward.default(mul_3891, relu_134, primals_478, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3891 = primals_478 = None
    getitem_1145: "f32[8, 36, 28, 28]" = convolution_backward_165[0]
    getitem_1146: "f32[72, 36, 3, 3]" = convolution_backward_165[1];  convolution_backward_165 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sub_989: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_158, unsqueeze_3325);  convolution_158 = unsqueeze_3325 = None
    mul_3893: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_137, sub_989)
    sum_335: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3893, [0, 2, 3]);  mul_3893 = None
    mul_3895: "f32[72]" = torch.ops.aten.mul.Tensor(sum_335, 0.0006377551020408163)
    mul_3896: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_475, squeeze_475)
    mul_3897: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3895, mul_3896);  mul_3895 = mul_3896 = None
    unsqueeze_3329: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3897, 0);  mul_3897 = None
    unsqueeze_3330: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3329, 2);  unsqueeze_3329 = None
    unsqueeze_3331: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3330, 3);  unsqueeze_3330 = None
    mul_3898: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_475, primals_476);  primals_476 = None
    unsqueeze_3332: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3898, 0);  mul_3898 = None
    unsqueeze_3333: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3332, 2);  unsqueeze_3332 = None
    unsqueeze_3334: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3333, 3);  unsqueeze_3333 = None
    mul_3899: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_989, unsqueeze_3331);  sub_989 = unsqueeze_3331 = None
    sub_991: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_137, mul_3899);  mul_3899 = None
    sub_992: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_991, unsqueeze_3316);  sub_991 = unsqueeze_3316 = None
    mul_3900: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_992, unsqueeze_3334);  sub_992 = unsqueeze_3334 = None
    mul_3901: "f32[72]" = torch.ops.aten.mul.Tensor(sum_335, squeeze_475);  sum_335 = squeeze_475 = None
    convolution_backward_166 = torch.ops.aten.convolution_backward.default(mul_3900, relu_145, primals_475, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3900 = primals_475 = None
    getitem_1148: "f32[8, 18, 28, 28]" = convolution_backward_166[0]
    getitem_1149: "f32[72, 18, 3, 3]" = convolution_backward_166[1];  convolution_backward_166 = None
    le_138: "b8[8, 18, 28, 28]" = torch.ops.aten.le.Scalar(relu_145, 0);  relu_145 = None
    where_138: "f32[8, 18, 28, 28]" = torch.ops.aten.where.self(le_138, full_default, getitem_1148);  le_138 = getitem_1148 = None
    sum_336: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_138, [0, 2, 3])
    sub_993: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_157, unsqueeze_3337);  convolution_157 = unsqueeze_3337 = None
    mul_3902: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(where_138, sub_993)
    sum_337: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3902, [0, 2, 3]);  mul_3902 = None
    mul_3903: "f32[18]" = torch.ops.aten.mul.Tensor(sum_336, 0.00015943877551020407)
    unsqueeze_3338: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3903, 0);  mul_3903 = None
    unsqueeze_3339: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3338, 2);  unsqueeze_3338 = None
    unsqueeze_3340: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3339, 3);  unsqueeze_3339 = None
    mul_3904: "f32[18]" = torch.ops.aten.mul.Tensor(sum_337, 0.00015943877551020407)
    mul_3905: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_472, squeeze_472)
    mul_3906: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3904, mul_3905);  mul_3904 = mul_3905 = None
    unsqueeze_3341: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3906, 0);  mul_3906 = None
    unsqueeze_3342: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3341, 2);  unsqueeze_3341 = None
    unsqueeze_3343: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3342, 3);  unsqueeze_3342 = None
    mul_3907: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_472, primals_473);  primals_473 = None
    unsqueeze_3344: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3907, 0);  mul_3907 = None
    unsqueeze_3345: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3344, 2);  unsqueeze_3344 = None
    unsqueeze_3346: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3345, 3);  unsqueeze_3345 = None
    mul_3908: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_993, unsqueeze_3343);  sub_993 = unsqueeze_3343 = None
    sub_995: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(where_138, mul_3908);  where_138 = mul_3908 = None
    sub_996: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_995, unsqueeze_3340);  sub_995 = unsqueeze_3340 = None
    mul_3909: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_996, unsqueeze_3346);  sub_996 = unsqueeze_3346 = None
    mul_3910: "f32[18]" = torch.ops.aten.mul.Tensor(sum_337, squeeze_472);  sum_337 = squeeze_472 = None
    convolution_backward_167 = torch.ops.aten.convolution_backward.default(mul_3909, relu_126, primals_472, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3909 = primals_472 = None
    getitem_1151: "f32[8, 18, 56, 56]" = convolution_backward_167[0]
    getitem_1152: "f32[18, 18, 3, 3]" = convolution_backward_167[1];  convolution_backward_167 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_139: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_144, 0);  relu_144 = None
    where_139: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_139, full_default, add_2009);  le_139 = add_2009 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_18: "f32[8, 36, 14, 14]" = torch.ops.aten._unsafe_index_put.default(full_default_25, [None, None, unsqueeze_259, convert_element_type_20], where_139, True)
    sum_338: "f32[36]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_18, [0, 2, 3])
    sub_997: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_156, unsqueeze_3349);  convolution_156 = unsqueeze_3349 = None
    mul_3911: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_18, sub_997)
    sum_339: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3911, [0, 2, 3]);  mul_3911 = None
    mul_3912: "f32[36]" = torch.ops.aten.mul.Tensor(sum_338, 0.0006377551020408163)
    unsqueeze_3350: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3912, 0);  mul_3912 = None
    unsqueeze_3351: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3350, 2);  unsqueeze_3350 = None
    unsqueeze_3352: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3351, 3);  unsqueeze_3351 = None
    mul_3913: "f32[36]" = torch.ops.aten.mul.Tensor(sum_339, 0.0006377551020408163)
    mul_3914: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_469, squeeze_469)
    mul_3915: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3913, mul_3914);  mul_3913 = mul_3914 = None
    unsqueeze_3353: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3915, 0);  mul_3915 = None
    unsqueeze_3354: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3353, 2);  unsqueeze_3353 = None
    unsqueeze_3355: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3354, 3);  unsqueeze_3354 = None
    mul_3916: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_469, primals_470);  primals_470 = None
    unsqueeze_3356: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3916, 0);  mul_3916 = None
    unsqueeze_3357: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3356, 2);  unsqueeze_3356 = None
    unsqueeze_3358: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3357, 3);  unsqueeze_3357 = None
    mul_3917: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_997, unsqueeze_3355);  sub_997 = unsqueeze_3355 = None
    sub_999: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_18, mul_3917);  _unsafe_index_put_18 = mul_3917 = None
    sub_1000: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(sub_999, unsqueeze_3352);  sub_999 = unsqueeze_3352 = None
    mul_3918: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1000, unsqueeze_3358);  sub_1000 = unsqueeze_3358 = None
    mul_3919: "f32[36]" = torch.ops.aten.mul.Tensor(sum_339, squeeze_469);  sum_339 = squeeze_469 = None
    convolution_backward_168 = torch.ops.aten.convolution_backward.default(mul_3918, relu_142, primals_469, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3918 = primals_469 = None
    getitem_1154: "f32[8, 72, 14, 14]" = convolution_backward_168[0]
    getitem_1155: "f32[36, 72, 1, 1]" = convolution_backward_168[1];  convolution_backward_168 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_2015: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_137, getitem_1154);  where_137 = getitem_1154 = None
    add_2016: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(getitem_1145, where_139);  getitem_1145 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sum_340: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_139, [0, 2, 3])
    sub_1001: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_155, unsqueeze_3361);  convolution_155 = unsqueeze_3361 = None
    mul_3920: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_139, sub_1001)
    sum_341: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_3920, [0, 2, 3]);  mul_3920 = None
    mul_3921: "f32[36]" = torch.ops.aten.mul.Tensor(sum_340, 0.00015943877551020407)
    unsqueeze_3362: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3921, 0);  mul_3921 = None
    unsqueeze_3363: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3362, 2);  unsqueeze_3362 = None
    unsqueeze_3364: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3363, 3);  unsqueeze_3363 = None
    mul_3922: "f32[36]" = torch.ops.aten.mul.Tensor(sum_341, 0.00015943877551020407)
    mul_3923: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_466, squeeze_466)
    mul_3924: "f32[36]" = torch.ops.aten.mul.Tensor(mul_3922, mul_3923);  mul_3922 = mul_3923 = None
    unsqueeze_3365: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3924, 0);  mul_3924 = None
    unsqueeze_3366: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3365, 2);  unsqueeze_3365 = None
    unsqueeze_3367: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3366, 3);  unsqueeze_3366 = None
    mul_3925: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_466, primals_467);  primals_467 = None
    unsqueeze_3368: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_3925, 0);  mul_3925 = None
    unsqueeze_3369: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3368, 2);  unsqueeze_3368 = None
    unsqueeze_3370: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3369, 3);  unsqueeze_3369 = None
    mul_3926: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1001, unsqueeze_3367);  sub_1001 = unsqueeze_3367 = None
    sub_1003: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_139, mul_3926);  where_139 = mul_3926 = None
    sub_1004: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1003, unsqueeze_3364);  sub_1003 = unsqueeze_3364 = None
    mul_3927: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1004, unsqueeze_3370);  sub_1004 = unsqueeze_3370 = None
    mul_3928: "f32[36]" = torch.ops.aten.mul.Tensor(sum_341, squeeze_466);  sum_341 = squeeze_466 = None
    convolution_backward_169 = torch.ops.aten.convolution_backward.default(mul_3927, relu_126, primals_466, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3927 = primals_466 = None
    getitem_1157: "f32[8, 18, 56, 56]" = convolution_backward_169[0]
    getitem_1158: "f32[36, 18, 3, 3]" = convolution_backward_169[1];  convolution_backward_169 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    add_2017: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(getitem_1151, getitem_1157);  getitem_1151 = getitem_1157 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_140: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_143, 0);  relu_143 = None
    where_140: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_140, full_default, add_2013);  le_140 = add_2013 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_19: "f32[8, 18, 14, 14]" = torch.ops.aten._unsafe_index_put.default(full_default_28, [None, None, unsqueeze_250, convert_element_type_14], where_140, True)
    sum_342: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_19, [0, 2, 3])
    sub_1005: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_154, unsqueeze_3373);  convolution_154 = unsqueeze_3373 = None
    mul_3929: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_19, sub_1005)
    sum_343: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3929, [0, 2, 3]);  mul_3929 = None
    mul_3930: "f32[18]" = torch.ops.aten.mul.Tensor(sum_342, 0.0006377551020408163)
    unsqueeze_3374: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3930, 0);  mul_3930 = None
    unsqueeze_3375: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3374, 2);  unsqueeze_3374 = None
    unsqueeze_3376: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3375, 3);  unsqueeze_3375 = None
    mul_3931: "f32[18]" = torch.ops.aten.mul.Tensor(sum_343, 0.0006377551020408163)
    mul_3932: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_463, squeeze_463)
    mul_3933: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3931, mul_3932);  mul_3931 = mul_3932 = None
    unsqueeze_3377: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3933, 0);  mul_3933 = None
    unsqueeze_3378: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3377, 2);  unsqueeze_3377 = None
    unsqueeze_3379: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3378, 3);  unsqueeze_3378 = None
    mul_3934: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_463, primals_464);  primals_464 = None
    unsqueeze_3380: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3934, 0);  mul_3934 = None
    unsqueeze_3381: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3380, 2);  unsqueeze_3380 = None
    unsqueeze_3382: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3381, 3);  unsqueeze_3381 = None
    mul_3935: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1005, unsqueeze_3379);  sub_1005 = unsqueeze_3379 = None
    sub_1007: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_19, mul_3935);  _unsafe_index_put_19 = mul_3935 = None
    sub_1008: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1007, unsqueeze_3376);  sub_1007 = unsqueeze_3376 = None
    mul_3936: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1008, unsqueeze_3382);  sub_1008 = unsqueeze_3382 = None
    mul_3937: "f32[18]" = torch.ops.aten.mul.Tensor(sum_343, squeeze_463);  sum_343 = squeeze_463 = None
    convolution_backward_170 = torch.ops.aten.convolution_backward.default(mul_3936, relu_142, primals_463, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3936 = primals_463 = None
    getitem_1160: "f32[8, 72, 14, 14]" = convolution_backward_170[0]
    getitem_1161: "f32[18, 72, 1, 1]" = convolution_backward_170[1];  convolution_backward_170 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_2018: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(add_2015, getitem_1160);  add_2015 = getitem_1160 = None
    add_2019: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(add_2017, where_140);  add_2017 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_20: "f32[8, 18, 28, 28]" = torch.ops.aten._unsafe_index_put.default(full_default_29, [None, None, unsqueeze_136, convert_element_type_2], where_140, True);  where_140 = None
    sum_344: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_20, [0, 2, 3])
    sub_1009: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_153, unsqueeze_3385);  convolution_153 = unsqueeze_3385 = None
    mul_3938: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_20, sub_1009)
    sum_345: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_3938, [0, 2, 3]);  mul_3938 = None
    mul_3939: "f32[18]" = torch.ops.aten.mul.Tensor(sum_344, 0.00015943877551020407)
    unsqueeze_3386: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3939, 0);  mul_3939 = None
    unsqueeze_3387: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3386, 2);  unsqueeze_3386 = None
    unsqueeze_3388: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3387, 3);  unsqueeze_3387 = None
    mul_3940: "f32[18]" = torch.ops.aten.mul.Tensor(sum_345, 0.00015943877551020407)
    mul_3941: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_460, squeeze_460)
    mul_3942: "f32[18]" = torch.ops.aten.mul.Tensor(mul_3940, mul_3941);  mul_3940 = mul_3941 = None
    unsqueeze_3389: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3942, 0);  mul_3942 = None
    unsqueeze_3390: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3389, 2);  unsqueeze_3389 = None
    unsqueeze_3391: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3390, 3);  unsqueeze_3390 = None
    mul_3943: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_460, primals_461);  primals_461 = None
    unsqueeze_3392: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_3943, 0);  mul_3943 = None
    unsqueeze_3393: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3392, 2);  unsqueeze_3392 = None
    unsqueeze_3394: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3393, 3);  unsqueeze_3393 = None
    mul_3944: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1009, unsqueeze_3391);  sub_1009 = unsqueeze_3391 = None
    sub_1011: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_20, mul_3944);  _unsafe_index_put_20 = mul_3944 = None
    sub_1012: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1011, unsqueeze_3388);  sub_1011 = unsqueeze_3388 = None
    mul_3945: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1012, unsqueeze_3394);  sub_1012 = unsqueeze_3394 = None
    mul_3946: "f32[18]" = torch.ops.aten.mul.Tensor(sum_345, squeeze_460);  sum_345 = squeeze_460 = None
    convolution_backward_171 = torch.ops.aten.convolution_backward.default(mul_3945, relu_134, primals_460, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3945 = primals_460 = None
    getitem_1163: "f32[8, 36, 28, 28]" = convolution_backward_171[0]
    getitem_1164: "f32[18, 36, 1, 1]" = convolution_backward_171[1];  convolution_backward_171 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_2020: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(add_2016, getitem_1163);  add_2016 = getitem_1163 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_141: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_142, 0);  relu_142 = None
    where_141: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_141, full_default, add_2018);  le_141 = add_2018 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_346: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_141, [0, 2, 3])
    sub_1013: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_152, unsqueeze_3397);  convolution_152 = unsqueeze_3397 = None
    mul_3947: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_141, sub_1013)
    sum_347: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3947, [0, 2, 3]);  mul_3947 = None
    mul_3948: "f32[72]" = torch.ops.aten.mul.Tensor(sum_346, 0.0006377551020408163)
    unsqueeze_3398: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3948, 0);  mul_3948 = None
    unsqueeze_3399: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3398, 2);  unsqueeze_3398 = None
    unsqueeze_3400: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3399, 3);  unsqueeze_3399 = None
    mul_3949: "f32[72]" = torch.ops.aten.mul.Tensor(sum_347, 0.0006377551020408163)
    mul_3950: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_457, squeeze_457)
    mul_3951: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3949, mul_3950);  mul_3949 = mul_3950 = None
    unsqueeze_3401: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3951, 0);  mul_3951 = None
    unsqueeze_3402: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3401, 2);  unsqueeze_3401 = None
    unsqueeze_3403: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3402, 3);  unsqueeze_3402 = None
    mul_3952: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_457, primals_458);  primals_458 = None
    unsqueeze_3404: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3952, 0);  mul_3952 = None
    unsqueeze_3405: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3404, 2);  unsqueeze_3404 = None
    unsqueeze_3406: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3405, 3);  unsqueeze_3405 = None
    mul_3953: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1013, unsqueeze_3403);  sub_1013 = unsqueeze_3403 = None
    sub_1015: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_141, mul_3953);  mul_3953 = None
    sub_1016: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1015, unsqueeze_3400);  sub_1015 = unsqueeze_3400 = None
    mul_3954: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1016, unsqueeze_3406);  sub_1016 = unsqueeze_3406 = None
    mul_3955: "f32[72]" = torch.ops.aten.mul.Tensor(sum_347, squeeze_457);  sum_347 = squeeze_457 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_172 = torch.ops.aten.convolution_backward.default(mul_3954, relu_141, primals_457, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3954 = primals_457 = None
    getitem_1166: "f32[8, 72, 14, 14]" = convolution_backward_172[0]
    getitem_1167: "f32[72, 72, 3, 3]" = convolution_backward_172[1];  convolution_backward_172 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_142: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_141, 0);  relu_141 = None
    where_142: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_142, full_default, getitem_1166);  le_142 = getitem_1166 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_348: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_142, [0, 2, 3])
    sub_1017: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_151, unsqueeze_3409);  convolution_151 = unsqueeze_3409 = None
    mul_3956: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_142, sub_1017)
    sum_349: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3956, [0, 2, 3]);  mul_3956 = None
    mul_3957: "f32[72]" = torch.ops.aten.mul.Tensor(sum_348, 0.0006377551020408163)
    unsqueeze_3410: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3957, 0);  mul_3957 = None
    unsqueeze_3411: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3410, 2);  unsqueeze_3410 = None
    unsqueeze_3412: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3411, 3);  unsqueeze_3411 = None
    mul_3958: "f32[72]" = torch.ops.aten.mul.Tensor(sum_349, 0.0006377551020408163)
    mul_3959: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_454, squeeze_454)
    mul_3960: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3958, mul_3959);  mul_3958 = mul_3959 = None
    unsqueeze_3413: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3960, 0);  mul_3960 = None
    unsqueeze_3414: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3413, 2);  unsqueeze_3413 = None
    unsqueeze_3415: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3414, 3);  unsqueeze_3414 = None
    mul_3961: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_454, primals_455);  primals_455 = None
    unsqueeze_3416: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3961, 0);  mul_3961 = None
    unsqueeze_3417: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3416, 2);  unsqueeze_3416 = None
    unsqueeze_3418: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3417, 3);  unsqueeze_3417 = None
    mul_3962: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1017, unsqueeze_3415);  sub_1017 = unsqueeze_3415 = None
    sub_1019: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_142, mul_3962);  where_142 = mul_3962 = None
    sub_1020: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1019, unsqueeze_3412);  sub_1019 = unsqueeze_3412 = None
    mul_3963: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1020, unsqueeze_3418);  sub_1020 = unsqueeze_3418 = None
    mul_3964: "f32[72]" = torch.ops.aten.mul.Tensor(sum_349, squeeze_454);  sum_349 = squeeze_454 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_173 = torch.ops.aten.convolution_backward.default(mul_3963, relu_140, primals_454, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3963 = primals_454 = None
    getitem_1169: "f32[8, 72, 14, 14]" = convolution_backward_173[0]
    getitem_1170: "f32[72, 72, 3, 3]" = convolution_backward_173[1];  convolution_backward_173 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2021: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_141, getitem_1169);  where_141 = getitem_1169 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_143: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_140, 0);  relu_140 = None
    where_143: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_143, full_default, add_2021);  le_143 = add_2021 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_350: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_143, [0, 2, 3])
    sub_1021: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_150, unsqueeze_3421);  convolution_150 = unsqueeze_3421 = None
    mul_3965: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_143, sub_1021)
    sum_351: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3965, [0, 2, 3]);  mul_3965 = None
    mul_3966: "f32[72]" = torch.ops.aten.mul.Tensor(sum_350, 0.0006377551020408163)
    unsqueeze_3422: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3966, 0);  mul_3966 = None
    unsqueeze_3423: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3422, 2);  unsqueeze_3422 = None
    unsqueeze_3424: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3423, 3);  unsqueeze_3423 = None
    mul_3967: "f32[72]" = torch.ops.aten.mul.Tensor(sum_351, 0.0006377551020408163)
    mul_3968: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_451, squeeze_451)
    mul_3969: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3967, mul_3968);  mul_3967 = mul_3968 = None
    unsqueeze_3425: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3969, 0);  mul_3969 = None
    unsqueeze_3426: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3425, 2);  unsqueeze_3425 = None
    unsqueeze_3427: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3426, 3);  unsqueeze_3426 = None
    mul_3970: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_451, primals_452);  primals_452 = None
    unsqueeze_3428: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3970, 0);  mul_3970 = None
    unsqueeze_3429: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3428, 2);  unsqueeze_3428 = None
    unsqueeze_3430: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3429, 3);  unsqueeze_3429 = None
    mul_3971: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1021, unsqueeze_3427);  sub_1021 = unsqueeze_3427 = None
    sub_1023: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_143, mul_3971);  mul_3971 = None
    sub_1024: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1023, unsqueeze_3424);  sub_1023 = unsqueeze_3424 = None
    mul_3972: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1024, unsqueeze_3430);  sub_1024 = unsqueeze_3430 = None
    mul_3973: "f32[72]" = torch.ops.aten.mul.Tensor(sum_351, squeeze_451);  sum_351 = squeeze_451 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_174 = torch.ops.aten.convolution_backward.default(mul_3972, relu_139, primals_451, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3972 = primals_451 = None
    getitem_1172: "f32[8, 72, 14, 14]" = convolution_backward_174[0]
    getitem_1173: "f32[72, 72, 3, 3]" = convolution_backward_174[1];  convolution_backward_174 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_144: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_139, 0);  relu_139 = None
    where_144: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_144, full_default, getitem_1172);  le_144 = getitem_1172 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_352: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_144, [0, 2, 3])
    sub_1025: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_149, unsqueeze_3433);  convolution_149 = unsqueeze_3433 = None
    mul_3974: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_144, sub_1025)
    sum_353: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3974, [0, 2, 3]);  mul_3974 = None
    mul_3975: "f32[72]" = torch.ops.aten.mul.Tensor(sum_352, 0.0006377551020408163)
    unsqueeze_3434: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3975, 0);  mul_3975 = None
    unsqueeze_3435: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3434, 2);  unsqueeze_3434 = None
    unsqueeze_3436: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3435, 3);  unsqueeze_3435 = None
    mul_3976: "f32[72]" = torch.ops.aten.mul.Tensor(sum_353, 0.0006377551020408163)
    mul_3977: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_448, squeeze_448)
    mul_3978: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3976, mul_3977);  mul_3976 = mul_3977 = None
    unsqueeze_3437: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3978, 0);  mul_3978 = None
    unsqueeze_3438: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3437, 2);  unsqueeze_3437 = None
    unsqueeze_3439: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3438, 3);  unsqueeze_3438 = None
    mul_3979: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_448, primals_449);  primals_449 = None
    unsqueeze_3440: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3979, 0);  mul_3979 = None
    unsqueeze_3441: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3440, 2);  unsqueeze_3440 = None
    unsqueeze_3442: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3441, 3);  unsqueeze_3441 = None
    mul_3980: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1025, unsqueeze_3439);  sub_1025 = unsqueeze_3439 = None
    sub_1027: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_144, mul_3980);  where_144 = mul_3980 = None
    sub_1028: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1027, unsqueeze_3436);  sub_1027 = unsqueeze_3436 = None
    mul_3981: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1028, unsqueeze_3442);  sub_1028 = unsqueeze_3442 = None
    mul_3982: "f32[72]" = torch.ops.aten.mul.Tensor(sum_353, squeeze_448);  sum_353 = squeeze_448 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_175 = torch.ops.aten.convolution_backward.default(mul_3981, relu_138, primals_448, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3981 = primals_448 = None
    getitem_1175: "f32[8, 72, 14, 14]" = convolution_backward_175[0]
    getitem_1176: "f32[72, 72, 3, 3]" = convolution_backward_175[1];  convolution_backward_175 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2022: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_143, getitem_1175);  where_143 = getitem_1175 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_145: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_138, 0);  relu_138 = None
    where_145: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_145, full_default, add_2022);  le_145 = add_2022 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_354: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_145, [0, 2, 3])
    sub_1029: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_148, unsqueeze_3445);  convolution_148 = unsqueeze_3445 = None
    mul_3983: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_145, sub_1029)
    sum_355: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3983, [0, 2, 3]);  mul_3983 = None
    mul_3984: "f32[72]" = torch.ops.aten.mul.Tensor(sum_354, 0.0006377551020408163)
    unsqueeze_3446: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3984, 0);  mul_3984 = None
    unsqueeze_3447: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3446, 2);  unsqueeze_3446 = None
    unsqueeze_3448: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3447, 3);  unsqueeze_3447 = None
    mul_3985: "f32[72]" = torch.ops.aten.mul.Tensor(sum_355, 0.0006377551020408163)
    mul_3986: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_445, squeeze_445)
    mul_3987: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3985, mul_3986);  mul_3985 = mul_3986 = None
    unsqueeze_3449: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3987, 0);  mul_3987 = None
    unsqueeze_3450: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3449, 2);  unsqueeze_3449 = None
    unsqueeze_3451: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3450, 3);  unsqueeze_3450 = None
    mul_3988: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_445, primals_446);  primals_446 = None
    unsqueeze_3452: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3988, 0);  mul_3988 = None
    unsqueeze_3453: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3452, 2);  unsqueeze_3452 = None
    unsqueeze_3454: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3453, 3);  unsqueeze_3453 = None
    mul_3989: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1029, unsqueeze_3451);  sub_1029 = unsqueeze_3451 = None
    sub_1031: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_145, mul_3989);  mul_3989 = None
    sub_1032: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1031, unsqueeze_3448);  sub_1031 = unsqueeze_3448 = None
    mul_3990: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1032, unsqueeze_3454);  sub_1032 = unsqueeze_3454 = None
    mul_3991: "f32[72]" = torch.ops.aten.mul.Tensor(sum_355, squeeze_445);  sum_355 = squeeze_445 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_176 = torch.ops.aten.convolution_backward.default(mul_3990, relu_137, primals_445, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3990 = primals_445 = None
    getitem_1178: "f32[8, 72, 14, 14]" = convolution_backward_176[0]
    getitem_1179: "f32[72, 72, 3, 3]" = convolution_backward_176[1];  convolution_backward_176 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_146: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_137, 0);  relu_137 = None
    where_146: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_146, full_default, getitem_1178);  le_146 = getitem_1178 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_356: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_146, [0, 2, 3])
    sub_1033: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_147, unsqueeze_3457);  convolution_147 = unsqueeze_3457 = None
    mul_3992: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_146, sub_1033)
    sum_357: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_3992, [0, 2, 3]);  mul_3992 = None
    mul_3993: "f32[72]" = torch.ops.aten.mul.Tensor(sum_356, 0.0006377551020408163)
    unsqueeze_3458: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3993, 0);  mul_3993 = None
    unsqueeze_3459: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3458, 2);  unsqueeze_3458 = None
    unsqueeze_3460: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3459, 3);  unsqueeze_3459 = None
    mul_3994: "f32[72]" = torch.ops.aten.mul.Tensor(sum_357, 0.0006377551020408163)
    mul_3995: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_442, squeeze_442)
    mul_3996: "f32[72]" = torch.ops.aten.mul.Tensor(mul_3994, mul_3995);  mul_3994 = mul_3995 = None
    unsqueeze_3461: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3996, 0);  mul_3996 = None
    unsqueeze_3462: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3461, 2);  unsqueeze_3461 = None
    unsqueeze_3463: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3462, 3);  unsqueeze_3462 = None
    mul_3997: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_442, primals_443);  primals_443 = None
    unsqueeze_3464: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_3997, 0);  mul_3997 = None
    unsqueeze_3465: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3464, 2);  unsqueeze_3464 = None
    unsqueeze_3466: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3465, 3);  unsqueeze_3465 = None
    mul_3998: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1033, unsqueeze_3463);  sub_1033 = unsqueeze_3463 = None
    sub_1035: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_146, mul_3998);  where_146 = mul_3998 = None
    sub_1036: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1035, unsqueeze_3460);  sub_1035 = unsqueeze_3460 = None
    mul_3999: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1036, unsqueeze_3466);  sub_1036 = unsqueeze_3466 = None
    mul_4000: "f32[72]" = torch.ops.aten.mul.Tensor(sum_357, squeeze_442);  sum_357 = squeeze_442 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_177 = torch.ops.aten.convolution_backward.default(mul_3999, relu_136, primals_442, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_3999 = primals_442 = None
    getitem_1181: "f32[8, 72, 14, 14]" = convolution_backward_177[0]
    getitem_1182: "f32[72, 72, 3, 3]" = convolution_backward_177[1];  convolution_backward_177 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2023: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_145, getitem_1181);  where_145 = getitem_1181 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_147: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_136, 0);  relu_136 = None
    where_147: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_147, full_default, add_2023);  le_147 = add_2023 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_358: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_147, [0, 2, 3])
    sub_1037: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_146, unsqueeze_3469);  convolution_146 = unsqueeze_3469 = None
    mul_4001: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_147, sub_1037)
    sum_359: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4001, [0, 2, 3]);  mul_4001 = None
    mul_4002: "f32[72]" = torch.ops.aten.mul.Tensor(sum_358, 0.0006377551020408163)
    unsqueeze_3470: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4002, 0);  mul_4002 = None
    unsqueeze_3471: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3470, 2);  unsqueeze_3470 = None
    unsqueeze_3472: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3471, 3);  unsqueeze_3471 = None
    mul_4003: "f32[72]" = torch.ops.aten.mul.Tensor(sum_359, 0.0006377551020408163)
    mul_4004: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_439, squeeze_439)
    mul_4005: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4003, mul_4004);  mul_4003 = mul_4004 = None
    unsqueeze_3473: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4005, 0);  mul_4005 = None
    unsqueeze_3474: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3473, 2);  unsqueeze_3473 = None
    unsqueeze_3475: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3474, 3);  unsqueeze_3474 = None
    mul_4006: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_439, primals_440);  primals_440 = None
    unsqueeze_3476: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4006, 0);  mul_4006 = None
    unsqueeze_3477: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3476, 2);  unsqueeze_3476 = None
    unsqueeze_3478: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3477, 3);  unsqueeze_3477 = None
    mul_4007: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1037, unsqueeze_3475);  sub_1037 = unsqueeze_3475 = None
    sub_1039: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_147, mul_4007);  mul_4007 = None
    sub_1040: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1039, unsqueeze_3472);  sub_1039 = unsqueeze_3472 = None
    mul_4008: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1040, unsqueeze_3478);  sub_1040 = unsqueeze_3478 = None
    mul_4009: "f32[72]" = torch.ops.aten.mul.Tensor(sum_359, squeeze_439);  sum_359 = squeeze_439 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_178 = torch.ops.aten.convolution_backward.default(mul_4008, relu_135, primals_439, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4008 = primals_439 = None
    getitem_1184: "f32[8, 72, 14, 14]" = convolution_backward_178[0]
    getitem_1185: "f32[72, 72, 3, 3]" = convolution_backward_178[1];  convolution_backward_178 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_148: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_135, 0);  relu_135 = None
    where_148: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_148, full_default, getitem_1184);  le_148 = getitem_1184 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_360: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_148, [0, 2, 3])
    sub_1041: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_145, unsqueeze_3481);  convolution_145 = unsqueeze_3481 = None
    mul_4010: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_148, sub_1041)
    sum_361: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4010, [0, 2, 3]);  mul_4010 = None
    mul_4011: "f32[72]" = torch.ops.aten.mul.Tensor(sum_360, 0.0006377551020408163)
    unsqueeze_3482: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4011, 0);  mul_4011 = None
    unsqueeze_3483: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3482, 2);  unsqueeze_3482 = None
    unsqueeze_3484: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3483, 3);  unsqueeze_3483 = None
    mul_4012: "f32[72]" = torch.ops.aten.mul.Tensor(sum_361, 0.0006377551020408163)
    mul_4013: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_436, squeeze_436)
    mul_4014: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4012, mul_4013);  mul_4012 = mul_4013 = None
    unsqueeze_3485: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4014, 0);  mul_4014 = None
    unsqueeze_3486: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3485, 2);  unsqueeze_3485 = None
    unsqueeze_3487: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3486, 3);  unsqueeze_3486 = None
    mul_4015: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_436, primals_437);  primals_437 = None
    unsqueeze_3488: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4015, 0);  mul_4015 = None
    unsqueeze_3489: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3488, 2);  unsqueeze_3488 = None
    unsqueeze_3490: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3489, 3);  unsqueeze_3489 = None
    mul_4016: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1041, unsqueeze_3487);  sub_1041 = unsqueeze_3487 = None
    sub_1043: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_148, mul_4016);  where_148 = mul_4016 = None
    sub_1044: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1043, unsqueeze_3484);  sub_1043 = unsqueeze_3484 = None
    mul_4017: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1044, unsqueeze_3490);  sub_1044 = unsqueeze_3490 = None
    mul_4018: "f32[72]" = torch.ops.aten.mul.Tensor(sum_361, squeeze_436);  sum_361 = squeeze_436 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_179 = torch.ops.aten.convolution_backward.default(mul_4017, relu_118, primals_436, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4017 = primals_436 = None
    getitem_1187: "f32[8, 72, 14, 14]" = convolution_backward_179[0]
    getitem_1188: "f32[72, 72, 3, 3]" = convolution_backward_179[1];  convolution_backward_179 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2024: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_147, getitem_1187);  where_147 = getitem_1187 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_149: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_134, 0);  relu_134 = None
    where_149: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_149, full_default, add_2020);  le_149 = add_2020 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_362: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_149, [0, 2, 3])
    sub_1045: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_144, unsqueeze_3493);  convolution_144 = unsqueeze_3493 = None
    mul_4019: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_149, sub_1045)
    sum_363: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4019, [0, 2, 3]);  mul_4019 = None
    mul_4020: "f32[36]" = torch.ops.aten.mul.Tensor(sum_362, 0.00015943877551020407)
    unsqueeze_3494: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4020, 0);  mul_4020 = None
    unsqueeze_3495: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3494, 2);  unsqueeze_3494 = None
    unsqueeze_3496: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3495, 3);  unsqueeze_3495 = None
    mul_4021: "f32[36]" = torch.ops.aten.mul.Tensor(sum_363, 0.00015943877551020407)
    mul_4022: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_433, squeeze_433)
    mul_4023: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4021, mul_4022);  mul_4021 = mul_4022 = None
    unsqueeze_3497: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4023, 0);  mul_4023 = None
    unsqueeze_3498: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3497, 2);  unsqueeze_3497 = None
    unsqueeze_3499: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3498, 3);  unsqueeze_3498 = None
    mul_4024: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_433, primals_434);  primals_434 = None
    unsqueeze_3500: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4024, 0);  mul_4024 = None
    unsqueeze_3501: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3500, 2);  unsqueeze_3500 = None
    unsqueeze_3502: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3501, 3);  unsqueeze_3501 = None
    mul_4025: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1045, unsqueeze_3499);  sub_1045 = unsqueeze_3499 = None
    sub_1047: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_149, mul_4025);  mul_4025 = None
    sub_1048: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1047, unsqueeze_3496);  sub_1047 = unsqueeze_3496 = None
    mul_4026: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1048, unsqueeze_3502);  sub_1048 = unsqueeze_3502 = None
    mul_4027: "f32[36]" = torch.ops.aten.mul.Tensor(sum_363, squeeze_433);  sum_363 = squeeze_433 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_180 = torch.ops.aten.convolution_backward.default(mul_4026, relu_133, primals_433, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4026 = primals_433 = None
    getitem_1190: "f32[8, 36, 28, 28]" = convolution_backward_180[0]
    getitem_1191: "f32[36, 36, 3, 3]" = convolution_backward_180[1];  convolution_backward_180 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_150: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_133, 0);  relu_133 = None
    where_150: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_150, full_default, getitem_1190);  le_150 = getitem_1190 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_364: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_150, [0, 2, 3])
    sub_1049: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_143, unsqueeze_3505);  convolution_143 = unsqueeze_3505 = None
    mul_4028: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_150, sub_1049)
    sum_365: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4028, [0, 2, 3]);  mul_4028 = None
    mul_4029: "f32[36]" = torch.ops.aten.mul.Tensor(sum_364, 0.00015943877551020407)
    unsqueeze_3506: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4029, 0);  mul_4029 = None
    unsqueeze_3507: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3506, 2);  unsqueeze_3506 = None
    unsqueeze_3508: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3507, 3);  unsqueeze_3507 = None
    mul_4030: "f32[36]" = torch.ops.aten.mul.Tensor(sum_365, 0.00015943877551020407)
    mul_4031: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_430, squeeze_430)
    mul_4032: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4030, mul_4031);  mul_4030 = mul_4031 = None
    unsqueeze_3509: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4032, 0);  mul_4032 = None
    unsqueeze_3510: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3509, 2);  unsqueeze_3509 = None
    unsqueeze_3511: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3510, 3);  unsqueeze_3510 = None
    mul_4033: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_430, primals_431);  primals_431 = None
    unsqueeze_3512: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4033, 0);  mul_4033 = None
    unsqueeze_3513: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3512, 2);  unsqueeze_3512 = None
    unsqueeze_3514: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3513, 3);  unsqueeze_3513 = None
    mul_4034: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1049, unsqueeze_3511);  sub_1049 = unsqueeze_3511 = None
    sub_1051: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_150, mul_4034);  where_150 = mul_4034 = None
    sub_1052: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1051, unsqueeze_3508);  sub_1051 = unsqueeze_3508 = None
    mul_4035: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1052, unsqueeze_3514);  sub_1052 = unsqueeze_3514 = None
    mul_4036: "f32[36]" = torch.ops.aten.mul.Tensor(sum_365, squeeze_430);  sum_365 = squeeze_430 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_181 = torch.ops.aten.convolution_backward.default(mul_4035, relu_132, primals_430, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4035 = primals_430 = None
    getitem_1193: "f32[8, 36, 28, 28]" = convolution_backward_181[0]
    getitem_1194: "f32[36, 36, 3, 3]" = convolution_backward_181[1];  convolution_backward_181 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2025: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_149, getitem_1193);  where_149 = getitem_1193 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_151: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_132, 0);  relu_132 = None
    where_151: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_151, full_default, add_2025);  le_151 = add_2025 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_366: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_151, [0, 2, 3])
    sub_1053: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_142, unsqueeze_3517);  convolution_142 = unsqueeze_3517 = None
    mul_4037: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_151, sub_1053)
    sum_367: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4037, [0, 2, 3]);  mul_4037 = None
    mul_4038: "f32[36]" = torch.ops.aten.mul.Tensor(sum_366, 0.00015943877551020407)
    unsqueeze_3518: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4038, 0);  mul_4038 = None
    unsqueeze_3519: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3518, 2);  unsqueeze_3518 = None
    unsqueeze_3520: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3519, 3);  unsqueeze_3519 = None
    mul_4039: "f32[36]" = torch.ops.aten.mul.Tensor(sum_367, 0.00015943877551020407)
    mul_4040: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_427, squeeze_427)
    mul_4041: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4039, mul_4040);  mul_4039 = mul_4040 = None
    unsqueeze_3521: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4041, 0);  mul_4041 = None
    unsqueeze_3522: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3521, 2);  unsqueeze_3521 = None
    unsqueeze_3523: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3522, 3);  unsqueeze_3522 = None
    mul_4042: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_427, primals_428);  primals_428 = None
    unsqueeze_3524: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4042, 0);  mul_4042 = None
    unsqueeze_3525: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3524, 2);  unsqueeze_3524 = None
    unsqueeze_3526: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3525, 3);  unsqueeze_3525 = None
    mul_4043: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1053, unsqueeze_3523);  sub_1053 = unsqueeze_3523 = None
    sub_1055: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_151, mul_4043);  mul_4043 = None
    sub_1056: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1055, unsqueeze_3520);  sub_1055 = unsqueeze_3520 = None
    mul_4044: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1056, unsqueeze_3526);  sub_1056 = unsqueeze_3526 = None
    mul_4045: "f32[36]" = torch.ops.aten.mul.Tensor(sum_367, squeeze_427);  sum_367 = squeeze_427 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_182 = torch.ops.aten.convolution_backward.default(mul_4044, relu_131, primals_427, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4044 = primals_427 = None
    getitem_1196: "f32[8, 36, 28, 28]" = convolution_backward_182[0]
    getitem_1197: "f32[36, 36, 3, 3]" = convolution_backward_182[1];  convolution_backward_182 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_152: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_131, 0);  relu_131 = None
    where_152: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_152, full_default, getitem_1196);  le_152 = getitem_1196 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_368: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_152, [0, 2, 3])
    sub_1057: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_141, unsqueeze_3529);  convolution_141 = unsqueeze_3529 = None
    mul_4046: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_152, sub_1057)
    sum_369: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4046, [0, 2, 3]);  mul_4046 = None
    mul_4047: "f32[36]" = torch.ops.aten.mul.Tensor(sum_368, 0.00015943877551020407)
    unsqueeze_3530: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4047, 0);  mul_4047 = None
    unsqueeze_3531: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3530, 2);  unsqueeze_3530 = None
    unsqueeze_3532: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3531, 3);  unsqueeze_3531 = None
    mul_4048: "f32[36]" = torch.ops.aten.mul.Tensor(sum_369, 0.00015943877551020407)
    mul_4049: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_424, squeeze_424)
    mul_4050: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4048, mul_4049);  mul_4048 = mul_4049 = None
    unsqueeze_3533: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4050, 0);  mul_4050 = None
    unsqueeze_3534: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3533, 2);  unsqueeze_3533 = None
    unsqueeze_3535: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3534, 3);  unsqueeze_3534 = None
    mul_4051: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_424, primals_425);  primals_425 = None
    unsqueeze_3536: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4051, 0);  mul_4051 = None
    unsqueeze_3537: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3536, 2);  unsqueeze_3536 = None
    unsqueeze_3538: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3537, 3);  unsqueeze_3537 = None
    mul_4052: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1057, unsqueeze_3535);  sub_1057 = unsqueeze_3535 = None
    sub_1059: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_152, mul_4052);  where_152 = mul_4052 = None
    sub_1060: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1059, unsqueeze_3532);  sub_1059 = unsqueeze_3532 = None
    mul_4053: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1060, unsqueeze_3538);  sub_1060 = unsqueeze_3538 = None
    mul_4054: "f32[36]" = torch.ops.aten.mul.Tensor(sum_369, squeeze_424);  sum_369 = squeeze_424 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_183 = torch.ops.aten.convolution_backward.default(mul_4053, relu_130, primals_424, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4053 = primals_424 = None
    getitem_1199: "f32[8, 36, 28, 28]" = convolution_backward_183[0]
    getitem_1200: "f32[36, 36, 3, 3]" = convolution_backward_183[1];  convolution_backward_183 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2026: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_151, getitem_1199);  where_151 = getitem_1199 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_153: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_130, 0);  relu_130 = None
    where_153: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_153, full_default, add_2026);  le_153 = add_2026 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_370: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_153, [0, 2, 3])
    sub_1061: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_140, unsqueeze_3541);  convolution_140 = unsqueeze_3541 = None
    mul_4055: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_153, sub_1061)
    sum_371: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4055, [0, 2, 3]);  mul_4055 = None
    mul_4056: "f32[36]" = torch.ops.aten.mul.Tensor(sum_370, 0.00015943877551020407)
    unsqueeze_3542: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4056, 0);  mul_4056 = None
    unsqueeze_3543: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3542, 2);  unsqueeze_3542 = None
    unsqueeze_3544: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3543, 3);  unsqueeze_3543 = None
    mul_4057: "f32[36]" = torch.ops.aten.mul.Tensor(sum_371, 0.00015943877551020407)
    mul_4058: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_421, squeeze_421)
    mul_4059: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4057, mul_4058);  mul_4057 = mul_4058 = None
    unsqueeze_3545: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4059, 0);  mul_4059 = None
    unsqueeze_3546: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3545, 2);  unsqueeze_3545 = None
    unsqueeze_3547: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3546, 3);  unsqueeze_3546 = None
    mul_4060: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_421, primals_422);  primals_422 = None
    unsqueeze_3548: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4060, 0);  mul_4060 = None
    unsqueeze_3549: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3548, 2);  unsqueeze_3548 = None
    unsqueeze_3550: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3549, 3);  unsqueeze_3549 = None
    mul_4061: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1061, unsqueeze_3547);  sub_1061 = unsqueeze_3547 = None
    sub_1063: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_153, mul_4061);  mul_4061 = None
    sub_1064: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1063, unsqueeze_3544);  sub_1063 = unsqueeze_3544 = None
    mul_4062: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1064, unsqueeze_3550);  sub_1064 = unsqueeze_3550 = None
    mul_4063: "f32[36]" = torch.ops.aten.mul.Tensor(sum_371, squeeze_421);  sum_371 = squeeze_421 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_184 = torch.ops.aten.convolution_backward.default(mul_4062, relu_129, primals_421, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4062 = primals_421 = None
    getitem_1202: "f32[8, 36, 28, 28]" = convolution_backward_184[0]
    getitem_1203: "f32[36, 36, 3, 3]" = convolution_backward_184[1];  convolution_backward_184 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_154: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_129, 0);  relu_129 = None
    where_154: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_154, full_default, getitem_1202);  le_154 = getitem_1202 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_372: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_154, [0, 2, 3])
    sub_1065: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_139, unsqueeze_3553);  convolution_139 = unsqueeze_3553 = None
    mul_4064: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_154, sub_1065)
    sum_373: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4064, [0, 2, 3]);  mul_4064 = None
    mul_4065: "f32[36]" = torch.ops.aten.mul.Tensor(sum_372, 0.00015943877551020407)
    unsqueeze_3554: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4065, 0);  mul_4065 = None
    unsqueeze_3555: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3554, 2);  unsqueeze_3554 = None
    unsqueeze_3556: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3555, 3);  unsqueeze_3555 = None
    mul_4066: "f32[36]" = torch.ops.aten.mul.Tensor(sum_373, 0.00015943877551020407)
    mul_4067: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_418, squeeze_418)
    mul_4068: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4066, mul_4067);  mul_4066 = mul_4067 = None
    unsqueeze_3557: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4068, 0);  mul_4068 = None
    unsqueeze_3558: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3557, 2);  unsqueeze_3557 = None
    unsqueeze_3559: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3558, 3);  unsqueeze_3558 = None
    mul_4069: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_418, primals_419);  primals_419 = None
    unsqueeze_3560: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4069, 0);  mul_4069 = None
    unsqueeze_3561: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3560, 2);  unsqueeze_3560 = None
    unsqueeze_3562: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3561, 3);  unsqueeze_3561 = None
    mul_4070: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1065, unsqueeze_3559);  sub_1065 = unsqueeze_3559 = None
    sub_1067: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_154, mul_4070);  where_154 = mul_4070 = None
    sub_1068: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1067, unsqueeze_3556);  sub_1067 = unsqueeze_3556 = None
    mul_4071: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1068, unsqueeze_3562);  sub_1068 = unsqueeze_3562 = None
    mul_4072: "f32[36]" = torch.ops.aten.mul.Tensor(sum_373, squeeze_418);  sum_373 = squeeze_418 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_185 = torch.ops.aten.convolution_backward.default(mul_4071, relu_128, primals_418, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4071 = primals_418 = None
    getitem_1205: "f32[8, 36, 28, 28]" = convolution_backward_185[0]
    getitem_1206: "f32[36, 36, 3, 3]" = convolution_backward_185[1];  convolution_backward_185 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2027: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_153, getitem_1205);  where_153 = getitem_1205 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_155: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_128, 0);  relu_128 = None
    where_155: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_155, full_default, add_2027);  le_155 = add_2027 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_374: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_155, [0, 2, 3])
    sub_1069: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_138, unsqueeze_3565);  convolution_138 = unsqueeze_3565 = None
    mul_4073: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_155, sub_1069)
    sum_375: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4073, [0, 2, 3]);  mul_4073 = None
    mul_4074: "f32[36]" = torch.ops.aten.mul.Tensor(sum_374, 0.00015943877551020407)
    unsqueeze_3566: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4074, 0);  mul_4074 = None
    unsqueeze_3567: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3566, 2);  unsqueeze_3566 = None
    unsqueeze_3568: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3567, 3);  unsqueeze_3567 = None
    mul_4075: "f32[36]" = torch.ops.aten.mul.Tensor(sum_375, 0.00015943877551020407)
    mul_4076: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_415, squeeze_415)
    mul_4077: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4075, mul_4076);  mul_4075 = mul_4076 = None
    unsqueeze_3569: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4077, 0);  mul_4077 = None
    unsqueeze_3570: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3569, 2);  unsqueeze_3569 = None
    unsqueeze_3571: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3570, 3);  unsqueeze_3570 = None
    mul_4078: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_415, primals_416);  primals_416 = None
    unsqueeze_3572: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4078, 0);  mul_4078 = None
    unsqueeze_3573: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3572, 2);  unsqueeze_3572 = None
    unsqueeze_3574: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3573, 3);  unsqueeze_3573 = None
    mul_4079: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1069, unsqueeze_3571);  sub_1069 = unsqueeze_3571 = None
    sub_1071: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_155, mul_4079);  mul_4079 = None
    sub_1072: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1071, unsqueeze_3568);  sub_1071 = unsqueeze_3568 = None
    mul_4080: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1072, unsqueeze_3574);  sub_1072 = unsqueeze_3574 = None
    mul_4081: "f32[36]" = torch.ops.aten.mul.Tensor(sum_375, squeeze_415);  sum_375 = squeeze_415 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_186 = torch.ops.aten.convolution_backward.default(mul_4080, relu_127, primals_415, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4080 = primals_415 = None
    getitem_1208: "f32[8, 36, 28, 28]" = convolution_backward_186[0]
    getitem_1209: "f32[36, 36, 3, 3]" = convolution_backward_186[1];  convolution_backward_186 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_156: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_127, 0);  relu_127 = None
    where_156: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_156, full_default, getitem_1208);  le_156 = getitem_1208 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_376: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_156, [0, 2, 3])
    sub_1073: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_137, unsqueeze_3577);  convolution_137 = unsqueeze_3577 = None
    mul_4082: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_156, sub_1073)
    sum_377: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4082, [0, 2, 3]);  mul_4082 = None
    mul_4083: "f32[36]" = torch.ops.aten.mul.Tensor(sum_376, 0.00015943877551020407)
    unsqueeze_3578: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4083, 0);  mul_4083 = None
    unsqueeze_3579: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3578, 2);  unsqueeze_3578 = None
    unsqueeze_3580: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3579, 3);  unsqueeze_3579 = None
    mul_4084: "f32[36]" = torch.ops.aten.mul.Tensor(sum_377, 0.00015943877551020407)
    mul_4085: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_412, squeeze_412)
    mul_4086: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4084, mul_4085);  mul_4084 = mul_4085 = None
    unsqueeze_3581: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4086, 0);  mul_4086 = None
    unsqueeze_3582: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3581, 2);  unsqueeze_3581 = None
    unsqueeze_3583: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3582, 3);  unsqueeze_3582 = None
    mul_4087: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_412, primals_413);  primals_413 = None
    unsqueeze_3584: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4087, 0);  mul_4087 = None
    unsqueeze_3585: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3584, 2);  unsqueeze_3584 = None
    unsqueeze_3586: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3585, 3);  unsqueeze_3585 = None
    mul_4088: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1073, unsqueeze_3583);  sub_1073 = unsqueeze_3583 = None
    sub_1075: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_156, mul_4088);  where_156 = mul_4088 = None
    sub_1076: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1075, unsqueeze_3580);  sub_1075 = unsqueeze_3580 = None
    mul_4089: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1076, unsqueeze_3586);  sub_1076 = unsqueeze_3586 = None
    mul_4090: "f32[36]" = torch.ops.aten.mul.Tensor(sum_377, squeeze_412);  sum_377 = squeeze_412 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_187 = torch.ops.aten.convolution_backward.default(mul_4089, relu_116, primals_412, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4089 = primals_412 = None
    getitem_1211: "f32[8, 36, 28, 28]" = convolution_backward_187[0]
    getitem_1212: "f32[36, 36, 3, 3]" = convolution_backward_187[1];  convolution_backward_187 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2028: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_155, getitem_1211);  where_155 = getitem_1211 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_157: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_126, 0);  relu_126 = None
    where_157: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_157, full_default, add_2019);  le_157 = add_2019 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_378: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_157, [0, 2, 3])
    sub_1077: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_136, unsqueeze_3589);  convolution_136 = unsqueeze_3589 = None
    mul_4091: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_157, sub_1077)
    sum_379: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4091, [0, 2, 3]);  mul_4091 = None
    mul_4092: "f32[18]" = torch.ops.aten.mul.Tensor(sum_378, 3.985969387755102e-05)
    unsqueeze_3590: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4092, 0);  mul_4092 = None
    unsqueeze_3591: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3590, 2);  unsqueeze_3590 = None
    unsqueeze_3592: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3591, 3);  unsqueeze_3591 = None
    mul_4093: "f32[18]" = torch.ops.aten.mul.Tensor(sum_379, 3.985969387755102e-05)
    mul_4094: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_409, squeeze_409)
    mul_4095: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4093, mul_4094);  mul_4093 = mul_4094 = None
    unsqueeze_3593: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4095, 0);  mul_4095 = None
    unsqueeze_3594: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3593, 2);  unsqueeze_3593 = None
    unsqueeze_3595: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3594, 3);  unsqueeze_3594 = None
    mul_4096: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_409, primals_410);  primals_410 = None
    unsqueeze_3596: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4096, 0);  mul_4096 = None
    unsqueeze_3597: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3596, 2);  unsqueeze_3596 = None
    unsqueeze_3598: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3597, 3);  unsqueeze_3597 = None
    mul_4097: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1077, unsqueeze_3595);  sub_1077 = unsqueeze_3595 = None
    sub_1079: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_157, mul_4097);  mul_4097 = None
    sub_1080: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1079, unsqueeze_3592);  sub_1079 = unsqueeze_3592 = None
    mul_4098: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1080, unsqueeze_3598);  sub_1080 = unsqueeze_3598 = None
    mul_4099: "f32[18]" = torch.ops.aten.mul.Tensor(sum_379, squeeze_409);  sum_379 = squeeze_409 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_188 = torch.ops.aten.convolution_backward.default(mul_4098, relu_125, primals_409, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4098 = primals_409 = None
    getitem_1214: "f32[8, 18, 56, 56]" = convolution_backward_188[0]
    getitem_1215: "f32[18, 18, 3, 3]" = convolution_backward_188[1];  convolution_backward_188 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_158: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_125, 0);  relu_125 = None
    where_158: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_158, full_default, getitem_1214);  le_158 = getitem_1214 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_380: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_158, [0, 2, 3])
    sub_1081: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_135, unsqueeze_3601);  convolution_135 = unsqueeze_3601 = None
    mul_4100: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_158, sub_1081)
    sum_381: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4100, [0, 2, 3]);  mul_4100 = None
    mul_4101: "f32[18]" = torch.ops.aten.mul.Tensor(sum_380, 3.985969387755102e-05)
    unsqueeze_3602: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4101, 0);  mul_4101 = None
    unsqueeze_3603: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3602, 2);  unsqueeze_3602 = None
    unsqueeze_3604: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3603, 3);  unsqueeze_3603 = None
    mul_4102: "f32[18]" = torch.ops.aten.mul.Tensor(sum_381, 3.985969387755102e-05)
    mul_4103: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_406, squeeze_406)
    mul_4104: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4102, mul_4103);  mul_4102 = mul_4103 = None
    unsqueeze_3605: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4104, 0);  mul_4104 = None
    unsqueeze_3606: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3605, 2);  unsqueeze_3605 = None
    unsqueeze_3607: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3606, 3);  unsqueeze_3606 = None
    mul_4105: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_406, primals_407);  primals_407 = None
    unsqueeze_3608: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4105, 0);  mul_4105 = None
    unsqueeze_3609: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3608, 2);  unsqueeze_3608 = None
    unsqueeze_3610: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3609, 3);  unsqueeze_3609 = None
    mul_4106: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1081, unsqueeze_3607);  sub_1081 = unsqueeze_3607 = None
    sub_1083: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_158, mul_4106);  where_158 = mul_4106 = None
    sub_1084: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1083, unsqueeze_3604);  sub_1083 = unsqueeze_3604 = None
    mul_4107: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1084, unsqueeze_3610);  sub_1084 = unsqueeze_3610 = None
    mul_4108: "f32[18]" = torch.ops.aten.mul.Tensor(sum_381, squeeze_406);  sum_381 = squeeze_406 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_189 = torch.ops.aten.convolution_backward.default(mul_4107, relu_124, primals_406, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4107 = primals_406 = None
    getitem_1217: "f32[8, 18, 56, 56]" = convolution_backward_189[0]
    getitem_1218: "f32[18, 18, 3, 3]" = convolution_backward_189[1];  convolution_backward_189 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2029: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_157, getitem_1217);  where_157 = getitem_1217 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_159: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_124, 0);  relu_124 = None
    where_159: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_159, full_default, add_2029);  le_159 = add_2029 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_382: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_159, [0, 2, 3])
    sub_1085: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_134, unsqueeze_3613);  convolution_134 = unsqueeze_3613 = None
    mul_4109: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_159, sub_1085)
    sum_383: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4109, [0, 2, 3]);  mul_4109 = None
    mul_4110: "f32[18]" = torch.ops.aten.mul.Tensor(sum_382, 3.985969387755102e-05)
    unsqueeze_3614: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4110, 0);  mul_4110 = None
    unsqueeze_3615: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3614, 2);  unsqueeze_3614 = None
    unsqueeze_3616: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3615, 3);  unsqueeze_3615 = None
    mul_4111: "f32[18]" = torch.ops.aten.mul.Tensor(sum_383, 3.985969387755102e-05)
    mul_4112: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_403, squeeze_403)
    mul_4113: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4111, mul_4112);  mul_4111 = mul_4112 = None
    unsqueeze_3617: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4113, 0);  mul_4113 = None
    unsqueeze_3618: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3617, 2);  unsqueeze_3617 = None
    unsqueeze_3619: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3618, 3);  unsqueeze_3618 = None
    mul_4114: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_403, primals_404);  primals_404 = None
    unsqueeze_3620: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4114, 0);  mul_4114 = None
    unsqueeze_3621: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3620, 2);  unsqueeze_3620 = None
    unsqueeze_3622: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3621, 3);  unsqueeze_3621 = None
    mul_4115: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1085, unsqueeze_3619);  sub_1085 = unsqueeze_3619 = None
    sub_1087: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_159, mul_4115);  mul_4115 = None
    sub_1088: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1087, unsqueeze_3616);  sub_1087 = unsqueeze_3616 = None
    mul_4116: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1088, unsqueeze_3622);  sub_1088 = unsqueeze_3622 = None
    mul_4117: "f32[18]" = torch.ops.aten.mul.Tensor(sum_383, squeeze_403);  sum_383 = squeeze_403 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_190 = torch.ops.aten.convolution_backward.default(mul_4116, relu_123, primals_403, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4116 = primals_403 = None
    getitem_1220: "f32[8, 18, 56, 56]" = convolution_backward_190[0]
    getitem_1221: "f32[18, 18, 3, 3]" = convolution_backward_190[1];  convolution_backward_190 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_160: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_123, 0);  relu_123 = None
    where_160: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_160, full_default, getitem_1220);  le_160 = getitem_1220 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_384: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_160, [0, 2, 3])
    sub_1089: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_133, unsqueeze_3625);  convolution_133 = unsqueeze_3625 = None
    mul_4118: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_160, sub_1089)
    sum_385: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4118, [0, 2, 3]);  mul_4118 = None
    mul_4119: "f32[18]" = torch.ops.aten.mul.Tensor(sum_384, 3.985969387755102e-05)
    unsqueeze_3626: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4119, 0);  mul_4119 = None
    unsqueeze_3627: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3626, 2);  unsqueeze_3626 = None
    unsqueeze_3628: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3627, 3);  unsqueeze_3627 = None
    mul_4120: "f32[18]" = torch.ops.aten.mul.Tensor(sum_385, 3.985969387755102e-05)
    mul_4121: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_400, squeeze_400)
    mul_4122: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4120, mul_4121);  mul_4120 = mul_4121 = None
    unsqueeze_3629: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4122, 0);  mul_4122 = None
    unsqueeze_3630: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3629, 2);  unsqueeze_3629 = None
    unsqueeze_3631: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3630, 3);  unsqueeze_3630 = None
    mul_4123: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_400, primals_401);  primals_401 = None
    unsqueeze_3632: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4123, 0);  mul_4123 = None
    unsqueeze_3633: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3632, 2);  unsqueeze_3632 = None
    unsqueeze_3634: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3633, 3);  unsqueeze_3633 = None
    mul_4124: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1089, unsqueeze_3631);  sub_1089 = unsqueeze_3631 = None
    sub_1091: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_160, mul_4124);  where_160 = mul_4124 = None
    sub_1092: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1091, unsqueeze_3628);  sub_1091 = unsqueeze_3628 = None
    mul_4125: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1092, unsqueeze_3634);  sub_1092 = unsqueeze_3634 = None
    mul_4126: "f32[18]" = torch.ops.aten.mul.Tensor(sum_385, squeeze_400);  sum_385 = squeeze_400 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_191 = torch.ops.aten.convolution_backward.default(mul_4125, relu_122, primals_400, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4125 = primals_400 = None
    getitem_1223: "f32[8, 18, 56, 56]" = convolution_backward_191[0]
    getitem_1224: "f32[18, 18, 3, 3]" = convolution_backward_191[1];  convolution_backward_191 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2030: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_159, getitem_1223);  where_159 = getitem_1223 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_161: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_122, 0);  relu_122 = None
    where_161: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_161, full_default, add_2030);  le_161 = add_2030 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_386: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_161, [0, 2, 3])
    sub_1093: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_132, unsqueeze_3637);  convolution_132 = unsqueeze_3637 = None
    mul_4127: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_161, sub_1093)
    sum_387: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4127, [0, 2, 3]);  mul_4127 = None
    mul_4128: "f32[18]" = torch.ops.aten.mul.Tensor(sum_386, 3.985969387755102e-05)
    unsqueeze_3638: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4128, 0);  mul_4128 = None
    unsqueeze_3639: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3638, 2);  unsqueeze_3638 = None
    unsqueeze_3640: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3639, 3);  unsqueeze_3639 = None
    mul_4129: "f32[18]" = torch.ops.aten.mul.Tensor(sum_387, 3.985969387755102e-05)
    mul_4130: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_397, squeeze_397)
    mul_4131: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4129, mul_4130);  mul_4129 = mul_4130 = None
    unsqueeze_3641: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4131, 0);  mul_4131 = None
    unsqueeze_3642: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3641, 2);  unsqueeze_3641 = None
    unsqueeze_3643: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3642, 3);  unsqueeze_3642 = None
    mul_4132: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_397, primals_398);  primals_398 = None
    unsqueeze_3644: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4132, 0);  mul_4132 = None
    unsqueeze_3645: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3644, 2);  unsqueeze_3644 = None
    unsqueeze_3646: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3645, 3);  unsqueeze_3645 = None
    mul_4133: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1093, unsqueeze_3643);  sub_1093 = unsqueeze_3643 = None
    sub_1095: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_161, mul_4133);  mul_4133 = None
    sub_1096: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1095, unsqueeze_3640);  sub_1095 = unsqueeze_3640 = None
    mul_4134: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1096, unsqueeze_3646);  sub_1096 = unsqueeze_3646 = None
    mul_4135: "f32[18]" = torch.ops.aten.mul.Tensor(sum_387, squeeze_397);  sum_387 = squeeze_397 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_192 = torch.ops.aten.convolution_backward.default(mul_4134, relu_121, primals_397, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4134 = primals_397 = None
    getitem_1226: "f32[8, 18, 56, 56]" = convolution_backward_192[0]
    getitem_1227: "f32[18, 18, 3, 3]" = convolution_backward_192[1];  convolution_backward_192 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_162: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_121, 0);  relu_121 = None
    where_162: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_162, full_default, getitem_1226);  le_162 = getitem_1226 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_388: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_162, [0, 2, 3])
    sub_1097: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_131, unsqueeze_3649);  convolution_131 = unsqueeze_3649 = None
    mul_4136: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_162, sub_1097)
    sum_389: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4136, [0, 2, 3]);  mul_4136 = None
    mul_4137: "f32[18]" = torch.ops.aten.mul.Tensor(sum_388, 3.985969387755102e-05)
    unsqueeze_3650: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4137, 0);  mul_4137 = None
    unsqueeze_3651: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3650, 2);  unsqueeze_3650 = None
    unsqueeze_3652: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3651, 3);  unsqueeze_3651 = None
    mul_4138: "f32[18]" = torch.ops.aten.mul.Tensor(sum_389, 3.985969387755102e-05)
    mul_4139: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_394, squeeze_394)
    mul_4140: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4138, mul_4139);  mul_4138 = mul_4139 = None
    unsqueeze_3653: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4140, 0);  mul_4140 = None
    unsqueeze_3654: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3653, 2);  unsqueeze_3653 = None
    unsqueeze_3655: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3654, 3);  unsqueeze_3654 = None
    mul_4141: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_394, primals_395);  primals_395 = None
    unsqueeze_3656: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4141, 0);  mul_4141 = None
    unsqueeze_3657: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3656, 2);  unsqueeze_3656 = None
    unsqueeze_3658: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3657, 3);  unsqueeze_3657 = None
    mul_4142: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1097, unsqueeze_3655);  sub_1097 = unsqueeze_3655 = None
    sub_1099: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_162, mul_4142);  where_162 = mul_4142 = None
    sub_1100: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1099, unsqueeze_3652);  sub_1099 = unsqueeze_3652 = None
    mul_4143: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1100, unsqueeze_3658);  sub_1100 = unsqueeze_3658 = None
    mul_4144: "f32[18]" = torch.ops.aten.mul.Tensor(sum_389, squeeze_394);  sum_389 = squeeze_394 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_193 = torch.ops.aten.convolution_backward.default(mul_4143, relu_120, primals_394, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4143 = primals_394 = None
    getitem_1229: "f32[8, 18, 56, 56]" = convolution_backward_193[0]
    getitem_1230: "f32[18, 18, 3, 3]" = convolution_backward_193[1];  convolution_backward_193 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2031: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_161, getitem_1229);  where_161 = getitem_1229 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_163: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_120, 0);  relu_120 = None
    where_163: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_163, full_default, add_2031);  le_163 = add_2031 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_390: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_163, [0, 2, 3])
    sub_1101: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_130, unsqueeze_3661);  convolution_130 = unsqueeze_3661 = None
    mul_4145: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_163, sub_1101)
    sum_391: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4145, [0, 2, 3]);  mul_4145 = None
    mul_4146: "f32[18]" = torch.ops.aten.mul.Tensor(sum_390, 3.985969387755102e-05)
    unsqueeze_3662: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4146, 0);  mul_4146 = None
    unsqueeze_3663: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3662, 2);  unsqueeze_3662 = None
    unsqueeze_3664: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3663, 3);  unsqueeze_3663 = None
    mul_4147: "f32[18]" = torch.ops.aten.mul.Tensor(sum_391, 3.985969387755102e-05)
    mul_4148: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_391, squeeze_391)
    mul_4149: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4147, mul_4148);  mul_4147 = mul_4148 = None
    unsqueeze_3665: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4149, 0);  mul_4149 = None
    unsqueeze_3666: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3665, 2);  unsqueeze_3665 = None
    unsqueeze_3667: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3666, 3);  unsqueeze_3666 = None
    mul_4150: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_391, primals_392);  primals_392 = None
    unsqueeze_3668: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4150, 0);  mul_4150 = None
    unsqueeze_3669: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3668, 2);  unsqueeze_3668 = None
    unsqueeze_3670: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3669, 3);  unsqueeze_3669 = None
    mul_4151: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1101, unsqueeze_3667);  sub_1101 = unsqueeze_3667 = None
    sub_1103: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_163, mul_4151);  mul_4151 = None
    sub_1104: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1103, unsqueeze_3664);  sub_1103 = unsqueeze_3664 = None
    mul_4152: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1104, unsqueeze_3670);  sub_1104 = unsqueeze_3670 = None
    mul_4153: "f32[18]" = torch.ops.aten.mul.Tensor(sum_391, squeeze_391);  sum_391 = squeeze_391 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_194 = torch.ops.aten.convolution_backward.default(mul_4152, relu_119, primals_391, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4152 = primals_391 = None
    getitem_1232: "f32[8, 18, 56, 56]" = convolution_backward_194[0]
    getitem_1233: "f32[18, 18, 3, 3]" = convolution_backward_194[1];  convolution_backward_194 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_164: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_119, 0);  relu_119 = None
    where_164: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_164, full_default, getitem_1232);  le_164 = getitem_1232 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_392: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_164, [0, 2, 3])
    sub_1105: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_129, unsqueeze_3673);  convolution_129 = unsqueeze_3673 = None
    mul_4154: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_164, sub_1105)
    sum_393: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4154, [0, 2, 3]);  mul_4154 = None
    mul_4155: "f32[18]" = torch.ops.aten.mul.Tensor(sum_392, 3.985969387755102e-05)
    unsqueeze_3674: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4155, 0);  mul_4155 = None
    unsqueeze_3675: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3674, 2);  unsqueeze_3674 = None
    unsqueeze_3676: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3675, 3);  unsqueeze_3675 = None
    mul_4156: "f32[18]" = torch.ops.aten.mul.Tensor(sum_393, 3.985969387755102e-05)
    mul_4157: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_388, squeeze_388)
    mul_4158: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4156, mul_4157);  mul_4156 = mul_4157 = None
    unsqueeze_3677: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4158, 0);  mul_4158 = None
    unsqueeze_3678: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3677, 2);  unsqueeze_3677 = None
    unsqueeze_3679: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3678, 3);  unsqueeze_3678 = None
    mul_4159: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_388, primals_389);  primals_389 = None
    unsqueeze_3680: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4159, 0);  mul_4159 = None
    unsqueeze_3681: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3680, 2);  unsqueeze_3680 = None
    unsqueeze_3682: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3681, 3);  unsqueeze_3681 = None
    mul_4160: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1105, unsqueeze_3679);  sub_1105 = unsqueeze_3679 = None
    sub_1107: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_164, mul_4160);  where_164 = mul_4160 = None
    sub_1108: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1107, unsqueeze_3676);  sub_1107 = unsqueeze_3676 = None
    mul_4161: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1108, unsqueeze_3682);  sub_1108 = unsqueeze_3682 = None
    mul_4162: "f32[18]" = torch.ops.aten.mul.Tensor(sum_393, squeeze_388);  sum_393 = squeeze_388 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_195 = torch.ops.aten.convolution_backward.default(mul_4161, relu_115, primals_388, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4161 = primals_388 = None
    getitem_1235: "f32[8, 18, 56, 56]" = convolution_backward_195[0]
    getitem_1236: "f32[18, 18, 3, 3]" = convolution_backward_195[1];  convolution_backward_195 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2032: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_163, getitem_1235);  where_163 = getitem_1235 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_165: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_118, 0);  relu_118 = None
    where_165: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_165, full_default, add_2024);  le_165 = add_2024 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    sum_394: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_165, [0, 2, 3])
    sub_1109: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_128, unsqueeze_3685);  convolution_128 = unsqueeze_3685 = None
    mul_4163: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_165, sub_1109)
    sum_395: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4163, [0, 2, 3]);  mul_4163 = None
    mul_4164: "f32[72]" = torch.ops.aten.mul.Tensor(sum_394, 0.0006377551020408163)
    unsqueeze_3686: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4164, 0);  mul_4164 = None
    unsqueeze_3687: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3686, 2);  unsqueeze_3686 = None
    unsqueeze_3688: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3687, 3);  unsqueeze_3687 = None
    mul_4165: "f32[72]" = torch.ops.aten.mul.Tensor(sum_395, 0.0006377551020408163)
    mul_4166: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_385, squeeze_385)
    mul_4167: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4165, mul_4166);  mul_4165 = mul_4166 = None
    unsqueeze_3689: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4167, 0);  mul_4167 = None
    unsqueeze_3690: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3689, 2);  unsqueeze_3689 = None
    unsqueeze_3691: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3690, 3);  unsqueeze_3690 = None
    mul_4168: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_385, primals_386);  primals_386 = None
    unsqueeze_3692: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4168, 0);  mul_4168 = None
    unsqueeze_3693: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3692, 2);  unsqueeze_3692 = None
    unsqueeze_3694: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3693, 3);  unsqueeze_3693 = None
    mul_4169: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1109, unsqueeze_3691);  sub_1109 = unsqueeze_3691 = None
    sub_1111: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_165, mul_4169);  mul_4169 = None
    sub_1112: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1111, unsqueeze_3688);  sub_1111 = None
    mul_4170: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1112, unsqueeze_3694);  sub_1112 = unsqueeze_3694 = None
    mul_4171: "f32[72]" = torch.ops.aten.mul.Tensor(sum_395, squeeze_385);  sum_395 = squeeze_385 = None
    convolution_backward_196 = torch.ops.aten.convolution_backward.default(mul_4170, relu_106, primals_385, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4170 = primals_385 = None
    getitem_1238: "f32[8, 36, 28, 28]" = convolution_backward_196[0]
    getitem_1239: "f32[72, 36, 3, 3]" = convolution_backward_196[1];  convolution_backward_196 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sub_1113: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_127, unsqueeze_3697);  convolution_127 = unsqueeze_3697 = None
    mul_4172: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_165, sub_1113)
    sum_397: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4172, [0, 2, 3]);  mul_4172 = None
    mul_4174: "f32[72]" = torch.ops.aten.mul.Tensor(sum_397, 0.0006377551020408163)
    mul_4175: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_382, squeeze_382)
    mul_4176: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4174, mul_4175);  mul_4174 = mul_4175 = None
    unsqueeze_3701: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4176, 0);  mul_4176 = None
    unsqueeze_3702: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3701, 2);  unsqueeze_3701 = None
    unsqueeze_3703: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3702, 3);  unsqueeze_3702 = None
    mul_4177: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_382, primals_383);  primals_383 = None
    unsqueeze_3704: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4177, 0);  mul_4177 = None
    unsqueeze_3705: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3704, 2);  unsqueeze_3704 = None
    unsqueeze_3706: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3705, 3);  unsqueeze_3705 = None
    mul_4178: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1113, unsqueeze_3703);  sub_1113 = unsqueeze_3703 = None
    sub_1115: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_165, mul_4178);  mul_4178 = None
    sub_1116: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1115, unsqueeze_3688);  sub_1115 = unsqueeze_3688 = None
    mul_4179: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1116, unsqueeze_3706);  sub_1116 = unsqueeze_3706 = None
    mul_4180: "f32[72]" = torch.ops.aten.mul.Tensor(sum_397, squeeze_382);  sum_397 = squeeze_382 = None
    convolution_backward_197 = torch.ops.aten.convolution_backward.default(mul_4179, relu_117, primals_382, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4179 = primals_382 = None
    getitem_1241: "f32[8, 18, 28, 28]" = convolution_backward_197[0]
    getitem_1242: "f32[72, 18, 3, 3]" = convolution_backward_197[1];  convolution_backward_197 = None
    le_166: "b8[8, 18, 28, 28]" = torch.ops.aten.le.Scalar(relu_117, 0);  relu_117 = None
    where_166: "f32[8, 18, 28, 28]" = torch.ops.aten.where.self(le_166, full_default, getitem_1241);  le_166 = getitem_1241 = None
    sum_398: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_166, [0, 2, 3])
    sub_1117: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_126, unsqueeze_3709);  convolution_126 = unsqueeze_3709 = None
    mul_4181: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(where_166, sub_1117)
    sum_399: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4181, [0, 2, 3]);  mul_4181 = None
    mul_4182: "f32[18]" = torch.ops.aten.mul.Tensor(sum_398, 0.00015943877551020407)
    unsqueeze_3710: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4182, 0);  mul_4182 = None
    unsqueeze_3711: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3710, 2);  unsqueeze_3710 = None
    unsqueeze_3712: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3711, 3);  unsqueeze_3711 = None
    mul_4183: "f32[18]" = torch.ops.aten.mul.Tensor(sum_399, 0.00015943877551020407)
    mul_4184: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_379, squeeze_379)
    mul_4185: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4183, mul_4184);  mul_4183 = mul_4184 = None
    unsqueeze_3713: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4185, 0);  mul_4185 = None
    unsqueeze_3714: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3713, 2);  unsqueeze_3713 = None
    unsqueeze_3715: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3714, 3);  unsqueeze_3714 = None
    mul_4186: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_379, primals_380);  primals_380 = None
    unsqueeze_3716: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4186, 0);  mul_4186 = None
    unsqueeze_3717: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3716, 2);  unsqueeze_3716 = None
    unsqueeze_3718: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3717, 3);  unsqueeze_3717 = None
    mul_4187: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1117, unsqueeze_3715);  sub_1117 = unsqueeze_3715 = None
    sub_1119: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(where_166, mul_4187);  where_166 = mul_4187 = None
    sub_1120: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1119, unsqueeze_3712);  sub_1119 = unsqueeze_3712 = None
    mul_4188: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1120, unsqueeze_3718);  sub_1120 = unsqueeze_3718 = None
    mul_4189: "f32[18]" = torch.ops.aten.mul.Tensor(sum_399, squeeze_379);  sum_399 = squeeze_379 = None
    convolution_backward_198 = torch.ops.aten.convolution_backward.default(mul_4188, relu_98, primals_379, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4188 = primals_379 = None
    getitem_1244: "f32[8, 18, 56, 56]" = convolution_backward_198[0]
    getitem_1245: "f32[18, 18, 3, 3]" = convolution_backward_198[1];  convolution_backward_198 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_167: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_116, 0);  relu_116 = None
    where_167: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_167, full_default, add_2028);  le_167 = add_2028 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_21: "f32[8, 36, 14, 14]" = torch.ops.aten._unsafe_index_put.default(full_default_25, [None, None, unsqueeze_259, convert_element_type_20], where_167, True)
    sum_400: "f32[36]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_21, [0, 2, 3])
    sub_1121: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_125, unsqueeze_3721);  convolution_125 = unsqueeze_3721 = None
    mul_4190: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_21, sub_1121)
    sum_401: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4190, [0, 2, 3]);  mul_4190 = None
    mul_4191: "f32[36]" = torch.ops.aten.mul.Tensor(sum_400, 0.0006377551020408163)
    unsqueeze_3722: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4191, 0);  mul_4191 = None
    unsqueeze_3723: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3722, 2);  unsqueeze_3722 = None
    unsqueeze_3724: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3723, 3);  unsqueeze_3723 = None
    mul_4192: "f32[36]" = torch.ops.aten.mul.Tensor(sum_401, 0.0006377551020408163)
    mul_4193: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_376, squeeze_376)
    mul_4194: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4192, mul_4193);  mul_4192 = mul_4193 = None
    unsqueeze_3725: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4194, 0);  mul_4194 = None
    unsqueeze_3726: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3725, 2);  unsqueeze_3725 = None
    unsqueeze_3727: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3726, 3);  unsqueeze_3726 = None
    mul_4195: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_376, primals_377);  primals_377 = None
    unsqueeze_3728: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4195, 0);  mul_4195 = None
    unsqueeze_3729: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3728, 2);  unsqueeze_3728 = None
    unsqueeze_3730: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3729, 3);  unsqueeze_3729 = None
    mul_4196: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1121, unsqueeze_3727);  sub_1121 = unsqueeze_3727 = None
    sub_1123: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_21, mul_4196);  _unsafe_index_put_21 = mul_4196 = None
    sub_1124: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1123, unsqueeze_3724);  sub_1123 = unsqueeze_3724 = None
    mul_4197: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1124, unsqueeze_3730);  sub_1124 = unsqueeze_3730 = None
    mul_4198: "f32[36]" = torch.ops.aten.mul.Tensor(sum_401, squeeze_376);  sum_401 = squeeze_376 = None
    convolution_backward_199 = torch.ops.aten.convolution_backward.default(mul_4197, relu_114, primals_376, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4197 = primals_376 = None
    getitem_1247: "f32[8, 72, 14, 14]" = convolution_backward_199[0]
    getitem_1248: "f32[36, 72, 1, 1]" = convolution_backward_199[1];  convolution_backward_199 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_2033: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_165, getitem_1247);  where_165 = getitem_1247 = None
    add_2034: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(getitem_1238, where_167);  getitem_1238 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sum_402: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_167, [0, 2, 3])
    sub_1125: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_124, unsqueeze_3733);  convolution_124 = unsqueeze_3733 = None
    mul_4199: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_167, sub_1125)
    sum_403: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4199, [0, 2, 3]);  mul_4199 = None
    mul_4200: "f32[36]" = torch.ops.aten.mul.Tensor(sum_402, 0.00015943877551020407)
    unsqueeze_3734: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4200, 0);  mul_4200 = None
    unsqueeze_3735: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3734, 2);  unsqueeze_3734 = None
    unsqueeze_3736: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3735, 3);  unsqueeze_3735 = None
    mul_4201: "f32[36]" = torch.ops.aten.mul.Tensor(sum_403, 0.00015943877551020407)
    mul_4202: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_373, squeeze_373)
    mul_4203: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4201, mul_4202);  mul_4201 = mul_4202 = None
    unsqueeze_3737: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4203, 0);  mul_4203 = None
    unsqueeze_3738: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3737, 2);  unsqueeze_3737 = None
    unsqueeze_3739: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3738, 3);  unsqueeze_3738 = None
    mul_4204: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_373, primals_374);  primals_374 = None
    unsqueeze_3740: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4204, 0);  mul_4204 = None
    unsqueeze_3741: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3740, 2);  unsqueeze_3740 = None
    unsqueeze_3742: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3741, 3);  unsqueeze_3741 = None
    mul_4205: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1125, unsqueeze_3739);  sub_1125 = unsqueeze_3739 = None
    sub_1127: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_167, mul_4205);  where_167 = mul_4205 = None
    sub_1128: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1127, unsqueeze_3736);  sub_1127 = unsqueeze_3736 = None
    mul_4206: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1128, unsqueeze_3742);  sub_1128 = unsqueeze_3742 = None
    mul_4207: "f32[36]" = torch.ops.aten.mul.Tensor(sum_403, squeeze_373);  sum_403 = squeeze_373 = None
    convolution_backward_200 = torch.ops.aten.convolution_backward.default(mul_4206, relu_98, primals_373, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4206 = primals_373 = None
    getitem_1250: "f32[8, 18, 56, 56]" = convolution_backward_200[0]
    getitem_1251: "f32[36, 18, 3, 3]" = convolution_backward_200[1];  convolution_backward_200 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    add_2035: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(getitem_1244, getitem_1250);  getitem_1244 = getitem_1250 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_168: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_115, 0);  relu_115 = None
    where_168: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_168, full_default, add_2032);  le_168 = add_2032 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_22: "f32[8, 18, 14, 14]" = torch.ops.aten._unsafe_index_put.default(full_default_28, [None, None, unsqueeze_250, convert_element_type_14], where_168, True)
    sum_404: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_22, [0, 2, 3])
    sub_1129: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_123, unsqueeze_3745);  convolution_123 = unsqueeze_3745 = None
    mul_4208: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_22, sub_1129)
    sum_405: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4208, [0, 2, 3]);  mul_4208 = None
    mul_4209: "f32[18]" = torch.ops.aten.mul.Tensor(sum_404, 0.0006377551020408163)
    unsqueeze_3746: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4209, 0);  mul_4209 = None
    unsqueeze_3747: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3746, 2);  unsqueeze_3746 = None
    unsqueeze_3748: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3747, 3);  unsqueeze_3747 = None
    mul_4210: "f32[18]" = torch.ops.aten.mul.Tensor(sum_405, 0.0006377551020408163)
    mul_4211: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_370, squeeze_370)
    mul_4212: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4210, mul_4211);  mul_4210 = mul_4211 = None
    unsqueeze_3749: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4212, 0);  mul_4212 = None
    unsqueeze_3750: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3749, 2);  unsqueeze_3749 = None
    unsqueeze_3751: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3750, 3);  unsqueeze_3750 = None
    mul_4213: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_370, primals_371);  primals_371 = None
    unsqueeze_3752: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4213, 0);  mul_4213 = None
    unsqueeze_3753: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3752, 2);  unsqueeze_3752 = None
    unsqueeze_3754: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3753, 3);  unsqueeze_3753 = None
    mul_4214: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1129, unsqueeze_3751);  sub_1129 = unsqueeze_3751 = None
    sub_1131: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_22, mul_4214);  _unsafe_index_put_22 = mul_4214 = None
    sub_1132: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1131, unsqueeze_3748);  sub_1131 = unsqueeze_3748 = None
    mul_4215: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1132, unsqueeze_3754);  sub_1132 = unsqueeze_3754 = None
    mul_4216: "f32[18]" = torch.ops.aten.mul.Tensor(sum_405, squeeze_370);  sum_405 = squeeze_370 = None
    convolution_backward_201 = torch.ops.aten.convolution_backward.default(mul_4215, relu_114, primals_370, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4215 = primals_370 = None
    getitem_1253: "f32[8, 72, 14, 14]" = convolution_backward_201[0]
    getitem_1254: "f32[18, 72, 1, 1]" = convolution_backward_201[1];  convolution_backward_201 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_2036: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(add_2033, getitem_1253);  add_2033 = getitem_1253 = None
    add_2037: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(add_2035, where_168);  add_2035 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_23: "f32[8, 18, 28, 28]" = torch.ops.aten._unsafe_index_put.default(full_default_29, [None, None, unsqueeze_136, convert_element_type_2], where_168, True);  where_168 = None
    sum_406: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_23, [0, 2, 3])
    sub_1133: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_122, unsqueeze_3757);  convolution_122 = unsqueeze_3757 = None
    mul_4217: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_23, sub_1133)
    sum_407: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4217, [0, 2, 3]);  mul_4217 = None
    mul_4218: "f32[18]" = torch.ops.aten.mul.Tensor(sum_406, 0.00015943877551020407)
    unsqueeze_3758: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4218, 0);  mul_4218 = None
    unsqueeze_3759: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3758, 2);  unsqueeze_3758 = None
    unsqueeze_3760: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3759, 3);  unsqueeze_3759 = None
    mul_4219: "f32[18]" = torch.ops.aten.mul.Tensor(sum_407, 0.00015943877551020407)
    mul_4220: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_367, squeeze_367)
    mul_4221: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4219, mul_4220);  mul_4219 = mul_4220 = None
    unsqueeze_3761: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4221, 0);  mul_4221 = None
    unsqueeze_3762: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3761, 2);  unsqueeze_3761 = None
    unsqueeze_3763: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3762, 3);  unsqueeze_3762 = None
    mul_4222: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_367, primals_368);  primals_368 = None
    unsqueeze_3764: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4222, 0);  mul_4222 = None
    unsqueeze_3765: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3764, 2);  unsqueeze_3764 = None
    unsqueeze_3766: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3765, 3);  unsqueeze_3765 = None
    mul_4223: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1133, unsqueeze_3763);  sub_1133 = unsqueeze_3763 = None
    sub_1135: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_23, mul_4223);  _unsafe_index_put_23 = mul_4223 = None
    sub_1136: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1135, unsqueeze_3760);  sub_1135 = unsqueeze_3760 = None
    mul_4224: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1136, unsqueeze_3766);  sub_1136 = unsqueeze_3766 = None
    mul_4225: "f32[18]" = torch.ops.aten.mul.Tensor(sum_407, squeeze_367);  sum_407 = squeeze_367 = None
    convolution_backward_202 = torch.ops.aten.convolution_backward.default(mul_4224, relu_106, primals_367, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4224 = primals_367 = None
    getitem_1256: "f32[8, 36, 28, 28]" = convolution_backward_202[0]
    getitem_1257: "f32[18, 36, 1, 1]" = convolution_backward_202[1];  convolution_backward_202 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_2038: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(add_2034, getitem_1256);  add_2034 = getitem_1256 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_169: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_114, 0);  relu_114 = None
    where_169: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_169, full_default, add_2036);  le_169 = add_2036 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_408: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_169, [0, 2, 3])
    sub_1137: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_121, unsqueeze_3769);  convolution_121 = unsqueeze_3769 = None
    mul_4226: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_169, sub_1137)
    sum_409: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4226, [0, 2, 3]);  mul_4226 = None
    mul_4227: "f32[72]" = torch.ops.aten.mul.Tensor(sum_408, 0.0006377551020408163)
    unsqueeze_3770: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4227, 0);  mul_4227 = None
    unsqueeze_3771: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3770, 2);  unsqueeze_3770 = None
    unsqueeze_3772: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3771, 3);  unsqueeze_3771 = None
    mul_4228: "f32[72]" = torch.ops.aten.mul.Tensor(sum_409, 0.0006377551020408163)
    mul_4229: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_364, squeeze_364)
    mul_4230: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4228, mul_4229);  mul_4228 = mul_4229 = None
    unsqueeze_3773: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4230, 0);  mul_4230 = None
    unsqueeze_3774: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3773, 2);  unsqueeze_3773 = None
    unsqueeze_3775: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3774, 3);  unsqueeze_3774 = None
    mul_4231: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_364, primals_365);  primals_365 = None
    unsqueeze_3776: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4231, 0);  mul_4231 = None
    unsqueeze_3777: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3776, 2);  unsqueeze_3776 = None
    unsqueeze_3778: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3777, 3);  unsqueeze_3777 = None
    mul_4232: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1137, unsqueeze_3775);  sub_1137 = unsqueeze_3775 = None
    sub_1139: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_169, mul_4232);  mul_4232 = None
    sub_1140: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1139, unsqueeze_3772);  sub_1139 = unsqueeze_3772 = None
    mul_4233: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1140, unsqueeze_3778);  sub_1140 = unsqueeze_3778 = None
    mul_4234: "f32[72]" = torch.ops.aten.mul.Tensor(sum_409, squeeze_364);  sum_409 = squeeze_364 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_203 = torch.ops.aten.convolution_backward.default(mul_4233, relu_113, primals_364, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4233 = primals_364 = None
    getitem_1259: "f32[8, 72, 14, 14]" = convolution_backward_203[0]
    getitem_1260: "f32[72, 72, 3, 3]" = convolution_backward_203[1];  convolution_backward_203 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_170: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_113, 0);  relu_113 = None
    where_170: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_170, full_default, getitem_1259);  le_170 = getitem_1259 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_410: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_170, [0, 2, 3])
    sub_1141: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_120, unsqueeze_3781);  convolution_120 = unsqueeze_3781 = None
    mul_4235: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_170, sub_1141)
    sum_411: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4235, [0, 2, 3]);  mul_4235 = None
    mul_4236: "f32[72]" = torch.ops.aten.mul.Tensor(sum_410, 0.0006377551020408163)
    unsqueeze_3782: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4236, 0);  mul_4236 = None
    unsqueeze_3783: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3782, 2);  unsqueeze_3782 = None
    unsqueeze_3784: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3783, 3);  unsqueeze_3783 = None
    mul_4237: "f32[72]" = torch.ops.aten.mul.Tensor(sum_411, 0.0006377551020408163)
    mul_4238: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_361, squeeze_361)
    mul_4239: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4237, mul_4238);  mul_4237 = mul_4238 = None
    unsqueeze_3785: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4239, 0);  mul_4239 = None
    unsqueeze_3786: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3785, 2);  unsqueeze_3785 = None
    unsqueeze_3787: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3786, 3);  unsqueeze_3786 = None
    mul_4240: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_361, primals_362);  primals_362 = None
    unsqueeze_3788: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4240, 0);  mul_4240 = None
    unsqueeze_3789: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3788, 2);  unsqueeze_3788 = None
    unsqueeze_3790: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3789, 3);  unsqueeze_3789 = None
    mul_4241: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1141, unsqueeze_3787);  sub_1141 = unsqueeze_3787 = None
    sub_1143: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_170, mul_4241);  where_170 = mul_4241 = None
    sub_1144: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1143, unsqueeze_3784);  sub_1143 = unsqueeze_3784 = None
    mul_4242: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1144, unsqueeze_3790);  sub_1144 = unsqueeze_3790 = None
    mul_4243: "f32[72]" = torch.ops.aten.mul.Tensor(sum_411, squeeze_361);  sum_411 = squeeze_361 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_204 = torch.ops.aten.convolution_backward.default(mul_4242, relu_112, primals_361, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4242 = primals_361 = None
    getitem_1262: "f32[8, 72, 14, 14]" = convolution_backward_204[0]
    getitem_1263: "f32[72, 72, 3, 3]" = convolution_backward_204[1];  convolution_backward_204 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2039: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_169, getitem_1262);  where_169 = getitem_1262 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_171: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_112, 0);  relu_112 = None
    where_171: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_171, full_default, add_2039);  le_171 = add_2039 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_412: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_171, [0, 2, 3])
    sub_1145: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_119, unsqueeze_3793);  convolution_119 = unsqueeze_3793 = None
    mul_4244: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_171, sub_1145)
    sum_413: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4244, [0, 2, 3]);  mul_4244 = None
    mul_4245: "f32[72]" = torch.ops.aten.mul.Tensor(sum_412, 0.0006377551020408163)
    unsqueeze_3794: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4245, 0);  mul_4245 = None
    unsqueeze_3795: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3794, 2);  unsqueeze_3794 = None
    unsqueeze_3796: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3795, 3);  unsqueeze_3795 = None
    mul_4246: "f32[72]" = torch.ops.aten.mul.Tensor(sum_413, 0.0006377551020408163)
    mul_4247: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_358, squeeze_358)
    mul_4248: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4246, mul_4247);  mul_4246 = mul_4247 = None
    unsqueeze_3797: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4248, 0);  mul_4248 = None
    unsqueeze_3798: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3797, 2);  unsqueeze_3797 = None
    unsqueeze_3799: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3798, 3);  unsqueeze_3798 = None
    mul_4249: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_358, primals_359);  primals_359 = None
    unsqueeze_3800: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4249, 0);  mul_4249 = None
    unsqueeze_3801: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3800, 2);  unsqueeze_3800 = None
    unsqueeze_3802: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3801, 3);  unsqueeze_3801 = None
    mul_4250: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1145, unsqueeze_3799);  sub_1145 = unsqueeze_3799 = None
    sub_1147: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_171, mul_4250);  mul_4250 = None
    sub_1148: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1147, unsqueeze_3796);  sub_1147 = unsqueeze_3796 = None
    mul_4251: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1148, unsqueeze_3802);  sub_1148 = unsqueeze_3802 = None
    mul_4252: "f32[72]" = torch.ops.aten.mul.Tensor(sum_413, squeeze_358);  sum_413 = squeeze_358 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_205 = torch.ops.aten.convolution_backward.default(mul_4251, relu_111, primals_358, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4251 = primals_358 = None
    getitem_1265: "f32[8, 72, 14, 14]" = convolution_backward_205[0]
    getitem_1266: "f32[72, 72, 3, 3]" = convolution_backward_205[1];  convolution_backward_205 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_172: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_111, 0);  relu_111 = None
    where_172: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_172, full_default, getitem_1265);  le_172 = getitem_1265 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_414: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_172, [0, 2, 3])
    sub_1149: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_118, unsqueeze_3805);  convolution_118 = unsqueeze_3805 = None
    mul_4253: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_172, sub_1149)
    sum_415: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4253, [0, 2, 3]);  mul_4253 = None
    mul_4254: "f32[72]" = torch.ops.aten.mul.Tensor(sum_414, 0.0006377551020408163)
    unsqueeze_3806: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4254, 0);  mul_4254 = None
    unsqueeze_3807: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3806, 2);  unsqueeze_3806 = None
    unsqueeze_3808: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3807, 3);  unsqueeze_3807 = None
    mul_4255: "f32[72]" = torch.ops.aten.mul.Tensor(sum_415, 0.0006377551020408163)
    mul_4256: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_355, squeeze_355)
    mul_4257: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4255, mul_4256);  mul_4255 = mul_4256 = None
    unsqueeze_3809: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4257, 0);  mul_4257 = None
    unsqueeze_3810: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3809, 2);  unsqueeze_3809 = None
    unsqueeze_3811: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3810, 3);  unsqueeze_3810 = None
    mul_4258: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_355, primals_356);  primals_356 = None
    unsqueeze_3812: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4258, 0);  mul_4258 = None
    unsqueeze_3813: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3812, 2);  unsqueeze_3812 = None
    unsqueeze_3814: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3813, 3);  unsqueeze_3813 = None
    mul_4259: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1149, unsqueeze_3811);  sub_1149 = unsqueeze_3811 = None
    sub_1151: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_172, mul_4259);  where_172 = mul_4259 = None
    sub_1152: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1151, unsqueeze_3808);  sub_1151 = unsqueeze_3808 = None
    mul_4260: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1152, unsqueeze_3814);  sub_1152 = unsqueeze_3814 = None
    mul_4261: "f32[72]" = torch.ops.aten.mul.Tensor(sum_415, squeeze_355);  sum_415 = squeeze_355 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_206 = torch.ops.aten.convolution_backward.default(mul_4260, relu_110, primals_355, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4260 = primals_355 = None
    getitem_1268: "f32[8, 72, 14, 14]" = convolution_backward_206[0]
    getitem_1269: "f32[72, 72, 3, 3]" = convolution_backward_206[1];  convolution_backward_206 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2040: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_171, getitem_1268);  where_171 = getitem_1268 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_173: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_110, 0);  relu_110 = None
    where_173: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_173, full_default, add_2040);  le_173 = add_2040 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_416: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_173, [0, 2, 3])
    sub_1153: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_117, unsqueeze_3817);  convolution_117 = unsqueeze_3817 = None
    mul_4262: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_173, sub_1153)
    sum_417: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4262, [0, 2, 3]);  mul_4262 = None
    mul_4263: "f32[72]" = torch.ops.aten.mul.Tensor(sum_416, 0.0006377551020408163)
    unsqueeze_3818: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4263, 0);  mul_4263 = None
    unsqueeze_3819: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3818, 2);  unsqueeze_3818 = None
    unsqueeze_3820: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3819, 3);  unsqueeze_3819 = None
    mul_4264: "f32[72]" = torch.ops.aten.mul.Tensor(sum_417, 0.0006377551020408163)
    mul_4265: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_352, squeeze_352)
    mul_4266: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4264, mul_4265);  mul_4264 = mul_4265 = None
    unsqueeze_3821: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4266, 0);  mul_4266 = None
    unsqueeze_3822: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3821, 2);  unsqueeze_3821 = None
    unsqueeze_3823: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3822, 3);  unsqueeze_3822 = None
    mul_4267: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_352, primals_353);  primals_353 = None
    unsqueeze_3824: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4267, 0);  mul_4267 = None
    unsqueeze_3825: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3824, 2);  unsqueeze_3824 = None
    unsqueeze_3826: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3825, 3);  unsqueeze_3825 = None
    mul_4268: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1153, unsqueeze_3823);  sub_1153 = unsqueeze_3823 = None
    sub_1155: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_173, mul_4268);  mul_4268 = None
    sub_1156: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1155, unsqueeze_3820);  sub_1155 = unsqueeze_3820 = None
    mul_4269: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1156, unsqueeze_3826);  sub_1156 = unsqueeze_3826 = None
    mul_4270: "f32[72]" = torch.ops.aten.mul.Tensor(sum_417, squeeze_352);  sum_417 = squeeze_352 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_207 = torch.ops.aten.convolution_backward.default(mul_4269, relu_109, primals_352, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4269 = primals_352 = None
    getitem_1271: "f32[8, 72, 14, 14]" = convolution_backward_207[0]
    getitem_1272: "f32[72, 72, 3, 3]" = convolution_backward_207[1];  convolution_backward_207 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_174: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_109, 0);  relu_109 = None
    where_174: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_174, full_default, getitem_1271);  le_174 = getitem_1271 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_418: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_174, [0, 2, 3])
    sub_1157: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_116, unsqueeze_3829);  convolution_116 = unsqueeze_3829 = None
    mul_4271: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_174, sub_1157)
    sum_419: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4271, [0, 2, 3]);  mul_4271 = None
    mul_4272: "f32[72]" = torch.ops.aten.mul.Tensor(sum_418, 0.0006377551020408163)
    unsqueeze_3830: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4272, 0);  mul_4272 = None
    unsqueeze_3831: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3830, 2);  unsqueeze_3830 = None
    unsqueeze_3832: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3831, 3);  unsqueeze_3831 = None
    mul_4273: "f32[72]" = torch.ops.aten.mul.Tensor(sum_419, 0.0006377551020408163)
    mul_4274: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_349, squeeze_349)
    mul_4275: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4273, mul_4274);  mul_4273 = mul_4274 = None
    unsqueeze_3833: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4275, 0);  mul_4275 = None
    unsqueeze_3834: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3833, 2);  unsqueeze_3833 = None
    unsqueeze_3835: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3834, 3);  unsqueeze_3834 = None
    mul_4276: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_349, primals_350);  primals_350 = None
    unsqueeze_3836: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4276, 0);  mul_4276 = None
    unsqueeze_3837: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3836, 2);  unsqueeze_3836 = None
    unsqueeze_3838: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3837, 3);  unsqueeze_3837 = None
    mul_4277: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1157, unsqueeze_3835);  sub_1157 = unsqueeze_3835 = None
    sub_1159: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_174, mul_4277);  where_174 = mul_4277 = None
    sub_1160: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1159, unsqueeze_3832);  sub_1159 = unsqueeze_3832 = None
    mul_4278: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1160, unsqueeze_3838);  sub_1160 = unsqueeze_3838 = None
    mul_4279: "f32[72]" = torch.ops.aten.mul.Tensor(sum_419, squeeze_349);  sum_419 = squeeze_349 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_208 = torch.ops.aten.convolution_backward.default(mul_4278, relu_108, primals_349, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4278 = primals_349 = None
    getitem_1274: "f32[8, 72, 14, 14]" = convolution_backward_208[0]
    getitem_1275: "f32[72, 72, 3, 3]" = convolution_backward_208[1];  convolution_backward_208 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2041: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_173, getitem_1274);  where_173 = getitem_1274 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_175: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_108, 0);  relu_108 = None
    where_175: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_175, full_default, add_2041);  le_175 = add_2041 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_420: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_175, [0, 2, 3])
    sub_1161: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_115, unsqueeze_3841);  convolution_115 = unsqueeze_3841 = None
    mul_4280: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_175, sub_1161)
    sum_421: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4280, [0, 2, 3]);  mul_4280 = None
    mul_4281: "f32[72]" = torch.ops.aten.mul.Tensor(sum_420, 0.0006377551020408163)
    unsqueeze_3842: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4281, 0);  mul_4281 = None
    unsqueeze_3843: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3842, 2);  unsqueeze_3842 = None
    unsqueeze_3844: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3843, 3);  unsqueeze_3843 = None
    mul_4282: "f32[72]" = torch.ops.aten.mul.Tensor(sum_421, 0.0006377551020408163)
    mul_4283: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_346, squeeze_346)
    mul_4284: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4282, mul_4283);  mul_4282 = mul_4283 = None
    unsqueeze_3845: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4284, 0);  mul_4284 = None
    unsqueeze_3846: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3845, 2);  unsqueeze_3845 = None
    unsqueeze_3847: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3846, 3);  unsqueeze_3846 = None
    mul_4285: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_346, primals_347);  primals_347 = None
    unsqueeze_3848: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4285, 0);  mul_4285 = None
    unsqueeze_3849: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3848, 2);  unsqueeze_3848 = None
    unsqueeze_3850: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3849, 3);  unsqueeze_3849 = None
    mul_4286: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1161, unsqueeze_3847);  sub_1161 = unsqueeze_3847 = None
    sub_1163: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_175, mul_4286);  mul_4286 = None
    sub_1164: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1163, unsqueeze_3844);  sub_1163 = unsqueeze_3844 = None
    mul_4287: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1164, unsqueeze_3850);  sub_1164 = unsqueeze_3850 = None
    mul_4288: "f32[72]" = torch.ops.aten.mul.Tensor(sum_421, squeeze_346);  sum_421 = squeeze_346 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_209 = torch.ops.aten.convolution_backward.default(mul_4287, relu_107, primals_346, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4287 = primals_346 = None
    getitem_1277: "f32[8, 72, 14, 14]" = convolution_backward_209[0]
    getitem_1278: "f32[72, 72, 3, 3]" = convolution_backward_209[1];  convolution_backward_209 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_176: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_107, 0);  relu_107 = None
    where_176: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_176, full_default, getitem_1277);  le_176 = getitem_1277 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_422: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_176, [0, 2, 3])
    sub_1165: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_114, unsqueeze_3853);  convolution_114 = unsqueeze_3853 = None
    mul_4289: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_176, sub_1165)
    sum_423: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4289, [0, 2, 3]);  mul_4289 = None
    mul_4290: "f32[72]" = torch.ops.aten.mul.Tensor(sum_422, 0.0006377551020408163)
    unsqueeze_3854: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4290, 0);  mul_4290 = None
    unsqueeze_3855: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3854, 2);  unsqueeze_3854 = None
    unsqueeze_3856: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3855, 3);  unsqueeze_3855 = None
    mul_4291: "f32[72]" = torch.ops.aten.mul.Tensor(sum_423, 0.0006377551020408163)
    mul_4292: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_343, squeeze_343)
    mul_4293: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4291, mul_4292);  mul_4291 = mul_4292 = None
    unsqueeze_3857: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4293, 0);  mul_4293 = None
    unsqueeze_3858: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3857, 2);  unsqueeze_3857 = None
    unsqueeze_3859: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3858, 3);  unsqueeze_3858 = None
    mul_4294: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_343, primals_344);  primals_344 = None
    unsqueeze_3860: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4294, 0);  mul_4294 = None
    unsqueeze_3861: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3860, 2);  unsqueeze_3860 = None
    unsqueeze_3862: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3861, 3);  unsqueeze_3861 = None
    mul_4295: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1165, unsqueeze_3859);  sub_1165 = unsqueeze_3859 = None
    sub_1167: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_176, mul_4295);  where_176 = mul_4295 = None
    sub_1168: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1167, unsqueeze_3856);  sub_1167 = unsqueeze_3856 = None
    mul_4296: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1168, unsqueeze_3862);  sub_1168 = unsqueeze_3862 = None
    mul_4297: "f32[72]" = torch.ops.aten.mul.Tensor(sum_423, squeeze_343);  sum_423 = squeeze_343 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_210 = torch.ops.aten.convolution_backward.default(mul_4296, relu_90, primals_343, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4296 = primals_343 = None
    getitem_1280: "f32[8, 72, 14, 14]" = convolution_backward_210[0]
    getitem_1281: "f32[72, 72, 3, 3]" = convolution_backward_210[1];  convolution_backward_210 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2042: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_175, getitem_1280);  where_175 = getitem_1280 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_177: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_106, 0);  relu_106 = None
    where_177: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_177, full_default, add_2038);  le_177 = add_2038 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_424: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_177, [0, 2, 3])
    sub_1169: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_113, unsqueeze_3865);  convolution_113 = unsqueeze_3865 = None
    mul_4298: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_177, sub_1169)
    sum_425: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4298, [0, 2, 3]);  mul_4298 = None
    mul_4299: "f32[36]" = torch.ops.aten.mul.Tensor(sum_424, 0.00015943877551020407)
    unsqueeze_3866: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4299, 0);  mul_4299 = None
    unsqueeze_3867: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3866, 2);  unsqueeze_3866 = None
    unsqueeze_3868: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3867, 3);  unsqueeze_3867 = None
    mul_4300: "f32[36]" = torch.ops.aten.mul.Tensor(sum_425, 0.00015943877551020407)
    mul_4301: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_340, squeeze_340)
    mul_4302: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4300, mul_4301);  mul_4300 = mul_4301 = None
    unsqueeze_3869: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4302, 0);  mul_4302 = None
    unsqueeze_3870: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3869, 2);  unsqueeze_3869 = None
    unsqueeze_3871: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3870, 3);  unsqueeze_3870 = None
    mul_4303: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_340, primals_341);  primals_341 = None
    unsqueeze_3872: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4303, 0);  mul_4303 = None
    unsqueeze_3873: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3872, 2);  unsqueeze_3872 = None
    unsqueeze_3874: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3873, 3);  unsqueeze_3873 = None
    mul_4304: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1169, unsqueeze_3871);  sub_1169 = unsqueeze_3871 = None
    sub_1171: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_177, mul_4304);  mul_4304 = None
    sub_1172: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1171, unsqueeze_3868);  sub_1171 = unsqueeze_3868 = None
    mul_4305: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1172, unsqueeze_3874);  sub_1172 = unsqueeze_3874 = None
    mul_4306: "f32[36]" = torch.ops.aten.mul.Tensor(sum_425, squeeze_340);  sum_425 = squeeze_340 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_211 = torch.ops.aten.convolution_backward.default(mul_4305, relu_105, primals_340, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4305 = primals_340 = None
    getitem_1283: "f32[8, 36, 28, 28]" = convolution_backward_211[0]
    getitem_1284: "f32[36, 36, 3, 3]" = convolution_backward_211[1];  convolution_backward_211 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_178: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_105, 0);  relu_105 = None
    where_178: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_178, full_default, getitem_1283);  le_178 = getitem_1283 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_426: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_178, [0, 2, 3])
    sub_1173: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_112, unsqueeze_3877);  convolution_112 = unsqueeze_3877 = None
    mul_4307: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_178, sub_1173)
    sum_427: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4307, [0, 2, 3]);  mul_4307 = None
    mul_4308: "f32[36]" = torch.ops.aten.mul.Tensor(sum_426, 0.00015943877551020407)
    unsqueeze_3878: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4308, 0);  mul_4308 = None
    unsqueeze_3879: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3878, 2);  unsqueeze_3878 = None
    unsqueeze_3880: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3879, 3);  unsqueeze_3879 = None
    mul_4309: "f32[36]" = torch.ops.aten.mul.Tensor(sum_427, 0.00015943877551020407)
    mul_4310: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_337, squeeze_337)
    mul_4311: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4309, mul_4310);  mul_4309 = mul_4310 = None
    unsqueeze_3881: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4311, 0);  mul_4311 = None
    unsqueeze_3882: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3881, 2);  unsqueeze_3881 = None
    unsqueeze_3883: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3882, 3);  unsqueeze_3882 = None
    mul_4312: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_337, primals_338);  primals_338 = None
    unsqueeze_3884: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4312, 0);  mul_4312 = None
    unsqueeze_3885: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3884, 2);  unsqueeze_3884 = None
    unsqueeze_3886: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3885, 3);  unsqueeze_3885 = None
    mul_4313: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1173, unsqueeze_3883);  sub_1173 = unsqueeze_3883 = None
    sub_1175: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_178, mul_4313);  where_178 = mul_4313 = None
    sub_1176: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1175, unsqueeze_3880);  sub_1175 = unsqueeze_3880 = None
    mul_4314: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1176, unsqueeze_3886);  sub_1176 = unsqueeze_3886 = None
    mul_4315: "f32[36]" = torch.ops.aten.mul.Tensor(sum_427, squeeze_337);  sum_427 = squeeze_337 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_212 = torch.ops.aten.convolution_backward.default(mul_4314, relu_104, primals_337, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4314 = primals_337 = None
    getitem_1286: "f32[8, 36, 28, 28]" = convolution_backward_212[0]
    getitem_1287: "f32[36, 36, 3, 3]" = convolution_backward_212[1];  convolution_backward_212 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2043: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_177, getitem_1286);  where_177 = getitem_1286 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_179: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_104, 0);  relu_104 = None
    where_179: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_179, full_default, add_2043);  le_179 = add_2043 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_428: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_179, [0, 2, 3])
    sub_1177: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_111, unsqueeze_3889);  convolution_111 = unsqueeze_3889 = None
    mul_4316: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_179, sub_1177)
    sum_429: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4316, [0, 2, 3]);  mul_4316 = None
    mul_4317: "f32[36]" = torch.ops.aten.mul.Tensor(sum_428, 0.00015943877551020407)
    unsqueeze_3890: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4317, 0);  mul_4317 = None
    unsqueeze_3891: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3890, 2);  unsqueeze_3890 = None
    unsqueeze_3892: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3891, 3);  unsqueeze_3891 = None
    mul_4318: "f32[36]" = torch.ops.aten.mul.Tensor(sum_429, 0.00015943877551020407)
    mul_4319: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_334, squeeze_334)
    mul_4320: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4318, mul_4319);  mul_4318 = mul_4319 = None
    unsqueeze_3893: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4320, 0);  mul_4320 = None
    unsqueeze_3894: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3893, 2);  unsqueeze_3893 = None
    unsqueeze_3895: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3894, 3);  unsqueeze_3894 = None
    mul_4321: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_334, primals_335);  primals_335 = None
    unsqueeze_3896: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4321, 0);  mul_4321 = None
    unsqueeze_3897: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3896, 2);  unsqueeze_3896 = None
    unsqueeze_3898: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3897, 3);  unsqueeze_3897 = None
    mul_4322: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1177, unsqueeze_3895);  sub_1177 = unsqueeze_3895 = None
    sub_1179: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_179, mul_4322);  mul_4322 = None
    sub_1180: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1179, unsqueeze_3892);  sub_1179 = unsqueeze_3892 = None
    mul_4323: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1180, unsqueeze_3898);  sub_1180 = unsqueeze_3898 = None
    mul_4324: "f32[36]" = torch.ops.aten.mul.Tensor(sum_429, squeeze_334);  sum_429 = squeeze_334 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_213 = torch.ops.aten.convolution_backward.default(mul_4323, relu_103, primals_334, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4323 = primals_334 = None
    getitem_1289: "f32[8, 36, 28, 28]" = convolution_backward_213[0]
    getitem_1290: "f32[36, 36, 3, 3]" = convolution_backward_213[1];  convolution_backward_213 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_180: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_103, 0);  relu_103 = None
    where_180: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_180, full_default, getitem_1289);  le_180 = getitem_1289 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_430: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_180, [0, 2, 3])
    sub_1181: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_110, unsqueeze_3901);  convolution_110 = unsqueeze_3901 = None
    mul_4325: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_180, sub_1181)
    sum_431: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4325, [0, 2, 3]);  mul_4325 = None
    mul_4326: "f32[36]" = torch.ops.aten.mul.Tensor(sum_430, 0.00015943877551020407)
    unsqueeze_3902: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4326, 0);  mul_4326 = None
    unsqueeze_3903: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3902, 2);  unsqueeze_3902 = None
    unsqueeze_3904: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3903, 3);  unsqueeze_3903 = None
    mul_4327: "f32[36]" = torch.ops.aten.mul.Tensor(sum_431, 0.00015943877551020407)
    mul_4328: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_331, squeeze_331)
    mul_4329: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4327, mul_4328);  mul_4327 = mul_4328 = None
    unsqueeze_3905: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4329, 0);  mul_4329 = None
    unsqueeze_3906: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3905, 2);  unsqueeze_3905 = None
    unsqueeze_3907: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3906, 3);  unsqueeze_3906 = None
    mul_4330: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_331, primals_332);  primals_332 = None
    unsqueeze_3908: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4330, 0);  mul_4330 = None
    unsqueeze_3909: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3908, 2);  unsqueeze_3908 = None
    unsqueeze_3910: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3909, 3);  unsqueeze_3909 = None
    mul_4331: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1181, unsqueeze_3907);  sub_1181 = unsqueeze_3907 = None
    sub_1183: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_180, mul_4331);  where_180 = mul_4331 = None
    sub_1184: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1183, unsqueeze_3904);  sub_1183 = unsqueeze_3904 = None
    mul_4332: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1184, unsqueeze_3910);  sub_1184 = unsqueeze_3910 = None
    mul_4333: "f32[36]" = torch.ops.aten.mul.Tensor(sum_431, squeeze_331);  sum_431 = squeeze_331 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_214 = torch.ops.aten.convolution_backward.default(mul_4332, relu_102, primals_331, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4332 = primals_331 = None
    getitem_1292: "f32[8, 36, 28, 28]" = convolution_backward_214[0]
    getitem_1293: "f32[36, 36, 3, 3]" = convolution_backward_214[1];  convolution_backward_214 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2044: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_179, getitem_1292);  where_179 = getitem_1292 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_181: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_102, 0);  relu_102 = None
    where_181: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_181, full_default, add_2044);  le_181 = add_2044 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_432: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_181, [0, 2, 3])
    sub_1185: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_109, unsqueeze_3913);  convolution_109 = unsqueeze_3913 = None
    mul_4334: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_181, sub_1185)
    sum_433: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4334, [0, 2, 3]);  mul_4334 = None
    mul_4335: "f32[36]" = torch.ops.aten.mul.Tensor(sum_432, 0.00015943877551020407)
    unsqueeze_3914: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4335, 0);  mul_4335 = None
    unsqueeze_3915: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3914, 2);  unsqueeze_3914 = None
    unsqueeze_3916: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3915, 3);  unsqueeze_3915 = None
    mul_4336: "f32[36]" = torch.ops.aten.mul.Tensor(sum_433, 0.00015943877551020407)
    mul_4337: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_328, squeeze_328)
    mul_4338: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4336, mul_4337);  mul_4336 = mul_4337 = None
    unsqueeze_3917: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4338, 0);  mul_4338 = None
    unsqueeze_3918: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3917, 2);  unsqueeze_3917 = None
    unsqueeze_3919: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3918, 3);  unsqueeze_3918 = None
    mul_4339: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_328, primals_329);  primals_329 = None
    unsqueeze_3920: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4339, 0);  mul_4339 = None
    unsqueeze_3921: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3920, 2);  unsqueeze_3920 = None
    unsqueeze_3922: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3921, 3);  unsqueeze_3921 = None
    mul_4340: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1185, unsqueeze_3919);  sub_1185 = unsqueeze_3919 = None
    sub_1187: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_181, mul_4340);  mul_4340 = None
    sub_1188: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1187, unsqueeze_3916);  sub_1187 = unsqueeze_3916 = None
    mul_4341: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1188, unsqueeze_3922);  sub_1188 = unsqueeze_3922 = None
    mul_4342: "f32[36]" = torch.ops.aten.mul.Tensor(sum_433, squeeze_328);  sum_433 = squeeze_328 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_215 = torch.ops.aten.convolution_backward.default(mul_4341, relu_101, primals_328, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4341 = primals_328 = None
    getitem_1295: "f32[8, 36, 28, 28]" = convolution_backward_215[0]
    getitem_1296: "f32[36, 36, 3, 3]" = convolution_backward_215[1];  convolution_backward_215 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_182: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_101, 0);  relu_101 = None
    where_182: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_182, full_default, getitem_1295);  le_182 = getitem_1295 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_434: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_182, [0, 2, 3])
    sub_1189: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_108, unsqueeze_3925);  convolution_108 = unsqueeze_3925 = None
    mul_4343: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_182, sub_1189)
    sum_435: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4343, [0, 2, 3]);  mul_4343 = None
    mul_4344: "f32[36]" = torch.ops.aten.mul.Tensor(sum_434, 0.00015943877551020407)
    unsqueeze_3926: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4344, 0);  mul_4344 = None
    unsqueeze_3927: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3926, 2);  unsqueeze_3926 = None
    unsqueeze_3928: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3927, 3);  unsqueeze_3927 = None
    mul_4345: "f32[36]" = torch.ops.aten.mul.Tensor(sum_435, 0.00015943877551020407)
    mul_4346: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_325, squeeze_325)
    mul_4347: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4345, mul_4346);  mul_4345 = mul_4346 = None
    unsqueeze_3929: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4347, 0);  mul_4347 = None
    unsqueeze_3930: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3929, 2);  unsqueeze_3929 = None
    unsqueeze_3931: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3930, 3);  unsqueeze_3930 = None
    mul_4348: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_325, primals_326);  primals_326 = None
    unsqueeze_3932: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4348, 0);  mul_4348 = None
    unsqueeze_3933: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3932, 2);  unsqueeze_3932 = None
    unsqueeze_3934: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3933, 3);  unsqueeze_3933 = None
    mul_4349: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1189, unsqueeze_3931);  sub_1189 = unsqueeze_3931 = None
    sub_1191: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_182, mul_4349);  where_182 = mul_4349 = None
    sub_1192: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1191, unsqueeze_3928);  sub_1191 = unsqueeze_3928 = None
    mul_4350: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1192, unsqueeze_3934);  sub_1192 = unsqueeze_3934 = None
    mul_4351: "f32[36]" = torch.ops.aten.mul.Tensor(sum_435, squeeze_325);  sum_435 = squeeze_325 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_216 = torch.ops.aten.convolution_backward.default(mul_4350, relu_100, primals_325, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4350 = primals_325 = None
    getitem_1298: "f32[8, 36, 28, 28]" = convolution_backward_216[0]
    getitem_1299: "f32[36, 36, 3, 3]" = convolution_backward_216[1];  convolution_backward_216 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2045: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_181, getitem_1298);  where_181 = getitem_1298 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_183: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_100, 0);  relu_100 = None
    where_183: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_183, full_default, add_2045);  le_183 = add_2045 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_436: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_183, [0, 2, 3])
    sub_1193: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_107, unsqueeze_3937);  convolution_107 = unsqueeze_3937 = None
    mul_4352: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_183, sub_1193)
    sum_437: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4352, [0, 2, 3]);  mul_4352 = None
    mul_4353: "f32[36]" = torch.ops.aten.mul.Tensor(sum_436, 0.00015943877551020407)
    unsqueeze_3938: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4353, 0);  mul_4353 = None
    unsqueeze_3939: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3938, 2);  unsqueeze_3938 = None
    unsqueeze_3940: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3939, 3);  unsqueeze_3939 = None
    mul_4354: "f32[36]" = torch.ops.aten.mul.Tensor(sum_437, 0.00015943877551020407)
    mul_4355: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_322, squeeze_322)
    mul_4356: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4354, mul_4355);  mul_4354 = mul_4355 = None
    unsqueeze_3941: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4356, 0);  mul_4356 = None
    unsqueeze_3942: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3941, 2);  unsqueeze_3941 = None
    unsqueeze_3943: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3942, 3);  unsqueeze_3942 = None
    mul_4357: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_322, primals_323);  primals_323 = None
    unsqueeze_3944: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4357, 0);  mul_4357 = None
    unsqueeze_3945: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3944, 2);  unsqueeze_3944 = None
    unsqueeze_3946: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3945, 3);  unsqueeze_3945 = None
    mul_4358: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1193, unsqueeze_3943);  sub_1193 = unsqueeze_3943 = None
    sub_1195: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_183, mul_4358);  mul_4358 = None
    sub_1196: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1195, unsqueeze_3940);  sub_1195 = unsqueeze_3940 = None
    mul_4359: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1196, unsqueeze_3946);  sub_1196 = unsqueeze_3946 = None
    mul_4360: "f32[36]" = torch.ops.aten.mul.Tensor(sum_437, squeeze_322);  sum_437 = squeeze_322 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_217 = torch.ops.aten.convolution_backward.default(mul_4359, relu_99, primals_322, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4359 = primals_322 = None
    getitem_1301: "f32[8, 36, 28, 28]" = convolution_backward_217[0]
    getitem_1302: "f32[36, 36, 3, 3]" = convolution_backward_217[1];  convolution_backward_217 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_184: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_99, 0);  relu_99 = None
    where_184: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_184, full_default, getitem_1301);  le_184 = getitem_1301 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_438: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_184, [0, 2, 3])
    sub_1197: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_106, unsqueeze_3949);  convolution_106 = unsqueeze_3949 = None
    mul_4361: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_184, sub_1197)
    sum_439: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4361, [0, 2, 3]);  mul_4361 = None
    mul_4362: "f32[36]" = torch.ops.aten.mul.Tensor(sum_438, 0.00015943877551020407)
    unsqueeze_3950: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4362, 0);  mul_4362 = None
    unsqueeze_3951: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3950, 2);  unsqueeze_3950 = None
    unsqueeze_3952: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3951, 3);  unsqueeze_3951 = None
    mul_4363: "f32[36]" = torch.ops.aten.mul.Tensor(sum_439, 0.00015943877551020407)
    mul_4364: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_319, squeeze_319)
    mul_4365: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4363, mul_4364);  mul_4363 = mul_4364 = None
    unsqueeze_3953: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4365, 0);  mul_4365 = None
    unsqueeze_3954: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3953, 2);  unsqueeze_3953 = None
    unsqueeze_3955: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3954, 3);  unsqueeze_3954 = None
    mul_4366: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_319, primals_320);  primals_320 = None
    unsqueeze_3956: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4366, 0);  mul_4366 = None
    unsqueeze_3957: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3956, 2);  unsqueeze_3956 = None
    unsqueeze_3958: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3957, 3);  unsqueeze_3957 = None
    mul_4367: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1197, unsqueeze_3955);  sub_1197 = unsqueeze_3955 = None
    sub_1199: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_184, mul_4367);  where_184 = mul_4367 = None
    sub_1200: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1199, unsqueeze_3952);  sub_1199 = unsqueeze_3952 = None
    mul_4368: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1200, unsqueeze_3958);  sub_1200 = unsqueeze_3958 = None
    mul_4369: "f32[36]" = torch.ops.aten.mul.Tensor(sum_439, squeeze_319);  sum_439 = squeeze_319 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_218 = torch.ops.aten.convolution_backward.default(mul_4368, relu_88, primals_319, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4368 = primals_319 = None
    getitem_1304: "f32[8, 36, 28, 28]" = convolution_backward_218[0]
    getitem_1305: "f32[36, 36, 3, 3]" = convolution_backward_218[1];  convolution_backward_218 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2046: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_183, getitem_1304);  where_183 = getitem_1304 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_185: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_98, 0);  relu_98 = None
    where_185: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_185, full_default, add_2037);  le_185 = add_2037 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_440: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_185, [0, 2, 3])
    sub_1201: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_105, unsqueeze_3961);  convolution_105 = unsqueeze_3961 = None
    mul_4370: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_185, sub_1201)
    sum_441: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4370, [0, 2, 3]);  mul_4370 = None
    mul_4371: "f32[18]" = torch.ops.aten.mul.Tensor(sum_440, 3.985969387755102e-05)
    unsqueeze_3962: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4371, 0);  mul_4371 = None
    unsqueeze_3963: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3962, 2);  unsqueeze_3962 = None
    unsqueeze_3964: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3963, 3);  unsqueeze_3963 = None
    mul_4372: "f32[18]" = torch.ops.aten.mul.Tensor(sum_441, 3.985969387755102e-05)
    mul_4373: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_316, squeeze_316)
    mul_4374: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4372, mul_4373);  mul_4372 = mul_4373 = None
    unsqueeze_3965: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4374, 0);  mul_4374 = None
    unsqueeze_3966: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3965, 2);  unsqueeze_3965 = None
    unsqueeze_3967: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3966, 3);  unsqueeze_3966 = None
    mul_4375: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_316, primals_317);  primals_317 = None
    unsqueeze_3968: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4375, 0);  mul_4375 = None
    unsqueeze_3969: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3968, 2);  unsqueeze_3968 = None
    unsqueeze_3970: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3969, 3);  unsqueeze_3969 = None
    mul_4376: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1201, unsqueeze_3967);  sub_1201 = unsqueeze_3967 = None
    sub_1203: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_185, mul_4376);  mul_4376 = None
    sub_1204: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1203, unsqueeze_3964);  sub_1203 = unsqueeze_3964 = None
    mul_4377: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1204, unsqueeze_3970);  sub_1204 = unsqueeze_3970 = None
    mul_4378: "f32[18]" = torch.ops.aten.mul.Tensor(sum_441, squeeze_316);  sum_441 = squeeze_316 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_219 = torch.ops.aten.convolution_backward.default(mul_4377, relu_97, primals_316, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4377 = primals_316 = None
    getitem_1307: "f32[8, 18, 56, 56]" = convolution_backward_219[0]
    getitem_1308: "f32[18, 18, 3, 3]" = convolution_backward_219[1];  convolution_backward_219 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_186: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_97, 0);  relu_97 = None
    where_186: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_186, full_default, getitem_1307);  le_186 = getitem_1307 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_442: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_186, [0, 2, 3])
    sub_1205: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_104, unsqueeze_3973);  convolution_104 = unsqueeze_3973 = None
    mul_4379: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_186, sub_1205)
    sum_443: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4379, [0, 2, 3]);  mul_4379 = None
    mul_4380: "f32[18]" = torch.ops.aten.mul.Tensor(sum_442, 3.985969387755102e-05)
    unsqueeze_3974: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4380, 0);  mul_4380 = None
    unsqueeze_3975: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3974, 2);  unsqueeze_3974 = None
    unsqueeze_3976: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3975, 3);  unsqueeze_3975 = None
    mul_4381: "f32[18]" = torch.ops.aten.mul.Tensor(sum_443, 3.985969387755102e-05)
    mul_4382: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_313, squeeze_313)
    mul_4383: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4381, mul_4382);  mul_4381 = mul_4382 = None
    unsqueeze_3977: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4383, 0);  mul_4383 = None
    unsqueeze_3978: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3977, 2);  unsqueeze_3977 = None
    unsqueeze_3979: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3978, 3);  unsqueeze_3978 = None
    mul_4384: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_313, primals_314);  primals_314 = None
    unsqueeze_3980: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4384, 0);  mul_4384 = None
    unsqueeze_3981: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3980, 2);  unsqueeze_3980 = None
    unsqueeze_3982: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3981, 3);  unsqueeze_3981 = None
    mul_4385: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1205, unsqueeze_3979);  sub_1205 = unsqueeze_3979 = None
    sub_1207: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_186, mul_4385);  where_186 = mul_4385 = None
    sub_1208: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1207, unsqueeze_3976);  sub_1207 = unsqueeze_3976 = None
    mul_4386: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1208, unsqueeze_3982);  sub_1208 = unsqueeze_3982 = None
    mul_4387: "f32[18]" = torch.ops.aten.mul.Tensor(sum_443, squeeze_313);  sum_443 = squeeze_313 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_220 = torch.ops.aten.convolution_backward.default(mul_4386, relu_96, primals_313, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4386 = primals_313 = None
    getitem_1310: "f32[8, 18, 56, 56]" = convolution_backward_220[0]
    getitem_1311: "f32[18, 18, 3, 3]" = convolution_backward_220[1];  convolution_backward_220 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2047: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_185, getitem_1310);  where_185 = getitem_1310 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_187: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_96, 0);  relu_96 = None
    where_187: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_187, full_default, add_2047);  le_187 = add_2047 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_444: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_187, [0, 2, 3])
    sub_1209: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_103, unsqueeze_3985);  convolution_103 = unsqueeze_3985 = None
    mul_4388: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_187, sub_1209)
    sum_445: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4388, [0, 2, 3]);  mul_4388 = None
    mul_4389: "f32[18]" = torch.ops.aten.mul.Tensor(sum_444, 3.985969387755102e-05)
    unsqueeze_3986: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4389, 0);  mul_4389 = None
    unsqueeze_3987: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3986, 2);  unsqueeze_3986 = None
    unsqueeze_3988: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3987, 3);  unsqueeze_3987 = None
    mul_4390: "f32[18]" = torch.ops.aten.mul.Tensor(sum_445, 3.985969387755102e-05)
    mul_4391: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_310, squeeze_310)
    mul_4392: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4390, mul_4391);  mul_4390 = mul_4391 = None
    unsqueeze_3989: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4392, 0);  mul_4392 = None
    unsqueeze_3990: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3989, 2);  unsqueeze_3989 = None
    unsqueeze_3991: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3990, 3);  unsqueeze_3990 = None
    mul_4393: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_310, primals_311);  primals_311 = None
    unsqueeze_3992: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4393, 0);  mul_4393 = None
    unsqueeze_3993: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3992, 2);  unsqueeze_3992 = None
    unsqueeze_3994: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3993, 3);  unsqueeze_3993 = None
    mul_4394: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1209, unsqueeze_3991);  sub_1209 = unsqueeze_3991 = None
    sub_1211: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_187, mul_4394);  mul_4394 = None
    sub_1212: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1211, unsqueeze_3988);  sub_1211 = unsqueeze_3988 = None
    mul_4395: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1212, unsqueeze_3994);  sub_1212 = unsqueeze_3994 = None
    mul_4396: "f32[18]" = torch.ops.aten.mul.Tensor(sum_445, squeeze_310);  sum_445 = squeeze_310 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_221 = torch.ops.aten.convolution_backward.default(mul_4395, relu_95, primals_310, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4395 = primals_310 = None
    getitem_1313: "f32[8, 18, 56, 56]" = convolution_backward_221[0]
    getitem_1314: "f32[18, 18, 3, 3]" = convolution_backward_221[1];  convolution_backward_221 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_188: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_95, 0);  relu_95 = None
    where_188: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_188, full_default, getitem_1313);  le_188 = getitem_1313 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_446: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_188, [0, 2, 3])
    sub_1213: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_102, unsqueeze_3997);  convolution_102 = unsqueeze_3997 = None
    mul_4397: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_188, sub_1213)
    sum_447: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4397, [0, 2, 3]);  mul_4397 = None
    mul_4398: "f32[18]" = torch.ops.aten.mul.Tensor(sum_446, 3.985969387755102e-05)
    unsqueeze_3998: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4398, 0);  mul_4398 = None
    unsqueeze_3999: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3998, 2);  unsqueeze_3998 = None
    unsqueeze_4000: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_3999, 3);  unsqueeze_3999 = None
    mul_4399: "f32[18]" = torch.ops.aten.mul.Tensor(sum_447, 3.985969387755102e-05)
    mul_4400: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_307, squeeze_307)
    mul_4401: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4399, mul_4400);  mul_4399 = mul_4400 = None
    unsqueeze_4001: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4401, 0);  mul_4401 = None
    unsqueeze_4002: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4001, 2);  unsqueeze_4001 = None
    unsqueeze_4003: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4002, 3);  unsqueeze_4002 = None
    mul_4402: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_307, primals_308);  primals_308 = None
    unsqueeze_4004: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4402, 0);  mul_4402 = None
    unsqueeze_4005: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4004, 2);  unsqueeze_4004 = None
    unsqueeze_4006: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4005, 3);  unsqueeze_4005 = None
    mul_4403: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1213, unsqueeze_4003);  sub_1213 = unsqueeze_4003 = None
    sub_1215: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_188, mul_4403);  where_188 = mul_4403 = None
    sub_1216: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1215, unsqueeze_4000);  sub_1215 = unsqueeze_4000 = None
    mul_4404: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1216, unsqueeze_4006);  sub_1216 = unsqueeze_4006 = None
    mul_4405: "f32[18]" = torch.ops.aten.mul.Tensor(sum_447, squeeze_307);  sum_447 = squeeze_307 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_222 = torch.ops.aten.convolution_backward.default(mul_4404, relu_94, primals_307, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4404 = primals_307 = None
    getitem_1316: "f32[8, 18, 56, 56]" = convolution_backward_222[0]
    getitem_1317: "f32[18, 18, 3, 3]" = convolution_backward_222[1];  convolution_backward_222 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2048: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_187, getitem_1316);  where_187 = getitem_1316 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_189: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_94, 0);  relu_94 = None
    where_189: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_189, full_default, add_2048);  le_189 = add_2048 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_448: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_189, [0, 2, 3])
    sub_1217: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_101, unsqueeze_4009);  convolution_101 = unsqueeze_4009 = None
    mul_4406: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_189, sub_1217)
    sum_449: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4406, [0, 2, 3]);  mul_4406 = None
    mul_4407: "f32[18]" = torch.ops.aten.mul.Tensor(sum_448, 3.985969387755102e-05)
    unsqueeze_4010: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4407, 0);  mul_4407 = None
    unsqueeze_4011: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4010, 2);  unsqueeze_4010 = None
    unsqueeze_4012: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4011, 3);  unsqueeze_4011 = None
    mul_4408: "f32[18]" = torch.ops.aten.mul.Tensor(sum_449, 3.985969387755102e-05)
    mul_4409: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_304, squeeze_304)
    mul_4410: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4408, mul_4409);  mul_4408 = mul_4409 = None
    unsqueeze_4013: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4410, 0);  mul_4410 = None
    unsqueeze_4014: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4013, 2);  unsqueeze_4013 = None
    unsqueeze_4015: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4014, 3);  unsqueeze_4014 = None
    mul_4411: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_304, primals_305);  primals_305 = None
    unsqueeze_4016: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4411, 0);  mul_4411 = None
    unsqueeze_4017: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4016, 2);  unsqueeze_4016 = None
    unsqueeze_4018: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4017, 3);  unsqueeze_4017 = None
    mul_4412: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1217, unsqueeze_4015);  sub_1217 = unsqueeze_4015 = None
    sub_1219: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_189, mul_4412);  mul_4412 = None
    sub_1220: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1219, unsqueeze_4012);  sub_1219 = unsqueeze_4012 = None
    mul_4413: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1220, unsqueeze_4018);  sub_1220 = unsqueeze_4018 = None
    mul_4414: "f32[18]" = torch.ops.aten.mul.Tensor(sum_449, squeeze_304);  sum_449 = squeeze_304 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_223 = torch.ops.aten.convolution_backward.default(mul_4413, relu_93, primals_304, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4413 = primals_304 = None
    getitem_1319: "f32[8, 18, 56, 56]" = convolution_backward_223[0]
    getitem_1320: "f32[18, 18, 3, 3]" = convolution_backward_223[1];  convolution_backward_223 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_190: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_93, 0);  relu_93 = None
    where_190: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_190, full_default, getitem_1319);  le_190 = getitem_1319 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_450: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_190, [0, 2, 3])
    sub_1221: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_100, unsqueeze_4021);  convolution_100 = unsqueeze_4021 = None
    mul_4415: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_190, sub_1221)
    sum_451: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4415, [0, 2, 3]);  mul_4415 = None
    mul_4416: "f32[18]" = torch.ops.aten.mul.Tensor(sum_450, 3.985969387755102e-05)
    unsqueeze_4022: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4416, 0);  mul_4416 = None
    unsqueeze_4023: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4022, 2);  unsqueeze_4022 = None
    unsqueeze_4024: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4023, 3);  unsqueeze_4023 = None
    mul_4417: "f32[18]" = torch.ops.aten.mul.Tensor(sum_451, 3.985969387755102e-05)
    mul_4418: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_301, squeeze_301)
    mul_4419: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4417, mul_4418);  mul_4417 = mul_4418 = None
    unsqueeze_4025: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4419, 0);  mul_4419 = None
    unsqueeze_4026: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4025, 2);  unsqueeze_4025 = None
    unsqueeze_4027: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4026, 3);  unsqueeze_4026 = None
    mul_4420: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_301, primals_302);  primals_302 = None
    unsqueeze_4028: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4420, 0);  mul_4420 = None
    unsqueeze_4029: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4028, 2);  unsqueeze_4028 = None
    unsqueeze_4030: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4029, 3);  unsqueeze_4029 = None
    mul_4421: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1221, unsqueeze_4027);  sub_1221 = unsqueeze_4027 = None
    sub_1223: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_190, mul_4421);  where_190 = mul_4421 = None
    sub_1224: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1223, unsqueeze_4024);  sub_1223 = unsqueeze_4024 = None
    mul_4422: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1224, unsqueeze_4030);  sub_1224 = unsqueeze_4030 = None
    mul_4423: "f32[18]" = torch.ops.aten.mul.Tensor(sum_451, squeeze_301);  sum_451 = squeeze_301 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_224 = torch.ops.aten.convolution_backward.default(mul_4422, relu_92, primals_301, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4422 = primals_301 = None
    getitem_1322: "f32[8, 18, 56, 56]" = convolution_backward_224[0]
    getitem_1323: "f32[18, 18, 3, 3]" = convolution_backward_224[1];  convolution_backward_224 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2049: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_189, getitem_1322);  where_189 = getitem_1322 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_191: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_92, 0);  relu_92 = None
    where_191: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_191, full_default, add_2049);  le_191 = add_2049 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_452: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_191, [0, 2, 3])
    sub_1225: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_99, unsqueeze_4033);  convolution_99 = unsqueeze_4033 = None
    mul_4424: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_191, sub_1225)
    sum_453: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4424, [0, 2, 3]);  mul_4424 = None
    mul_4425: "f32[18]" = torch.ops.aten.mul.Tensor(sum_452, 3.985969387755102e-05)
    unsqueeze_4034: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4425, 0);  mul_4425 = None
    unsqueeze_4035: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4034, 2);  unsqueeze_4034 = None
    unsqueeze_4036: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4035, 3);  unsqueeze_4035 = None
    mul_4426: "f32[18]" = torch.ops.aten.mul.Tensor(sum_453, 3.985969387755102e-05)
    mul_4427: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_298, squeeze_298)
    mul_4428: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4426, mul_4427);  mul_4426 = mul_4427 = None
    unsqueeze_4037: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4428, 0);  mul_4428 = None
    unsqueeze_4038: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4037, 2);  unsqueeze_4037 = None
    unsqueeze_4039: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4038, 3);  unsqueeze_4038 = None
    mul_4429: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_298, primals_299);  primals_299 = None
    unsqueeze_4040: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4429, 0);  mul_4429 = None
    unsqueeze_4041: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4040, 2);  unsqueeze_4040 = None
    unsqueeze_4042: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4041, 3);  unsqueeze_4041 = None
    mul_4430: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1225, unsqueeze_4039);  sub_1225 = unsqueeze_4039 = None
    sub_1227: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_191, mul_4430);  mul_4430 = None
    sub_1228: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1227, unsqueeze_4036);  sub_1227 = unsqueeze_4036 = None
    mul_4431: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1228, unsqueeze_4042);  sub_1228 = unsqueeze_4042 = None
    mul_4432: "f32[18]" = torch.ops.aten.mul.Tensor(sum_453, squeeze_298);  sum_453 = squeeze_298 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_225 = torch.ops.aten.convolution_backward.default(mul_4431, relu_91, primals_298, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4431 = primals_298 = None
    getitem_1325: "f32[8, 18, 56, 56]" = convolution_backward_225[0]
    getitem_1326: "f32[18, 18, 3, 3]" = convolution_backward_225[1];  convolution_backward_225 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_192: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_91, 0);  relu_91 = None
    where_192: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_192, full_default, getitem_1325);  le_192 = getitem_1325 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_454: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_192, [0, 2, 3])
    sub_1229: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_98, unsqueeze_4045);  convolution_98 = unsqueeze_4045 = None
    mul_4433: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_192, sub_1229)
    sum_455: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4433, [0, 2, 3]);  mul_4433 = None
    mul_4434: "f32[18]" = torch.ops.aten.mul.Tensor(sum_454, 3.985969387755102e-05)
    unsqueeze_4046: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4434, 0);  mul_4434 = None
    unsqueeze_4047: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4046, 2);  unsqueeze_4046 = None
    unsqueeze_4048: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4047, 3);  unsqueeze_4047 = None
    mul_4435: "f32[18]" = torch.ops.aten.mul.Tensor(sum_455, 3.985969387755102e-05)
    mul_4436: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_295, squeeze_295)
    mul_4437: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4435, mul_4436);  mul_4435 = mul_4436 = None
    unsqueeze_4049: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4437, 0);  mul_4437 = None
    unsqueeze_4050: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4049, 2);  unsqueeze_4049 = None
    unsqueeze_4051: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4050, 3);  unsqueeze_4050 = None
    mul_4438: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_295, primals_296);  primals_296 = None
    unsqueeze_4052: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4438, 0);  mul_4438 = None
    unsqueeze_4053: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4052, 2);  unsqueeze_4052 = None
    unsqueeze_4054: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4053, 3);  unsqueeze_4053 = None
    mul_4439: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1229, unsqueeze_4051);  sub_1229 = unsqueeze_4051 = None
    sub_1231: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_192, mul_4439);  where_192 = mul_4439 = None
    sub_1232: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1231, unsqueeze_4048);  sub_1231 = unsqueeze_4048 = None
    mul_4440: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1232, unsqueeze_4054);  sub_1232 = unsqueeze_4054 = None
    mul_4441: "f32[18]" = torch.ops.aten.mul.Tensor(sum_455, squeeze_295);  sum_455 = squeeze_295 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_226 = torch.ops.aten.convolution_backward.default(mul_4440, relu_87, primals_295, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4440 = primals_295 = None
    getitem_1328: "f32[8, 18, 56, 56]" = convolution_backward_226[0]
    getitem_1329: "f32[18, 18, 3, 3]" = convolution_backward_226[1];  convolution_backward_226 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2050: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_191, getitem_1328);  where_191 = getitem_1328 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_193: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_90, 0);  relu_90 = None
    where_193: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_193, full_default, add_2042);  le_193 = add_2042 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    sum_456: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_193, [0, 2, 3])
    sub_1233: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_97, unsqueeze_4057);  convolution_97 = unsqueeze_4057 = None
    mul_4442: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_193, sub_1233)
    sum_457: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4442, [0, 2, 3]);  mul_4442 = None
    mul_4443: "f32[72]" = torch.ops.aten.mul.Tensor(sum_456, 0.0006377551020408163)
    unsqueeze_4058: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4443, 0);  mul_4443 = None
    unsqueeze_4059: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4058, 2);  unsqueeze_4058 = None
    unsqueeze_4060: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4059, 3);  unsqueeze_4059 = None
    mul_4444: "f32[72]" = torch.ops.aten.mul.Tensor(sum_457, 0.0006377551020408163)
    mul_4445: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_292, squeeze_292)
    mul_4446: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4444, mul_4445);  mul_4444 = mul_4445 = None
    unsqueeze_4061: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4446, 0);  mul_4446 = None
    unsqueeze_4062: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4061, 2);  unsqueeze_4061 = None
    unsqueeze_4063: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4062, 3);  unsqueeze_4062 = None
    mul_4447: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_292, primals_293);  primals_293 = None
    unsqueeze_4064: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4447, 0);  mul_4447 = None
    unsqueeze_4065: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4064, 2);  unsqueeze_4064 = None
    unsqueeze_4066: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4065, 3);  unsqueeze_4065 = None
    mul_4448: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1233, unsqueeze_4063);  sub_1233 = unsqueeze_4063 = None
    sub_1235: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_193, mul_4448);  mul_4448 = None
    sub_1236: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1235, unsqueeze_4060);  sub_1235 = None
    mul_4449: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1236, unsqueeze_4066);  sub_1236 = unsqueeze_4066 = None
    mul_4450: "f32[72]" = torch.ops.aten.mul.Tensor(sum_457, squeeze_292);  sum_457 = squeeze_292 = None
    convolution_backward_227 = torch.ops.aten.convolution_backward.default(mul_4449, relu_78, primals_292, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4449 = primals_292 = None
    getitem_1331: "f32[8, 36, 28, 28]" = convolution_backward_227[0]
    getitem_1332: "f32[72, 36, 3, 3]" = convolution_backward_227[1];  convolution_backward_227 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sub_1237: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_96, unsqueeze_4069);  convolution_96 = unsqueeze_4069 = None
    mul_4451: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_193, sub_1237)
    sum_459: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4451, [0, 2, 3]);  mul_4451 = None
    mul_4453: "f32[72]" = torch.ops.aten.mul.Tensor(sum_459, 0.0006377551020408163)
    mul_4454: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_289, squeeze_289)
    mul_4455: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4453, mul_4454);  mul_4453 = mul_4454 = None
    unsqueeze_4073: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4455, 0);  mul_4455 = None
    unsqueeze_4074: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4073, 2);  unsqueeze_4073 = None
    unsqueeze_4075: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4074, 3);  unsqueeze_4074 = None
    mul_4456: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_289, primals_290);  primals_290 = None
    unsqueeze_4076: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4456, 0);  mul_4456 = None
    unsqueeze_4077: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4076, 2);  unsqueeze_4076 = None
    unsqueeze_4078: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4077, 3);  unsqueeze_4077 = None
    mul_4457: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1237, unsqueeze_4075);  sub_1237 = unsqueeze_4075 = None
    sub_1239: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_193, mul_4457);  mul_4457 = None
    sub_1240: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1239, unsqueeze_4060);  sub_1239 = unsqueeze_4060 = None
    mul_4458: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1240, unsqueeze_4078);  sub_1240 = unsqueeze_4078 = None
    mul_4459: "f32[72]" = torch.ops.aten.mul.Tensor(sum_459, squeeze_289);  sum_459 = squeeze_289 = None
    convolution_backward_228 = torch.ops.aten.convolution_backward.default(mul_4458, relu_89, primals_289, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4458 = primals_289 = None
    getitem_1334: "f32[8, 18, 28, 28]" = convolution_backward_228[0]
    getitem_1335: "f32[72, 18, 3, 3]" = convolution_backward_228[1];  convolution_backward_228 = None
    le_194: "b8[8, 18, 28, 28]" = torch.ops.aten.le.Scalar(relu_89, 0);  relu_89 = None
    where_194: "f32[8, 18, 28, 28]" = torch.ops.aten.where.self(le_194, full_default, getitem_1334);  le_194 = getitem_1334 = None
    sum_460: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_194, [0, 2, 3])
    sub_1241: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_95, unsqueeze_4081);  convolution_95 = unsqueeze_4081 = None
    mul_4460: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(where_194, sub_1241)
    sum_461: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4460, [0, 2, 3]);  mul_4460 = None
    mul_4461: "f32[18]" = torch.ops.aten.mul.Tensor(sum_460, 0.00015943877551020407)
    unsqueeze_4082: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4461, 0);  mul_4461 = None
    unsqueeze_4083: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4082, 2);  unsqueeze_4082 = None
    unsqueeze_4084: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4083, 3);  unsqueeze_4083 = None
    mul_4462: "f32[18]" = torch.ops.aten.mul.Tensor(sum_461, 0.00015943877551020407)
    mul_4463: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_286, squeeze_286)
    mul_4464: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4462, mul_4463);  mul_4462 = mul_4463 = None
    unsqueeze_4085: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4464, 0);  mul_4464 = None
    unsqueeze_4086: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4085, 2);  unsqueeze_4085 = None
    unsqueeze_4087: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4086, 3);  unsqueeze_4086 = None
    mul_4465: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_286, primals_287);  primals_287 = None
    unsqueeze_4088: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4465, 0);  mul_4465 = None
    unsqueeze_4089: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4088, 2);  unsqueeze_4088 = None
    unsqueeze_4090: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4089, 3);  unsqueeze_4089 = None
    mul_4466: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1241, unsqueeze_4087);  sub_1241 = unsqueeze_4087 = None
    sub_1243: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(where_194, mul_4466);  where_194 = mul_4466 = None
    sub_1244: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1243, unsqueeze_4084);  sub_1243 = unsqueeze_4084 = None
    mul_4467: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1244, unsqueeze_4090);  sub_1244 = unsqueeze_4090 = None
    mul_4468: "f32[18]" = torch.ops.aten.mul.Tensor(sum_461, squeeze_286);  sum_461 = squeeze_286 = None
    convolution_backward_229 = torch.ops.aten.convolution_backward.default(mul_4467, relu_70, primals_286, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4467 = primals_286 = None
    getitem_1337: "f32[8, 18, 56, 56]" = convolution_backward_229[0]
    getitem_1338: "f32[18, 18, 3, 3]" = convolution_backward_229[1];  convolution_backward_229 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_195: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_88, 0);  relu_88 = None
    where_195: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_195, full_default, add_2046);  le_195 = add_2046 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_24: "f32[8, 36, 14, 14]" = torch.ops.aten._unsafe_index_put.default(full_default_25, [None, None, unsqueeze_259, convert_element_type_20], where_195, True)
    sum_462: "f32[36]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_24, [0, 2, 3])
    sub_1245: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_94, unsqueeze_4093);  convolution_94 = unsqueeze_4093 = None
    mul_4469: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_24, sub_1245)
    sum_463: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4469, [0, 2, 3]);  mul_4469 = None
    mul_4470: "f32[36]" = torch.ops.aten.mul.Tensor(sum_462, 0.0006377551020408163)
    unsqueeze_4094: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4470, 0);  mul_4470 = None
    unsqueeze_4095: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4094, 2);  unsqueeze_4094 = None
    unsqueeze_4096: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4095, 3);  unsqueeze_4095 = None
    mul_4471: "f32[36]" = torch.ops.aten.mul.Tensor(sum_463, 0.0006377551020408163)
    mul_4472: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_283, squeeze_283)
    mul_4473: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4471, mul_4472);  mul_4471 = mul_4472 = None
    unsqueeze_4097: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4473, 0);  mul_4473 = None
    unsqueeze_4098: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4097, 2);  unsqueeze_4097 = None
    unsqueeze_4099: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4098, 3);  unsqueeze_4098 = None
    mul_4474: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_283, primals_284);  primals_284 = None
    unsqueeze_4100: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4474, 0);  mul_4474 = None
    unsqueeze_4101: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4100, 2);  unsqueeze_4100 = None
    unsqueeze_4102: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4101, 3);  unsqueeze_4101 = None
    mul_4475: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1245, unsqueeze_4099);  sub_1245 = unsqueeze_4099 = None
    sub_1247: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_24, mul_4475);  _unsafe_index_put_24 = mul_4475 = None
    sub_1248: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1247, unsqueeze_4096);  sub_1247 = unsqueeze_4096 = None
    mul_4476: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1248, unsqueeze_4102);  sub_1248 = unsqueeze_4102 = None
    mul_4477: "f32[36]" = torch.ops.aten.mul.Tensor(sum_463, squeeze_283);  sum_463 = squeeze_283 = None
    convolution_backward_230 = torch.ops.aten.convolution_backward.default(mul_4476, relu_86, primals_283, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4476 = primals_283 = None
    getitem_1340: "f32[8, 72, 14, 14]" = convolution_backward_230[0]
    getitem_1341: "f32[36, 72, 1, 1]" = convolution_backward_230[1];  convolution_backward_230 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_2051: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_193, getitem_1340);  where_193 = getitem_1340 = None
    add_2052: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(getitem_1331, where_195);  getitem_1331 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sum_464: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_195, [0, 2, 3])
    sub_1249: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_93, unsqueeze_4105);  convolution_93 = unsqueeze_4105 = None
    mul_4478: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_195, sub_1249)
    sum_465: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4478, [0, 2, 3]);  mul_4478 = None
    mul_4479: "f32[36]" = torch.ops.aten.mul.Tensor(sum_464, 0.00015943877551020407)
    unsqueeze_4106: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4479, 0);  mul_4479 = None
    unsqueeze_4107: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4106, 2);  unsqueeze_4106 = None
    unsqueeze_4108: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4107, 3);  unsqueeze_4107 = None
    mul_4480: "f32[36]" = torch.ops.aten.mul.Tensor(sum_465, 0.00015943877551020407)
    mul_4481: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_280, squeeze_280)
    mul_4482: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4480, mul_4481);  mul_4480 = mul_4481 = None
    unsqueeze_4109: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4482, 0);  mul_4482 = None
    unsqueeze_4110: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4109, 2);  unsqueeze_4109 = None
    unsqueeze_4111: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4110, 3);  unsqueeze_4110 = None
    mul_4483: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_280, primals_281);  primals_281 = None
    unsqueeze_4112: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4483, 0);  mul_4483 = None
    unsqueeze_4113: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4112, 2);  unsqueeze_4112 = None
    unsqueeze_4114: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4113, 3);  unsqueeze_4113 = None
    mul_4484: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1249, unsqueeze_4111);  sub_1249 = unsqueeze_4111 = None
    sub_1251: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_195, mul_4484);  where_195 = mul_4484 = None
    sub_1252: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1251, unsqueeze_4108);  sub_1251 = unsqueeze_4108 = None
    mul_4485: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1252, unsqueeze_4114);  sub_1252 = unsqueeze_4114 = None
    mul_4486: "f32[36]" = torch.ops.aten.mul.Tensor(sum_465, squeeze_280);  sum_465 = squeeze_280 = None
    convolution_backward_231 = torch.ops.aten.convolution_backward.default(mul_4485, relu_70, primals_280, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4485 = primals_280 = None
    getitem_1343: "f32[8, 18, 56, 56]" = convolution_backward_231[0]
    getitem_1344: "f32[36, 18, 3, 3]" = convolution_backward_231[1];  convolution_backward_231 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    add_2053: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(getitem_1337, getitem_1343);  getitem_1337 = getitem_1343 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_196: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_87, 0);  relu_87 = None
    where_196: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_196, full_default, add_2050);  le_196 = add_2050 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_25: "f32[8, 18, 14, 14]" = torch.ops.aten._unsafe_index_put.default(full_default_28, [None, None, unsqueeze_250, convert_element_type_14], where_196, True)
    sum_466: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_25, [0, 2, 3])
    sub_1253: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_92, unsqueeze_4117);  convolution_92 = unsqueeze_4117 = None
    mul_4487: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_25, sub_1253)
    sum_467: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4487, [0, 2, 3]);  mul_4487 = None
    mul_4488: "f32[18]" = torch.ops.aten.mul.Tensor(sum_466, 0.0006377551020408163)
    unsqueeze_4118: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4488, 0);  mul_4488 = None
    unsqueeze_4119: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4118, 2);  unsqueeze_4118 = None
    unsqueeze_4120: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4119, 3);  unsqueeze_4119 = None
    mul_4489: "f32[18]" = torch.ops.aten.mul.Tensor(sum_467, 0.0006377551020408163)
    mul_4490: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_277, squeeze_277)
    mul_4491: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4489, mul_4490);  mul_4489 = mul_4490 = None
    unsqueeze_4121: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4491, 0);  mul_4491 = None
    unsqueeze_4122: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4121, 2);  unsqueeze_4121 = None
    unsqueeze_4123: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4122, 3);  unsqueeze_4122 = None
    mul_4492: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_277, primals_278);  primals_278 = None
    unsqueeze_4124: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4492, 0);  mul_4492 = None
    unsqueeze_4125: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4124, 2);  unsqueeze_4124 = None
    unsqueeze_4126: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4125, 3);  unsqueeze_4125 = None
    mul_4493: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1253, unsqueeze_4123);  sub_1253 = unsqueeze_4123 = None
    sub_1255: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_25, mul_4493);  _unsafe_index_put_25 = mul_4493 = None
    sub_1256: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1255, unsqueeze_4120);  sub_1255 = unsqueeze_4120 = None
    mul_4494: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1256, unsqueeze_4126);  sub_1256 = unsqueeze_4126 = None
    mul_4495: "f32[18]" = torch.ops.aten.mul.Tensor(sum_467, squeeze_277);  sum_467 = squeeze_277 = None
    convolution_backward_232 = torch.ops.aten.convolution_backward.default(mul_4494, relu_86, primals_277, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4494 = primals_277 = None
    getitem_1346: "f32[8, 72, 14, 14]" = convolution_backward_232[0]
    getitem_1347: "f32[18, 72, 1, 1]" = convolution_backward_232[1];  convolution_backward_232 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_2054: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(add_2051, getitem_1346);  add_2051 = getitem_1346 = None
    add_2055: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(add_2053, where_196);  add_2053 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_26: "f32[8, 18, 28, 28]" = torch.ops.aten._unsafe_index_put.default(full_default_29, [None, None, unsqueeze_136, convert_element_type_2], where_196, True);  where_196 = None
    sum_468: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_26, [0, 2, 3])
    sub_1257: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_91, unsqueeze_4129);  convolution_91 = unsqueeze_4129 = None
    mul_4496: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_26, sub_1257)
    sum_469: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4496, [0, 2, 3]);  mul_4496 = None
    mul_4497: "f32[18]" = torch.ops.aten.mul.Tensor(sum_468, 0.00015943877551020407)
    unsqueeze_4130: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4497, 0);  mul_4497 = None
    unsqueeze_4131: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4130, 2);  unsqueeze_4130 = None
    unsqueeze_4132: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4131, 3);  unsqueeze_4131 = None
    mul_4498: "f32[18]" = torch.ops.aten.mul.Tensor(sum_469, 0.00015943877551020407)
    mul_4499: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_274, squeeze_274)
    mul_4500: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4498, mul_4499);  mul_4498 = mul_4499 = None
    unsqueeze_4133: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4500, 0);  mul_4500 = None
    unsqueeze_4134: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4133, 2);  unsqueeze_4133 = None
    unsqueeze_4135: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4134, 3);  unsqueeze_4134 = None
    mul_4501: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_274, primals_275);  primals_275 = None
    unsqueeze_4136: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4501, 0);  mul_4501 = None
    unsqueeze_4137: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4136, 2);  unsqueeze_4136 = None
    unsqueeze_4138: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4137, 3);  unsqueeze_4137 = None
    mul_4502: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1257, unsqueeze_4135);  sub_1257 = unsqueeze_4135 = None
    sub_1259: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_26, mul_4502);  _unsafe_index_put_26 = mul_4502 = None
    sub_1260: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1259, unsqueeze_4132);  sub_1259 = unsqueeze_4132 = None
    mul_4503: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1260, unsqueeze_4138);  sub_1260 = unsqueeze_4138 = None
    mul_4504: "f32[18]" = torch.ops.aten.mul.Tensor(sum_469, squeeze_274);  sum_469 = squeeze_274 = None
    convolution_backward_233 = torch.ops.aten.convolution_backward.default(mul_4503, relu_78, primals_274, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4503 = primals_274 = None
    getitem_1349: "f32[8, 36, 28, 28]" = convolution_backward_233[0]
    getitem_1350: "f32[18, 36, 1, 1]" = convolution_backward_233[1];  convolution_backward_233 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_2056: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(add_2052, getitem_1349);  add_2052 = getitem_1349 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_197: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_86, 0);  relu_86 = None
    where_197: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_197, full_default, add_2054);  le_197 = add_2054 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_470: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_197, [0, 2, 3])
    sub_1261: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_90, unsqueeze_4141);  convolution_90 = unsqueeze_4141 = None
    mul_4505: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_197, sub_1261)
    sum_471: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4505, [0, 2, 3]);  mul_4505 = None
    mul_4506: "f32[72]" = torch.ops.aten.mul.Tensor(sum_470, 0.0006377551020408163)
    unsqueeze_4142: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4506, 0);  mul_4506 = None
    unsqueeze_4143: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4142, 2);  unsqueeze_4142 = None
    unsqueeze_4144: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4143, 3);  unsqueeze_4143 = None
    mul_4507: "f32[72]" = torch.ops.aten.mul.Tensor(sum_471, 0.0006377551020408163)
    mul_4508: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_271, squeeze_271)
    mul_4509: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4507, mul_4508);  mul_4507 = mul_4508 = None
    unsqueeze_4145: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4509, 0);  mul_4509 = None
    unsqueeze_4146: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4145, 2);  unsqueeze_4145 = None
    unsqueeze_4147: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4146, 3);  unsqueeze_4146 = None
    mul_4510: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_271, primals_272);  primals_272 = None
    unsqueeze_4148: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4510, 0);  mul_4510 = None
    unsqueeze_4149: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4148, 2);  unsqueeze_4148 = None
    unsqueeze_4150: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4149, 3);  unsqueeze_4149 = None
    mul_4511: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1261, unsqueeze_4147);  sub_1261 = unsqueeze_4147 = None
    sub_1263: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_197, mul_4511);  mul_4511 = None
    sub_1264: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1263, unsqueeze_4144);  sub_1263 = unsqueeze_4144 = None
    mul_4512: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1264, unsqueeze_4150);  sub_1264 = unsqueeze_4150 = None
    mul_4513: "f32[72]" = torch.ops.aten.mul.Tensor(sum_471, squeeze_271);  sum_471 = squeeze_271 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_234 = torch.ops.aten.convolution_backward.default(mul_4512, relu_85, primals_271, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4512 = primals_271 = None
    getitem_1352: "f32[8, 72, 14, 14]" = convolution_backward_234[0]
    getitem_1353: "f32[72, 72, 3, 3]" = convolution_backward_234[1];  convolution_backward_234 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_198: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_85, 0);  relu_85 = None
    where_198: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_198, full_default, getitem_1352);  le_198 = getitem_1352 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_472: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_198, [0, 2, 3])
    sub_1265: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_89, unsqueeze_4153);  convolution_89 = unsqueeze_4153 = None
    mul_4514: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_198, sub_1265)
    sum_473: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4514, [0, 2, 3]);  mul_4514 = None
    mul_4515: "f32[72]" = torch.ops.aten.mul.Tensor(sum_472, 0.0006377551020408163)
    unsqueeze_4154: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4515, 0);  mul_4515 = None
    unsqueeze_4155: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4154, 2);  unsqueeze_4154 = None
    unsqueeze_4156: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4155, 3);  unsqueeze_4155 = None
    mul_4516: "f32[72]" = torch.ops.aten.mul.Tensor(sum_473, 0.0006377551020408163)
    mul_4517: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_268, squeeze_268)
    mul_4518: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4516, mul_4517);  mul_4516 = mul_4517 = None
    unsqueeze_4157: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4518, 0);  mul_4518 = None
    unsqueeze_4158: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4157, 2);  unsqueeze_4157 = None
    unsqueeze_4159: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4158, 3);  unsqueeze_4158 = None
    mul_4519: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_268, primals_269);  primals_269 = None
    unsqueeze_4160: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4519, 0);  mul_4519 = None
    unsqueeze_4161: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4160, 2);  unsqueeze_4160 = None
    unsqueeze_4162: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4161, 3);  unsqueeze_4161 = None
    mul_4520: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1265, unsqueeze_4159);  sub_1265 = unsqueeze_4159 = None
    sub_1267: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_198, mul_4520);  where_198 = mul_4520 = None
    sub_1268: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1267, unsqueeze_4156);  sub_1267 = unsqueeze_4156 = None
    mul_4521: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1268, unsqueeze_4162);  sub_1268 = unsqueeze_4162 = None
    mul_4522: "f32[72]" = torch.ops.aten.mul.Tensor(sum_473, squeeze_268);  sum_473 = squeeze_268 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_235 = torch.ops.aten.convolution_backward.default(mul_4521, relu_84, primals_268, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4521 = primals_268 = None
    getitem_1355: "f32[8, 72, 14, 14]" = convolution_backward_235[0]
    getitem_1356: "f32[72, 72, 3, 3]" = convolution_backward_235[1];  convolution_backward_235 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2057: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_197, getitem_1355);  where_197 = getitem_1355 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_199: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_84, 0);  relu_84 = None
    where_199: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_199, full_default, add_2057);  le_199 = add_2057 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_474: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_199, [0, 2, 3])
    sub_1269: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_88, unsqueeze_4165);  convolution_88 = unsqueeze_4165 = None
    mul_4523: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_199, sub_1269)
    sum_475: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4523, [0, 2, 3]);  mul_4523 = None
    mul_4524: "f32[72]" = torch.ops.aten.mul.Tensor(sum_474, 0.0006377551020408163)
    unsqueeze_4166: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4524, 0);  mul_4524 = None
    unsqueeze_4167: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4166, 2);  unsqueeze_4166 = None
    unsqueeze_4168: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4167, 3);  unsqueeze_4167 = None
    mul_4525: "f32[72]" = torch.ops.aten.mul.Tensor(sum_475, 0.0006377551020408163)
    mul_4526: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_265, squeeze_265)
    mul_4527: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4525, mul_4526);  mul_4525 = mul_4526 = None
    unsqueeze_4169: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4527, 0);  mul_4527 = None
    unsqueeze_4170: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4169, 2);  unsqueeze_4169 = None
    unsqueeze_4171: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4170, 3);  unsqueeze_4170 = None
    mul_4528: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_265, primals_266);  primals_266 = None
    unsqueeze_4172: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4528, 0);  mul_4528 = None
    unsqueeze_4173: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4172, 2);  unsqueeze_4172 = None
    unsqueeze_4174: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4173, 3);  unsqueeze_4173 = None
    mul_4529: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1269, unsqueeze_4171);  sub_1269 = unsqueeze_4171 = None
    sub_1271: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_199, mul_4529);  mul_4529 = None
    sub_1272: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1271, unsqueeze_4168);  sub_1271 = unsqueeze_4168 = None
    mul_4530: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1272, unsqueeze_4174);  sub_1272 = unsqueeze_4174 = None
    mul_4531: "f32[72]" = torch.ops.aten.mul.Tensor(sum_475, squeeze_265);  sum_475 = squeeze_265 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_236 = torch.ops.aten.convolution_backward.default(mul_4530, relu_83, primals_265, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4530 = primals_265 = None
    getitem_1358: "f32[8, 72, 14, 14]" = convolution_backward_236[0]
    getitem_1359: "f32[72, 72, 3, 3]" = convolution_backward_236[1];  convolution_backward_236 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_200: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_83, 0);  relu_83 = None
    where_200: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_200, full_default, getitem_1358);  le_200 = getitem_1358 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_476: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_200, [0, 2, 3])
    sub_1273: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_87, unsqueeze_4177);  convolution_87 = unsqueeze_4177 = None
    mul_4532: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_200, sub_1273)
    sum_477: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4532, [0, 2, 3]);  mul_4532 = None
    mul_4533: "f32[72]" = torch.ops.aten.mul.Tensor(sum_476, 0.0006377551020408163)
    unsqueeze_4178: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4533, 0);  mul_4533 = None
    unsqueeze_4179: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4178, 2);  unsqueeze_4178 = None
    unsqueeze_4180: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4179, 3);  unsqueeze_4179 = None
    mul_4534: "f32[72]" = torch.ops.aten.mul.Tensor(sum_477, 0.0006377551020408163)
    mul_4535: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_262, squeeze_262)
    mul_4536: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4534, mul_4535);  mul_4534 = mul_4535 = None
    unsqueeze_4181: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4536, 0);  mul_4536 = None
    unsqueeze_4182: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4181, 2);  unsqueeze_4181 = None
    unsqueeze_4183: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4182, 3);  unsqueeze_4182 = None
    mul_4537: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_262, primals_263);  primals_263 = None
    unsqueeze_4184: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4537, 0);  mul_4537 = None
    unsqueeze_4185: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4184, 2);  unsqueeze_4184 = None
    unsqueeze_4186: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4185, 3);  unsqueeze_4185 = None
    mul_4538: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1273, unsqueeze_4183);  sub_1273 = unsqueeze_4183 = None
    sub_1275: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_200, mul_4538);  where_200 = mul_4538 = None
    sub_1276: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1275, unsqueeze_4180);  sub_1275 = unsqueeze_4180 = None
    mul_4539: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1276, unsqueeze_4186);  sub_1276 = unsqueeze_4186 = None
    mul_4540: "f32[72]" = torch.ops.aten.mul.Tensor(sum_477, squeeze_262);  sum_477 = squeeze_262 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_237 = torch.ops.aten.convolution_backward.default(mul_4539, relu_82, primals_262, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4539 = primals_262 = None
    getitem_1361: "f32[8, 72, 14, 14]" = convolution_backward_237[0]
    getitem_1362: "f32[72, 72, 3, 3]" = convolution_backward_237[1];  convolution_backward_237 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2058: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_199, getitem_1361);  where_199 = getitem_1361 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_201: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_82, 0);  relu_82 = None
    where_201: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_201, full_default, add_2058);  le_201 = add_2058 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_478: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_201, [0, 2, 3])
    sub_1277: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_86, unsqueeze_4189);  convolution_86 = unsqueeze_4189 = None
    mul_4541: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_201, sub_1277)
    sum_479: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4541, [0, 2, 3]);  mul_4541 = None
    mul_4542: "f32[72]" = torch.ops.aten.mul.Tensor(sum_478, 0.0006377551020408163)
    unsqueeze_4190: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4542, 0);  mul_4542 = None
    unsqueeze_4191: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4190, 2);  unsqueeze_4190 = None
    unsqueeze_4192: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4191, 3);  unsqueeze_4191 = None
    mul_4543: "f32[72]" = torch.ops.aten.mul.Tensor(sum_479, 0.0006377551020408163)
    mul_4544: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_259, squeeze_259)
    mul_4545: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4543, mul_4544);  mul_4543 = mul_4544 = None
    unsqueeze_4193: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4545, 0);  mul_4545 = None
    unsqueeze_4194: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4193, 2);  unsqueeze_4193 = None
    unsqueeze_4195: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4194, 3);  unsqueeze_4194 = None
    mul_4546: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_259, primals_260);  primals_260 = None
    unsqueeze_4196: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4546, 0);  mul_4546 = None
    unsqueeze_4197: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4196, 2);  unsqueeze_4196 = None
    unsqueeze_4198: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4197, 3);  unsqueeze_4197 = None
    mul_4547: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1277, unsqueeze_4195);  sub_1277 = unsqueeze_4195 = None
    sub_1279: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_201, mul_4547);  mul_4547 = None
    sub_1280: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1279, unsqueeze_4192);  sub_1279 = unsqueeze_4192 = None
    mul_4548: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1280, unsqueeze_4198);  sub_1280 = unsqueeze_4198 = None
    mul_4549: "f32[72]" = torch.ops.aten.mul.Tensor(sum_479, squeeze_259);  sum_479 = squeeze_259 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_238 = torch.ops.aten.convolution_backward.default(mul_4548, relu_81, primals_259, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4548 = primals_259 = None
    getitem_1364: "f32[8, 72, 14, 14]" = convolution_backward_238[0]
    getitem_1365: "f32[72, 72, 3, 3]" = convolution_backward_238[1];  convolution_backward_238 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_202: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_81, 0);  relu_81 = None
    where_202: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_202, full_default, getitem_1364);  le_202 = getitem_1364 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_480: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_202, [0, 2, 3])
    sub_1281: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_85, unsqueeze_4201);  convolution_85 = unsqueeze_4201 = None
    mul_4550: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_202, sub_1281)
    sum_481: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4550, [0, 2, 3]);  mul_4550 = None
    mul_4551: "f32[72]" = torch.ops.aten.mul.Tensor(sum_480, 0.0006377551020408163)
    unsqueeze_4202: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4551, 0);  mul_4551 = None
    unsqueeze_4203: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4202, 2);  unsqueeze_4202 = None
    unsqueeze_4204: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4203, 3);  unsqueeze_4203 = None
    mul_4552: "f32[72]" = torch.ops.aten.mul.Tensor(sum_481, 0.0006377551020408163)
    mul_4553: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_256, squeeze_256)
    mul_4554: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4552, mul_4553);  mul_4552 = mul_4553 = None
    unsqueeze_4205: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4554, 0);  mul_4554 = None
    unsqueeze_4206: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4205, 2);  unsqueeze_4205 = None
    unsqueeze_4207: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4206, 3);  unsqueeze_4206 = None
    mul_4555: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_256, primals_257);  primals_257 = None
    unsqueeze_4208: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4555, 0);  mul_4555 = None
    unsqueeze_4209: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4208, 2);  unsqueeze_4208 = None
    unsqueeze_4210: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4209, 3);  unsqueeze_4209 = None
    mul_4556: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1281, unsqueeze_4207);  sub_1281 = unsqueeze_4207 = None
    sub_1283: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_202, mul_4556);  where_202 = mul_4556 = None
    sub_1284: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1283, unsqueeze_4204);  sub_1283 = unsqueeze_4204 = None
    mul_4557: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1284, unsqueeze_4210);  sub_1284 = unsqueeze_4210 = None
    mul_4558: "f32[72]" = torch.ops.aten.mul.Tensor(sum_481, squeeze_256);  sum_481 = squeeze_256 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_239 = torch.ops.aten.convolution_backward.default(mul_4557, relu_80, primals_256, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4557 = primals_256 = None
    getitem_1367: "f32[8, 72, 14, 14]" = convolution_backward_239[0]
    getitem_1368: "f32[72, 72, 3, 3]" = convolution_backward_239[1];  convolution_backward_239 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2059: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_201, getitem_1367);  where_201 = getitem_1367 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_203: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_80, 0);  relu_80 = None
    where_203: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_203, full_default, add_2059);  le_203 = add_2059 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_482: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_203, [0, 2, 3])
    sub_1285: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_84, unsqueeze_4213);  convolution_84 = unsqueeze_4213 = None
    mul_4559: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_203, sub_1285)
    sum_483: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4559, [0, 2, 3]);  mul_4559 = None
    mul_4560: "f32[72]" = torch.ops.aten.mul.Tensor(sum_482, 0.0006377551020408163)
    unsqueeze_4214: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4560, 0);  mul_4560 = None
    unsqueeze_4215: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4214, 2);  unsqueeze_4214 = None
    unsqueeze_4216: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4215, 3);  unsqueeze_4215 = None
    mul_4561: "f32[72]" = torch.ops.aten.mul.Tensor(sum_483, 0.0006377551020408163)
    mul_4562: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_253, squeeze_253)
    mul_4563: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4561, mul_4562);  mul_4561 = mul_4562 = None
    unsqueeze_4217: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4563, 0);  mul_4563 = None
    unsqueeze_4218: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4217, 2);  unsqueeze_4217 = None
    unsqueeze_4219: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4218, 3);  unsqueeze_4218 = None
    mul_4564: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_253, primals_254);  primals_254 = None
    unsqueeze_4220: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4564, 0);  mul_4564 = None
    unsqueeze_4221: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4220, 2);  unsqueeze_4220 = None
    unsqueeze_4222: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4221, 3);  unsqueeze_4221 = None
    mul_4565: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1285, unsqueeze_4219);  sub_1285 = unsqueeze_4219 = None
    sub_1287: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_203, mul_4565);  mul_4565 = None
    sub_1288: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1287, unsqueeze_4216);  sub_1287 = unsqueeze_4216 = None
    mul_4566: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1288, unsqueeze_4222);  sub_1288 = unsqueeze_4222 = None
    mul_4567: "f32[72]" = torch.ops.aten.mul.Tensor(sum_483, squeeze_253);  sum_483 = squeeze_253 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_240 = torch.ops.aten.convolution_backward.default(mul_4566, relu_79, primals_253, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4566 = primals_253 = None
    getitem_1370: "f32[8, 72, 14, 14]" = convolution_backward_240[0]
    getitem_1371: "f32[72, 72, 3, 3]" = convolution_backward_240[1];  convolution_backward_240 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_204: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_79, 0);  relu_79 = None
    where_204: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_204, full_default, getitem_1370);  le_204 = getitem_1370 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_484: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_204, [0, 2, 3])
    sub_1289: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_83, unsqueeze_4225);  convolution_83 = unsqueeze_4225 = None
    mul_4568: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_204, sub_1289)
    sum_485: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4568, [0, 2, 3]);  mul_4568 = None
    mul_4569: "f32[72]" = torch.ops.aten.mul.Tensor(sum_484, 0.0006377551020408163)
    unsqueeze_4226: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4569, 0);  mul_4569 = None
    unsqueeze_4227: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4226, 2);  unsqueeze_4226 = None
    unsqueeze_4228: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4227, 3);  unsqueeze_4227 = None
    mul_4570: "f32[72]" = torch.ops.aten.mul.Tensor(sum_485, 0.0006377551020408163)
    mul_4571: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_250, squeeze_250)
    mul_4572: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4570, mul_4571);  mul_4570 = mul_4571 = None
    unsqueeze_4229: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4572, 0);  mul_4572 = None
    unsqueeze_4230: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4229, 2);  unsqueeze_4229 = None
    unsqueeze_4231: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4230, 3);  unsqueeze_4230 = None
    mul_4573: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_250, primals_251);  primals_251 = None
    unsqueeze_4232: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4573, 0);  mul_4573 = None
    unsqueeze_4233: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4232, 2);  unsqueeze_4232 = None
    unsqueeze_4234: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4233, 3);  unsqueeze_4233 = None
    mul_4574: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1289, unsqueeze_4231);  sub_1289 = unsqueeze_4231 = None
    sub_1291: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_204, mul_4574);  where_204 = mul_4574 = None
    sub_1292: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1291, unsqueeze_4228);  sub_1291 = unsqueeze_4228 = None
    mul_4575: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1292, unsqueeze_4234);  sub_1292 = unsqueeze_4234 = None
    mul_4576: "f32[72]" = torch.ops.aten.mul.Tensor(sum_485, squeeze_250);  sum_485 = squeeze_250 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_241 = torch.ops.aten.convolution_backward.default(mul_4575, relu_62, primals_250, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4575 = primals_250 = None
    getitem_1373: "f32[8, 72, 14, 14]" = convolution_backward_241[0]
    getitem_1374: "f32[72, 72, 3, 3]" = convolution_backward_241[1];  convolution_backward_241 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2060: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_203, getitem_1373);  where_203 = getitem_1373 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_205: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_78, 0);  relu_78 = None
    where_205: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_205, full_default, add_2056);  le_205 = add_2056 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_486: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_205, [0, 2, 3])
    sub_1293: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_82, unsqueeze_4237);  convolution_82 = unsqueeze_4237 = None
    mul_4577: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_205, sub_1293)
    sum_487: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4577, [0, 2, 3]);  mul_4577 = None
    mul_4578: "f32[36]" = torch.ops.aten.mul.Tensor(sum_486, 0.00015943877551020407)
    unsqueeze_4238: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4578, 0);  mul_4578 = None
    unsqueeze_4239: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4238, 2);  unsqueeze_4238 = None
    unsqueeze_4240: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4239, 3);  unsqueeze_4239 = None
    mul_4579: "f32[36]" = torch.ops.aten.mul.Tensor(sum_487, 0.00015943877551020407)
    mul_4580: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_247, squeeze_247)
    mul_4581: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4579, mul_4580);  mul_4579 = mul_4580 = None
    unsqueeze_4241: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4581, 0);  mul_4581 = None
    unsqueeze_4242: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4241, 2);  unsqueeze_4241 = None
    unsqueeze_4243: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4242, 3);  unsqueeze_4242 = None
    mul_4582: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_247, primals_248);  primals_248 = None
    unsqueeze_4244: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4582, 0);  mul_4582 = None
    unsqueeze_4245: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4244, 2);  unsqueeze_4244 = None
    unsqueeze_4246: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4245, 3);  unsqueeze_4245 = None
    mul_4583: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1293, unsqueeze_4243);  sub_1293 = unsqueeze_4243 = None
    sub_1295: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_205, mul_4583);  mul_4583 = None
    sub_1296: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1295, unsqueeze_4240);  sub_1295 = unsqueeze_4240 = None
    mul_4584: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1296, unsqueeze_4246);  sub_1296 = unsqueeze_4246 = None
    mul_4585: "f32[36]" = torch.ops.aten.mul.Tensor(sum_487, squeeze_247);  sum_487 = squeeze_247 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_242 = torch.ops.aten.convolution_backward.default(mul_4584, relu_77, primals_247, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4584 = primals_247 = None
    getitem_1376: "f32[8, 36, 28, 28]" = convolution_backward_242[0]
    getitem_1377: "f32[36, 36, 3, 3]" = convolution_backward_242[1];  convolution_backward_242 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_206: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_77, 0);  relu_77 = None
    where_206: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_206, full_default, getitem_1376);  le_206 = getitem_1376 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_488: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_206, [0, 2, 3])
    sub_1297: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_81, unsqueeze_4249);  convolution_81 = unsqueeze_4249 = None
    mul_4586: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_206, sub_1297)
    sum_489: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4586, [0, 2, 3]);  mul_4586 = None
    mul_4587: "f32[36]" = torch.ops.aten.mul.Tensor(sum_488, 0.00015943877551020407)
    unsqueeze_4250: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4587, 0);  mul_4587 = None
    unsqueeze_4251: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4250, 2);  unsqueeze_4250 = None
    unsqueeze_4252: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4251, 3);  unsqueeze_4251 = None
    mul_4588: "f32[36]" = torch.ops.aten.mul.Tensor(sum_489, 0.00015943877551020407)
    mul_4589: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_244, squeeze_244)
    mul_4590: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4588, mul_4589);  mul_4588 = mul_4589 = None
    unsqueeze_4253: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4590, 0);  mul_4590 = None
    unsqueeze_4254: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4253, 2);  unsqueeze_4253 = None
    unsqueeze_4255: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4254, 3);  unsqueeze_4254 = None
    mul_4591: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_244, primals_245);  primals_245 = None
    unsqueeze_4256: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4591, 0);  mul_4591 = None
    unsqueeze_4257: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4256, 2);  unsqueeze_4256 = None
    unsqueeze_4258: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4257, 3);  unsqueeze_4257 = None
    mul_4592: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1297, unsqueeze_4255);  sub_1297 = unsqueeze_4255 = None
    sub_1299: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_206, mul_4592);  where_206 = mul_4592 = None
    sub_1300: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1299, unsqueeze_4252);  sub_1299 = unsqueeze_4252 = None
    mul_4593: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1300, unsqueeze_4258);  sub_1300 = unsqueeze_4258 = None
    mul_4594: "f32[36]" = torch.ops.aten.mul.Tensor(sum_489, squeeze_244);  sum_489 = squeeze_244 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_243 = torch.ops.aten.convolution_backward.default(mul_4593, relu_76, primals_244, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4593 = primals_244 = None
    getitem_1379: "f32[8, 36, 28, 28]" = convolution_backward_243[0]
    getitem_1380: "f32[36, 36, 3, 3]" = convolution_backward_243[1];  convolution_backward_243 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2061: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_205, getitem_1379);  where_205 = getitem_1379 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_207: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_76, 0);  relu_76 = None
    where_207: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_207, full_default, add_2061);  le_207 = add_2061 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_490: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_207, [0, 2, 3])
    sub_1301: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_80, unsqueeze_4261);  convolution_80 = unsqueeze_4261 = None
    mul_4595: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_207, sub_1301)
    sum_491: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4595, [0, 2, 3]);  mul_4595 = None
    mul_4596: "f32[36]" = torch.ops.aten.mul.Tensor(sum_490, 0.00015943877551020407)
    unsqueeze_4262: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4596, 0);  mul_4596 = None
    unsqueeze_4263: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4262, 2);  unsqueeze_4262 = None
    unsqueeze_4264: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4263, 3);  unsqueeze_4263 = None
    mul_4597: "f32[36]" = torch.ops.aten.mul.Tensor(sum_491, 0.00015943877551020407)
    mul_4598: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_241, squeeze_241)
    mul_4599: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4597, mul_4598);  mul_4597 = mul_4598 = None
    unsqueeze_4265: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4599, 0);  mul_4599 = None
    unsqueeze_4266: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4265, 2);  unsqueeze_4265 = None
    unsqueeze_4267: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4266, 3);  unsqueeze_4266 = None
    mul_4600: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_241, primals_242);  primals_242 = None
    unsqueeze_4268: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4600, 0);  mul_4600 = None
    unsqueeze_4269: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4268, 2);  unsqueeze_4268 = None
    unsqueeze_4270: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4269, 3);  unsqueeze_4269 = None
    mul_4601: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1301, unsqueeze_4267);  sub_1301 = unsqueeze_4267 = None
    sub_1303: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_207, mul_4601);  mul_4601 = None
    sub_1304: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1303, unsqueeze_4264);  sub_1303 = unsqueeze_4264 = None
    mul_4602: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1304, unsqueeze_4270);  sub_1304 = unsqueeze_4270 = None
    mul_4603: "f32[36]" = torch.ops.aten.mul.Tensor(sum_491, squeeze_241);  sum_491 = squeeze_241 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_244 = torch.ops.aten.convolution_backward.default(mul_4602, relu_75, primals_241, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4602 = primals_241 = None
    getitem_1382: "f32[8, 36, 28, 28]" = convolution_backward_244[0]
    getitem_1383: "f32[36, 36, 3, 3]" = convolution_backward_244[1];  convolution_backward_244 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_208: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_75, 0);  relu_75 = None
    where_208: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_208, full_default, getitem_1382);  le_208 = getitem_1382 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_492: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_208, [0, 2, 3])
    sub_1305: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_79, unsqueeze_4273);  convolution_79 = unsqueeze_4273 = None
    mul_4604: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_208, sub_1305)
    sum_493: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4604, [0, 2, 3]);  mul_4604 = None
    mul_4605: "f32[36]" = torch.ops.aten.mul.Tensor(sum_492, 0.00015943877551020407)
    unsqueeze_4274: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4605, 0);  mul_4605 = None
    unsqueeze_4275: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4274, 2);  unsqueeze_4274 = None
    unsqueeze_4276: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4275, 3);  unsqueeze_4275 = None
    mul_4606: "f32[36]" = torch.ops.aten.mul.Tensor(sum_493, 0.00015943877551020407)
    mul_4607: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_238, squeeze_238)
    mul_4608: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4606, mul_4607);  mul_4606 = mul_4607 = None
    unsqueeze_4277: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4608, 0);  mul_4608 = None
    unsqueeze_4278: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4277, 2);  unsqueeze_4277 = None
    unsqueeze_4279: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4278, 3);  unsqueeze_4278 = None
    mul_4609: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_238, primals_239);  primals_239 = None
    unsqueeze_4280: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4609, 0);  mul_4609 = None
    unsqueeze_4281: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4280, 2);  unsqueeze_4280 = None
    unsqueeze_4282: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4281, 3);  unsqueeze_4281 = None
    mul_4610: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1305, unsqueeze_4279);  sub_1305 = unsqueeze_4279 = None
    sub_1307: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_208, mul_4610);  where_208 = mul_4610 = None
    sub_1308: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1307, unsqueeze_4276);  sub_1307 = unsqueeze_4276 = None
    mul_4611: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1308, unsqueeze_4282);  sub_1308 = unsqueeze_4282 = None
    mul_4612: "f32[36]" = torch.ops.aten.mul.Tensor(sum_493, squeeze_238);  sum_493 = squeeze_238 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_245 = torch.ops.aten.convolution_backward.default(mul_4611, relu_74, primals_238, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4611 = primals_238 = None
    getitem_1385: "f32[8, 36, 28, 28]" = convolution_backward_245[0]
    getitem_1386: "f32[36, 36, 3, 3]" = convolution_backward_245[1];  convolution_backward_245 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2062: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_207, getitem_1385);  where_207 = getitem_1385 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_209: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_74, 0);  relu_74 = None
    where_209: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_209, full_default, add_2062);  le_209 = add_2062 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_494: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_209, [0, 2, 3])
    sub_1309: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_78, unsqueeze_4285);  convolution_78 = unsqueeze_4285 = None
    mul_4613: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_209, sub_1309)
    sum_495: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4613, [0, 2, 3]);  mul_4613 = None
    mul_4614: "f32[36]" = torch.ops.aten.mul.Tensor(sum_494, 0.00015943877551020407)
    unsqueeze_4286: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4614, 0);  mul_4614 = None
    unsqueeze_4287: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4286, 2);  unsqueeze_4286 = None
    unsqueeze_4288: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4287, 3);  unsqueeze_4287 = None
    mul_4615: "f32[36]" = torch.ops.aten.mul.Tensor(sum_495, 0.00015943877551020407)
    mul_4616: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_235, squeeze_235)
    mul_4617: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4615, mul_4616);  mul_4615 = mul_4616 = None
    unsqueeze_4289: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4617, 0);  mul_4617 = None
    unsqueeze_4290: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4289, 2);  unsqueeze_4289 = None
    unsqueeze_4291: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4290, 3);  unsqueeze_4290 = None
    mul_4618: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_235, primals_236);  primals_236 = None
    unsqueeze_4292: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4618, 0);  mul_4618 = None
    unsqueeze_4293: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4292, 2);  unsqueeze_4292 = None
    unsqueeze_4294: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4293, 3);  unsqueeze_4293 = None
    mul_4619: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1309, unsqueeze_4291);  sub_1309 = unsqueeze_4291 = None
    sub_1311: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_209, mul_4619);  mul_4619 = None
    sub_1312: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1311, unsqueeze_4288);  sub_1311 = unsqueeze_4288 = None
    mul_4620: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1312, unsqueeze_4294);  sub_1312 = unsqueeze_4294 = None
    mul_4621: "f32[36]" = torch.ops.aten.mul.Tensor(sum_495, squeeze_235);  sum_495 = squeeze_235 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_246 = torch.ops.aten.convolution_backward.default(mul_4620, relu_73, primals_235, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4620 = primals_235 = None
    getitem_1388: "f32[8, 36, 28, 28]" = convolution_backward_246[0]
    getitem_1389: "f32[36, 36, 3, 3]" = convolution_backward_246[1];  convolution_backward_246 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_210: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_73, 0);  relu_73 = None
    where_210: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_210, full_default, getitem_1388);  le_210 = getitem_1388 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_496: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_210, [0, 2, 3])
    sub_1313: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_77, unsqueeze_4297);  convolution_77 = unsqueeze_4297 = None
    mul_4622: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_210, sub_1313)
    sum_497: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4622, [0, 2, 3]);  mul_4622 = None
    mul_4623: "f32[36]" = torch.ops.aten.mul.Tensor(sum_496, 0.00015943877551020407)
    unsqueeze_4298: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4623, 0);  mul_4623 = None
    unsqueeze_4299: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4298, 2);  unsqueeze_4298 = None
    unsqueeze_4300: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4299, 3);  unsqueeze_4299 = None
    mul_4624: "f32[36]" = torch.ops.aten.mul.Tensor(sum_497, 0.00015943877551020407)
    mul_4625: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_232, squeeze_232)
    mul_4626: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4624, mul_4625);  mul_4624 = mul_4625 = None
    unsqueeze_4301: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4626, 0);  mul_4626 = None
    unsqueeze_4302: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4301, 2);  unsqueeze_4301 = None
    unsqueeze_4303: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4302, 3);  unsqueeze_4302 = None
    mul_4627: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_232, primals_233);  primals_233 = None
    unsqueeze_4304: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4627, 0);  mul_4627 = None
    unsqueeze_4305: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4304, 2);  unsqueeze_4304 = None
    unsqueeze_4306: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4305, 3);  unsqueeze_4305 = None
    mul_4628: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1313, unsqueeze_4303);  sub_1313 = unsqueeze_4303 = None
    sub_1315: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_210, mul_4628);  where_210 = mul_4628 = None
    sub_1316: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1315, unsqueeze_4300);  sub_1315 = unsqueeze_4300 = None
    mul_4629: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1316, unsqueeze_4306);  sub_1316 = unsqueeze_4306 = None
    mul_4630: "f32[36]" = torch.ops.aten.mul.Tensor(sum_497, squeeze_232);  sum_497 = squeeze_232 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_247 = torch.ops.aten.convolution_backward.default(mul_4629, relu_72, primals_232, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4629 = primals_232 = None
    getitem_1391: "f32[8, 36, 28, 28]" = convolution_backward_247[0]
    getitem_1392: "f32[36, 36, 3, 3]" = convolution_backward_247[1];  convolution_backward_247 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2063: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_209, getitem_1391);  where_209 = getitem_1391 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_211: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_72, 0);  relu_72 = None
    where_211: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_211, full_default, add_2063);  le_211 = add_2063 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_498: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_211, [0, 2, 3])
    sub_1317: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_76, unsqueeze_4309);  convolution_76 = unsqueeze_4309 = None
    mul_4631: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_211, sub_1317)
    sum_499: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4631, [0, 2, 3]);  mul_4631 = None
    mul_4632: "f32[36]" = torch.ops.aten.mul.Tensor(sum_498, 0.00015943877551020407)
    unsqueeze_4310: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4632, 0);  mul_4632 = None
    unsqueeze_4311: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4310, 2);  unsqueeze_4310 = None
    unsqueeze_4312: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4311, 3);  unsqueeze_4311 = None
    mul_4633: "f32[36]" = torch.ops.aten.mul.Tensor(sum_499, 0.00015943877551020407)
    mul_4634: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_229, squeeze_229)
    mul_4635: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4633, mul_4634);  mul_4633 = mul_4634 = None
    unsqueeze_4313: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4635, 0);  mul_4635 = None
    unsqueeze_4314: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4313, 2);  unsqueeze_4313 = None
    unsqueeze_4315: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4314, 3);  unsqueeze_4314 = None
    mul_4636: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_229, primals_230);  primals_230 = None
    unsqueeze_4316: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4636, 0);  mul_4636 = None
    unsqueeze_4317: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4316, 2);  unsqueeze_4316 = None
    unsqueeze_4318: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4317, 3);  unsqueeze_4317 = None
    mul_4637: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1317, unsqueeze_4315);  sub_1317 = unsqueeze_4315 = None
    sub_1319: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_211, mul_4637);  mul_4637 = None
    sub_1320: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1319, unsqueeze_4312);  sub_1319 = unsqueeze_4312 = None
    mul_4638: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1320, unsqueeze_4318);  sub_1320 = unsqueeze_4318 = None
    mul_4639: "f32[36]" = torch.ops.aten.mul.Tensor(sum_499, squeeze_229);  sum_499 = squeeze_229 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_248 = torch.ops.aten.convolution_backward.default(mul_4638, relu_71, primals_229, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4638 = primals_229 = None
    getitem_1394: "f32[8, 36, 28, 28]" = convolution_backward_248[0]
    getitem_1395: "f32[36, 36, 3, 3]" = convolution_backward_248[1];  convolution_backward_248 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_212: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_71, 0);  relu_71 = None
    where_212: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_212, full_default, getitem_1394);  le_212 = getitem_1394 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_500: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_212, [0, 2, 3])
    sub_1321: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_75, unsqueeze_4321);  convolution_75 = unsqueeze_4321 = None
    mul_4640: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_212, sub_1321)
    sum_501: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4640, [0, 2, 3]);  mul_4640 = None
    mul_4641: "f32[36]" = torch.ops.aten.mul.Tensor(sum_500, 0.00015943877551020407)
    unsqueeze_4322: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4641, 0);  mul_4641 = None
    unsqueeze_4323: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4322, 2);  unsqueeze_4322 = None
    unsqueeze_4324: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4323, 3);  unsqueeze_4323 = None
    mul_4642: "f32[36]" = torch.ops.aten.mul.Tensor(sum_501, 0.00015943877551020407)
    mul_4643: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_226, squeeze_226)
    mul_4644: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4642, mul_4643);  mul_4642 = mul_4643 = None
    unsqueeze_4325: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4644, 0);  mul_4644 = None
    unsqueeze_4326: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4325, 2);  unsqueeze_4325 = None
    unsqueeze_4327: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4326, 3);  unsqueeze_4326 = None
    mul_4645: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_226, primals_227);  primals_227 = None
    unsqueeze_4328: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4645, 0);  mul_4645 = None
    unsqueeze_4329: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4328, 2);  unsqueeze_4328 = None
    unsqueeze_4330: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4329, 3);  unsqueeze_4329 = None
    mul_4646: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1321, unsqueeze_4327);  sub_1321 = unsqueeze_4327 = None
    sub_1323: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_212, mul_4646);  where_212 = mul_4646 = None
    sub_1324: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1323, unsqueeze_4324);  sub_1323 = unsqueeze_4324 = None
    mul_4647: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1324, unsqueeze_4330);  sub_1324 = unsqueeze_4330 = None
    mul_4648: "f32[36]" = torch.ops.aten.mul.Tensor(sum_501, squeeze_226);  sum_501 = squeeze_226 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_249 = torch.ops.aten.convolution_backward.default(mul_4647, relu_60, primals_226, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4647 = primals_226 = None
    getitem_1397: "f32[8, 36, 28, 28]" = convolution_backward_249[0]
    getitem_1398: "f32[36, 36, 3, 3]" = convolution_backward_249[1];  convolution_backward_249 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2064: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_211, getitem_1397);  where_211 = getitem_1397 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_213: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_70, 0);  relu_70 = None
    where_213: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_213, full_default, add_2055);  le_213 = add_2055 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_502: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_213, [0, 2, 3])
    sub_1325: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_74, unsqueeze_4333);  convolution_74 = unsqueeze_4333 = None
    mul_4649: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_213, sub_1325)
    sum_503: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4649, [0, 2, 3]);  mul_4649 = None
    mul_4650: "f32[18]" = torch.ops.aten.mul.Tensor(sum_502, 3.985969387755102e-05)
    unsqueeze_4334: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4650, 0);  mul_4650 = None
    unsqueeze_4335: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4334, 2);  unsqueeze_4334 = None
    unsqueeze_4336: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4335, 3);  unsqueeze_4335 = None
    mul_4651: "f32[18]" = torch.ops.aten.mul.Tensor(sum_503, 3.985969387755102e-05)
    mul_4652: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_223, squeeze_223)
    mul_4653: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4651, mul_4652);  mul_4651 = mul_4652 = None
    unsqueeze_4337: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4653, 0);  mul_4653 = None
    unsqueeze_4338: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4337, 2);  unsqueeze_4337 = None
    unsqueeze_4339: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4338, 3);  unsqueeze_4338 = None
    mul_4654: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_223, primals_224);  primals_224 = None
    unsqueeze_4340: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4654, 0);  mul_4654 = None
    unsqueeze_4341: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4340, 2);  unsqueeze_4340 = None
    unsqueeze_4342: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4341, 3);  unsqueeze_4341 = None
    mul_4655: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1325, unsqueeze_4339);  sub_1325 = unsqueeze_4339 = None
    sub_1327: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_213, mul_4655);  mul_4655 = None
    sub_1328: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1327, unsqueeze_4336);  sub_1327 = unsqueeze_4336 = None
    mul_4656: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1328, unsqueeze_4342);  sub_1328 = unsqueeze_4342 = None
    mul_4657: "f32[18]" = torch.ops.aten.mul.Tensor(sum_503, squeeze_223);  sum_503 = squeeze_223 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_250 = torch.ops.aten.convolution_backward.default(mul_4656, relu_69, primals_223, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4656 = primals_223 = None
    getitem_1400: "f32[8, 18, 56, 56]" = convolution_backward_250[0]
    getitem_1401: "f32[18, 18, 3, 3]" = convolution_backward_250[1];  convolution_backward_250 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_214: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_69, 0);  relu_69 = None
    where_214: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_214, full_default, getitem_1400);  le_214 = getitem_1400 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_504: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_214, [0, 2, 3])
    sub_1329: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_73, unsqueeze_4345);  convolution_73 = unsqueeze_4345 = None
    mul_4658: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_214, sub_1329)
    sum_505: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4658, [0, 2, 3]);  mul_4658 = None
    mul_4659: "f32[18]" = torch.ops.aten.mul.Tensor(sum_504, 3.985969387755102e-05)
    unsqueeze_4346: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4659, 0);  mul_4659 = None
    unsqueeze_4347: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4346, 2);  unsqueeze_4346 = None
    unsqueeze_4348: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4347, 3);  unsqueeze_4347 = None
    mul_4660: "f32[18]" = torch.ops.aten.mul.Tensor(sum_505, 3.985969387755102e-05)
    mul_4661: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_220, squeeze_220)
    mul_4662: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4660, mul_4661);  mul_4660 = mul_4661 = None
    unsqueeze_4349: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4662, 0);  mul_4662 = None
    unsqueeze_4350: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4349, 2);  unsqueeze_4349 = None
    unsqueeze_4351: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4350, 3);  unsqueeze_4350 = None
    mul_4663: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_220, primals_221);  primals_221 = None
    unsqueeze_4352: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4663, 0);  mul_4663 = None
    unsqueeze_4353: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4352, 2);  unsqueeze_4352 = None
    unsqueeze_4354: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4353, 3);  unsqueeze_4353 = None
    mul_4664: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1329, unsqueeze_4351);  sub_1329 = unsqueeze_4351 = None
    sub_1331: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_214, mul_4664);  where_214 = mul_4664 = None
    sub_1332: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1331, unsqueeze_4348);  sub_1331 = unsqueeze_4348 = None
    mul_4665: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1332, unsqueeze_4354);  sub_1332 = unsqueeze_4354 = None
    mul_4666: "f32[18]" = torch.ops.aten.mul.Tensor(sum_505, squeeze_220);  sum_505 = squeeze_220 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_251 = torch.ops.aten.convolution_backward.default(mul_4665, relu_68, primals_220, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4665 = primals_220 = None
    getitem_1403: "f32[8, 18, 56, 56]" = convolution_backward_251[0]
    getitem_1404: "f32[18, 18, 3, 3]" = convolution_backward_251[1];  convolution_backward_251 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2065: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_213, getitem_1403);  where_213 = getitem_1403 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_215: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_68, 0);  relu_68 = None
    where_215: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_215, full_default, add_2065);  le_215 = add_2065 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_506: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_215, [0, 2, 3])
    sub_1333: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_72, unsqueeze_4357);  convolution_72 = unsqueeze_4357 = None
    mul_4667: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_215, sub_1333)
    sum_507: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4667, [0, 2, 3]);  mul_4667 = None
    mul_4668: "f32[18]" = torch.ops.aten.mul.Tensor(sum_506, 3.985969387755102e-05)
    unsqueeze_4358: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4668, 0);  mul_4668 = None
    unsqueeze_4359: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4358, 2);  unsqueeze_4358 = None
    unsqueeze_4360: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4359, 3);  unsqueeze_4359 = None
    mul_4669: "f32[18]" = torch.ops.aten.mul.Tensor(sum_507, 3.985969387755102e-05)
    mul_4670: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_217, squeeze_217)
    mul_4671: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4669, mul_4670);  mul_4669 = mul_4670 = None
    unsqueeze_4361: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4671, 0);  mul_4671 = None
    unsqueeze_4362: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4361, 2);  unsqueeze_4361 = None
    unsqueeze_4363: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4362, 3);  unsqueeze_4362 = None
    mul_4672: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_217, primals_218);  primals_218 = None
    unsqueeze_4364: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4672, 0);  mul_4672 = None
    unsqueeze_4365: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4364, 2);  unsqueeze_4364 = None
    unsqueeze_4366: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4365, 3);  unsqueeze_4365 = None
    mul_4673: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1333, unsqueeze_4363);  sub_1333 = unsqueeze_4363 = None
    sub_1335: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_215, mul_4673);  mul_4673 = None
    sub_1336: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1335, unsqueeze_4360);  sub_1335 = unsqueeze_4360 = None
    mul_4674: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1336, unsqueeze_4366);  sub_1336 = unsqueeze_4366 = None
    mul_4675: "f32[18]" = torch.ops.aten.mul.Tensor(sum_507, squeeze_217);  sum_507 = squeeze_217 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_252 = torch.ops.aten.convolution_backward.default(mul_4674, relu_67, primals_217, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4674 = primals_217 = None
    getitem_1406: "f32[8, 18, 56, 56]" = convolution_backward_252[0]
    getitem_1407: "f32[18, 18, 3, 3]" = convolution_backward_252[1];  convolution_backward_252 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_216: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_67, 0);  relu_67 = None
    where_216: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_216, full_default, getitem_1406);  le_216 = getitem_1406 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_508: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_216, [0, 2, 3])
    sub_1337: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_71, unsqueeze_4369);  convolution_71 = unsqueeze_4369 = None
    mul_4676: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_216, sub_1337)
    sum_509: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4676, [0, 2, 3]);  mul_4676 = None
    mul_4677: "f32[18]" = torch.ops.aten.mul.Tensor(sum_508, 3.985969387755102e-05)
    unsqueeze_4370: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4677, 0);  mul_4677 = None
    unsqueeze_4371: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4370, 2);  unsqueeze_4370 = None
    unsqueeze_4372: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4371, 3);  unsqueeze_4371 = None
    mul_4678: "f32[18]" = torch.ops.aten.mul.Tensor(sum_509, 3.985969387755102e-05)
    mul_4679: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_214, squeeze_214)
    mul_4680: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4678, mul_4679);  mul_4678 = mul_4679 = None
    unsqueeze_4373: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4680, 0);  mul_4680 = None
    unsqueeze_4374: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4373, 2);  unsqueeze_4373 = None
    unsqueeze_4375: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4374, 3);  unsqueeze_4374 = None
    mul_4681: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_214, primals_215);  primals_215 = None
    unsqueeze_4376: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4681, 0);  mul_4681 = None
    unsqueeze_4377: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4376, 2);  unsqueeze_4376 = None
    unsqueeze_4378: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4377, 3);  unsqueeze_4377 = None
    mul_4682: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1337, unsqueeze_4375);  sub_1337 = unsqueeze_4375 = None
    sub_1339: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_216, mul_4682);  where_216 = mul_4682 = None
    sub_1340: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1339, unsqueeze_4372);  sub_1339 = unsqueeze_4372 = None
    mul_4683: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1340, unsqueeze_4378);  sub_1340 = unsqueeze_4378 = None
    mul_4684: "f32[18]" = torch.ops.aten.mul.Tensor(sum_509, squeeze_214);  sum_509 = squeeze_214 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_253 = torch.ops.aten.convolution_backward.default(mul_4683, relu_66, primals_214, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4683 = primals_214 = None
    getitem_1409: "f32[8, 18, 56, 56]" = convolution_backward_253[0]
    getitem_1410: "f32[18, 18, 3, 3]" = convolution_backward_253[1];  convolution_backward_253 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2066: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_215, getitem_1409);  where_215 = getitem_1409 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_217: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_66, 0);  relu_66 = None
    where_217: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_217, full_default, add_2066);  le_217 = add_2066 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_510: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_217, [0, 2, 3])
    sub_1341: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_70, unsqueeze_4381);  convolution_70 = unsqueeze_4381 = None
    mul_4685: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_217, sub_1341)
    sum_511: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4685, [0, 2, 3]);  mul_4685 = None
    mul_4686: "f32[18]" = torch.ops.aten.mul.Tensor(sum_510, 3.985969387755102e-05)
    unsqueeze_4382: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4686, 0);  mul_4686 = None
    unsqueeze_4383: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4382, 2);  unsqueeze_4382 = None
    unsqueeze_4384: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4383, 3);  unsqueeze_4383 = None
    mul_4687: "f32[18]" = torch.ops.aten.mul.Tensor(sum_511, 3.985969387755102e-05)
    mul_4688: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_211, squeeze_211)
    mul_4689: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4687, mul_4688);  mul_4687 = mul_4688 = None
    unsqueeze_4385: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4689, 0);  mul_4689 = None
    unsqueeze_4386: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4385, 2);  unsqueeze_4385 = None
    unsqueeze_4387: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4386, 3);  unsqueeze_4386 = None
    mul_4690: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_211, primals_212);  primals_212 = None
    unsqueeze_4388: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4690, 0);  mul_4690 = None
    unsqueeze_4389: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4388, 2);  unsqueeze_4388 = None
    unsqueeze_4390: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4389, 3);  unsqueeze_4389 = None
    mul_4691: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1341, unsqueeze_4387);  sub_1341 = unsqueeze_4387 = None
    sub_1343: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_217, mul_4691);  mul_4691 = None
    sub_1344: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1343, unsqueeze_4384);  sub_1343 = unsqueeze_4384 = None
    mul_4692: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1344, unsqueeze_4390);  sub_1344 = unsqueeze_4390 = None
    mul_4693: "f32[18]" = torch.ops.aten.mul.Tensor(sum_511, squeeze_211);  sum_511 = squeeze_211 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_254 = torch.ops.aten.convolution_backward.default(mul_4692, relu_65, primals_211, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4692 = primals_211 = None
    getitem_1412: "f32[8, 18, 56, 56]" = convolution_backward_254[0]
    getitem_1413: "f32[18, 18, 3, 3]" = convolution_backward_254[1];  convolution_backward_254 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_218: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_65, 0);  relu_65 = None
    where_218: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_218, full_default, getitem_1412);  le_218 = getitem_1412 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_512: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_218, [0, 2, 3])
    sub_1345: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_69, unsqueeze_4393);  convolution_69 = unsqueeze_4393 = None
    mul_4694: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_218, sub_1345)
    sum_513: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4694, [0, 2, 3]);  mul_4694 = None
    mul_4695: "f32[18]" = torch.ops.aten.mul.Tensor(sum_512, 3.985969387755102e-05)
    unsqueeze_4394: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4695, 0);  mul_4695 = None
    unsqueeze_4395: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4394, 2);  unsqueeze_4394 = None
    unsqueeze_4396: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4395, 3);  unsqueeze_4395 = None
    mul_4696: "f32[18]" = torch.ops.aten.mul.Tensor(sum_513, 3.985969387755102e-05)
    mul_4697: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_208, squeeze_208)
    mul_4698: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4696, mul_4697);  mul_4696 = mul_4697 = None
    unsqueeze_4397: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4698, 0);  mul_4698 = None
    unsqueeze_4398: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4397, 2);  unsqueeze_4397 = None
    unsqueeze_4399: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4398, 3);  unsqueeze_4398 = None
    mul_4699: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_208, primals_209);  primals_209 = None
    unsqueeze_4400: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4699, 0);  mul_4699 = None
    unsqueeze_4401: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4400, 2);  unsqueeze_4400 = None
    unsqueeze_4402: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4401, 3);  unsqueeze_4401 = None
    mul_4700: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1345, unsqueeze_4399);  sub_1345 = unsqueeze_4399 = None
    sub_1347: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_218, mul_4700);  where_218 = mul_4700 = None
    sub_1348: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1347, unsqueeze_4396);  sub_1347 = unsqueeze_4396 = None
    mul_4701: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1348, unsqueeze_4402);  sub_1348 = unsqueeze_4402 = None
    mul_4702: "f32[18]" = torch.ops.aten.mul.Tensor(sum_513, squeeze_208);  sum_513 = squeeze_208 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_255 = torch.ops.aten.convolution_backward.default(mul_4701, relu_64, primals_208, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4701 = primals_208 = None
    getitem_1415: "f32[8, 18, 56, 56]" = convolution_backward_255[0]
    getitem_1416: "f32[18, 18, 3, 3]" = convolution_backward_255[1];  convolution_backward_255 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2067: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_217, getitem_1415);  where_217 = getitem_1415 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_219: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_64, 0);  relu_64 = None
    where_219: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_219, full_default, add_2067);  le_219 = add_2067 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_514: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_219, [0, 2, 3])
    sub_1349: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_68, unsqueeze_4405);  convolution_68 = unsqueeze_4405 = None
    mul_4703: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_219, sub_1349)
    sum_515: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4703, [0, 2, 3]);  mul_4703 = None
    mul_4704: "f32[18]" = torch.ops.aten.mul.Tensor(sum_514, 3.985969387755102e-05)
    unsqueeze_4406: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4704, 0);  mul_4704 = None
    unsqueeze_4407: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4406, 2);  unsqueeze_4406 = None
    unsqueeze_4408: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4407, 3);  unsqueeze_4407 = None
    mul_4705: "f32[18]" = torch.ops.aten.mul.Tensor(sum_515, 3.985969387755102e-05)
    mul_4706: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_205, squeeze_205)
    mul_4707: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4705, mul_4706);  mul_4705 = mul_4706 = None
    unsqueeze_4409: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4707, 0);  mul_4707 = None
    unsqueeze_4410: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4409, 2);  unsqueeze_4409 = None
    unsqueeze_4411: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4410, 3);  unsqueeze_4410 = None
    mul_4708: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_205, primals_206);  primals_206 = None
    unsqueeze_4412: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4708, 0);  mul_4708 = None
    unsqueeze_4413: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4412, 2);  unsqueeze_4412 = None
    unsqueeze_4414: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4413, 3);  unsqueeze_4413 = None
    mul_4709: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1349, unsqueeze_4411);  sub_1349 = unsqueeze_4411 = None
    sub_1351: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_219, mul_4709);  mul_4709 = None
    sub_1352: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1351, unsqueeze_4408);  sub_1351 = unsqueeze_4408 = None
    mul_4710: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1352, unsqueeze_4414);  sub_1352 = unsqueeze_4414 = None
    mul_4711: "f32[18]" = torch.ops.aten.mul.Tensor(sum_515, squeeze_205);  sum_515 = squeeze_205 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_256 = torch.ops.aten.convolution_backward.default(mul_4710, relu_63, primals_205, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4710 = primals_205 = None
    getitem_1418: "f32[8, 18, 56, 56]" = convolution_backward_256[0]
    getitem_1419: "f32[18, 18, 3, 3]" = convolution_backward_256[1];  convolution_backward_256 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_220: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_63, 0);  relu_63 = None
    where_220: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_220, full_default, getitem_1418);  le_220 = getitem_1418 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_516: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_220, [0, 2, 3])
    sub_1353: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_67, unsqueeze_4417);  convolution_67 = unsqueeze_4417 = None
    mul_4712: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_220, sub_1353)
    sum_517: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4712, [0, 2, 3]);  mul_4712 = None
    mul_4713: "f32[18]" = torch.ops.aten.mul.Tensor(sum_516, 3.985969387755102e-05)
    unsqueeze_4418: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4713, 0);  mul_4713 = None
    unsqueeze_4419: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4418, 2);  unsqueeze_4418 = None
    unsqueeze_4420: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4419, 3);  unsqueeze_4419 = None
    mul_4714: "f32[18]" = torch.ops.aten.mul.Tensor(sum_517, 3.985969387755102e-05)
    mul_4715: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_202, squeeze_202)
    mul_4716: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4714, mul_4715);  mul_4714 = mul_4715 = None
    unsqueeze_4421: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4716, 0);  mul_4716 = None
    unsqueeze_4422: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4421, 2);  unsqueeze_4421 = None
    unsqueeze_4423: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4422, 3);  unsqueeze_4422 = None
    mul_4717: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_202, primals_203);  primals_203 = None
    unsqueeze_4424: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4717, 0);  mul_4717 = None
    unsqueeze_4425: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4424, 2);  unsqueeze_4424 = None
    unsqueeze_4426: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4425, 3);  unsqueeze_4425 = None
    mul_4718: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1353, unsqueeze_4423);  sub_1353 = unsqueeze_4423 = None
    sub_1355: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_220, mul_4718);  where_220 = mul_4718 = None
    sub_1356: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1355, unsqueeze_4420);  sub_1355 = unsqueeze_4420 = None
    mul_4719: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1356, unsqueeze_4426);  sub_1356 = unsqueeze_4426 = None
    mul_4720: "f32[18]" = torch.ops.aten.mul.Tensor(sum_517, squeeze_202);  sum_517 = squeeze_202 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_257 = torch.ops.aten.convolution_backward.default(mul_4719, relu_59, primals_202, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4719 = primals_202 = None
    getitem_1421: "f32[8, 18, 56, 56]" = convolution_backward_257[0]
    getitem_1422: "f32[18, 18, 3, 3]" = convolution_backward_257[1];  convolution_backward_257 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2068: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_219, getitem_1421);  where_219 = getitem_1421 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_221: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_62, 0);  relu_62 = None
    where_221: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_221, full_default, add_2060);  le_221 = add_2060 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    sum_518: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_221, [0, 2, 3])
    sub_1357: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_66, unsqueeze_4429);  convolution_66 = unsqueeze_4429 = None
    mul_4721: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_221, sub_1357)
    sum_519: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4721, [0, 2, 3]);  mul_4721 = None
    mul_4722: "f32[72]" = torch.ops.aten.mul.Tensor(sum_518, 0.0006377551020408163)
    unsqueeze_4430: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4722, 0);  mul_4722 = None
    unsqueeze_4431: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4430, 2);  unsqueeze_4430 = None
    unsqueeze_4432: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4431, 3);  unsqueeze_4431 = None
    mul_4723: "f32[72]" = torch.ops.aten.mul.Tensor(sum_519, 0.0006377551020408163)
    mul_4724: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_199, squeeze_199)
    mul_4725: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4723, mul_4724);  mul_4723 = mul_4724 = None
    unsqueeze_4433: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4725, 0);  mul_4725 = None
    unsqueeze_4434: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4433, 2);  unsqueeze_4433 = None
    unsqueeze_4435: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4434, 3);  unsqueeze_4434 = None
    mul_4726: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_199, primals_200);  primals_200 = None
    unsqueeze_4436: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4726, 0);  mul_4726 = None
    unsqueeze_4437: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4436, 2);  unsqueeze_4436 = None
    unsqueeze_4438: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4437, 3);  unsqueeze_4437 = None
    mul_4727: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1357, unsqueeze_4435);  sub_1357 = unsqueeze_4435 = None
    sub_1359: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_221, mul_4727);  mul_4727 = None
    sub_1360: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1359, unsqueeze_4432);  sub_1359 = None
    mul_4728: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1360, unsqueeze_4438);  sub_1360 = unsqueeze_4438 = None
    mul_4729: "f32[72]" = torch.ops.aten.mul.Tensor(sum_519, squeeze_199);  sum_519 = squeeze_199 = None
    convolution_backward_258 = torch.ops.aten.convolution_backward.default(mul_4728, relu_50, primals_199, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4728 = primals_199 = None
    getitem_1424: "f32[8, 36, 28, 28]" = convolution_backward_258[0]
    getitem_1425: "f32[72, 36, 3, 3]" = convolution_backward_258[1];  convolution_backward_258 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sub_1361: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_65, unsqueeze_4441);  convolution_65 = unsqueeze_4441 = None
    mul_4730: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_221, sub_1361)
    sum_521: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4730, [0, 2, 3]);  mul_4730 = None
    mul_4732: "f32[72]" = torch.ops.aten.mul.Tensor(sum_521, 0.0006377551020408163)
    mul_4733: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_196, squeeze_196)
    mul_4734: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4732, mul_4733);  mul_4732 = mul_4733 = None
    unsqueeze_4445: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4734, 0);  mul_4734 = None
    unsqueeze_4446: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4445, 2);  unsqueeze_4445 = None
    unsqueeze_4447: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4446, 3);  unsqueeze_4446 = None
    mul_4735: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_196, primals_197);  primals_197 = None
    unsqueeze_4448: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4735, 0);  mul_4735 = None
    unsqueeze_4449: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4448, 2);  unsqueeze_4448 = None
    unsqueeze_4450: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4449, 3);  unsqueeze_4449 = None
    mul_4736: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1361, unsqueeze_4447);  sub_1361 = unsqueeze_4447 = None
    sub_1363: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_221, mul_4736);  mul_4736 = None
    sub_1364: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1363, unsqueeze_4432);  sub_1363 = unsqueeze_4432 = None
    mul_4737: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1364, unsqueeze_4450);  sub_1364 = unsqueeze_4450 = None
    mul_4738: "f32[72]" = torch.ops.aten.mul.Tensor(sum_521, squeeze_196);  sum_521 = squeeze_196 = None
    convolution_backward_259 = torch.ops.aten.convolution_backward.default(mul_4737, relu_61, primals_196, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4737 = primals_196 = None
    getitem_1427: "f32[8, 18, 28, 28]" = convolution_backward_259[0]
    getitem_1428: "f32[72, 18, 3, 3]" = convolution_backward_259[1];  convolution_backward_259 = None
    le_222: "b8[8, 18, 28, 28]" = torch.ops.aten.le.Scalar(relu_61, 0);  relu_61 = None
    where_222: "f32[8, 18, 28, 28]" = torch.ops.aten.where.self(le_222, full_default, getitem_1427);  le_222 = getitem_1427 = None
    sum_522: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_222, [0, 2, 3])
    sub_1365: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_64, unsqueeze_4453);  convolution_64 = unsqueeze_4453 = None
    mul_4739: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(where_222, sub_1365)
    sum_523: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4739, [0, 2, 3]);  mul_4739 = None
    mul_4740: "f32[18]" = torch.ops.aten.mul.Tensor(sum_522, 0.00015943877551020407)
    unsqueeze_4454: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4740, 0);  mul_4740 = None
    unsqueeze_4455: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4454, 2);  unsqueeze_4454 = None
    unsqueeze_4456: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4455, 3);  unsqueeze_4455 = None
    mul_4741: "f32[18]" = torch.ops.aten.mul.Tensor(sum_523, 0.00015943877551020407)
    mul_4742: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_193, squeeze_193)
    mul_4743: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4741, mul_4742);  mul_4741 = mul_4742 = None
    unsqueeze_4457: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4743, 0);  mul_4743 = None
    unsqueeze_4458: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4457, 2);  unsqueeze_4457 = None
    unsqueeze_4459: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4458, 3);  unsqueeze_4458 = None
    mul_4744: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_193, primals_194);  primals_194 = None
    unsqueeze_4460: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4744, 0);  mul_4744 = None
    unsqueeze_4461: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4460, 2);  unsqueeze_4460 = None
    unsqueeze_4462: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4461, 3);  unsqueeze_4461 = None
    mul_4745: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1365, unsqueeze_4459);  sub_1365 = unsqueeze_4459 = None
    sub_1367: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(where_222, mul_4745);  where_222 = mul_4745 = None
    sub_1368: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1367, unsqueeze_4456);  sub_1367 = unsqueeze_4456 = None
    mul_4746: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1368, unsqueeze_4462);  sub_1368 = unsqueeze_4462 = None
    mul_4747: "f32[18]" = torch.ops.aten.mul.Tensor(sum_523, squeeze_193);  sum_523 = squeeze_193 = None
    convolution_backward_260 = torch.ops.aten.convolution_backward.default(mul_4746, relu_42, primals_193, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4746 = primals_193 = None
    getitem_1430: "f32[8, 18, 56, 56]" = convolution_backward_260[0]
    getitem_1431: "f32[18, 18, 3, 3]" = convolution_backward_260[1];  convolution_backward_260 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_223: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_60, 0);  relu_60 = None
    where_223: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_223, full_default, add_2064);  le_223 = add_2064 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_27: "f32[8, 36, 14, 14]" = torch.ops.prims._unsafe_index_put_.default(full_default_25, [None, None, unsqueeze_259, convert_element_type_20], where_223, True);  full_default_25 = unsqueeze_259 = convert_element_type_20 = None
    sum_524: "f32[36]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_27, [0, 2, 3])
    sub_1369: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_63, unsqueeze_4465);  convolution_63 = unsqueeze_4465 = None
    mul_4748: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_27, sub_1369)
    sum_525: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4748, [0, 2, 3]);  mul_4748 = None
    mul_4749: "f32[36]" = torch.ops.aten.mul.Tensor(sum_524, 0.0006377551020408163)
    unsqueeze_4466: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4749, 0);  mul_4749 = None
    unsqueeze_4467: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4466, 2);  unsqueeze_4466 = None
    unsqueeze_4468: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4467, 3);  unsqueeze_4467 = None
    mul_4750: "f32[36]" = torch.ops.aten.mul.Tensor(sum_525, 0.0006377551020408163)
    mul_4751: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_190, squeeze_190)
    mul_4752: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4750, mul_4751);  mul_4750 = mul_4751 = None
    unsqueeze_4469: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4752, 0);  mul_4752 = None
    unsqueeze_4470: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4469, 2);  unsqueeze_4469 = None
    unsqueeze_4471: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4470, 3);  unsqueeze_4470 = None
    mul_4753: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_190, primals_191);  primals_191 = None
    unsqueeze_4472: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4753, 0);  mul_4753 = None
    unsqueeze_4473: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4472, 2);  unsqueeze_4472 = None
    unsqueeze_4474: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4473, 3);  unsqueeze_4473 = None
    mul_4754: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1369, unsqueeze_4471);  sub_1369 = unsqueeze_4471 = None
    sub_1371: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_27, mul_4754);  _unsafe_index_put_27 = mul_4754 = None
    sub_1372: "f32[8, 36, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1371, unsqueeze_4468);  sub_1371 = unsqueeze_4468 = None
    mul_4755: "f32[8, 36, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1372, unsqueeze_4474);  sub_1372 = unsqueeze_4474 = None
    mul_4756: "f32[36]" = torch.ops.aten.mul.Tensor(sum_525, squeeze_190);  sum_525 = squeeze_190 = None
    convolution_backward_261 = torch.ops.aten.convolution_backward.default(mul_4755, relu_58, primals_190, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4755 = primals_190 = None
    getitem_1433: "f32[8, 72, 14, 14]" = convolution_backward_261[0]
    getitem_1434: "f32[36, 72, 1, 1]" = convolution_backward_261[1];  convolution_backward_261 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_2069: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_221, getitem_1433);  where_221 = getitem_1433 = None
    add_2070: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(getitem_1424, where_223);  getitem_1424 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sum_526: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_223, [0, 2, 3])
    sub_1373: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_62, unsqueeze_4477);  convolution_62 = unsqueeze_4477 = None
    mul_4757: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_223, sub_1373)
    sum_527: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4757, [0, 2, 3]);  mul_4757 = None
    mul_4758: "f32[36]" = torch.ops.aten.mul.Tensor(sum_526, 0.00015943877551020407)
    unsqueeze_4478: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4758, 0);  mul_4758 = None
    unsqueeze_4479: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4478, 2);  unsqueeze_4478 = None
    unsqueeze_4480: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4479, 3);  unsqueeze_4479 = None
    mul_4759: "f32[36]" = torch.ops.aten.mul.Tensor(sum_527, 0.00015943877551020407)
    mul_4760: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_187, squeeze_187)
    mul_4761: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4759, mul_4760);  mul_4759 = mul_4760 = None
    unsqueeze_4481: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4761, 0);  mul_4761 = None
    unsqueeze_4482: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4481, 2);  unsqueeze_4481 = None
    unsqueeze_4483: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4482, 3);  unsqueeze_4482 = None
    mul_4762: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_187, primals_188);  primals_188 = None
    unsqueeze_4484: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4762, 0);  mul_4762 = None
    unsqueeze_4485: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4484, 2);  unsqueeze_4484 = None
    unsqueeze_4486: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4485, 3);  unsqueeze_4485 = None
    mul_4763: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1373, unsqueeze_4483);  sub_1373 = unsqueeze_4483 = None
    sub_1375: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_223, mul_4763);  where_223 = mul_4763 = None
    sub_1376: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1375, unsqueeze_4480);  sub_1375 = unsqueeze_4480 = None
    mul_4764: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1376, unsqueeze_4486);  sub_1376 = unsqueeze_4486 = None
    mul_4765: "f32[36]" = torch.ops.aten.mul.Tensor(sum_527, squeeze_187);  sum_527 = squeeze_187 = None
    convolution_backward_262 = torch.ops.aten.convolution_backward.default(mul_4764, relu_42, primals_187, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4764 = primals_187 = None
    getitem_1436: "f32[8, 18, 56, 56]" = convolution_backward_262[0]
    getitem_1437: "f32[36, 18, 3, 3]" = convolution_backward_262[1];  convolution_backward_262 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    add_2071: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(getitem_1430, getitem_1436);  getitem_1430 = getitem_1436 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_224: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_59, 0);  relu_59 = None
    where_224: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_224, full_default, add_2068);  le_224 = add_2068 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_28: "f32[8, 18, 14, 14]" = torch.ops.prims._unsafe_index_put_.default(full_default_28, [None, None, unsqueeze_250, convert_element_type_14], where_224, True);  full_default_28 = unsqueeze_250 = convert_element_type_14 = None
    sum_528: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_28, [0, 2, 3])
    sub_1377: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_61, unsqueeze_4489);  convolution_61 = unsqueeze_4489 = None
    mul_4766: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_28, sub_1377)
    sum_529: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4766, [0, 2, 3]);  mul_4766 = None
    mul_4767: "f32[18]" = torch.ops.aten.mul.Tensor(sum_528, 0.0006377551020408163)
    unsqueeze_4490: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4767, 0);  mul_4767 = None
    unsqueeze_4491: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4490, 2);  unsqueeze_4490 = None
    unsqueeze_4492: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4491, 3);  unsqueeze_4491 = None
    mul_4768: "f32[18]" = torch.ops.aten.mul.Tensor(sum_529, 0.0006377551020408163)
    mul_4769: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_184, squeeze_184)
    mul_4770: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4768, mul_4769);  mul_4768 = mul_4769 = None
    unsqueeze_4493: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4770, 0);  mul_4770 = None
    unsqueeze_4494: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4493, 2);  unsqueeze_4493 = None
    unsqueeze_4495: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4494, 3);  unsqueeze_4494 = None
    mul_4771: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_184, primals_185);  primals_185 = None
    unsqueeze_4496: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4771, 0);  mul_4771 = None
    unsqueeze_4497: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4496, 2);  unsqueeze_4496 = None
    unsqueeze_4498: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4497, 3);  unsqueeze_4497 = None
    mul_4772: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1377, unsqueeze_4495);  sub_1377 = unsqueeze_4495 = None
    sub_1379: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_28, mul_4772);  _unsafe_index_put_28 = mul_4772 = None
    sub_1380: "f32[8, 18, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1379, unsqueeze_4492);  sub_1379 = unsqueeze_4492 = None
    mul_4773: "f32[8, 18, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1380, unsqueeze_4498);  sub_1380 = unsqueeze_4498 = None
    mul_4774: "f32[18]" = torch.ops.aten.mul.Tensor(sum_529, squeeze_184);  sum_529 = squeeze_184 = None
    convolution_backward_263 = torch.ops.aten.convolution_backward.default(mul_4773, relu_58, primals_184, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4773 = primals_184 = None
    getitem_1439: "f32[8, 72, 14, 14]" = convolution_backward_263[0]
    getitem_1440: "f32[18, 72, 1, 1]" = convolution_backward_263[1];  convolution_backward_263 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_2072: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(add_2069, getitem_1439);  add_2069 = getitem_1439 = None
    add_2073: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(add_2071, where_224);  add_2071 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_29: "f32[8, 18, 28, 28]" = torch.ops.aten._unsafe_index_put.default(full_default_29, [None, None, unsqueeze_136, convert_element_type_2], where_224, True);  where_224 = None
    sum_530: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_29, [0, 2, 3])
    sub_1381: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_60, unsqueeze_4501);  convolution_60 = unsqueeze_4501 = None
    mul_4775: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_29, sub_1381)
    sum_531: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4775, [0, 2, 3]);  mul_4775 = None
    mul_4776: "f32[18]" = torch.ops.aten.mul.Tensor(sum_530, 0.00015943877551020407)
    unsqueeze_4502: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4776, 0);  mul_4776 = None
    unsqueeze_4503: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4502, 2);  unsqueeze_4502 = None
    unsqueeze_4504: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4503, 3);  unsqueeze_4503 = None
    mul_4777: "f32[18]" = torch.ops.aten.mul.Tensor(sum_531, 0.00015943877551020407)
    mul_4778: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_181, squeeze_181)
    mul_4779: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4777, mul_4778);  mul_4777 = mul_4778 = None
    unsqueeze_4505: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4779, 0);  mul_4779 = None
    unsqueeze_4506: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4505, 2);  unsqueeze_4505 = None
    unsqueeze_4507: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4506, 3);  unsqueeze_4506 = None
    mul_4780: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_181, primals_182);  primals_182 = None
    unsqueeze_4508: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4780, 0);  mul_4780 = None
    unsqueeze_4509: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4508, 2);  unsqueeze_4508 = None
    unsqueeze_4510: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4509, 3);  unsqueeze_4509 = None
    mul_4781: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1381, unsqueeze_4507);  sub_1381 = unsqueeze_4507 = None
    sub_1383: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_29, mul_4781);  _unsafe_index_put_29 = mul_4781 = None
    sub_1384: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1383, unsqueeze_4504);  sub_1383 = unsqueeze_4504 = None
    mul_4782: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1384, unsqueeze_4510);  sub_1384 = unsqueeze_4510 = None
    mul_4783: "f32[18]" = torch.ops.aten.mul.Tensor(sum_531, squeeze_181);  sum_531 = squeeze_181 = None
    convolution_backward_264 = torch.ops.aten.convolution_backward.default(mul_4782, relu_50, primals_181, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4782 = primals_181 = None
    getitem_1442: "f32[8, 36, 28, 28]" = convolution_backward_264[0]
    getitem_1443: "f32[18, 36, 1, 1]" = convolution_backward_264[1];  convolution_backward_264 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_2074: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(add_2070, getitem_1442);  add_2070 = getitem_1442 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_225: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_58, 0);  relu_58 = None
    where_225: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_225, full_default, add_2072);  le_225 = add_2072 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_532: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_225, [0, 2, 3])
    sub_1385: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_59, unsqueeze_4513);  convolution_59 = unsqueeze_4513 = None
    mul_4784: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_225, sub_1385)
    sum_533: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4784, [0, 2, 3]);  mul_4784 = None
    mul_4785: "f32[72]" = torch.ops.aten.mul.Tensor(sum_532, 0.0006377551020408163)
    unsqueeze_4514: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4785, 0);  mul_4785 = None
    unsqueeze_4515: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4514, 2);  unsqueeze_4514 = None
    unsqueeze_4516: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4515, 3);  unsqueeze_4515 = None
    mul_4786: "f32[72]" = torch.ops.aten.mul.Tensor(sum_533, 0.0006377551020408163)
    mul_4787: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_178, squeeze_178)
    mul_4788: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4786, mul_4787);  mul_4786 = mul_4787 = None
    unsqueeze_4517: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4788, 0);  mul_4788 = None
    unsqueeze_4518: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4517, 2);  unsqueeze_4517 = None
    unsqueeze_4519: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4518, 3);  unsqueeze_4518 = None
    mul_4789: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_178, primals_179);  primals_179 = None
    unsqueeze_4520: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4789, 0);  mul_4789 = None
    unsqueeze_4521: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4520, 2);  unsqueeze_4520 = None
    unsqueeze_4522: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4521, 3);  unsqueeze_4521 = None
    mul_4790: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1385, unsqueeze_4519);  sub_1385 = unsqueeze_4519 = None
    sub_1387: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_225, mul_4790);  mul_4790 = None
    sub_1388: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1387, unsqueeze_4516);  sub_1387 = unsqueeze_4516 = None
    mul_4791: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1388, unsqueeze_4522);  sub_1388 = unsqueeze_4522 = None
    mul_4792: "f32[72]" = torch.ops.aten.mul.Tensor(sum_533, squeeze_178);  sum_533 = squeeze_178 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_265 = torch.ops.aten.convolution_backward.default(mul_4791, relu_57, primals_178, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4791 = primals_178 = None
    getitem_1445: "f32[8, 72, 14, 14]" = convolution_backward_265[0]
    getitem_1446: "f32[72, 72, 3, 3]" = convolution_backward_265[1];  convolution_backward_265 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_226: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_57, 0);  relu_57 = None
    where_226: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_226, full_default, getitem_1445);  le_226 = getitem_1445 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_534: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_226, [0, 2, 3])
    sub_1389: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_58, unsqueeze_4525);  convolution_58 = unsqueeze_4525 = None
    mul_4793: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_226, sub_1389)
    sum_535: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4793, [0, 2, 3]);  mul_4793 = None
    mul_4794: "f32[72]" = torch.ops.aten.mul.Tensor(sum_534, 0.0006377551020408163)
    unsqueeze_4526: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4794, 0);  mul_4794 = None
    unsqueeze_4527: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4526, 2);  unsqueeze_4526 = None
    unsqueeze_4528: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4527, 3);  unsqueeze_4527 = None
    mul_4795: "f32[72]" = torch.ops.aten.mul.Tensor(sum_535, 0.0006377551020408163)
    mul_4796: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_175, squeeze_175)
    mul_4797: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4795, mul_4796);  mul_4795 = mul_4796 = None
    unsqueeze_4529: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4797, 0);  mul_4797 = None
    unsqueeze_4530: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4529, 2);  unsqueeze_4529 = None
    unsqueeze_4531: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4530, 3);  unsqueeze_4530 = None
    mul_4798: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_175, primals_176);  primals_176 = None
    unsqueeze_4532: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4798, 0);  mul_4798 = None
    unsqueeze_4533: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4532, 2);  unsqueeze_4532 = None
    unsqueeze_4534: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4533, 3);  unsqueeze_4533 = None
    mul_4799: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1389, unsqueeze_4531);  sub_1389 = unsqueeze_4531 = None
    sub_1391: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_226, mul_4799);  where_226 = mul_4799 = None
    sub_1392: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1391, unsqueeze_4528);  sub_1391 = unsqueeze_4528 = None
    mul_4800: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1392, unsqueeze_4534);  sub_1392 = unsqueeze_4534 = None
    mul_4801: "f32[72]" = torch.ops.aten.mul.Tensor(sum_535, squeeze_175);  sum_535 = squeeze_175 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_266 = torch.ops.aten.convolution_backward.default(mul_4800, relu_56, primals_175, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4800 = primals_175 = None
    getitem_1448: "f32[8, 72, 14, 14]" = convolution_backward_266[0]
    getitem_1449: "f32[72, 72, 3, 3]" = convolution_backward_266[1];  convolution_backward_266 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2075: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_225, getitem_1448);  where_225 = getitem_1448 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_227: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_56, 0);  relu_56 = None
    where_227: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_227, full_default, add_2075);  le_227 = add_2075 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_536: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_227, [0, 2, 3])
    sub_1393: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_57, unsqueeze_4537);  convolution_57 = unsqueeze_4537 = None
    mul_4802: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_227, sub_1393)
    sum_537: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4802, [0, 2, 3]);  mul_4802 = None
    mul_4803: "f32[72]" = torch.ops.aten.mul.Tensor(sum_536, 0.0006377551020408163)
    unsqueeze_4538: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4803, 0);  mul_4803 = None
    unsqueeze_4539: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4538, 2);  unsqueeze_4538 = None
    unsqueeze_4540: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4539, 3);  unsqueeze_4539 = None
    mul_4804: "f32[72]" = torch.ops.aten.mul.Tensor(sum_537, 0.0006377551020408163)
    mul_4805: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_172, squeeze_172)
    mul_4806: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4804, mul_4805);  mul_4804 = mul_4805 = None
    unsqueeze_4541: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4806, 0);  mul_4806 = None
    unsqueeze_4542: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4541, 2);  unsqueeze_4541 = None
    unsqueeze_4543: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4542, 3);  unsqueeze_4542 = None
    mul_4807: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_172, primals_173);  primals_173 = None
    unsqueeze_4544: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4807, 0);  mul_4807 = None
    unsqueeze_4545: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4544, 2);  unsqueeze_4544 = None
    unsqueeze_4546: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4545, 3);  unsqueeze_4545 = None
    mul_4808: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1393, unsqueeze_4543);  sub_1393 = unsqueeze_4543 = None
    sub_1395: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_227, mul_4808);  mul_4808 = None
    sub_1396: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1395, unsqueeze_4540);  sub_1395 = unsqueeze_4540 = None
    mul_4809: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1396, unsqueeze_4546);  sub_1396 = unsqueeze_4546 = None
    mul_4810: "f32[72]" = torch.ops.aten.mul.Tensor(sum_537, squeeze_172);  sum_537 = squeeze_172 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_267 = torch.ops.aten.convolution_backward.default(mul_4809, relu_55, primals_172, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4809 = primals_172 = None
    getitem_1451: "f32[8, 72, 14, 14]" = convolution_backward_267[0]
    getitem_1452: "f32[72, 72, 3, 3]" = convolution_backward_267[1];  convolution_backward_267 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_228: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_55, 0);  relu_55 = None
    where_228: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_228, full_default, getitem_1451);  le_228 = getitem_1451 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_538: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_228, [0, 2, 3])
    sub_1397: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_56, unsqueeze_4549);  convolution_56 = unsqueeze_4549 = None
    mul_4811: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_228, sub_1397)
    sum_539: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4811, [0, 2, 3]);  mul_4811 = None
    mul_4812: "f32[72]" = torch.ops.aten.mul.Tensor(sum_538, 0.0006377551020408163)
    unsqueeze_4550: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4812, 0);  mul_4812 = None
    unsqueeze_4551: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4550, 2);  unsqueeze_4550 = None
    unsqueeze_4552: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4551, 3);  unsqueeze_4551 = None
    mul_4813: "f32[72]" = torch.ops.aten.mul.Tensor(sum_539, 0.0006377551020408163)
    mul_4814: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_169, squeeze_169)
    mul_4815: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4813, mul_4814);  mul_4813 = mul_4814 = None
    unsqueeze_4553: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4815, 0);  mul_4815 = None
    unsqueeze_4554: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4553, 2);  unsqueeze_4553 = None
    unsqueeze_4555: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4554, 3);  unsqueeze_4554 = None
    mul_4816: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_169, primals_170);  primals_170 = None
    unsqueeze_4556: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4816, 0);  mul_4816 = None
    unsqueeze_4557: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4556, 2);  unsqueeze_4556 = None
    unsqueeze_4558: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4557, 3);  unsqueeze_4557 = None
    mul_4817: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1397, unsqueeze_4555);  sub_1397 = unsqueeze_4555 = None
    sub_1399: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_228, mul_4817);  where_228 = mul_4817 = None
    sub_1400: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1399, unsqueeze_4552);  sub_1399 = unsqueeze_4552 = None
    mul_4818: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1400, unsqueeze_4558);  sub_1400 = unsqueeze_4558 = None
    mul_4819: "f32[72]" = torch.ops.aten.mul.Tensor(sum_539, squeeze_169);  sum_539 = squeeze_169 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_268 = torch.ops.aten.convolution_backward.default(mul_4818, relu_54, primals_169, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4818 = primals_169 = None
    getitem_1454: "f32[8, 72, 14, 14]" = convolution_backward_268[0]
    getitem_1455: "f32[72, 72, 3, 3]" = convolution_backward_268[1];  convolution_backward_268 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2076: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_227, getitem_1454);  where_227 = getitem_1454 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_229: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_54, 0);  relu_54 = None
    where_229: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_229, full_default, add_2076);  le_229 = add_2076 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_540: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_229, [0, 2, 3])
    sub_1401: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_55, unsqueeze_4561);  convolution_55 = unsqueeze_4561 = None
    mul_4820: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_229, sub_1401)
    sum_541: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4820, [0, 2, 3]);  mul_4820 = None
    mul_4821: "f32[72]" = torch.ops.aten.mul.Tensor(sum_540, 0.0006377551020408163)
    unsqueeze_4562: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4821, 0);  mul_4821 = None
    unsqueeze_4563: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4562, 2);  unsqueeze_4562 = None
    unsqueeze_4564: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4563, 3);  unsqueeze_4563 = None
    mul_4822: "f32[72]" = torch.ops.aten.mul.Tensor(sum_541, 0.0006377551020408163)
    mul_4823: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_166, squeeze_166)
    mul_4824: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4822, mul_4823);  mul_4822 = mul_4823 = None
    unsqueeze_4565: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4824, 0);  mul_4824 = None
    unsqueeze_4566: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4565, 2);  unsqueeze_4565 = None
    unsqueeze_4567: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4566, 3);  unsqueeze_4566 = None
    mul_4825: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_166, primals_167);  primals_167 = None
    unsqueeze_4568: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4825, 0);  mul_4825 = None
    unsqueeze_4569: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4568, 2);  unsqueeze_4568 = None
    unsqueeze_4570: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4569, 3);  unsqueeze_4569 = None
    mul_4826: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1401, unsqueeze_4567);  sub_1401 = unsqueeze_4567 = None
    sub_1403: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_229, mul_4826);  mul_4826 = None
    sub_1404: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1403, unsqueeze_4564);  sub_1403 = unsqueeze_4564 = None
    mul_4827: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1404, unsqueeze_4570);  sub_1404 = unsqueeze_4570 = None
    mul_4828: "f32[72]" = torch.ops.aten.mul.Tensor(sum_541, squeeze_166);  sum_541 = squeeze_166 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_269 = torch.ops.aten.convolution_backward.default(mul_4827, relu_53, primals_166, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4827 = primals_166 = None
    getitem_1457: "f32[8, 72, 14, 14]" = convolution_backward_269[0]
    getitem_1458: "f32[72, 72, 3, 3]" = convolution_backward_269[1];  convolution_backward_269 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_230: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_53, 0);  relu_53 = None
    where_230: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_230, full_default, getitem_1457);  le_230 = getitem_1457 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_542: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_230, [0, 2, 3])
    sub_1405: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_54, unsqueeze_4573);  convolution_54 = unsqueeze_4573 = None
    mul_4829: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_230, sub_1405)
    sum_543: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4829, [0, 2, 3]);  mul_4829 = None
    mul_4830: "f32[72]" = torch.ops.aten.mul.Tensor(sum_542, 0.0006377551020408163)
    unsqueeze_4574: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4830, 0);  mul_4830 = None
    unsqueeze_4575: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4574, 2);  unsqueeze_4574 = None
    unsqueeze_4576: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4575, 3);  unsqueeze_4575 = None
    mul_4831: "f32[72]" = torch.ops.aten.mul.Tensor(sum_543, 0.0006377551020408163)
    mul_4832: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_163, squeeze_163)
    mul_4833: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4831, mul_4832);  mul_4831 = mul_4832 = None
    unsqueeze_4577: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4833, 0);  mul_4833 = None
    unsqueeze_4578: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4577, 2);  unsqueeze_4577 = None
    unsqueeze_4579: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4578, 3);  unsqueeze_4578 = None
    mul_4834: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_163, primals_164);  primals_164 = None
    unsqueeze_4580: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4834, 0);  mul_4834 = None
    unsqueeze_4581: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4580, 2);  unsqueeze_4580 = None
    unsqueeze_4582: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4581, 3);  unsqueeze_4581 = None
    mul_4835: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1405, unsqueeze_4579);  sub_1405 = unsqueeze_4579 = None
    sub_1407: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_230, mul_4835);  where_230 = mul_4835 = None
    sub_1408: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1407, unsqueeze_4576);  sub_1407 = unsqueeze_4576 = None
    mul_4836: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1408, unsqueeze_4582);  sub_1408 = unsqueeze_4582 = None
    mul_4837: "f32[72]" = torch.ops.aten.mul.Tensor(sum_543, squeeze_163);  sum_543 = squeeze_163 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_270 = torch.ops.aten.convolution_backward.default(mul_4836, relu_52, primals_163, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4836 = primals_163 = None
    getitem_1460: "f32[8, 72, 14, 14]" = convolution_backward_270[0]
    getitem_1461: "f32[72, 72, 3, 3]" = convolution_backward_270[1];  convolution_backward_270 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2077: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_229, getitem_1460);  where_229 = getitem_1460 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_231: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_52, 0);  relu_52 = None
    where_231: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_231, full_default, add_2077);  le_231 = add_2077 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_544: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_231, [0, 2, 3])
    sub_1409: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_53, unsqueeze_4585);  convolution_53 = unsqueeze_4585 = None
    mul_4838: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_231, sub_1409)
    sum_545: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4838, [0, 2, 3]);  mul_4838 = None
    mul_4839: "f32[72]" = torch.ops.aten.mul.Tensor(sum_544, 0.0006377551020408163)
    unsqueeze_4586: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4839, 0);  mul_4839 = None
    unsqueeze_4587: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4586, 2);  unsqueeze_4586 = None
    unsqueeze_4588: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4587, 3);  unsqueeze_4587 = None
    mul_4840: "f32[72]" = torch.ops.aten.mul.Tensor(sum_545, 0.0006377551020408163)
    mul_4841: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_160, squeeze_160)
    mul_4842: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4840, mul_4841);  mul_4840 = mul_4841 = None
    unsqueeze_4589: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4842, 0);  mul_4842 = None
    unsqueeze_4590: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4589, 2);  unsqueeze_4589 = None
    unsqueeze_4591: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4590, 3);  unsqueeze_4590 = None
    mul_4843: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_160, primals_161);  primals_161 = None
    unsqueeze_4592: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4843, 0);  mul_4843 = None
    unsqueeze_4593: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4592, 2);  unsqueeze_4592 = None
    unsqueeze_4594: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4593, 3);  unsqueeze_4593 = None
    mul_4844: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1409, unsqueeze_4591);  sub_1409 = unsqueeze_4591 = None
    sub_1411: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_231, mul_4844);  mul_4844 = None
    sub_1412: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1411, unsqueeze_4588);  sub_1411 = unsqueeze_4588 = None
    mul_4845: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1412, unsqueeze_4594);  sub_1412 = unsqueeze_4594 = None
    mul_4846: "f32[72]" = torch.ops.aten.mul.Tensor(sum_545, squeeze_160);  sum_545 = squeeze_160 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_271 = torch.ops.aten.convolution_backward.default(mul_4845, relu_51, primals_160, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4845 = primals_160 = None
    getitem_1463: "f32[8, 72, 14, 14]" = convolution_backward_271[0]
    getitem_1464: "f32[72, 72, 3, 3]" = convolution_backward_271[1];  convolution_backward_271 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_232: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_51, 0);  relu_51 = None
    where_232: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_232, full_default, getitem_1463);  le_232 = getitem_1463 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_546: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_232, [0, 2, 3])
    sub_1413: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_52, unsqueeze_4597);  convolution_52 = unsqueeze_4597 = None
    mul_4847: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_232, sub_1413)
    sum_547: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_4847, [0, 2, 3]);  mul_4847 = None
    mul_4848: "f32[72]" = torch.ops.aten.mul.Tensor(sum_546, 0.0006377551020408163)
    unsqueeze_4598: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4848, 0);  mul_4848 = None
    unsqueeze_4599: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4598, 2);  unsqueeze_4598 = None
    unsqueeze_4600: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4599, 3);  unsqueeze_4599 = None
    mul_4849: "f32[72]" = torch.ops.aten.mul.Tensor(sum_547, 0.0006377551020408163)
    mul_4850: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_157, squeeze_157)
    mul_4851: "f32[72]" = torch.ops.aten.mul.Tensor(mul_4849, mul_4850);  mul_4849 = mul_4850 = None
    unsqueeze_4601: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4851, 0);  mul_4851 = None
    unsqueeze_4602: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4601, 2);  unsqueeze_4601 = None
    unsqueeze_4603: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4602, 3);  unsqueeze_4602 = None
    mul_4852: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_157, primals_158);  primals_158 = None
    unsqueeze_4604: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_4852, 0);  mul_4852 = None
    unsqueeze_4605: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4604, 2);  unsqueeze_4604 = None
    unsqueeze_4606: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4605, 3);  unsqueeze_4605 = None
    mul_4853: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1413, unsqueeze_4603);  sub_1413 = unsqueeze_4603 = None
    sub_1415: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_232, mul_4853);  where_232 = mul_4853 = None
    sub_1416: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1415, unsqueeze_4600);  sub_1415 = unsqueeze_4600 = None
    mul_4854: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1416, unsqueeze_4606);  sub_1416 = unsqueeze_4606 = None
    mul_4855: "f32[72]" = torch.ops.aten.mul.Tensor(sum_547, squeeze_157);  sum_547 = squeeze_157 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_272 = torch.ops.aten.convolution_backward.default(mul_4854, relu_34, primals_157, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4854 = primals_157 = None
    getitem_1466: "f32[8, 72, 14, 14]" = convolution_backward_272[0]
    getitem_1467: "f32[72, 72, 3, 3]" = convolution_backward_272[1];  convolution_backward_272 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2078: "f32[8, 72, 14, 14]" = torch.ops.aten.add.Tensor(where_231, getitem_1466);  where_231 = getitem_1466 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_233: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_50, 0);  relu_50 = None
    where_233: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_233, full_default, add_2074);  le_233 = add_2074 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_548: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_233, [0, 2, 3])
    sub_1417: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_51, unsqueeze_4609);  convolution_51 = unsqueeze_4609 = None
    mul_4856: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_233, sub_1417)
    sum_549: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4856, [0, 2, 3]);  mul_4856 = None
    mul_4857: "f32[36]" = torch.ops.aten.mul.Tensor(sum_548, 0.00015943877551020407)
    unsqueeze_4610: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4857, 0);  mul_4857 = None
    unsqueeze_4611: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4610, 2);  unsqueeze_4610 = None
    unsqueeze_4612: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4611, 3);  unsqueeze_4611 = None
    mul_4858: "f32[36]" = torch.ops.aten.mul.Tensor(sum_549, 0.00015943877551020407)
    mul_4859: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_154, squeeze_154)
    mul_4860: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4858, mul_4859);  mul_4858 = mul_4859 = None
    unsqueeze_4613: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4860, 0);  mul_4860 = None
    unsqueeze_4614: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4613, 2);  unsqueeze_4613 = None
    unsqueeze_4615: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4614, 3);  unsqueeze_4614 = None
    mul_4861: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_154, primals_155);  primals_155 = None
    unsqueeze_4616: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4861, 0);  mul_4861 = None
    unsqueeze_4617: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4616, 2);  unsqueeze_4616 = None
    unsqueeze_4618: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4617, 3);  unsqueeze_4617 = None
    mul_4862: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1417, unsqueeze_4615);  sub_1417 = unsqueeze_4615 = None
    sub_1419: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_233, mul_4862);  mul_4862 = None
    sub_1420: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1419, unsqueeze_4612);  sub_1419 = unsqueeze_4612 = None
    mul_4863: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1420, unsqueeze_4618);  sub_1420 = unsqueeze_4618 = None
    mul_4864: "f32[36]" = torch.ops.aten.mul.Tensor(sum_549, squeeze_154);  sum_549 = squeeze_154 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_273 = torch.ops.aten.convolution_backward.default(mul_4863, relu_49, primals_154, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4863 = primals_154 = None
    getitem_1469: "f32[8, 36, 28, 28]" = convolution_backward_273[0]
    getitem_1470: "f32[36, 36, 3, 3]" = convolution_backward_273[1];  convolution_backward_273 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_234: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_49, 0);  relu_49 = None
    where_234: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_234, full_default, getitem_1469);  le_234 = getitem_1469 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_550: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_234, [0, 2, 3])
    sub_1421: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_50, unsqueeze_4621);  convolution_50 = unsqueeze_4621 = None
    mul_4865: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_234, sub_1421)
    sum_551: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4865, [0, 2, 3]);  mul_4865 = None
    mul_4866: "f32[36]" = torch.ops.aten.mul.Tensor(sum_550, 0.00015943877551020407)
    unsqueeze_4622: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4866, 0);  mul_4866 = None
    unsqueeze_4623: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4622, 2);  unsqueeze_4622 = None
    unsqueeze_4624: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4623, 3);  unsqueeze_4623 = None
    mul_4867: "f32[36]" = torch.ops.aten.mul.Tensor(sum_551, 0.00015943877551020407)
    mul_4868: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_151, squeeze_151)
    mul_4869: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4867, mul_4868);  mul_4867 = mul_4868 = None
    unsqueeze_4625: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4869, 0);  mul_4869 = None
    unsqueeze_4626: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4625, 2);  unsqueeze_4625 = None
    unsqueeze_4627: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4626, 3);  unsqueeze_4626 = None
    mul_4870: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_151, primals_152);  primals_152 = None
    unsqueeze_4628: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4870, 0);  mul_4870 = None
    unsqueeze_4629: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4628, 2);  unsqueeze_4628 = None
    unsqueeze_4630: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4629, 3);  unsqueeze_4629 = None
    mul_4871: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1421, unsqueeze_4627);  sub_1421 = unsqueeze_4627 = None
    sub_1423: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_234, mul_4871);  where_234 = mul_4871 = None
    sub_1424: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1423, unsqueeze_4624);  sub_1423 = unsqueeze_4624 = None
    mul_4872: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1424, unsqueeze_4630);  sub_1424 = unsqueeze_4630 = None
    mul_4873: "f32[36]" = torch.ops.aten.mul.Tensor(sum_551, squeeze_151);  sum_551 = squeeze_151 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_274 = torch.ops.aten.convolution_backward.default(mul_4872, relu_48, primals_151, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4872 = primals_151 = None
    getitem_1472: "f32[8, 36, 28, 28]" = convolution_backward_274[0]
    getitem_1473: "f32[36, 36, 3, 3]" = convolution_backward_274[1];  convolution_backward_274 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2079: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_233, getitem_1472);  where_233 = getitem_1472 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_235: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_48, 0);  relu_48 = None
    where_235: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_235, full_default, add_2079);  le_235 = add_2079 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_552: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_235, [0, 2, 3])
    sub_1425: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_49, unsqueeze_4633);  convolution_49 = unsqueeze_4633 = None
    mul_4874: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_235, sub_1425)
    sum_553: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4874, [0, 2, 3]);  mul_4874 = None
    mul_4875: "f32[36]" = torch.ops.aten.mul.Tensor(sum_552, 0.00015943877551020407)
    unsqueeze_4634: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4875, 0);  mul_4875 = None
    unsqueeze_4635: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4634, 2);  unsqueeze_4634 = None
    unsqueeze_4636: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4635, 3);  unsqueeze_4635 = None
    mul_4876: "f32[36]" = torch.ops.aten.mul.Tensor(sum_553, 0.00015943877551020407)
    mul_4877: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_148, squeeze_148)
    mul_4878: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4876, mul_4877);  mul_4876 = mul_4877 = None
    unsqueeze_4637: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4878, 0);  mul_4878 = None
    unsqueeze_4638: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4637, 2);  unsqueeze_4637 = None
    unsqueeze_4639: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4638, 3);  unsqueeze_4638 = None
    mul_4879: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_148, primals_149);  primals_149 = None
    unsqueeze_4640: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4879, 0);  mul_4879 = None
    unsqueeze_4641: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4640, 2);  unsqueeze_4640 = None
    unsqueeze_4642: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4641, 3);  unsqueeze_4641 = None
    mul_4880: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1425, unsqueeze_4639);  sub_1425 = unsqueeze_4639 = None
    sub_1427: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_235, mul_4880);  mul_4880 = None
    sub_1428: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1427, unsqueeze_4636);  sub_1427 = unsqueeze_4636 = None
    mul_4881: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1428, unsqueeze_4642);  sub_1428 = unsqueeze_4642 = None
    mul_4882: "f32[36]" = torch.ops.aten.mul.Tensor(sum_553, squeeze_148);  sum_553 = squeeze_148 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_275 = torch.ops.aten.convolution_backward.default(mul_4881, relu_47, primals_148, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4881 = primals_148 = None
    getitem_1475: "f32[8, 36, 28, 28]" = convolution_backward_275[0]
    getitem_1476: "f32[36, 36, 3, 3]" = convolution_backward_275[1];  convolution_backward_275 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_236: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_47, 0);  relu_47 = None
    where_236: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_236, full_default, getitem_1475);  le_236 = getitem_1475 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_554: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_236, [0, 2, 3])
    sub_1429: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_48, unsqueeze_4645);  convolution_48 = unsqueeze_4645 = None
    mul_4883: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_236, sub_1429)
    sum_555: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4883, [0, 2, 3]);  mul_4883 = None
    mul_4884: "f32[36]" = torch.ops.aten.mul.Tensor(sum_554, 0.00015943877551020407)
    unsqueeze_4646: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4884, 0);  mul_4884 = None
    unsqueeze_4647: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4646, 2);  unsqueeze_4646 = None
    unsqueeze_4648: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4647, 3);  unsqueeze_4647 = None
    mul_4885: "f32[36]" = torch.ops.aten.mul.Tensor(sum_555, 0.00015943877551020407)
    mul_4886: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_145, squeeze_145)
    mul_4887: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4885, mul_4886);  mul_4885 = mul_4886 = None
    unsqueeze_4649: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4887, 0);  mul_4887 = None
    unsqueeze_4650: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4649, 2);  unsqueeze_4649 = None
    unsqueeze_4651: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4650, 3);  unsqueeze_4650 = None
    mul_4888: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_145, primals_146);  primals_146 = None
    unsqueeze_4652: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4888, 0);  mul_4888 = None
    unsqueeze_4653: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4652, 2);  unsqueeze_4652 = None
    unsqueeze_4654: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4653, 3);  unsqueeze_4653 = None
    mul_4889: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1429, unsqueeze_4651);  sub_1429 = unsqueeze_4651 = None
    sub_1431: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_236, mul_4889);  where_236 = mul_4889 = None
    sub_1432: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1431, unsqueeze_4648);  sub_1431 = unsqueeze_4648 = None
    mul_4890: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1432, unsqueeze_4654);  sub_1432 = unsqueeze_4654 = None
    mul_4891: "f32[36]" = torch.ops.aten.mul.Tensor(sum_555, squeeze_145);  sum_555 = squeeze_145 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_276 = torch.ops.aten.convolution_backward.default(mul_4890, relu_46, primals_145, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4890 = primals_145 = None
    getitem_1478: "f32[8, 36, 28, 28]" = convolution_backward_276[0]
    getitem_1479: "f32[36, 36, 3, 3]" = convolution_backward_276[1];  convolution_backward_276 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2080: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_235, getitem_1478);  where_235 = getitem_1478 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_237: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_46, 0);  relu_46 = None
    where_237: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_237, full_default, add_2080);  le_237 = add_2080 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_556: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_237, [0, 2, 3])
    sub_1433: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_47, unsqueeze_4657);  convolution_47 = unsqueeze_4657 = None
    mul_4892: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_237, sub_1433)
    sum_557: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4892, [0, 2, 3]);  mul_4892 = None
    mul_4893: "f32[36]" = torch.ops.aten.mul.Tensor(sum_556, 0.00015943877551020407)
    unsqueeze_4658: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4893, 0);  mul_4893 = None
    unsqueeze_4659: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4658, 2);  unsqueeze_4658 = None
    unsqueeze_4660: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4659, 3);  unsqueeze_4659 = None
    mul_4894: "f32[36]" = torch.ops.aten.mul.Tensor(sum_557, 0.00015943877551020407)
    mul_4895: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_142, squeeze_142)
    mul_4896: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4894, mul_4895);  mul_4894 = mul_4895 = None
    unsqueeze_4661: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4896, 0);  mul_4896 = None
    unsqueeze_4662: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4661, 2);  unsqueeze_4661 = None
    unsqueeze_4663: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4662, 3);  unsqueeze_4662 = None
    mul_4897: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_142, primals_143);  primals_143 = None
    unsqueeze_4664: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4897, 0);  mul_4897 = None
    unsqueeze_4665: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4664, 2);  unsqueeze_4664 = None
    unsqueeze_4666: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4665, 3);  unsqueeze_4665 = None
    mul_4898: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1433, unsqueeze_4663);  sub_1433 = unsqueeze_4663 = None
    sub_1435: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_237, mul_4898);  mul_4898 = None
    sub_1436: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1435, unsqueeze_4660);  sub_1435 = unsqueeze_4660 = None
    mul_4899: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1436, unsqueeze_4666);  sub_1436 = unsqueeze_4666 = None
    mul_4900: "f32[36]" = torch.ops.aten.mul.Tensor(sum_557, squeeze_142);  sum_557 = squeeze_142 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_277 = torch.ops.aten.convolution_backward.default(mul_4899, relu_45, primals_142, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4899 = primals_142 = None
    getitem_1481: "f32[8, 36, 28, 28]" = convolution_backward_277[0]
    getitem_1482: "f32[36, 36, 3, 3]" = convolution_backward_277[1];  convolution_backward_277 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_238: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_45, 0);  relu_45 = None
    where_238: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_238, full_default, getitem_1481);  le_238 = getitem_1481 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_558: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_238, [0, 2, 3])
    sub_1437: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_46, unsqueeze_4669);  convolution_46 = unsqueeze_4669 = None
    mul_4901: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_238, sub_1437)
    sum_559: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4901, [0, 2, 3]);  mul_4901 = None
    mul_4902: "f32[36]" = torch.ops.aten.mul.Tensor(sum_558, 0.00015943877551020407)
    unsqueeze_4670: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4902, 0);  mul_4902 = None
    unsqueeze_4671: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4670, 2);  unsqueeze_4670 = None
    unsqueeze_4672: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4671, 3);  unsqueeze_4671 = None
    mul_4903: "f32[36]" = torch.ops.aten.mul.Tensor(sum_559, 0.00015943877551020407)
    mul_4904: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_139, squeeze_139)
    mul_4905: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4903, mul_4904);  mul_4903 = mul_4904 = None
    unsqueeze_4673: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4905, 0);  mul_4905 = None
    unsqueeze_4674: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4673, 2);  unsqueeze_4673 = None
    unsqueeze_4675: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4674, 3);  unsqueeze_4674 = None
    mul_4906: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_139, primals_140);  primals_140 = None
    unsqueeze_4676: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4906, 0);  mul_4906 = None
    unsqueeze_4677: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4676, 2);  unsqueeze_4676 = None
    unsqueeze_4678: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4677, 3);  unsqueeze_4677 = None
    mul_4907: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1437, unsqueeze_4675);  sub_1437 = unsqueeze_4675 = None
    sub_1439: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_238, mul_4907);  where_238 = mul_4907 = None
    sub_1440: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1439, unsqueeze_4672);  sub_1439 = unsqueeze_4672 = None
    mul_4908: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1440, unsqueeze_4678);  sub_1440 = unsqueeze_4678 = None
    mul_4909: "f32[36]" = torch.ops.aten.mul.Tensor(sum_559, squeeze_139);  sum_559 = squeeze_139 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_278 = torch.ops.aten.convolution_backward.default(mul_4908, relu_44, primals_139, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4908 = primals_139 = None
    getitem_1484: "f32[8, 36, 28, 28]" = convolution_backward_278[0]
    getitem_1485: "f32[36, 36, 3, 3]" = convolution_backward_278[1];  convolution_backward_278 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2081: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_237, getitem_1484);  where_237 = getitem_1484 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_239: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_44, 0);  relu_44 = None
    where_239: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_239, full_default, add_2081);  le_239 = add_2081 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_560: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_239, [0, 2, 3])
    sub_1441: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_45, unsqueeze_4681);  convolution_45 = unsqueeze_4681 = None
    mul_4910: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_239, sub_1441)
    sum_561: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4910, [0, 2, 3]);  mul_4910 = None
    mul_4911: "f32[36]" = torch.ops.aten.mul.Tensor(sum_560, 0.00015943877551020407)
    unsqueeze_4682: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4911, 0);  mul_4911 = None
    unsqueeze_4683: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4682, 2);  unsqueeze_4682 = None
    unsqueeze_4684: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4683, 3);  unsqueeze_4683 = None
    mul_4912: "f32[36]" = torch.ops.aten.mul.Tensor(sum_561, 0.00015943877551020407)
    mul_4913: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_136, squeeze_136)
    mul_4914: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4912, mul_4913);  mul_4912 = mul_4913 = None
    unsqueeze_4685: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4914, 0);  mul_4914 = None
    unsqueeze_4686: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4685, 2);  unsqueeze_4685 = None
    unsqueeze_4687: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4686, 3);  unsqueeze_4686 = None
    mul_4915: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_136, primals_137);  primals_137 = None
    unsqueeze_4688: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4915, 0);  mul_4915 = None
    unsqueeze_4689: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4688, 2);  unsqueeze_4688 = None
    unsqueeze_4690: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4689, 3);  unsqueeze_4689 = None
    mul_4916: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1441, unsqueeze_4687);  sub_1441 = unsqueeze_4687 = None
    sub_1443: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_239, mul_4916);  mul_4916 = None
    sub_1444: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1443, unsqueeze_4684);  sub_1443 = unsqueeze_4684 = None
    mul_4917: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1444, unsqueeze_4690);  sub_1444 = unsqueeze_4690 = None
    mul_4918: "f32[36]" = torch.ops.aten.mul.Tensor(sum_561, squeeze_136);  sum_561 = squeeze_136 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_279 = torch.ops.aten.convolution_backward.default(mul_4917, relu_43, primals_136, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4917 = primals_136 = None
    getitem_1487: "f32[8, 36, 28, 28]" = convolution_backward_279[0]
    getitem_1488: "f32[36, 36, 3, 3]" = convolution_backward_279[1];  convolution_backward_279 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_240: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_43, 0);  relu_43 = None
    where_240: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_240, full_default, getitem_1487);  le_240 = getitem_1487 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_562: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_240, [0, 2, 3])
    sub_1445: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_44, unsqueeze_4693);  convolution_44 = unsqueeze_4693 = None
    mul_4919: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_240, sub_1445)
    sum_563: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_4919, [0, 2, 3]);  mul_4919 = None
    mul_4920: "f32[36]" = torch.ops.aten.mul.Tensor(sum_562, 0.00015943877551020407)
    unsqueeze_4694: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4920, 0);  mul_4920 = None
    unsqueeze_4695: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4694, 2);  unsqueeze_4694 = None
    unsqueeze_4696: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4695, 3);  unsqueeze_4695 = None
    mul_4921: "f32[36]" = torch.ops.aten.mul.Tensor(sum_563, 0.00015943877551020407)
    mul_4922: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_133, squeeze_133)
    mul_4923: "f32[36]" = torch.ops.aten.mul.Tensor(mul_4921, mul_4922);  mul_4921 = mul_4922 = None
    unsqueeze_4697: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4923, 0);  mul_4923 = None
    unsqueeze_4698: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4697, 2);  unsqueeze_4697 = None
    unsqueeze_4699: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4698, 3);  unsqueeze_4698 = None
    mul_4924: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_133, primals_134);  primals_134 = None
    unsqueeze_4700: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_4924, 0);  mul_4924 = None
    unsqueeze_4701: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4700, 2);  unsqueeze_4700 = None
    unsqueeze_4702: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4701, 3);  unsqueeze_4701 = None
    mul_4925: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1445, unsqueeze_4699);  sub_1445 = unsqueeze_4699 = None
    sub_1447: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_240, mul_4925);  where_240 = mul_4925 = None
    sub_1448: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1447, unsqueeze_4696);  sub_1447 = unsqueeze_4696 = None
    mul_4926: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1448, unsqueeze_4702);  sub_1448 = unsqueeze_4702 = None
    mul_4927: "f32[36]" = torch.ops.aten.mul.Tensor(sum_563, squeeze_133);  sum_563 = squeeze_133 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_280 = torch.ops.aten.convolution_backward.default(mul_4926, relu_33, primals_133, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4926 = primals_133 = None
    getitem_1490: "f32[8, 36, 28, 28]" = convolution_backward_280[0]
    getitem_1491: "f32[36, 36, 3, 3]" = convolution_backward_280[1];  convolution_backward_280 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2082: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_239, getitem_1490);  where_239 = getitem_1490 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_241: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_42, 0);  relu_42 = None
    where_241: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_241, full_default, add_2073);  le_241 = add_2073 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_564: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_241, [0, 2, 3])
    sub_1449: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_43, unsqueeze_4705);  convolution_43 = unsqueeze_4705 = None
    mul_4928: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_241, sub_1449)
    sum_565: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4928, [0, 2, 3]);  mul_4928 = None
    mul_4929: "f32[18]" = torch.ops.aten.mul.Tensor(sum_564, 3.985969387755102e-05)
    unsqueeze_4706: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4929, 0);  mul_4929 = None
    unsqueeze_4707: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4706, 2);  unsqueeze_4706 = None
    unsqueeze_4708: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4707, 3);  unsqueeze_4707 = None
    mul_4930: "f32[18]" = torch.ops.aten.mul.Tensor(sum_565, 3.985969387755102e-05)
    mul_4931: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_130, squeeze_130)
    mul_4932: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4930, mul_4931);  mul_4930 = mul_4931 = None
    unsqueeze_4709: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4932, 0);  mul_4932 = None
    unsqueeze_4710: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4709, 2);  unsqueeze_4709 = None
    unsqueeze_4711: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4710, 3);  unsqueeze_4710 = None
    mul_4933: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_130, primals_131);  primals_131 = None
    unsqueeze_4712: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4933, 0);  mul_4933 = None
    unsqueeze_4713: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4712, 2);  unsqueeze_4712 = None
    unsqueeze_4714: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4713, 3);  unsqueeze_4713 = None
    mul_4934: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1449, unsqueeze_4711);  sub_1449 = unsqueeze_4711 = None
    sub_1451: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_241, mul_4934);  mul_4934 = None
    sub_1452: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1451, unsqueeze_4708);  sub_1451 = unsqueeze_4708 = None
    mul_4935: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1452, unsqueeze_4714);  sub_1452 = unsqueeze_4714 = None
    mul_4936: "f32[18]" = torch.ops.aten.mul.Tensor(sum_565, squeeze_130);  sum_565 = squeeze_130 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_281 = torch.ops.aten.convolution_backward.default(mul_4935, relu_41, primals_130, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4935 = primals_130 = None
    getitem_1493: "f32[8, 18, 56, 56]" = convolution_backward_281[0]
    getitem_1494: "f32[18, 18, 3, 3]" = convolution_backward_281[1];  convolution_backward_281 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_242: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_41, 0);  relu_41 = None
    where_242: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_242, full_default, getitem_1493);  le_242 = getitem_1493 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_566: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_242, [0, 2, 3])
    sub_1453: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_42, unsqueeze_4717);  convolution_42 = unsqueeze_4717 = None
    mul_4937: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_242, sub_1453)
    sum_567: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4937, [0, 2, 3]);  mul_4937 = None
    mul_4938: "f32[18]" = torch.ops.aten.mul.Tensor(sum_566, 3.985969387755102e-05)
    unsqueeze_4718: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4938, 0);  mul_4938 = None
    unsqueeze_4719: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4718, 2);  unsqueeze_4718 = None
    unsqueeze_4720: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4719, 3);  unsqueeze_4719 = None
    mul_4939: "f32[18]" = torch.ops.aten.mul.Tensor(sum_567, 3.985969387755102e-05)
    mul_4940: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_127, squeeze_127)
    mul_4941: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4939, mul_4940);  mul_4939 = mul_4940 = None
    unsqueeze_4721: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4941, 0);  mul_4941 = None
    unsqueeze_4722: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4721, 2);  unsqueeze_4721 = None
    unsqueeze_4723: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4722, 3);  unsqueeze_4722 = None
    mul_4942: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_127, primals_128);  primals_128 = None
    unsqueeze_4724: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4942, 0);  mul_4942 = None
    unsqueeze_4725: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4724, 2);  unsqueeze_4724 = None
    unsqueeze_4726: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4725, 3);  unsqueeze_4725 = None
    mul_4943: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1453, unsqueeze_4723);  sub_1453 = unsqueeze_4723 = None
    sub_1455: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_242, mul_4943);  where_242 = mul_4943 = None
    sub_1456: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1455, unsqueeze_4720);  sub_1455 = unsqueeze_4720 = None
    mul_4944: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1456, unsqueeze_4726);  sub_1456 = unsqueeze_4726 = None
    mul_4945: "f32[18]" = torch.ops.aten.mul.Tensor(sum_567, squeeze_127);  sum_567 = squeeze_127 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_282 = torch.ops.aten.convolution_backward.default(mul_4944, relu_40, primals_127, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4944 = primals_127 = None
    getitem_1496: "f32[8, 18, 56, 56]" = convolution_backward_282[0]
    getitem_1497: "f32[18, 18, 3, 3]" = convolution_backward_282[1];  convolution_backward_282 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2083: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_241, getitem_1496);  where_241 = getitem_1496 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_243: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_40, 0);  relu_40 = None
    where_243: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_243, full_default, add_2083);  le_243 = add_2083 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_568: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_243, [0, 2, 3])
    sub_1457: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_41, unsqueeze_4729);  convolution_41 = unsqueeze_4729 = None
    mul_4946: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_243, sub_1457)
    sum_569: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4946, [0, 2, 3]);  mul_4946 = None
    mul_4947: "f32[18]" = torch.ops.aten.mul.Tensor(sum_568, 3.985969387755102e-05)
    unsqueeze_4730: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4947, 0);  mul_4947 = None
    unsqueeze_4731: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4730, 2);  unsqueeze_4730 = None
    unsqueeze_4732: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4731, 3);  unsqueeze_4731 = None
    mul_4948: "f32[18]" = torch.ops.aten.mul.Tensor(sum_569, 3.985969387755102e-05)
    mul_4949: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_124, squeeze_124)
    mul_4950: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4948, mul_4949);  mul_4948 = mul_4949 = None
    unsqueeze_4733: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4950, 0);  mul_4950 = None
    unsqueeze_4734: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4733, 2);  unsqueeze_4733 = None
    unsqueeze_4735: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4734, 3);  unsqueeze_4734 = None
    mul_4951: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_124, primals_125);  primals_125 = None
    unsqueeze_4736: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4951, 0);  mul_4951 = None
    unsqueeze_4737: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4736, 2);  unsqueeze_4736 = None
    unsqueeze_4738: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4737, 3);  unsqueeze_4737 = None
    mul_4952: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1457, unsqueeze_4735);  sub_1457 = unsqueeze_4735 = None
    sub_1459: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_243, mul_4952);  mul_4952 = None
    sub_1460: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1459, unsqueeze_4732);  sub_1459 = unsqueeze_4732 = None
    mul_4953: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1460, unsqueeze_4738);  sub_1460 = unsqueeze_4738 = None
    mul_4954: "f32[18]" = torch.ops.aten.mul.Tensor(sum_569, squeeze_124);  sum_569 = squeeze_124 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_283 = torch.ops.aten.convolution_backward.default(mul_4953, relu_39, primals_124, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4953 = primals_124 = None
    getitem_1499: "f32[8, 18, 56, 56]" = convolution_backward_283[0]
    getitem_1500: "f32[18, 18, 3, 3]" = convolution_backward_283[1];  convolution_backward_283 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_244: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_39, 0);  relu_39 = None
    where_244: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_244, full_default, getitem_1499);  le_244 = getitem_1499 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_570: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_244, [0, 2, 3])
    sub_1461: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_40, unsqueeze_4741);  convolution_40 = unsqueeze_4741 = None
    mul_4955: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_244, sub_1461)
    sum_571: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4955, [0, 2, 3]);  mul_4955 = None
    mul_4956: "f32[18]" = torch.ops.aten.mul.Tensor(sum_570, 3.985969387755102e-05)
    unsqueeze_4742: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4956, 0);  mul_4956 = None
    unsqueeze_4743: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4742, 2);  unsqueeze_4742 = None
    unsqueeze_4744: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4743, 3);  unsqueeze_4743 = None
    mul_4957: "f32[18]" = torch.ops.aten.mul.Tensor(sum_571, 3.985969387755102e-05)
    mul_4958: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_121, squeeze_121)
    mul_4959: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4957, mul_4958);  mul_4957 = mul_4958 = None
    unsqueeze_4745: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4959, 0);  mul_4959 = None
    unsqueeze_4746: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4745, 2);  unsqueeze_4745 = None
    unsqueeze_4747: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4746, 3);  unsqueeze_4746 = None
    mul_4960: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_121, primals_122);  primals_122 = None
    unsqueeze_4748: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4960, 0);  mul_4960 = None
    unsqueeze_4749: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4748, 2);  unsqueeze_4748 = None
    unsqueeze_4750: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4749, 3);  unsqueeze_4749 = None
    mul_4961: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1461, unsqueeze_4747);  sub_1461 = unsqueeze_4747 = None
    sub_1463: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_244, mul_4961);  where_244 = mul_4961 = None
    sub_1464: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1463, unsqueeze_4744);  sub_1463 = unsqueeze_4744 = None
    mul_4962: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1464, unsqueeze_4750);  sub_1464 = unsqueeze_4750 = None
    mul_4963: "f32[18]" = torch.ops.aten.mul.Tensor(sum_571, squeeze_121);  sum_571 = squeeze_121 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_284 = torch.ops.aten.convolution_backward.default(mul_4962, relu_38, primals_121, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4962 = primals_121 = None
    getitem_1502: "f32[8, 18, 56, 56]" = convolution_backward_284[0]
    getitem_1503: "f32[18, 18, 3, 3]" = convolution_backward_284[1];  convolution_backward_284 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2084: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_243, getitem_1502);  where_243 = getitem_1502 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_245: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_38, 0);  relu_38 = None
    where_245: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_245, full_default, add_2084);  le_245 = add_2084 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_572: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_245, [0, 2, 3])
    sub_1465: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_39, unsqueeze_4753);  convolution_39 = unsqueeze_4753 = None
    mul_4964: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_245, sub_1465)
    sum_573: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4964, [0, 2, 3]);  mul_4964 = None
    mul_4965: "f32[18]" = torch.ops.aten.mul.Tensor(sum_572, 3.985969387755102e-05)
    unsqueeze_4754: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4965, 0);  mul_4965 = None
    unsqueeze_4755: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4754, 2);  unsqueeze_4754 = None
    unsqueeze_4756: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4755, 3);  unsqueeze_4755 = None
    mul_4966: "f32[18]" = torch.ops.aten.mul.Tensor(sum_573, 3.985969387755102e-05)
    mul_4967: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_118, squeeze_118)
    mul_4968: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4966, mul_4967);  mul_4966 = mul_4967 = None
    unsqueeze_4757: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4968, 0);  mul_4968 = None
    unsqueeze_4758: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4757, 2);  unsqueeze_4757 = None
    unsqueeze_4759: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4758, 3);  unsqueeze_4758 = None
    mul_4969: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_118, primals_119);  primals_119 = None
    unsqueeze_4760: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4969, 0);  mul_4969 = None
    unsqueeze_4761: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4760, 2);  unsqueeze_4760 = None
    unsqueeze_4762: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4761, 3);  unsqueeze_4761 = None
    mul_4970: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1465, unsqueeze_4759);  sub_1465 = unsqueeze_4759 = None
    sub_1467: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_245, mul_4970);  mul_4970 = None
    sub_1468: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1467, unsqueeze_4756);  sub_1467 = unsqueeze_4756 = None
    mul_4971: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1468, unsqueeze_4762);  sub_1468 = unsqueeze_4762 = None
    mul_4972: "f32[18]" = torch.ops.aten.mul.Tensor(sum_573, squeeze_118);  sum_573 = squeeze_118 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_285 = torch.ops.aten.convolution_backward.default(mul_4971, relu_37, primals_118, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4971 = primals_118 = None
    getitem_1505: "f32[8, 18, 56, 56]" = convolution_backward_285[0]
    getitem_1506: "f32[18, 18, 3, 3]" = convolution_backward_285[1];  convolution_backward_285 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_246: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_37, 0);  relu_37 = None
    where_246: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_246, full_default, getitem_1505);  le_246 = getitem_1505 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_574: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_246, [0, 2, 3])
    sub_1469: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_38, unsqueeze_4765);  convolution_38 = unsqueeze_4765 = None
    mul_4973: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_246, sub_1469)
    sum_575: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4973, [0, 2, 3]);  mul_4973 = None
    mul_4974: "f32[18]" = torch.ops.aten.mul.Tensor(sum_574, 3.985969387755102e-05)
    unsqueeze_4766: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4974, 0);  mul_4974 = None
    unsqueeze_4767: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4766, 2);  unsqueeze_4766 = None
    unsqueeze_4768: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4767, 3);  unsqueeze_4767 = None
    mul_4975: "f32[18]" = torch.ops.aten.mul.Tensor(sum_575, 3.985969387755102e-05)
    mul_4976: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_115, squeeze_115)
    mul_4977: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4975, mul_4976);  mul_4975 = mul_4976 = None
    unsqueeze_4769: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4977, 0);  mul_4977 = None
    unsqueeze_4770: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4769, 2);  unsqueeze_4769 = None
    unsqueeze_4771: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4770, 3);  unsqueeze_4770 = None
    mul_4978: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_115, primals_116);  primals_116 = None
    unsqueeze_4772: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4978, 0);  mul_4978 = None
    unsqueeze_4773: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4772, 2);  unsqueeze_4772 = None
    unsqueeze_4774: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4773, 3);  unsqueeze_4773 = None
    mul_4979: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1469, unsqueeze_4771);  sub_1469 = unsqueeze_4771 = None
    sub_1471: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_246, mul_4979);  where_246 = mul_4979 = None
    sub_1472: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1471, unsqueeze_4768);  sub_1471 = unsqueeze_4768 = None
    mul_4980: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1472, unsqueeze_4774);  sub_1472 = unsqueeze_4774 = None
    mul_4981: "f32[18]" = torch.ops.aten.mul.Tensor(sum_575, squeeze_115);  sum_575 = squeeze_115 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_286 = torch.ops.aten.convolution_backward.default(mul_4980, relu_36, primals_115, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4980 = primals_115 = None
    getitem_1508: "f32[8, 18, 56, 56]" = convolution_backward_286[0]
    getitem_1509: "f32[18, 18, 3, 3]" = convolution_backward_286[1];  convolution_backward_286 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2085: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_245, getitem_1508);  where_245 = getitem_1508 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_247: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_36, 0);  relu_36 = None
    where_247: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_247, full_default, add_2085);  le_247 = add_2085 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_576: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_247, [0, 2, 3])
    sub_1473: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_37, unsqueeze_4777);  convolution_37 = unsqueeze_4777 = None
    mul_4982: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_247, sub_1473)
    sum_577: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4982, [0, 2, 3]);  mul_4982 = None
    mul_4983: "f32[18]" = torch.ops.aten.mul.Tensor(sum_576, 3.985969387755102e-05)
    unsqueeze_4778: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4983, 0);  mul_4983 = None
    unsqueeze_4779: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4778, 2);  unsqueeze_4778 = None
    unsqueeze_4780: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4779, 3);  unsqueeze_4779 = None
    mul_4984: "f32[18]" = torch.ops.aten.mul.Tensor(sum_577, 3.985969387755102e-05)
    mul_4985: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_112, squeeze_112)
    mul_4986: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4984, mul_4985);  mul_4984 = mul_4985 = None
    unsqueeze_4781: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4986, 0);  mul_4986 = None
    unsqueeze_4782: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4781, 2);  unsqueeze_4781 = None
    unsqueeze_4783: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4782, 3);  unsqueeze_4782 = None
    mul_4987: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_112, primals_113);  primals_113 = None
    unsqueeze_4784: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4987, 0);  mul_4987 = None
    unsqueeze_4785: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4784, 2);  unsqueeze_4784 = None
    unsqueeze_4786: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4785, 3);  unsqueeze_4785 = None
    mul_4988: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1473, unsqueeze_4783);  sub_1473 = unsqueeze_4783 = None
    sub_1475: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_247, mul_4988);  mul_4988 = None
    sub_1476: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1475, unsqueeze_4780);  sub_1475 = unsqueeze_4780 = None
    mul_4989: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1476, unsqueeze_4786);  sub_1476 = unsqueeze_4786 = None
    mul_4990: "f32[18]" = torch.ops.aten.mul.Tensor(sum_577, squeeze_112);  sum_577 = squeeze_112 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_287 = torch.ops.aten.convolution_backward.default(mul_4989, relu_35, primals_112, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4989 = primals_112 = None
    getitem_1511: "f32[8, 18, 56, 56]" = convolution_backward_287[0]
    getitem_1512: "f32[18, 18, 3, 3]" = convolution_backward_287[1];  convolution_backward_287 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_248: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_35, 0);  relu_35 = None
    where_248: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_248, full_default, getitem_1511);  le_248 = getitem_1511 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_578: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_248, [0, 2, 3])
    sub_1477: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_36, unsqueeze_4789);  convolution_36 = unsqueeze_4789 = None
    mul_4991: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_248, sub_1477)
    sum_579: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_4991, [0, 2, 3]);  mul_4991 = None
    mul_4992: "f32[18]" = torch.ops.aten.mul.Tensor(sum_578, 3.985969387755102e-05)
    unsqueeze_4790: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4992, 0);  mul_4992 = None
    unsqueeze_4791: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4790, 2);  unsqueeze_4790 = None
    unsqueeze_4792: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4791, 3);  unsqueeze_4791 = None
    mul_4993: "f32[18]" = torch.ops.aten.mul.Tensor(sum_579, 3.985969387755102e-05)
    mul_4994: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_109, squeeze_109)
    mul_4995: "f32[18]" = torch.ops.aten.mul.Tensor(mul_4993, mul_4994);  mul_4993 = mul_4994 = None
    unsqueeze_4793: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4995, 0);  mul_4995 = None
    unsqueeze_4794: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4793, 2);  unsqueeze_4793 = None
    unsqueeze_4795: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4794, 3);  unsqueeze_4794 = None
    mul_4996: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_109, primals_110);  primals_110 = None
    unsqueeze_4796: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_4996, 0);  mul_4996 = None
    unsqueeze_4797: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4796, 2);  unsqueeze_4796 = None
    unsqueeze_4798: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4797, 3);  unsqueeze_4797 = None
    mul_4997: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1477, unsqueeze_4795);  sub_1477 = unsqueeze_4795 = None
    sub_1479: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_248, mul_4997);  where_248 = mul_4997 = None
    sub_1480: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1479, unsqueeze_4792);  sub_1479 = unsqueeze_4792 = None
    mul_4998: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1480, unsqueeze_4798);  sub_1480 = unsqueeze_4798 = None
    mul_4999: "f32[18]" = torch.ops.aten.mul.Tensor(sum_579, squeeze_109);  sum_579 = squeeze_109 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_288 = torch.ops.aten.convolution_backward.default(mul_4998, relu_32, primals_109, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_4998 = primals_109 = None
    getitem_1514: "f32[8, 18, 56, 56]" = convolution_backward_288[0]
    getitem_1515: "f32[18, 18, 3, 3]" = convolution_backward_288[1];  convolution_backward_288 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2086: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_247, getitem_1514);  where_247 = getitem_1514 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:753, code: xl = [t(yl[-1]) if not isinstance(t, nn.Identity) else yl[i] for i, t in enumerate(self.transition2)]
    le_249: "b8[8, 72, 14, 14]" = torch.ops.aten.le.Scalar(relu_34, 0);  relu_34 = None
    where_249: "f32[8, 72, 14, 14]" = torch.ops.aten.where.self(le_249, full_default, add_2078);  le_249 = add_2078 = None
    sum_580: "f32[72]" = torch.ops.aten.sum.dim_IntList(where_249, [0, 2, 3])
    sub_1481: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(convolution_35, unsqueeze_4801);  convolution_35 = unsqueeze_4801 = None
    mul_5000: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(where_249, sub_1481)
    sum_581: "f32[72]" = torch.ops.aten.sum.dim_IntList(mul_5000, [0, 2, 3]);  mul_5000 = None
    mul_5001: "f32[72]" = torch.ops.aten.mul.Tensor(sum_580, 0.0006377551020408163)
    unsqueeze_4802: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_5001, 0);  mul_5001 = None
    unsqueeze_4803: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4802, 2);  unsqueeze_4802 = None
    unsqueeze_4804: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4803, 3);  unsqueeze_4803 = None
    mul_5002: "f32[72]" = torch.ops.aten.mul.Tensor(sum_581, 0.0006377551020408163)
    mul_5003: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_106, squeeze_106)
    mul_5004: "f32[72]" = torch.ops.aten.mul.Tensor(mul_5002, mul_5003);  mul_5002 = mul_5003 = None
    unsqueeze_4805: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_5004, 0);  mul_5004 = None
    unsqueeze_4806: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4805, 2);  unsqueeze_4805 = None
    unsqueeze_4807: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4806, 3);  unsqueeze_4806 = None
    mul_5005: "f32[72]" = torch.ops.aten.mul.Tensor(squeeze_106, primals_107);  primals_107 = None
    unsqueeze_4808: "f32[1, 72]" = torch.ops.aten.unsqueeze.default(mul_5005, 0);  mul_5005 = None
    unsqueeze_4809: "f32[1, 72, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4808, 2);  unsqueeze_4808 = None
    unsqueeze_4810: "f32[1, 72, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4809, 3);  unsqueeze_4809 = None
    mul_5006: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1481, unsqueeze_4807);  sub_1481 = unsqueeze_4807 = None
    sub_1483: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(where_249, mul_5006);  where_249 = mul_5006 = None
    sub_1484: "f32[8, 72, 14, 14]" = torch.ops.aten.sub.Tensor(sub_1483, unsqueeze_4804);  sub_1483 = unsqueeze_4804 = None
    mul_5007: "f32[8, 72, 14, 14]" = torch.ops.aten.mul.Tensor(sub_1484, unsqueeze_4810);  sub_1484 = unsqueeze_4810 = None
    mul_5008: "f32[72]" = torch.ops.aten.mul.Tensor(sum_581, squeeze_106);  sum_581 = squeeze_106 = None
    convolution_backward_289 = torch.ops.aten.convolution_backward.default(mul_5007, relu_33, primals_106, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5007 = primals_106 = None
    getitem_1517: "f32[8, 36, 28, 28]" = convolution_backward_289[0]
    getitem_1518: "f32[72, 36, 3, 3]" = convolution_backward_289[1];  convolution_backward_289 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:753, code: xl = [t(yl[-1]) if not isinstance(t, nn.Identity) else yl[i] for i, t in enumerate(self.transition2)]
    add_2087: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(add_2082, getitem_1517);  add_2082 = getitem_1517 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_250: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_33, 0);  relu_33 = None
    where_250: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_250, full_default, add_2087);  le_250 = add_2087 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:482, code: y = f(x[j])
    sum_582: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_250, [0, 2, 3])
    sub_1485: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_34, unsqueeze_4813);  convolution_34 = unsqueeze_4813 = None
    mul_5009: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_250, sub_1485)
    sum_583: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_5009, [0, 2, 3]);  mul_5009 = None
    mul_5010: "f32[36]" = torch.ops.aten.mul.Tensor(sum_582, 0.00015943877551020407)
    unsqueeze_4814: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5010, 0);  mul_5010 = None
    unsqueeze_4815: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4814, 2);  unsqueeze_4814 = None
    unsqueeze_4816: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4815, 3);  unsqueeze_4815 = None
    mul_5011: "f32[36]" = torch.ops.aten.mul.Tensor(sum_583, 0.00015943877551020407)
    mul_5012: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_103, squeeze_103)
    mul_5013: "f32[36]" = torch.ops.aten.mul.Tensor(mul_5011, mul_5012);  mul_5011 = mul_5012 = None
    unsqueeze_4817: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5013, 0);  mul_5013 = None
    unsqueeze_4818: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4817, 2);  unsqueeze_4817 = None
    unsqueeze_4819: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4818, 3);  unsqueeze_4818 = None
    mul_5014: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_103, primals_104);  primals_104 = None
    unsqueeze_4820: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5014, 0);  mul_5014 = None
    unsqueeze_4821: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4820, 2);  unsqueeze_4820 = None
    unsqueeze_4822: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4821, 3);  unsqueeze_4821 = None
    mul_5015: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1485, unsqueeze_4819);  sub_1485 = unsqueeze_4819 = None
    sub_1487: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_250, mul_5015);  mul_5015 = None
    sub_1488: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1487, unsqueeze_4816);  sub_1487 = unsqueeze_4816 = None
    mul_5016: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1488, unsqueeze_4822);  sub_1488 = unsqueeze_4822 = None
    mul_5017: "f32[36]" = torch.ops.aten.mul.Tensor(sum_583, squeeze_103);  sum_583 = squeeze_103 = None
    convolution_backward_290 = torch.ops.aten.convolution_backward.default(mul_5016, relu_23, primals_103, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5016 = primals_103 = None
    getitem_1520: "f32[8, 18, 56, 56]" = convolution_backward_290[0]
    getitem_1521: "f32[36, 18, 3, 3]" = convolution_backward_290[1];  convolution_backward_290 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:485, code: x_fuse.append(self.fuse_act(y))
    le_251: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_32, 0);  relu_32 = None
    where_251: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_251, full_default, add_2086);  le_251 = add_2086 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_2088: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(getitem_1520, where_251);  getitem_1520 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    _unsafe_index_put_30: "f32[8, 18, 28, 28]" = torch.ops.prims._unsafe_index_put_.default(full_default_29, [None, None, unsqueeze_136, convert_element_type_2], where_251, True);  full_default_29 = unsqueeze_136 = convert_element_type_2 = where_251 = None
    sum_584: "f32[18]" = torch.ops.aten.sum.dim_IntList(_unsafe_index_put_30, [0, 2, 3])
    sub_1489: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_33, unsqueeze_4825);  convolution_33 = unsqueeze_4825 = None
    mul_5018: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(_unsafe_index_put_30, sub_1489)
    sum_585: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_5018, [0, 2, 3]);  mul_5018 = None
    mul_5019: "f32[18]" = torch.ops.aten.mul.Tensor(sum_584, 0.00015943877551020407)
    unsqueeze_4826: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5019, 0);  mul_5019 = None
    unsqueeze_4827: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4826, 2);  unsqueeze_4826 = None
    unsqueeze_4828: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4827, 3);  unsqueeze_4827 = None
    mul_5020: "f32[18]" = torch.ops.aten.mul.Tensor(sum_585, 0.00015943877551020407)
    mul_5021: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_100, squeeze_100)
    mul_5022: "f32[18]" = torch.ops.aten.mul.Tensor(mul_5020, mul_5021);  mul_5020 = mul_5021 = None
    unsqueeze_4829: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5022, 0);  mul_5022 = None
    unsqueeze_4830: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4829, 2);  unsqueeze_4829 = None
    unsqueeze_4831: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4830, 3);  unsqueeze_4830 = None
    mul_5023: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_100, primals_101);  primals_101 = None
    unsqueeze_4832: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5023, 0);  mul_5023 = None
    unsqueeze_4833: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4832, 2);  unsqueeze_4832 = None
    unsqueeze_4834: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4833, 3);  unsqueeze_4833 = None
    mul_5024: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1489, unsqueeze_4831);  sub_1489 = unsqueeze_4831 = None
    sub_1491: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(_unsafe_index_put_30, mul_5024);  _unsafe_index_put_30 = mul_5024 = None
    sub_1492: "f32[8, 18, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1491, unsqueeze_4828);  sub_1491 = unsqueeze_4828 = None
    mul_5025: "f32[8, 18, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1492, unsqueeze_4834);  sub_1492 = unsqueeze_4834 = None
    mul_5026: "f32[18]" = torch.ops.aten.mul.Tensor(sum_585, squeeze_100);  sum_585 = squeeze_100 = None
    convolution_backward_291 = torch.ops.aten.convolution_backward.default(mul_5025, relu_31, primals_100, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5025 = primals_100 = None
    getitem_1523: "f32[8, 36, 28, 28]" = convolution_backward_291[0]
    getitem_1524: "f32[18, 36, 1, 1]" = convolution_backward_291[1];  convolution_backward_291 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:484, code: y = y + f(x[j])
    add_2089: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_250, getitem_1523);  where_250 = getitem_1523 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_252: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_31, 0);  relu_31 = None
    where_252: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_252, full_default, add_2089);  le_252 = add_2089 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_586: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_252, [0, 2, 3])
    sub_1493: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_32, unsqueeze_4837);  convolution_32 = unsqueeze_4837 = None
    mul_5027: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_252, sub_1493)
    sum_587: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_5027, [0, 2, 3]);  mul_5027 = None
    mul_5028: "f32[36]" = torch.ops.aten.mul.Tensor(sum_586, 0.00015943877551020407)
    unsqueeze_4838: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5028, 0);  mul_5028 = None
    unsqueeze_4839: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4838, 2);  unsqueeze_4838 = None
    unsqueeze_4840: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4839, 3);  unsqueeze_4839 = None
    mul_5029: "f32[36]" = torch.ops.aten.mul.Tensor(sum_587, 0.00015943877551020407)
    mul_5030: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_97, squeeze_97)
    mul_5031: "f32[36]" = torch.ops.aten.mul.Tensor(mul_5029, mul_5030);  mul_5029 = mul_5030 = None
    unsqueeze_4841: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5031, 0);  mul_5031 = None
    unsqueeze_4842: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4841, 2);  unsqueeze_4841 = None
    unsqueeze_4843: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4842, 3);  unsqueeze_4842 = None
    mul_5032: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_97, primals_98);  primals_98 = None
    unsqueeze_4844: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5032, 0);  mul_5032 = None
    unsqueeze_4845: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4844, 2);  unsqueeze_4844 = None
    unsqueeze_4846: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4845, 3);  unsqueeze_4845 = None
    mul_5033: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1493, unsqueeze_4843);  sub_1493 = unsqueeze_4843 = None
    sub_1495: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_252, mul_5033);  mul_5033 = None
    sub_1496: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1495, unsqueeze_4840);  sub_1495 = unsqueeze_4840 = None
    mul_5034: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1496, unsqueeze_4846);  sub_1496 = unsqueeze_4846 = None
    mul_5035: "f32[36]" = torch.ops.aten.mul.Tensor(sum_587, squeeze_97);  sum_587 = squeeze_97 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_292 = torch.ops.aten.convolution_backward.default(mul_5034, relu_30, primals_97, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5034 = primals_97 = None
    getitem_1526: "f32[8, 36, 28, 28]" = convolution_backward_292[0]
    getitem_1527: "f32[36, 36, 3, 3]" = convolution_backward_292[1];  convolution_backward_292 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_253: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_30, 0);  relu_30 = None
    where_253: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_253, full_default, getitem_1526);  le_253 = getitem_1526 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_588: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_253, [0, 2, 3])
    sub_1497: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_31, unsqueeze_4849);  convolution_31 = unsqueeze_4849 = None
    mul_5036: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_253, sub_1497)
    sum_589: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_5036, [0, 2, 3]);  mul_5036 = None
    mul_5037: "f32[36]" = torch.ops.aten.mul.Tensor(sum_588, 0.00015943877551020407)
    unsqueeze_4850: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5037, 0);  mul_5037 = None
    unsqueeze_4851: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4850, 2);  unsqueeze_4850 = None
    unsqueeze_4852: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4851, 3);  unsqueeze_4851 = None
    mul_5038: "f32[36]" = torch.ops.aten.mul.Tensor(sum_589, 0.00015943877551020407)
    mul_5039: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_94, squeeze_94)
    mul_5040: "f32[36]" = torch.ops.aten.mul.Tensor(mul_5038, mul_5039);  mul_5038 = mul_5039 = None
    unsqueeze_4853: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5040, 0);  mul_5040 = None
    unsqueeze_4854: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4853, 2);  unsqueeze_4853 = None
    unsqueeze_4855: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4854, 3);  unsqueeze_4854 = None
    mul_5041: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_94, primals_95);  primals_95 = None
    unsqueeze_4856: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5041, 0);  mul_5041 = None
    unsqueeze_4857: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4856, 2);  unsqueeze_4856 = None
    unsqueeze_4858: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4857, 3);  unsqueeze_4857 = None
    mul_5042: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1497, unsqueeze_4855);  sub_1497 = unsqueeze_4855 = None
    sub_1499: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_253, mul_5042);  where_253 = mul_5042 = None
    sub_1500: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1499, unsqueeze_4852);  sub_1499 = unsqueeze_4852 = None
    mul_5043: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1500, unsqueeze_4858);  sub_1500 = unsqueeze_4858 = None
    mul_5044: "f32[36]" = torch.ops.aten.mul.Tensor(sum_589, squeeze_94);  sum_589 = squeeze_94 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_293 = torch.ops.aten.convolution_backward.default(mul_5043, relu_29, primals_94, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5043 = primals_94 = None
    getitem_1529: "f32[8, 36, 28, 28]" = convolution_backward_293[0]
    getitem_1530: "f32[36, 36, 3, 3]" = convolution_backward_293[1];  convolution_backward_293 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2090: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_252, getitem_1529);  where_252 = getitem_1529 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_254: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_29, 0);  relu_29 = None
    where_254: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_254, full_default, add_2090);  le_254 = add_2090 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_590: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_254, [0, 2, 3])
    sub_1501: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_30, unsqueeze_4861);  convolution_30 = unsqueeze_4861 = None
    mul_5045: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_254, sub_1501)
    sum_591: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_5045, [0, 2, 3]);  mul_5045 = None
    mul_5046: "f32[36]" = torch.ops.aten.mul.Tensor(sum_590, 0.00015943877551020407)
    unsqueeze_4862: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5046, 0);  mul_5046 = None
    unsqueeze_4863: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4862, 2);  unsqueeze_4862 = None
    unsqueeze_4864: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4863, 3);  unsqueeze_4863 = None
    mul_5047: "f32[36]" = torch.ops.aten.mul.Tensor(sum_591, 0.00015943877551020407)
    mul_5048: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_91, squeeze_91)
    mul_5049: "f32[36]" = torch.ops.aten.mul.Tensor(mul_5047, mul_5048);  mul_5047 = mul_5048 = None
    unsqueeze_4865: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5049, 0);  mul_5049 = None
    unsqueeze_4866: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4865, 2);  unsqueeze_4865 = None
    unsqueeze_4867: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4866, 3);  unsqueeze_4866 = None
    mul_5050: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_91, primals_92);  primals_92 = None
    unsqueeze_4868: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5050, 0);  mul_5050 = None
    unsqueeze_4869: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4868, 2);  unsqueeze_4868 = None
    unsqueeze_4870: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4869, 3);  unsqueeze_4869 = None
    mul_5051: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1501, unsqueeze_4867);  sub_1501 = unsqueeze_4867 = None
    sub_1503: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_254, mul_5051);  mul_5051 = None
    sub_1504: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1503, unsqueeze_4864);  sub_1503 = unsqueeze_4864 = None
    mul_5052: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1504, unsqueeze_4870);  sub_1504 = unsqueeze_4870 = None
    mul_5053: "f32[36]" = torch.ops.aten.mul.Tensor(sum_591, squeeze_91);  sum_591 = squeeze_91 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_294 = torch.ops.aten.convolution_backward.default(mul_5052, relu_28, primals_91, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5052 = primals_91 = None
    getitem_1532: "f32[8, 36, 28, 28]" = convolution_backward_294[0]
    getitem_1533: "f32[36, 36, 3, 3]" = convolution_backward_294[1];  convolution_backward_294 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_255: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_28, 0);  relu_28 = None
    where_255: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_255, full_default, getitem_1532);  le_255 = getitem_1532 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_592: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_255, [0, 2, 3])
    sub_1505: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_29, unsqueeze_4873);  convolution_29 = unsqueeze_4873 = None
    mul_5054: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_255, sub_1505)
    sum_593: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_5054, [0, 2, 3]);  mul_5054 = None
    mul_5055: "f32[36]" = torch.ops.aten.mul.Tensor(sum_592, 0.00015943877551020407)
    unsqueeze_4874: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5055, 0);  mul_5055 = None
    unsqueeze_4875: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4874, 2);  unsqueeze_4874 = None
    unsqueeze_4876: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4875, 3);  unsqueeze_4875 = None
    mul_5056: "f32[36]" = torch.ops.aten.mul.Tensor(sum_593, 0.00015943877551020407)
    mul_5057: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_88, squeeze_88)
    mul_5058: "f32[36]" = torch.ops.aten.mul.Tensor(mul_5056, mul_5057);  mul_5056 = mul_5057 = None
    unsqueeze_4877: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5058, 0);  mul_5058 = None
    unsqueeze_4878: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4877, 2);  unsqueeze_4877 = None
    unsqueeze_4879: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4878, 3);  unsqueeze_4878 = None
    mul_5059: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_88, primals_89);  primals_89 = None
    unsqueeze_4880: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5059, 0);  mul_5059 = None
    unsqueeze_4881: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4880, 2);  unsqueeze_4880 = None
    unsqueeze_4882: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4881, 3);  unsqueeze_4881 = None
    mul_5060: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1505, unsqueeze_4879);  sub_1505 = unsqueeze_4879 = None
    sub_1507: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_255, mul_5060);  where_255 = mul_5060 = None
    sub_1508: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1507, unsqueeze_4876);  sub_1507 = unsqueeze_4876 = None
    mul_5061: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1508, unsqueeze_4882);  sub_1508 = unsqueeze_4882 = None
    mul_5062: "f32[36]" = torch.ops.aten.mul.Tensor(sum_593, squeeze_88);  sum_593 = squeeze_88 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_295 = torch.ops.aten.convolution_backward.default(mul_5061, relu_27, primals_88, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5061 = primals_88 = None
    getitem_1535: "f32[8, 36, 28, 28]" = convolution_backward_295[0]
    getitem_1536: "f32[36, 36, 3, 3]" = convolution_backward_295[1];  convolution_backward_295 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2091: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_254, getitem_1535);  where_254 = getitem_1535 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_256: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_27, 0);  relu_27 = None
    where_256: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_256, full_default, add_2091);  le_256 = add_2091 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_594: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_256, [0, 2, 3])
    sub_1509: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_28, unsqueeze_4885);  convolution_28 = unsqueeze_4885 = None
    mul_5063: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_256, sub_1509)
    sum_595: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_5063, [0, 2, 3]);  mul_5063 = None
    mul_5064: "f32[36]" = torch.ops.aten.mul.Tensor(sum_594, 0.00015943877551020407)
    unsqueeze_4886: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5064, 0);  mul_5064 = None
    unsqueeze_4887: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4886, 2);  unsqueeze_4886 = None
    unsqueeze_4888: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4887, 3);  unsqueeze_4887 = None
    mul_5065: "f32[36]" = torch.ops.aten.mul.Tensor(sum_595, 0.00015943877551020407)
    mul_5066: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_85, squeeze_85)
    mul_5067: "f32[36]" = torch.ops.aten.mul.Tensor(mul_5065, mul_5066);  mul_5065 = mul_5066 = None
    unsqueeze_4889: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5067, 0);  mul_5067 = None
    unsqueeze_4890: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4889, 2);  unsqueeze_4889 = None
    unsqueeze_4891: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4890, 3);  unsqueeze_4890 = None
    mul_5068: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_85, primals_86);  primals_86 = None
    unsqueeze_4892: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5068, 0);  mul_5068 = None
    unsqueeze_4893: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4892, 2);  unsqueeze_4892 = None
    unsqueeze_4894: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4893, 3);  unsqueeze_4893 = None
    mul_5069: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1509, unsqueeze_4891);  sub_1509 = unsqueeze_4891 = None
    sub_1511: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_256, mul_5069);  mul_5069 = None
    sub_1512: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1511, unsqueeze_4888);  sub_1511 = unsqueeze_4888 = None
    mul_5070: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1512, unsqueeze_4894);  sub_1512 = unsqueeze_4894 = None
    mul_5071: "f32[36]" = torch.ops.aten.mul.Tensor(sum_595, squeeze_85);  sum_595 = squeeze_85 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_296 = torch.ops.aten.convolution_backward.default(mul_5070, relu_26, primals_85, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5070 = primals_85 = None
    getitem_1538: "f32[8, 36, 28, 28]" = convolution_backward_296[0]
    getitem_1539: "f32[36, 36, 3, 3]" = convolution_backward_296[1];  convolution_backward_296 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_257: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_26, 0);  relu_26 = None
    where_257: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_257, full_default, getitem_1538);  le_257 = getitem_1538 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_596: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_257, [0, 2, 3])
    sub_1513: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_27, unsqueeze_4897);  convolution_27 = unsqueeze_4897 = None
    mul_5072: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_257, sub_1513)
    sum_597: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_5072, [0, 2, 3]);  mul_5072 = None
    mul_5073: "f32[36]" = torch.ops.aten.mul.Tensor(sum_596, 0.00015943877551020407)
    unsqueeze_4898: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5073, 0);  mul_5073 = None
    unsqueeze_4899: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4898, 2);  unsqueeze_4898 = None
    unsqueeze_4900: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4899, 3);  unsqueeze_4899 = None
    mul_5074: "f32[36]" = torch.ops.aten.mul.Tensor(sum_597, 0.00015943877551020407)
    mul_5075: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_82, squeeze_82)
    mul_5076: "f32[36]" = torch.ops.aten.mul.Tensor(mul_5074, mul_5075);  mul_5074 = mul_5075 = None
    unsqueeze_4901: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5076, 0);  mul_5076 = None
    unsqueeze_4902: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4901, 2);  unsqueeze_4901 = None
    unsqueeze_4903: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4902, 3);  unsqueeze_4902 = None
    mul_5077: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_82, primals_83);  primals_83 = None
    unsqueeze_4904: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5077, 0);  mul_5077 = None
    unsqueeze_4905: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4904, 2);  unsqueeze_4904 = None
    unsqueeze_4906: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4905, 3);  unsqueeze_4905 = None
    mul_5078: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1513, unsqueeze_4903);  sub_1513 = unsqueeze_4903 = None
    sub_1515: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_257, mul_5078);  where_257 = mul_5078 = None
    sub_1516: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1515, unsqueeze_4900);  sub_1515 = unsqueeze_4900 = None
    mul_5079: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1516, unsqueeze_4906);  sub_1516 = unsqueeze_4906 = None
    mul_5080: "f32[36]" = torch.ops.aten.mul.Tensor(sum_597, squeeze_82);  sum_597 = squeeze_82 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_297 = torch.ops.aten.convolution_backward.default(mul_5079, relu_25, primals_82, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5079 = primals_82 = None
    getitem_1541: "f32[8, 36, 28, 28]" = convolution_backward_297[0]
    getitem_1542: "f32[36, 36, 3, 3]" = convolution_backward_297[1];  convolution_backward_297 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2092: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_256, getitem_1541);  where_256 = getitem_1541 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_258: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_25, 0);  relu_25 = None
    where_258: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_258, full_default, add_2092);  le_258 = add_2092 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_598: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_258, [0, 2, 3])
    sub_1517: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_26, unsqueeze_4909);  convolution_26 = unsqueeze_4909 = None
    mul_5081: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_258, sub_1517)
    sum_599: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_5081, [0, 2, 3]);  mul_5081 = None
    mul_5082: "f32[36]" = torch.ops.aten.mul.Tensor(sum_598, 0.00015943877551020407)
    unsqueeze_4910: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5082, 0);  mul_5082 = None
    unsqueeze_4911: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4910, 2);  unsqueeze_4910 = None
    unsqueeze_4912: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4911, 3);  unsqueeze_4911 = None
    mul_5083: "f32[36]" = torch.ops.aten.mul.Tensor(sum_599, 0.00015943877551020407)
    mul_5084: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_79, squeeze_79)
    mul_5085: "f32[36]" = torch.ops.aten.mul.Tensor(mul_5083, mul_5084);  mul_5083 = mul_5084 = None
    unsqueeze_4913: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5085, 0);  mul_5085 = None
    unsqueeze_4914: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4913, 2);  unsqueeze_4913 = None
    unsqueeze_4915: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4914, 3);  unsqueeze_4914 = None
    mul_5086: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_79, primals_80);  primals_80 = None
    unsqueeze_4916: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5086, 0);  mul_5086 = None
    unsqueeze_4917: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4916, 2);  unsqueeze_4916 = None
    unsqueeze_4918: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4917, 3);  unsqueeze_4917 = None
    mul_5087: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1517, unsqueeze_4915);  sub_1517 = unsqueeze_4915 = None
    sub_1519: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_258, mul_5087);  mul_5087 = None
    sub_1520: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1519, unsqueeze_4912);  sub_1519 = unsqueeze_4912 = None
    mul_5088: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1520, unsqueeze_4918);  sub_1520 = unsqueeze_4918 = None
    mul_5089: "f32[36]" = torch.ops.aten.mul.Tensor(sum_599, squeeze_79);  sum_599 = squeeze_79 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_298 = torch.ops.aten.convolution_backward.default(mul_5088, relu_24, primals_79, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5088 = primals_79 = None
    getitem_1544: "f32[8, 36, 28, 28]" = convolution_backward_298[0]
    getitem_1545: "f32[36, 36, 3, 3]" = convolution_backward_298[1];  convolution_backward_298 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_259: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_24, 0);  relu_24 = None
    where_259: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_259, full_default, getitem_1544);  le_259 = getitem_1544 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_600: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_259, [0, 2, 3])
    sub_1521: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_25, unsqueeze_4921);  convolution_25 = unsqueeze_4921 = None
    mul_5090: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_259, sub_1521)
    sum_601: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_5090, [0, 2, 3]);  mul_5090 = None
    mul_5091: "f32[36]" = torch.ops.aten.mul.Tensor(sum_600, 0.00015943877551020407)
    unsqueeze_4922: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5091, 0);  mul_5091 = None
    unsqueeze_4923: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4922, 2);  unsqueeze_4922 = None
    unsqueeze_4924: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4923, 3);  unsqueeze_4923 = None
    mul_5092: "f32[36]" = torch.ops.aten.mul.Tensor(sum_601, 0.00015943877551020407)
    mul_5093: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_76, squeeze_76)
    mul_5094: "f32[36]" = torch.ops.aten.mul.Tensor(mul_5092, mul_5093);  mul_5092 = mul_5093 = None
    unsqueeze_4925: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5094, 0);  mul_5094 = None
    unsqueeze_4926: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4925, 2);  unsqueeze_4925 = None
    unsqueeze_4927: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4926, 3);  unsqueeze_4926 = None
    mul_5095: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_76, primals_77);  primals_77 = None
    unsqueeze_4928: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5095, 0);  mul_5095 = None
    unsqueeze_4929: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4928, 2);  unsqueeze_4928 = None
    unsqueeze_4930: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4929, 3);  unsqueeze_4929 = None
    mul_5096: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1521, unsqueeze_4927);  sub_1521 = unsqueeze_4927 = None
    sub_1523: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_259, mul_5096);  where_259 = mul_5096 = None
    sub_1524: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1523, unsqueeze_4924);  sub_1523 = unsqueeze_4924 = None
    mul_5097: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1524, unsqueeze_4930);  sub_1524 = unsqueeze_4930 = None
    mul_5098: "f32[36]" = torch.ops.aten.mul.Tensor(sum_601, squeeze_76);  sum_601 = squeeze_76 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_299 = torch.ops.aten.convolution_backward.default(mul_5097, relu_15, primals_76, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5097 = primals_76 = None
    getitem_1547: "f32[8, 36, 28, 28]" = convolution_backward_299[0]
    getitem_1548: "f32[36, 36, 3, 3]" = convolution_backward_299[1];  convolution_backward_299 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2093: "f32[8, 36, 28, 28]" = torch.ops.aten.add.Tensor(where_258, getitem_1547);  where_258 = getitem_1547 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_260: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_23, 0);  relu_23 = None
    where_260: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_260, full_default, add_2088);  le_260 = add_2088 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_602: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_260, [0, 2, 3])
    sub_1525: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_24, unsqueeze_4933);  convolution_24 = unsqueeze_4933 = None
    mul_5099: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_260, sub_1525)
    sum_603: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_5099, [0, 2, 3]);  mul_5099 = None
    mul_5100: "f32[18]" = torch.ops.aten.mul.Tensor(sum_602, 3.985969387755102e-05)
    unsqueeze_4934: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5100, 0);  mul_5100 = None
    unsqueeze_4935: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4934, 2);  unsqueeze_4934 = None
    unsqueeze_4936: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4935, 3);  unsqueeze_4935 = None
    mul_5101: "f32[18]" = torch.ops.aten.mul.Tensor(sum_603, 3.985969387755102e-05)
    mul_5102: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_73, squeeze_73)
    mul_5103: "f32[18]" = torch.ops.aten.mul.Tensor(mul_5101, mul_5102);  mul_5101 = mul_5102 = None
    unsqueeze_4937: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5103, 0);  mul_5103 = None
    unsqueeze_4938: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4937, 2);  unsqueeze_4937 = None
    unsqueeze_4939: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4938, 3);  unsqueeze_4938 = None
    mul_5104: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_73, primals_74);  primals_74 = None
    unsqueeze_4940: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5104, 0);  mul_5104 = None
    unsqueeze_4941: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4940, 2);  unsqueeze_4940 = None
    unsqueeze_4942: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4941, 3);  unsqueeze_4941 = None
    mul_5105: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1525, unsqueeze_4939);  sub_1525 = unsqueeze_4939 = None
    sub_1527: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_260, mul_5105);  mul_5105 = None
    sub_1528: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1527, unsqueeze_4936);  sub_1527 = unsqueeze_4936 = None
    mul_5106: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1528, unsqueeze_4942);  sub_1528 = unsqueeze_4942 = None
    mul_5107: "f32[18]" = torch.ops.aten.mul.Tensor(sum_603, squeeze_73);  sum_603 = squeeze_73 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_300 = torch.ops.aten.convolution_backward.default(mul_5106, relu_22, primals_73, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5106 = primals_73 = None
    getitem_1550: "f32[8, 18, 56, 56]" = convolution_backward_300[0]
    getitem_1551: "f32[18, 18, 3, 3]" = convolution_backward_300[1];  convolution_backward_300 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_261: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_22, 0);  relu_22 = None
    where_261: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_261, full_default, getitem_1550);  le_261 = getitem_1550 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_604: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_261, [0, 2, 3])
    sub_1529: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_23, unsqueeze_4945);  convolution_23 = unsqueeze_4945 = None
    mul_5108: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_261, sub_1529)
    sum_605: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_5108, [0, 2, 3]);  mul_5108 = None
    mul_5109: "f32[18]" = torch.ops.aten.mul.Tensor(sum_604, 3.985969387755102e-05)
    unsqueeze_4946: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5109, 0);  mul_5109 = None
    unsqueeze_4947: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4946, 2);  unsqueeze_4946 = None
    unsqueeze_4948: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4947, 3);  unsqueeze_4947 = None
    mul_5110: "f32[18]" = torch.ops.aten.mul.Tensor(sum_605, 3.985969387755102e-05)
    mul_5111: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_70, squeeze_70)
    mul_5112: "f32[18]" = torch.ops.aten.mul.Tensor(mul_5110, mul_5111);  mul_5110 = mul_5111 = None
    unsqueeze_4949: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5112, 0);  mul_5112 = None
    unsqueeze_4950: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4949, 2);  unsqueeze_4949 = None
    unsqueeze_4951: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4950, 3);  unsqueeze_4950 = None
    mul_5113: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_70, primals_71);  primals_71 = None
    unsqueeze_4952: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5113, 0);  mul_5113 = None
    unsqueeze_4953: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4952, 2);  unsqueeze_4952 = None
    unsqueeze_4954: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4953, 3);  unsqueeze_4953 = None
    mul_5114: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1529, unsqueeze_4951);  sub_1529 = unsqueeze_4951 = None
    sub_1531: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_261, mul_5114);  where_261 = mul_5114 = None
    sub_1532: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1531, unsqueeze_4948);  sub_1531 = unsqueeze_4948 = None
    mul_5115: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1532, unsqueeze_4954);  sub_1532 = unsqueeze_4954 = None
    mul_5116: "f32[18]" = torch.ops.aten.mul.Tensor(sum_605, squeeze_70);  sum_605 = squeeze_70 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_301 = torch.ops.aten.convolution_backward.default(mul_5115, relu_21, primals_70, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5115 = primals_70 = None
    getitem_1553: "f32[8, 18, 56, 56]" = convolution_backward_301[0]
    getitem_1554: "f32[18, 18, 3, 3]" = convolution_backward_301[1];  convolution_backward_301 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2094: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_260, getitem_1553);  where_260 = getitem_1553 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_262: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_21, 0);  relu_21 = None
    where_262: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_262, full_default, add_2094);  le_262 = add_2094 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_606: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_262, [0, 2, 3])
    sub_1533: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_22, unsqueeze_4957);  convolution_22 = unsqueeze_4957 = None
    mul_5117: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_262, sub_1533)
    sum_607: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_5117, [0, 2, 3]);  mul_5117 = None
    mul_5118: "f32[18]" = torch.ops.aten.mul.Tensor(sum_606, 3.985969387755102e-05)
    unsqueeze_4958: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5118, 0);  mul_5118 = None
    unsqueeze_4959: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4958, 2);  unsqueeze_4958 = None
    unsqueeze_4960: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4959, 3);  unsqueeze_4959 = None
    mul_5119: "f32[18]" = torch.ops.aten.mul.Tensor(sum_607, 3.985969387755102e-05)
    mul_5120: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_67, squeeze_67)
    mul_5121: "f32[18]" = torch.ops.aten.mul.Tensor(mul_5119, mul_5120);  mul_5119 = mul_5120 = None
    unsqueeze_4961: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5121, 0);  mul_5121 = None
    unsqueeze_4962: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4961, 2);  unsqueeze_4961 = None
    unsqueeze_4963: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4962, 3);  unsqueeze_4962 = None
    mul_5122: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_67, primals_68);  primals_68 = None
    unsqueeze_4964: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5122, 0);  mul_5122 = None
    unsqueeze_4965: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4964, 2);  unsqueeze_4964 = None
    unsqueeze_4966: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4965, 3);  unsqueeze_4965 = None
    mul_5123: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1533, unsqueeze_4963);  sub_1533 = unsqueeze_4963 = None
    sub_1535: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_262, mul_5123);  mul_5123 = None
    sub_1536: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1535, unsqueeze_4960);  sub_1535 = unsqueeze_4960 = None
    mul_5124: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1536, unsqueeze_4966);  sub_1536 = unsqueeze_4966 = None
    mul_5125: "f32[18]" = torch.ops.aten.mul.Tensor(sum_607, squeeze_67);  sum_607 = squeeze_67 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_302 = torch.ops.aten.convolution_backward.default(mul_5124, relu_20, primals_67, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5124 = primals_67 = None
    getitem_1556: "f32[8, 18, 56, 56]" = convolution_backward_302[0]
    getitem_1557: "f32[18, 18, 3, 3]" = convolution_backward_302[1];  convolution_backward_302 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_263: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_20, 0);  relu_20 = None
    where_263: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_263, full_default, getitem_1556);  le_263 = getitem_1556 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_608: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_263, [0, 2, 3])
    sub_1537: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_21, unsqueeze_4969);  convolution_21 = unsqueeze_4969 = None
    mul_5126: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_263, sub_1537)
    sum_609: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_5126, [0, 2, 3]);  mul_5126 = None
    mul_5127: "f32[18]" = torch.ops.aten.mul.Tensor(sum_608, 3.985969387755102e-05)
    unsqueeze_4970: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5127, 0);  mul_5127 = None
    unsqueeze_4971: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4970, 2);  unsqueeze_4970 = None
    unsqueeze_4972: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4971, 3);  unsqueeze_4971 = None
    mul_5128: "f32[18]" = torch.ops.aten.mul.Tensor(sum_609, 3.985969387755102e-05)
    mul_5129: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_64, squeeze_64)
    mul_5130: "f32[18]" = torch.ops.aten.mul.Tensor(mul_5128, mul_5129);  mul_5128 = mul_5129 = None
    unsqueeze_4973: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5130, 0);  mul_5130 = None
    unsqueeze_4974: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4973, 2);  unsqueeze_4973 = None
    unsqueeze_4975: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4974, 3);  unsqueeze_4974 = None
    mul_5131: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_64, primals_65);  primals_65 = None
    unsqueeze_4976: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5131, 0);  mul_5131 = None
    unsqueeze_4977: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4976, 2);  unsqueeze_4976 = None
    unsqueeze_4978: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4977, 3);  unsqueeze_4977 = None
    mul_5132: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1537, unsqueeze_4975);  sub_1537 = unsqueeze_4975 = None
    sub_1539: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_263, mul_5132);  where_263 = mul_5132 = None
    sub_1540: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1539, unsqueeze_4972);  sub_1539 = unsqueeze_4972 = None
    mul_5133: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1540, unsqueeze_4978);  sub_1540 = unsqueeze_4978 = None
    mul_5134: "f32[18]" = torch.ops.aten.mul.Tensor(sum_609, squeeze_64);  sum_609 = squeeze_64 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_303 = torch.ops.aten.convolution_backward.default(mul_5133, relu_19, primals_64, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5133 = primals_64 = None
    getitem_1559: "f32[8, 18, 56, 56]" = convolution_backward_303[0]
    getitem_1560: "f32[18, 18, 3, 3]" = convolution_backward_303[1];  convolution_backward_303 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2095: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_262, getitem_1559);  where_262 = getitem_1559 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_264: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_19, 0);  relu_19 = None
    where_264: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_264, full_default, add_2095);  le_264 = add_2095 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_610: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_264, [0, 2, 3])
    sub_1541: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_20, unsqueeze_4981);  convolution_20 = unsqueeze_4981 = None
    mul_5135: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_264, sub_1541)
    sum_611: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_5135, [0, 2, 3]);  mul_5135 = None
    mul_5136: "f32[18]" = torch.ops.aten.mul.Tensor(sum_610, 3.985969387755102e-05)
    unsqueeze_4982: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5136, 0);  mul_5136 = None
    unsqueeze_4983: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4982, 2);  unsqueeze_4982 = None
    unsqueeze_4984: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4983, 3);  unsqueeze_4983 = None
    mul_5137: "f32[18]" = torch.ops.aten.mul.Tensor(sum_611, 3.985969387755102e-05)
    mul_5138: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_61, squeeze_61)
    mul_5139: "f32[18]" = torch.ops.aten.mul.Tensor(mul_5137, mul_5138);  mul_5137 = mul_5138 = None
    unsqueeze_4985: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5139, 0);  mul_5139 = None
    unsqueeze_4986: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4985, 2);  unsqueeze_4985 = None
    unsqueeze_4987: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4986, 3);  unsqueeze_4986 = None
    mul_5140: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_61, primals_62);  primals_62 = None
    unsqueeze_4988: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5140, 0);  mul_5140 = None
    unsqueeze_4989: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4988, 2);  unsqueeze_4988 = None
    unsqueeze_4990: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4989, 3);  unsqueeze_4989 = None
    mul_5141: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1541, unsqueeze_4987);  sub_1541 = unsqueeze_4987 = None
    sub_1543: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_264, mul_5141);  mul_5141 = None
    sub_1544: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1543, unsqueeze_4984);  sub_1543 = unsqueeze_4984 = None
    mul_5142: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1544, unsqueeze_4990);  sub_1544 = unsqueeze_4990 = None
    mul_5143: "f32[18]" = torch.ops.aten.mul.Tensor(sum_611, squeeze_61);  sum_611 = squeeze_61 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_304 = torch.ops.aten.convolution_backward.default(mul_5142, relu_18, primals_61, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5142 = primals_61 = None
    getitem_1562: "f32[8, 18, 56, 56]" = convolution_backward_304[0]
    getitem_1563: "f32[18, 18, 3, 3]" = convolution_backward_304[1];  convolution_backward_304 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_265: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_18, 0);  relu_18 = None
    where_265: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_265, full_default, getitem_1562);  le_265 = getitem_1562 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_612: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_265, [0, 2, 3])
    sub_1545: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_19, unsqueeze_4993);  convolution_19 = unsqueeze_4993 = None
    mul_5144: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_265, sub_1545)
    sum_613: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_5144, [0, 2, 3]);  mul_5144 = None
    mul_5145: "f32[18]" = torch.ops.aten.mul.Tensor(sum_612, 3.985969387755102e-05)
    unsqueeze_4994: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5145, 0);  mul_5145 = None
    unsqueeze_4995: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4994, 2);  unsqueeze_4994 = None
    unsqueeze_4996: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4995, 3);  unsqueeze_4995 = None
    mul_5146: "f32[18]" = torch.ops.aten.mul.Tensor(sum_613, 3.985969387755102e-05)
    mul_5147: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_58, squeeze_58)
    mul_5148: "f32[18]" = torch.ops.aten.mul.Tensor(mul_5146, mul_5147);  mul_5146 = mul_5147 = None
    unsqueeze_4997: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5148, 0);  mul_5148 = None
    unsqueeze_4998: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4997, 2);  unsqueeze_4997 = None
    unsqueeze_4999: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_4998, 3);  unsqueeze_4998 = None
    mul_5149: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_58, primals_59);  primals_59 = None
    unsqueeze_5000: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5149, 0);  mul_5149 = None
    unsqueeze_5001: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5000, 2);  unsqueeze_5000 = None
    unsqueeze_5002: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5001, 3);  unsqueeze_5001 = None
    mul_5150: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1545, unsqueeze_4999);  sub_1545 = unsqueeze_4999 = None
    sub_1547: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_265, mul_5150);  where_265 = mul_5150 = None
    sub_1548: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1547, unsqueeze_4996);  sub_1547 = unsqueeze_4996 = None
    mul_5151: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1548, unsqueeze_5002);  sub_1548 = unsqueeze_5002 = None
    mul_5152: "f32[18]" = torch.ops.aten.mul.Tensor(sum_613, squeeze_58);  sum_613 = squeeze_58 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_305 = torch.ops.aten.convolution_backward.default(mul_5151, relu_17, primals_58, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5151 = primals_58 = None
    getitem_1565: "f32[8, 18, 56, 56]" = convolution_backward_305[0]
    getitem_1566: "f32[18, 18, 3, 3]" = convolution_backward_305[1];  convolution_backward_305 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2096: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_264, getitem_1565);  where_264 = getitem_1565 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:116, code: x = self.act2(x)
    le_266: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_17, 0);  relu_17 = None
    where_266: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_266, full_default, add_2096);  le_266 = add_2096 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:105, code: x = self.bn2(x)
    sum_614: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_266, [0, 2, 3])
    sub_1549: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_18, unsqueeze_5005);  convolution_18 = unsqueeze_5005 = None
    mul_5153: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_266, sub_1549)
    sum_615: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_5153, [0, 2, 3]);  mul_5153 = None
    mul_5154: "f32[18]" = torch.ops.aten.mul.Tensor(sum_614, 3.985969387755102e-05)
    unsqueeze_5006: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5154, 0);  mul_5154 = None
    unsqueeze_5007: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5006, 2);  unsqueeze_5006 = None
    unsqueeze_5008: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5007, 3);  unsqueeze_5007 = None
    mul_5155: "f32[18]" = torch.ops.aten.mul.Tensor(sum_615, 3.985969387755102e-05)
    mul_5156: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_55, squeeze_55)
    mul_5157: "f32[18]" = torch.ops.aten.mul.Tensor(mul_5155, mul_5156);  mul_5155 = mul_5156 = None
    unsqueeze_5009: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5157, 0);  mul_5157 = None
    unsqueeze_5010: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5009, 2);  unsqueeze_5009 = None
    unsqueeze_5011: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5010, 3);  unsqueeze_5010 = None
    mul_5158: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_55, primals_56);  primals_56 = None
    unsqueeze_5012: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5158, 0);  mul_5158 = None
    unsqueeze_5013: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5012, 2);  unsqueeze_5012 = None
    unsqueeze_5014: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5013, 3);  unsqueeze_5013 = None
    mul_5159: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1549, unsqueeze_5011);  sub_1549 = unsqueeze_5011 = None
    sub_1551: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_266, mul_5159);  mul_5159 = None
    sub_1552: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1551, unsqueeze_5008);  sub_1551 = unsqueeze_5008 = None
    mul_5160: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1552, unsqueeze_5014);  sub_1552 = unsqueeze_5014 = None
    mul_5161: "f32[18]" = torch.ops.aten.mul.Tensor(sum_615, squeeze_55);  sum_615 = squeeze_55 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:104, code: x = self.conv2(x)
    convolution_backward_306 = torch.ops.aten.convolution_backward.default(mul_5160, relu_16, primals_55, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5160 = primals_55 = None
    getitem_1568: "f32[8, 18, 56, 56]" = convolution_backward_306[0]
    getitem_1569: "f32[18, 18, 3, 3]" = convolution_backward_306[1];  convolution_backward_306 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:101, code: x = self.act1(x)
    le_267: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_16, 0);  relu_16 = None
    where_267: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_267, full_default, getitem_1568);  le_267 = getitem_1568 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:99, code: x = self.bn1(x)
    sum_616: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_267, [0, 2, 3])
    sub_1553: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_17, unsqueeze_5017);  convolution_17 = unsqueeze_5017 = None
    mul_5162: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_267, sub_1553)
    sum_617: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_5162, [0, 2, 3]);  mul_5162 = None
    mul_5163: "f32[18]" = torch.ops.aten.mul.Tensor(sum_616, 3.985969387755102e-05)
    unsqueeze_5018: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5163, 0);  mul_5163 = None
    unsqueeze_5019: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5018, 2);  unsqueeze_5018 = None
    unsqueeze_5020: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5019, 3);  unsqueeze_5019 = None
    mul_5164: "f32[18]" = torch.ops.aten.mul.Tensor(sum_617, 3.985969387755102e-05)
    mul_5165: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_52, squeeze_52)
    mul_5166: "f32[18]" = torch.ops.aten.mul.Tensor(mul_5164, mul_5165);  mul_5164 = mul_5165 = None
    unsqueeze_5021: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5166, 0);  mul_5166 = None
    unsqueeze_5022: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5021, 2);  unsqueeze_5021 = None
    unsqueeze_5023: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5022, 3);  unsqueeze_5022 = None
    mul_5167: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_52, primals_53);  primals_53 = None
    unsqueeze_5024: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5167, 0);  mul_5167 = None
    unsqueeze_5025: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5024, 2);  unsqueeze_5024 = None
    unsqueeze_5026: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5025, 3);  unsqueeze_5025 = None
    mul_5168: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1553, unsqueeze_5023);  sub_1553 = unsqueeze_5023 = None
    sub_1555: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_267, mul_5168);  where_267 = mul_5168 = None
    sub_1556: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1555, unsqueeze_5020);  sub_1555 = unsqueeze_5020 = None
    mul_5169: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1556, unsqueeze_5026);  sub_1556 = unsqueeze_5026 = None
    mul_5170: "f32[18]" = torch.ops.aten.mul.Tensor(sum_617, squeeze_52);  sum_617 = squeeze_52 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    convolution_backward_307 = torch.ops.aten.convolution_backward.default(mul_5169, relu_14, primals_52, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5169 = primals_52 = None
    getitem_1571: "f32[8, 18, 56, 56]" = convolution_backward_307[0]
    getitem_1572: "f32[18, 18, 3, 3]" = convolution_backward_307[1];  convolution_backward_307 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:98, code: x = self.conv1(x)
    add_2097: "f32[8, 18, 56, 56]" = torch.ops.aten.add.Tensor(where_266, getitem_1571);  where_266 = getitem_1571 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:750, code: xl = [t(x) for i, t in enumerate(self.transition1)]
    le_268: "b8[8, 36, 28, 28]" = torch.ops.aten.le.Scalar(relu_15, 0);  relu_15 = None
    where_268: "f32[8, 36, 28, 28]" = torch.ops.aten.where.self(le_268, full_default, add_2093);  le_268 = add_2093 = None
    sum_618: "f32[36]" = torch.ops.aten.sum.dim_IntList(where_268, [0, 2, 3])
    sub_1557: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(convolution_16, unsqueeze_5029);  convolution_16 = unsqueeze_5029 = None
    mul_5171: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(where_268, sub_1557)
    sum_619: "f32[36]" = torch.ops.aten.sum.dim_IntList(mul_5171, [0, 2, 3]);  mul_5171 = None
    mul_5172: "f32[36]" = torch.ops.aten.mul.Tensor(sum_618, 0.00015943877551020407)
    unsqueeze_5030: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5172, 0);  mul_5172 = None
    unsqueeze_5031: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5030, 2);  unsqueeze_5030 = None
    unsqueeze_5032: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5031, 3);  unsqueeze_5031 = None
    mul_5173: "f32[36]" = torch.ops.aten.mul.Tensor(sum_619, 0.00015943877551020407)
    mul_5174: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_49, squeeze_49)
    mul_5175: "f32[36]" = torch.ops.aten.mul.Tensor(mul_5173, mul_5174);  mul_5173 = mul_5174 = None
    unsqueeze_5033: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5175, 0);  mul_5175 = None
    unsqueeze_5034: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5033, 2);  unsqueeze_5033 = None
    unsqueeze_5035: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5034, 3);  unsqueeze_5034 = None
    mul_5176: "f32[36]" = torch.ops.aten.mul.Tensor(squeeze_49, primals_50);  primals_50 = None
    unsqueeze_5036: "f32[1, 36]" = torch.ops.aten.unsqueeze.default(mul_5176, 0);  mul_5176 = None
    unsqueeze_5037: "f32[1, 36, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5036, 2);  unsqueeze_5036 = None
    unsqueeze_5038: "f32[1, 36, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5037, 3);  unsqueeze_5037 = None
    mul_5177: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1557, unsqueeze_5035);  sub_1557 = unsqueeze_5035 = None
    sub_1559: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(where_268, mul_5177);  where_268 = mul_5177 = None
    sub_1560: "f32[8, 36, 28, 28]" = torch.ops.aten.sub.Tensor(sub_1559, unsqueeze_5032);  sub_1559 = unsqueeze_5032 = None
    mul_5178: "f32[8, 36, 28, 28]" = torch.ops.aten.mul.Tensor(sub_1560, unsqueeze_5038);  sub_1560 = unsqueeze_5038 = None
    mul_5179: "f32[36]" = torch.ops.aten.mul.Tensor(sum_619, squeeze_49);  sum_619 = squeeze_49 = None
    convolution_backward_308 = torch.ops.aten.convolution_backward.default(mul_5178, relu_13, primals_49, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5178 = primals_49 = None
    getitem_1574: "f32[8, 256, 56, 56]" = convolution_backward_308[0]
    getitem_1575: "f32[36, 256, 3, 3]" = convolution_backward_308[1];  convolution_backward_308 = None
    le_269: "b8[8, 18, 56, 56]" = torch.ops.aten.le.Scalar(relu_14, 0);  relu_14 = None
    where_269: "f32[8, 18, 56, 56]" = torch.ops.aten.where.self(le_269, full_default, add_2097);  le_269 = add_2097 = None
    sum_620: "f32[18]" = torch.ops.aten.sum.dim_IntList(where_269, [0, 2, 3])
    sub_1561: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_15, unsqueeze_5041);  convolution_15 = unsqueeze_5041 = None
    mul_5180: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(where_269, sub_1561)
    sum_621: "f32[18]" = torch.ops.aten.sum.dim_IntList(mul_5180, [0, 2, 3]);  mul_5180 = None
    mul_5181: "f32[18]" = torch.ops.aten.mul.Tensor(sum_620, 3.985969387755102e-05)
    unsqueeze_5042: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5181, 0);  mul_5181 = None
    unsqueeze_5043: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5042, 2);  unsqueeze_5042 = None
    unsqueeze_5044: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5043, 3);  unsqueeze_5043 = None
    mul_5182: "f32[18]" = torch.ops.aten.mul.Tensor(sum_621, 3.985969387755102e-05)
    mul_5183: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_46, squeeze_46)
    mul_5184: "f32[18]" = torch.ops.aten.mul.Tensor(mul_5182, mul_5183);  mul_5182 = mul_5183 = None
    unsqueeze_5045: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5184, 0);  mul_5184 = None
    unsqueeze_5046: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5045, 2);  unsqueeze_5045 = None
    unsqueeze_5047: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5046, 3);  unsqueeze_5046 = None
    mul_5185: "f32[18]" = torch.ops.aten.mul.Tensor(squeeze_46, primals_47);  primals_47 = None
    unsqueeze_5048: "f32[1, 18]" = torch.ops.aten.unsqueeze.default(mul_5185, 0);  mul_5185 = None
    unsqueeze_5049: "f32[1, 18, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5048, 2);  unsqueeze_5048 = None
    unsqueeze_5050: "f32[1, 18, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5049, 3);  unsqueeze_5049 = None
    mul_5186: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1561, unsqueeze_5047);  sub_1561 = unsqueeze_5047 = None
    sub_1563: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(where_269, mul_5186);  where_269 = mul_5186 = None
    sub_1564: "f32[8, 18, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1563, unsqueeze_5044);  sub_1563 = unsqueeze_5044 = None
    mul_5187: "f32[8, 18, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1564, unsqueeze_5050);  sub_1564 = unsqueeze_5050 = None
    mul_5188: "f32[18]" = torch.ops.aten.mul.Tensor(sum_621, squeeze_46);  sum_621 = squeeze_46 = None
    convolution_backward_309 = torch.ops.aten.convolution_backward.default(mul_5187, relu_13, primals_46, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5187 = primals_46 = None
    getitem_1577: "f32[8, 256, 56, 56]" = convolution_backward_309[0]
    getitem_1578: "f32[18, 256, 3, 3]" = convolution_backward_309[1];  convolution_backward_309 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:750, code: xl = [t(x) for i, t in enumerate(self.transition1)]
    add_2098: "f32[8, 256, 56, 56]" = torch.ops.aten.add.Tensor(getitem_1574, getitem_1577);  getitem_1574 = getitem_1577 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:202, code: x = self.act3(x)
    le_270: "b8[8, 256, 56, 56]" = torch.ops.aten.le.Scalar(relu_13, 0);  relu_13 = None
    where_270: "f32[8, 256, 56, 56]" = torch.ops.aten.where.self(le_270, full_default, add_2098);  le_270 = add_2098 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:191, code: x = self.bn3(x)
    sum_622: "f32[256]" = torch.ops.aten.sum.dim_IntList(where_270, [0, 2, 3])
    sub_1565: "f32[8, 256, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_14, unsqueeze_5053);  convolution_14 = unsqueeze_5053 = None
    mul_5189: "f32[8, 256, 56, 56]" = torch.ops.aten.mul.Tensor(where_270, sub_1565)
    sum_623: "f32[256]" = torch.ops.aten.sum.dim_IntList(mul_5189, [0, 2, 3]);  mul_5189 = None
    mul_5190: "f32[256]" = torch.ops.aten.mul.Tensor(sum_622, 3.985969387755102e-05)
    unsqueeze_5054: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_5190, 0);  mul_5190 = None
    unsqueeze_5055: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5054, 2);  unsqueeze_5054 = None
    unsqueeze_5056: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5055, 3);  unsqueeze_5055 = None
    mul_5191: "f32[256]" = torch.ops.aten.mul.Tensor(sum_623, 3.985969387755102e-05)
    mul_5192: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_43, squeeze_43)
    mul_5193: "f32[256]" = torch.ops.aten.mul.Tensor(mul_5191, mul_5192);  mul_5191 = mul_5192 = None
    unsqueeze_5057: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_5193, 0);  mul_5193 = None
    unsqueeze_5058: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5057, 2);  unsqueeze_5057 = None
    unsqueeze_5059: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5058, 3);  unsqueeze_5058 = None
    mul_5194: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_43, primals_44);  primals_44 = None
    unsqueeze_5060: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_5194, 0);  mul_5194 = None
    unsqueeze_5061: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5060, 2);  unsqueeze_5060 = None
    unsqueeze_5062: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5061, 3);  unsqueeze_5061 = None
    mul_5195: "f32[8, 256, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1565, unsqueeze_5059);  sub_1565 = unsqueeze_5059 = None
    sub_1567: "f32[8, 256, 56, 56]" = torch.ops.aten.sub.Tensor(where_270, mul_5195);  mul_5195 = None
    sub_1568: "f32[8, 256, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1567, unsqueeze_5056);  sub_1567 = unsqueeze_5056 = None
    mul_5196: "f32[8, 256, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1568, unsqueeze_5062);  sub_1568 = unsqueeze_5062 = None
    mul_5197: "f32[256]" = torch.ops.aten.mul.Tensor(sum_623, squeeze_43);  sum_623 = squeeze_43 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:190, code: x = self.conv3(x)
    convolution_backward_310 = torch.ops.aten.convolution_backward.default(mul_5196, relu_12, primals_43, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5196 = primals_43 = None
    getitem_1580: "f32[8, 64, 56, 56]" = convolution_backward_310[0]
    getitem_1581: "f32[256, 64, 1, 1]" = convolution_backward_310[1];  convolution_backward_310 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:187, code: x = self.act2(x)
    le_271: "b8[8, 64, 56, 56]" = torch.ops.aten.le.Scalar(relu_12, 0);  relu_12 = None
    where_271: "f32[8, 64, 56, 56]" = torch.ops.aten.where.self(le_271, full_default, getitem_1580);  le_271 = getitem_1580 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:185, code: x = self.bn2(x)
    sum_624: "f32[64]" = torch.ops.aten.sum.dim_IntList(where_271, [0, 2, 3])
    sub_1569: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_13, unsqueeze_5065);  convolution_13 = unsqueeze_5065 = None
    mul_5198: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(where_271, sub_1569)
    sum_625: "f32[64]" = torch.ops.aten.sum.dim_IntList(mul_5198, [0, 2, 3]);  mul_5198 = None
    mul_5199: "f32[64]" = torch.ops.aten.mul.Tensor(sum_624, 3.985969387755102e-05)
    unsqueeze_5066: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5199, 0);  mul_5199 = None
    unsqueeze_5067: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5066, 2);  unsqueeze_5066 = None
    unsqueeze_5068: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5067, 3);  unsqueeze_5067 = None
    mul_5200: "f32[64]" = torch.ops.aten.mul.Tensor(sum_625, 3.985969387755102e-05)
    mul_5201: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_40, squeeze_40)
    mul_5202: "f32[64]" = torch.ops.aten.mul.Tensor(mul_5200, mul_5201);  mul_5200 = mul_5201 = None
    unsqueeze_5069: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5202, 0);  mul_5202 = None
    unsqueeze_5070: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5069, 2);  unsqueeze_5069 = None
    unsqueeze_5071: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5070, 3);  unsqueeze_5070 = None
    mul_5203: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_40, primals_41);  primals_41 = None
    unsqueeze_5072: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5203, 0);  mul_5203 = None
    unsqueeze_5073: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5072, 2);  unsqueeze_5072 = None
    unsqueeze_5074: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5073, 3);  unsqueeze_5073 = None
    mul_5204: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1569, unsqueeze_5071);  sub_1569 = unsqueeze_5071 = None
    sub_1571: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(where_271, mul_5204);  where_271 = mul_5204 = None
    sub_1572: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1571, unsqueeze_5068);  sub_1571 = unsqueeze_5068 = None
    mul_5205: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1572, unsqueeze_5074);  sub_1572 = unsqueeze_5074 = None
    mul_5206: "f32[64]" = torch.ops.aten.mul.Tensor(sum_625, squeeze_40);  sum_625 = squeeze_40 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:184, code: x = self.conv2(x)
    convolution_backward_311 = torch.ops.aten.convolution_backward.default(mul_5205, relu_11, primals_40, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5205 = primals_40 = None
    getitem_1583: "f32[8, 64, 56, 56]" = convolution_backward_311[0]
    getitem_1584: "f32[64, 64, 3, 3]" = convolution_backward_311[1];  convolution_backward_311 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:182, code: x = self.act1(x)
    le_272: "b8[8, 64, 56, 56]" = torch.ops.aten.le.Scalar(relu_11, 0);  relu_11 = None
    where_272: "f32[8, 64, 56, 56]" = torch.ops.aten.where.self(le_272, full_default, getitem_1583);  le_272 = getitem_1583 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:181, code: x = self.bn1(x)
    sum_626: "f32[64]" = torch.ops.aten.sum.dim_IntList(where_272, [0, 2, 3])
    sub_1573: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_12, unsqueeze_5077);  convolution_12 = unsqueeze_5077 = None
    mul_5207: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(where_272, sub_1573)
    sum_627: "f32[64]" = torch.ops.aten.sum.dim_IntList(mul_5207, [0, 2, 3]);  mul_5207 = None
    mul_5208: "f32[64]" = torch.ops.aten.mul.Tensor(sum_626, 3.985969387755102e-05)
    unsqueeze_5078: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5208, 0);  mul_5208 = None
    unsqueeze_5079: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5078, 2);  unsqueeze_5078 = None
    unsqueeze_5080: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5079, 3);  unsqueeze_5079 = None
    mul_5209: "f32[64]" = torch.ops.aten.mul.Tensor(sum_627, 3.985969387755102e-05)
    mul_5210: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_37, squeeze_37)
    mul_5211: "f32[64]" = torch.ops.aten.mul.Tensor(mul_5209, mul_5210);  mul_5209 = mul_5210 = None
    unsqueeze_5081: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5211, 0);  mul_5211 = None
    unsqueeze_5082: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5081, 2);  unsqueeze_5081 = None
    unsqueeze_5083: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5082, 3);  unsqueeze_5082 = None
    mul_5212: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_37, primals_38);  primals_38 = None
    unsqueeze_5084: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5212, 0);  mul_5212 = None
    unsqueeze_5085: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5084, 2);  unsqueeze_5084 = None
    unsqueeze_5086: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5085, 3);  unsqueeze_5085 = None
    mul_5213: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1573, unsqueeze_5083);  sub_1573 = unsqueeze_5083 = None
    sub_1575: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(where_272, mul_5213);  where_272 = mul_5213 = None
    sub_1576: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1575, unsqueeze_5080);  sub_1575 = unsqueeze_5080 = None
    mul_5214: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1576, unsqueeze_5086);  sub_1576 = unsqueeze_5086 = None
    mul_5215: "f32[64]" = torch.ops.aten.mul.Tensor(sum_627, squeeze_37);  sum_627 = squeeze_37 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:180, code: x = self.conv1(x)
    convolution_backward_312 = torch.ops.aten.convolution_backward.default(mul_5214, relu_10, primals_37, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5214 = primals_37 = None
    getitem_1586: "f32[8, 256, 56, 56]" = convolution_backward_312[0]
    getitem_1587: "f32[64, 256, 1, 1]" = convolution_backward_312[1];  convolution_backward_312 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:180, code: x = self.conv1(x)
    add_2099: "f32[8, 256, 56, 56]" = torch.ops.aten.add.Tensor(where_270, getitem_1586);  where_270 = getitem_1586 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:202, code: x = self.act3(x)
    le_273: "b8[8, 256, 56, 56]" = torch.ops.aten.le.Scalar(relu_10, 0);  relu_10 = None
    where_273: "f32[8, 256, 56, 56]" = torch.ops.aten.where.self(le_273, full_default, add_2099);  le_273 = add_2099 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:191, code: x = self.bn3(x)
    sum_628: "f32[256]" = torch.ops.aten.sum.dim_IntList(where_273, [0, 2, 3])
    sub_1577: "f32[8, 256, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_11, unsqueeze_5089);  convolution_11 = unsqueeze_5089 = None
    mul_5216: "f32[8, 256, 56, 56]" = torch.ops.aten.mul.Tensor(where_273, sub_1577)
    sum_629: "f32[256]" = torch.ops.aten.sum.dim_IntList(mul_5216, [0, 2, 3]);  mul_5216 = None
    mul_5217: "f32[256]" = torch.ops.aten.mul.Tensor(sum_628, 3.985969387755102e-05)
    unsqueeze_5090: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_5217, 0);  mul_5217 = None
    unsqueeze_5091: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5090, 2);  unsqueeze_5090 = None
    unsqueeze_5092: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5091, 3);  unsqueeze_5091 = None
    mul_5218: "f32[256]" = torch.ops.aten.mul.Tensor(sum_629, 3.985969387755102e-05)
    mul_5219: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_34, squeeze_34)
    mul_5220: "f32[256]" = torch.ops.aten.mul.Tensor(mul_5218, mul_5219);  mul_5218 = mul_5219 = None
    unsqueeze_5093: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_5220, 0);  mul_5220 = None
    unsqueeze_5094: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5093, 2);  unsqueeze_5093 = None
    unsqueeze_5095: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5094, 3);  unsqueeze_5094 = None
    mul_5221: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_34, primals_35);  primals_35 = None
    unsqueeze_5096: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_5221, 0);  mul_5221 = None
    unsqueeze_5097: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5096, 2);  unsqueeze_5096 = None
    unsqueeze_5098: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5097, 3);  unsqueeze_5097 = None
    mul_5222: "f32[8, 256, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1577, unsqueeze_5095);  sub_1577 = unsqueeze_5095 = None
    sub_1579: "f32[8, 256, 56, 56]" = torch.ops.aten.sub.Tensor(where_273, mul_5222);  mul_5222 = None
    sub_1580: "f32[8, 256, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1579, unsqueeze_5092);  sub_1579 = unsqueeze_5092 = None
    mul_5223: "f32[8, 256, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1580, unsqueeze_5098);  sub_1580 = unsqueeze_5098 = None
    mul_5224: "f32[256]" = torch.ops.aten.mul.Tensor(sum_629, squeeze_34);  sum_629 = squeeze_34 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:190, code: x = self.conv3(x)
    convolution_backward_313 = torch.ops.aten.convolution_backward.default(mul_5223, relu_9, primals_34, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5223 = primals_34 = None
    getitem_1589: "f32[8, 64, 56, 56]" = convolution_backward_313[0]
    getitem_1590: "f32[256, 64, 1, 1]" = convolution_backward_313[1];  convolution_backward_313 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:187, code: x = self.act2(x)
    le_274: "b8[8, 64, 56, 56]" = torch.ops.aten.le.Scalar(relu_9, 0);  relu_9 = None
    where_274: "f32[8, 64, 56, 56]" = torch.ops.aten.where.self(le_274, full_default, getitem_1589);  le_274 = getitem_1589 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:185, code: x = self.bn2(x)
    sum_630: "f32[64]" = torch.ops.aten.sum.dim_IntList(where_274, [0, 2, 3])
    sub_1581: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_10, unsqueeze_5101);  convolution_10 = unsqueeze_5101 = None
    mul_5225: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(where_274, sub_1581)
    sum_631: "f32[64]" = torch.ops.aten.sum.dim_IntList(mul_5225, [0, 2, 3]);  mul_5225 = None
    mul_5226: "f32[64]" = torch.ops.aten.mul.Tensor(sum_630, 3.985969387755102e-05)
    unsqueeze_5102: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5226, 0);  mul_5226 = None
    unsqueeze_5103: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5102, 2);  unsqueeze_5102 = None
    unsqueeze_5104: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5103, 3);  unsqueeze_5103 = None
    mul_5227: "f32[64]" = torch.ops.aten.mul.Tensor(sum_631, 3.985969387755102e-05)
    mul_5228: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_31, squeeze_31)
    mul_5229: "f32[64]" = torch.ops.aten.mul.Tensor(mul_5227, mul_5228);  mul_5227 = mul_5228 = None
    unsqueeze_5105: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5229, 0);  mul_5229 = None
    unsqueeze_5106: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5105, 2);  unsqueeze_5105 = None
    unsqueeze_5107: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5106, 3);  unsqueeze_5106 = None
    mul_5230: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_31, primals_32);  primals_32 = None
    unsqueeze_5108: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5230, 0);  mul_5230 = None
    unsqueeze_5109: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5108, 2);  unsqueeze_5108 = None
    unsqueeze_5110: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5109, 3);  unsqueeze_5109 = None
    mul_5231: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1581, unsqueeze_5107);  sub_1581 = unsqueeze_5107 = None
    sub_1583: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(where_274, mul_5231);  where_274 = mul_5231 = None
    sub_1584: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1583, unsqueeze_5104);  sub_1583 = unsqueeze_5104 = None
    mul_5232: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1584, unsqueeze_5110);  sub_1584 = unsqueeze_5110 = None
    mul_5233: "f32[64]" = torch.ops.aten.mul.Tensor(sum_631, squeeze_31);  sum_631 = squeeze_31 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:184, code: x = self.conv2(x)
    convolution_backward_314 = torch.ops.aten.convolution_backward.default(mul_5232, relu_8, primals_31, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5232 = primals_31 = None
    getitem_1592: "f32[8, 64, 56, 56]" = convolution_backward_314[0]
    getitem_1593: "f32[64, 64, 3, 3]" = convolution_backward_314[1];  convolution_backward_314 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:182, code: x = self.act1(x)
    le_275: "b8[8, 64, 56, 56]" = torch.ops.aten.le.Scalar(relu_8, 0);  relu_8 = None
    where_275: "f32[8, 64, 56, 56]" = torch.ops.aten.where.self(le_275, full_default, getitem_1592);  le_275 = getitem_1592 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:181, code: x = self.bn1(x)
    sum_632: "f32[64]" = torch.ops.aten.sum.dim_IntList(where_275, [0, 2, 3])
    sub_1585: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_9, unsqueeze_5113);  convolution_9 = unsqueeze_5113 = None
    mul_5234: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(where_275, sub_1585)
    sum_633: "f32[64]" = torch.ops.aten.sum.dim_IntList(mul_5234, [0, 2, 3]);  mul_5234 = None
    mul_5235: "f32[64]" = torch.ops.aten.mul.Tensor(sum_632, 3.985969387755102e-05)
    unsqueeze_5114: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5235, 0);  mul_5235 = None
    unsqueeze_5115: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5114, 2);  unsqueeze_5114 = None
    unsqueeze_5116: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5115, 3);  unsqueeze_5115 = None
    mul_5236: "f32[64]" = torch.ops.aten.mul.Tensor(sum_633, 3.985969387755102e-05)
    mul_5237: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_28, squeeze_28)
    mul_5238: "f32[64]" = torch.ops.aten.mul.Tensor(mul_5236, mul_5237);  mul_5236 = mul_5237 = None
    unsqueeze_5117: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5238, 0);  mul_5238 = None
    unsqueeze_5118: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5117, 2);  unsqueeze_5117 = None
    unsqueeze_5119: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5118, 3);  unsqueeze_5118 = None
    mul_5239: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_28, primals_29);  primals_29 = None
    unsqueeze_5120: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5239, 0);  mul_5239 = None
    unsqueeze_5121: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5120, 2);  unsqueeze_5120 = None
    unsqueeze_5122: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5121, 3);  unsqueeze_5121 = None
    mul_5240: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1585, unsqueeze_5119);  sub_1585 = unsqueeze_5119 = None
    sub_1587: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(where_275, mul_5240);  where_275 = mul_5240 = None
    sub_1588: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1587, unsqueeze_5116);  sub_1587 = unsqueeze_5116 = None
    mul_5241: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1588, unsqueeze_5122);  sub_1588 = unsqueeze_5122 = None
    mul_5242: "f32[64]" = torch.ops.aten.mul.Tensor(sum_633, squeeze_28);  sum_633 = squeeze_28 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:180, code: x = self.conv1(x)
    convolution_backward_315 = torch.ops.aten.convolution_backward.default(mul_5241, relu_7, primals_28, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5241 = primals_28 = None
    getitem_1595: "f32[8, 256, 56, 56]" = convolution_backward_315[0]
    getitem_1596: "f32[64, 256, 1, 1]" = convolution_backward_315[1];  convolution_backward_315 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:180, code: x = self.conv1(x)
    add_2100: "f32[8, 256, 56, 56]" = torch.ops.aten.add.Tensor(where_273, getitem_1595);  where_273 = getitem_1595 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:202, code: x = self.act3(x)
    le_276: "b8[8, 256, 56, 56]" = torch.ops.aten.le.Scalar(relu_7, 0);  relu_7 = None
    where_276: "f32[8, 256, 56, 56]" = torch.ops.aten.where.self(le_276, full_default, add_2100);  le_276 = add_2100 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:191, code: x = self.bn3(x)
    sum_634: "f32[256]" = torch.ops.aten.sum.dim_IntList(where_276, [0, 2, 3])
    sub_1589: "f32[8, 256, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_8, unsqueeze_5125);  convolution_8 = unsqueeze_5125 = None
    mul_5243: "f32[8, 256, 56, 56]" = torch.ops.aten.mul.Tensor(where_276, sub_1589)
    sum_635: "f32[256]" = torch.ops.aten.sum.dim_IntList(mul_5243, [0, 2, 3]);  mul_5243 = None
    mul_5244: "f32[256]" = torch.ops.aten.mul.Tensor(sum_634, 3.985969387755102e-05)
    unsqueeze_5126: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_5244, 0);  mul_5244 = None
    unsqueeze_5127: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5126, 2);  unsqueeze_5126 = None
    unsqueeze_5128: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5127, 3);  unsqueeze_5127 = None
    mul_5245: "f32[256]" = torch.ops.aten.mul.Tensor(sum_635, 3.985969387755102e-05)
    mul_5246: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_25, squeeze_25)
    mul_5247: "f32[256]" = torch.ops.aten.mul.Tensor(mul_5245, mul_5246);  mul_5245 = mul_5246 = None
    unsqueeze_5129: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_5247, 0);  mul_5247 = None
    unsqueeze_5130: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5129, 2);  unsqueeze_5129 = None
    unsqueeze_5131: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5130, 3);  unsqueeze_5130 = None
    mul_5248: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_25, primals_26);  primals_26 = None
    unsqueeze_5132: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_5248, 0);  mul_5248 = None
    unsqueeze_5133: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5132, 2);  unsqueeze_5132 = None
    unsqueeze_5134: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5133, 3);  unsqueeze_5133 = None
    mul_5249: "f32[8, 256, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1589, unsqueeze_5131);  sub_1589 = unsqueeze_5131 = None
    sub_1591: "f32[8, 256, 56, 56]" = torch.ops.aten.sub.Tensor(where_276, mul_5249);  mul_5249 = None
    sub_1592: "f32[8, 256, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1591, unsqueeze_5128);  sub_1591 = unsqueeze_5128 = None
    mul_5250: "f32[8, 256, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1592, unsqueeze_5134);  sub_1592 = unsqueeze_5134 = None
    mul_5251: "f32[256]" = torch.ops.aten.mul.Tensor(sum_635, squeeze_25);  sum_635 = squeeze_25 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:190, code: x = self.conv3(x)
    convolution_backward_316 = torch.ops.aten.convolution_backward.default(mul_5250, relu_6, primals_25, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5250 = primals_25 = None
    getitem_1598: "f32[8, 64, 56, 56]" = convolution_backward_316[0]
    getitem_1599: "f32[256, 64, 1, 1]" = convolution_backward_316[1];  convolution_backward_316 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:187, code: x = self.act2(x)
    le_277: "b8[8, 64, 56, 56]" = torch.ops.aten.le.Scalar(relu_6, 0);  relu_6 = None
    where_277: "f32[8, 64, 56, 56]" = torch.ops.aten.where.self(le_277, full_default, getitem_1598);  le_277 = getitem_1598 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:185, code: x = self.bn2(x)
    sum_636: "f32[64]" = torch.ops.aten.sum.dim_IntList(where_277, [0, 2, 3])
    sub_1593: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_7, unsqueeze_5137);  convolution_7 = unsqueeze_5137 = None
    mul_5252: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(where_277, sub_1593)
    sum_637: "f32[64]" = torch.ops.aten.sum.dim_IntList(mul_5252, [0, 2, 3]);  mul_5252 = None
    mul_5253: "f32[64]" = torch.ops.aten.mul.Tensor(sum_636, 3.985969387755102e-05)
    unsqueeze_5138: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5253, 0);  mul_5253 = None
    unsqueeze_5139: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5138, 2);  unsqueeze_5138 = None
    unsqueeze_5140: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5139, 3);  unsqueeze_5139 = None
    mul_5254: "f32[64]" = torch.ops.aten.mul.Tensor(sum_637, 3.985969387755102e-05)
    mul_5255: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_22, squeeze_22)
    mul_5256: "f32[64]" = torch.ops.aten.mul.Tensor(mul_5254, mul_5255);  mul_5254 = mul_5255 = None
    unsqueeze_5141: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5256, 0);  mul_5256 = None
    unsqueeze_5142: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5141, 2);  unsqueeze_5141 = None
    unsqueeze_5143: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5142, 3);  unsqueeze_5142 = None
    mul_5257: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_22, primals_23);  primals_23 = None
    unsqueeze_5144: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5257, 0);  mul_5257 = None
    unsqueeze_5145: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5144, 2);  unsqueeze_5144 = None
    unsqueeze_5146: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5145, 3);  unsqueeze_5145 = None
    mul_5258: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1593, unsqueeze_5143);  sub_1593 = unsqueeze_5143 = None
    sub_1595: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(where_277, mul_5258);  where_277 = mul_5258 = None
    sub_1596: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1595, unsqueeze_5140);  sub_1595 = unsqueeze_5140 = None
    mul_5259: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1596, unsqueeze_5146);  sub_1596 = unsqueeze_5146 = None
    mul_5260: "f32[64]" = torch.ops.aten.mul.Tensor(sum_637, squeeze_22);  sum_637 = squeeze_22 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:184, code: x = self.conv2(x)
    convolution_backward_317 = torch.ops.aten.convolution_backward.default(mul_5259, relu_5, primals_22, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5259 = primals_22 = None
    getitem_1601: "f32[8, 64, 56, 56]" = convolution_backward_317[0]
    getitem_1602: "f32[64, 64, 3, 3]" = convolution_backward_317[1];  convolution_backward_317 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:182, code: x = self.act1(x)
    le_278: "b8[8, 64, 56, 56]" = torch.ops.aten.le.Scalar(relu_5, 0);  relu_5 = None
    where_278: "f32[8, 64, 56, 56]" = torch.ops.aten.where.self(le_278, full_default, getitem_1601);  le_278 = getitem_1601 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:181, code: x = self.bn1(x)
    sum_638: "f32[64]" = torch.ops.aten.sum.dim_IntList(where_278, [0, 2, 3])
    sub_1597: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_6, unsqueeze_5149);  convolution_6 = unsqueeze_5149 = None
    mul_5261: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(where_278, sub_1597)
    sum_639: "f32[64]" = torch.ops.aten.sum.dim_IntList(mul_5261, [0, 2, 3]);  mul_5261 = None
    mul_5262: "f32[64]" = torch.ops.aten.mul.Tensor(sum_638, 3.985969387755102e-05)
    unsqueeze_5150: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5262, 0);  mul_5262 = None
    unsqueeze_5151: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5150, 2);  unsqueeze_5150 = None
    unsqueeze_5152: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5151, 3);  unsqueeze_5151 = None
    mul_5263: "f32[64]" = torch.ops.aten.mul.Tensor(sum_639, 3.985969387755102e-05)
    mul_5264: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_19, squeeze_19)
    mul_5265: "f32[64]" = torch.ops.aten.mul.Tensor(mul_5263, mul_5264);  mul_5263 = mul_5264 = None
    unsqueeze_5153: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5265, 0);  mul_5265 = None
    unsqueeze_5154: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5153, 2);  unsqueeze_5153 = None
    unsqueeze_5155: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5154, 3);  unsqueeze_5154 = None
    mul_5266: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_19, primals_20);  primals_20 = None
    unsqueeze_5156: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5266, 0);  mul_5266 = None
    unsqueeze_5157: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5156, 2);  unsqueeze_5156 = None
    unsqueeze_5158: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5157, 3);  unsqueeze_5157 = None
    mul_5267: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1597, unsqueeze_5155);  sub_1597 = unsqueeze_5155 = None
    sub_1599: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(where_278, mul_5267);  where_278 = mul_5267 = None
    sub_1600: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1599, unsqueeze_5152);  sub_1599 = unsqueeze_5152 = None
    mul_5268: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1600, unsqueeze_5158);  sub_1600 = unsqueeze_5158 = None
    mul_5269: "f32[64]" = torch.ops.aten.mul.Tensor(sum_639, squeeze_19);  sum_639 = squeeze_19 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:180, code: x = self.conv1(x)
    convolution_backward_318 = torch.ops.aten.convolution_backward.default(mul_5268, relu_4, primals_19, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5268 = primals_19 = None
    getitem_1604: "f32[8, 256, 56, 56]" = convolution_backward_318[0]
    getitem_1605: "f32[64, 256, 1, 1]" = convolution_backward_318[1];  convolution_backward_318 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:180, code: x = self.conv1(x)
    add_2101: "f32[8, 256, 56, 56]" = torch.ops.aten.add.Tensor(where_276, getitem_1604);  where_276 = getitem_1604 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:202, code: x = self.act3(x)
    le_279: "b8[8, 256, 56, 56]" = torch.ops.aten.le.Scalar(relu_4, 0);  relu_4 = None
    where_279: "f32[8, 256, 56, 56]" = torch.ops.aten.where.self(le_279, full_default, add_2101);  le_279 = add_2101 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:200, code: shortcut = self.downsample(shortcut)
    sum_640: "f32[256]" = torch.ops.aten.sum.dim_IntList(where_279, [0, 2, 3])
    sub_1601: "f32[8, 256, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_5, unsqueeze_5161);  convolution_5 = unsqueeze_5161 = None
    mul_5270: "f32[8, 256, 56, 56]" = torch.ops.aten.mul.Tensor(where_279, sub_1601)
    sum_641: "f32[256]" = torch.ops.aten.sum.dim_IntList(mul_5270, [0, 2, 3]);  mul_5270 = None
    mul_5271: "f32[256]" = torch.ops.aten.mul.Tensor(sum_640, 3.985969387755102e-05)
    unsqueeze_5162: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_5271, 0);  mul_5271 = None
    unsqueeze_5163: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5162, 2);  unsqueeze_5162 = None
    unsqueeze_5164: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5163, 3);  unsqueeze_5163 = None
    mul_5272: "f32[256]" = torch.ops.aten.mul.Tensor(sum_641, 3.985969387755102e-05)
    mul_5273: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_16, squeeze_16)
    mul_5274: "f32[256]" = torch.ops.aten.mul.Tensor(mul_5272, mul_5273);  mul_5272 = mul_5273 = None
    unsqueeze_5165: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_5274, 0);  mul_5274 = None
    unsqueeze_5166: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5165, 2);  unsqueeze_5165 = None
    unsqueeze_5167: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5166, 3);  unsqueeze_5166 = None
    mul_5275: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_16, primals_17);  primals_17 = None
    unsqueeze_5168: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_5275, 0);  mul_5275 = None
    unsqueeze_5169: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5168, 2);  unsqueeze_5168 = None
    unsqueeze_5170: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5169, 3);  unsqueeze_5169 = None
    mul_5276: "f32[8, 256, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1601, unsqueeze_5167);  sub_1601 = unsqueeze_5167 = None
    sub_1603: "f32[8, 256, 56, 56]" = torch.ops.aten.sub.Tensor(where_279, mul_5276);  mul_5276 = None
    sub_1604: "f32[8, 256, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1603, unsqueeze_5164);  sub_1603 = None
    mul_5277: "f32[8, 256, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1604, unsqueeze_5170);  sub_1604 = unsqueeze_5170 = None
    mul_5278: "f32[256]" = torch.ops.aten.mul.Tensor(sum_641, squeeze_16);  sum_641 = squeeze_16 = None
    convolution_backward_319 = torch.ops.aten.convolution_backward.default(mul_5277, relu_1, primals_16, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5277 = primals_16 = None
    getitem_1607: "f32[8, 64, 56, 56]" = convolution_backward_319[0]
    getitem_1608: "f32[256, 64, 1, 1]" = convolution_backward_319[1];  convolution_backward_319 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:191, code: x = self.bn3(x)
    sub_1605: "f32[8, 256, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_4, unsqueeze_5173);  convolution_4 = unsqueeze_5173 = None
    mul_5279: "f32[8, 256, 56, 56]" = torch.ops.aten.mul.Tensor(where_279, sub_1605)
    sum_643: "f32[256]" = torch.ops.aten.sum.dim_IntList(mul_5279, [0, 2, 3]);  mul_5279 = None
    mul_5281: "f32[256]" = torch.ops.aten.mul.Tensor(sum_643, 3.985969387755102e-05)
    mul_5282: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_13, squeeze_13)
    mul_5283: "f32[256]" = torch.ops.aten.mul.Tensor(mul_5281, mul_5282);  mul_5281 = mul_5282 = None
    unsqueeze_5177: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_5283, 0);  mul_5283 = None
    unsqueeze_5178: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5177, 2);  unsqueeze_5177 = None
    unsqueeze_5179: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5178, 3);  unsqueeze_5178 = None
    mul_5284: "f32[256]" = torch.ops.aten.mul.Tensor(squeeze_13, primals_14);  primals_14 = None
    unsqueeze_5180: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(mul_5284, 0);  mul_5284 = None
    unsqueeze_5181: "f32[1, 256, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5180, 2);  unsqueeze_5180 = None
    unsqueeze_5182: "f32[1, 256, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5181, 3);  unsqueeze_5181 = None
    mul_5285: "f32[8, 256, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1605, unsqueeze_5179);  sub_1605 = unsqueeze_5179 = None
    sub_1607: "f32[8, 256, 56, 56]" = torch.ops.aten.sub.Tensor(where_279, mul_5285);  where_279 = mul_5285 = None
    sub_1608: "f32[8, 256, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1607, unsqueeze_5164);  sub_1607 = unsqueeze_5164 = None
    mul_5286: "f32[8, 256, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1608, unsqueeze_5182);  sub_1608 = unsqueeze_5182 = None
    mul_5287: "f32[256]" = torch.ops.aten.mul.Tensor(sum_643, squeeze_13);  sum_643 = squeeze_13 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:190, code: x = self.conv3(x)
    convolution_backward_320 = torch.ops.aten.convolution_backward.default(mul_5286, relu_3, primals_13, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5286 = primals_13 = None
    getitem_1610: "f32[8, 64, 56, 56]" = convolution_backward_320[0]
    getitem_1611: "f32[256, 64, 1, 1]" = convolution_backward_320[1];  convolution_backward_320 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:187, code: x = self.act2(x)
    le_280: "b8[8, 64, 56, 56]" = torch.ops.aten.le.Scalar(relu_3, 0);  relu_3 = None
    where_280: "f32[8, 64, 56, 56]" = torch.ops.aten.where.self(le_280, full_default, getitem_1610);  le_280 = getitem_1610 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:185, code: x = self.bn2(x)
    sum_644: "f32[64]" = torch.ops.aten.sum.dim_IntList(where_280, [0, 2, 3])
    sub_1609: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_3, unsqueeze_5185);  convolution_3 = unsqueeze_5185 = None
    mul_5288: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(where_280, sub_1609)
    sum_645: "f32[64]" = torch.ops.aten.sum.dim_IntList(mul_5288, [0, 2, 3]);  mul_5288 = None
    mul_5289: "f32[64]" = torch.ops.aten.mul.Tensor(sum_644, 3.985969387755102e-05)
    unsqueeze_5186: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5289, 0);  mul_5289 = None
    unsqueeze_5187: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5186, 2);  unsqueeze_5186 = None
    unsqueeze_5188: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5187, 3);  unsqueeze_5187 = None
    mul_5290: "f32[64]" = torch.ops.aten.mul.Tensor(sum_645, 3.985969387755102e-05)
    mul_5291: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_10, squeeze_10)
    mul_5292: "f32[64]" = torch.ops.aten.mul.Tensor(mul_5290, mul_5291);  mul_5290 = mul_5291 = None
    unsqueeze_5189: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5292, 0);  mul_5292 = None
    unsqueeze_5190: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5189, 2);  unsqueeze_5189 = None
    unsqueeze_5191: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5190, 3);  unsqueeze_5190 = None
    mul_5293: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_10, primals_11);  primals_11 = None
    unsqueeze_5192: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5293, 0);  mul_5293 = None
    unsqueeze_5193: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5192, 2);  unsqueeze_5192 = None
    unsqueeze_5194: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5193, 3);  unsqueeze_5193 = None
    mul_5294: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1609, unsqueeze_5191);  sub_1609 = unsqueeze_5191 = None
    sub_1611: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(where_280, mul_5294);  where_280 = mul_5294 = None
    sub_1612: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1611, unsqueeze_5188);  sub_1611 = unsqueeze_5188 = None
    mul_5295: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1612, unsqueeze_5194);  sub_1612 = unsqueeze_5194 = None
    mul_5296: "f32[64]" = torch.ops.aten.mul.Tensor(sum_645, squeeze_10);  sum_645 = squeeze_10 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:184, code: x = self.conv2(x)
    convolution_backward_321 = torch.ops.aten.convolution_backward.default(mul_5295, relu_2, primals_10, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5295 = primals_10 = None
    getitem_1613: "f32[8, 64, 56, 56]" = convolution_backward_321[0]
    getitem_1614: "f32[64, 64, 3, 3]" = convolution_backward_321[1];  convolution_backward_321 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:182, code: x = self.act1(x)
    le_281: "b8[8, 64, 56, 56]" = torch.ops.aten.le.Scalar(relu_2, 0);  relu_2 = None
    where_281: "f32[8, 64, 56, 56]" = torch.ops.aten.where.self(le_281, full_default, getitem_1613);  le_281 = getitem_1613 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:181, code: x = self.bn1(x)
    sum_646: "f32[64]" = torch.ops.aten.sum.dim_IntList(where_281, [0, 2, 3])
    sub_1613: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_2, unsqueeze_5197);  convolution_2 = unsqueeze_5197 = None
    mul_5297: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(where_281, sub_1613)
    sum_647: "f32[64]" = torch.ops.aten.sum.dim_IntList(mul_5297, [0, 2, 3]);  mul_5297 = None
    mul_5298: "f32[64]" = torch.ops.aten.mul.Tensor(sum_646, 3.985969387755102e-05)
    unsqueeze_5198: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5298, 0);  mul_5298 = None
    unsqueeze_5199: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5198, 2);  unsqueeze_5198 = None
    unsqueeze_5200: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5199, 3);  unsqueeze_5199 = None
    mul_5299: "f32[64]" = torch.ops.aten.mul.Tensor(sum_647, 3.985969387755102e-05)
    mul_5300: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_7, squeeze_7)
    mul_5301: "f32[64]" = torch.ops.aten.mul.Tensor(mul_5299, mul_5300);  mul_5299 = mul_5300 = None
    unsqueeze_5201: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5301, 0);  mul_5301 = None
    unsqueeze_5202: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5201, 2);  unsqueeze_5201 = None
    unsqueeze_5203: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5202, 3);  unsqueeze_5202 = None
    mul_5302: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_7, primals_8);  primals_8 = None
    unsqueeze_5204: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5302, 0);  mul_5302 = None
    unsqueeze_5205: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5204, 2);  unsqueeze_5204 = None
    unsqueeze_5206: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5205, 3);  unsqueeze_5205 = None
    mul_5303: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1613, unsqueeze_5203);  sub_1613 = unsqueeze_5203 = None
    sub_1615: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(where_281, mul_5303);  where_281 = mul_5303 = None
    sub_1616: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1615, unsqueeze_5200);  sub_1615 = unsqueeze_5200 = None
    mul_5304: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1616, unsqueeze_5206);  sub_1616 = unsqueeze_5206 = None
    mul_5305: "f32[64]" = torch.ops.aten.mul.Tensor(sum_647, squeeze_7);  sum_647 = squeeze_7 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:180, code: x = self.conv1(x)
    convolution_backward_322 = torch.ops.aten.convolution_backward.default(mul_5304, relu_1, primals_7, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5304 = primals_7 = None
    getitem_1616: "f32[8, 64, 56, 56]" = convolution_backward_322[0]
    getitem_1617: "f32[64, 64, 1, 1]" = convolution_backward_322[1];  convolution_backward_322 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/resnet.py:180, code: x = self.conv1(x)
    add_2102: "f32[8, 64, 56, 56]" = torch.ops.aten.add.Tensor(getitem_1607, getitem_1616);  getitem_1607 = getitem_1616 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:767, code: x = self.act2(x)
    le_282: "b8[8, 64, 56, 56]" = torch.ops.aten.le.Scalar(relu_1, 0);  relu_1 = None
    where_282: "f32[8, 64, 56, 56]" = torch.ops.aten.where.self(le_282, full_default, add_2102);  le_282 = add_2102 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:766, code: x = self.bn2(x)
    sum_648: "f32[64]" = torch.ops.aten.sum.dim_IntList(where_282, [0, 2, 3])
    sub_1617: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(convolution_1, unsqueeze_5209);  convolution_1 = unsqueeze_5209 = None
    mul_5306: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(where_282, sub_1617)
    sum_649: "f32[64]" = torch.ops.aten.sum.dim_IntList(mul_5306, [0, 2, 3]);  mul_5306 = None
    mul_5307: "f32[64]" = torch.ops.aten.mul.Tensor(sum_648, 3.985969387755102e-05)
    unsqueeze_5210: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5307, 0);  mul_5307 = None
    unsqueeze_5211: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5210, 2);  unsqueeze_5210 = None
    unsqueeze_5212: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5211, 3);  unsqueeze_5211 = None
    mul_5308: "f32[64]" = torch.ops.aten.mul.Tensor(sum_649, 3.985969387755102e-05)
    mul_5309: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_4, squeeze_4)
    mul_5310: "f32[64]" = torch.ops.aten.mul.Tensor(mul_5308, mul_5309);  mul_5308 = mul_5309 = None
    unsqueeze_5213: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5310, 0);  mul_5310 = None
    unsqueeze_5214: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5213, 2);  unsqueeze_5213 = None
    unsqueeze_5215: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5214, 3);  unsqueeze_5214 = None
    mul_5311: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_4, primals_5);  primals_5 = None
    unsqueeze_5216: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5311, 0);  mul_5311 = None
    unsqueeze_5217: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5216, 2);  unsqueeze_5216 = None
    unsqueeze_5218: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5217, 3);  unsqueeze_5217 = None
    mul_5312: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1617, unsqueeze_5215);  sub_1617 = unsqueeze_5215 = None
    sub_1619: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(where_282, mul_5312);  where_282 = mul_5312 = None
    sub_1620: "f32[8, 64, 56, 56]" = torch.ops.aten.sub.Tensor(sub_1619, unsqueeze_5212);  sub_1619 = unsqueeze_5212 = None
    mul_5313: "f32[8, 64, 56, 56]" = torch.ops.aten.mul.Tensor(sub_1620, unsqueeze_5218);  sub_1620 = unsqueeze_5218 = None
    mul_5314: "f32[64]" = torch.ops.aten.mul.Tensor(sum_649, squeeze_4);  sum_649 = squeeze_4 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:765, code: x = self.conv2(x)
    convolution_backward_323 = torch.ops.aten.convolution_backward.default(mul_5313, relu, primals_4, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_5313 = primals_4 = None
    getitem_1619: "f32[8, 64, 112, 112]" = convolution_backward_323[0]
    getitem_1620: "f32[64, 64, 3, 3]" = convolution_backward_323[1];  convolution_backward_323 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:764, code: x = self.act1(x)
    le_283: "b8[8, 64, 112, 112]" = torch.ops.aten.le.Scalar(relu, 0);  relu = None
    where_283: "f32[8, 64, 112, 112]" = torch.ops.aten.where.self(le_283, full_default, getitem_1619);  le_283 = full_default = getitem_1619 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:763, code: x = self.bn1(x)
    sum_650: "f32[64]" = torch.ops.aten.sum.dim_IntList(where_283, [0, 2, 3])
    sub_1621: "f32[8, 64, 112, 112]" = torch.ops.aten.sub.Tensor(convolution, unsqueeze_5221);  convolution = unsqueeze_5221 = None
    mul_5315: "f32[8, 64, 112, 112]" = torch.ops.aten.mul.Tensor(where_283, sub_1621)
    sum_651: "f32[64]" = torch.ops.aten.sum.dim_IntList(mul_5315, [0, 2, 3]);  mul_5315 = None
    mul_5316: "f32[64]" = torch.ops.aten.mul.Tensor(sum_650, 9.964923469387754e-06)
    unsqueeze_5222: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5316, 0);  mul_5316 = None
    unsqueeze_5223: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5222, 2);  unsqueeze_5222 = None
    unsqueeze_5224: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5223, 3);  unsqueeze_5223 = None
    mul_5317: "f32[64]" = torch.ops.aten.mul.Tensor(sum_651, 9.964923469387754e-06)
    mul_5318: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_1, squeeze_1)
    mul_5319: "f32[64]" = torch.ops.aten.mul.Tensor(mul_5317, mul_5318);  mul_5317 = mul_5318 = None
    unsqueeze_5225: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5319, 0);  mul_5319 = None
    unsqueeze_5226: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5225, 2);  unsqueeze_5225 = None
    unsqueeze_5227: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5226, 3);  unsqueeze_5226 = None
    mul_5320: "f32[64]" = torch.ops.aten.mul.Tensor(squeeze_1, primals_2);  primals_2 = None
    unsqueeze_5228: "f32[1, 64]" = torch.ops.aten.unsqueeze.default(mul_5320, 0);  mul_5320 = None
    unsqueeze_5229: "f32[1, 64, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5228, 2);  unsqueeze_5228 = None
    unsqueeze_5230: "f32[1, 64, 1, 1]" = torch.ops.aten.unsqueeze.default(unsqueeze_5229, 3);  unsqueeze_5229 = None
    mul_5321: "f32[8, 64, 112, 112]" = torch.ops.aten.mul.Tensor(sub_1621, unsqueeze_5227);  sub_1621 = unsqueeze_5227 = None
    sub_1623: "f32[8, 64, 112, 112]" = torch.ops.aten.sub.Tensor(where_283, mul_5321);  where_283 = mul_5321 = None
    sub_1624: "f32[8, 64, 112, 112]" = torch.ops.aten.sub.Tensor(sub_1623, unsqueeze_5224);  sub_1623 = unsqueeze_5224 = None
    mul_5322: "f32[8, 64, 112, 112]" = torch.ops.aten.mul.Tensor(sub_1624, unsqueeze_5230);  sub_1624 = unsqueeze_5230 = None
    mul_5323: "f32[64]" = torch.ops.aten.mul.Tensor(sum_651, squeeze_1);  sum_651 = squeeze_1 = None
    
    # File: /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/timm/models/hrnet.py:762, code: x = self.conv1(x)
    convolution_backward_324 = torch.ops.aten.convolution_backward.default(mul_5322, primals_1957, primals_1, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [False, True, False]);  mul_5322 = primals_1957 = primals_1 = None
    getitem_1623: "f32[64, 3, 3, 3]" = convolution_backward_324[1];  convolution_backward_324 = None
    return [getitem_1623, mul_5323, sum_650, getitem_1620, mul_5314, sum_648, getitem_1617, mul_5305, sum_646, getitem_1614, mul_5296, sum_644, getitem_1611, mul_5287, sum_640, getitem_1608, mul_5278, sum_640, getitem_1605, mul_5269, sum_638, getitem_1602, mul_5260, sum_636, getitem_1599, mul_5251, sum_634, getitem_1596, mul_5242, sum_632, getitem_1593, mul_5233, sum_630, getitem_1590, mul_5224, sum_628, getitem_1587, mul_5215, sum_626, getitem_1584, mul_5206, sum_624, getitem_1581, mul_5197, sum_622, getitem_1578, mul_5188, sum_620, getitem_1575, mul_5179, sum_618, getitem_1572, mul_5170, sum_616, getitem_1569, mul_5161, sum_614, getitem_1566, mul_5152, sum_612, getitem_1563, mul_5143, sum_610, getitem_1560, mul_5134, sum_608, getitem_1557, mul_5125, sum_606, getitem_1554, mul_5116, sum_604, getitem_1551, mul_5107, sum_602, getitem_1548, mul_5098, sum_600, getitem_1545, mul_5089, sum_598, getitem_1542, mul_5080, sum_596, getitem_1539, mul_5071, sum_594, getitem_1536, mul_5062, sum_592, getitem_1533, mul_5053, sum_590, getitem_1530, mul_5044, sum_588, getitem_1527, mul_5035, sum_586, getitem_1524, mul_5026, sum_584, getitem_1521, mul_5017, sum_582, getitem_1518, mul_5008, sum_580, getitem_1515, mul_4999, sum_578, getitem_1512, mul_4990, sum_576, getitem_1509, mul_4981, sum_574, getitem_1506, mul_4972, sum_572, getitem_1503, mul_4963, sum_570, getitem_1500, mul_4954, sum_568, getitem_1497, mul_4945, sum_566, getitem_1494, mul_4936, sum_564, getitem_1491, mul_4927, sum_562, getitem_1488, mul_4918, sum_560, getitem_1485, mul_4909, sum_558, getitem_1482, mul_4900, sum_556, getitem_1479, mul_4891, sum_554, getitem_1476, mul_4882, sum_552, getitem_1473, mul_4873, sum_550, getitem_1470, mul_4864, sum_548, getitem_1467, mul_4855, sum_546, getitem_1464, mul_4846, sum_544, getitem_1461, mul_4837, sum_542, getitem_1458, mul_4828, sum_540, getitem_1455, mul_4819, sum_538, getitem_1452, mul_4810, sum_536, getitem_1449, mul_4801, sum_534, getitem_1446, mul_4792, sum_532, getitem_1443, mul_4783, sum_530, getitem_1440, mul_4774, sum_528, getitem_1437, mul_4765, sum_526, getitem_1434, mul_4756, sum_524, getitem_1431, mul_4747, sum_522, getitem_1428, mul_4738, sum_518, getitem_1425, mul_4729, sum_518, getitem_1422, mul_4720, sum_516, getitem_1419, mul_4711, sum_514, getitem_1416, mul_4702, sum_512, getitem_1413, mul_4693, sum_510, getitem_1410, mul_4684, sum_508, getitem_1407, mul_4675, sum_506, getitem_1404, mul_4666, sum_504, getitem_1401, mul_4657, sum_502, getitem_1398, mul_4648, sum_500, getitem_1395, mul_4639, sum_498, getitem_1392, mul_4630, sum_496, getitem_1389, mul_4621, sum_494, getitem_1386, mul_4612, sum_492, getitem_1383, mul_4603, sum_490, getitem_1380, mul_4594, sum_488, getitem_1377, mul_4585, sum_486, getitem_1374, mul_4576, sum_484, getitem_1371, mul_4567, sum_482, getitem_1368, mul_4558, sum_480, getitem_1365, mul_4549, sum_478, getitem_1362, mul_4540, sum_476, getitem_1359, mul_4531, sum_474, getitem_1356, mul_4522, sum_472, getitem_1353, mul_4513, sum_470, getitem_1350, mul_4504, sum_468, getitem_1347, mul_4495, sum_466, getitem_1344, mul_4486, sum_464, getitem_1341, mul_4477, sum_462, getitem_1338, mul_4468, sum_460, getitem_1335, mul_4459, sum_456, getitem_1332, mul_4450, sum_456, getitem_1329, mul_4441, sum_454, getitem_1326, mul_4432, sum_452, getitem_1323, mul_4423, sum_450, getitem_1320, mul_4414, sum_448, getitem_1317, mul_4405, sum_446, getitem_1314, mul_4396, sum_444, getitem_1311, mul_4387, sum_442, getitem_1308, mul_4378, sum_440, getitem_1305, mul_4369, sum_438, getitem_1302, mul_4360, sum_436, getitem_1299, mul_4351, sum_434, getitem_1296, mul_4342, sum_432, getitem_1293, mul_4333, sum_430, getitem_1290, mul_4324, sum_428, getitem_1287, mul_4315, sum_426, getitem_1284, mul_4306, sum_424, getitem_1281, mul_4297, sum_422, getitem_1278, mul_4288, sum_420, getitem_1275, mul_4279, sum_418, getitem_1272, mul_4270, sum_416, getitem_1269, mul_4261, sum_414, getitem_1266, mul_4252, sum_412, getitem_1263, mul_4243, sum_410, getitem_1260, mul_4234, sum_408, getitem_1257, mul_4225, sum_406, getitem_1254, mul_4216, sum_404, getitem_1251, mul_4207, sum_402, getitem_1248, mul_4198, sum_400, getitem_1245, mul_4189, sum_398, getitem_1242, mul_4180, sum_394, getitem_1239, mul_4171, sum_394, getitem_1236, mul_4162, sum_392, getitem_1233, mul_4153, sum_390, getitem_1230, mul_4144, sum_388, getitem_1227, mul_4135, sum_386, getitem_1224, mul_4126, sum_384, getitem_1221, mul_4117, sum_382, getitem_1218, mul_4108, sum_380, getitem_1215, mul_4099, sum_378, getitem_1212, mul_4090, sum_376, getitem_1209, mul_4081, sum_374, getitem_1206, mul_4072, sum_372, getitem_1203, mul_4063, sum_370, getitem_1200, mul_4054, sum_368, getitem_1197, mul_4045, sum_366, getitem_1194, mul_4036, sum_364, getitem_1191, mul_4027, sum_362, getitem_1188, mul_4018, sum_360, getitem_1185, mul_4009, sum_358, getitem_1182, mul_4000, sum_356, getitem_1179, mul_3991, sum_354, getitem_1176, mul_3982, sum_352, getitem_1173, mul_3973, sum_350, getitem_1170, mul_3964, sum_348, getitem_1167, mul_3955, sum_346, getitem_1164, mul_3946, sum_344, getitem_1161, mul_3937, sum_342, getitem_1158, mul_3928, sum_340, getitem_1155, mul_3919, sum_338, getitem_1152, mul_3910, sum_336, getitem_1149, mul_3901, sum_332, getitem_1146, mul_3892, sum_332, getitem_1143, mul_3883, sum_330, getitem_1140, mul_3874, sum_328, getitem_1137, mul_3865, sum_326, getitem_1134, mul_3856, sum_324, getitem_1131, mul_3847, sum_322, getitem_1128, mul_3838, sum_320, getitem_1125, mul_3829, sum_318, getitem_1122, mul_3820, sum_316, getitem_1119, mul_3811, sum_314, getitem_1116, mul_3802, sum_312, getitem_1113, mul_3793, sum_310, getitem_1110, mul_3784, sum_308, getitem_1107, mul_3775, sum_306, getitem_1104, mul_3766, sum_304, getitem_1101, mul_3757, sum_302, getitem_1098, mul_3748, sum_300, getitem_1095, mul_3739, sum_298, getitem_1092, mul_3730, sum_296, getitem_1089, mul_3721, sum_294, getitem_1086, mul_3712, sum_292, getitem_1083, mul_3703, sum_290, getitem_1080, mul_3694, sum_288, getitem_1077, mul_3685, sum_286, getitem_1074, mul_3676, sum_284, getitem_1071, mul_3667, sum_282, getitem_1068, mul_3658, sum_280, getitem_1065, mul_3649, sum_278, getitem_1062, mul_3640, sum_276, getitem_1059, mul_3631, sum_274, getitem_1056, mul_3622, sum_272, getitem_1053, mul_3613, sum_270, getitem_1050, mul_3604, sum_268, getitem_1047, mul_3595, sum_266, getitem_1044, mul_3586, sum_264, getitem_1041, mul_3577, sum_262, getitem_1038, mul_3568, sum_260, getitem_1035, mul_3559, sum_258, getitem_1032, mul_3550, sum_256, getitem_1029, mul_3541, sum_254, getitem_1026, mul_3532, sum_252, getitem_1023, mul_3523, sum_248, getitem_1020, mul_3514, sum_248, getitem_1017, mul_3505, sum_246, getitem_1014, mul_3496, sum_244, getitem_1011, mul_3487, sum_242, getitem_1008, mul_3478, sum_234, getitem_1005, mul_3469, sum_238, getitem_1002, mul_3460, sum_234, getitem_999, mul_3451, sum_234, getitem_996, mul_3442, sum_232, getitem_993, mul_3433, sum_230, getitem_990, mul_3424, sum_228, getitem_987, mul_3415, sum_226, getitem_984, mul_3406, sum_224, getitem_981, mul_3397, sum_222, getitem_978, mul_3388, sum_220, getitem_975, mul_3379, sum_218, getitem_972, mul_3370, sum_216, getitem_969, mul_3361, sum_214, getitem_966, mul_3352, sum_212, getitem_963, mul_3343, sum_210, getitem_960, mul_3334, sum_208, getitem_957, mul_3325, sum_206, getitem_954, mul_3316, sum_204, getitem_951, mul_3307, sum_202, getitem_948, mul_3298, sum_200, getitem_945, mul_3289, sum_198, getitem_942, mul_3280, sum_196, getitem_939, mul_3271, sum_194, getitem_936, mul_3262, sum_192, getitem_933, mul_3253, sum_190, getitem_930, mul_3244, sum_188, getitem_927, mul_3235, sum_186, getitem_924, mul_3226, sum_184, getitem_921, mul_3217, sum_182, getitem_918, mul_3208, sum_180, getitem_915, mul_3199, sum_178, getitem_912, mul_3190, sum_176, getitem_909, mul_3181, sum_174, getitem_906, mul_3172, sum_172, getitem_903, mul_3163, sum_170, getitem_900, mul_3154, sum_168, getitem_897, mul_3145, sum_166, getitem_894, mul_3136, sum_164, getitem_891, mul_3127, sum_162, getitem_888, mul_3118, sum_160, getitem_885, mul_3109, sum_158, getitem_882, mul_3100, sum_156, getitem_879, mul_3091, sum_152, getitem_876, mul_3082, sum_152, getitem_873, mul_3073, sum_150, getitem_870, mul_3064, sum_148, getitem_867, mul_3055, sum_146, getitem_864, mul_3046, sum_138, getitem_861, mul_3037, sum_142, getitem_858, mul_3028, sum_138, getitem_855, mul_3019, sum_138, getitem_852, mul_3010, sum_136, getitem_849, mul_3001, sum_134, getitem_846, mul_2992, sum_132, getitem_843, mul_2983, sum_130, getitem_840, mul_2974, sum_128, getitem_837, mul_2965, sum_126, getitem_834, mul_2956, sum_124, getitem_831, mul_2947, sum_122, getitem_828, mul_2938, sum_120, getitem_825, mul_2929, sum_118, getitem_822, mul_2920, sum_116, getitem_819, mul_2911, sum_114, getitem_816, mul_2902, sum_112, getitem_813, mul_2893, sum_110, getitem_810, mul_2884, sum_108, getitem_807, mul_2875, sum_106, getitem_804, mul_2866, sum_104, getitem_801, mul_2857, sum_102, getitem_798, mul_2848, sum_100, getitem_795, mul_2839, sum_98, getitem_792, mul_2830, sum_96, getitem_789, mul_2821, sum_94, getitem_786, mul_2812, sum_92, getitem_783, mul_2803, sum_90, getitem_780, mul_2794, sum_88, getitem_777, mul_2785, sum_86, getitem_774, mul_2776, sum_84, getitem_771, mul_2767, sum_82, getitem_768, mul_2758, sum_80, getitem_765, mul_2749, sum_78, getitem_762, mul_2740, sum_76, getitem_759, mul_2731, sum_74, getitem_756, mul_2722, sum_72, getitem_753, mul_2713, sum_70, getitem_750, mul_2704, sum_68, getitem_747, mul_2695, sum_66, getitem_744, mul_2686, sum_64, getitem_741, mul_2677, sum_62, getitem_738, mul_2668, sum_60, getitem_735, mul_2659, sum_56, getitem_732, mul_2650, sum_56, getitem_729, mul_2641, sum_54, getitem_726, mul_2632, sum_52, getitem_723, mul_2623, sum_50, getitem_720, mul_2614, sum_42, getitem_717, mul_2605, sum_46, getitem_714, mul_2596, sum_42, getitem_711, mul_2587, sum_42, getitem_708, mul_2578, sum_40, getitem_705, mul_2569, sum_38, getitem_702, mul_2560, sum_34, getitem_699, mul_2551, sum_34, getitem_696, mul_2542, sum_32, getitem_693, mul_2533, sum_30, getitem_690, mul_2524, sum_26, getitem_687, mul_2515, sum_26, getitem_684, getitem_685, mul_2506, sum_24, getitem_681, mul_2497, sum_22, getitem_678, mul_2488, sum_20, getitem_675, mul_2479, sum_16, getitem_672, mul_2470, sum_16, getitem_669, getitem_670, mul_2461, sum_14, getitem_666, mul_2452, sum_12, getitem_663, mul_2443, sum_10, getitem_660, mul_2434, sum_6, getitem_657, mul_2425, sum_6, getitem_654, getitem_655, mul_2416, sum_4, getitem_651, getitem_652, mul_2407, sum_2, permute_4, view_1, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]
    