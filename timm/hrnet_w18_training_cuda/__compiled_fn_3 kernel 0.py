
from ctypes import c_void_p, c_long
import torch
import math
import random
import os
import tempfile
from math import inf, nan
from torch._inductor.hooks import run_intermediate_hooks
from torch._inductor.utils import maybe_profile
from torch._inductor.codegen.memory_planning import _align as align

from torch import device, empty, empty_strided
from torch._inductor.codecache import AsyncCompile
from torch._inductor.select_algorithm import extern_kernels

aten = torch.ops.aten
inductor_ops = torch.ops.inductor
assert_size_stride = torch._C._dynamo.guards.assert_size_stride
alloc_from_pool = torch.ops.inductor._alloc_from_pool
reinterpret_tensor = torch.ops.inductor._reinterpret_tensor
async_compile = AsyncCompile()


# kernel path: /tmp/torchinductor_youkaichao/cx/ccx7xbhxmbqep7kdwzfoge3fu7arpi53l4bjepquecwvapm2ibzw.py
# Source Nodes: [x_1], Original ATen: [aten._native_batch_norm_legit_functional]
# x_1 => var_mean
triton_red_fused__native_batch_norm_legit_functional_0 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[1024, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_0', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 832
    rnumel = 7720
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 13
    x1 = (xindex // 13)
    tmp15_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp15_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    x3 = xindex
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = r2 + (7720*x0)
        tmp1 = tl.full([1, 1], 100352, tl.int32)
        tmp2 = tmp0 < tmp1
        tmp3 = tl.load(in_ptr0 + ((12544*x1) + (802816*(((r2 + (7720*x0)) // 12544) % 8)) + ((r2 + (7720*x0)) % 12544)), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp4 = tl.full(tmp3.shape, 0, tmp3.dtype)
        tmp5 = tl.where(tmp2, tmp3, tmp4)
        tmp6 = 0.0
        tmp7 = tl.full(tmp6.shape, 0, tmp6.dtype)
        tmp8 = tl.where(tmp2, tmp6, tmp7)
        tmp9 = 1.0
        tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
        tmp11 = tl.where(tmp2, tmp9, tmp10)
        tmp12 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
        tmp13 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
        tmp14 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_combine(
            tmp15_mean, tmp15_m2, tmp15_weight,
            tmp12, tmp13, tmp14
        )
        tmp15_mean = tl.where(rmask & xmask, tmp15_mean_next, tmp15_mean)
        tmp15_m2 = tl.where(rmask & xmask, tmp15_m2_next, tmp15_m2)
        tmp15_weight = tl.where(rmask & xmask, tmp15_weight_next, tmp15_weight)
    tmp15_tmp, tmp16_tmp, tmp17_tmp = triton_helpers.welford(
        tmp15_mean, tmp15_m2, tmp15_weight, 1
    )
    tmp15 = tmp15_tmp[:, None]
    tmp16 = tmp16_tmp[:, None]
    tmp17 = tmp17_tmp[:, None]
    tl.store(out_ptr0 + (x3), tmp15, xmask)
    tl.store(out_ptr1 + (x3), tmp16, xmask)
    tl.store(out_ptr2 + (x3), tmp17, xmask)
''')

import triton
import triton.language as tl
from torch._inductor.triton_heuristics import grid, start_graph, end_graph
from torch._C import _cuda_getCurrentRawStream as get_cuda_stream


# kernel path: /tmp/torchinductor_youkaichao/j7/cj7577cqg4n66b3xqkcmg6a3vhwdqbcq52nfscszzitfddxwo2am.py
# Source Nodes: [x_1], Original ATen: [aten._native_batch_norm_legit_functional]
# x_1 => add_1, add_2, add_3, mul_1, mul_2, mul_3, mul_4, mul_5, rsqrt, squeeze_1, var_mean
triton_per_fused__native_batch_norm_legit_functional_1 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[64, 16],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_1', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 64
    rnumel = 13
    RBLOCK: tl.constexpr = 16
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (13*x0)), rmask & xmask, other=0.0)
    tmp1 = tl.load(in_ptr1 + (r1 + (13*x0)), rmask & xmask, other=0.0)
    tmp2 = tl.load(in_ptr2 + (r1 + (13*x0)), rmask & xmask, other=0.0)
    tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
    tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
    tmp7 = tl.where(rmask & xmask, tmp3, 0)
    tmp8 = tl.where(rmask & xmask, tmp4, 0)
    tmp9 = tl.where(rmask & xmask, tmp5, 0)
    tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
    tmp13 = tmp10[:, None]
    tmp14 = tmp11[:, None]
    tmp15 = tmp12[:, None]
    tmp16 = 100352.0
    tmp17 = tmp14 / tmp16
    tmp18 = 1e-05
    tmp19 = tmp17 + tmp18
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = 0.1
    tmp22 = tmp13 * tmp21
    tmp24 = 0.9
    tmp25 = tmp23 * tmp24
    tmp26 = tmp22 + tmp25
    tmp27 = 1.00000996502277
    tmp28 = tmp17 * tmp27
    tmp29 = tmp28 * tmp21
    tmp31 = tmp30 * tmp24
    tmp32 = tmp29 + tmp31
    tl.store(out_ptr2 + (x0), tmp20, xmask)
    tl.store(out_ptr4 + (x0), tmp26, xmask)
    tl.store(out_ptr6 + (x0), tmp32, xmask)
    tl.store(out_ptr0 + (x0), tmp13, xmask)
    tl.store(out_ptr1 + (x0), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/7y/c7ylhig4hyzsq4bww3ib2lx7xey7cwthx3cxpj4dxnottbujjgx5.py
# Source Nodes: [x_1, x_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# x_1 => add_1, add_4, mul, mul_6, rsqrt, sub, var_mean
# x_2 => relu
triton_poi_fused__native_batch_norm_legit_functional_relu_2 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_2', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6422528
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 12544) % 64
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 100352.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x3), tmp14, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/t7/ct7w74abvron55suhpktnfssqm2xjyze3oayjm7qakswbixs7zr7.py
# Source Nodes: [x_4], Original ATen: [aten._native_batch_norm_legit_functional]
# x_4 => var_mean_1
triton_red_fused__native_batch_norm_legit_functional_3 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[256, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_3', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 256
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 64
    x1 = (xindex // 64)
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    x3 = xindex
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + ((3136*x0) + (200704*(r2 // 3136)) + (401408*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x3), tmp2, xmask)
    tl.store(out_ptr1 + (x3), tmp3, xmask)
    tl.store(out_ptr2 + (x3), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/g6/cg6uyjpbxhhbct7kb6rvpawaamsya3wruczx2d7kbp4zgbgl7a6i.py
# Source Nodes: [x_4], Original ATen: [aten._native_batch_norm_legit_functional]
# x_4 => add_6, add_7, add_8, mul_10, mul_11, mul_12, mul_8, mul_9, rsqrt_1, squeeze_4, var_mean_1
triton_per_fused__native_batch_norm_legit_functional_4 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[64, 4],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_4', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 64
    rnumel = 4
    RBLOCK: tl.constexpr = 4
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
    tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0.0)
    tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0.0)
    tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
    tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
    tmp7 = tl.where(rmask & xmask, tmp3, 0)
    tmp8 = tl.where(rmask & xmask, tmp4, 0)
    tmp9 = tl.where(rmask & xmask, tmp5, 0)
    tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
    tmp13 = tmp10[:, None]
    tmp14 = tmp11[:, None]
    tmp15 = tmp12[:, None]
    tmp16 = 25088.0
    tmp17 = tmp14 / tmp16
    tmp18 = 1e-05
    tmp19 = tmp17 + tmp18
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = 0.1
    tmp22 = tmp13 * tmp21
    tmp24 = 0.9
    tmp25 = tmp23 * tmp24
    tmp26 = tmp22 + tmp25
    tmp27 = 1.0000398612827361
    tmp28 = tmp17 * tmp27
    tmp29 = tmp28 * tmp21
    tmp31 = tmp30 * tmp24
    tmp32 = tmp29 + tmp31
    tl.store(out_ptr2 + (x0), tmp20, xmask)
    tl.store(out_ptr4 + (x0), tmp26, xmask)
    tl.store(out_ptr6 + (x0), tmp32, xmask)
    tl.store(out_ptr0 + (x0), tmp13, xmask)
    tl.store(out_ptr1 + (x0), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/bb/cbbtk3vszjxqagssql6ykhpojiw36jyl7n42m2ptkwejszndpwm7.py
# Source Nodes: [shortcut, x_4], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# shortcut => relu_1
# x_4 => add_6, add_9, mul_13, mul_7, rsqrt_1, sub_1, var_mean_1
triton_poi_fused__native_batch_norm_legit_functional_relu_5 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2097152], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_5', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 1605632
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 64
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 25088.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x3), tmp14, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/so/cso5lohapvutzsgdtlpyc3jyvihuvoxef52xck554wfdxetfjh7e.py
# Source Nodes: [x_15], Original ATen: [aten._native_batch_norm_legit_functional]
# x_15 => add_21, add_22, add_23, mul_29, mul_30, mul_31, mul_32, mul_33, rsqrt_4, squeeze_13, var_mean_4
triton_red_fused__native_batch_norm_legit_functional_6 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[256, 32768],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_6', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 256
    rnumel = 25088
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 3136
        r2 = (rindex // 3136)
        tmp0 = tl.load(in_ptr0 + (r1 + (3136*x0) + (802816*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tl.store(out_ptr1 + (x0), tmp3, xmask)
    tmp12 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp5 = 25088.0
    tmp6 = tmp3 / tmp5
    tmp7 = 1e-05
    tmp8 = tmp6 + tmp7
    tmp9 = tl.math.rsqrt(tmp8)
    tmp10 = 0.1
    tmp11 = tmp2 * tmp10
    tmp13 = 0.9
    tmp14 = tmp12 * tmp13
    tmp15 = tmp11 + tmp14
    tmp16 = 1.0000398612827361
    tmp17 = tmp6 * tmp16
    tmp18 = tmp17 * tmp10
    tmp20 = tmp19 * tmp13
    tmp21 = tmp18 + tmp20
    tl.store(out_ptr2 + (x0), tmp9, xmask)
    tl.store(out_ptr4 + (x0), tmp15, xmask)
    tl.store(out_ptr6 + (x0), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/j2/cj2afz65z742uhlpp4xec3alddzvbdg2dkiswzzyai7dgnparbwl.py
# Source Nodes: [shortcut_1, shortcut_2, x_15, x_16], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
# shortcut_1 => add_26, add_29, mul_35, mul_41, rsqrt_5, sub_5, var_mean_5
# shortcut_2 => relu_4
# x_15 => add_21, add_24, mul_28, mul_34, rsqrt_4, sub_4, var_mean_4
# x_16 => add_30
triton_poi_fused__native_batch_norm_legit_functional_add_relu_7 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_7', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6422528
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 256
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x3), None)
    tmp15 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x1), None, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x1), None, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 25088.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp13 + tmp25
    tmp27 = triton_helpers.maximum(0, tmp26)
    tl.store(in_out_ptr0 + (x3), tmp27, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/hb/chbrvbtsatibbzmc5dfhill633m3lzlzbqqffqtthh7itp4ikezn.py
# Source Nodes: [shortcut_3, x_27, x_28], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
# shortcut_3 => relu_7
# x_27 => add_42, add_45, mul_56, mul_62, rsqrt_8, sub_8, var_mean_8
# x_28 => add_46
triton_poi_fused__native_batch_norm_legit_functional_add_relu_8 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_8', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6422528
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 256
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x3), None)
    tmp2 = tmp0 - tmp1
    tmp4 = 25088.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp16 = triton_helpers.maximum(0, tmp15)
    tl.store(out_ptr0 + (x3), tmp16, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/dp/cdpubeais5rjszy2bl3dwvlq7toiyzp6so3ybudcgjofnbu4jykb.py
# Source Nodes: [l__mod___transition1_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
# l__mod___transition1_0_1 => var_mean_15
triton_red_fused__native_batch_norm_legit_functional_9 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_9', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 72
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 18
    x1 = (xindex // 18)
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    x3 = xindex
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + ((3136*x0) + (56448*(r2 // 3136)) + (112896*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x3), tmp2, xmask)
    tl.store(out_ptr1 + (x3), tmp3, xmask)
    tl.store(out_ptr2 + (x3), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/mb/cmbfb5ehoxax6xfp7o2fj5v5xeid55dkyspiwgek66d7nppqqyk7.py
# Source Nodes: [l__mod___transition1_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
# l__mod___transition1_0_1 => add_80, add_81, add_82, mul_106, mul_107, mul_108, mul_109, mul_110, rsqrt_15, squeeze_46, var_mean_15
triton_per_fused__native_batch_norm_legit_functional_10 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[32, 4],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_10', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 18
    rnumel = 4
    RBLOCK: tl.constexpr = 4
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (18*r1)), rmask & xmask, other=0.0)
    tmp1 = tl.load(in_ptr1 + (x0 + (18*r1)), rmask & xmask, other=0.0)
    tmp2 = tl.load(in_ptr2 + (x0 + (18*r1)), rmask & xmask, other=0.0)
    tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
    tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
    tmp7 = tl.where(rmask & xmask, tmp3, 0)
    tmp8 = tl.where(rmask & xmask, tmp4, 0)
    tmp9 = tl.where(rmask & xmask, tmp5, 0)
    tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
    tmp13 = tmp10[:, None]
    tmp14 = tmp11[:, None]
    tmp15 = tmp12[:, None]
    tmp16 = 25088.0
    tmp17 = tmp14 / tmp16
    tmp18 = 1e-05
    tmp19 = tmp17 + tmp18
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = 0.1
    tmp22 = tmp13 * tmp21
    tmp24 = 0.9
    tmp25 = tmp23 * tmp24
    tmp26 = tmp22 + tmp25
    tmp27 = 1.0000398612827361
    tmp28 = tmp17 * tmp27
    tmp29 = tmp28 * tmp21
    tmp31 = tmp30 * tmp24
    tmp32 = tmp29 + tmp31
    tl.store(out_ptr2 + (x0), tmp20, xmask)
    tl.store(out_ptr4 + (x0), tmp26, xmask)
    tl.store(out_ptr6 + (x0), tmp32, xmask)
    tl.store(out_ptr0 + (x0), tmp13, xmask)
    tl.store(out_ptr1 + (x0), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ta/ctauxr3ta3ht2hvroj3c4rfacwk4dpoagtli2e75m3c6saexqx3w.py
# Source Nodes: [l__mod___transition1_0_1, shortcut_5], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# l__mod___transition1_0_1 => add_80, add_83, mul_105, mul_111, rsqrt_15, sub_15, var_mean_15
# shortcut_5 => relu_14
triton_poi_fused__native_batch_norm_legit_functional_relu_11 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_11', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 18
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 25088.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x3), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/fl/cflxny3r6av4vpxkcdaa364gzsblkjjmlsgliwut6qsth64znthu.py
# Source Nodes: [l__mod___transition1_1_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
# l__mod___transition1_1_0_1 => add_85, add_86, add_87, mul_113, mul_114, mul_115, mul_116, mul_117, rsqrt_16, squeeze_49, var_mean_16
triton_red_fused__native_batch_norm_legit_functional_12 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[64, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_12', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 36
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 784
        r2 = (rindex // 784)
        tmp0 = tl.load(in_ptr0 + (r1 + (784*x0) + (28224*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tl.store(out_ptr1 + (x0), tmp3, xmask)
    tmp12 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp5 = 6272.0
    tmp6 = tmp3 / tmp5
    tmp7 = 1e-05
    tmp8 = tmp6 + tmp7
    tmp9 = tl.math.rsqrt(tmp8)
    tmp10 = 0.1
    tmp11 = tmp2 * tmp10
    tmp13 = 0.9
    tmp14 = tmp12 * tmp13
    tmp15 = tmp11 + tmp14
    tmp16 = 1.0001594642002871
    tmp17 = tmp6 * tmp16
    tmp18 = tmp17 * tmp10
    tmp20 = tmp19 * tmp13
    tmp21 = tmp18 + tmp20
    tl.store(out_ptr2 + (x0), tmp9, xmask)
    tl.store(out_ptr4 + (x0), tmp15, xmask)
    tl.store(out_ptr6 + (x0), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/7e/c7ebid7vw23cjthdvvypuv2a623w4ch5hlmx2n7vzanevpepn5df.py
# Source Nodes: [l__mod___transition1_1_0_1, shortcut_9], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# l__mod___transition1_1_0_1 => add_85, add_88, mul_112, mul_118, rsqrt_16, sub_16, var_mean_16
# shortcut_9 => relu_15
triton_poi_fused__native_batch_norm_legit_functional_relu_13 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_13', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 225792
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 784) % 36
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 6272.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x3), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/dc/cdcceu32nrj7k6cg3p64fi2xf5n2rlpalbpcfkvasx3orr7spk53.py
# Source Nodes: [shortcut_6, x_60, x_61], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
# shortcut_6 => relu_17
# x_60 => add_95, add_98, mul_126, mul_132, rsqrt_18, sub_18, var_mean_18
# x_61 => add_99
triton_poi_fused__native_batch_norm_legit_functional_add_relu_14 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_14', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 18
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x3), xmask)
    tmp2 = tmp0 - tmp1
    tmp4 = 25088.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp16 = triton_helpers.maximum(0, tmp15)
    tl.store(out_ptr0 + (x3), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/rz/crzy4dqp4py4eejraa2nqtldpapxnkqd5mqzptlxuzj4uwm22cop.py
# Source Nodes: [shortcut_10, x_96, x_97], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
# shortcut_10 => relu_25
# x_96 => add_139, add_142, mul_182, mul_188, rsqrt_26, sub_26, var_mean_26
# x_97 => add_143
triton_poi_fused__native_batch_norm_legit_functional_add_relu_15 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_15', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 225792
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 784) % 36
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x3), xmask)
    tmp2 = tmp0 - tmp1
    tmp4 = 6272.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp16 = triton_helpers.maximum(0, tmp15)
    tl.store(out_ptr0 + (x3), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ze/cze53tlc5x2vyhheed6mnagpa4d4orlbepvjfwchpi3igmy75urs.py
# Source Nodes: [l__mod___stage2_0_fuse_layers_0_1_1], Original ATen: [aten._native_batch_norm_legit_functional]
# l__mod___stage2_0_fuse_layers_0_1_1 => add_178, add_179, add_180, mul_232, mul_233, mul_234, mul_235, mul_236, rsqrt_33, squeeze_100, var_mean_33
triton_red_fused__native_batch_norm_legit_functional_16 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[32, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_16', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 18
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 784
        r2 = (rindex // 784)
        tmp0 = tl.load(in_ptr0 + (r1 + (784*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tl.store(out_ptr1 + (x0), tmp3, xmask)
    tmp12 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp5 = 6272.0
    tmp6 = tmp3 / tmp5
    tmp7 = 1e-05
    tmp8 = tmp6 + tmp7
    tmp9 = tl.math.rsqrt(tmp8)
    tmp10 = 0.1
    tmp11 = tmp2 * tmp10
    tmp13 = 0.9
    tmp14 = tmp12 * tmp13
    tmp15 = tmp11 + tmp14
    tmp16 = 1.0001594642002871
    tmp17 = tmp6 * tmp16
    tmp18 = tmp17 * tmp10
    tmp20 = tmp19 * tmp13
    tmp21 = tmp18 + tmp20
    tl.store(out_ptr2 + (x0), tmp9, xmask)
    tl.store(out_ptr4 + (x0), tmp15, xmask)
    tl.store(out_ptr6 + (x0), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/vq/cvq3cbqfvsl6ld65xjmob4nsxx55kxmsb6ilz75zq4xnjdobr4gm.py
# Source Nodes: [l__mod___stage2_0_fuse_layers_0_1_2], Original ATen: [aten._to_copy, aten.add, aten.arange, aten.mul]
# l__mod___stage2_0_fuse_layers_0_1_2 => add_182, add_183, convert_element_type, convert_element_type_1, iota, mul_238, mul_239
triton_poi_fused__to_copy_add_arange_mul_17 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[64], 
    filename=__file__,
    triton_meta={'signature': {0: '*i64', 1: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0,), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(1,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_mul_17', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = x0
    tmp1 = tmp0.to(tl.float32)
    tmp2 = 1.0
    tmp3 = tmp1 * tmp2
    tmp4 = 0.0
    tmp5 = tmp3 + tmp4
    tmp6 = tmp5 + tmp4
    tmp7 = 0.5
    tmp8 = tmp6 * tmp7
    tmp9 = tmp8.to(tl.int32)
    tl.store(out_ptr0 + (x0), tmp9, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/s2/cs2h43qponag5z74dgobocvspkcruy2tlmoiofsqlmswz44a34mh.py
# Source Nodes: [l__mod___stage2_0_fuse_layers_0_1_1, l__mod___stage2_0_fuse_layers_0_1_2, shortcut_13, x_87, x_88, x_89, y_1], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
# l__mod___stage2_0_fuse_layers_0_1_1 => add_178, add_181, mul_231, mul_237, rsqrt_33, sub_33, var_mean_33
# l__mod___stage2_0_fuse_layers_0_1_2 => _unsafe_index
# shortcut_13 => relu_32
# x_87 => add_128, add_131, mul_168, mul_174, rsqrt_24, sub_24, var_mean_24
# x_88 => add_132
# x_89 => relu_23
# y_1 => add_186
triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_18 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*i64', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(14,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_18', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 18
    x5 = (xindex // 56) % 56
    x4 = xindex % 56
    x6 = (xindex // 3136)
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x3), xmask)
    tmp17 = tl.load(in_ptr6 + (x5), xmask, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr6 + (x4), xmask, eviction_policy='evict_last')
    tmp26 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp28 = tl.load(in_ptr9 + (x1), xmask, eviction_policy='evict_last')
    tmp34 = tl.load(in_ptr10 + (x1), xmask, eviction_policy='evict_last')
    tmp36 = tl.load(in_ptr11 + (x1), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 25088.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp16 = triton_helpers.maximum(0, tmp15)
    tmp18 = tmp17 + 28
    tmp19 = tmp17 < 0
    tmp20 = tl.where(tmp19, tmp18, tmp17)
    tmp22 = tmp21 + 28
    tmp23 = tmp21 < 0
    tmp24 = tl.where(tmp23, tmp22, tmp21)
    tmp25 = tl.load(in_ptr7 + (tmp24 + (28*tmp20) + (784*x6)), xmask, eviction_policy='evict_last')
    tmp27 = tmp25 - tmp26
    tmp29 = 6272.0
    tmp30 = tmp28 / tmp29
    tmp31 = tmp30 + tmp6
    tmp32 = tl.math.rsqrt(tmp31)
    tmp33 = tmp27 * tmp32
    tmp35 = tmp33 * tmp34
    tmp37 = tmp35 + tmp36
    tmp38 = tmp16 + tmp37
    tmp39 = triton_helpers.maximum(0, tmp38)
    tl.store(out_ptr0 + (x3), tmp16, xmask)
    tl.store(out_ptr1 + (x3), tmp39, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/fj/cfjxueafyhkaljeipadq7yl3ofcwn3on5jtqydckp6omgjgk3764.py
# Source Nodes: [l__mod___transition2_2_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
# l__mod___transition2_2_0_1 => add_194, add_195, add_196, mul_250, mul_251, mul_252, mul_253, mul_254, rsqrt_35, squeeze_106, var_mean_35
triton_red_fused__native_batch_norm_legit_functional_19 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_19', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 72
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tl.store(out_ptr1 + (x0), tmp3, xmask)
    tmp12 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp5 = 1568.0
    tmp6 = tmp3 / tmp5
    tmp7 = 1e-05
    tmp8 = tmp6 + tmp7
    tmp9 = tl.math.rsqrt(tmp8)
    tmp10 = 0.1
    tmp11 = tmp2 * tmp10
    tmp13 = 0.9
    tmp14 = tmp12 * tmp13
    tmp15 = tmp11 + tmp14
    tmp16 = 1.0006381620931717
    tmp17 = tmp6 * tmp16
    tmp18 = tmp17 * tmp10
    tmp20 = tmp19 * tmp13
    tmp21 = tmp18 + tmp20
    tl.store(out_ptr2 + (x0), tmp9, xmask)
    tl.store(out_ptr4 + (x0), tmp15, xmask)
    tl.store(out_ptr6 + (x0), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/bh/cbhbg72wxggke5wq7ymqcyyakbuz2dskhdroluqbsyfk4wzsy75x.py
# Source Nodes: [l__mod___transition2_2_0_1, shortcut_21], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# l__mod___transition2_2_0_1 => add_194, add_197, mul_249, mul_255, rsqrt_35, sub_35, var_mean_35
# shortcut_21 => relu_34
triton_poi_fused__native_batch_norm_legit_functional_relu_20 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_20', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 72
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 1568.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x3), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/fy/cfyfjr5zev6jonew7ryal7giyzhufiycc56yvw5pt2pm4v3h3qgc.py
# Source Nodes: [shortcut_22, x_204, x_205], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
# shortcut_22 => relu_52
# x_204 => add_292, add_295, mul_375, mul_381, rsqrt_53, sub_53, var_mean_53
# x_205 => add_296
triton_poi_fused__native_batch_norm_legit_functional_add_relu_21 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_21', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 72
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x3), xmask)
    tmp2 = tmp0 - tmp1
    tmp4 = 1568.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp16 = triton_helpers.maximum(0, tmp15)
    tl.store(out_ptr0 + (x3), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/sl/cslpawdlhku32mam7esg4j2scwefbregx42stv5wxz5kqnhc7aiy.py
# Source Nodes: [l__mod___stage3_0_fuse_layers_0_2_1], Original ATen: [aten._native_batch_norm_legit_functional]
# l__mod___stage3_0_fuse_layers_0_2_1 => add_341, add_342, add_343, mul_436, mul_437, mul_438, mul_439, mul_440, rsqrt_61, squeeze_184, var_mean_61
triton_red_fused__native_batch_norm_legit_functional_22 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[32, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_22', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 18
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (3528*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tl.store(out_ptr1 + (x0), tmp3, xmask)
    tmp12 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp5 = 1568.0
    tmp6 = tmp3 / tmp5
    tmp7 = 1e-05
    tmp8 = tmp6 + tmp7
    tmp9 = tl.math.rsqrt(tmp8)
    tmp10 = 0.1
    tmp11 = tmp2 * tmp10
    tmp13 = 0.9
    tmp14 = tmp12 * tmp13
    tmp15 = tmp11 + tmp14
    tmp16 = 1.0006381620931717
    tmp17 = tmp6 * tmp16
    tmp18 = tmp17 * tmp10
    tmp20 = tmp19 * tmp13
    tmp21 = tmp18 + tmp20
    tl.store(out_ptr2 + (x0), tmp9, xmask)
    tl.store(out_ptr4 + (x0), tmp15, xmask)
    tl.store(out_ptr6 + (x0), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/7e/c7ebv2fxjrmytor44adrfgika4vjhomx6ozmvdsqmwr4x4baseqz.py
# Source Nodes: [l__mod___stage2_0_fuse_layers_0_1_2, l__mod___stage3_0_fuse_layers_0_2_2], Original ATen: [aten._to_copy, aten.add, aten.arange, aten.mul]
# l__mod___stage2_0_fuse_layers_0_1_2 => add_182, add_183, convert_element_type, iota, mul_238
# l__mod___stage3_0_fuse_layers_0_2_2 => convert_element_type_9, mul_443
triton_poi_fused__to_copy_add_arange_mul_23 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[64], 
    filename=__file__,
    triton_meta={'signature': {0: '*i64', 1: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0,), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(1,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_mul_23', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = x0
    tmp1 = tmp0.to(tl.float32)
    tmp2 = 1.0
    tmp3 = tmp1 * tmp2
    tmp4 = 0.0
    tmp5 = tmp3 + tmp4
    tmp6 = tmp5 + tmp4
    tmp7 = 0.25
    tmp8 = tmp6 * tmp7
    tmp9 = tmp8.to(tl.int32)
    tl.store(out_ptr0 + (x0), tmp9, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/eo/ceob5gwizmxxl7z3bclrl42lj4mefh7q2actqmftje2drcinnna6.py
# Source Nodes: [l__mod___stage3_0_fuse_layers_0_1_1, l__mod___stage3_0_fuse_layers_0_1_2, l__mod___stage3_0_fuse_layers_0_2_1, l__mod___stage3_0_fuse_layers_0_2_2, shortcut_25, x_159, x_160, x_161, y_5, y_6], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
# l__mod___stage3_0_fuse_layers_0_1_1 => add_331, add_334, mul_424, mul_430, rsqrt_60, sub_60, var_mean_60
# l__mod___stage3_0_fuse_layers_0_1_2 => _unsafe_index_1
# l__mod___stage3_0_fuse_layers_0_2_1 => add_341, add_344, mul_435, mul_441, rsqrt_61, sub_61, var_mean_61
# l__mod___stage3_0_fuse_layers_0_2_2 => _unsafe_index_2
# shortcut_25 => relu_59
# x_159 => add_237, add_240, mul_305, mul_311, rsqrt_43, sub_43, var_mean_43
# x_160 => add_241
# x_161 => relu_42
# y_5 => add_339
# y_6 => add_349
triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_24 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*i64', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*i64', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: '*fp32', 18: '*fp32', 19: '*fp32', 20: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(20,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_24', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 18
    x5 = (xindex // 56) % 56
    x4 = xindex % 56
    x6 = (xindex // 3136)
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x3), xmask)
    tmp17 = tl.load(in_ptr6 + (x5), xmask, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr6 + (x4), xmask, eviction_policy='evict_last')
    tmp26 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp28 = tl.load(in_ptr9 + (x1), xmask, eviction_policy='evict_last')
    tmp34 = tl.load(in_ptr10 + (x1), xmask, eviction_policy='evict_last')
    tmp36 = tl.load(in_ptr11 + (x1), xmask, eviction_policy='evict_last')
    tmp39 = tl.load(in_ptr12 + (x5), xmask, eviction_policy='evict_last')
    tmp43 = tl.load(in_ptr12 + (x4), xmask, eviction_policy='evict_last')
    tmp48 = tl.load(in_ptr14 + (x1), xmask, eviction_policy='evict_last')
    tmp50 = tl.load(in_ptr15 + (x1), xmask, eviction_policy='evict_last')
    tmp56 = tl.load(in_ptr16 + (x1), xmask, eviction_policy='evict_last')
    tmp58 = tl.load(in_ptr17 + (x1), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 25088.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp16 = triton_helpers.maximum(0, tmp15)
    tmp18 = tmp17 + 28
    tmp19 = tmp17 < 0
    tmp20 = tl.where(tmp19, tmp18, tmp17)
    tmp22 = tmp21 + 28
    tmp23 = tmp21 < 0
    tmp24 = tl.where(tmp23, tmp22, tmp21)
    tmp25 = tl.load(in_ptr7 + (tmp24 + (28*tmp20) + (784*x6)), xmask, eviction_policy='evict_last')
    tmp27 = tmp25 - tmp26
    tmp29 = 6272.0
    tmp30 = tmp28 / tmp29
    tmp31 = tmp30 + tmp6
    tmp32 = tl.math.rsqrt(tmp31)
    tmp33 = tmp27 * tmp32
    tmp35 = tmp33 * tmp34
    tmp37 = tmp35 + tmp36
    tmp38 = tmp16 + tmp37
    tmp40 = tmp39 + 14
    tmp41 = tmp39 < 0
    tmp42 = tl.where(tmp41, tmp40, tmp39)
    tmp44 = tmp43 + 14
    tmp45 = tmp43 < 0
    tmp46 = tl.where(tmp45, tmp44, tmp43)
    tmp47 = tl.load(in_ptr13 + (tmp46 + (14*tmp42) + (196*x6)), xmask, eviction_policy='evict_last')
    tmp49 = tmp47 - tmp48
    tmp51 = 1568.0
    tmp52 = tmp50 / tmp51
    tmp53 = tmp52 + tmp6
    tmp54 = tl.math.rsqrt(tmp53)
    tmp55 = tmp49 * tmp54
    tmp57 = tmp55 * tmp56
    tmp59 = tmp57 + tmp58
    tmp60 = tmp38 + tmp59
    tmp61 = triton_helpers.maximum(0, tmp60)
    tl.store(out_ptr0 + (x3), tmp16, xmask)
    tl.store(in_out_ptr0 + (x3), tmp61, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/zp/czpo6mewlahu6g37uozkbx2di7hta3yiobecxenc26ndza5o577z.py
# Source Nodes: [l__mod___stage3_0_fuse_layers_1_2_1], Original ATen: [aten._native_batch_norm_legit_functional]
# l__mod___stage3_0_fuse_layers_1_2_1 => add_357, add_358, add_359, mul_454, mul_455, mul_456, mul_457, mul_458, rsqrt_63, squeeze_190, var_mean_63
triton_red_fused__native_batch_norm_legit_functional_25 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[64, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_25', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 36
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (7056*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tl.store(out_ptr1 + (x0), tmp3, xmask)
    tmp12 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp5 = 1568.0
    tmp6 = tmp3 / tmp5
    tmp7 = 1e-05
    tmp8 = tmp6 + tmp7
    tmp9 = tl.math.rsqrt(tmp8)
    tmp10 = 0.1
    tmp11 = tmp2 * tmp10
    tmp13 = 0.9
    tmp14 = tmp12 * tmp13
    tmp15 = tmp11 + tmp14
    tmp16 = 1.0006381620931717
    tmp17 = tmp6 * tmp16
    tmp18 = tmp17 * tmp10
    tmp20 = tmp19 * tmp13
    tmp21 = tmp18 + tmp20
    tl.store(out_ptr2 + (x0), tmp9, xmask)
    tl.store(out_ptr4 + (x0), tmp15, xmask)
    tl.store(out_ptr6 + (x0), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/zk/czkohnrwre2ndcoxmopcxk6f4otisdofazxiwoi43ec3qojujyi6.py
# Source Nodes: [l__mod___stage3_0_fuse_layers_1_2_2], Original ATen: [aten._to_copy, aten.add, aten.arange, aten.mul]
# l__mod___stage3_0_fuse_layers_1_2_2 => add_361, add_362, convert_element_type_12, convert_element_type_13, iota_6, mul_460, mul_461
triton_poi_fused__to_copy_add_arange_mul_26 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[32], 
    filename=__file__,
    triton_meta={'signature': {0: '*i64', 1: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0,), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_mul_26', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 28
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = x0
    tmp1 = tmp0.to(tl.float32)
    tmp2 = 1.0
    tmp3 = tmp1 * tmp2
    tmp4 = 0.0
    tmp5 = tmp3 + tmp4
    tmp6 = tmp5 + tmp4
    tmp7 = 0.5
    tmp8 = tmp6 * tmp7
    tmp9 = tmp8.to(tl.int32)
    tl.store(out_ptr0 + (x0), tmp9, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/gj/cgj5oarlf4soivdoje6v2ams2htknvt3xnviccuof6omymk4aivz.py
# Source Nodes: [l__mod___stage3_0_fuse_layers_1_2_1, l__mod___stage3_0_fuse_layers_1_2_2, shortcut_29, y_7, y_8, y_9], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
# l__mod___stage3_0_fuse_layers_1_2_1 => add_357, add_360, mul_453, mul_459, rsqrt_63, sub_63, var_mean_63
# l__mod___stage3_0_fuse_layers_1_2_2 => _unsafe_index_3
# shortcut_29 => relu_60
# y_7 => add_351, add_354, mul_446, mul_452, rsqrt_62, sub_62, var_mean_62
# y_8 => add_355
# y_9 => add_365
triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_27 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*i64', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(13,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_27', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, xnumel, XBLOCK : tl.constexpr):
    xnumel = 225792
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x4 = xindex
    x2 = (xindex // 784) % 36
    x1 = (xindex // 28) % 28
    x0 = xindex % 28
    x6 = (xindex // 784)
    tmp0 = tl.load(in_ptr0 + (x4), xmask)
    tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x2), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x4), xmask)
    tmp16 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp20 = tl.load(in_ptr6 + (x0), xmask, eviction_policy='evict_last')
    tmp25 = tl.load(in_ptr8 + (x2), xmask, eviction_policy='evict_last')
    tmp27 = tl.load(in_ptr9 + (x2), xmask, eviction_policy='evict_last')
    tmp33 = tl.load(in_ptr10 + (x2), xmask, eviction_policy='evict_last')
    tmp35 = tl.load(in_ptr11 + (x2), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 6272.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp17 = tmp16 + 14
    tmp18 = tmp16 < 0
    tmp19 = tl.where(tmp18, tmp17, tmp16)
    tmp21 = tmp20 + 14
    tmp22 = tmp20 < 0
    tmp23 = tl.where(tmp22, tmp21, tmp20)
    tmp24 = tl.load(in_ptr7 + (tmp23 + (14*tmp19) + (196*x6)), xmask, eviction_policy='evict_last')
    tmp26 = tmp24 - tmp25
    tmp28 = 1568.0
    tmp29 = tmp27 / tmp28
    tmp30 = tmp29 + tmp6
    tmp31 = tl.math.rsqrt(tmp30)
    tmp32 = tmp26 * tmp31
    tmp34 = tmp32 * tmp33
    tmp36 = tmp34 + tmp35
    tmp37 = tmp15 + tmp36
    tmp38 = triton_helpers.maximum(0, tmp37)
    tl.store(in_out_ptr0 + (x4), tmp38, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ej/cejm6qfwftsvfnzkenaxbdzllthouolwtmg3sqjyjz66v7rdfhb4.py
# Source Nodes: [l__mod___stage3_0_fuse_layers_2_0_0_1, l__mod___stage3_0_fuse_layers_2_0_0_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# l__mod___stage3_0_fuse_layers_2_0_0_1 => add_367, add_370, mul_464, mul_470, rsqrt_64, sub_64, var_mean_64
# l__mod___stage3_0_fuse_layers_2_0_0_2 => relu_61
triton_poi_fused__native_batch_norm_legit_functional_relu_28 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_28', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 784) % 18
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 6272.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x3), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/hy/chy6aobqdwaivqvrcolexffeabfxixuigks5gj5nq6y47twvwp3n.py
# Source Nodes: [l__mod___stage3_0_fuse_layers_2_1_0_1, shortcut_33, y_10, y_11, y_12], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
# l__mod___stage3_0_fuse_layers_2_1_0_1 => add_377, add_380, mul_478, mul_484, rsqrt_66, sub_66, var_mean_66
# shortcut_33 => relu_62
# y_10 => add_372, add_375, mul_471, mul_477, rsqrt_65, sub_65, var_mean_65
# y_11 => add_381
# y_12 => add_382
triton_poi_fused__native_batch_norm_legit_functional_add_relu_29 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(12,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_29', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 72
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x3), xmask)
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x1), xmask, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x1), xmask, eviction_policy='evict_last')
    tmp27 = tl.load(in_ptr10 + (x3), xmask)
    tmp2 = tmp0 - tmp1
    tmp4 = 1568.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp13 + tmp25
    tmp28 = tmp26 + tmp27
    tmp29 = triton_helpers.maximum(0, tmp28)
    tl.store(in_out_ptr0 + (x3), tmp29, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/d5/cd5u6sq5pwnvgi6crcuvtorln4xsgir2m4kpivclvo7bku2phfcc.py
# Source Nodes: [l__mod___transition3_3_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
# l__mod___transition3_3_0_1 => add_939, add_940, add_941, mul_1173, mul_1174, mul_1175, mul_1176, mul_1177, rsqrt_160, squeeze_481, var_mean_160
triton_per_fused__native_batch_norm_legit_functional_30 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[256, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_30', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel):
    xnumel = 144
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp24 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp31 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.broadcast_to(tmp1, [RBLOCK])
    tmp6 = tl.where(rmask & xmask, tmp4, 0)
    tmp7 = triton_helpers.promote_to_tensor(tl.sum(tmp6, 0))
    tmp8 = tl.full([1], 392, tl.int32)
    tmp9 = tmp8.to(tl.float32)
    tmp10 = tmp7 / tmp9
    tmp11 = tmp1 - tmp10
    tmp12 = tmp11 * tmp11
    tmp13 = tl.broadcast_to(tmp12, [RBLOCK])
    tmp15 = tl.where(rmask & xmask, tmp13, 0)
    tmp16 = triton_helpers.promote_to_tensor(tl.sum(tmp15, 0))
    tmp17 = 392.0
    tmp18 = tmp16 / tmp17
    tmp19 = 1e-05
    tmp20 = tmp18 + tmp19
    tmp21 = tl.math.rsqrt(tmp20)
    tmp22 = 0.1
    tmp23 = tmp10 * tmp22
    tmp25 = 0.9
    tmp26 = tmp24 * tmp25
    tmp27 = tmp23 + tmp26
    tmp28 = 1.0025575447570332
    tmp29 = tmp18 * tmp28
    tmp30 = tmp29 * tmp22
    tmp32 = tmp31 * tmp25
    tmp33 = tmp30 + tmp32
    tl.store(out_ptr2 + (x0), tmp21, xmask)
    tl.store(out_ptr4 + (x0), tmp27, xmask)
    tl.store(out_ptr6 + (x0), tmp33, xmask)
    tl.store(out_ptr0 + (x0), tmp10, xmask)
    tl.store(out_ptr1 + (x0), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/uz/cuzpa2uahlubv3cvboqkxzso35jyg3pplu2ccgyfkbekozmmtert.py
# Source Nodes: [l__mod___transition3_3_0_1, shortcut_73], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# l__mod___transition3_3_0_1 => add_939, add_942, mul_1172, mul_1178, rsqrt_160, sub_160, var_mean_160
# shortcut_73 => relu_147
triton_poi_fused__native_batch_norm_legit_functional_relu_31 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_31', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 144
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 392.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x3), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/s5/cs5klsdzi3lbffuw5o65wtnv3b5xjyfqw4lsp5e2rmghzcn534km.py
# Source Nodes: [shortcut_74, x_672, x_673], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
# shortcut_74 => relu_173
# x_672 => add_1081, add_1084, mul_1354, mul_1360, rsqrt_186, sub_186, var_mean_186
# x_673 => add_1085
triton_poi_fused__native_batch_norm_legit_functional_add_relu_32 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_32', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 144
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x3), xmask)
    tmp2 = tmp0 - tmp1
    tmp4 = 392.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp16 = triton_helpers.maximum(0, tmp15)
    tl.store(out_ptr0 + (x3), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ky/ckyfplvpuouhjxvzlryx77l3uib6ibzqllmzlrfqs5suqsx76anb.py
# Source Nodes: [l__mod___stage4_0_fuse_layers_0_3_1], Original ATen: [aten._native_batch_norm_legit_functional]
# l__mod___stage4_0_fuse_layers_0_3_1 => add_1140, add_1141, add_1142, mul_1426, mul_1427, mul_1428, mul_1429, mul_1430, rsqrt_195, squeeze_586, var_mean_195
triton_per_fused__native_batch_norm_legit_functional_33 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[32, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_33', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel):
    xnumel = 18
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (882*r2)), rmask & xmask, other=0.0)
    tmp24 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp31 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.broadcast_to(tmp1, [RBLOCK])
    tmp6 = tl.where(rmask & xmask, tmp4, 0)
    tmp7 = triton_helpers.promote_to_tensor(tl.sum(tmp6, 0))
    tmp8 = tl.full([1], 392, tl.int32)
    tmp9 = tmp8.to(tl.float32)
    tmp10 = tmp7 / tmp9
    tmp11 = tmp1 - tmp10
    tmp12 = tmp11 * tmp11
    tmp13 = tl.broadcast_to(tmp12, [RBLOCK])
    tmp15 = tl.where(rmask & xmask, tmp13, 0)
    tmp16 = triton_helpers.promote_to_tensor(tl.sum(tmp15, 0))
    tmp17 = 392.0
    tmp18 = tmp16 / tmp17
    tmp19 = 1e-05
    tmp20 = tmp18 + tmp19
    tmp21 = tl.math.rsqrt(tmp20)
    tmp22 = 0.1
    tmp23 = tmp10 * tmp22
    tmp25 = 0.9
    tmp26 = tmp24 * tmp25
    tmp27 = tmp23 + tmp26
    tmp28 = 1.0025575447570332
    tmp29 = tmp18 * tmp28
    tmp30 = tmp29 * tmp22
    tmp32 = tmp31 * tmp25
    tmp33 = tmp30 + tmp32
    tl.store(out_ptr2 + (x0), tmp21, xmask)
    tl.store(out_ptr4 + (x0), tmp27, xmask)
    tl.store(out_ptr6 + (x0), tmp33, xmask)
    tl.store(out_ptr0 + (x0), tmp10, xmask)
    tl.store(out_ptr1 + (x0), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/pm/cpml74sickf6eujkqyrhollulwke3mdnjbtnaoxznjryezwynqws.py
# Source Nodes: [l__mod___stage2_0_fuse_layers_0_1_2, l__mod___stage4_0_fuse_layers_0_3_2], Original ATen: [aten._to_copy, aten.add, aten.arange, aten.mul]
# l__mod___stage2_0_fuse_layers_0_1_2 => add_182, add_183, convert_element_type, iota, mul_238
# l__mod___stage4_0_fuse_layers_0_3_2 => convert_element_type_61, mul_1433
triton_poi_fused__to_copy_add_arange_mul_34 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[64], 
    filename=__file__,
    triton_meta={'signature': {0: '*i64', 1: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0,), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(1,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_mul_34', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = x0
    tmp1 = tmp0.to(tl.float32)
    tmp2 = 1.0
    tmp3 = tmp1 * tmp2
    tmp4 = 0.0
    tmp5 = tmp3 + tmp4
    tmp6 = tmp5 + tmp4
    tmp7 = 0.125
    tmp8 = tmp6 * tmp7
    tmp9 = tmp8.to(tl.int32)
    tl.store(out_ptr0 + (x0), tmp9, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/jy/cjyengvvd7zrdbz4ntq35dc4b7k7zj3lt5pufx4n7u3vu5mpwcdg.py
# Source Nodes: [l__mod___stage4_0_fuse_layers_0_1_1, l__mod___stage4_0_fuse_layers_0_1_2, l__mod___stage4_0_fuse_layers_0_2_1, l__mod___stage4_0_fuse_layers_0_2_2, l__mod___stage4_0_fuse_layers_0_3_1, l__mod___stage4_0_fuse_layers_0_3_2, shortcut_77, x_591, x_592, x_593, y_41, y_42, y_43], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
# l__mod___stage4_0_fuse_layers_0_1_1 => add_1120, add_1123, mul_1403, mul_1409, rsqrt_193, sub_193, var_mean_193
# l__mod___stage4_0_fuse_layers_0_1_2 => _unsafe_index_13
# l__mod___stage4_0_fuse_layers_0_2_1 => add_1130, add_1133, mul_1414, mul_1420, rsqrt_194, sub_194, var_mean_194
# l__mod___stage4_0_fuse_layers_0_2_2 => _unsafe_index_14
# l__mod___stage4_0_fuse_layers_0_3_1 => add_1140, add_1143, mul_1425, mul_1431, rsqrt_195, sub_195, var_mean_195
# l__mod___stage4_0_fuse_layers_0_3_2 => _unsafe_index_15
# shortcut_77 => relu_180
# x_591 => add_982, add_985, mul_1228, mul_1234, rsqrt_168, sub_168, var_mean_168
# x_592 => add_986
# x_593 => relu_155
# y_41 => add_1128
# y_42 => add_1138
# y_43 => add_1148
triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_35 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*i64', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*i64', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: '*fp32', 18: '*fp32', 19: '*i64', 20: '*fp32', 21: '*fp32', 22: '*fp32', 23: '*fp32', 24: '*fp32', 25: '*fp32', 26: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(26,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_35', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, in_ptr20, in_ptr21, in_ptr22, in_ptr23, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 18
    x5 = (xindex // 56) % 56
    x4 = xindex % 56
    x6 = (xindex // 3136)
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x3), xmask)
    tmp17 = tl.load(in_ptr6 + (x5), xmask, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr6 + (x4), xmask, eviction_policy='evict_last')
    tmp26 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp28 = tl.load(in_ptr9 + (x1), xmask, eviction_policy='evict_last')
    tmp34 = tl.load(in_ptr10 + (x1), xmask, eviction_policy='evict_last')
    tmp36 = tl.load(in_ptr11 + (x1), xmask, eviction_policy='evict_last')
    tmp39 = tl.load(in_ptr12 + (x5), xmask, eviction_policy='evict_last')
    tmp43 = tl.load(in_ptr12 + (x4), xmask, eviction_policy='evict_last')
    tmp48 = tl.load(in_ptr14 + (x1), xmask, eviction_policy='evict_last')
    tmp50 = tl.load(in_ptr15 + (x1), xmask, eviction_policy='evict_last')
    tmp56 = tl.load(in_ptr16 + (x1), xmask, eviction_policy='evict_last')
    tmp58 = tl.load(in_ptr17 + (x1), xmask, eviction_policy='evict_last')
    tmp61 = tl.load(in_ptr18 + (x5), xmask, eviction_policy='evict_last')
    tmp65 = tl.load(in_ptr18 + (x4), xmask, eviction_policy='evict_last')
    tmp70 = tl.load(in_ptr20 + (x1), xmask, eviction_policy='evict_last')
    tmp72 = tl.load(in_ptr21 + (x1), xmask, eviction_policy='evict_last')
    tmp78 = tl.load(in_ptr22 + (x1), xmask, eviction_policy='evict_last')
    tmp80 = tl.load(in_ptr23 + (x1), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 25088.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp16 = triton_helpers.maximum(0, tmp15)
    tmp18 = tmp17 + 28
    tmp19 = tmp17 < 0
    tmp20 = tl.where(tmp19, tmp18, tmp17)
    tmp22 = tmp21 + 28
    tmp23 = tmp21 < 0
    tmp24 = tl.where(tmp23, tmp22, tmp21)
    tmp25 = tl.load(in_ptr7 + (tmp24 + (28*tmp20) + (784*x6)), xmask, eviction_policy='evict_last')
    tmp27 = tmp25 - tmp26
    tmp29 = 6272.0
    tmp30 = tmp28 / tmp29
    tmp31 = tmp30 + tmp6
    tmp32 = tl.math.rsqrt(tmp31)
    tmp33 = tmp27 * tmp32
    tmp35 = tmp33 * tmp34
    tmp37 = tmp35 + tmp36
    tmp38 = tmp16 + tmp37
    tmp40 = tmp39 + 14
    tmp41 = tmp39 < 0
    tmp42 = tl.where(tmp41, tmp40, tmp39)
    tmp44 = tmp43 + 14
    tmp45 = tmp43 < 0
    tmp46 = tl.where(tmp45, tmp44, tmp43)
    tmp47 = tl.load(in_ptr13 + (tmp46 + (14*tmp42) + (196*x6)), xmask, eviction_policy='evict_last')
    tmp49 = tmp47 - tmp48
    tmp51 = 1568.0
    tmp52 = tmp50 / tmp51
    tmp53 = tmp52 + tmp6
    tmp54 = tl.math.rsqrt(tmp53)
    tmp55 = tmp49 * tmp54
    tmp57 = tmp55 * tmp56
    tmp59 = tmp57 + tmp58
    tmp60 = tmp38 + tmp59
    tmp62 = tmp61 + 7
    tmp63 = tmp61 < 0
    tmp64 = tl.where(tmp63, tmp62, tmp61)
    tmp66 = tmp65 + 7
    tmp67 = tmp65 < 0
    tmp68 = tl.where(tmp67, tmp66, tmp65)
    tmp69 = tl.load(in_ptr19 + (tmp68 + (7*tmp64) + (49*x6)), xmask, eviction_policy='evict_last')
    tmp71 = tmp69 - tmp70
    tmp73 = 392.0
    tmp74 = tmp72 / tmp73
    tmp75 = tmp74 + tmp6
    tmp76 = tl.math.rsqrt(tmp75)
    tmp77 = tmp71 * tmp76
    tmp79 = tmp77 * tmp78
    tmp81 = tmp79 + tmp80
    tmp82 = tmp60 + tmp81
    tmp83 = triton_helpers.maximum(0, tmp82)
    tl.store(out_ptr0 + (x3), tmp16, xmask)
    tl.store(in_out_ptr0 + (x3), tmp83, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ju/cjuh7vestdtuf7usbuk7bxkuwsvkjo6mvswixqjqi4c27ggb22xs.py
# Source Nodes: [l__mod___stage4_0_fuse_layers_1_3_1], Original ATen: [aten._native_batch_norm_legit_functional]
# l__mod___stage4_0_fuse_layers_1_3_1 => add_1166, add_1167, add_1168, mul_1455, mul_1456, mul_1457, mul_1458, mul_1459, rsqrt_198, squeeze_595, var_mean_198
triton_per_fused__native_batch_norm_legit_functional_36 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[64, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_36', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel):
    xnumel = 36
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (1764*r2)), rmask & xmask, other=0.0)
    tmp24 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp31 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.broadcast_to(tmp1, [RBLOCK])
    tmp6 = tl.where(rmask & xmask, tmp4, 0)
    tmp7 = triton_helpers.promote_to_tensor(tl.sum(tmp6, 0))
    tmp8 = tl.full([1], 392, tl.int32)
    tmp9 = tmp8.to(tl.float32)
    tmp10 = tmp7 / tmp9
    tmp11 = tmp1 - tmp10
    tmp12 = tmp11 * tmp11
    tmp13 = tl.broadcast_to(tmp12, [RBLOCK])
    tmp15 = tl.where(rmask & xmask, tmp13, 0)
    tmp16 = triton_helpers.promote_to_tensor(tl.sum(tmp15, 0))
    tmp17 = 392.0
    tmp18 = tmp16 / tmp17
    tmp19 = 1e-05
    tmp20 = tmp18 + tmp19
    tmp21 = tl.math.rsqrt(tmp20)
    tmp22 = 0.1
    tmp23 = tmp10 * tmp22
    tmp25 = 0.9
    tmp26 = tmp24 * tmp25
    tmp27 = tmp23 + tmp26
    tmp28 = 1.0025575447570332
    tmp29 = tmp18 * tmp28
    tmp30 = tmp29 * tmp22
    tmp32 = tmp31 * tmp25
    tmp33 = tmp30 + tmp32
    tl.store(out_ptr2 + (x0), tmp21, xmask)
    tl.store(out_ptr4 + (x0), tmp27, xmask)
    tl.store(out_ptr6 + (x0), tmp33, xmask)
    tl.store(out_ptr0 + (x0), tmp10, xmask)
    tl.store(out_ptr1 + (x0), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/cm/ccmmwtzzfibo44aw4cefngityabyxtzzmyntvsfnqnhph3s3xlls.py
# Source Nodes: [l__mod___stage3_0_fuse_layers_1_2_2, l__mod___stage4_0_fuse_layers_1_3_2], Original ATen: [aten._to_copy, aten.add, aten.arange, aten.mul]
# l__mod___stage3_0_fuse_layers_1_2_2 => add_361, add_362, convert_element_type_12, iota_6, mul_460
# l__mod___stage4_0_fuse_layers_1_3_2 => convert_element_type_69, mul_1462
triton_poi_fused__to_copy_add_arange_mul_37 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[32], 
    filename=__file__,
    triton_meta={'signature': {0: '*i64', 1: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0,), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_mul_37', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 28
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = x0
    tmp1 = tmp0.to(tl.float32)
    tmp2 = 1.0
    tmp3 = tmp1 * tmp2
    tmp4 = 0.0
    tmp5 = tmp3 + tmp4
    tmp6 = tmp5 + tmp4
    tmp7 = 0.25
    tmp8 = tmp6 * tmp7
    tmp9 = tmp8.to(tl.int32)
    tl.store(out_ptr0 + (x0), tmp9, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/27/c27f7zlo6h6jkkfleiiz72ia24jgc74gldpy2qf5iwilrhftsdis.py
# Source Nodes: [l__mod___stage4_0_fuse_layers_1_2_1, l__mod___stage4_0_fuse_layers_1_2_2, l__mod___stage4_0_fuse_layers_1_3_1, l__mod___stage4_0_fuse_layers_1_3_2, shortcut_81, y_44, y_45, y_46, y_47], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
# l__mod___stage4_0_fuse_layers_1_2_1 => add_1156, add_1159, mul_1443, mul_1449, rsqrt_197, sub_197, var_mean_197
# l__mod___stage4_0_fuse_layers_1_2_2 => _unsafe_index_16
# l__mod___stage4_0_fuse_layers_1_3_1 => add_1166, add_1169, mul_1454, mul_1460, rsqrt_198, sub_198, var_mean_198
# l__mod___stage4_0_fuse_layers_1_3_2 => _unsafe_index_17
# shortcut_81 => relu_181
# y_44 => add_1150, add_1153, mul_1436, mul_1442, rsqrt_196, sub_196, var_mean_196
# y_45 => add_1154
# y_46 => add_1164
# y_47 => add_1174
triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_38 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*i64', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*i64', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: '*fp32', 18: '*fp32', 19: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(19,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_38', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, xnumel, XBLOCK : tl.constexpr):
    xnumel = 225792
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x4 = xindex
    x2 = (xindex // 784) % 36
    x1 = (xindex // 28) % 28
    x0 = xindex % 28
    x6 = (xindex // 784)
    tmp0 = tl.load(in_ptr0 + (x4), xmask)
    tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x2), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x4), xmask)
    tmp16 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp20 = tl.load(in_ptr6 + (x0), xmask, eviction_policy='evict_last')
    tmp25 = tl.load(in_ptr8 + (x2), xmask, eviction_policy='evict_last')
    tmp27 = tl.load(in_ptr9 + (x2), xmask, eviction_policy='evict_last')
    tmp33 = tl.load(in_ptr10 + (x2), xmask, eviction_policy='evict_last')
    tmp35 = tl.load(in_ptr11 + (x2), xmask, eviction_policy='evict_last')
    tmp38 = tl.load(in_ptr12 + (x1), xmask, eviction_policy='evict_last')
    tmp42 = tl.load(in_ptr12 + (x0), xmask, eviction_policy='evict_last')
    tmp47 = tl.load(in_ptr14 + (x2), xmask, eviction_policy='evict_last')
    tmp49 = tl.load(in_ptr15 + (x2), xmask, eviction_policy='evict_last')
    tmp55 = tl.load(in_ptr16 + (x2), xmask, eviction_policy='evict_last')
    tmp57 = tl.load(in_ptr17 + (x2), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 6272.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp15 = tmp13 + tmp14
    tmp17 = tmp16 + 14
    tmp18 = tmp16 < 0
    tmp19 = tl.where(tmp18, tmp17, tmp16)
    tmp21 = tmp20 + 14
    tmp22 = tmp20 < 0
    tmp23 = tl.where(tmp22, tmp21, tmp20)
    tmp24 = tl.load(in_ptr7 + (tmp23 + (14*tmp19) + (196*x6)), xmask, eviction_policy='evict_last')
    tmp26 = tmp24 - tmp25
    tmp28 = 1568.0
    tmp29 = tmp27 / tmp28
    tmp30 = tmp29 + tmp6
    tmp31 = tl.math.rsqrt(tmp30)
    tmp32 = tmp26 * tmp31
    tmp34 = tmp32 * tmp33
    tmp36 = tmp34 + tmp35
    tmp37 = tmp15 + tmp36
    tmp39 = tmp38 + 7
    tmp40 = tmp38 < 0
    tmp41 = tl.where(tmp40, tmp39, tmp38)
    tmp43 = tmp42 + 7
    tmp44 = tmp42 < 0
    tmp45 = tl.where(tmp44, tmp43, tmp42)
    tmp46 = tl.load(in_ptr13 + (tmp45 + (7*tmp41) + (49*x6)), xmask, eviction_policy='evict_last')
    tmp48 = tmp46 - tmp47
    tmp50 = 392.0
    tmp51 = tmp49 / tmp50
    tmp52 = tmp51 + tmp6
    tmp53 = tl.math.rsqrt(tmp52)
    tmp54 = tmp48 * tmp53
    tmp56 = tmp54 * tmp55
    tmp58 = tmp56 + tmp57
    tmp59 = tmp37 + tmp58
    tmp60 = triton_helpers.maximum(0, tmp59)
    tl.store(in_out_ptr0 + (x4), tmp60, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/4j/c4jgab5mmxoztxkhytqzpuzirnhrg4vgd53p4udbfyihbmf5vtvz.py
# Source Nodes: [l__mod___stage4_0_fuse_layers_2_3_1], Original ATen: [aten._native_batch_norm_legit_functional]
# l__mod___stage4_0_fuse_layers_2_3_1 => add_1193, add_1194, add_1195, mul_1487, mul_1488, mul_1489, mul_1490, mul_1491, rsqrt_202, squeeze_607, var_mean_202
triton_per_fused__native_batch_norm_legit_functional_39 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[128, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_39', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel):
    xnumel = 72
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (3528*r2)), rmask & xmask, other=0.0)
    tmp24 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp31 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.broadcast_to(tmp1, [RBLOCK])
    tmp6 = tl.where(rmask & xmask, tmp4, 0)
    tmp7 = triton_helpers.promote_to_tensor(tl.sum(tmp6, 0))
    tmp8 = tl.full([1], 392, tl.int32)
    tmp9 = tmp8.to(tl.float32)
    tmp10 = tmp7 / tmp9
    tmp11 = tmp1 - tmp10
    tmp12 = tmp11 * tmp11
    tmp13 = tl.broadcast_to(tmp12, [RBLOCK])
    tmp15 = tl.where(rmask & xmask, tmp13, 0)
    tmp16 = triton_helpers.promote_to_tensor(tl.sum(tmp15, 0))
    tmp17 = 392.0
    tmp18 = tmp16 / tmp17
    tmp19 = 1e-05
    tmp20 = tmp18 + tmp19
    tmp21 = tl.math.rsqrt(tmp20)
    tmp22 = 0.1
    tmp23 = tmp10 * tmp22
    tmp25 = 0.9
    tmp26 = tmp24 * tmp25
    tmp27 = tmp23 + tmp26
    tmp28 = 1.0025575447570332
    tmp29 = tmp18 * tmp28
    tmp30 = tmp29 * tmp22
    tmp32 = tmp31 * tmp25
    tmp33 = tmp30 + tmp32
    tl.store(out_ptr2 + (x0), tmp21, xmask)
    tl.store(out_ptr4 + (x0), tmp27, xmask)
    tl.store(out_ptr6 + (x0), tmp33, xmask)
    tl.store(out_ptr0 + (x0), tmp10, xmask)
    tl.store(out_ptr1 + (x0), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/s4/cs4xsbabviuxxb4ysi5wokzjusinuwen4442o2aco34er4lj47v7.py
# Source Nodes: [l__mod___stage4_0_fuse_layers_2_3_2], Original ATen: [aten._to_copy, aten.add, aten.arange, aten.mul]
# l__mod___stage4_0_fuse_layers_2_3_2 => add_1197, add_1198, convert_element_type_72, convert_element_type_73, iota_36, mul_1493, mul_1494
triton_poi_fused__to_copy_add_arange_mul_40 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16], 
    filename=__file__,
    triton_meta={'signature': {0: '*i64', 1: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0,), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_mul_40', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 14
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = x0
    tmp1 = tmp0.to(tl.float32)
    tmp2 = 1.0
    tmp3 = tmp1 * tmp2
    tmp4 = 0.0
    tmp5 = tmp3 + tmp4
    tmp6 = tmp5 + tmp4
    tmp7 = 0.5
    tmp8 = tmp6 * tmp7
    tmp9 = tmp8.to(tl.int32)
    tl.store(out_ptr0 + (x0), tmp9, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/er/cerfi3xv7hxorrp3iwnm37prumzx2flbzudp2qj7ynnj5djl4oth.py
# Source Nodes: [l__mod___stage4_0_fuse_layers_2_1_0_1, l__mod___stage4_0_fuse_layers_2_3_1, l__mod___stage4_0_fuse_layers_2_3_2, shortcut_85, y_48, y_49, y_50, y_51], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
# l__mod___stage4_0_fuse_layers_2_1_0_1 => add_1186, add_1189, mul_1479, mul_1485, rsqrt_201, sub_201, var_mean_201
# l__mod___stage4_0_fuse_layers_2_3_1 => add_1193, add_1196, mul_1486, mul_1492, rsqrt_202, sub_202, var_mean_202
# l__mod___stage4_0_fuse_layers_2_3_2 => _unsafe_index_18
# shortcut_85 => relu_183
# y_48 => add_1181, add_1184, mul_1472, mul_1478, rsqrt_200, sub_200, var_mean_200
# y_49 => add_1190
# y_50 => add_1191
# y_51 => add_1201
triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_41 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*i64', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: '*fp32', 18: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(18,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_41', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 72
    x5 = (xindex // 14) % 14
    x4 = xindex % 14
    x6 = (xindex // 196)
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x3), xmask)
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x1), xmask, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x1), xmask, eviction_policy='evict_last')
    tmp27 = tl.load(in_ptr10 + (x3), xmask)
    tmp29 = tl.load(in_ptr11 + (x5), xmask, eviction_policy='evict_last')
    tmp33 = tl.load(in_ptr11 + (x4), xmask, eviction_policy='evict_last')
    tmp38 = tl.load(in_ptr13 + (x1), xmask, eviction_policy='evict_last')
    tmp40 = tl.load(in_ptr14 + (x1), xmask, eviction_policy='evict_last')
    tmp46 = tl.load(in_ptr15 + (x1), xmask, eviction_policy='evict_last')
    tmp48 = tl.load(in_ptr16 + (x1), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 1568.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp13 + tmp25
    tmp28 = tmp26 + tmp27
    tmp30 = tmp29 + 7
    tmp31 = tmp29 < 0
    tmp32 = tl.where(tmp31, tmp30, tmp29)
    tmp34 = tmp33 + 7
    tmp35 = tmp33 < 0
    tmp36 = tl.where(tmp35, tmp34, tmp33)
    tmp37 = tl.load(in_ptr12 + (tmp36 + (7*tmp32) + (49*x6)), xmask, eviction_policy='evict_last')
    tmp39 = tmp37 - tmp38
    tmp41 = 392.0
    tmp42 = tmp40 / tmp41
    tmp43 = tmp42 + tmp6
    tmp44 = tl.math.rsqrt(tmp43)
    tmp45 = tmp39 * tmp44
    tmp47 = tmp45 * tmp46
    tmp49 = tmp47 + tmp48
    tmp50 = tmp28 + tmp49
    tmp51 = triton_helpers.maximum(0, tmp50)
    tl.store(in_out_ptr0 + (x3), tmp51, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ne/cnevk6mmditqa2hkkfcbpxkwy2a2q4ux2zo75yrorwp5j55wrp5i.py
# Source Nodes: [l__mod___stage4_0_fuse_layers_3_0_1_1, l__mod___stage4_0_fuse_layers_3_0_1_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# l__mod___stage4_0_fuse_layers_3_0_1_1 => add_1208, add_1211, mul_1504, mul_1510, rsqrt_204, sub_204, var_mean_204
# l__mod___stage4_0_fuse_layers_3_0_1_2 => relu_185
triton_poi_fused__native_batch_norm_legit_functional_relu_42 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[32768], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_42', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 28224
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 18
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 1568.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x3), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/i2/ci2kx6onradiznuo2y6jrkvz6h6uuibzqgksqvapy3c2ep3pbltj.py
# Source Nodes: [l__mod___stage4_0_fuse_layers_3_1_0_1, l__mod___stage4_0_fuse_layers_3_1_0_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# l__mod___stage4_0_fuse_layers_3_1_0_1 => add_1218, add_1221, mul_1518, mul_1524, rsqrt_206, sub_206, var_mean_206
# l__mod___stage4_0_fuse_layers_3_1_0_2 => relu_186
triton_poi_fused__native_batch_norm_legit_functional_relu_43 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_43', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 36
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 1568.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x3), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/43/c43g4zyeyjwl756xpakwpxx5mi5c7htidab4hrvti3zpt4znmyxg.py
# Source Nodes: [l__mod___stage4_0_fuse_layers_3_1_1_1, l__mod___stage4_0_fuse_layers_3_2_0_1, shortcut_89, y_52, y_53, y_54, y_55], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
# l__mod___stage4_0_fuse_layers_3_1_1_1 => add_1223, add_1226, mul_1525, mul_1531, rsqrt_207, sub_207, var_mean_207
# l__mod___stage4_0_fuse_layers_3_2_0_1 => add_1229, add_1232, mul_1532, mul_1538, rsqrt_208, sub_208, var_mean_208
# shortcut_89 => relu_187
# y_52 => add_1213, add_1216, mul_1511, mul_1517, rsqrt_205, sub_205, var_mean_205
# y_53 => add_1227
# y_54 => add_1233
# y_55 => add_1234
triton_poi_fused__native_batch_norm_legit_functional_add_relu_44 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(17,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_44', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 144
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x3), xmask)
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x1), xmask, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x1), xmask, eviction_policy='evict_last')
    tmp27 = tl.load(in_ptr10 + (x3), xmask)
    tmp28 = tl.load(in_ptr11 + (x1), xmask, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr12 + (x1), xmask, eviction_policy='evict_last')
    tmp35 = tl.load(in_ptr13 + (x1), xmask, eviction_policy='evict_last')
    tmp37 = tl.load(in_ptr14 + (x1), xmask, eviction_policy='evict_last')
    tmp40 = tl.load(in_ptr15 + (x3), xmask)
    tmp2 = tmp0 - tmp1
    tmp4 = 392.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp13 + tmp25
    tmp29 = tmp27 - tmp28
    tmp31 = tmp30 / tmp4
    tmp32 = tmp31 + tmp6
    tmp33 = tl.math.rsqrt(tmp32)
    tmp34 = tmp29 * tmp33
    tmp36 = tmp34 * tmp35
    tmp38 = tmp36 + tmp37
    tmp39 = tmp26 + tmp38
    tmp41 = tmp39 + tmp40
    tmp42 = triton_helpers.maximum(0, tmp41)
    tl.store(in_out_ptr0 + (x3), tmp42, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/m6/cm6p5yu2o622ujjwt2m72fm33lbcgn4vavk2v65kthpazgmxpmuf.py
# Source Nodes: [x_991], Original ATen: [aten._native_batch_norm_legit_functional]
# x_991 => var_mean_305
triton_red_fused__native_batch_norm_legit_functional_45 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_45', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 128
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 32
    x1 = (xindex // 32)
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    x3 = xindex
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + ((3136*x0) + (100352*(r2 // 3136)) + (200704*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x3), tmp2, xmask)
    tl.store(out_ptr1 + (x3), tmp3, xmask)
    tl.store(out_ptr2 + (x3), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/js/cjsv7fjxb2pwwucxl42bsuxk2ouiyv67k7z7lwgdckxdovchrh3t.py
# Source Nodes: [x_991], Original ATen: [aten._native_batch_norm_legit_functional]
# x_991 => add_1820, add_1821, add_1822, mul_2260, mul_2261, mul_2262, mul_2263, mul_2264, rsqrt_305, squeeze_916, var_mean_305
triton_per_fused__native_batch_norm_legit_functional_46 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[32, 4],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_46', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 32
    rnumel = 4
    RBLOCK: tl.constexpr = 4
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (32*r1)), rmask & xmask, other=0.0)
    tmp1 = tl.load(in_ptr1 + (x0 + (32*r1)), rmask & xmask, other=0.0)
    tmp2 = tl.load(in_ptr2 + (x0 + (32*r1)), rmask & xmask, other=0.0)
    tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
    tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
    tmp7 = tl.where(rmask & xmask, tmp3, 0)
    tmp8 = tl.where(rmask & xmask, tmp4, 0)
    tmp9 = tl.where(rmask & xmask, tmp5, 0)
    tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
    tmp13 = tmp10[:, None]
    tmp14 = tmp11[:, None]
    tmp15 = tmp12[:, None]
    tmp16 = 25088.0
    tmp17 = tmp14 / tmp16
    tmp18 = 1e-05
    tmp19 = tmp17 + tmp18
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = 0.1
    tmp22 = tmp13 * tmp21
    tmp24 = 0.9
    tmp25 = tmp23 * tmp24
    tmp26 = tmp22 + tmp25
    tmp27 = 1.0000398612827361
    tmp28 = tmp17 * tmp27
    tmp29 = tmp28 * tmp21
    tmp31 = tmp30 * tmp24
    tmp32 = tmp29 + tmp31
    tl.store(out_ptr2 + (x0), tmp20, xmask)
    tl.store(out_ptr4 + (x0), tmp26, xmask)
    tl.store(out_ptr6 + (x0), tmp32, xmask)
    tl.store(out_ptr0 + (x0), tmp13, xmask)
    tl.store(out_ptr1 + (x0), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/w5/cw5pa4wpn77j4h3l2ryutdvzvtpiayhchid5hr6f2vxjeql2iphu.py
# Source Nodes: [x_991, x_992], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# x_991 => add_1820, add_1823, mul_2259, mul_2265, rsqrt_305, sub_305, var_mean_305
# x_992 => relu_268
triton_poi_fused__native_batch_norm_legit_functional_relu_47 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1048576], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_47', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 802816
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 32
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 25088.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x3), tmp14, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/r4/cr4bnfdym7xi6u2g4butess5dnl6syzppnnldu7apdpov5ztlroc.py
# Source Nodes: [x_999], Original ATen: [aten._native_batch_norm_legit_functional]
# x_999 => var_mean_307
triton_red_fused__native_batch_norm_legit_functional_48 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[512, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_48', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 512
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 128
    x1 = (xindex // 128)
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    x3 = xindex
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + ((3136*x0) + (401408*(r2 // 3136)) + (802816*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x3), tmp2, xmask)
    tl.store(out_ptr1 + (x3), tmp3, xmask)
    tl.store(out_ptr2 + (x3), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/7w/c7woc4gtzt52vwpal2qu7asmgf3ymsdgofrfo2lkduzeofux5tux.py
# Source Nodes: [x_999], Original ATen: [aten._native_batch_norm_legit_functional]
# x_999 => add_1830, add_1831, add_1832, mul_2274, mul_2275, mul_2276, mul_2277, mul_2278, rsqrt_307, squeeze_922, var_mean_307
triton_per_fused__native_batch_norm_legit_functional_49 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[128, 4],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_49', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 128
    rnumel = 4
    RBLOCK: tl.constexpr = 4
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
    tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0.0)
    tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0.0)
    tmp23 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
    tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
    tmp7 = tl.where(rmask & xmask, tmp3, 0)
    tmp8 = tl.where(rmask & xmask, tmp4, 0)
    tmp9 = tl.where(rmask & xmask, tmp5, 0)
    tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
    tmp13 = tmp10[:, None]
    tmp14 = tmp11[:, None]
    tmp15 = tmp12[:, None]
    tmp16 = 25088.0
    tmp17 = tmp14 / tmp16
    tmp18 = 1e-05
    tmp19 = tmp17 + tmp18
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = 0.1
    tmp22 = tmp13 * tmp21
    tmp24 = 0.9
    tmp25 = tmp23 * tmp24
    tmp26 = tmp22 + tmp25
    tmp27 = 1.0000398612827361
    tmp28 = tmp17 * tmp27
    tmp29 = tmp28 * tmp21
    tmp31 = tmp30 * tmp24
    tmp32 = tmp29 + tmp31
    tl.store(out_ptr2 + (x0), tmp20, xmask)
    tl.store(out_ptr4 + (x0), tmp26, xmask)
    tl.store(out_ptr6 + (x0), tmp32, xmask)
    tl.store(out_ptr0 + (x0), tmp13, xmask)
    tl.store(out_ptr1 + (x0), tmp14, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/lu/clu5b6frrkgpdcnjdgr2asqr36fzgbvn2whe4cuxhg7cxxapzlcm.py
# Source Nodes: [shortcut_110, x_1000, x_999, y_88], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
# shortcut_110 => add_1835, add_1838, mul_2280, mul_2286, rsqrt_308, sub_308, var_mean_308
# x_1000 => add_1839
# x_999 => add_1830, add_1833, mul_2273, mul_2279, rsqrt_307, sub_307, var_mean_307
# y_88 => relu_270
triton_poi_fused__native_batch_norm_legit_functional_add_relu_50 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4194304], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_50', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, xnumel, XBLOCK : tl.constexpr):
    xnumel = 3211264
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 128
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x3), None)
    tmp15 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x1), None, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x1), None, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 25088.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp13 + tmp25
    tmp27 = triton_helpers.maximum(0, tmp26)
    tl.store(in_out_ptr0 + (x3), tmp27, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/ea/ceah65i6nhdmbu3jpmnrlcbeypqxixu7tdfbicbj3egwn2eh7qqb.py
# Source Nodes: [x_1003], Original ATen: [aten._native_batch_norm_legit_functional]
# x_1003 => add_1841, add_1842, add_1843, mul_2288, mul_2289, mul_2290, mul_2291, mul_2292, rsqrt_309, squeeze_928, var_mean_309
triton_red_fused__native_batch_norm_legit_functional_51 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[64, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_51', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 64
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 784
        r2 = (rindex // 784)
        tmp0 = tl.load(in_ptr0 + (r1 + (784*x0) + (50176*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tl.store(out_ptr1 + (x0), tmp3, xmask)
    tmp12 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp5 = 6272.0
    tmp6 = tmp3 / tmp5
    tmp7 = 1e-05
    tmp8 = tmp6 + tmp7
    tmp9 = tl.math.rsqrt(tmp8)
    tmp10 = 0.1
    tmp11 = tmp2 * tmp10
    tmp13 = 0.9
    tmp14 = tmp12 * tmp13
    tmp15 = tmp11 + tmp14
    tmp16 = 1.0001594642002871
    tmp17 = tmp6 * tmp16
    tmp18 = tmp17 * tmp10
    tmp20 = tmp19 * tmp13
    tmp21 = tmp18 + tmp20
    tl.store(out_ptr2 + (x0), tmp9, xmask)
    tl.store(out_ptr4 + (x0), tmp15, xmask)
    tl.store(out_ptr6 + (x0), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/vv/cvvx2q7ft4ukmviivuuubyfraekyztwaoupsrrvzzmj2s3izxyiu.py
# Source Nodes: [x_1003, x_1004], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# x_1003 => add_1841, add_1844, mul_2287, mul_2293, rsqrt_309, sub_309, var_mean_309
# x_1004 => relu_271
triton_poi_fused__native_batch_norm_legit_functional_relu_52 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_52', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 401408
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 784) % 64
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 6272.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x3), tmp14, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/6o/c6ohzbydz5u3k3r2ghb5hwb6ukp3jqf3zqc67a5e45yunaoow2af.py
# Source Nodes: [x_1011], Original ATen: [aten._native_batch_norm_legit_functional]
# x_1011 => add_1851, add_1852, add_1853, mul_2302, mul_2303, mul_2304, mul_2305, mul_2306, rsqrt_311, squeeze_934, var_mean_311
triton_red_fused__native_batch_norm_legit_functional_53 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[256, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_53', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 256
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 784
        r2 = (rindex // 784)
        tmp0 = tl.load(in_ptr0 + (r1 + (784*x0) + (200704*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tl.store(out_ptr1 + (x0), tmp3, xmask)
    tmp12 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp5 = 6272.0
    tmp6 = tmp3 / tmp5
    tmp7 = 1e-05
    tmp8 = tmp6 + tmp7
    tmp9 = tl.math.rsqrt(tmp8)
    tmp10 = 0.1
    tmp11 = tmp2 * tmp10
    tmp13 = 0.9
    tmp14 = tmp12 * tmp13
    tmp15 = tmp11 + tmp14
    tmp16 = 1.0001594642002871
    tmp17 = tmp6 * tmp16
    tmp18 = tmp17 * tmp10
    tmp20 = tmp19 * tmp13
    tmp21 = tmp18 + tmp20
    tl.store(out_ptr2 + (x0), tmp9, xmask)
    tl.store(out_ptr4 + (x0), tmp15, xmask)
    tl.store(out_ptr6 + (x0), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/uo/cuoanw3jdm7a2d2b7psmzrx43eqljukbncxdbnvvfmz6zuxuoxmb.py
# Source Nodes: [forward], Original ATen: [aten.convolution]
# forward => convolution_313
triton_poi_fused_convolution_54 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2097152], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_54', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 1605632
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 784) % 256
    tmp0 = tl.load(in_out_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
    tmp2 = tmp0 + tmp1
    tl.store(in_out_ptr0 + (x3), tmp2, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/ub/cubwegvttrdmvh7bxrz6wm7zreukkbqalsogigmzbegcl53kycip.py
# Source Nodes: [forward, shortcut_112, x_1011, x_1012, x_1013, y_89], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu, aten.threshold_backward]
# forward => add_1862, add_1865, mul_2315, mul_2321, relu_274, rsqrt_313, sub_313, var_mean_313
# shortcut_112 => add_1856, add_1859, mul_2308, mul_2314, rsqrt_312, sub_312, var_mean_312
# x_1011 => add_1851, add_1854, mul_2301, mul_2307, rsqrt_311, sub_311, var_mean_311
# x_1012 => add_1860
# x_1013 => relu_273
# y_89 => add_1866
triton_poi_fused__native_batch_norm_legit_functional_add_relu_threshold_backward_55 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2097152], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*i1', 17: '*i1', 18: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(18,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_threshold_backward_55', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, out_ptr2, out_ptr3, out_ptr4, xnumel, XBLOCK : tl.constexpr):
    xnumel = 1605632
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 784) % 256
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x3), None)
    tmp15 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x1), None, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x1), None, eviction_policy='evict_last')
    tmp27 = tl.load(in_ptr10 + (x3), None)
    tmp28 = tl.load(in_ptr11 + (x1), None, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr12 + (x1), None, eviction_policy='evict_last')
    tmp35 = tl.load(in_ptr13 + (x1), None, eviction_policy='evict_last')
    tmp37 = tl.load(in_ptr14 + (x1), None, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 6272.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp13 + tmp25
    tmp29 = tmp27 - tmp28
    tmp31 = tmp30 / tmp4
    tmp32 = tmp31 + tmp6
    tmp33 = tl.math.rsqrt(tmp32)
    tmp34 = tmp29 * tmp33
    tmp36 = tmp34 * tmp35
    tmp38 = tmp36 + tmp37
    tmp39 = triton_helpers.maximum(0, tmp38)
    tmp40 = triton_helpers.maximum(0, tmp26)
    tmp41 = tmp40 + tmp39
    tmp42 = 0.0
    tmp43 = tmp39 <= tmp42
    tmp44 = tmp40 <= tmp42
    tl.store(out_ptr2 + (x3), tmp41, None)
    tl.store(out_ptr3 + (x3), tmp43, None)
    tl.store(out_ptr4 + (x3), tmp44, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/4d/c4dma5j6t3colocrllq52qaujtzzixxzkbwj7a3ymhqxhg2qg4ga.py
# Source Nodes: [x_1015], Original ATen: [aten._native_batch_norm_legit_functional]
# x_1015 => add_1868, add_1869, add_1870, mul_2323, mul_2324, mul_2325, mul_2326, mul_2327, rsqrt_314, squeeze_943, var_mean_314
triton_red_fused__native_batch_norm_legit_functional_56 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_56', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 128
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (25088*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tl.store(out_ptr1 + (x0), tmp3, xmask)
    tmp12 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp5 = 1568.0
    tmp6 = tmp3 / tmp5
    tmp7 = 1e-05
    tmp8 = tmp6 + tmp7
    tmp9 = tl.math.rsqrt(tmp8)
    tmp10 = 0.1
    tmp11 = tmp2 * tmp10
    tmp13 = 0.9
    tmp14 = tmp12 * tmp13
    tmp15 = tmp11 + tmp14
    tmp16 = 1.0006381620931717
    tmp17 = tmp6 * tmp16
    tmp18 = tmp17 * tmp10
    tmp20 = tmp19 * tmp13
    tmp21 = tmp18 + tmp20
    tl.store(out_ptr2 + (x0), tmp9, xmask)
    tl.store(out_ptr4 + (x0), tmp15, xmask)
    tl.store(out_ptr6 + (x0), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/jn/cjn4yh6jcfaklfxzbnzlumidxmzidy25ndb7qy2svv653tzms44p.py
# Source Nodes: [x_1015, x_1016], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# x_1015 => add_1868, add_1871, mul_2322, mul_2328, rsqrt_314, sub_314, var_mean_314
# x_1016 => relu_275
triton_poi_fused__native_batch_norm_legit_functional_relu_57 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_57', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 200704
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 128
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 1568.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x3), tmp14, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/yk/cykoqgx2v6kpcj7tfwh4635mlwmbqv4vlhxw7uruz6bmacn2ouh7.py
# Source Nodes: [x_1023], Original ATen: [aten._native_batch_norm_legit_functional]
# x_1023 => add_1878, add_1879, add_1880, mul_2337, mul_2338, mul_2339, mul_2340, mul_2341, rsqrt_316, squeeze_949, var_mean_316
triton_red_fused__native_batch_norm_legit_functional_58 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[512, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_58', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 512
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (100352*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
            tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
        )
        tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
        tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
        tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
    tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
        tmp2_mean, tmp2_m2, tmp2_weight, 1
    )
    tmp2 = tmp2_tmp[:, None]
    tmp3 = tmp3_tmp[:, None]
    tmp4 = tmp4_tmp[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tl.store(out_ptr1 + (x0), tmp3, xmask)
    tmp12 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp5 = 1568.0
    tmp6 = tmp3 / tmp5
    tmp7 = 1e-05
    tmp8 = tmp6 + tmp7
    tmp9 = tl.math.rsqrt(tmp8)
    tmp10 = 0.1
    tmp11 = tmp2 * tmp10
    tmp13 = 0.9
    tmp14 = tmp12 * tmp13
    tmp15 = tmp11 + tmp14
    tmp16 = 1.0006381620931717
    tmp17 = tmp6 * tmp16
    tmp18 = tmp17 * tmp10
    tmp20 = tmp19 * tmp13
    tmp21 = tmp18 + tmp20
    tl.store(out_ptr2 + (x0), tmp9, xmask)
    tl.store(out_ptr4 + (x0), tmp15, xmask)
    tl.store(out_ptr6 + (x0), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/o4/co4762p72gonbasaoikh74dpuxlvv52srxxu633ir7arazlbjsvd.py
# Source Nodes: [forward_1], Original ATen: [aten.convolution]
# forward_1 => convolution_318
triton_poi_fused_convolution_59 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1048576], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_59', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 802816
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 512
    tmp0 = tl.load(in_out_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
    tmp2 = tmp0 + tmp1
    tl.store(in_out_ptr0 + (x3), tmp2, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/73/c7347b22ve544ypjznhj7c5ymo553dd6o4pioeccjy2oj2zx3tzo.py
# Source Nodes: [forward_1, shortcut_114, x_1023, x_1024, x_1025, y_90], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu, aten.threshold_backward]
# forward_1 => add_1889, add_1892, mul_2350, mul_2356, relu_278, rsqrt_318, sub_318, var_mean_318
# shortcut_114 => add_1883, add_1886, mul_2343, mul_2349, rsqrt_317, sub_317, var_mean_317
# x_1023 => add_1878, add_1881, mul_2336, mul_2342, rsqrt_316, sub_316, var_mean_316
# x_1024 => add_1887
# x_1025 => relu_277
# y_90 => add_1893
triton_poi_fused__native_batch_norm_legit_functional_add_relu_threshold_backward_60 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1048576], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*i1', 17: '*i1', 18: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(18,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_threshold_backward_60', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, out_ptr2, out_ptr3, out_ptr4, xnumel, XBLOCK : tl.constexpr):
    xnumel = 802816
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 512
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x3), None)
    tmp15 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x1), None, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x1), None, eviction_policy='evict_last')
    tmp27 = tl.load(in_ptr10 + (x3), None)
    tmp28 = tl.load(in_ptr11 + (x1), None, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr12 + (x1), None, eviction_policy='evict_last')
    tmp35 = tl.load(in_ptr13 + (x1), None, eviction_policy='evict_last')
    tmp37 = tl.load(in_ptr14 + (x1), None, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 1568.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp13 + tmp25
    tmp29 = tmp27 - tmp28
    tmp31 = tmp30 / tmp4
    tmp32 = tmp31 + tmp6
    tmp33 = tl.math.rsqrt(tmp32)
    tmp34 = tmp29 * tmp33
    tmp36 = tmp34 * tmp35
    tmp38 = tmp36 + tmp37
    tmp39 = triton_helpers.maximum(0, tmp38)
    tmp40 = triton_helpers.maximum(0, tmp26)
    tmp41 = tmp40 + tmp39
    tmp42 = 0.0
    tmp43 = tmp39 <= tmp42
    tmp44 = tmp40 <= tmp42
    tl.store(out_ptr2 + (x3), tmp41, None)
    tl.store(out_ptr3 + (x3), tmp43, None)
    tl.store(out_ptr4 + (x3), tmp44, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/32/c32f25gq4cdlctmxzpwebnuvwwx4td3yb7vd3xsi7pn2cncvianm.py
# Source Nodes: [x_1027], Original ATen: [aten._native_batch_norm_legit_functional]
# x_1027 => add_1895, add_1896, add_1897, mul_2358, mul_2359, mul_2360, mul_2361, mul_2362, rsqrt_319, squeeze_958, var_mean_319
triton_per_fused__native_batch_norm_legit_functional_61 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[256, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_61', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel):
    xnumel = 256
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (12544*r2)), rmask & xmask, other=0.0)
    tmp24 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp31 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.broadcast_to(tmp1, [RBLOCK])
    tmp6 = tl.where(rmask & xmask, tmp4, 0)
    tmp7 = triton_helpers.promote_to_tensor(tl.sum(tmp6, 0))
    tmp8 = tl.full([1], 392, tl.int32)
    tmp9 = tmp8.to(tl.float32)
    tmp10 = tmp7 / tmp9
    tmp11 = tmp1 - tmp10
    tmp12 = tmp11 * tmp11
    tmp13 = tl.broadcast_to(tmp12, [RBLOCK])
    tmp15 = tl.where(rmask & xmask, tmp13, 0)
    tmp16 = triton_helpers.promote_to_tensor(tl.sum(tmp15, 0))
    tmp17 = 392.0
    tmp18 = tmp16 / tmp17
    tmp19 = 1e-05
    tmp20 = tmp18 + tmp19
    tmp21 = tl.math.rsqrt(tmp20)
    tmp22 = 0.1
    tmp23 = tmp10 * tmp22
    tmp25 = 0.9
    tmp26 = tmp24 * tmp25
    tmp27 = tmp23 + tmp26
    tmp28 = 1.0025575447570332
    tmp29 = tmp18 * tmp28
    tmp30 = tmp29 * tmp22
    tmp32 = tmp31 * tmp25
    tmp33 = tmp30 + tmp32
    tl.store(out_ptr2 + (x0), tmp21, xmask)
    tl.store(out_ptr4 + (x0), tmp27, xmask)
    tl.store(out_ptr6 + (x0), tmp33, xmask)
    tl.store(out_ptr0 + (x0), tmp10, xmask)
    tl.store(out_ptr1 + (x0), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/xo/cxofslziwa6y6usa4rzf4ykjco2dx7pes7khgbbgodylskfzz7vt.py
# Source Nodes: [x_1027, x_1028], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
# x_1027 => add_1895, add_1898, mul_2357, mul_2363, rsqrt_319, sub_319, var_mean_319
# x_1028 => relu_279
triton_poi_fused__native_batch_norm_legit_functional_relu_62 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_62', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 100352
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 256
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 392.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tl.store(out_ptr0 + (x3), tmp14, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/ss/css6arst3yf463ed7duzrfebwysah6wb7adhgtdtsb5fzcdnkfxu.py
# Source Nodes: [x_1035], Original ATen: [aten._native_batch_norm_legit_functional]
# x_1035 => add_1905, add_1906, add_1907, mul_2372, mul_2373, mul_2374, mul_2375, mul_2376, rsqrt_321, squeeze_964, var_mean_321
triton_per_fused__native_batch_norm_legit_functional_63 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[1024, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_63', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel):
    xnumel = 1024
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (50176*r2)), rmask & xmask, other=0.0)
    tmp24 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp31 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.broadcast_to(tmp1, [RBLOCK])
    tmp6 = tl.where(rmask & xmask, tmp4, 0)
    tmp7 = triton_helpers.promote_to_tensor(tl.sum(tmp6, 0))
    tmp8 = tl.full([1], 392, tl.int32)
    tmp9 = tmp8.to(tl.float32)
    tmp10 = tmp7 / tmp9
    tmp11 = tmp1 - tmp10
    tmp12 = tmp11 * tmp11
    tmp13 = tl.broadcast_to(tmp12, [RBLOCK])
    tmp15 = tl.where(rmask & xmask, tmp13, 0)
    tmp16 = triton_helpers.promote_to_tensor(tl.sum(tmp15, 0))
    tmp17 = 392.0
    tmp18 = tmp16 / tmp17
    tmp19 = 1e-05
    tmp20 = tmp18 + tmp19
    tmp21 = tl.math.rsqrt(tmp20)
    tmp22 = 0.1
    tmp23 = tmp10 * tmp22
    tmp25 = 0.9
    tmp26 = tmp24 * tmp25
    tmp27 = tmp23 + tmp26
    tmp28 = 1.0025575447570332
    tmp29 = tmp18 * tmp28
    tmp30 = tmp29 * tmp22
    tmp32 = tmp31 * tmp25
    tmp33 = tmp30 + tmp32
    tl.store(out_ptr2 + (x0), tmp21, xmask)
    tl.store(out_ptr4 + (x0), tmp27, xmask)
    tl.store(out_ptr6 + (x0), tmp33, xmask)
    tl.store(out_ptr0 + (x0), tmp10, xmask)
    tl.store(out_ptr1 + (x0), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/yr/cyrw5v4ite5265dokuvizzpqkutpq6yiiqyfejj5y35yfdiguwsq.py
# Source Nodes: [forward_2], Original ATen: [aten.convolution]
# forward_2 => convolution_323
triton_poi_fused_convolution_64 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_64', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 401408
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 1024
    tmp0 = tl.load(in_out_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
    tmp2 = tmp0 + tmp1
    tl.store(in_out_ptr0 + (x3), tmp2, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/zx/czxdae23eddipvluwganuvng72x6evvbovboo42cuywflqqe3lko.py
# Source Nodes: [forward_2, shortcut_116, x_1035, x_1036, x_1037, y_91], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu, aten.threshold_backward]
# forward_2 => add_1916, add_1919, mul_2385, mul_2391, relu_282, rsqrt_323, sub_323, var_mean_323
# shortcut_116 => add_1910, add_1913, mul_2378, mul_2384, rsqrt_322, sub_322, var_mean_322
# x_1035 => add_1905, add_1908, mul_2371, mul_2377, rsqrt_321, sub_321, var_mean_321
# x_1036 => add_1914
# x_1037 => relu_281
# y_91 => add_1920
triton_poi_fused__native_batch_norm_legit_functional_add_relu_threshold_backward_65 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*i1', 17: '*i1', 18: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(18,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_threshold_backward_65', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, out_ptr2, out_ptr3, out_ptr4, xnumel, XBLOCK : tl.constexpr):
    xnumel = 401408
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 1024
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp14 = tl.load(in_ptr5 + (x3), None)
    tmp15 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x1), None, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x1), None, eviction_policy='evict_last')
    tmp27 = tl.load(in_ptr10 + (x3), None)
    tmp28 = tl.load(in_ptr11 + (x1), None, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr12 + (x1), None, eviction_policy='evict_last')
    tmp35 = tl.load(in_ptr13 + (x1), None, eviction_policy='evict_last')
    tmp37 = tl.load(in_ptr14 + (x1), None, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 392.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp16 = tmp14 - tmp15
    tmp18 = tmp17 / tmp4
    tmp19 = tmp18 + tmp6
    tmp20 = tl.math.rsqrt(tmp19)
    tmp21 = tmp16 * tmp20
    tmp23 = tmp21 * tmp22
    tmp25 = tmp23 + tmp24
    tmp26 = tmp13 + tmp25
    tmp29 = tmp27 - tmp28
    tmp31 = tmp30 / tmp4
    tmp32 = tmp31 + tmp6
    tmp33 = tl.math.rsqrt(tmp32)
    tmp34 = tmp29 * tmp33
    tmp36 = tmp34 * tmp35
    tmp38 = tmp36 + tmp37
    tmp39 = triton_helpers.maximum(0, tmp38)
    tmp40 = triton_helpers.maximum(0, tmp26)
    tmp41 = tmp40 + tmp39
    tmp42 = 0.0
    tmp43 = tmp39 <= tmp42
    tmp44 = tmp40 <= tmp42
    tl.store(out_ptr2 + (x3), tmp41, None)
    tl.store(out_ptr3 + (x3), tmp43, None)
    tl.store(out_ptr4 + (x3), tmp44, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/4j/c4jado5jhqhlp4bloz7sbazxr5apmqz67oh6mbxijuraxs3xzue2.py
# Source Nodes: [l__mod___final_layer_0], Original ATen: [aten.convolution]
# l__mod___final_layer_0 => convolution_324
triton_poi_fused_convolution_66 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1048576], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_66', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 802816
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 2048
    tmp0 = tl.load(in_out_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
    tmp2 = tmp0 + tmp1
    tl.store(in_out_ptr0 + (x3), tmp2, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/5m/c5mipv4impjjqvixmkwfyys4rgy6g2qxtn6ug5wmgga3qsr37f26.py
# Source Nodes: [l__mod___final_layer_1], Original ATen: [aten._native_batch_norm_legit_functional]
# l__mod___final_layer_1 => add_1922, add_1923, add_1924, mul_2393, mul_2394, mul_2395, mul_2396, mul_2397, rsqrt_324, squeeze_973, var_mean_324
triton_per_fused__native_batch_norm_legit_functional_67 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[2048, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_67', 'mutated_arg_names': ['in_ptr1', 'in_ptr2', 'out_ptr4', 'out_ptr6']}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, xnumel, rnumel):
    xnumel = 2048
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (100352*r2)), rmask, other=0.0)
    tmp24 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
    tmp31 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [RBLOCK])
    tmp3 = tl.where(rmask, tmp1, 0)
    tmp4 = tl.broadcast_to(tmp1, [RBLOCK])
    tmp6 = tl.where(rmask, tmp4, 0)
    tmp7 = triton_helpers.promote_to_tensor(tl.sum(tmp6, 0))
    tmp8 = tl.full([1], 392, tl.int32)
    tmp9 = tmp8.to(tl.float32)
    tmp10 = tmp7 / tmp9
    tmp11 = tmp1 - tmp10
    tmp12 = tmp11 * tmp11
    tmp13 = tl.broadcast_to(tmp12, [RBLOCK])
    tmp15 = tl.where(rmask, tmp13, 0)
    tmp16 = triton_helpers.promote_to_tensor(tl.sum(tmp15, 0))
    tmp17 = 392.0
    tmp18 = tmp16 / tmp17
    tmp19 = 1e-05
    tmp20 = tmp18 + tmp19
    tmp21 = tl.math.rsqrt(tmp20)
    tmp22 = 0.1
    tmp23 = tmp10 * tmp22
    tmp25 = 0.9
    tmp26 = tmp24 * tmp25
    tmp27 = tmp23 + tmp26
    tmp28 = 1.0025575447570332
    tmp29 = tmp18 * tmp28
    tmp30 = tmp29 * tmp22
    tmp32 = tmp31 * tmp25
    tmp33 = tmp30 + tmp32
    tl.store(out_ptr2 + (x0), tmp21, None)
    tl.store(out_ptr4 + (x0), tmp27, None)
    tl.store(out_ptr6 + (x0), tmp33, None)
    tl.store(out_ptr0 + (x0), tmp10, None)
    tl.store(out_ptr1 + (x0), tmp16, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/gh/cghp3w7vevwn4m7gtrdslhovgcoxqrz7wzflss634dscxqy63lkk.py
# Source Nodes: [l__mod___final_layer_1, x_1038, x_1040, y_93], Original ATen: [aten._native_batch_norm_legit_functional, aten.mean, aten.relu, aten.threshold_backward, aten.view]
# l__mod___final_layer_1 => add_1922, add_1925, mul_2392, mul_2398, rsqrt_324, sub_324, var_mean_324
# x_1038 => mean
# x_1040 => view
# y_93 => relu_283
triton_per_fused__native_batch_norm_legit_functional_mean_relu_threshold_backward_view_68 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[16384, 64],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*i1', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_mean_relu_threshold_backward_view_68', 'mutated_arg_names': ['in_out_ptr0']}
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr1, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 16384
    rnumel = 49
    RBLOCK: tl.constexpr = 64
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r2 = rindex
    x3 = xindex
    x0 = xindex % 2048
    tmp0 = tl.load(in_ptr0 + (r2 + (49*x3)), rmask, other=0.0)
    tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
    tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
    tmp2 = tmp0 - tmp1
    tmp4 = 392.0
    tmp5 = tmp3 / tmp4
    tmp6 = 1e-05
    tmp7 = tmp5 + tmp6
    tmp8 = tl.math.rsqrt(tmp7)
    tmp9 = tmp2 * tmp8
    tmp11 = tmp9 * tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = triton_helpers.maximum(0, tmp13)
    tmp15 = 0.0
    tmp16 = tmp14 <= tmp15
    tmp17 = tl.broadcast_to(tmp14, [XBLOCK, RBLOCK])
    tmp19 = tl.where(rmask, tmp17, 0)
    tmp20 = tl.sum(tmp19, 1)[:, None]
    tmp21 = 49.0
    tmp22 = tmp20 / tmp21
    tl.store(out_ptr1 + (r2 + (49*x3)), tmp16, rmask)
    tl.debug_barrier()
    tl.store(in_out_ptr0 + (x3), tmp22, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/sq/csqd5k63jtiq3zvl3b3cbbtdzxlw6z2b4xaivnftrdb5krazrtc6.py
# Source Nodes: [x_1], Original ATen: [aten.add]
# x_1 => add
triton_poi_fused_add_69 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1], 
    filename=__file__,
    triton_meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_69', 'mutated_arg_names': ['in_ptr0', 'out_ptr1']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 1
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    tmp0 = tl.load(in_ptr0 + (0))
    tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
    tmp2 = tl.full([1], 1, tl.int64)
    tmp3 = tmp1 + tmp2
    tl.store(out_ptr1 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
''')


async_compile.wait(globals())
del async_compile

def call(args):
    primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190, primals_191, primals_192, primals_193, primals_194, primals_195, primals_196, primals_197, primals_198, primals_199, primals_200, primals_201, primals_202, primals_203, primals_204, primals_205, primals_206, primals_207, primals_208, primals_209, primals_210, primals_211, primals_212, primals_213, primals_214, primals_215, primals_216, primals_217, primals_218, primals_219, primals_220, primals_221, primals_222, primals_223, primals_224, primals_225, primals_226, primals_227, primals_228, primals_229, primals_230, primals_231, primals_232, primals_233, primals_234, primals_235, primals_236, primals_237, primals_238, primals_239, primals_240, primals_241, primals_242, primals_243, primals_244, primals_245, primals_246, primals_247, primals_248, primals_249, primals_250, primals_251, primals_252, primals_253, primals_254, primals_255, primals_256, primals_257, primals_258, primals_259, primals_260, primals_261, primals_262, primals_263, primals_264, primals_265, primals_266, primals_267, primals_268, primals_269, primals_270, primals_271, primals_272, primals_273, primals_274, primals_275, primals_276, primals_277, primals_278, primals_279, primals_280, primals_281, primals_282, primals_283, primals_284, primals_285, primals_286, primals_287, primals_288, primals_289, primals_290, primals_291, primals_292, primals_293, primals_294, primals_295, primals_296, primals_297, primals_298, primals_299, primals_300, primals_301, primals_302, primals_303, primals_304, primals_305, primals_306, primals_307, primals_308, primals_309, primals_310, primals_311, primals_312, primals_313, primals_314, primals_315, primals_316, primals_317, primals_318, primals_319, primals_320, primals_321, primals_322, primals_323, primals_324, primals_325, primals_326, primals_327, primals_328, primals_329, primals_330, primals_331, primals_332, primals_333, primals_334, primals_335, primals_336, primals_337, primals_338, primals_339, primals_340, primals_341, primals_342, primals_343, primals_344, primals_345, primals_346, primals_347, primals_348, primals_349, primals_350, primals_351, primals_352, primals_353, primals_354, primals_355, primals_356, primals_357, primals_358, primals_359, primals_360, primals_361, primals_362, primals_363, primals_364, primals_365, primals_366, primals_367, primals_368, primals_369, primals_370, primals_371, primals_372, primals_373, primals_374, primals_375, primals_376, primals_377, primals_378, primals_379, primals_380, primals_381, primals_382, primals_383, primals_384, primals_385, primals_386, primals_387, primals_388, primals_389, primals_390, primals_391, primals_392, primals_393, primals_394, primals_395, primals_396, primals_397, primals_398, primals_399, primals_400, primals_401, primals_402, primals_403, primals_404, primals_405, primals_406, primals_407, primals_408, primals_409, primals_410, primals_411, primals_412, primals_413, primals_414, primals_415, primals_416, primals_417, primals_418, primals_419, primals_420, primals_421, primals_422, primals_423, primals_424, primals_425, primals_426, primals_427, primals_428, primals_429, primals_430, primals_431, primals_432, primals_433, primals_434, primals_435, primals_436, primals_437, primals_438, primals_439, primals_440, primals_441, primals_442, primals_443, primals_444, primals_445, primals_446, primals_447, primals_448, primals_449, primals_450, primals_451, primals_452, primals_453, primals_454, primals_455, primals_456, primals_457, primals_458, primals_459, primals_460, primals_461, primals_462, primals_463, primals_464, primals_465, primals_466, primals_467, primals_468, primals_469, primals_470, primals_471, primals_472, primals_473, primals_474, primals_475, primals_476, primals_477, primals_478, primals_479, primals_480, primals_481, primals_482, primals_483, primals_484, primals_485, primals_486, primals_487, primals_488, primals_489, primals_490, primals_491, primals_492, primals_493, primals_494, primals_495, primals_496, primals_497, primals_498, primals_499, primals_500, primals_501, primals_502, primals_503, primals_504, primals_505, primals_506, primals_507, primals_508, primals_509, primals_510, primals_511, primals_512, primals_513, primals_514, primals_515, primals_516, primals_517, primals_518, primals_519, primals_520, primals_521, primals_522, primals_523, primals_524, primals_525, primals_526, primals_527, primals_528, primals_529, primals_530, primals_531, primals_532, primals_533, primals_534, primals_535, primals_536, primals_537, primals_538, primals_539, primals_540, primals_541, primals_542, primals_543, primals_544, primals_545, primals_546, primals_547, primals_548, primals_549, primals_550, primals_551, primals_552, primals_553, primals_554, primals_555, primals_556, primals_557, primals_558, primals_559, primals_560, primals_561, primals_562, primals_563, primals_564, primals_565, primals_566, primals_567, primals_568, primals_569, primals_570, primals_571, primals_572, primals_573, primals_574, primals_575, primals_576, primals_577, primals_578, primals_579, primals_580, primals_581, primals_582, primals_583, primals_584, primals_585, primals_586, primals_587, primals_588, primals_589, primals_590, primals_591, primals_592, primals_593, primals_594, primals_595, primals_596, primals_597, primals_598, primals_599, primals_600, primals_601, primals_602, primals_603, primals_604, primals_605, primals_606, primals_607, primals_608, primals_609, primals_610, primals_611, primals_612, primals_613, primals_614, primals_615, primals_616, primals_617, primals_618, primals_619, primals_620, primals_621, primals_622, primals_623, primals_624, primals_625, primals_626, primals_627, primals_628, primals_629, primals_630, primals_631, primals_632, primals_633, primals_634, primals_635, primals_636, primals_637, primals_638, primals_639, primals_640, primals_641, primals_642, primals_643, primals_644, primals_645, primals_646, primals_647, primals_648, primals_649, primals_650, primals_651, primals_652, primals_653, primals_654, primals_655, primals_656, primals_657, primals_658, primals_659, primals_660, primals_661, primals_662, primals_663, primals_664, primals_665, primals_666, primals_667, primals_668, primals_669, primals_670, primals_671, primals_672, primals_673, primals_674, primals_675, primals_676, primals_677, primals_678, primals_679, primals_680, primals_681, primals_682, primals_683, primals_684, primals_685, primals_686, primals_687, primals_688, primals_689, primals_690, primals_691, primals_692, primals_693, primals_694, primals_695, primals_696, primals_697, primals_698, primals_699, primals_700, primals_701, primals_702, primals_703, primals_704, primals_705, primals_706, primals_707, primals_708, primals_709, primals_710, primals_711, primals_712, primals_713, primals_714, primals_715, primals_716, primals_717, primals_718, primals_719, primals_720, primals_721, primals_722, primals_723, primals_724, primals_725, primals_726, primals_727, primals_728, primals_729, primals_730, primals_731, primals_732, primals_733, primals_734, primals_735, primals_736, primals_737, primals_738, primals_739, primals_740, primals_741, primals_742, primals_743, primals_744, primals_745, primals_746, primals_747, primals_748, primals_749, primals_750, primals_751, primals_752, primals_753, primals_754, primals_755, primals_756, primals_757, primals_758, primals_759, primals_760, primals_761, primals_762, primals_763, primals_764, primals_765, primals_766, primals_767, primals_768, primals_769, primals_770, primals_771, primals_772, primals_773, primals_774, primals_775, primals_776, primals_777, primals_778, primals_779, primals_780, primals_781, primals_782, primals_783, primals_784, primals_785, primals_786, primals_787, primals_788, primals_789, primals_790, primals_791, primals_792, primals_793, primals_794, primals_795, primals_796, primals_797, primals_798, primals_799, primals_800, primals_801, primals_802, primals_803, primals_804, primals_805, primals_806, primals_807, primals_808, primals_809, primals_810, primals_811, primals_812, primals_813, primals_814, primals_815, primals_816, primals_817, primals_818, primals_819, primals_820, primals_821, primals_822, primals_823, primals_824, primals_825, primals_826, primals_827, primals_828, primals_829, primals_830, primals_831, primals_832, primals_833, primals_834, primals_835, primals_836, primals_837, primals_838, primals_839, primals_840, primals_841, primals_842, primals_843, primals_844, primals_845, primals_846, primals_847, primals_848, primals_849, primals_850, primals_851, primals_852, primals_853, primals_854, primals_855, primals_856, primals_857, primals_858, primals_859, primals_860, primals_861, primals_862, primals_863, primals_864, primals_865, primals_866, primals_867, primals_868, primals_869, primals_870, primals_871, primals_872, primals_873, primals_874, primals_875, primals_876, primals_877, primals_878, primals_879, primals_880, primals_881, primals_882, primals_883, primals_884, primals_885, primals_886, primals_887, primals_888, primals_889, primals_890, primals_891, primals_892, primals_893, primals_894, primals_895, primals_896, primals_897, primals_898, primals_899, primals_900, primals_901, primals_902, primals_903, primals_904, primals_905, primals_906, primals_907, primals_908, primals_909, primals_910, primals_911, primals_912, primals_913, primals_914, primals_915, primals_916, primals_917, primals_918, primals_919, primals_920, primals_921, primals_922, primals_923, primals_924, primals_925, primals_926, primals_927, primals_928, primals_929, primals_930, primals_931, primals_932, primals_933, primals_934, primals_935, primals_936, primals_937, primals_938, primals_939, primals_940, primals_941, primals_942, primals_943, primals_944, primals_945, primals_946, primals_947, primals_948, primals_949, primals_950, primals_951, primals_952, primals_953, primals_954, primals_955, primals_956, primals_957, primals_958, primals_959, primals_960, primals_961, primals_962, primals_963, primals_964, primals_965, primals_966, primals_967, primals_968, primals_969, primals_970, primals_971, primals_972, primals_973, primals_974, primals_975, primals_976, primals_977, primals_978, primals_979, primals_980, primals_981, primals_982, primals_983, primals_984, primals_985, primals_986, primals_987, primals_988, primals_989, primals_990, primals_991, primals_992, primals_993, primals_994, primals_995, primals_996, primals_997, primals_998, primals_999, primals_1000, primals_1001, primals_1002, primals_1003, primals_1004, primals_1005, primals_1006, primals_1007, primals_1008, primals_1009, primals_1010, primals_1011, primals_1012, primals_1013, primals_1014, primals_1015, primals_1016, primals_1017, primals_1018, primals_1019, primals_1020, primals_1021, primals_1022, primals_1023, primals_1024, primals_1025, primals_1026, primals_1027, primals_1028, primals_1029, primals_1030, primals_1031, primals_1032, primals_1033, primals_1034, primals_1035, primals_1036, primals_1037, primals_1038, primals_1039, primals_1040, primals_1041, primals_1042, primals_1043, primals_1044, primals_1045, primals_1046, primals_1047, primals_1048, primals_1049, primals_1050, primals_1051, primals_1052, primals_1053, primals_1054, primals_1055, primals_1056, primals_1057, primals_1058, primals_1059, primals_1060, primals_1061, primals_1062, primals_1063, primals_1064, primals_1065, primals_1066, primals_1067, primals_1068, primals_1069, primals_1070, primals_1071, primals_1072, primals_1073, primals_1074, primals_1075, primals_1076, primals_1077, primals_1078, primals_1079, primals_1080, primals_1081, primals_1082, primals_1083, primals_1084, primals_1085, primals_1086, primals_1087, primals_1088, primals_1089, primals_1090, primals_1091, primals_1092, primals_1093, primals_1094, primals_1095, primals_1096, primals_1097, primals_1098, primals_1099, primals_1100, primals_1101, primals_1102, primals_1103, primals_1104, primals_1105, primals_1106, primals_1107, primals_1108, primals_1109, primals_1110, primals_1111, primals_1112, primals_1113, primals_1114, primals_1115, primals_1116, primals_1117, primals_1118, primals_1119, primals_1120, primals_1121, primals_1122, primals_1123, primals_1124, primals_1125, primals_1126, primals_1127, primals_1128, primals_1129, primals_1130, primals_1131, primals_1132, primals_1133, primals_1134, primals_1135, primals_1136, primals_1137, primals_1138, primals_1139, primals_1140, primals_1141, primals_1142, primals_1143, primals_1144, primals_1145, primals_1146, primals_1147, primals_1148, primals_1149, primals_1150, primals_1151, primals_1152, primals_1153, primals_1154, primals_1155, primals_1156, primals_1157, primals_1158, primals_1159, primals_1160, primals_1161, primals_1162, primals_1163, primals_1164, primals_1165, primals_1166, primals_1167, primals_1168, primals_1169, primals_1170, primals_1171, primals_1172, primals_1173, primals_1174, primals_1175, primals_1176, primals_1177, primals_1178, primals_1179, primals_1180, primals_1181, primals_1182, primals_1183, primals_1184, primals_1185, primals_1186, primals_1187, primals_1188, primals_1189, primals_1190, primals_1191, primals_1192, primals_1193, primals_1194, primals_1195, primals_1196, primals_1197, primals_1198, primals_1199, primals_1200, primals_1201, primals_1202, primals_1203, primals_1204, primals_1205, primals_1206, primals_1207, primals_1208, primals_1209, primals_1210, primals_1211, primals_1212, primals_1213, primals_1214, primals_1215, primals_1216, primals_1217, primals_1218, primals_1219, primals_1220, primals_1221, primals_1222, primals_1223, primals_1224, primals_1225, primals_1226, primals_1227, primals_1228, primals_1229, primals_1230, primals_1231, primals_1232, primals_1233, primals_1234, primals_1235, primals_1236, primals_1237, primals_1238, primals_1239, primals_1240, primals_1241, primals_1242, primals_1243, primals_1244, primals_1245, primals_1246, primals_1247, primals_1248, primals_1249, primals_1250, primals_1251, primals_1252, primals_1253, primals_1254, primals_1255, primals_1256, primals_1257, primals_1258, primals_1259, primals_1260, primals_1261, primals_1262, primals_1263, primals_1264, primals_1265, primals_1266, primals_1267, primals_1268, primals_1269, primals_1270, primals_1271, primals_1272, primals_1273, primals_1274, primals_1275, primals_1276, primals_1277, primals_1278, primals_1279, primals_1280, primals_1281, primals_1282, primals_1283, primals_1284, primals_1285, primals_1286, primals_1287, primals_1288, primals_1289, primals_1290, primals_1291, primals_1292, primals_1293, primals_1294, primals_1295, primals_1296, primals_1297, primals_1298, primals_1299, primals_1300, primals_1301, primals_1302, primals_1303, primals_1304, primals_1305, primals_1306, primals_1307, primals_1308, primals_1309, primals_1310, primals_1311, primals_1312, primals_1313, primals_1314, primals_1315, primals_1316, primals_1317, primals_1318, primals_1319, primals_1320, primals_1321, primals_1322, primals_1323, primals_1324, primals_1325, primals_1326, primals_1327, primals_1328, primals_1329, primals_1330, primals_1331, primals_1332, primals_1333, primals_1334, primals_1335, primals_1336, primals_1337, primals_1338, primals_1339, primals_1340, primals_1341, primals_1342, primals_1343, primals_1344, primals_1345, primals_1346, primals_1347, primals_1348, primals_1349, primals_1350, primals_1351, primals_1352, primals_1353, primals_1354, primals_1355, primals_1356, primals_1357, primals_1358, primals_1359, primals_1360, primals_1361, primals_1362, primals_1363, primals_1364, primals_1365, primals_1366, primals_1367, primals_1368, primals_1369, primals_1370, primals_1371, primals_1372, primals_1373, primals_1374, primals_1375, primals_1376, primals_1377, primals_1378, primals_1379, primals_1380, primals_1381, primals_1382, primals_1383, primals_1384, primals_1385, primals_1386, primals_1387, primals_1388, primals_1389, primals_1390, primals_1391, primals_1392, primals_1393, primals_1394, primals_1395, primals_1396, primals_1397, primals_1398, primals_1399, primals_1400, primals_1401, primals_1402, primals_1403, primals_1404, primals_1405, primals_1406, primals_1407, primals_1408, primals_1409, primals_1410, primals_1411, primals_1412, primals_1413, primals_1414, primals_1415, primals_1416, primals_1417, primals_1418, primals_1419, primals_1420, primals_1421, primals_1422, primals_1423, primals_1424, primals_1425, primals_1426, primals_1427, primals_1428, primals_1429, primals_1430, primals_1431, primals_1432, primals_1433, primals_1434, primals_1435, primals_1436, primals_1437, primals_1438, primals_1439, primals_1440, primals_1441, primals_1442, primals_1443, primals_1444, primals_1445, primals_1446, primals_1447, primals_1448, primals_1449, primals_1450, primals_1451, primals_1452, primals_1453, primals_1454, primals_1455, primals_1456, primals_1457, primals_1458, primals_1459, primals_1460, primals_1461, primals_1462, primals_1463, primals_1464, primals_1465, primals_1466, primals_1467, primals_1468, primals_1469, primals_1470, primals_1471, primals_1472, primals_1473, primals_1474, primals_1475, primals_1476, primals_1477, primals_1478, primals_1479, primals_1480, primals_1481, primals_1482, primals_1483, primals_1484, primals_1485, primals_1486, primals_1487, primals_1488, primals_1489, primals_1490, primals_1491, primals_1492, primals_1493, primals_1494, primals_1495, primals_1496, primals_1497, primals_1498, primals_1499, primals_1500, primals_1501, primals_1502, primals_1503, primals_1504, primals_1505, primals_1506, primals_1507, primals_1508, primals_1509, primals_1510, primals_1511, primals_1512, primals_1513, primals_1514, primals_1515, primals_1516, primals_1517, primals_1518, primals_1519, primals_1520, primals_1521, primals_1522, primals_1523, primals_1524, primals_1525, primals_1526, primals_1527, primals_1528, primals_1529, primals_1530, primals_1531, primals_1532, primals_1533, primals_1534, primals_1535, primals_1536, primals_1537, primals_1538, primals_1539, primals_1540, primals_1541, primals_1542, primals_1543, primals_1544, primals_1545, primals_1546, primals_1547, primals_1548, primals_1549, primals_1550, primals_1551, primals_1552, primals_1553, primals_1554, primals_1555, primals_1556, primals_1557, primals_1558, primals_1559, primals_1560, primals_1561, primals_1562, primals_1563, primals_1564, primals_1565, primals_1566, primals_1567, primals_1568, primals_1569, primals_1570, primals_1571, primals_1572, primals_1573, primals_1574, primals_1575, primals_1576, primals_1577, primals_1578, primals_1579, primals_1580, primals_1581, primals_1582, primals_1583, primals_1584, primals_1585, primals_1586, primals_1587, primals_1588, primals_1589, primals_1590, primals_1591, primals_1592, primals_1593, primals_1594, primals_1595, primals_1596, primals_1597, primals_1598, primals_1599, primals_1600, primals_1601, primals_1602, primals_1603, primals_1604, primals_1605, primals_1606, primals_1607, primals_1608, primals_1609, primals_1610, primals_1611, primals_1612, primals_1613, primals_1614, primals_1615, primals_1616, primals_1617, primals_1618, primals_1619, primals_1620, primals_1621, primals_1622, primals_1623, primals_1624, primals_1625, primals_1626, primals_1627, primals_1628, primals_1629, primals_1630, primals_1631, primals_1632, primals_1633, primals_1634, primals_1635, primals_1636, primals_1637, primals_1638, primals_1639, primals_1640, primals_1641, primals_1642, primals_1643, primals_1644, primals_1645, primals_1646, primals_1647, primals_1648, primals_1649, primals_1650, primals_1651, primals_1652, primals_1653, primals_1654, primals_1655, primals_1656, primals_1657, primals_1658, primals_1659, primals_1660, primals_1661, primals_1662, primals_1663, primals_1664, primals_1665, primals_1666, primals_1667, primals_1668, primals_1669, primals_1670, primals_1671, primals_1672, primals_1673, primals_1674, primals_1675, primals_1676, primals_1677, primals_1678, primals_1679, primals_1680, primals_1681, primals_1682, primals_1683, primals_1684, primals_1685, primals_1686, primals_1687, primals_1688, primals_1689, primals_1690, primals_1691, primals_1692, primals_1693, primals_1694, primals_1695, primals_1696, primals_1697, primals_1698, primals_1699, primals_1700, primals_1701, primals_1702, primals_1703, primals_1704, primals_1705, primals_1706, primals_1707, primals_1708, primals_1709, primals_1710, primals_1711, primals_1712, primals_1713, primals_1714, primals_1715, primals_1716, primals_1717, primals_1718, primals_1719, primals_1720, primals_1721, primals_1722, primals_1723, primals_1724, primals_1725, primals_1726, primals_1727, primals_1728, primals_1729, primals_1730, primals_1731, primals_1732, primals_1733, primals_1734, primals_1735, primals_1736, primals_1737, primals_1738, primals_1739, primals_1740, primals_1741, primals_1742, primals_1743, primals_1744, primals_1745, primals_1746, primals_1747, primals_1748, primals_1749, primals_1750, primals_1751, primals_1752, primals_1753, primals_1754, primals_1755, primals_1756, primals_1757, primals_1758, primals_1759, primals_1760, primals_1761, primals_1762, primals_1763, primals_1764, primals_1765, primals_1766, primals_1767, primals_1768, primals_1769, primals_1770, primals_1771, primals_1772, primals_1773, primals_1774, primals_1775, primals_1776, primals_1777, primals_1778, primals_1779, primals_1780, primals_1781, primals_1782, primals_1783, primals_1784, primals_1785, primals_1786, primals_1787, primals_1788, primals_1789, primals_1790, primals_1791, primals_1792, primals_1793, primals_1794, primals_1795, primals_1796, primals_1797, primals_1798, primals_1799, primals_1800, primals_1801, primals_1802, primals_1803, primals_1804, primals_1805, primals_1806, primals_1807, primals_1808, primals_1809, primals_1810, primals_1811, primals_1812, primals_1813, primals_1814, primals_1815, primals_1816, primals_1817, primals_1818, primals_1819, primals_1820, primals_1821, primals_1822, primals_1823, primals_1824, primals_1825, primals_1826, primals_1827, primals_1828, primals_1829, primals_1830, primals_1831, primals_1832, primals_1833, primals_1834, primals_1835, primals_1836, primals_1837, primals_1838, primals_1839, primals_1840, primals_1841, primals_1842, primals_1843, primals_1844, primals_1845, primals_1846, primals_1847, primals_1848, primals_1849, primals_1850, primals_1851, primals_1852, primals_1853, primals_1854, primals_1855, primals_1856, primals_1857, primals_1858, primals_1859, primals_1860, primals_1861, primals_1862, primals_1863, primals_1864, primals_1865, primals_1866, primals_1867, primals_1868, primals_1869, primals_1870, primals_1871, primals_1872, primals_1873, primals_1874, primals_1875, primals_1876, primals_1877, primals_1878, primals_1879, primals_1880, primals_1881, primals_1882, primals_1883, primals_1884, primals_1885, primals_1886, primals_1887, primals_1888, primals_1889, primals_1890, primals_1891, primals_1892, primals_1893, primals_1894, primals_1895, primals_1896, primals_1897, primals_1898, primals_1899, primals_1900, primals_1901, primals_1902, primals_1903, primals_1904, primals_1905, primals_1906, primals_1907, primals_1908, primals_1909, primals_1910, primals_1911, primals_1912, primals_1913, primals_1914, primals_1915, primals_1916, primals_1917, primals_1918, primals_1919, primals_1920, primals_1921, primals_1922, primals_1923, primals_1924, primals_1925, primals_1926, primals_1927, primals_1928, primals_1929, primals_1930, primals_1931, primals_1932, primals_1933, primals_1934, primals_1935, primals_1936, primals_1937, primals_1938, primals_1939, primals_1940, primals_1941, primals_1942, primals_1943, primals_1944, primals_1945, primals_1946, primals_1947, primals_1948, primals_1949, primals_1950, primals_1951, primals_1952, primals_1953, primals_1954, primals_1955, primals_1956, primals_1957 = args
    args.clear()
    assert_size_stride(primals_1, (64, 3, 3, 3), (27, 9, 3, 1))
    assert_size_stride(primals_2, (64, ), (1, ))
    assert_size_stride(primals_3, (64, ), (1, ))
    assert_size_stride(primals_4, (64, 64, 3, 3), (576, 9, 3, 1))
    assert_size_stride(primals_5, (64, ), (1, ))
    assert_size_stride(primals_6, (64, ), (1, ))
    assert_size_stride(primals_7, (64, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(primals_8, (64, ), (1, ))
    assert_size_stride(primals_9, (64, ), (1, ))
    assert_size_stride(primals_10, (64, 64, 3, 3), (576, 9, 3, 1))
    assert_size_stride(primals_11, (64, ), (1, ))
    assert_size_stride(primals_12, (64, ), (1, ))
    assert_size_stride(primals_13, (256, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(primals_14, (256, ), (1, ))
    assert_size_stride(primals_15, (256, ), (1, ))
    assert_size_stride(primals_16, (256, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(primals_17, (256, ), (1, ))
    assert_size_stride(primals_18, (256, ), (1, ))
    assert_size_stride(primals_19, (64, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(primals_20, (64, ), (1, ))
    assert_size_stride(primals_21, (64, ), (1, ))
    assert_size_stride(primals_22, (64, 64, 3, 3), (576, 9, 3, 1))
    assert_size_stride(primals_23, (64, ), (1, ))
    assert_size_stride(primals_24, (64, ), (1, ))
    assert_size_stride(primals_25, (256, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(primals_26, (256, ), (1, ))
    assert_size_stride(primals_27, (256, ), (1, ))
    assert_size_stride(primals_28, (64, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(primals_29, (64, ), (1, ))
    assert_size_stride(primals_30, (64, ), (1, ))
    assert_size_stride(primals_31, (64, 64, 3, 3), (576, 9, 3, 1))
    assert_size_stride(primals_32, (64, ), (1, ))
    assert_size_stride(primals_33, (64, ), (1, ))
    assert_size_stride(primals_34, (256, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(primals_35, (256, ), (1, ))
    assert_size_stride(primals_36, (256, ), (1, ))
    assert_size_stride(primals_37, (64, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(primals_38, (64, ), (1, ))
    assert_size_stride(primals_39, (64, ), (1, ))
    assert_size_stride(primals_40, (64, 64, 3, 3), (576, 9, 3, 1))
    assert_size_stride(primals_41, (64, ), (1, ))
    assert_size_stride(primals_42, (64, ), (1, ))
    assert_size_stride(primals_43, (256, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(primals_44, (256, ), (1, ))
    assert_size_stride(primals_45, (256, ), (1, ))
    assert_size_stride(primals_46, (18, 256, 3, 3), (2304, 9, 3, 1))
    assert_size_stride(primals_47, (18, ), (1, ))
    assert_size_stride(primals_48, (18, ), (1, ))
    assert_size_stride(primals_49, (36, 256, 3, 3), (2304, 9, 3, 1))
    assert_size_stride(primals_50, (36, ), (1, ))
    assert_size_stride(primals_51, (36, ), (1, ))
    assert_size_stride(primals_52, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_53, (18, ), (1, ))
    assert_size_stride(primals_54, (18, ), (1, ))
    assert_size_stride(primals_55, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_56, (18, ), (1, ))
    assert_size_stride(primals_57, (18, ), (1, ))
    assert_size_stride(primals_58, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_59, (18, ), (1, ))
    assert_size_stride(primals_60, (18, ), (1, ))
    assert_size_stride(primals_61, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_62, (18, ), (1, ))
    assert_size_stride(primals_63, (18, ), (1, ))
    assert_size_stride(primals_64, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_65, (18, ), (1, ))
    assert_size_stride(primals_66, (18, ), (1, ))
    assert_size_stride(primals_67, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_68, (18, ), (1, ))
    assert_size_stride(primals_69, (18, ), (1, ))
    assert_size_stride(primals_70, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_71, (18, ), (1, ))
    assert_size_stride(primals_72, (18, ), (1, ))
    assert_size_stride(primals_73, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_74, (18, ), (1, ))
    assert_size_stride(primals_75, (18, ), (1, ))
    assert_size_stride(primals_76, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_77, (36, ), (1, ))
    assert_size_stride(primals_78, (36, ), (1, ))
    assert_size_stride(primals_79, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_80, (36, ), (1, ))
    assert_size_stride(primals_81, (36, ), (1, ))
    assert_size_stride(primals_82, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_83, (36, ), (1, ))
    assert_size_stride(primals_84, (36, ), (1, ))
    assert_size_stride(primals_85, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_86, (36, ), (1, ))
    assert_size_stride(primals_87, (36, ), (1, ))
    assert_size_stride(primals_88, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_89, (36, ), (1, ))
    assert_size_stride(primals_90, (36, ), (1, ))
    assert_size_stride(primals_91, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_92, (36, ), (1, ))
    assert_size_stride(primals_93, (36, ), (1, ))
    assert_size_stride(primals_94, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_95, (36, ), (1, ))
    assert_size_stride(primals_96, (36, ), (1, ))
    assert_size_stride(primals_97, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_98, (36, ), (1, ))
    assert_size_stride(primals_99, (36, ), (1, ))
    assert_size_stride(primals_100, (18, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_101, (18, ), (1, ))
    assert_size_stride(primals_102, (18, ), (1, ))
    assert_size_stride(primals_103, (36, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_104, (36, ), (1, ))
    assert_size_stride(primals_105, (36, ), (1, ))
    assert_size_stride(primals_106, (72, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_107, (72, ), (1, ))
    assert_size_stride(primals_108, (72, ), (1, ))
    assert_size_stride(primals_109, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_110, (18, ), (1, ))
    assert_size_stride(primals_111, (18, ), (1, ))
    assert_size_stride(primals_112, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_113, (18, ), (1, ))
    assert_size_stride(primals_114, (18, ), (1, ))
    assert_size_stride(primals_115, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_116, (18, ), (1, ))
    assert_size_stride(primals_117, (18, ), (1, ))
    assert_size_stride(primals_118, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_119, (18, ), (1, ))
    assert_size_stride(primals_120, (18, ), (1, ))
    assert_size_stride(primals_121, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_122, (18, ), (1, ))
    assert_size_stride(primals_123, (18, ), (1, ))
    assert_size_stride(primals_124, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_125, (18, ), (1, ))
    assert_size_stride(primals_126, (18, ), (1, ))
    assert_size_stride(primals_127, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_128, (18, ), (1, ))
    assert_size_stride(primals_129, (18, ), (1, ))
    assert_size_stride(primals_130, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_131, (18, ), (1, ))
    assert_size_stride(primals_132, (18, ), (1, ))
    assert_size_stride(primals_133, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_134, (36, ), (1, ))
    assert_size_stride(primals_135, (36, ), (1, ))
    assert_size_stride(primals_136, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_137, (36, ), (1, ))
    assert_size_stride(primals_138, (36, ), (1, ))
    assert_size_stride(primals_139, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_140, (36, ), (1, ))
    assert_size_stride(primals_141, (36, ), (1, ))
    assert_size_stride(primals_142, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_143, (36, ), (1, ))
    assert_size_stride(primals_144, (36, ), (1, ))
    assert_size_stride(primals_145, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_146, (36, ), (1, ))
    assert_size_stride(primals_147, (36, ), (1, ))
    assert_size_stride(primals_148, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_149, (36, ), (1, ))
    assert_size_stride(primals_150, (36, ), (1, ))
    assert_size_stride(primals_151, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_152, (36, ), (1, ))
    assert_size_stride(primals_153, (36, ), (1, ))
    assert_size_stride(primals_154, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_155, (36, ), (1, ))
    assert_size_stride(primals_156, (36, ), (1, ))
    assert_size_stride(primals_157, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_158, (72, ), (1, ))
    assert_size_stride(primals_159, (72, ), (1, ))
    assert_size_stride(primals_160, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_161, (72, ), (1, ))
    assert_size_stride(primals_162, (72, ), (1, ))
    assert_size_stride(primals_163, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_164, (72, ), (1, ))
    assert_size_stride(primals_165, (72, ), (1, ))
    assert_size_stride(primals_166, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_167, (72, ), (1, ))
    assert_size_stride(primals_168, (72, ), (1, ))
    assert_size_stride(primals_169, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_170, (72, ), (1, ))
    assert_size_stride(primals_171, (72, ), (1, ))
    assert_size_stride(primals_172, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_173, (72, ), (1, ))
    assert_size_stride(primals_174, (72, ), (1, ))
    assert_size_stride(primals_175, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_176, (72, ), (1, ))
    assert_size_stride(primals_177, (72, ), (1, ))
    assert_size_stride(primals_178, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_179, (72, ), (1, ))
    assert_size_stride(primals_180, (72, ), (1, ))
    assert_size_stride(primals_181, (18, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_182, (18, ), (1, ))
    assert_size_stride(primals_183, (18, ), (1, ))
    assert_size_stride(primals_184, (18, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_185, (18, ), (1, ))
    assert_size_stride(primals_186, (18, ), (1, ))
    assert_size_stride(primals_187, (36, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_188, (36, ), (1, ))
    assert_size_stride(primals_189, (36, ), (1, ))
    assert_size_stride(primals_190, (36, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_191, (36, ), (1, ))
    assert_size_stride(primals_192, (36, ), (1, ))
    assert_size_stride(primals_193, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_194, (18, ), (1, ))
    assert_size_stride(primals_195, (18, ), (1, ))
    assert_size_stride(primals_196, (72, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_197, (72, ), (1, ))
    assert_size_stride(primals_198, (72, ), (1, ))
    assert_size_stride(primals_199, (72, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_200, (72, ), (1, ))
    assert_size_stride(primals_201, (72, ), (1, ))
    assert_size_stride(primals_202, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_203, (18, ), (1, ))
    assert_size_stride(primals_204, (18, ), (1, ))
    assert_size_stride(primals_205, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_206, (18, ), (1, ))
    assert_size_stride(primals_207, (18, ), (1, ))
    assert_size_stride(primals_208, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_209, (18, ), (1, ))
    assert_size_stride(primals_210, (18, ), (1, ))
    assert_size_stride(primals_211, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_212, (18, ), (1, ))
    assert_size_stride(primals_213, (18, ), (1, ))
    assert_size_stride(primals_214, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_215, (18, ), (1, ))
    assert_size_stride(primals_216, (18, ), (1, ))
    assert_size_stride(primals_217, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_218, (18, ), (1, ))
    assert_size_stride(primals_219, (18, ), (1, ))
    assert_size_stride(primals_220, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_221, (18, ), (1, ))
    assert_size_stride(primals_222, (18, ), (1, ))
    assert_size_stride(primals_223, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_224, (18, ), (1, ))
    assert_size_stride(primals_225, (18, ), (1, ))
    assert_size_stride(primals_226, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_227, (36, ), (1, ))
    assert_size_stride(primals_228, (36, ), (1, ))
    assert_size_stride(primals_229, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_230, (36, ), (1, ))
    assert_size_stride(primals_231, (36, ), (1, ))
    assert_size_stride(primals_232, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_233, (36, ), (1, ))
    assert_size_stride(primals_234, (36, ), (1, ))
    assert_size_stride(primals_235, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_236, (36, ), (1, ))
    assert_size_stride(primals_237, (36, ), (1, ))
    assert_size_stride(primals_238, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_239, (36, ), (1, ))
    assert_size_stride(primals_240, (36, ), (1, ))
    assert_size_stride(primals_241, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_242, (36, ), (1, ))
    assert_size_stride(primals_243, (36, ), (1, ))
    assert_size_stride(primals_244, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_245, (36, ), (1, ))
    assert_size_stride(primals_246, (36, ), (1, ))
    assert_size_stride(primals_247, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_248, (36, ), (1, ))
    assert_size_stride(primals_249, (36, ), (1, ))
    assert_size_stride(primals_250, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_251, (72, ), (1, ))
    assert_size_stride(primals_252, (72, ), (1, ))
    assert_size_stride(primals_253, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_254, (72, ), (1, ))
    assert_size_stride(primals_255, (72, ), (1, ))
    assert_size_stride(primals_256, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_257, (72, ), (1, ))
    assert_size_stride(primals_258, (72, ), (1, ))
    assert_size_stride(primals_259, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_260, (72, ), (1, ))
    assert_size_stride(primals_261, (72, ), (1, ))
    assert_size_stride(primals_262, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_263, (72, ), (1, ))
    assert_size_stride(primals_264, (72, ), (1, ))
    assert_size_stride(primals_265, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_266, (72, ), (1, ))
    assert_size_stride(primals_267, (72, ), (1, ))
    assert_size_stride(primals_268, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_269, (72, ), (1, ))
    assert_size_stride(primals_270, (72, ), (1, ))
    assert_size_stride(primals_271, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_272, (72, ), (1, ))
    assert_size_stride(primals_273, (72, ), (1, ))
    assert_size_stride(primals_274, (18, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_275, (18, ), (1, ))
    assert_size_stride(primals_276, (18, ), (1, ))
    assert_size_stride(primals_277, (18, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_278, (18, ), (1, ))
    assert_size_stride(primals_279, (18, ), (1, ))
    assert_size_stride(primals_280, (36, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_281, (36, ), (1, ))
    assert_size_stride(primals_282, (36, ), (1, ))
    assert_size_stride(primals_283, (36, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_284, (36, ), (1, ))
    assert_size_stride(primals_285, (36, ), (1, ))
    assert_size_stride(primals_286, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_287, (18, ), (1, ))
    assert_size_stride(primals_288, (18, ), (1, ))
    assert_size_stride(primals_289, (72, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_290, (72, ), (1, ))
    assert_size_stride(primals_291, (72, ), (1, ))
    assert_size_stride(primals_292, (72, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_293, (72, ), (1, ))
    assert_size_stride(primals_294, (72, ), (1, ))
    assert_size_stride(primals_295, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_296, (18, ), (1, ))
    assert_size_stride(primals_297, (18, ), (1, ))
    assert_size_stride(primals_298, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_299, (18, ), (1, ))
    assert_size_stride(primals_300, (18, ), (1, ))
    assert_size_stride(primals_301, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_302, (18, ), (1, ))
    assert_size_stride(primals_303, (18, ), (1, ))
    assert_size_stride(primals_304, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_305, (18, ), (1, ))
    assert_size_stride(primals_306, (18, ), (1, ))
    assert_size_stride(primals_307, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_308, (18, ), (1, ))
    assert_size_stride(primals_309, (18, ), (1, ))
    assert_size_stride(primals_310, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_311, (18, ), (1, ))
    assert_size_stride(primals_312, (18, ), (1, ))
    assert_size_stride(primals_313, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_314, (18, ), (1, ))
    assert_size_stride(primals_315, (18, ), (1, ))
    assert_size_stride(primals_316, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_317, (18, ), (1, ))
    assert_size_stride(primals_318, (18, ), (1, ))
    assert_size_stride(primals_319, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_320, (36, ), (1, ))
    assert_size_stride(primals_321, (36, ), (1, ))
    assert_size_stride(primals_322, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_323, (36, ), (1, ))
    assert_size_stride(primals_324, (36, ), (1, ))
    assert_size_stride(primals_325, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_326, (36, ), (1, ))
    assert_size_stride(primals_327, (36, ), (1, ))
    assert_size_stride(primals_328, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_329, (36, ), (1, ))
    assert_size_stride(primals_330, (36, ), (1, ))
    assert_size_stride(primals_331, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_332, (36, ), (1, ))
    assert_size_stride(primals_333, (36, ), (1, ))
    assert_size_stride(primals_334, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_335, (36, ), (1, ))
    assert_size_stride(primals_336, (36, ), (1, ))
    assert_size_stride(primals_337, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_338, (36, ), (1, ))
    assert_size_stride(primals_339, (36, ), (1, ))
    assert_size_stride(primals_340, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_341, (36, ), (1, ))
    assert_size_stride(primals_342, (36, ), (1, ))
    assert_size_stride(primals_343, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_344, (72, ), (1, ))
    assert_size_stride(primals_345, (72, ), (1, ))
    assert_size_stride(primals_346, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_347, (72, ), (1, ))
    assert_size_stride(primals_348, (72, ), (1, ))
    assert_size_stride(primals_349, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_350, (72, ), (1, ))
    assert_size_stride(primals_351, (72, ), (1, ))
    assert_size_stride(primals_352, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_353, (72, ), (1, ))
    assert_size_stride(primals_354, (72, ), (1, ))
    assert_size_stride(primals_355, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_356, (72, ), (1, ))
    assert_size_stride(primals_357, (72, ), (1, ))
    assert_size_stride(primals_358, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_359, (72, ), (1, ))
    assert_size_stride(primals_360, (72, ), (1, ))
    assert_size_stride(primals_361, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_362, (72, ), (1, ))
    assert_size_stride(primals_363, (72, ), (1, ))
    assert_size_stride(primals_364, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_365, (72, ), (1, ))
    assert_size_stride(primals_366, (72, ), (1, ))
    assert_size_stride(primals_367, (18, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_368, (18, ), (1, ))
    assert_size_stride(primals_369, (18, ), (1, ))
    assert_size_stride(primals_370, (18, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_371, (18, ), (1, ))
    assert_size_stride(primals_372, (18, ), (1, ))
    assert_size_stride(primals_373, (36, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_374, (36, ), (1, ))
    assert_size_stride(primals_375, (36, ), (1, ))
    assert_size_stride(primals_376, (36, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_377, (36, ), (1, ))
    assert_size_stride(primals_378, (36, ), (1, ))
    assert_size_stride(primals_379, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_380, (18, ), (1, ))
    assert_size_stride(primals_381, (18, ), (1, ))
    assert_size_stride(primals_382, (72, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_383, (72, ), (1, ))
    assert_size_stride(primals_384, (72, ), (1, ))
    assert_size_stride(primals_385, (72, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_386, (72, ), (1, ))
    assert_size_stride(primals_387, (72, ), (1, ))
    assert_size_stride(primals_388, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_389, (18, ), (1, ))
    assert_size_stride(primals_390, (18, ), (1, ))
    assert_size_stride(primals_391, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_392, (18, ), (1, ))
    assert_size_stride(primals_393, (18, ), (1, ))
    assert_size_stride(primals_394, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_395, (18, ), (1, ))
    assert_size_stride(primals_396, (18, ), (1, ))
    assert_size_stride(primals_397, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_398, (18, ), (1, ))
    assert_size_stride(primals_399, (18, ), (1, ))
    assert_size_stride(primals_400, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_401, (18, ), (1, ))
    assert_size_stride(primals_402, (18, ), (1, ))
    assert_size_stride(primals_403, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_404, (18, ), (1, ))
    assert_size_stride(primals_405, (18, ), (1, ))
    assert_size_stride(primals_406, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_407, (18, ), (1, ))
    assert_size_stride(primals_408, (18, ), (1, ))
    assert_size_stride(primals_409, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_410, (18, ), (1, ))
    assert_size_stride(primals_411, (18, ), (1, ))
    assert_size_stride(primals_412, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_413, (36, ), (1, ))
    assert_size_stride(primals_414, (36, ), (1, ))
    assert_size_stride(primals_415, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_416, (36, ), (1, ))
    assert_size_stride(primals_417, (36, ), (1, ))
    assert_size_stride(primals_418, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_419, (36, ), (1, ))
    assert_size_stride(primals_420, (36, ), (1, ))
    assert_size_stride(primals_421, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_422, (36, ), (1, ))
    assert_size_stride(primals_423, (36, ), (1, ))
    assert_size_stride(primals_424, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_425, (36, ), (1, ))
    assert_size_stride(primals_426, (36, ), (1, ))
    assert_size_stride(primals_427, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_428, (36, ), (1, ))
    assert_size_stride(primals_429, (36, ), (1, ))
    assert_size_stride(primals_430, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_431, (36, ), (1, ))
    assert_size_stride(primals_432, (36, ), (1, ))
    assert_size_stride(primals_433, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_434, (36, ), (1, ))
    assert_size_stride(primals_435, (36, ), (1, ))
    assert_size_stride(primals_436, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_437, (72, ), (1, ))
    assert_size_stride(primals_438, (72, ), (1, ))
    assert_size_stride(primals_439, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_440, (72, ), (1, ))
    assert_size_stride(primals_441, (72, ), (1, ))
    assert_size_stride(primals_442, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_443, (72, ), (1, ))
    assert_size_stride(primals_444, (72, ), (1, ))
    assert_size_stride(primals_445, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_446, (72, ), (1, ))
    assert_size_stride(primals_447, (72, ), (1, ))
    assert_size_stride(primals_448, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_449, (72, ), (1, ))
    assert_size_stride(primals_450, (72, ), (1, ))
    assert_size_stride(primals_451, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_452, (72, ), (1, ))
    assert_size_stride(primals_453, (72, ), (1, ))
    assert_size_stride(primals_454, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_455, (72, ), (1, ))
    assert_size_stride(primals_456, (72, ), (1, ))
    assert_size_stride(primals_457, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_458, (72, ), (1, ))
    assert_size_stride(primals_459, (72, ), (1, ))
    assert_size_stride(primals_460, (18, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_461, (18, ), (1, ))
    assert_size_stride(primals_462, (18, ), (1, ))
    assert_size_stride(primals_463, (18, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_464, (18, ), (1, ))
    assert_size_stride(primals_465, (18, ), (1, ))
    assert_size_stride(primals_466, (36, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_467, (36, ), (1, ))
    assert_size_stride(primals_468, (36, ), (1, ))
    assert_size_stride(primals_469, (36, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_470, (36, ), (1, ))
    assert_size_stride(primals_471, (36, ), (1, ))
    assert_size_stride(primals_472, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_473, (18, ), (1, ))
    assert_size_stride(primals_474, (18, ), (1, ))
    assert_size_stride(primals_475, (72, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_476, (72, ), (1, ))
    assert_size_stride(primals_477, (72, ), (1, ))
    assert_size_stride(primals_478, (72, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_479, (72, ), (1, ))
    assert_size_stride(primals_480, (72, ), (1, ))
    assert_size_stride(primals_481, (144, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_482, (144, ), (1, ))
    assert_size_stride(primals_483, (144, ), (1, ))
    assert_size_stride(primals_484, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_485, (18, ), (1, ))
    assert_size_stride(primals_486, (18, ), (1, ))
    assert_size_stride(primals_487, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_488, (18, ), (1, ))
    assert_size_stride(primals_489, (18, ), (1, ))
    assert_size_stride(primals_490, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_491, (18, ), (1, ))
    assert_size_stride(primals_492, (18, ), (1, ))
    assert_size_stride(primals_493, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_494, (18, ), (1, ))
    assert_size_stride(primals_495, (18, ), (1, ))
    assert_size_stride(primals_496, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_497, (18, ), (1, ))
    assert_size_stride(primals_498, (18, ), (1, ))
    assert_size_stride(primals_499, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_500, (18, ), (1, ))
    assert_size_stride(primals_501, (18, ), (1, ))
    assert_size_stride(primals_502, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_503, (18, ), (1, ))
    assert_size_stride(primals_504, (18, ), (1, ))
    assert_size_stride(primals_505, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_506, (18, ), (1, ))
    assert_size_stride(primals_507, (18, ), (1, ))
    assert_size_stride(primals_508, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_509, (36, ), (1, ))
    assert_size_stride(primals_510, (36, ), (1, ))
    assert_size_stride(primals_511, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_512, (36, ), (1, ))
    assert_size_stride(primals_513, (36, ), (1, ))
    assert_size_stride(primals_514, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_515, (36, ), (1, ))
    assert_size_stride(primals_516, (36, ), (1, ))
    assert_size_stride(primals_517, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_518, (36, ), (1, ))
    assert_size_stride(primals_519, (36, ), (1, ))
    assert_size_stride(primals_520, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_521, (36, ), (1, ))
    assert_size_stride(primals_522, (36, ), (1, ))
    assert_size_stride(primals_523, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_524, (36, ), (1, ))
    assert_size_stride(primals_525, (36, ), (1, ))
    assert_size_stride(primals_526, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_527, (36, ), (1, ))
    assert_size_stride(primals_528, (36, ), (1, ))
    assert_size_stride(primals_529, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_530, (36, ), (1, ))
    assert_size_stride(primals_531, (36, ), (1, ))
    assert_size_stride(primals_532, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_533, (72, ), (1, ))
    assert_size_stride(primals_534, (72, ), (1, ))
    assert_size_stride(primals_535, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_536, (72, ), (1, ))
    assert_size_stride(primals_537, (72, ), (1, ))
    assert_size_stride(primals_538, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_539, (72, ), (1, ))
    assert_size_stride(primals_540, (72, ), (1, ))
    assert_size_stride(primals_541, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_542, (72, ), (1, ))
    assert_size_stride(primals_543, (72, ), (1, ))
    assert_size_stride(primals_544, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_545, (72, ), (1, ))
    assert_size_stride(primals_546, (72, ), (1, ))
    assert_size_stride(primals_547, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_548, (72, ), (1, ))
    assert_size_stride(primals_549, (72, ), (1, ))
    assert_size_stride(primals_550, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_551, (72, ), (1, ))
    assert_size_stride(primals_552, (72, ), (1, ))
    assert_size_stride(primals_553, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_554, (72, ), (1, ))
    assert_size_stride(primals_555, (72, ), (1, ))
    assert_size_stride(primals_556, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_557, (144, ), (1, ))
    assert_size_stride(primals_558, (144, ), (1, ))
    assert_size_stride(primals_559, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_560, (144, ), (1, ))
    assert_size_stride(primals_561, (144, ), (1, ))
    assert_size_stride(primals_562, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_563, (144, ), (1, ))
    assert_size_stride(primals_564, (144, ), (1, ))
    assert_size_stride(primals_565, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_566, (144, ), (1, ))
    assert_size_stride(primals_567, (144, ), (1, ))
    assert_size_stride(primals_568, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_569, (144, ), (1, ))
    assert_size_stride(primals_570, (144, ), (1, ))
    assert_size_stride(primals_571, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_572, (144, ), (1, ))
    assert_size_stride(primals_573, (144, ), (1, ))
    assert_size_stride(primals_574, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_575, (144, ), (1, ))
    assert_size_stride(primals_576, (144, ), (1, ))
    assert_size_stride(primals_577, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_578, (144, ), (1, ))
    assert_size_stride(primals_579, (144, ), (1, ))
    assert_size_stride(primals_580, (18, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_581, (18, ), (1, ))
    assert_size_stride(primals_582, (18, ), (1, ))
    assert_size_stride(primals_583, (18, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_584, (18, ), (1, ))
    assert_size_stride(primals_585, (18, ), (1, ))
    assert_size_stride(primals_586, (18, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_587, (18, ), (1, ))
    assert_size_stride(primals_588, (18, ), (1, ))
    assert_size_stride(primals_589, (36, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_590, (36, ), (1, ))
    assert_size_stride(primals_591, (36, ), (1, ))
    assert_size_stride(primals_592, (36, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_593, (36, ), (1, ))
    assert_size_stride(primals_594, (36, ), (1, ))
    assert_size_stride(primals_595, (36, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_596, (36, ), (1, ))
    assert_size_stride(primals_597, (36, ), (1, ))
    assert_size_stride(primals_598, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_599, (18, ), (1, ))
    assert_size_stride(primals_600, (18, ), (1, ))
    assert_size_stride(primals_601, (72, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_602, (72, ), (1, ))
    assert_size_stride(primals_603, (72, ), (1, ))
    assert_size_stride(primals_604, (72, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_605, (72, ), (1, ))
    assert_size_stride(primals_606, (72, ), (1, ))
    assert_size_stride(primals_607, (72, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_608, (72, ), (1, ))
    assert_size_stride(primals_609, (72, ), (1, ))
    assert_size_stride(primals_610, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_611, (18, ), (1, ))
    assert_size_stride(primals_612, (18, ), (1, ))
    assert_size_stride(primals_613, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_614, (18, ), (1, ))
    assert_size_stride(primals_615, (18, ), (1, ))
    assert_size_stride(primals_616, (144, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_617, (144, ), (1, ))
    assert_size_stride(primals_618, (144, ), (1, ))
    assert_size_stride(primals_619, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_620, (36, ), (1, ))
    assert_size_stride(primals_621, (36, ), (1, ))
    assert_size_stride(primals_622, (144, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_623, (144, ), (1, ))
    assert_size_stride(primals_624, (144, ), (1, ))
    assert_size_stride(primals_625, (144, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_626, (144, ), (1, ))
    assert_size_stride(primals_627, (144, ), (1, ))
    assert_size_stride(primals_628, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_629, (18, ), (1, ))
    assert_size_stride(primals_630, (18, ), (1, ))
    assert_size_stride(primals_631, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_632, (18, ), (1, ))
    assert_size_stride(primals_633, (18, ), (1, ))
    assert_size_stride(primals_634, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_635, (18, ), (1, ))
    assert_size_stride(primals_636, (18, ), (1, ))
    assert_size_stride(primals_637, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_638, (18, ), (1, ))
    assert_size_stride(primals_639, (18, ), (1, ))
    assert_size_stride(primals_640, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_641, (18, ), (1, ))
    assert_size_stride(primals_642, (18, ), (1, ))
    assert_size_stride(primals_643, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_644, (18, ), (1, ))
    assert_size_stride(primals_645, (18, ), (1, ))
    assert_size_stride(primals_646, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_647, (18, ), (1, ))
    assert_size_stride(primals_648, (18, ), (1, ))
    assert_size_stride(primals_649, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_650, (18, ), (1, ))
    assert_size_stride(primals_651, (18, ), (1, ))
    assert_size_stride(primals_652, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_653, (36, ), (1, ))
    assert_size_stride(primals_654, (36, ), (1, ))
    assert_size_stride(primals_655, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_656, (36, ), (1, ))
    assert_size_stride(primals_657, (36, ), (1, ))
    assert_size_stride(primals_658, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_659, (36, ), (1, ))
    assert_size_stride(primals_660, (36, ), (1, ))
    assert_size_stride(primals_661, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_662, (36, ), (1, ))
    assert_size_stride(primals_663, (36, ), (1, ))
    assert_size_stride(primals_664, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_665, (36, ), (1, ))
    assert_size_stride(primals_666, (36, ), (1, ))
    assert_size_stride(primals_667, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_668, (36, ), (1, ))
    assert_size_stride(primals_669, (36, ), (1, ))
    assert_size_stride(primals_670, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_671, (36, ), (1, ))
    assert_size_stride(primals_672, (36, ), (1, ))
    assert_size_stride(primals_673, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_674, (36, ), (1, ))
    assert_size_stride(primals_675, (36, ), (1, ))
    assert_size_stride(primals_676, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_677, (72, ), (1, ))
    assert_size_stride(primals_678, (72, ), (1, ))
    assert_size_stride(primals_679, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_680, (72, ), (1, ))
    assert_size_stride(primals_681, (72, ), (1, ))
    assert_size_stride(primals_682, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_683, (72, ), (1, ))
    assert_size_stride(primals_684, (72, ), (1, ))
    assert_size_stride(primals_685, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_686, (72, ), (1, ))
    assert_size_stride(primals_687, (72, ), (1, ))
    assert_size_stride(primals_688, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_689, (72, ), (1, ))
    assert_size_stride(primals_690, (72, ), (1, ))
    assert_size_stride(primals_691, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_692, (72, ), (1, ))
    assert_size_stride(primals_693, (72, ), (1, ))
    assert_size_stride(primals_694, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_695, (72, ), (1, ))
    assert_size_stride(primals_696, (72, ), (1, ))
    assert_size_stride(primals_697, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_698, (72, ), (1, ))
    assert_size_stride(primals_699, (72, ), (1, ))
    assert_size_stride(primals_700, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_701, (144, ), (1, ))
    assert_size_stride(primals_702, (144, ), (1, ))
    assert_size_stride(primals_703, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_704, (144, ), (1, ))
    assert_size_stride(primals_705, (144, ), (1, ))
    assert_size_stride(primals_706, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_707, (144, ), (1, ))
    assert_size_stride(primals_708, (144, ), (1, ))
    assert_size_stride(primals_709, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_710, (144, ), (1, ))
    assert_size_stride(primals_711, (144, ), (1, ))
    assert_size_stride(primals_712, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_713, (144, ), (1, ))
    assert_size_stride(primals_714, (144, ), (1, ))
    assert_size_stride(primals_715, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_716, (144, ), (1, ))
    assert_size_stride(primals_717, (144, ), (1, ))
    assert_size_stride(primals_718, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_719, (144, ), (1, ))
    assert_size_stride(primals_720, (144, ), (1, ))
    assert_size_stride(primals_721, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_722, (144, ), (1, ))
    assert_size_stride(primals_723, (144, ), (1, ))
    assert_size_stride(primals_724, (18, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_725, (18, ), (1, ))
    assert_size_stride(primals_726, (18, ), (1, ))
    assert_size_stride(primals_727, (18, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_728, (18, ), (1, ))
    assert_size_stride(primals_729, (18, ), (1, ))
    assert_size_stride(primals_730, (18, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_731, (18, ), (1, ))
    assert_size_stride(primals_732, (18, ), (1, ))
    assert_size_stride(primals_733, (36, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_734, (36, ), (1, ))
    assert_size_stride(primals_735, (36, ), (1, ))
    assert_size_stride(primals_736, (36, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_737, (36, ), (1, ))
    assert_size_stride(primals_738, (36, ), (1, ))
    assert_size_stride(primals_739, (36, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_740, (36, ), (1, ))
    assert_size_stride(primals_741, (36, ), (1, ))
    assert_size_stride(primals_742, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_743, (18, ), (1, ))
    assert_size_stride(primals_744, (18, ), (1, ))
    assert_size_stride(primals_745, (72, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_746, (72, ), (1, ))
    assert_size_stride(primals_747, (72, ), (1, ))
    assert_size_stride(primals_748, (72, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_749, (72, ), (1, ))
    assert_size_stride(primals_750, (72, ), (1, ))
    assert_size_stride(primals_751, (72, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_752, (72, ), (1, ))
    assert_size_stride(primals_753, (72, ), (1, ))
    assert_size_stride(primals_754, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_755, (18, ), (1, ))
    assert_size_stride(primals_756, (18, ), (1, ))
    assert_size_stride(primals_757, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_758, (18, ), (1, ))
    assert_size_stride(primals_759, (18, ), (1, ))
    assert_size_stride(primals_760, (144, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_761, (144, ), (1, ))
    assert_size_stride(primals_762, (144, ), (1, ))
    assert_size_stride(primals_763, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_764, (36, ), (1, ))
    assert_size_stride(primals_765, (36, ), (1, ))
    assert_size_stride(primals_766, (144, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_767, (144, ), (1, ))
    assert_size_stride(primals_768, (144, ), (1, ))
    assert_size_stride(primals_769, (144, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_770, (144, ), (1, ))
    assert_size_stride(primals_771, (144, ), (1, ))
    assert_size_stride(primals_772, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_773, (18, ), (1, ))
    assert_size_stride(primals_774, (18, ), (1, ))
    assert_size_stride(primals_775, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_776, (18, ), (1, ))
    assert_size_stride(primals_777, (18, ), (1, ))
    assert_size_stride(primals_778, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_779, (18, ), (1, ))
    assert_size_stride(primals_780, (18, ), (1, ))
    assert_size_stride(primals_781, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_782, (18, ), (1, ))
    assert_size_stride(primals_783, (18, ), (1, ))
    assert_size_stride(primals_784, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_785, (18, ), (1, ))
    assert_size_stride(primals_786, (18, ), (1, ))
    assert_size_stride(primals_787, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_788, (18, ), (1, ))
    assert_size_stride(primals_789, (18, ), (1, ))
    assert_size_stride(primals_790, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_791, (18, ), (1, ))
    assert_size_stride(primals_792, (18, ), (1, ))
    assert_size_stride(primals_793, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_794, (18, ), (1, ))
    assert_size_stride(primals_795, (18, ), (1, ))
    assert_size_stride(primals_796, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_797, (36, ), (1, ))
    assert_size_stride(primals_798, (36, ), (1, ))
    assert_size_stride(primals_799, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_800, (36, ), (1, ))
    assert_size_stride(primals_801, (36, ), (1, ))
    assert_size_stride(primals_802, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_803, (36, ), (1, ))
    assert_size_stride(primals_804, (36, ), (1, ))
    assert_size_stride(primals_805, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_806, (36, ), (1, ))
    assert_size_stride(primals_807, (36, ), (1, ))
    assert_size_stride(primals_808, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_809, (36, ), (1, ))
    assert_size_stride(primals_810, (36, ), (1, ))
    assert_size_stride(primals_811, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_812, (36, ), (1, ))
    assert_size_stride(primals_813, (36, ), (1, ))
    assert_size_stride(primals_814, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_815, (36, ), (1, ))
    assert_size_stride(primals_816, (36, ), (1, ))
    assert_size_stride(primals_817, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_818, (36, ), (1, ))
    assert_size_stride(primals_819, (36, ), (1, ))
    assert_size_stride(primals_820, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_821, (72, ), (1, ))
    assert_size_stride(primals_822, (72, ), (1, ))
    assert_size_stride(primals_823, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_824, (72, ), (1, ))
    assert_size_stride(primals_825, (72, ), (1, ))
    assert_size_stride(primals_826, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_827, (72, ), (1, ))
    assert_size_stride(primals_828, (72, ), (1, ))
    assert_size_stride(primals_829, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_830, (72, ), (1, ))
    assert_size_stride(primals_831, (72, ), (1, ))
    assert_size_stride(primals_832, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_833, (72, ), (1, ))
    assert_size_stride(primals_834, (72, ), (1, ))
    assert_size_stride(primals_835, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_836, (72, ), (1, ))
    assert_size_stride(primals_837, (72, ), (1, ))
    assert_size_stride(primals_838, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_839, (72, ), (1, ))
    assert_size_stride(primals_840, (72, ), (1, ))
    assert_size_stride(primals_841, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_842, (72, ), (1, ))
    assert_size_stride(primals_843, (72, ), (1, ))
    assert_size_stride(primals_844, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_845, (144, ), (1, ))
    assert_size_stride(primals_846, (144, ), (1, ))
    assert_size_stride(primals_847, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_848, (144, ), (1, ))
    assert_size_stride(primals_849, (144, ), (1, ))
    assert_size_stride(primals_850, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_851, (144, ), (1, ))
    assert_size_stride(primals_852, (144, ), (1, ))
    assert_size_stride(primals_853, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_854, (144, ), (1, ))
    assert_size_stride(primals_855, (144, ), (1, ))
    assert_size_stride(primals_856, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_857, (144, ), (1, ))
    assert_size_stride(primals_858, (144, ), (1, ))
    assert_size_stride(primals_859, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_860, (144, ), (1, ))
    assert_size_stride(primals_861, (144, ), (1, ))
    assert_size_stride(primals_862, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_863, (144, ), (1, ))
    assert_size_stride(primals_864, (144, ), (1, ))
    assert_size_stride(primals_865, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_866, (144, ), (1, ))
    assert_size_stride(primals_867, (144, ), (1, ))
    assert_size_stride(primals_868, (18, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_869, (18, ), (1, ))
    assert_size_stride(primals_870, (18, ), (1, ))
    assert_size_stride(primals_871, (18, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_872, (18, ), (1, ))
    assert_size_stride(primals_873, (18, ), (1, ))
    assert_size_stride(primals_874, (18, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_875, (18, ), (1, ))
    assert_size_stride(primals_876, (18, ), (1, ))
    assert_size_stride(primals_877, (36, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_878, (36, ), (1, ))
    assert_size_stride(primals_879, (36, ), (1, ))
    assert_size_stride(primals_880, (36, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_881, (36, ), (1, ))
    assert_size_stride(primals_882, (36, ), (1, ))
    assert_size_stride(primals_883, (36, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_884, (36, ), (1, ))
    assert_size_stride(primals_885, (36, ), (1, ))
    assert_size_stride(primals_886, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_887, (18, ), (1, ))
    assert_size_stride(primals_888, (18, ), (1, ))
    assert_size_stride(primals_889, (72, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_890, (72, ), (1, ))
    assert_size_stride(primals_891, (72, ), (1, ))
    assert_size_stride(primals_892, (72, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_893, (72, ), (1, ))
    assert_size_stride(primals_894, (72, ), (1, ))
    assert_size_stride(primals_895, (72, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_896, (72, ), (1, ))
    assert_size_stride(primals_897, (72, ), (1, ))
    assert_size_stride(primals_898, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_899, (18, ), (1, ))
    assert_size_stride(primals_900, (18, ), (1, ))
    assert_size_stride(primals_901, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_902, (18, ), (1, ))
    assert_size_stride(primals_903, (18, ), (1, ))
    assert_size_stride(primals_904, (144, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_905, (144, ), (1, ))
    assert_size_stride(primals_906, (144, ), (1, ))
    assert_size_stride(primals_907, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_908, (36, ), (1, ))
    assert_size_stride(primals_909, (36, ), (1, ))
    assert_size_stride(primals_910, (144, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_911, (144, ), (1, ))
    assert_size_stride(primals_912, (144, ), (1, ))
    assert_size_stride(primals_913, (144, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_914, (144, ), (1, ))
    assert_size_stride(primals_915, (144, ), (1, ))
    assert_size_stride(primals_916, (32, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(primals_917, (32, ), (1, ))
    assert_size_stride(primals_918, (32, ), (1, ))
    assert_size_stride(primals_919, (32, 32, 3, 3), (288, 9, 3, 1))
    assert_size_stride(primals_920, (32, ), (1, ))
    assert_size_stride(primals_921, (32, ), (1, ))
    assert_size_stride(primals_922, (128, 32, 1, 1), (32, 1, 1, 1))
    assert_size_stride(primals_923, (128, ), (1, ))
    assert_size_stride(primals_924, (128, ), (1, ))
    assert_size_stride(primals_925, (128, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(primals_926, (128, ), (1, ))
    assert_size_stride(primals_927, (128, ), (1, ))
    assert_size_stride(primals_928, (64, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_929, (64, ), (1, ))
    assert_size_stride(primals_930, (64, ), (1, ))
    assert_size_stride(primals_931, (64, 64, 3, 3), (576, 9, 3, 1))
    assert_size_stride(primals_932, (64, ), (1, ))
    assert_size_stride(primals_933, (64, ), (1, ))
    assert_size_stride(primals_934, (256, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(primals_935, (256, ), (1, ))
    assert_size_stride(primals_936, (256, ), (1, ))
    assert_size_stride(primals_937, (256, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_938, (256, ), (1, ))
    assert_size_stride(primals_939, (256, ), (1, ))
    assert_size_stride(primals_940, (256, 128, 3, 3), (1152, 9, 3, 1))
    assert_size_stride(primals_941, (256, ), (1, ))
    assert_size_stride(primals_942, (256, ), (1, ))
    assert_size_stride(primals_943, (256, ), (1, ))
    assert_size_stride(primals_944, (128, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_945, (128, ), (1, ))
    assert_size_stride(primals_946, (128, ), (1, ))
    assert_size_stride(primals_947, (128, 128, 3, 3), (1152, 9, 3, 1))
    assert_size_stride(primals_948, (128, ), (1, ))
    assert_size_stride(primals_949, (128, ), (1, ))
    assert_size_stride(primals_950, (512, 128, 1, 1), (128, 1, 1, 1))
    assert_size_stride(primals_951, (512, ), (1, ))
    assert_size_stride(primals_952, (512, ), (1, ))
    assert_size_stride(primals_953, (512, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_954, (512, ), (1, ))
    assert_size_stride(primals_955, (512, ), (1, ))
    assert_size_stride(primals_956, (512, 256, 3, 3), (2304, 9, 3, 1))
    assert_size_stride(primals_957, (512, ), (1, ))
    assert_size_stride(primals_958, (512, ), (1, ))
    assert_size_stride(primals_959, (512, ), (1, ))
    assert_size_stride(primals_960, (256, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_961, (256, ), (1, ))
    assert_size_stride(primals_962, (256, ), (1, ))
    assert_size_stride(primals_963, (256, 256, 3, 3), (2304, 9, 3, 1))
    assert_size_stride(primals_964, (256, ), (1, ))
    assert_size_stride(primals_965, (256, ), (1, ))
    assert_size_stride(primals_966, (1024, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(primals_967, (1024, ), (1, ))
    assert_size_stride(primals_968, (1024, ), (1, ))
    assert_size_stride(primals_969, (1024, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_970, (1024, ), (1, ))
    assert_size_stride(primals_971, (1024, ), (1, ))
    assert_size_stride(primals_972, (1024, 512, 3, 3), (4608, 9, 3, 1))
    assert_size_stride(primals_973, (1024, ), (1, ))
    assert_size_stride(primals_974, (1024, ), (1, ))
    assert_size_stride(primals_975, (1024, ), (1, ))
    assert_size_stride(primals_976, (2048, 1024, 1, 1), (1024, 1, 1, 1))
    assert_size_stride(primals_977, (2048, ), (1, ))
    assert_size_stride(primals_978, (2048, ), (1, ))
    assert_size_stride(primals_979, (2048, ), (1, ))
    assert_size_stride(primals_980, (1000, 2048), (2048, 1))
    assert_size_stride(primals_981, (1000, ), (1, ))
    assert_size_stride(primals_982, (64, ), (1, ))
    assert_size_stride(primals_983, (64, ), (1, ))
    assert_size_stride(primals_984, (), ())
    assert_size_stride(primals_985, (64, ), (1, ))
    assert_size_stride(primals_986, (64, ), (1, ))
    assert_size_stride(primals_987, (), ())
    assert_size_stride(primals_988, (64, ), (1, ))
    assert_size_stride(primals_989, (64, ), (1, ))
    assert_size_stride(primals_990, (), ())
    assert_size_stride(primals_991, (64, ), (1, ))
    assert_size_stride(primals_992, (64, ), (1, ))
    assert_size_stride(primals_993, (), ())
    assert_size_stride(primals_994, (256, ), (1, ))
    assert_size_stride(primals_995, (256, ), (1, ))
    assert_size_stride(primals_996, (), ())
    assert_size_stride(primals_997, (256, ), (1, ))
    assert_size_stride(primals_998, (256, ), (1, ))
    assert_size_stride(primals_999, (), ())
    assert_size_stride(primals_1000, (64, ), (1, ))
    assert_size_stride(primals_1001, (64, ), (1, ))
    assert_size_stride(primals_1002, (), ())
    assert_size_stride(primals_1003, (64, ), (1, ))
    assert_size_stride(primals_1004, (64, ), (1, ))
    assert_size_stride(primals_1005, (), ())
    assert_size_stride(primals_1006, (256, ), (1, ))
    assert_size_stride(primals_1007, (256, ), (1, ))
    assert_size_stride(primals_1008, (), ())
    assert_size_stride(primals_1009, (64, ), (1, ))
    assert_size_stride(primals_1010, (64, ), (1, ))
    assert_size_stride(primals_1011, (), ())
    assert_size_stride(primals_1012, (64, ), (1, ))
    assert_size_stride(primals_1013, (64, ), (1, ))
    assert_size_stride(primals_1014, (), ())
    assert_size_stride(primals_1015, (256, ), (1, ))
    assert_size_stride(primals_1016, (256, ), (1, ))
    assert_size_stride(primals_1017, (), ())
    assert_size_stride(primals_1018, (64, ), (1, ))
    assert_size_stride(primals_1019, (64, ), (1, ))
    assert_size_stride(primals_1020, (), ())
    assert_size_stride(primals_1021, (64, ), (1, ))
    assert_size_stride(primals_1022, (64, ), (1, ))
    assert_size_stride(primals_1023, (), ())
    assert_size_stride(primals_1024, (256, ), (1, ))
    assert_size_stride(primals_1025, (256, ), (1, ))
    assert_size_stride(primals_1026, (), ())
    assert_size_stride(primals_1027, (18, ), (1, ))
    assert_size_stride(primals_1028, (18, ), (1, ))
    assert_size_stride(primals_1029, (), ())
    assert_size_stride(primals_1030, (36, ), (1, ))
    assert_size_stride(primals_1031, (36, ), (1, ))
    assert_size_stride(primals_1032, (), ())
    assert_size_stride(primals_1033, (18, ), (1, ))
    assert_size_stride(primals_1034, (18, ), (1, ))
    assert_size_stride(primals_1035, (), ())
    assert_size_stride(primals_1036, (18, ), (1, ))
    assert_size_stride(primals_1037, (18, ), (1, ))
    assert_size_stride(primals_1038, (), ())
    assert_size_stride(primals_1039, (18, ), (1, ))
    assert_size_stride(primals_1040, (18, ), (1, ))
    assert_size_stride(primals_1041, (), ())
    assert_size_stride(primals_1042, (18, ), (1, ))
    assert_size_stride(primals_1043, (18, ), (1, ))
    assert_size_stride(primals_1044, (), ())
    assert_size_stride(primals_1045, (18, ), (1, ))
    assert_size_stride(primals_1046, (18, ), (1, ))
    assert_size_stride(primals_1047, (), ())
    assert_size_stride(primals_1048, (18, ), (1, ))
    assert_size_stride(primals_1049, (18, ), (1, ))
    assert_size_stride(primals_1050, (), ())
    assert_size_stride(primals_1051, (18, ), (1, ))
    assert_size_stride(primals_1052, (18, ), (1, ))
    assert_size_stride(primals_1053, (), ())
    assert_size_stride(primals_1054, (18, ), (1, ))
    assert_size_stride(primals_1055, (18, ), (1, ))
    assert_size_stride(primals_1056, (), ())
    assert_size_stride(primals_1057, (36, ), (1, ))
    assert_size_stride(primals_1058, (36, ), (1, ))
    assert_size_stride(primals_1059, (), ())
    assert_size_stride(primals_1060, (36, ), (1, ))
    assert_size_stride(primals_1061, (36, ), (1, ))
    assert_size_stride(primals_1062, (), ())
    assert_size_stride(primals_1063, (36, ), (1, ))
    assert_size_stride(primals_1064, (36, ), (1, ))
    assert_size_stride(primals_1065, (), ())
    assert_size_stride(primals_1066, (36, ), (1, ))
    assert_size_stride(primals_1067, (36, ), (1, ))
    assert_size_stride(primals_1068, (), ())
    assert_size_stride(primals_1069, (36, ), (1, ))
    assert_size_stride(primals_1070, (36, ), (1, ))
    assert_size_stride(primals_1071, (), ())
    assert_size_stride(primals_1072, (36, ), (1, ))
    assert_size_stride(primals_1073, (36, ), (1, ))
    assert_size_stride(primals_1074, (), ())
    assert_size_stride(primals_1075, (36, ), (1, ))
    assert_size_stride(primals_1076, (36, ), (1, ))
    assert_size_stride(primals_1077, (), ())
    assert_size_stride(primals_1078, (36, ), (1, ))
    assert_size_stride(primals_1079, (36, ), (1, ))
    assert_size_stride(primals_1080, (), ())
    assert_size_stride(primals_1081, (18, ), (1, ))
    assert_size_stride(primals_1082, (18, ), (1, ))
    assert_size_stride(primals_1083, (), ())
    assert_size_stride(primals_1084, (36, ), (1, ))
    assert_size_stride(primals_1085, (36, ), (1, ))
    assert_size_stride(primals_1086, (), ())
    assert_size_stride(primals_1087, (72, ), (1, ))
    assert_size_stride(primals_1088, (72, ), (1, ))
    assert_size_stride(primals_1089, (), ())
    assert_size_stride(primals_1090, (18, ), (1, ))
    assert_size_stride(primals_1091, (18, ), (1, ))
    assert_size_stride(primals_1092, (), ())
    assert_size_stride(primals_1093, (18, ), (1, ))
    assert_size_stride(primals_1094, (18, ), (1, ))
    assert_size_stride(primals_1095, (), ())
    assert_size_stride(primals_1096, (18, ), (1, ))
    assert_size_stride(primals_1097, (18, ), (1, ))
    assert_size_stride(primals_1098, (), ())
    assert_size_stride(primals_1099, (18, ), (1, ))
    assert_size_stride(primals_1100, (18, ), (1, ))
    assert_size_stride(primals_1101, (), ())
    assert_size_stride(primals_1102, (18, ), (1, ))
    assert_size_stride(primals_1103, (18, ), (1, ))
    assert_size_stride(primals_1104, (), ())
    assert_size_stride(primals_1105, (18, ), (1, ))
    assert_size_stride(primals_1106, (18, ), (1, ))
    assert_size_stride(primals_1107, (), ())
    assert_size_stride(primals_1108, (18, ), (1, ))
    assert_size_stride(primals_1109, (18, ), (1, ))
    assert_size_stride(primals_1110, (), ())
    assert_size_stride(primals_1111, (18, ), (1, ))
    assert_size_stride(primals_1112, (18, ), (1, ))
    assert_size_stride(primals_1113, (), ())
    assert_size_stride(primals_1114, (36, ), (1, ))
    assert_size_stride(primals_1115, (36, ), (1, ))
    assert_size_stride(primals_1116, (), ())
    assert_size_stride(primals_1117, (36, ), (1, ))
    assert_size_stride(primals_1118, (36, ), (1, ))
    assert_size_stride(primals_1119, (), ())
    assert_size_stride(primals_1120, (36, ), (1, ))
    assert_size_stride(primals_1121, (36, ), (1, ))
    assert_size_stride(primals_1122, (), ())
    assert_size_stride(primals_1123, (36, ), (1, ))
    assert_size_stride(primals_1124, (36, ), (1, ))
    assert_size_stride(primals_1125, (), ())
    assert_size_stride(primals_1126, (36, ), (1, ))
    assert_size_stride(primals_1127, (36, ), (1, ))
    assert_size_stride(primals_1128, (), ())
    assert_size_stride(primals_1129, (36, ), (1, ))
    assert_size_stride(primals_1130, (36, ), (1, ))
    assert_size_stride(primals_1131, (), ())
    assert_size_stride(primals_1132, (36, ), (1, ))
    assert_size_stride(primals_1133, (36, ), (1, ))
    assert_size_stride(primals_1134, (), ())
    assert_size_stride(primals_1135, (36, ), (1, ))
    assert_size_stride(primals_1136, (36, ), (1, ))
    assert_size_stride(primals_1137, (), ())
    assert_size_stride(primals_1138, (72, ), (1, ))
    assert_size_stride(primals_1139, (72, ), (1, ))
    assert_size_stride(primals_1140, (), ())
    assert_size_stride(primals_1141, (72, ), (1, ))
    assert_size_stride(primals_1142, (72, ), (1, ))
    assert_size_stride(primals_1143, (), ())
    assert_size_stride(primals_1144, (72, ), (1, ))
    assert_size_stride(primals_1145, (72, ), (1, ))
    assert_size_stride(primals_1146, (), ())
    assert_size_stride(primals_1147, (72, ), (1, ))
    assert_size_stride(primals_1148, (72, ), (1, ))
    assert_size_stride(primals_1149, (), ())
    assert_size_stride(primals_1150, (72, ), (1, ))
    assert_size_stride(primals_1151, (72, ), (1, ))
    assert_size_stride(primals_1152, (), ())
    assert_size_stride(primals_1153, (72, ), (1, ))
    assert_size_stride(primals_1154, (72, ), (1, ))
    assert_size_stride(primals_1155, (), ())
    assert_size_stride(primals_1156, (72, ), (1, ))
    assert_size_stride(primals_1157, (72, ), (1, ))
    assert_size_stride(primals_1158, (), ())
    assert_size_stride(primals_1159, (72, ), (1, ))
    assert_size_stride(primals_1160, (72, ), (1, ))
    assert_size_stride(primals_1161, (), ())
    assert_size_stride(primals_1162, (18, ), (1, ))
    assert_size_stride(primals_1163, (18, ), (1, ))
    assert_size_stride(primals_1164, (), ())
    assert_size_stride(primals_1165, (18, ), (1, ))
    assert_size_stride(primals_1166, (18, ), (1, ))
    assert_size_stride(primals_1167, (), ())
    assert_size_stride(primals_1168, (36, ), (1, ))
    assert_size_stride(primals_1169, (36, ), (1, ))
    assert_size_stride(primals_1170, (), ())
    assert_size_stride(primals_1171, (36, ), (1, ))
    assert_size_stride(primals_1172, (36, ), (1, ))
    assert_size_stride(primals_1173, (), ())
    assert_size_stride(primals_1174, (18, ), (1, ))
    assert_size_stride(primals_1175, (18, ), (1, ))
    assert_size_stride(primals_1176, (), ())
    assert_size_stride(primals_1177, (72, ), (1, ))
    assert_size_stride(primals_1178, (72, ), (1, ))
    assert_size_stride(primals_1179, (), ())
    assert_size_stride(primals_1180, (72, ), (1, ))
    assert_size_stride(primals_1181, (72, ), (1, ))
    assert_size_stride(primals_1182, (), ())
    assert_size_stride(primals_1183, (18, ), (1, ))
    assert_size_stride(primals_1184, (18, ), (1, ))
    assert_size_stride(primals_1185, (), ())
    assert_size_stride(primals_1186, (18, ), (1, ))
    assert_size_stride(primals_1187, (18, ), (1, ))
    assert_size_stride(primals_1188, (), ())
    assert_size_stride(primals_1189, (18, ), (1, ))
    assert_size_stride(primals_1190, (18, ), (1, ))
    assert_size_stride(primals_1191, (), ())
    assert_size_stride(primals_1192, (18, ), (1, ))
    assert_size_stride(primals_1193, (18, ), (1, ))
    assert_size_stride(primals_1194, (), ())
    assert_size_stride(primals_1195, (18, ), (1, ))
    assert_size_stride(primals_1196, (18, ), (1, ))
    assert_size_stride(primals_1197, (), ())
    assert_size_stride(primals_1198, (18, ), (1, ))
    assert_size_stride(primals_1199, (18, ), (1, ))
    assert_size_stride(primals_1200, (), ())
    assert_size_stride(primals_1201, (18, ), (1, ))
    assert_size_stride(primals_1202, (18, ), (1, ))
    assert_size_stride(primals_1203, (), ())
    assert_size_stride(primals_1204, (18, ), (1, ))
    assert_size_stride(primals_1205, (18, ), (1, ))
    assert_size_stride(primals_1206, (), ())
    assert_size_stride(primals_1207, (36, ), (1, ))
    assert_size_stride(primals_1208, (36, ), (1, ))
    assert_size_stride(primals_1209, (), ())
    assert_size_stride(primals_1210, (36, ), (1, ))
    assert_size_stride(primals_1211, (36, ), (1, ))
    assert_size_stride(primals_1212, (), ())
    assert_size_stride(primals_1213, (36, ), (1, ))
    assert_size_stride(primals_1214, (36, ), (1, ))
    assert_size_stride(primals_1215, (), ())
    assert_size_stride(primals_1216, (36, ), (1, ))
    assert_size_stride(primals_1217, (36, ), (1, ))
    assert_size_stride(primals_1218, (), ())
    assert_size_stride(primals_1219, (36, ), (1, ))
    assert_size_stride(primals_1220, (36, ), (1, ))
    assert_size_stride(primals_1221, (), ())
    assert_size_stride(primals_1222, (36, ), (1, ))
    assert_size_stride(primals_1223, (36, ), (1, ))
    assert_size_stride(primals_1224, (), ())
    assert_size_stride(primals_1225, (36, ), (1, ))
    assert_size_stride(primals_1226, (36, ), (1, ))
    assert_size_stride(primals_1227, (), ())
    assert_size_stride(primals_1228, (36, ), (1, ))
    assert_size_stride(primals_1229, (36, ), (1, ))
    assert_size_stride(primals_1230, (), ())
    assert_size_stride(primals_1231, (72, ), (1, ))
    assert_size_stride(primals_1232, (72, ), (1, ))
    assert_size_stride(primals_1233, (), ())
    assert_size_stride(primals_1234, (72, ), (1, ))
    assert_size_stride(primals_1235, (72, ), (1, ))
    assert_size_stride(primals_1236, (), ())
    assert_size_stride(primals_1237, (72, ), (1, ))
    assert_size_stride(primals_1238, (72, ), (1, ))
    assert_size_stride(primals_1239, (), ())
    assert_size_stride(primals_1240, (72, ), (1, ))
    assert_size_stride(primals_1241, (72, ), (1, ))
    assert_size_stride(primals_1242, (), ())
    assert_size_stride(primals_1243, (72, ), (1, ))
    assert_size_stride(primals_1244, (72, ), (1, ))
    assert_size_stride(primals_1245, (), ())
    assert_size_stride(primals_1246, (72, ), (1, ))
    assert_size_stride(primals_1247, (72, ), (1, ))
    assert_size_stride(primals_1248, (), ())
    assert_size_stride(primals_1249, (72, ), (1, ))
    assert_size_stride(primals_1250, (72, ), (1, ))
    assert_size_stride(primals_1251, (), ())
    assert_size_stride(primals_1252, (72, ), (1, ))
    assert_size_stride(primals_1253, (72, ), (1, ))
    assert_size_stride(primals_1254, (), ())
    assert_size_stride(primals_1255, (18, ), (1, ))
    assert_size_stride(primals_1256, (18, ), (1, ))
    assert_size_stride(primals_1257, (), ())
    assert_size_stride(primals_1258, (18, ), (1, ))
    assert_size_stride(primals_1259, (18, ), (1, ))
    assert_size_stride(primals_1260, (), ())
    assert_size_stride(primals_1261, (36, ), (1, ))
    assert_size_stride(primals_1262, (36, ), (1, ))
    assert_size_stride(primals_1263, (), ())
    assert_size_stride(primals_1264, (36, ), (1, ))
    assert_size_stride(primals_1265, (36, ), (1, ))
    assert_size_stride(primals_1266, (), ())
    assert_size_stride(primals_1267, (18, ), (1, ))
    assert_size_stride(primals_1268, (18, ), (1, ))
    assert_size_stride(primals_1269, (), ())
    assert_size_stride(primals_1270, (72, ), (1, ))
    assert_size_stride(primals_1271, (72, ), (1, ))
    assert_size_stride(primals_1272, (), ())
    assert_size_stride(primals_1273, (72, ), (1, ))
    assert_size_stride(primals_1274, (72, ), (1, ))
    assert_size_stride(primals_1275, (), ())
    assert_size_stride(primals_1276, (18, ), (1, ))
    assert_size_stride(primals_1277, (18, ), (1, ))
    assert_size_stride(primals_1278, (), ())
    assert_size_stride(primals_1279, (18, ), (1, ))
    assert_size_stride(primals_1280, (18, ), (1, ))
    assert_size_stride(primals_1281, (), ())
    assert_size_stride(primals_1282, (18, ), (1, ))
    assert_size_stride(primals_1283, (18, ), (1, ))
    assert_size_stride(primals_1284, (), ())
    assert_size_stride(primals_1285, (18, ), (1, ))
    assert_size_stride(primals_1286, (18, ), (1, ))
    assert_size_stride(primals_1287, (), ())
    assert_size_stride(primals_1288, (18, ), (1, ))
    assert_size_stride(primals_1289, (18, ), (1, ))
    assert_size_stride(primals_1290, (), ())
    assert_size_stride(primals_1291, (18, ), (1, ))
    assert_size_stride(primals_1292, (18, ), (1, ))
    assert_size_stride(primals_1293, (), ())
    assert_size_stride(primals_1294, (18, ), (1, ))
    assert_size_stride(primals_1295, (18, ), (1, ))
    assert_size_stride(primals_1296, (), ())
    assert_size_stride(primals_1297, (18, ), (1, ))
    assert_size_stride(primals_1298, (18, ), (1, ))
    assert_size_stride(primals_1299, (), ())
    assert_size_stride(primals_1300, (36, ), (1, ))
    assert_size_stride(primals_1301, (36, ), (1, ))
    assert_size_stride(primals_1302, (), ())
    assert_size_stride(primals_1303, (36, ), (1, ))
    assert_size_stride(primals_1304, (36, ), (1, ))
    assert_size_stride(primals_1305, (), ())
    assert_size_stride(primals_1306, (36, ), (1, ))
    assert_size_stride(primals_1307, (36, ), (1, ))
    assert_size_stride(primals_1308, (), ())
    assert_size_stride(primals_1309, (36, ), (1, ))
    assert_size_stride(primals_1310, (36, ), (1, ))
    assert_size_stride(primals_1311, (), ())
    assert_size_stride(primals_1312, (36, ), (1, ))
    assert_size_stride(primals_1313, (36, ), (1, ))
    assert_size_stride(primals_1314, (), ())
    assert_size_stride(primals_1315, (36, ), (1, ))
    assert_size_stride(primals_1316, (36, ), (1, ))
    assert_size_stride(primals_1317, (), ())
    assert_size_stride(primals_1318, (36, ), (1, ))
    assert_size_stride(primals_1319, (36, ), (1, ))
    assert_size_stride(primals_1320, (), ())
    assert_size_stride(primals_1321, (36, ), (1, ))
    assert_size_stride(primals_1322, (36, ), (1, ))
    assert_size_stride(primals_1323, (), ())
    assert_size_stride(primals_1324, (72, ), (1, ))
    assert_size_stride(primals_1325, (72, ), (1, ))
    assert_size_stride(primals_1326, (), ())
    assert_size_stride(primals_1327, (72, ), (1, ))
    assert_size_stride(primals_1328, (72, ), (1, ))
    assert_size_stride(primals_1329, (), ())
    assert_size_stride(primals_1330, (72, ), (1, ))
    assert_size_stride(primals_1331, (72, ), (1, ))
    assert_size_stride(primals_1332, (), ())
    assert_size_stride(primals_1333, (72, ), (1, ))
    assert_size_stride(primals_1334, (72, ), (1, ))
    assert_size_stride(primals_1335, (), ())
    assert_size_stride(primals_1336, (72, ), (1, ))
    assert_size_stride(primals_1337, (72, ), (1, ))
    assert_size_stride(primals_1338, (), ())
    assert_size_stride(primals_1339, (72, ), (1, ))
    assert_size_stride(primals_1340, (72, ), (1, ))
    assert_size_stride(primals_1341, (), ())
    assert_size_stride(primals_1342, (72, ), (1, ))
    assert_size_stride(primals_1343, (72, ), (1, ))
    assert_size_stride(primals_1344, (), ())
    assert_size_stride(primals_1345, (72, ), (1, ))
    assert_size_stride(primals_1346, (72, ), (1, ))
    assert_size_stride(primals_1347, (), ())
    assert_size_stride(primals_1348, (18, ), (1, ))
    assert_size_stride(primals_1349, (18, ), (1, ))
    assert_size_stride(primals_1350, (), ())
    assert_size_stride(primals_1351, (18, ), (1, ))
    assert_size_stride(primals_1352, (18, ), (1, ))
    assert_size_stride(primals_1353, (), ())
    assert_size_stride(primals_1354, (36, ), (1, ))
    assert_size_stride(primals_1355, (36, ), (1, ))
    assert_size_stride(primals_1356, (), ())
    assert_size_stride(primals_1357, (36, ), (1, ))
    assert_size_stride(primals_1358, (36, ), (1, ))
    assert_size_stride(primals_1359, (), ())
    assert_size_stride(primals_1360, (18, ), (1, ))
    assert_size_stride(primals_1361, (18, ), (1, ))
    assert_size_stride(primals_1362, (), ())
    assert_size_stride(primals_1363, (72, ), (1, ))
    assert_size_stride(primals_1364, (72, ), (1, ))
    assert_size_stride(primals_1365, (), ())
    assert_size_stride(primals_1366, (72, ), (1, ))
    assert_size_stride(primals_1367, (72, ), (1, ))
    assert_size_stride(primals_1368, (), ())
    assert_size_stride(primals_1369, (18, ), (1, ))
    assert_size_stride(primals_1370, (18, ), (1, ))
    assert_size_stride(primals_1371, (), ())
    assert_size_stride(primals_1372, (18, ), (1, ))
    assert_size_stride(primals_1373, (18, ), (1, ))
    assert_size_stride(primals_1374, (), ())
    assert_size_stride(primals_1375, (18, ), (1, ))
    assert_size_stride(primals_1376, (18, ), (1, ))
    assert_size_stride(primals_1377, (), ())
    assert_size_stride(primals_1378, (18, ), (1, ))
    assert_size_stride(primals_1379, (18, ), (1, ))
    assert_size_stride(primals_1380, (), ())
    assert_size_stride(primals_1381, (18, ), (1, ))
    assert_size_stride(primals_1382, (18, ), (1, ))
    assert_size_stride(primals_1383, (), ())
    assert_size_stride(primals_1384, (18, ), (1, ))
    assert_size_stride(primals_1385, (18, ), (1, ))
    assert_size_stride(primals_1386, (), ())
    assert_size_stride(primals_1387, (18, ), (1, ))
    assert_size_stride(primals_1388, (18, ), (1, ))
    assert_size_stride(primals_1389, (), ())
    assert_size_stride(primals_1390, (18, ), (1, ))
    assert_size_stride(primals_1391, (18, ), (1, ))
    assert_size_stride(primals_1392, (), ())
    assert_size_stride(primals_1393, (36, ), (1, ))
    assert_size_stride(primals_1394, (36, ), (1, ))
    assert_size_stride(primals_1395, (), ())
    assert_size_stride(primals_1396, (36, ), (1, ))
    assert_size_stride(primals_1397, (36, ), (1, ))
    assert_size_stride(primals_1398, (), ())
    assert_size_stride(primals_1399, (36, ), (1, ))
    assert_size_stride(primals_1400, (36, ), (1, ))
    assert_size_stride(primals_1401, (), ())
    assert_size_stride(primals_1402, (36, ), (1, ))
    assert_size_stride(primals_1403, (36, ), (1, ))
    assert_size_stride(primals_1404, (), ())
    assert_size_stride(primals_1405, (36, ), (1, ))
    assert_size_stride(primals_1406, (36, ), (1, ))
    assert_size_stride(primals_1407, (), ())
    assert_size_stride(primals_1408, (36, ), (1, ))
    assert_size_stride(primals_1409, (36, ), (1, ))
    assert_size_stride(primals_1410, (), ())
    assert_size_stride(primals_1411, (36, ), (1, ))
    assert_size_stride(primals_1412, (36, ), (1, ))
    assert_size_stride(primals_1413, (), ())
    assert_size_stride(primals_1414, (36, ), (1, ))
    assert_size_stride(primals_1415, (36, ), (1, ))
    assert_size_stride(primals_1416, (), ())
    assert_size_stride(primals_1417, (72, ), (1, ))
    assert_size_stride(primals_1418, (72, ), (1, ))
    assert_size_stride(primals_1419, (), ())
    assert_size_stride(primals_1420, (72, ), (1, ))
    assert_size_stride(primals_1421, (72, ), (1, ))
    assert_size_stride(primals_1422, (), ())
    assert_size_stride(primals_1423, (72, ), (1, ))
    assert_size_stride(primals_1424, (72, ), (1, ))
    assert_size_stride(primals_1425, (), ())
    assert_size_stride(primals_1426, (72, ), (1, ))
    assert_size_stride(primals_1427, (72, ), (1, ))
    assert_size_stride(primals_1428, (), ())
    assert_size_stride(primals_1429, (72, ), (1, ))
    assert_size_stride(primals_1430, (72, ), (1, ))
    assert_size_stride(primals_1431, (), ())
    assert_size_stride(primals_1432, (72, ), (1, ))
    assert_size_stride(primals_1433, (72, ), (1, ))
    assert_size_stride(primals_1434, (), ())
    assert_size_stride(primals_1435, (72, ), (1, ))
    assert_size_stride(primals_1436, (72, ), (1, ))
    assert_size_stride(primals_1437, (), ())
    assert_size_stride(primals_1438, (72, ), (1, ))
    assert_size_stride(primals_1439, (72, ), (1, ))
    assert_size_stride(primals_1440, (), ())
    assert_size_stride(primals_1441, (18, ), (1, ))
    assert_size_stride(primals_1442, (18, ), (1, ))
    assert_size_stride(primals_1443, (), ())
    assert_size_stride(primals_1444, (18, ), (1, ))
    assert_size_stride(primals_1445, (18, ), (1, ))
    assert_size_stride(primals_1446, (), ())
    assert_size_stride(primals_1447, (36, ), (1, ))
    assert_size_stride(primals_1448, (36, ), (1, ))
    assert_size_stride(primals_1449, (), ())
    assert_size_stride(primals_1450, (36, ), (1, ))
    assert_size_stride(primals_1451, (36, ), (1, ))
    assert_size_stride(primals_1452, (), ())
    assert_size_stride(primals_1453, (18, ), (1, ))
    assert_size_stride(primals_1454, (18, ), (1, ))
    assert_size_stride(primals_1455, (), ())
    assert_size_stride(primals_1456, (72, ), (1, ))
    assert_size_stride(primals_1457, (72, ), (1, ))
    assert_size_stride(primals_1458, (), ())
    assert_size_stride(primals_1459, (72, ), (1, ))
    assert_size_stride(primals_1460, (72, ), (1, ))
    assert_size_stride(primals_1461, (), ())
    assert_size_stride(primals_1462, (144, ), (1, ))
    assert_size_stride(primals_1463, (144, ), (1, ))
    assert_size_stride(primals_1464, (), ())
    assert_size_stride(primals_1465, (18, ), (1, ))
    assert_size_stride(primals_1466, (18, ), (1, ))
    assert_size_stride(primals_1467, (), ())
    assert_size_stride(primals_1468, (18, ), (1, ))
    assert_size_stride(primals_1469, (18, ), (1, ))
    assert_size_stride(primals_1470, (), ())
    assert_size_stride(primals_1471, (18, ), (1, ))
    assert_size_stride(primals_1472, (18, ), (1, ))
    assert_size_stride(primals_1473, (), ())
    assert_size_stride(primals_1474, (18, ), (1, ))
    assert_size_stride(primals_1475, (18, ), (1, ))
    assert_size_stride(primals_1476, (), ())
    assert_size_stride(primals_1477, (18, ), (1, ))
    assert_size_stride(primals_1478, (18, ), (1, ))
    assert_size_stride(primals_1479, (), ())
    assert_size_stride(primals_1480, (18, ), (1, ))
    assert_size_stride(primals_1481, (18, ), (1, ))
    assert_size_stride(primals_1482, (), ())
    assert_size_stride(primals_1483, (18, ), (1, ))
    assert_size_stride(primals_1484, (18, ), (1, ))
    assert_size_stride(primals_1485, (), ())
    assert_size_stride(primals_1486, (18, ), (1, ))
    assert_size_stride(primals_1487, (18, ), (1, ))
    assert_size_stride(primals_1488, (), ())
    assert_size_stride(primals_1489, (36, ), (1, ))
    assert_size_stride(primals_1490, (36, ), (1, ))
    assert_size_stride(primals_1491, (), ())
    assert_size_stride(primals_1492, (36, ), (1, ))
    assert_size_stride(primals_1493, (36, ), (1, ))
    assert_size_stride(primals_1494, (), ())
    assert_size_stride(primals_1495, (36, ), (1, ))
    assert_size_stride(primals_1496, (36, ), (1, ))
    assert_size_stride(primals_1497, (), ())
    assert_size_stride(primals_1498, (36, ), (1, ))
    assert_size_stride(primals_1499, (36, ), (1, ))
    assert_size_stride(primals_1500, (), ())
    assert_size_stride(primals_1501, (36, ), (1, ))
    assert_size_stride(primals_1502, (36, ), (1, ))
    assert_size_stride(primals_1503, (), ())
    assert_size_stride(primals_1504, (36, ), (1, ))
    assert_size_stride(primals_1505, (36, ), (1, ))
    assert_size_stride(primals_1506, (), ())
    assert_size_stride(primals_1507, (36, ), (1, ))
    assert_size_stride(primals_1508, (36, ), (1, ))
    assert_size_stride(primals_1509, (), ())
    assert_size_stride(primals_1510, (36, ), (1, ))
    assert_size_stride(primals_1511, (36, ), (1, ))
    assert_size_stride(primals_1512, (), ())
    assert_size_stride(primals_1513, (72, ), (1, ))
    assert_size_stride(primals_1514, (72, ), (1, ))
    assert_size_stride(primals_1515, (), ())
    assert_size_stride(primals_1516, (72, ), (1, ))
    assert_size_stride(primals_1517, (72, ), (1, ))
    assert_size_stride(primals_1518, (), ())
    assert_size_stride(primals_1519, (72, ), (1, ))
    assert_size_stride(primals_1520, (72, ), (1, ))
    assert_size_stride(primals_1521, (), ())
    assert_size_stride(primals_1522, (72, ), (1, ))
    assert_size_stride(primals_1523, (72, ), (1, ))
    assert_size_stride(primals_1524, (), ())
    assert_size_stride(primals_1525, (72, ), (1, ))
    assert_size_stride(primals_1526, (72, ), (1, ))
    assert_size_stride(primals_1527, (), ())
    assert_size_stride(primals_1528, (72, ), (1, ))
    assert_size_stride(primals_1529, (72, ), (1, ))
    assert_size_stride(primals_1530, (), ())
    assert_size_stride(primals_1531, (72, ), (1, ))
    assert_size_stride(primals_1532, (72, ), (1, ))
    assert_size_stride(primals_1533, (), ())
    assert_size_stride(primals_1534, (72, ), (1, ))
    assert_size_stride(primals_1535, (72, ), (1, ))
    assert_size_stride(primals_1536, (), ())
    assert_size_stride(primals_1537, (144, ), (1, ))
    assert_size_stride(primals_1538, (144, ), (1, ))
    assert_size_stride(primals_1539, (), ())
    assert_size_stride(primals_1540, (144, ), (1, ))
    assert_size_stride(primals_1541, (144, ), (1, ))
    assert_size_stride(primals_1542, (), ())
    assert_size_stride(primals_1543, (144, ), (1, ))
    assert_size_stride(primals_1544, (144, ), (1, ))
    assert_size_stride(primals_1545, (), ())
    assert_size_stride(primals_1546, (144, ), (1, ))
    assert_size_stride(primals_1547, (144, ), (1, ))
    assert_size_stride(primals_1548, (), ())
    assert_size_stride(primals_1549, (144, ), (1, ))
    assert_size_stride(primals_1550, (144, ), (1, ))
    assert_size_stride(primals_1551, (), ())
    assert_size_stride(primals_1552, (144, ), (1, ))
    assert_size_stride(primals_1553, (144, ), (1, ))
    assert_size_stride(primals_1554, (), ())
    assert_size_stride(primals_1555, (144, ), (1, ))
    assert_size_stride(primals_1556, (144, ), (1, ))
    assert_size_stride(primals_1557, (), ())
    assert_size_stride(primals_1558, (144, ), (1, ))
    assert_size_stride(primals_1559, (144, ), (1, ))
    assert_size_stride(primals_1560, (), ())
    assert_size_stride(primals_1561, (18, ), (1, ))
    assert_size_stride(primals_1562, (18, ), (1, ))
    assert_size_stride(primals_1563, (), ())
    assert_size_stride(primals_1564, (18, ), (1, ))
    assert_size_stride(primals_1565, (18, ), (1, ))
    assert_size_stride(primals_1566, (), ())
    assert_size_stride(primals_1567, (18, ), (1, ))
    assert_size_stride(primals_1568, (18, ), (1, ))
    assert_size_stride(primals_1569, (), ())
    assert_size_stride(primals_1570, (36, ), (1, ))
    assert_size_stride(primals_1571, (36, ), (1, ))
    assert_size_stride(primals_1572, (), ())
    assert_size_stride(primals_1573, (36, ), (1, ))
    assert_size_stride(primals_1574, (36, ), (1, ))
    assert_size_stride(primals_1575, (), ())
    assert_size_stride(primals_1576, (36, ), (1, ))
    assert_size_stride(primals_1577, (36, ), (1, ))
    assert_size_stride(primals_1578, (), ())
    assert_size_stride(primals_1579, (18, ), (1, ))
    assert_size_stride(primals_1580, (18, ), (1, ))
    assert_size_stride(primals_1581, (), ())
    assert_size_stride(primals_1582, (72, ), (1, ))
    assert_size_stride(primals_1583, (72, ), (1, ))
    assert_size_stride(primals_1584, (), ())
    assert_size_stride(primals_1585, (72, ), (1, ))
    assert_size_stride(primals_1586, (72, ), (1, ))
    assert_size_stride(primals_1587, (), ())
    assert_size_stride(primals_1588, (72, ), (1, ))
    assert_size_stride(primals_1589, (72, ), (1, ))
    assert_size_stride(primals_1590, (), ())
    assert_size_stride(primals_1591, (18, ), (1, ))
    assert_size_stride(primals_1592, (18, ), (1, ))
    assert_size_stride(primals_1593, (), ())
    assert_size_stride(primals_1594, (18, ), (1, ))
    assert_size_stride(primals_1595, (18, ), (1, ))
    assert_size_stride(primals_1596, (), ())
    assert_size_stride(primals_1597, (144, ), (1, ))
    assert_size_stride(primals_1598, (144, ), (1, ))
    assert_size_stride(primals_1599, (), ())
    assert_size_stride(primals_1600, (36, ), (1, ))
    assert_size_stride(primals_1601, (36, ), (1, ))
    assert_size_stride(primals_1602, (), ())
    assert_size_stride(primals_1603, (144, ), (1, ))
    assert_size_stride(primals_1604, (144, ), (1, ))
    assert_size_stride(primals_1605, (), ())
    assert_size_stride(primals_1606, (144, ), (1, ))
    assert_size_stride(primals_1607, (144, ), (1, ))
    assert_size_stride(primals_1608, (), ())
    assert_size_stride(primals_1609, (18, ), (1, ))
    assert_size_stride(primals_1610, (18, ), (1, ))
    assert_size_stride(primals_1611, (), ())
    assert_size_stride(primals_1612, (18, ), (1, ))
    assert_size_stride(primals_1613, (18, ), (1, ))
    assert_size_stride(primals_1614, (), ())
    assert_size_stride(primals_1615, (18, ), (1, ))
    assert_size_stride(primals_1616, (18, ), (1, ))
    assert_size_stride(primals_1617, (), ())
    assert_size_stride(primals_1618, (18, ), (1, ))
    assert_size_stride(primals_1619, (18, ), (1, ))
    assert_size_stride(primals_1620, (), ())
    assert_size_stride(primals_1621, (18, ), (1, ))
    assert_size_stride(primals_1622, (18, ), (1, ))
    assert_size_stride(primals_1623, (), ())
    assert_size_stride(primals_1624, (18, ), (1, ))
    assert_size_stride(primals_1625, (18, ), (1, ))
    assert_size_stride(primals_1626, (), ())
    assert_size_stride(primals_1627, (18, ), (1, ))
    assert_size_stride(primals_1628, (18, ), (1, ))
    assert_size_stride(primals_1629, (), ())
    assert_size_stride(primals_1630, (18, ), (1, ))
    assert_size_stride(primals_1631, (18, ), (1, ))
    assert_size_stride(primals_1632, (), ())
    assert_size_stride(primals_1633, (36, ), (1, ))
    assert_size_stride(primals_1634, (36, ), (1, ))
    assert_size_stride(primals_1635, (), ())
    assert_size_stride(primals_1636, (36, ), (1, ))
    assert_size_stride(primals_1637, (36, ), (1, ))
    assert_size_stride(primals_1638, (), ())
    assert_size_stride(primals_1639, (36, ), (1, ))
    assert_size_stride(primals_1640, (36, ), (1, ))
    assert_size_stride(primals_1641, (), ())
    assert_size_stride(primals_1642, (36, ), (1, ))
    assert_size_stride(primals_1643, (36, ), (1, ))
    assert_size_stride(primals_1644, (), ())
    assert_size_stride(primals_1645, (36, ), (1, ))
    assert_size_stride(primals_1646, (36, ), (1, ))
    assert_size_stride(primals_1647, (), ())
    assert_size_stride(primals_1648, (36, ), (1, ))
    assert_size_stride(primals_1649, (36, ), (1, ))
    assert_size_stride(primals_1650, (), ())
    assert_size_stride(primals_1651, (36, ), (1, ))
    assert_size_stride(primals_1652, (36, ), (1, ))
    assert_size_stride(primals_1653, (), ())
    assert_size_stride(primals_1654, (36, ), (1, ))
    assert_size_stride(primals_1655, (36, ), (1, ))
    assert_size_stride(primals_1656, (), ())
    assert_size_stride(primals_1657, (72, ), (1, ))
    assert_size_stride(primals_1658, (72, ), (1, ))
    assert_size_stride(primals_1659, (), ())
    assert_size_stride(primals_1660, (72, ), (1, ))
    assert_size_stride(primals_1661, (72, ), (1, ))
    assert_size_stride(primals_1662, (), ())
    assert_size_stride(primals_1663, (72, ), (1, ))
    assert_size_stride(primals_1664, (72, ), (1, ))
    assert_size_stride(primals_1665, (), ())
    assert_size_stride(primals_1666, (72, ), (1, ))
    assert_size_stride(primals_1667, (72, ), (1, ))
    assert_size_stride(primals_1668, (), ())
    assert_size_stride(primals_1669, (72, ), (1, ))
    assert_size_stride(primals_1670, (72, ), (1, ))
    assert_size_stride(primals_1671, (), ())
    assert_size_stride(primals_1672, (72, ), (1, ))
    assert_size_stride(primals_1673, (72, ), (1, ))
    assert_size_stride(primals_1674, (), ())
    assert_size_stride(primals_1675, (72, ), (1, ))
    assert_size_stride(primals_1676, (72, ), (1, ))
    assert_size_stride(primals_1677, (), ())
    assert_size_stride(primals_1678, (72, ), (1, ))
    assert_size_stride(primals_1679, (72, ), (1, ))
    assert_size_stride(primals_1680, (), ())
    assert_size_stride(primals_1681, (144, ), (1, ))
    assert_size_stride(primals_1682, (144, ), (1, ))
    assert_size_stride(primals_1683, (), ())
    assert_size_stride(primals_1684, (144, ), (1, ))
    assert_size_stride(primals_1685, (144, ), (1, ))
    assert_size_stride(primals_1686, (), ())
    assert_size_stride(primals_1687, (144, ), (1, ))
    assert_size_stride(primals_1688, (144, ), (1, ))
    assert_size_stride(primals_1689, (), ())
    assert_size_stride(primals_1690, (144, ), (1, ))
    assert_size_stride(primals_1691, (144, ), (1, ))
    assert_size_stride(primals_1692, (), ())
    assert_size_stride(primals_1693, (144, ), (1, ))
    assert_size_stride(primals_1694, (144, ), (1, ))
    assert_size_stride(primals_1695, (), ())
    assert_size_stride(primals_1696, (144, ), (1, ))
    assert_size_stride(primals_1697, (144, ), (1, ))
    assert_size_stride(primals_1698, (), ())
    assert_size_stride(primals_1699, (144, ), (1, ))
    assert_size_stride(primals_1700, (144, ), (1, ))
    assert_size_stride(primals_1701, (), ())
    assert_size_stride(primals_1702, (144, ), (1, ))
    assert_size_stride(primals_1703, (144, ), (1, ))
    assert_size_stride(primals_1704, (), ())
    assert_size_stride(primals_1705, (18, ), (1, ))
    assert_size_stride(primals_1706, (18, ), (1, ))
    assert_size_stride(primals_1707, (), ())
    assert_size_stride(primals_1708, (18, ), (1, ))
    assert_size_stride(primals_1709, (18, ), (1, ))
    assert_size_stride(primals_1710, (), ())
    assert_size_stride(primals_1711, (18, ), (1, ))
    assert_size_stride(primals_1712, (18, ), (1, ))
    assert_size_stride(primals_1713, (), ())
    assert_size_stride(primals_1714, (36, ), (1, ))
    assert_size_stride(primals_1715, (36, ), (1, ))
    assert_size_stride(primals_1716, (), ())
    assert_size_stride(primals_1717, (36, ), (1, ))
    assert_size_stride(primals_1718, (36, ), (1, ))
    assert_size_stride(primals_1719, (), ())
    assert_size_stride(primals_1720, (36, ), (1, ))
    assert_size_stride(primals_1721, (36, ), (1, ))
    assert_size_stride(primals_1722, (), ())
    assert_size_stride(primals_1723, (18, ), (1, ))
    assert_size_stride(primals_1724, (18, ), (1, ))
    assert_size_stride(primals_1725, (), ())
    assert_size_stride(primals_1726, (72, ), (1, ))
    assert_size_stride(primals_1727, (72, ), (1, ))
    assert_size_stride(primals_1728, (), ())
    assert_size_stride(primals_1729, (72, ), (1, ))
    assert_size_stride(primals_1730, (72, ), (1, ))
    assert_size_stride(primals_1731, (), ())
    assert_size_stride(primals_1732, (72, ), (1, ))
    assert_size_stride(primals_1733, (72, ), (1, ))
    assert_size_stride(primals_1734, (), ())
    assert_size_stride(primals_1735, (18, ), (1, ))
    assert_size_stride(primals_1736, (18, ), (1, ))
    assert_size_stride(primals_1737, (), ())
    assert_size_stride(primals_1738, (18, ), (1, ))
    assert_size_stride(primals_1739, (18, ), (1, ))
    assert_size_stride(primals_1740, (), ())
    assert_size_stride(primals_1741, (144, ), (1, ))
    assert_size_stride(primals_1742, (144, ), (1, ))
    assert_size_stride(primals_1743, (), ())
    assert_size_stride(primals_1744, (36, ), (1, ))
    assert_size_stride(primals_1745, (36, ), (1, ))
    assert_size_stride(primals_1746, (), ())
    assert_size_stride(primals_1747, (144, ), (1, ))
    assert_size_stride(primals_1748, (144, ), (1, ))
    assert_size_stride(primals_1749, (), ())
    assert_size_stride(primals_1750, (144, ), (1, ))
    assert_size_stride(primals_1751, (144, ), (1, ))
    assert_size_stride(primals_1752, (), ())
    assert_size_stride(primals_1753, (18, ), (1, ))
    assert_size_stride(primals_1754, (18, ), (1, ))
    assert_size_stride(primals_1755, (), ())
    assert_size_stride(primals_1756, (18, ), (1, ))
    assert_size_stride(primals_1757, (18, ), (1, ))
    assert_size_stride(primals_1758, (), ())
    assert_size_stride(primals_1759, (18, ), (1, ))
    assert_size_stride(primals_1760, (18, ), (1, ))
    assert_size_stride(primals_1761, (), ())
    assert_size_stride(primals_1762, (18, ), (1, ))
    assert_size_stride(primals_1763, (18, ), (1, ))
    assert_size_stride(primals_1764, (), ())
    assert_size_stride(primals_1765, (18, ), (1, ))
    assert_size_stride(primals_1766, (18, ), (1, ))
    assert_size_stride(primals_1767, (), ())
    assert_size_stride(primals_1768, (18, ), (1, ))
    assert_size_stride(primals_1769, (18, ), (1, ))
    assert_size_stride(primals_1770, (), ())
    assert_size_stride(primals_1771, (18, ), (1, ))
    assert_size_stride(primals_1772, (18, ), (1, ))
    assert_size_stride(primals_1773, (), ())
    assert_size_stride(primals_1774, (18, ), (1, ))
    assert_size_stride(primals_1775, (18, ), (1, ))
    assert_size_stride(primals_1776, (), ())
    assert_size_stride(primals_1777, (36, ), (1, ))
    assert_size_stride(primals_1778, (36, ), (1, ))
    assert_size_stride(primals_1779, (), ())
    assert_size_stride(primals_1780, (36, ), (1, ))
    assert_size_stride(primals_1781, (36, ), (1, ))
    assert_size_stride(primals_1782, (), ())
    assert_size_stride(primals_1783, (36, ), (1, ))
    assert_size_stride(primals_1784, (36, ), (1, ))
    assert_size_stride(primals_1785, (), ())
    assert_size_stride(primals_1786, (36, ), (1, ))
    assert_size_stride(primals_1787, (36, ), (1, ))
    assert_size_stride(primals_1788, (), ())
    assert_size_stride(primals_1789, (36, ), (1, ))
    assert_size_stride(primals_1790, (36, ), (1, ))
    assert_size_stride(primals_1791, (), ())
    assert_size_stride(primals_1792, (36, ), (1, ))
    assert_size_stride(primals_1793, (36, ), (1, ))
    assert_size_stride(primals_1794, (), ())
    assert_size_stride(primals_1795, (36, ), (1, ))
    assert_size_stride(primals_1796, (36, ), (1, ))
    assert_size_stride(primals_1797, (), ())
    assert_size_stride(primals_1798, (36, ), (1, ))
    assert_size_stride(primals_1799, (36, ), (1, ))
    assert_size_stride(primals_1800, (), ())
    assert_size_stride(primals_1801, (72, ), (1, ))
    assert_size_stride(primals_1802, (72, ), (1, ))
    assert_size_stride(primals_1803, (), ())
    assert_size_stride(primals_1804, (72, ), (1, ))
    assert_size_stride(primals_1805, (72, ), (1, ))
    assert_size_stride(primals_1806, (), ())
    assert_size_stride(primals_1807, (72, ), (1, ))
    assert_size_stride(primals_1808, (72, ), (1, ))
    assert_size_stride(primals_1809, (), ())
    assert_size_stride(primals_1810, (72, ), (1, ))
    assert_size_stride(primals_1811, (72, ), (1, ))
    assert_size_stride(primals_1812, (), ())
    assert_size_stride(primals_1813, (72, ), (1, ))
    assert_size_stride(primals_1814, (72, ), (1, ))
    assert_size_stride(primals_1815, (), ())
    assert_size_stride(primals_1816, (72, ), (1, ))
    assert_size_stride(primals_1817, (72, ), (1, ))
    assert_size_stride(primals_1818, (), ())
    assert_size_stride(primals_1819, (72, ), (1, ))
    assert_size_stride(primals_1820, (72, ), (1, ))
    assert_size_stride(primals_1821, (), ())
    assert_size_stride(primals_1822, (72, ), (1, ))
    assert_size_stride(primals_1823, (72, ), (1, ))
    assert_size_stride(primals_1824, (), ())
    assert_size_stride(primals_1825, (144, ), (1, ))
    assert_size_stride(primals_1826, (144, ), (1, ))
    assert_size_stride(primals_1827, (), ())
    assert_size_stride(primals_1828, (144, ), (1, ))
    assert_size_stride(primals_1829, (144, ), (1, ))
    assert_size_stride(primals_1830, (), ())
    assert_size_stride(primals_1831, (144, ), (1, ))
    assert_size_stride(primals_1832, (144, ), (1, ))
    assert_size_stride(primals_1833, (), ())
    assert_size_stride(primals_1834, (144, ), (1, ))
    assert_size_stride(primals_1835, (144, ), (1, ))
    assert_size_stride(primals_1836, (), ())
    assert_size_stride(primals_1837, (144, ), (1, ))
    assert_size_stride(primals_1838, (144, ), (1, ))
    assert_size_stride(primals_1839, (), ())
    assert_size_stride(primals_1840, (144, ), (1, ))
    assert_size_stride(primals_1841, (144, ), (1, ))
    assert_size_stride(primals_1842, (), ())
    assert_size_stride(primals_1843, (144, ), (1, ))
    assert_size_stride(primals_1844, (144, ), (1, ))
    assert_size_stride(primals_1845, (), ())
    assert_size_stride(primals_1846, (144, ), (1, ))
    assert_size_stride(primals_1847, (144, ), (1, ))
    assert_size_stride(primals_1848, (), ())
    assert_size_stride(primals_1849, (18, ), (1, ))
    assert_size_stride(primals_1850, (18, ), (1, ))
    assert_size_stride(primals_1851, (), ())
    assert_size_stride(primals_1852, (18, ), (1, ))
    assert_size_stride(primals_1853, (18, ), (1, ))
    assert_size_stride(primals_1854, (), ())
    assert_size_stride(primals_1855, (18, ), (1, ))
    assert_size_stride(primals_1856, (18, ), (1, ))
    assert_size_stride(primals_1857, (), ())
    assert_size_stride(primals_1858, (36, ), (1, ))
    assert_size_stride(primals_1859, (36, ), (1, ))
    assert_size_stride(primals_1860, (), ())
    assert_size_stride(primals_1861, (36, ), (1, ))
    assert_size_stride(primals_1862, (36, ), (1, ))
    assert_size_stride(primals_1863, (), ())
    assert_size_stride(primals_1864, (36, ), (1, ))
    assert_size_stride(primals_1865, (36, ), (1, ))
    assert_size_stride(primals_1866, (), ())
    assert_size_stride(primals_1867, (18, ), (1, ))
    assert_size_stride(primals_1868, (18, ), (1, ))
    assert_size_stride(primals_1869, (), ())
    assert_size_stride(primals_1870, (72, ), (1, ))
    assert_size_stride(primals_1871, (72, ), (1, ))
    assert_size_stride(primals_1872, (), ())
    assert_size_stride(primals_1873, (72, ), (1, ))
    assert_size_stride(primals_1874, (72, ), (1, ))
    assert_size_stride(primals_1875, (), ())
    assert_size_stride(primals_1876, (72, ), (1, ))
    assert_size_stride(primals_1877, (72, ), (1, ))
    assert_size_stride(primals_1878, (), ())
    assert_size_stride(primals_1879, (18, ), (1, ))
    assert_size_stride(primals_1880, (18, ), (1, ))
    assert_size_stride(primals_1881, (), ())
    assert_size_stride(primals_1882, (18, ), (1, ))
    assert_size_stride(primals_1883, (18, ), (1, ))
    assert_size_stride(primals_1884, (), ())
    assert_size_stride(primals_1885, (144, ), (1, ))
    assert_size_stride(primals_1886, (144, ), (1, ))
    assert_size_stride(primals_1887, (), ())
    assert_size_stride(primals_1888, (36, ), (1, ))
    assert_size_stride(primals_1889, (36, ), (1, ))
    assert_size_stride(primals_1890, (), ())
    assert_size_stride(primals_1891, (144, ), (1, ))
    assert_size_stride(primals_1892, (144, ), (1, ))
    assert_size_stride(primals_1893, (), ())
    assert_size_stride(primals_1894, (144, ), (1, ))
    assert_size_stride(primals_1895, (144, ), (1, ))
    assert_size_stride(primals_1896, (), ())
    assert_size_stride(primals_1897, (32, ), (1, ))
    assert_size_stride(primals_1898, (32, ), (1, ))
    assert_size_stride(primals_1899, (), ())
    assert_size_stride(primals_1900, (32, ), (1, ))
    assert_size_stride(primals_1901, (32, ), (1, ))
    assert_size_stride(primals_1902, (), ())
    assert_size_stride(primals_1903, (128, ), (1, ))
    assert_size_stride(primals_1904, (128, ), (1, ))
    assert_size_stride(primals_1905, (), ())
    assert_size_stride(primals_1906, (128, ), (1, ))
    assert_size_stride(primals_1907, (128, ), (1, ))
    assert_size_stride(primals_1908, (), ())
    assert_size_stride(primals_1909, (64, ), (1, ))
    assert_size_stride(primals_1910, (64, ), (1, ))
    assert_size_stride(primals_1911, (), ())
    assert_size_stride(primals_1912, (64, ), (1, ))
    assert_size_stride(primals_1913, (64, ), (1, ))
    assert_size_stride(primals_1914, (), ())
    assert_size_stride(primals_1915, (256, ), (1, ))
    assert_size_stride(primals_1916, (256, ), (1, ))
    assert_size_stride(primals_1917, (), ())
    assert_size_stride(primals_1918, (256, ), (1, ))
    assert_size_stride(primals_1919, (256, ), (1, ))
    assert_size_stride(primals_1920, (), ())
    assert_size_stride(primals_1921, (256, ), (1, ))
    assert_size_stride(primals_1922, (256, ), (1, ))
    assert_size_stride(primals_1923, (), ())
    assert_size_stride(primals_1924, (128, ), (1, ))
    assert_size_stride(primals_1925, (128, ), (1, ))
    assert_size_stride(primals_1926, (), ())
    assert_size_stride(primals_1927, (128, ), (1, ))
    assert_size_stride(primals_1928, (128, ), (1, ))
    assert_size_stride(primals_1929, (), ())
    assert_size_stride(primals_1930, (512, ), (1, ))
    assert_size_stride(primals_1931, (512, ), (1, ))
    assert_size_stride(primals_1932, (), ())
    assert_size_stride(primals_1933, (512, ), (1, ))
    assert_size_stride(primals_1934, (512, ), (1, ))
    assert_size_stride(primals_1935, (), ())
    assert_size_stride(primals_1936, (512, ), (1, ))
    assert_size_stride(primals_1937, (512, ), (1, ))
    assert_size_stride(primals_1938, (), ())
    assert_size_stride(primals_1939, (256, ), (1, ))
    assert_size_stride(primals_1940, (256, ), (1, ))
    assert_size_stride(primals_1941, (), ())
    assert_size_stride(primals_1942, (256, ), (1, ))
    assert_size_stride(primals_1943, (256, ), (1, ))
    assert_size_stride(primals_1944, (), ())
    assert_size_stride(primals_1945, (1024, ), (1, ))
    assert_size_stride(primals_1946, (1024, ), (1, ))
    assert_size_stride(primals_1947, (), ())
    assert_size_stride(primals_1948, (1024, ), (1, ))
    assert_size_stride(primals_1949, (1024, ), (1, ))
    assert_size_stride(primals_1950, (), ())
    assert_size_stride(primals_1951, (1024, ), (1, ))
    assert_size_stride(primals_1952, (1024, ), (1, ))
    assert_size_stride(primals_1953, (), ())
    assert_size_stride(primals_1954, (2048, ), (1, ))
    assert_size_stride(primals_1955, (2048, ), (1, ))
    assert_size_stride(primals_1956, (), ())
    assert_size_stride(primals_1957, (8, 3, 224, 224), (150528, 50176, 224, 1))
    with torch.cuda._DeviceGuard(0):
        torch.cuda.set_device(0) # no-op to ensure context
        # Source Nodes: [x], Original ATen: [aten.convolution]
        buf0 = extern_kernels.convolution(primals_1957, primals_1, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf0, (8, 64, 112, 112), (802816, 12544, 112, 1))
        buf1 = empty_strided((1, 64, 1, 1, 13), (832, 13, 832, 832, 1), device='cuda', dtype=torch.float32)
        buf2 = empty_strided((1, 64, 1, 1, 13), (832, 13, 832, 832, 1), device='cuda', dtype=torch.float32)
        buf3 = empty_strided((1, 64, 1, 1, 13), (832, 13, 832, 832, 1), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1], Original ATen: [aten._native_batch_norm_legit_functional]
        stream0 = get_cuda_stream(0)
        triton_red_fused__native_batch_norm_legit_functional_0.run(buf0, buf1, buf2, buf3, 832, 7720, grid=grid(832), stream=stream0)
        buf4 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
        buf5 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
        buf7 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_1.run(buf1, buf2, buf3, primals_982, primals_983, buf4, buf5, buf7, primals_982, primals_983, 64, 13, grid=grid(64), stream=stream0)
        del buf1
        del buf2
        del buf3
        del primals_982
        del primals_983
        buf8 = empty((8, 64, 112, 112), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1, x_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_2.run(buf0, buf4, buf5, primals_2, primals_3, buf8, 6422528, grid=grid(6422528), stream=stream0)
        del primals_3
        # Source Nodes: [x_3], Original ATen: [aten.convolution]
        buf9 = extern_kernels.convolution(buf8, primals_4, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf9, (8, 64, 56, 56), (200704, 3136, 56, 1))
        buf10 = empty_strided((1, 64, 1, 1, 4), (256, 1, 256, 256, 64), device='cuda', dtype=torch.float32)
        buf11 = empty_strided((1, 64, 1, 1, 4), (256, 1, 256, 256, 64), device='cuda', dtype=torch.float32)
        buf12 = empty_strided((1, 64, 1, 1, 4), (256, 1, 256, 256, 64), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_3.run(buf9, buf10, buf11, buf12, 256, 6272, grid=grid(256), stream=stream0)
        buf13 = buf5; del buf5  # reuse
        buf14 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
        buf16 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_4], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_4.run(buf10, buf11, buf12, primals_985, primals_986, buf13, buf14, buf16, primals_985, primals_986, 64, 4, grid=grid(64), stream=stream0)
        del primals_985
        del primals_986
        buf17 = empty((8, 64, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut, x_4], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_5.run(buf9, buf13, buf14, primals_5, primals_6, buf17, 1605632, grid=grid(1605632), stream=stream0)
        del primals_6
        # Source Nodes: [x_6], Original ATen: [aten.convolution]
        buf18 = extern_kernels.convolution(buf17, primals_7, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf18, (8, 64, 56, 56), (200704, 3136, 56, 1))
        buf19 = buf12; del buf12  # reuse
        buf20 = buf11; del buf11  # reuse
        buf21 = buf10; del buf10  # reuse
        # Source Nodes: [x_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_3.run(buf18, buf19, buf20, buf21, 256, 6272, grid=grid(256), stream=stream0)
        buf22 = buf14; del buf14  # reuse
        buf23 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
        buf25 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_4.run(buf19, buf20, buf21, primals_988, primals_989, buf22, buf23, buf25, primals_988, primals_989, 64, 4, grid=grid(64), stream=stream0)
        del primals_988
        del primals_989
        buf26 = empty((8, 64, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_7, x_8], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_5.run(buf18, buf22, buf23, primals_8, primals_9, buf26, 1605632, grid=grid(1605632), stream=stream0)
        del primals_9
        # Source Nodes: [x_9], Original ATen: [aten.convolution]
        buf27 = extern_kernels.convolution(buf26, primals_10, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf27, (8, 64, 56, 56), (200704, 3136, 56, 1))
        buf28 = buf21; del buf21  # reuse
        buf29 = buf20; del buf20  # reuse
        buf30 = buf19; del buf19  # reuse
        # Source Nodes: [x_10], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_3.run(buf27, buf28, buf29, buf30, 256, 6272, grid=grid(256), stream=stream0)
        buf31 = buf23; del buf23  # reuse
        buf32 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
        buf34 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_10], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_4.run(buf28, buf29, buf30, primals_991, primals_992, buf31, buf32, buf34, primals_991, primals_992, 64, 4, grid=grid(64), stream=stream0)
        del primals_991
        del primals_992
        buf35 = empty((8, 64, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_10, x_12], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_5.run(buf27, buf31, buf32, primals_11, primals_12, buf35, 1605632, grid=grid(1605632), stream=stream0)
        del primals_12
        # Source Nodes: [x_14], Original ATen: [aten.convolution]
        buf36 = extern_kernels.convolution(buf35, primals_13, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf36, (8, 256, 56, 56), (802816, 3136, 56, 1))
        buf37 = reinterpret_tensor(buf30, (1, 256, 1, 1), (256, 1, 256, 256), 0); del buf30  # reuse
        buf38 = reinterpret_tensor(buf29, (1, 256, 1, 1), (256, 1, 256, 256), 0); del buf29  # reuse
        buf40 = reinterpret_tensor(buf28, (256, ), (1, ), 0); del buf28  # reuse
        # Source Nodes: [x_15], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_6.run(buf36, primals_994, primals_995, buf37, buf38, buf40, primals_994, primals_995, 256, 25088, grid=grid(256), stream=stream0)
        del primals_994
        del primals_995
        # Source Nodes: [getattr_l__mod___layer1___0___downsample_0], Original ATen: [aten.convolution]
        buf41 = extern_kernels.convolution(buf17, primals_16, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf41, (8, 256, 56, 56), (802816, 3136, 56, 1))
        buf42 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
        buf43 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
        buf45 = empty((256, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_6.run(buf41, primals_997, primals_998, buf42, buf43, buf45, primals_997, primals_998, 256, 25088, grid=grid(256), stream=stream0)
        del primals_997
        del primals_998
        buf46 = empty((8, 256, 56, 56), device='cuda', dtype=torch.float32)
        buf47 = buf46; del buf46  # reuse
        # Source Nodes: [shortcut_1, shortcut_2, x_15, x_16], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_7.run(buf47, buf36, buf37, buf38, primals_14, primals_15, buf41, buf42, buf43, primals_17, primals_18, 6422528, grid=grid(6422528), stream=stream0)
        del primals_15
        del primals_18
        # Source Nodes: [x_18], Original ATen: [aten.convolution]
        buf48 = extern_kernels.convolution(buf47, primals_19, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf48, (8, 64, 56, 56), (200704, 3136, 56, 1))
        buf49 = reinterpret_tensor(buf43, (1, 64, 1, 1, 4), (256, 1, 256, 256, 64), 0); del buf43  # reuse
        buf50 = reinterpret_tensor(buf38, (1, 64, 1, 1, 4), (256, 1, 256, 256, 64), 0); del buf38  # reuse
        buf51 = empty_strided((1, 64, 1, 1, 4), (256, 1, 256, 256, 64), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_19], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_3.run(buf48, buf49, buf50, buf51, 256, 6272, grid=grid(256), stream=stream0)
        buf52 = buf32; del buf32  # reuse
        buf53 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
        buf55 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_19], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_4.run(buf49, buf50, buf51, primals_1000, primals_1001, buf52, buf53, buf55, primals_1000, primals_1001, 64, 4, grid=grid(64), stream=stream0)
        del primals_1000
        del primals_1001
        buf56 = empty((8, 64, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_19, x_20], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_5.run(buf48, buf52, buf53, primals_20, primals_21, buf56, 1605632, grid=grid(1605632), stream=stream0)
        del primals_21
        # Source Nodes: [x_21], Original ATen: [aten.convolution]
        buf57 = extern_kernels.convolution(buf56, primals_22, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf57, (8, 64, 56, 56), (200704, 3136, 56, 1))
        buf58 = buf51; del buf51  # reuse
        buf59 = buf50; del buf50  # reuse
        buf60 = buf49; del buf49  # reuse
        # Source Nodes: [x_22], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_3.run(buf57, buf58, buf59, buf60, 256, 6272, grid=grid(256), stream=stream0)
        buf61 = buf53; del buf53  # reuse
        buf62 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
        buf64 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_22], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_4.run(buf58, buf59, buf60, primals_1003, primals_1004, buf61, buf62, buf64, primals_1003, primals_1004, 64, 4, grid=grid(64), stream=stream0)
        del primals_1003
        del primals_1004
        buf65 = empty((8, 64, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_22, x_24], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_5.run(buf57, buf61, buf62, primals_23, primals_24, buf65, 1605632, grid=grid(1605632), stream=stream0)
        del primals_24
        # Source Nodes: [x_26], Original ATen: [aten.convolution]
        buf66 = extern_kernels.convolution(buf65, primals_25, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf66, (8, 256, 56, 56), (802816, 3136, 56, 1))
        buf67 = reinterpret_tensor(buf60, (1, 256, 1, 1), (256, 1, 256, 256), 0); del buf60  # reuse
        buf68 = reinterpret_tensor(buf59, (1, 256, 1, 1), (256, 1, 256, 256), 0); del buf59  # reuse
        buf70 = reinterpret_tensor(buf58, (256, ), (1, ), 0); del buf58  # reuse
        # Source Nodes: [x_27], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_6.run(buf66, primals_1006, primals_1007, buf67, buf68, buf70, primals_1006, primals_1007, 256, 25088, grid=grid(256), stream=stream0)
        del primals_1006
        del primals_1007
        buf71 = empty((8, 256, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_3, x_27, x_28], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_8.run(buf66, buf67, buf68, primals_26, primals_27, buf47, buf71, 6422528, grid=grid(6422528), stream=stream0)
        del primals_27
        # Source Nodes: [x_30], Original ATen: [aten.convolution]
        buf72 = extern_kernels.convolution(buf71, primals_28, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf72, (8, 64, 56, 56), (200704, 3136, 56, 1))
        buf73 = reinterpret_tensor(buf68, (1, 64, 1, 1, 4), (256, 1, 256, 256, 64), 0); del buf68  # reuse
        buf74 = empty_strided((1, 64, 1, 1, 4), (256, 1, 256, 256, 64), device='cuda', dtype=torch.float32)
        buf75 = empty_strided((1, 64, 1, 1, 4), (256, 1, 256, 256, 64), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_31], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_3.run(buf72, buf73, buf74, buf75, 256, 6272, grid=grid(256), stream=stream0)
        buf76 = buf62; del buf62  # reuse
        buf77 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
        buf79 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_31], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_4.run(buf73, buf74, buf75, primals_1009, primals_1010, buf76, buf77, buf79, primals_1009, primals_1010, 64, 4, grid=grid(64), stream=stream0)
        del primals_1009
        del primals_1010
        buf80 = empty((8, 64, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_31, x_32], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_5.run(buf72, buf76, buf77, primals_29, primals_30, buf80, 1605632, grid=grid(1605632), stream=stream0)
        del primals_30
        # Source Nodes: [x_33], Original ATen: [aten.convolution]
        buf81 = extern_kernels.convolution(buf80, primals_31, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf81, (8, 64, 56, 56), (200704, 3136, 56, 1))
        buf82 = buf75; del buf75  # reuse
        buf83 = buf74; del buf74  # reuse
        buf84 = buf73; del buf73  # reuse
        # Source Nodes: [x_34], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_3.run(buf81, buf82, buf83, buf84, 256, 6272, grid=grid(256), stream=stream0)
        buf85 = buf77; del buf77  # reuse
        buf86 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
        buf88 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_34], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_4.run(buf82, buf83, buf84, primals_1012, primals_1013, buf85, buf86, buf88, primals_1012, primals_1013, 64, 4, grid=grid(64), stream=stream0)
        del primals_1012
        del primals_1013
        buf89 = empty((8, 64, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_34, x_36], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_5.run(buf81, buf85, buf86, primals_32, primals_33, buf89, 1605632, grid=grid(1605632), stream=stream0)
        del primals_33
        # Source Nodes: [x_38], Original ATen: [aten.convolution]
        buf90 = extern_kernels.convolution(buf89, primals_34, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf90, (8, 256, 56, 56), (802816, 3136, 56, 1))
        buf91 = reinterpret_tensor(buf84, (1, 256, 1, 1), (256, 1, 256, 256), 0); del buf84  # reuse
        buf92 = reinterpret_tensor(buf83, (1, 256, 1, 1), (256, 1, 256, 256), 0); del buf83  # reuse
        buf94 = reinterpret_tensor(buf82, (256, ), (1, ), 0); del buf82  # reuse
        # Source Nodes: [x_39], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_6.run(buf90, primals_1015, primals_1016, buf91, buf92, buf94, primals_1015, primals_1016, 256, 25088, grid=grid(256), stream=stream0)
        del primals_1015
        del primals_1016
        buf95 = empty((8, 256, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_4, x_39, x_40], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_8.run(buf90, buf91, buf92, primals_35, primals_36, buf71, buf95, 6422528, grid=grid(6422528), stream=stream0)
        del primals_36
        # Source Nodes: [x_42], Original ATen: [aten.convolution]
        buf96 = extern_kernels.convolution(buf95, primals_37, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf96, (8, 64, 56, 56), (200704, 3136, 56, 1))
        buf97 = reinterpret_tensor(buf92, (1, 64, 1, 1, 4), (256, 1, 256, 256, 64), 0); del buf92  # reuse
        buf98 = empty_strided((1, 64, 1, 1, 4), (256, 1, 256, 256, 64), device='cuda', dtype=torch.float32)
        buf99 = empty_strided((1, 64, 1, 1, 4), (256, 1, 256, 256, 64), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_43], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_3.run(buf96, buf97, buf98, buf99, 256, 6272, grid=grid(256), stream=stream0)
        buf100 = buf86; del buf86  # reuse
        buf101 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
        buf103 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_43], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_4.run(buf97, buf98, buf99, primals_1018, primals_1019, buf100, buf101, buf103, primals_1018, primals_1019, 64, 4, grid=grid(64), stream=stream0)
        del primals_1018
        del primals_1019
        buf104 = empty((8, 64, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_43, x_44], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_5.run(buf96, buf100, buf101, primals_38, primals_39, buf104, 1605632, grid=grid(1605632), stream=stream0)
        del primals_39
        # Source Nodes: [x_45], Original ATen: [aten.convolution]
        buf105 = extern_kernels.convolution(buf104, primals_40, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf105, (8, 64, 56, 56), (200704, 3136, 56, 1))
        buf106 = buf99; del buf99  # reuse
        buf107 = buf98; del buf98  # reuse
        buf108 = buf97; del buf97  # reuse
        # Source Nodes: [x_46], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_3.run(buf105, buf106, buf107, buf108, 256, 6272, grid=grid(256), stream=stream0)
        buf109 = buf101; del buf101  # reuse
        buf110 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
        buf112 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_46], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_4.run(buf106, buf107, buf108, primals_1021, primals_1022, buf109, buf110, buf112, primals_1021, primals_1022, 64, 4, grid=grid(64), stream=stream0)
        del primals_1021
        del primals_1022
        buf113 = empty((8, 64, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_46, x_48], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_5.run(buf105, buf109, buf110, primals_41, primals_42, buf113, 1605632, grid=grid(1605632), stream=stream0)
        del primals_42
        # Source Nodes: [x_50], Original ATen: [aten.convolution]
        buf114 = extern_kernels.convolution(buf113, primals_43, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf114, (8, 256, 56, 56), (802816, 3136, 56, 1))
        buf115 = reinterpret_tensor(buf108, (1, 256, 1, 1), (256, 1, 256, 256), 0); del buf108  # reuse
        buf116 = reinterpret_tensor(buf107, (1, 256, 1, 1), (256, 1, 256, 256), 0); del buf107  # reuse
        buf118 = reinterpret_tensor(buf106, (256, ), (1, ), 0); del buf106  # reuse
        # Source Nodes: [x_51], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_6.run(buf114, primals_1024, primals_1025, buf115, buf116, buf118, primals_1024, primals_1025, 256, 25088, grid=grid(256), stream=stream0)
        del primals_1024
        del primals_1025
        buf119 = empty((8, 256, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_51, x_52, x_53], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_8.run(buf114, buf115, buf116, primals_44, primals_45, buf95, buf119, 6422528, grid=grid(6422528), stream=stream0)
        del primals_45
        # Source Nodes: [l__mod___transition1_0_0], Original ATen: [aten.convolution]
        buf120 = extern_kernels.convolution(buf119, primals_46, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf120, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf121 = empty_strided((1, 18, 1, 1, 4), (72, 1, 72, 72, 18), device='cuda', dtype=torch.float32)
        buf122 = empty_strided((1, 18, 1, 1, 4), (72, 1, 72, 72, 18), device='cuda', dtype=torch.float32)
        buf123 = empty_strided((1, 18, 1, 1, 4), (72, 1, 72, 72, 18), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___transition1_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf120, buf121, buf122, buf123, 72, 6272, grid=grid(72), stream=stream0)
        buf124 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf125 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf127 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___transition1_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf121, buf122, buf123, primals_1027, primals_1028, buf124, buf125, buf127, primals_1027, primals_1028, 18, 4, grid=grid(18), stream=stream0)
        del primals_1027
        del primals_1028
        buf128 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___transition1_0_1, shortcut_5], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf120, buf124, buf125, primals_47, primals_48, buf128, 451584, grid=grid(451584), stream=stream0)
        del primals_48
        # Source Nodes: [l__mod___transition1_1_0_0], Original ATen: [aten.convolution]
        buf129 = extern_kernels.convolution(buf119, primals_49, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf129, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf130 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf131 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf133 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___transition1_1_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf129, primals_1030, primals_1031, buf130, buf131, buf133, primals_1030, primals_1031, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1030
        del primals_1031
        buf134 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___transition1_1_0_1, shortcut_9], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf129, buf130, buf131, primals_50, primals_51, buf134, 225792, grid=grid(225792), stream=stream0)
        del primals_51
        # Source Nodes: [x_54], Original ATen: [aten.convolution]
        buf135 = extern_kernels.convolution(buf128, primals_52, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf135, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf136 = buf123; del buf123  # reuse
        buf137 = buf122; del buf122  # reuse
        buf138 = buf121; del buf121  # reuse
        # Source Nodes: [x_55], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf135, buf136, buf137, buf138, 72, 6272, grid=grid(72), stream=stream0)
        buf139 = buf125; del buf125  # reuse
        buf140 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf142 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_55], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf136, buf137, buf138, primals_1033, primals_1034, buf139, buf140, buf142, primals_1033, primals_1034, 18, 4, grid=grid(18), stream=stream0)
        del primals_1033
        del primals_1034
        buf143 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_55, x_57], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf135, buf139, buf140, primals_53, primals_54, buf143, 451584, grid=grid(451584), stream=stream0)
        del primals_54
        # Source Nodes: [x_59], Original ATen: [aten.convolution]
        buf144 = extern_kernels.convolution(buf143, primals_55, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf144, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf145 = buf138; del buf138  # reuse
        buf146 = buf137; del buf137  # reuse
        buf147 = buf136; del buf136  # reuse
        # Source Nodes: [x_60], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf144, buf145, buf146, buf147, 72, 6272, grid=grid(72), stream=stream0)
        buf148 = buf140; del buf140  # reuse
        buf149 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf151 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_60], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf145, buf146, buf147, primals_1036, primals_1037, buf148, buf149, buf151, primals_1036, primals_1037, 18, 4, grid=grid(18), stream=stream0)
        del primals_1036
        del primals_1037
        buf152 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_6, x_60, x_61], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf144, buf148, buf149, primals_56, primals_57, buf128, buf152, 451584, grid=grid(451584), stream=stream0)
        del primals_57
        # Source Nodes: [x_63], Original ATen: [aten.convolution]
        buf153 = extern_kernels.convolution(buf152, primals_58, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf153, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf154 = buf147; del buf147  # reuse
        buf155 = buf146; del buf146  # reuse
        buf156 = buf145; del buf145  # reuse
        # Source Nodes: [x_64], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf153, buf154, buf155, buf156, 72, 6272, grid=grid(72), stream=stream0)
        buf157 = buf149; del buf149  # reuse
        buf158 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf160 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_64], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf154, buf155, buf156, primals_1039, primals_1040, buf157, buf158, buf160, primals_1039, primals_1040, 18, 4, grid=grid(18), stream=stream0)
        del primals_1039
        del primals_1040
        buf161 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_64, x_66], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf153, buf157, buf158, primals_59, primals_60, buf161, 451584, grid=grid(451584), stream=stream0)
        del primals_60
        # Source Nodes: [x_68], Original ATen: [aten.convolution]
        buf162 = extern_kernels.convolution(buf161, primals_61, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf162, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf163 = buf156; del buf156  # reuse
        buf164 = buf155; del buf155  # reuse
        buf165 = buf154; del buf154  # reuse
        # Source Nodes: [x_69], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf162, buf163, buf164, buf165, 72, 6272, grid=grid(72), stream=stream0)
        buf166 = buf158; del buf158  # reuse
        buf167 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf169 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_69], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf163, buf164, buf165, primals_1042, primals_1043, buf166, buf167, buf169, primals_1042, primals_1043, 18, 4, grid=grid(18), stream=stream0)
        del primals_1042
        del primals_1043
        buf170 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_7, x_69, x_70], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf162, buf166, buf167, primals_62, primals_63, buf152, buf170, 451584, grid=grid(451584), stream=stream0)
        del primals_63
        # Source Nodes: [x_72], Original ATen: [aten.convolution]
        buf171 = extern_kernels.convolution(buf170, primals_64, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf171, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf172 = buf165; del buf165  # reuse
        buf173 = buf164; del buf164  # reuse
        buf174 = buf163; del buf163  # reuse
        # Source Nodes: [x_73], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf171, buf172, buf173, buf174, 72, 6272, grid=grid(72), stream=stream0)
        buf175 = buf167; del buf167  # reuse
        buf176 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf178 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_73], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf172, buf173, buf174, primals_1045, primals_1046, buf175, buf176, buf178, primals_1045, primals_1046, 18, 4, grid=grid(18), stream=stream0)
        del primals_1045
        del primals_1046
        buf179 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_73, x_75], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf171, buf175, buf176, primals_65, primals_66, buf179, 451584, grid=grid(451584), stream=stream0)
        del primals_66
        # Source Nodes: [x_77], Original ATen: [aten.convolution]
        buf180 = extern_kernels.convolution(buf179, primals_67, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf180, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf181 = buf174; del buf174  # reuse
        buf182 = buf173; del buf173  # reuse
        buf183 = buf172; del buf172  # reuse
        # Source Nodes: [x_78], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf180, buf181, buf182, buf183, 72, 6272, grid=grid(72), stream=stream0)
        buf184 = buf176; del buf176  # reuse
        buf185 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf187 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_78], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf181, buf182, buf183, primals_1048, primals_1049, buf184, buf185, buf187, primals_1048, primals_1049, 18, 4, grid=grid(18), stream=stream0)
        del primals_1048
        del primals_1049
        buf188 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_8, x_78, x_79], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf180, buf184, buf185, primals_68, primals_69, buf170, buf188, 451584, grid=grid(451584), stream=stream0)
        del primals_69
        # Source Nodes: [x_81], Original ATen: [aten.convolution]
        buf189 = extern_kernels.convolution(buf188, primals_70, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf189, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf190 = buf183; del buf183  # reuse
        buf191 = buf182; del buf182  # reuse
        buf192 = buf181; del buf181  # reuse
        # Source Nodes: [x_82], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf189, buf190, buf191, buf192, 72, 6272, grid=grid(72), stream=stream0)
        buf193 = buf185; del buf185  # reuse
        buf194 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf196 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_82], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf190, buf191, buf192, primals_1051, primals_1052, buf193, buf194, buf196, primals_1051, primals_1052, 18, 4, grid=grid(18), stream=stream0)
        del primals_1051
        del primals_1052
        buf197 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_82, x_84], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf189, buf193, buf194, primals_71, primals_72, buf197, 451584, grid=grid(451584), stream=stream0)
        del primals_72
        # Source Nodes: [x_86], Original ATen: [aten.convolution]
        buf198 = extern_kernels.convolution(buf197, primals_73, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf198, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf199 = buf192; del buf192  # reuse
        buf200 = buf191; del buf191  # reuse
        buf201 = buf190; del buf190  # reuse
        # Source Nodes: [x_87], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf198, buf199, buf200, buf201, 72, 6272, grid=grid(72), stream=stream0)
        buf202 = buf194; del buf194  # reuse
        buf203 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf205 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_87], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf199, buf200, buf201, primals_1054, primals_1055, buf202, buf203, buf205, primals_1054, primals_1055, 18, 4, grid=grid(18), stream=stream0)
        del primals_1054
        del primals_1055
        # Source Nodes: [x_90], Original ATen: [aten.convolution]
        buf207 = extern_kernels.convolution(buf134, primals_76, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf207, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf208 = buf131; del buf131  # reuse
        buf209 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf211 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_91], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf207, primals_1057, primals_1058, buf208, buf209, buf211, primals_1057, primals_1058, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1057
        del primals_1058
        buf212 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_91, x_93], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf207, buf208, buf209, primals_77, primals_78, buf212, 225792, grid=grid(225792), stream=stream0)
        del primals_78
        # Source Nodes: [x_95], Original ATen: [aten.convolution]
        buf213 = extern_kernels.convolution(buf212, primals_79, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf213, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf214 = buf209; del buf209  # reuse
        buf215 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf217 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_96], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf213, primals_1060, primals_1061, buf214, buf215, buf217, primals_1060, primals_1061, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1060
        del primals_1061
        buf218 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_10, x_96, x_97], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf213, buf214, buf215, primals_80, primals_81, buf134, buf218, 225792, grid=grid(225792), stream=stream0)
        del primals_81
        # Source Nodes: [x_99], Original ATen: [aten.convolution]
        buf219 = extern_kernels.convolution(buf218, primals_82, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf219, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf220 = buf215; del buf215  # reuse
        buf221 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf223 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_100], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf219, primals_1063, primals_1064, buf220, buf221, buf223, primals_1063, primals_1064, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1063
        del primals_1064
        buf224 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_100, x_102], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf219, buf220, buf221, primals_83, primals_84, buf224, 225792, grid=grid(225792), stream=stream0)
        del primals_84
        # Source Nodes: [x_104], Original ATen: [aten.convolution]
        buf225 = extern_kernels.convolution(buf224, primals_85, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf225, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf226 = buf221; del buf221  # reuse
        buf227 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf229 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_105], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf225, primals_1066, primals_1067, buf226, buf227, buf229, primals_1066, primals_1067, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1066
        del primals_1067
        buf230 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_11, x_105, x_106], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf225, buf226, buf227, primals_86, primals_87, buf218, buf230, 225792, grid=grid(225792), stream=stream0)
        del primals_87
        # Source Nodes: [x_108], Original ATen: [aten.convolution]
        buf231 = extern_kernels.convolution(buf230, primals_88, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf231, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf232 = buf227; del buf227  # reuse
        buf233 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf235 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_109], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf231, primals_1069, primals_1070, buf232, buf233, buf235, primals_1069, primals_1070, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1069
        del primals_1070
        buf236 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_109, x_111], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf231, buf232, buf233, primals_89, primals_90, buf236, 225792, grid=grid(225792), stream=stream0)
        del primals_90
        # Source Nodes: [x_113], Original ATen: [aten.convolution]
        buf237 = extern_kernels.convolution(buf236, primals_91, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf237, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf238 = buf233; del buf233  # reuse
        buf239 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf241 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_114], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf237, primals_1072, primals_1073, buf238, buf239, buf241, primals_1072, primals_1073, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1072
        del primals_1073
        buf242 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_12, x_114, x_115], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf237, buf238, buf239, primals_92, primals_93, buf230, buf242, 225792, grid=grid(225792), stream=stream0)
        del primals_93
        # Source Nodes: [x_117], Original ATen: [aten.convolution]
        buf243 = extern_kernels.convolution(buf242, primals_94, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf243, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf244 = buf239; del buf239  # reuse
        buf245 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf247 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_118], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf243, primals_1075, primals_1076, buf244, buf245, buf247, primals_1075, primals_1076, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1075
        del primals_1076
        buf248 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_118, x_120], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf243, buf244, buf245, primals_95, primals_96, buf248, 225792, grid=grid(225792), stream=stream0)
        del primals_96
        # Source Nodes: [x_122], Original ATen: [aten.convolution]
        buf249 = extern_kernels.convolution(buf248, primals_97, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf249, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf250 = buf245; del buf245  # reuse
        buf251 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf253 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_123], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf249, primals_1078, primals_1079, buf250, buf251, buf253, primals_1078, primals_1079, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1078
        del primals_1079
        buf254 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_123, x_124, x_125], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf249, buf250, buf251, primals_98, primals_99, buf242, buf254, 225792, grid=grid(225792), stream=stream0)
        del primals_99
        # Source Nodes: [l__mod___stage2_0_fuse_layers_0_1_0], Original ATen: [aten.convolution]
        buf255 = extern_kernels.convolution(buf254, primals_100, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf255, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf256 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf257 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf259 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage2_0_fuse_layers_0_1_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf255, primals_1081, primals_1082, buf256, buf257, buf259, primals_1081, primals_1082, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1081
        del primals_1082
        buf260 = empty((56, ), device='cuda', dtype=torch.int64)
        # Source Nodes: [l__mod___stage2_0_fuse_layers_0_1_2], Original ATen: [aten._to_copy, aten.add, aten.arange, aten.mul]
        triton_poi_fused__to_copy_add_arange_mul_17.run(buf260, 56, grid=grid(56), stream=stream0)
        buf206 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        buf261 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage2_0_fuse_layers_0_1_1, l__mod___stage2_0_fuse_layers_0_1_2, shortcut_13, x_87, x_88, x_89, y_1], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_18.run(buf198, buf202, buf203, primals_74, primals_75, buf188, buf260, buf255, buf256, buf257, primals_101, primals_102, buf206, buf261, 451584, grid=grid(451584), stream=stream0)
        del primals_102
        del primals_75
        # Source Nodes: [l__mod___stage2_0_fuse_layers_1_0_0_0], Original ATen: [aten.convolution]
        buf262 = extern_kernels.convolution(buf206, primals_103, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf262, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf263 = buf251; del buf251  # reuse
        buf264 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf266 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf262, primals_1084, primals_1085, buf263, buf264, buf266, primals_1084, primals_1085, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1084
        del primals_1085
        buf267 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_17, y_2, y_3], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf262, buf263, buf264, primals_104, primals_105, buf254, buf267, 225792, grid=grid(225792), stream=stream0)
        del primals_105
        # Source Nodes: [l__mod___transition2_2_0_0], Original ATen: [aten.convolution]
        buf268 = extern_kernels.convolution(buf267, primals_106, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf268, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf269 = reinterpret_tensor(buf201, (1, 72, 1, 1), (72, 1, 72, 72), 0); del buf201  # reuse
        buf270 = reinterpret_tensor(buf200, (1, 72, 1, 1), (72, 1, 72, 72), 0); del buf200  # reuse
        buf272 = reinterpret_tensor(buf199, (72, ), (1, ), 0); del buf199  # reuse
        # Source Nodes: [l__mod___transition2_2_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf268, primals_1087, primals_1088, buf269, buf270, buf272, primals_1087, primals_1088, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1087
        del primals_1088
        buf273 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___transition2_2_0_1, shortcut_21], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf268, buf269, buf270, primals_107, primals_108, buf273, 112896, grid=grid(112896), stream=stream0)
        del primals_108
        # Source Nodes: [x_126], Original ATen: [aten.convolution]
        buf274 = extern_kernels.convolution(buf261, primals_109, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf274, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf275 = reinterpret_tensor(buf270, (1, 18, 1, 1, 4), (72, 1, 72, 72, 18), 0); del buf270  # reuse
        buf276 = empty_strided((1, 18, 1, 1, 4), (72, 1, 72, 72, 18), device='cuda', dtype=torch.float32)
        buf277 = empty_strided((1, 18, 1, 1, 4), (72, 1, 72, 72, 18), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_127], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf274, buf275, buf276, buf277, 72, 6272, grid=grid(72), stream=stream0)
        buf278 = buf257; del buf257  # reuse
        buf279 = buf203; del buf203  # reuse
        buf281 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_127], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf275, buf276, buf277, primals_1090, primals_1091, buf278, buf279, buf281, primals_1090, primals_1091, 18, 4, grid=grid(18), stream=stream0)
        del primals_1090
        del primals_1091
        buf282 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_127, x_129], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf274, buf278, buf279, primals_110, primals_111, buf282, 451584, grid=grid(451584), stream=stream0)
        del primals_111
        # Source Nodes: [x_131], Original ATen: [aten.convolution]
        buf283 = extern_kernels.convolution(buf282, primals_112, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf283, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf284 = buf277; del buf277  # reuse
        buf285 = buf276; del buf276  # reuse
        buf286 = buf275; del buf275  # reuse
        # Source Nodes: [x_132], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf283, buf284, buf285, buf286, 72, 6272, grid=grid(72), stream=stream0)
        buf287 = buf279; del buf279  # reuse
        buf288 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf290 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_132], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf284, buf285, buf286, primals_1093, primals_1094, buf287, buf288, buf290, primals_1093, primals_1094, 18, 4, grid=grid(18), stream=stream0)
        del primals_1093
        del primals_1094
        buf291 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_14, x_132, x_133], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf283, buf287, buf288, primals_113, primals_114, buf261, buf291, 451584, grid=grid(451584), stream=stream0)
        del primals_114
        # Source Nodes: [x_135], Original ATen: [aten.convolution]
        buf292 = extern_kernels.convolution(buf291, primals_115, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf292, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf293 = buf286; del buf286  # reuse
        buf294 = buf285; del buf285  # reuse
        buf295 = buf284; del buf284  # reuse
        # Source Nodes: [x_136], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf292, buf293, buf294, buf295, 72, 6272, grid=grid(72), stream=stream0)
        buf296 = buf288; del buf288  # reuse
        buf297 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf299 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_136], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf293, buf294, buf295, primals_1096, primals_1097, buf296, buf297, buf299, primals_1096, primals_1097, 18, 4, grid=grid(18), stream=stream0)
        del primals_1096
        del primals_1097
        buf300 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_136, x_138], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf292, buf296, buf297, primals_116, primals_117, buf300, 451584, grid=grid(451584), stream=stream0)
        del primals_117
        # Source Nodes: [x_140], Original ATen: [aten.convolution]
        buf301 = extern_kernels.convolution(buf300, primals_118, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf301, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf302 = buf295; del buf295  # reuse
        buf303 = buf294; del buf294  # reuse
        buf304 = buf293; del buf293  # reuse
        # Source Nodes: [x_141], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf301, buf302, buf303, buf304, 72, 6272, grid=grid(72), stream=stream0)
        buf305 = buf297; del buf297  # reuse
        buf306 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf308 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_141], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf302, buf303, buf304, primals_1099, primals_1100, buf305, buf306, buf308, primals_1099, primals_1100, 18, 4, grid=grid(18), stream=stream0)
        del primals_1099
        del primals_1100
        buf309 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_15, x_141, x_142], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf301, buf305, buf306, primals_119, primals_120, buf291, buf309, 451584, grid=grid(451584), stream=stream0)
        del primals_120
        # Source Nodes: [x_144], Original ATen: [aten.convolution]
        buf310 = extern_kernels.convolution(buf309, primals_121, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf310, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf311 = buf304; del buf304  # reuse
        buf312 = buf303; del buf303  # reuse
        buf313 = buf302; del buf302  # reuse
        # Source Nodes: [x_145], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf310, buf311, buf312, buf313, 72, 6272, grid=grid(72), stream=stream0)
        buf314 = buf306; del buf306  # reuse
        buf315 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf317 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_145], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf311, buf312, buf313, primals_1102, primals_1103, buf314, buf315, buf317, primals_1102, primals_1103, 18, 4, grid=grid(18), stream=stream0)
        del primals_1102
        del primals_1103
        buf318 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_145, x_147], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf310, buf314, buf315, primals_122, primals_123, buf318, 451584, grid=grid(451584), stream=stream0)
        del primals_123
        # Source Nodes: [x_149], Original ATen: [aten.convolution]
        buf319 = extern_kernels.convolution(buf318, primals_124, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf319, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf320 = buf313; del buf313  # reuse
        buf321 = buf312; del buf312  # reuse
        buf322 = buf311; del buf311  # reuse
        # Source Nodes: [x_150], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf319, buf320, buf321, buf322, 72, 6272, grid=grid(72), stream=stream0)
        buf323 = buf315; del buf315  # reuse
        buf324 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf326 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_150], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf320, buf321, buf322, primals_1105, primals_1106, buf323, buf324, buf326, primals_1105, primals_1106, 18, 4, grid=grid(18), stream=stream0)
        del primals_1105
        del primals_1106
        buf327 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_16, x_150, x_151], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf319, buf323, buf324, primals_125, primals_126, buf309, buf327, 451584, grid=grid(451584), stream=stream0)
        del primals_126
        # Source Nodes: [x_153], Original ATen: [aten.convolution]
        buf328 = extern_kernels.convolution(buf327, primals_127, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf328, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf329 = buf322; del buf322  # reuse
        buf330 = buf321; del buf321  # reuse
        buf331 = buf320; del buf320  # reuse
        # Source Nodes: [x_154], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf328, buf329, buf330, buf331, 72, 6272, grid=grid(72), stream=stream0)
        buf332 = buf324; del buf324  # reuse
        buf333 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf335 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_154], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf329, buf330, buf331, primals_1108, primals_1109, buf332, buf333, buf335, primals_1108, primals_1109, 18, 4, grid=grid(18), stream=stream0)
        del primals_1108
        del primals_1109
        buf336 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_154, x_156], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf328, buf332, buf333, primals_128, primals_129, buf336, 451584, grid=grid(451584), stream=stream0)
        del primals_129
        # Source Nodes: [x_158], Original ATen: [aten.convolution]
        buf337 = extern_kernels.convolution(buf336, primals_130, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf337, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf338 = buf331; del buf331  # reuse
        buf339 = buf330; del buf330  # reuse
        buf340 = buf329; del buf329  # reuse
        # Source Nodes: [x_159], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf337, buf338, buf339, buf340, 72, 6272, grid=grid(72), stream=stream0)
        buf341 = buf333; del buf333  # reuse
        buf342 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf344 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_159], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf338, buf339, buf340, primals_1111, primals_1112, buf341, buf342, buf344, primals_1111, primals_1112, 18, 4, grid=grid(18), stream=stream0)
        del primals_1111
        del primals_1112
        # Source Nodes: [x_162], Original ATen: [aten.convolution]
        buf346 = extern_kernels.convolution(buf267, primals_133, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf346, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf347 = buf264; del buf264  # reuse
        buf348 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf350 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_163], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf346, primals_1114, primals_1115, buf347, buf348, buf350, primals_1114, primals_1115, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1114
        del primals_1115
        buf351 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_163, x_165], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf346, buf347, buf348, primals_134, primals_135, buf351, 225792, grid=grid(225792), stream=stream0)
        del primals_135
        # Source Nodes: [x_167], Original ATen: [aten.convolution]
        buf352 = extern_kernels.convolution(buf351, primals_136, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf352, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf353 = buf348; del buf348  # reuse
        buf354 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf356 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_168], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf352, primals_1117, primals_1118, buf353, buf354, buf356, primals_1117, primals_1118, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1117
        del primals_1118
        buf357 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_18, x_168, x_169], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf352, buf353, buf354, primals_137, primals_138, buf267, buf357, 225792, grid=grid(225792), stream=stream0)
        del primals_138
        # Source Nodes: [x_171], Original ATen: [aten.convolution]
        buf358 = extern_kernels.convolution(buf357, primals_139, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf358, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf359 = buf354; del buf354  # reuse
        buf360 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf362 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_172], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf358, primals_1120, primals_1121, buf359, buf360, buf362, primals_1120, primals_1121, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1120
        del primals_1121
        buf363 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_172, x_174], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf358, buf359, buf360, primals_140, primals_141, buf363, 225792, grid=grid(225792), stream=stream0)
        del primals_141
        # Source Nodes: [x_176], Original ATen: [aten.convolution]
        buf364 = extern_kernels.convolution(buf363, primals_142, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf364, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf365 = buf360; del buf360  # reuse
        buf366 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf368 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_177], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf364, primals_1123, primals_1124, buf365, buf366, buf368, primals_1123, primals_1124, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1123
        del primals_1124
        buf369 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_19, x_177, x_178], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf364, buf365, buf366, primals_143, primals_144, buf357, buf369, 225792, grid=grid(225792), stream=stream0)
        del primals_144
        # Source Nodes: [x_180], Original ATen: [aten.convolution]
        buf370 = extern_kernels.convolution(buf369, primals_145, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf370, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf371 = buf366; del buf366  # reuse
        buf372 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf374 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_181], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf370, primals_1126, primals_1127, buf371, buf372, buf374, primals_1126, primals_1127, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1126
        del primals_1127
        buf375 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_181, x_183], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf370, buf371, buf372, primals_146, primals_147, buf375, 225792, grid=grid(225792), stream=stream0)
        del primals_147
        # Source Nodes: [x_185], Original ATen: [aten.convolution]
        buf376 = extern_kernels.convolution(buf375, primals_148, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf376, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf377 = buf372; del buf372  # reuse
        buf378 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf380 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_186], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf376, primals_1129, primals_1130, buf377, buf378, buf380, primals_1129, primals_1130, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1129
        del primals_1130
        buf381 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_20, x_186, x_187], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf376, buf377, buf378, primals_149, primals_150, buf369, buf381, 225792, grid=grid(225792), stream=stream0)
        del primals_150
        # Source Nodes: [x_189], Original ATen: [aten.convolution]
        buf382 = extern_kernels.convolution(buf381, primals_151, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf382, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf383 = buf378; del buf378  # reuse
        buf384 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf386 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_190], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf382, primals_1132, primals_1133, buf383, buf384, buf386, primals_1132, primals_1133, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1132
        del primals_1133
        buf387 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_190, x_192], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf382, buf383, buf384, primals_152, primals_153, buf387, 225792, grid=grid(225792), stream=stream0)
        del primals_153
        # Source Nodes: [x_194], Original ATen: [aten.convolution]
        buf388 = extern_kernels.convolution(buf387, primals_154, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf388, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf389 = buf384; del buf384  # reuse
        buf390 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf392 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_195], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf388, primals_1135, primals_1136, buf389, buf390, buf392, primals_1135, primals_1136, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1135
        del primals_1136
        buf393 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_195, x_196, x_197], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf388, buf389, buf390, primals_155, primals_156, buf381, buf393, 225792, grid=grid(225792), stream=stream0)
        del primals_156
        # Source Nodes: [l__mod___stage3_0_fuse_layers_0_1_0], Original ATen: [aten.convolution]
        buf442 = extern_kernels.convolution(buf393, primals_181, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf442, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf443 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf444 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf446 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_0_fuse_layers_0_1_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf442, primals_1162, primals_1163, buf443, buf444, buf446, primals_1162, primals_1163, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1162
        del primals_1163
        # Source Nodes: [x_198], Original ATen: [aten.convolution]
        buf394 = extern_kernels.convolution(buf273, primals_157, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf394, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf395 = reinterpret_tensor(buf340, (1, 72, 1, 1), (72, 1, 72, 72), 0); del buf340  # reuse
        buf396 = reinterpret_tensor(buf339, (1, 72, 1, 1), (72, 1, 72, 72), 0); del buf339  # reuse
        buf398 = reinterpret_tensor(buf338, (72, ), (1, ), 0); del buf338  # reuse
        # Source Nodes: [x_199], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf394, primals_1138, primals_1139, buf395, buf396, buf398, primals_1138, primals_1139, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1138
        del primals_1139
        buf399 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_199, x_201], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf394, buf395, buf396, primals_158, primals_159, buf399, 112896, grid=grid(112896), stream=stream0)
        del primals_159
        # Source Nodes: [x_203], Original ATen: [aten.convolution]
        buf400 = extern_kernels.convolution(buf399, primals_160, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf400, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf401 = buf396; del buf396  # reuse
        buf402 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf404 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_204], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf400, primals_1141, primals_1142, buf401, buf402, buf404, primals_1141, primals_1142, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1141
        del primals_1142
        buf405 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_22, x_204, x_205], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf400, buf401, buf402, primals_161, primals_162, buf273, buf405, 112896, grid=grid(112896), stream=stream0)
        del primals_162
        # Source Nodes: [x_207], Original ATen: [aten.convolution]
        buf406 = extern_kernels.convolution(buf405, primals_163, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf406, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf407 = buf402; del buf402  # reuse
        buf408 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf410 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_208], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf406, primals_1144, primals_1145, buf407, buf408, buf410, primals_1144, primals_1145, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1144
        del primals_1145
        buf411 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_208, x_210], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf406, buf407, buf408, primals_164, primals_165, buf411, 112896, grid=grid(112896), stream=stream0)
        del primals_165
        # Source Nodes: [x_212], Original ATen: [aten.convolution]
        buf412 = extern_kernels.convolution(buf411, primals_166, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf412, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf413 = buf408; del buf408  # reuse
        buf414 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf416 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_213], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf412, primals_1147, primals_1148, buf413, buf414, buf416, primals_1147, primals_1148, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1147
        del primals_1148
        buf417 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_23, x_213, x_214], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf412, buf413, buf414, primals_167, primals_168, buf405, buf417, 112896, grid=grid(112896), stream=stream0)
        del primals_168
        # Source Nodes: [x_216], Original ATen: [aten.convolution]
        buf418 = extern_kernels.convolution(buf417, primals_169, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf418, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf419 = buf414; del buf414  # reuse
        buf420 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf422 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_217], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf418, primals_1150, primals_1151, buf419, buf420, buf422, primals_1150, primals_1151, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1150
        del primals_1151
        buf423 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_217, x_219], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf418, buf419, buf420, primals_170, primals_171, buf423, 112896, grid=grid(112896), stream=stream0)
        del primals_171
        # Source Nodes: [x_221], Original ATen: [aten.convolution]
        buf424 = extern_kernels.convolution(buf423, primals_172, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf424, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf425 = buf420; del buf420  # reuse
        buf426 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf428 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_222], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf424, primals_1153, primals_1154, buf425, buf426, buf428, primals_1153, primals_1154, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1153
        del primals_1154
        buf429 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_24, x_222, x_223], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf424, buf425, buf426, primals_173, primals_174, buf417, buf429, 112896, grid=grid(112896), stream=stream0)
        del primals_174
        # Source Nodes: [x_225], Original ATen: [aten.convolution]
        buf430 = extern_kernels.convolution(buf429, primals_175, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf430, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf431 = buf426; del buf426  # reuse
        buf432 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf434 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_226], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf430, primals_1156, primals_1157, buf431, buf432, buf434, primals_1156, primals_1157, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1156
        del primals_1157
        buf435 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_226, x_228], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf430, buf431, buf432, primals_176, primals_177, buf435, 112896, grid=grid(112896), stream=stream0)
        del primals_177
        # Source Nodes: [x_230], Original ATen: [aten.convolution]
        buf436 = extern_kernels.convolution(buf435, primals_178, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf436, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf437 = buf432; del buf432  # reuse
        buf438 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf440 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_231], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf436, primals_1159, primals_1160, buf437, buf438, buf440, primals_1159, primals_1160, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1159
        del primals_1160
        buf441 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_231, x_232, x_233], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf436, buf437, buf438, primals_179, primals_180, buf429, buf441, 112896, grid=grid(112896), stream=stream0)
        del primals_180
        # Source Nodes: [l__mod___stage3_0_fuse_layers_0_2_0], Original ATen: [aten.convolution]
        buf447 = extern_kernels.convolution(buf441, primals_184, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf447, (8, 18, 14, 14), (3528, 196, 14, 1))
        buf448 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf449 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf451 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_0_fuse_layers_0_2_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_22.run(buf447, primals_1165, primals_1166, buf448, buf449, buf451, primals_1165, primals_1166, 18, 1568, grid=grid(18), stream=stream0)
        del primals_1165
        del primals_1166
        buf452 = empty((56, ), device='cuda', dtype=torch.int64)
        # Source Nodes: [l__mod___stage2_0_fuse_layers_0_1_2, l__mod___stage3_0_fuse_layers_0_2_2], Original ATen: [aten._to_copy, aten.add, aten.arange, aten.mul]
        triton_poi_fused__to_copy_add_arange_mul_23.run(buf452, 56, grid=grid(56), stream=stream0)
        buf345 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        buf453 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        buf454 = buf453; del buf453  # reuse
        # Source Nodes: [l__mod___stage3_0_fuse_layers_0_1_1, l__mod___stage3_0_fuse_layers_0_1_2, l__mod___stage3_0_fuse_layers_0_2_1, l__mod___stage3_0_fuse_layers_0_2_2, shortcut_25, x_159, x_160, x_161, y_5, y_6], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_24.run(buf454, buf337, buf341, buf342, primals_131, primals_132, buf327, buf260, buf442, buf443, buf444, primals_182, primals_183, buf452, buf447, buf448, buf449, primals_185, primals_186, buf345, 451584, grid=grid(451584), stream=stream0)
        del primals_132
        del primals_183
        del primals_186
        # Source Nodes: [l__mod___stage3_0_fuse_layers_1_0_0_0], Original ATen: [aten.convolution]
        buf455 = extern_kernels.convolution(buf345, primals_187, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf455, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf456 = buf390; del buf390  # reuse
        buf457 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf459 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_7], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf455, primals_1168, primals_1169, buf456, buf457, buf459, primals_1168, primals_1169, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1168
        del primals_1169
        # Source Nodes: [l__mod___stage3_0_fuse_layers_1_2_0], Original ATen: [aten.convolution]
        buf460 = extern_kernels.convolution(buf441, primals_190, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf460, (8, 36, 14, 14), (7056, 196, 14, 1))
        buf461 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf462 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf464 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_0_fuse_layers_1_2_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_25.run(buf460, primals_1171, primals_1172, buf461, buf462, buf464, primals_1171, primals_1172, 36, 1568, grid=grid(36), stream=stream0)
        del primals_1171
        del primals_1172
        buf465 = empty((28, ), device='cuda', dtype=torch.int64)
        # Source Nodes: [l__mod___stage3_0_fuse_layers_1_2_2], Original ATen: [aten._to_copy, aten.add, aten.arange, aten.mul]
        triton_poi_fused__to_copy_add_arange_mul_26.run(buf465, 28, grid=grid(28), stream=stream0)
        buf466 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        buf467 = buf466; del buf466  # reuse
        # Source Nodes: [l__mod___stage3_0_fuse_layers_1_2_1, l__mod___stage3_0_fuse_layers_1_2_2, shortcut_29, y_7, y_8, y_9], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_27.run(buf467, buf455, buf456, buf457, primals_188, primals_189, buf393, buf465, buf460, buf461, buf462, primals_191, primals_192, 225792, grid=grid(225792), stream=stream0)
        del primals_189
        del primals_192
        # Source Nodes: [l__mod___stage3_0_fuse_layers_2_0_0_0], Original ATen: [aten.convolution]
        buf468 = extern_kernels.convolution(buf345, primals_193, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf468, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf469 = buf449; del buf449  # reuse
        buf470 = buf444; del buf444  # reuse
        buf472 = reinterpret_tensor(buf342, (18, ), (1, ), 0); del buf342  # reuse
        # Source Nodes: [l__mod___stage3_0_fuse_layers_2_0_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf468, primals_1174, primals_1175, buf469, buf470, buf472, primals_1174, primals_1175, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1174
        del primals_1175
        buf473 = empty((8, 18, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_0_fuse_layers_2_0_0_1, l__mod___stage3_0_fuse_layers_2_0_0_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_28.run(buf468, buf469, buf470, primals_194, primals_195, buf473, 112896, grid=grid(112896), stream=stream0)
        del primals_195
        # Source Nodes: [l__mod___stage3_0_fuse_layers_2_0_1_0], Original ATen: [aten.convolution]
        buf474 = extern_kernels.convolution(buf473, primals_196, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf474, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf475 = buf438; del buf438  # reuse
        buf476 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf478 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_10], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf474, primals_1177, primals_1178, buf475, buf476, buf478, primals_1177, primals_1178, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1177
        del primals_1178
        # Source Nodes: [l__mod___stage3_0_fuse_layers_2_1_0_0], Original ATen: [aten.convolution]
        buf479 = extern_kernels.convolution(buf393, primals_199, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf479, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf480 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf481 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf483 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_0_fuse_layers_2_1_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf479, primals_1180, primals_1181, buf480, buf481, buf483, primals_1180, primals_1181, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1180
        del primals_1181
        buf484 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        buf485 = buf484; del buf484  # reuse
        # Source Nodes: [l__mod___stage3_0_fuse_layers_2_1_0_1, shortcut_33, y_10, y_11, y_12], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_29.run(buf485, buf474, buf475, buf476, primals_197, primals_198, buf479, buf480, buf481, primals_200, primals_201, buf441, 112896, grid=grid(112896), stream=stream0)
        del primals_198
        del primals_201
        # Source Nodes: [x_234], Original ATen: [aten.convolution]
        buf486 = extern_kernels.convolution(buf454, primals_202, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf486, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf487 = reinterpret_tensor(buf481, (1, 18, 1, 1, 4), (72, 1, 72, 72, 18), 0); del buf481  # reuse
        buf488 = reinterpret_tensor(buf476, (1, 18, 1, 1, 4), (72, 1, 72, 72, 18), 0); del buf476  # reuse
        buf489 = empty_strided((1, 18, 1, 1, 4), (72, 1, 72, 72, 18), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_235], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf486, buf487, buf488, buf489, 72, 6272, grid=grid(72), stream=stream0)
        buf490 = buf470; del buf470  # reuse
        buf491 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf493 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_235], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf487, buf488, buf489, primals_1183, primals_1184, buf490, buf491, buf493, primals_1183, primals_1184, 18, 4, grid=grid(18), stream=stream0)
        del primals_1183
        del primals_1184
        buf494 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_235, x_237], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf486, buf490, buf491, primals_203, primals_204, buf494, 451584, grid=grid(451584), stream=stream0)
        del primals_204
        # Source Nodes: [x_239], Original ATen: [aten.convolution]
        buf495 = extern_kernels.convolution(buf494, primals_205, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf495, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf496 = buf489; del buf489  # reuse
        buf497 = buf488; del buf488  # reuse
        buf498 = buf487; del buf487  # reuse
        # Source Nodes: [x_240], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf495, buf496, buf497, buf498, 72, 6272, grid=grid(72), stream=stream0)
        buf499 = buf491; del buf491  # reuse
        buf500 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf502 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_240], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf496, buf497, buf498, primals_1186, primals_1187, buf499, buf500, buf502, primals_1186, primals_1187, 18, 4, grid=grid(18), stream=stream0)
        del primals_1186
        del primals_1187
        buf503 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_26, x_240, x_241], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf495, buf499, buf500, primals_206, primals_207, buf454, buf503, 451584, grid=grid(451584), stream=stream0)
        del primals_207
        # Source Nodes: [x_243], Original ATen: [aten.convolution]
        buf504 = extern_kernels.convolution(buf503, primals_208, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf504, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf505 = buf498; del buf498  # reuse
        buf506 = buf497; del buf497  # reuse
        buf507 = buf496; del buf496  # reuse
        # Source Nodes: [x_244], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf504, buf505, buf506, buf507, 72, 6272, grid=grid(72), stream=stream0)
        buf508 = buf500; del buf500  # reuse
        buf509 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf511 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_244], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf505, buf506, buf507, primals_1189, primals_1190, buf508, buf509, buf511, primals_1189, primals_1190, 18, 4, grid=grid(18), stream=stream0)
        del primals_1189
        del primals_1190
        buf512 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_244, x_246], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf504, buf508, buf509, primals_209, primals_210, buf512, 451584, grid=grid(451584), stream=stream0)
        del primals_210
        # Source Nodes: [x_248], Original ATen: [aten.convolution]
        buf513 = extern_kernels.convolution(buf512, primals_211, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf513, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf514 = buf507; del buf507  # reuse
        buf515 = buf506; del buf506  # reuse
        buf516 = buf505; del buf505  # reuse
        # Source Nodes: [x_249], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf513, buf514, buf515, buf516, 72, 6272, grid=grid(72), stream=stream0)
        buf517 = buf509; del buf509  # reuse
        buf518 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf520 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_249], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf514, buf515, buf516, primals_1192, primals_1193, buf517, buf518, buf520, primals_1192, primals_1193, 18, 4, grid=grid(18), stream=stream0)
        del primals_1192
        del primals_1193
        buf521 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_27, x_249, x_250], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf513, buf517, buf518, primals_212, primals_213, buf503, buf521, 451584, grid=grid(451584), stream=stream0)
        del primals_213
        # Source Nodes: [x_252], Original ATen: [aten.convolution]
        buf522 = extern_kernels.convolution(buf521, primals_214, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf522, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf523 = buf516; del buf516  # reuse
        buf524 = buf515; del buf515  # reuse
        buf525 = buf514; del buf514  # reuse
        # Source Nodes: [x_253], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf522, buf523, buf524, buf525, 72, 6272, grid=grid(72), stream=stream0)
        buf526 = buf518; del buf518  # reuse
        buf527 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf529 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_253], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf523, buf524, buf525, primals_1195, primals_1196, buf526, buf527, buf529, primals_1195, primals_1196, 18, 4, grid=grid(18), stream=stream0)
        del primals_1195
        del primals_1196
        buf530 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_253, x_255], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf522, buf526, buf527, primals_215, primals_216, buf530, 451584, grid=grid(451584), stream=stream0)
        del primals_216
        # Source Nodes: [x_257], Original ATen: [aten.convolution]
        buf531 = extern_kernels.convolution(buf530, primals_217, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf531, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf532 = buf525; del buf525  # reuse
        buf533 = buf524; del buf524  # reuse
        buf534 = buf523; del buf523  # reuse
        # Source Nodes: [x_258], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf531, buf532, buf533, buf534, 72, 6272, grid=grid(72), stream=stream0)
        buf535 = buf527; del buf527  # reuse
        buf536 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf538 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_258], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf532, buf533, buf534, primals_1198, primals_1199, buf535, buf536, buf538, primals_1198, primals_1199, 18, 4, grid=grid(18), stream=stream0)
        del primals_1198
        del primals_1199
        buf539 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_28, x_258, x_259], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf531, buf535, buf536, primals_218, primals_219, buf521, buf539, 451584, grid=grid(451584), stream=stream0)
        del primals_219
        # Source Nodes: [x_261], Original ATen: [aten.convolution]
        buf540 = extern_kernels.convolution(buf539, primals_220, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf540, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf541 = buf534; del buf534  # reuse
        buf542 = buf533; del buf533  # reuse
        buf543 = buf532; del buf532  # reuse
        # Source Nodes: [x_262], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf540, buf541, buf542, buf543, 72, 6272, grid=grid(72), stream=stream0)
        buf544 = buf536; del buf536  # reuse
        buf545 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf547 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_262], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf541, buf542, buf543, primals_1201, primals_1202, buf544, buf545, buf547, primals_1201, primals_1202, 18, 4, grid=grid(18), stream=stream0)
        del primals_1201
        del primals_1202
        buf548 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_262, x_264], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf540, buf544, buf545, primals_221, primals_222, buf548, 451584, grid=grid(451584), stream=stream0)
        del primals_222
        # Source Nodes: [x_266], Original ATen: [aten.convolution]
        buf549 = extern_kernels.convolution(buf548, primals_223, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf549, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf550 = buf543; del buf543  # reuse
        buf551 = buf542; del buf542  # reuse
        buf552 = buf541; del buf541  # reuse
        # Source Nodes: [x_267], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf549, buf550, buf551, buf552, 72, 6272, grid=grid(72), stream=stream0)
        buf553 = buf545; del buf545  # reuse
        buf554 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf556 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_267], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf550, buf551, buf552, primals_1204, primals_1205, buf553, buf554, buf556, primals_1204, primals_1205, 18, 4, grid=grid(18), stream=stream0)
        del primals_1204
        del primals_1205
        # Source Nodes: [x_270], Original ATen: [aten.convolution]
        buf558 = extern_kernels.convolution(buf467, primals_226, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf558, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf559 = buf462; del buf462  # reuse
        buf560 = buf457; del buf457  # reuse
        buf562 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_271], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf558, primals_1207, primals_1208, buf559, buf560, buf562, primals_1207, primals_1208, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1207
        del primals_1208
        buf563 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_271, x_273], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf558, buf559, buf560, primals_227, primals_228, buf563, 225792, grid=grid(225792), stream=stream0)
        del primals_228
        # Source Nodes: [x_275], Original ATen: [aten.convolution]
        buf564 = extern_kernels.convolution(buf563, primals_229, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf564, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf565 = buf560; del buf560  # reuse
        buf566 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf568 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_276], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf564, primals_1210, primals_1211, buf565, buf566, buf568, primals_1210, primals_1211, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1210
        del primals_1211
        buf569 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_30, x_276, x_277], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf564, buf565, buf566, primals_230, primals_231, buf467, buf569, 225792, grid=grid(225792), stream=stream0)
        del primals_231
        # Source Nodes: [x_279], Original ATen: [aten.convolution]
        buf570 = extern_kernels.convolution(buf569, primals_232, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf570, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf571 = buf566; del buf566  # reuse
        buf572 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf574 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_280], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf570, primals_1213, primals_1214, buf571, buf572, buf574, primals_1213, primals_1214, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1213
        del primals_1214
        buf575 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_280, x_282], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf570, buf571, buf572, primals_233, primals_234, buf575, 225792, grid=grid(225792), stream=stream0)
        del primals_234
        # Source Nodes: [x_284], Original ATen: [aten.convolution]
        buf576 = extern_kernels.convolution(buf575, primals_235, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf576, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf577 = buf572; del buf572  # reuse
        buf578 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf580 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_285], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf576, primals_1216, primals_1217, buf577, buf578, buf580, primals_1216, primals_1217, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1216
        del primals_1217
        buf581 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_31, x_285, x_286], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf576, buf577, buf578, primals_236, primals_237, buf569, buf581, 225792, grid=grid(225792), stream=stream0)
        del primals_237
        # Source Nodes: [x_288], Original ATen: [aten.convolution]
        buf582 = extern_kernels.convolution(buf581, primals_238, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf582, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf583 = buf578; del buf578  # reuse
        buf584 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf586 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_289], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf582, primals_1219, primals_1220, buf583, buf584, buf586, primals_1219, primals_1220, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1219
        del primals_1220
        buf587 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_289, x_291], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf582, buf583, buf584, primals_239, primals_240, buf587, 225792, grid=grid(225792), stream=stream0)
        del primals_240
        # Source Nodes: [x_293], Original ATen: [aten.convolution]
        buf588 = extern_kernels.convolution(buf587, primals_241, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf588, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf589 = buf584; del buf584  # reuse
        buf590 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf592 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_294], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf588, primals_1222, primals_1223, buf589, buf590, buf592, primals_1222, primals_1223, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1222
        del primals_1223
        buf593 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_32, x_294, x_295], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf588, buf589, buf590, primals_242, primals_243, buf581, buf593, 225792, grid=grid(225792), stream=stream0)
        del primals_243
        # Source Nodes: [x_297], Original ATen: [aten.convolution]
        buf594 = extern_kernels.convolution(buf593, primals_244, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf594, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf595 = buf590; del buf590  # reuse
        buf596 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf598 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_298], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf594, primals_1225, primals_1226, buf595, buf596, buf598, primals_1225, primals_1226, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1225
        del primals_1226
        buf599 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_298, x_300], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf594, buf595, buf596, primals_245, primals_246, buf599, 225792, grid=grid(225792), stream=stream0)
        del primals_246
        # Source Nodes: [x_302], Original ATen: [aten.convolution]
        buf600 = extern_kernels.convolution(buf599, primals_247, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf600, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf601 = buf596; del buf596  # reuse
        buf602 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf604 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_303], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf600, primals_1228, primals_1229, buf601, buf602, buf604, primals_1228, primals_1229, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1228
        del primals_1229
        buf605 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_303, x_304, x_305], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf600, buf601, buf602, primals_248, primals_249, buf593, buf605, 225792, grid=grid(225792), stream=stream0)
        del primals_249
        # Source Nodes: [l__mod___stage3_1_fuse_layers_0_1_0], Original ATen: [aten.convolution]
        buf654 = extern_kernels.convolution(buf605, primals_274, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf654, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf655 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf656 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf658 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_1_fuse_layers_0_1_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf654, primals_1255, primals_1256, buf655, buf656, buf658, primals_1255, primals_1256, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1255
        del primals_1256
        # Source Nodes: [x_306], Original ATen: [aten.convolution]
        buf606 = extern_kernels.convolution(buf485, primals_250, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf606, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf607 = reinterpret_tensor(buf552, (1, 72, 1, 1), (72, 1, 72, 72), 0); del buf552  # reuse
        buf608 = reinterpret_tensor(buf551, (1, 72, 1, 1), (72, 1, 72, 72), 0); del buf551  # reuse
        buf610 = reinterpret_tensor(buf550, (72, ), (1, ), 0); del buf550  # reuse
        # Source Nodes: [x_307], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf606, primals_1231, primals_1232, buf607, buf608, buf610, primals_1231, primals_1232, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1231
        del primals_1232
        buf611 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_307, x_309], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf606, buf607, buf608, primals_251, primals_252, buf611, 112896, grid=grid(112896), stream=stream0)
        del primals_252
        # Source Nodes: [x_311], Original ATen: [aten.convolution]
        buf612 = extern_kernels.convolution(buf611, primals_253, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf612, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf613 = buf608; del buf608  # reuse
        buf614 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf616 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_312], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf612, primals_1234, primals_1235, buf613, buf614, buf616, primals_1234, primals_1235, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1234
        del primals_1235
        buf617 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_34, x_312, x_313], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf612, buf613, buf614, primals_254, primals_255, buf485, buf617, 112896, grid=grid(112896), stream=stream0)
        del primals_255
        # Source Nodes: [x_315], Original ATen: [aten.convolution]
        buf618 = extern_kernels.convolution(buf617, primals_256, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf618, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf619 = buf614; del buf614  # reuse
        buf620 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf622 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_316], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf618, primals_1237, primals_1238, buf619, buf620, buf622, primals_1237, primals_1238, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1237
        del primals_1238
        buf623 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_316, x_318], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf618, buf619, buf620, primals_257, primals_258, buf623, 112896, grid=grid(112896), stream=stream0)
        del primals_258
        # Source Nodes: [x_320], Original ATen: [aten.convolution]
        buf624 = extern_kernels.convolution(buf623, primals_259, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf624, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf625 = buf620; del buf620  # reuse
        buf626 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf628 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_321], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf624, primals_1240, primals_1241, buf625, buf626, buf628, primals_1240, primals_1241, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1240
        del primals_1241
        buf629 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_35, x_321, x_322], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf624, buf625, buf626, primals_260, primals_261, buf617, buf629, 112896, grid=grid(112896), stream=stream0)
        del primals_261
        # Source Nodes: [x_324], Original ATen: [aten.convolution]
        buf630 = extern_kernels.convolution(buf629, primals_262, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf630, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf631 = buf626; del buf626  # reuse
        buf632 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf634 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_325], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf630, primals_1243, primals_1244, buf631, buf632, buf634, primals_1243, primals_1244, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1243
        del primals_1244
        buf635 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_325, x_327], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf630, buf631, buf632, primals_263, primals_264, buf635, 112896, grid=grid(112896), stream=stream0)
        del primals_264
        # Source Nodes: [x_329], Original ATen: [aten.convolution]
        buf636 = extern_kernels.convolution(buf635, primals_265, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf636, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf637 = buf632; del buf632  # reuse
        buf638 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf640 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_330], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf636, primals_1246, primals_1247, buf637, buf638, buf640, primals_1246, primals_1247, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1246
        del primals_1247
        buf641 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_36, x_330, x_331], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf636, buf637, buf638, primals_266, primals_267, buf629, buf641, 112896, grid=grid(112896), stream=stream0)
        del primals_267
        # Source Nodes: [x_333], Original ATen: [aten.convolution]
        buf642 = extern_kernels.convolution(buf641, primals_268, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf642, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf643 = buf638; del buf638  # reuse
        buf644 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf646 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_334], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf642, primals_1249, primals_1250, buf643, buf644, buf646, primals_1249, primals_1250, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1249
        del primals_1250
        buf647 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_334, x_336], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf642, buf643, buf644, primals_269, primals_270, buf647, 112896, grid=grid(112896), stream=stream0)
        del primals_270
        # Source Nodes: [x_338], Original ATen: [aten.convolution]
        buf648 = extern_kernels.convolution(buf647, primals_271, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf648, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf649 = buf644; del buf644  # reuse
        buf650 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf652 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_339], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf648, primals_1252, primals_1253, buf649, buf650, buf652, primals_1252, primals_1253, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1252
        del primals_1253
        buf653 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_339, x_340, x_341], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf648, buf649, buf650, primals_272, primals_273, buf641, buf653, 112896, grid=grid(112896), stream=stream0)
        del primals_273
        # Source Nodes: [l__mod___stage3_1_fuse_layers_0_2_0], Original ATen: [aten.convolution]
        buf659 = extern_kernels.convolution(buf653, primals_277, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf659, (8, 18, 14, 14), (3528, 196, 14, 1))
        buf660 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf661 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf663 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_1_fuse_layers_0_2_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_22.run(buf659, primals_1258, primals_1259, buf660, buf661, buf663, primals_1258, primals_1259, 18, 1568, grid=grid(18), stream=stream0)
        del primals_1258
        del primals_1259
        buf557 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        buf664 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        buf665 = buf664; del buf664  # reuse
        # Source Nodes: [l__mod___stage3_1_fuse_layers_0_1_1, l__mod___stage3_1_fuse_layers_0_1_2, l__mod___stage3_1_fuse_layers_0_2_1, l__mod___stage3_1_fuse_layers_0_2_2, shortcut_37, x_267, x_268, x_269, y_14, y_15], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_24.run(buf665, buf549, buf553, buf554, primals_224, primals_225, buf539, buf260, buf654, buf655, buf656, primals_275, primals_276, buf452, buf659, buf660, buf661, primals_278, primals_279, buf557, 451584, grid=grid(451584), stream=stream0)
        del primals_225
        del primals_276
        del primals_279
        # Source Nodes: [l__mod___stage3_1_fuse_layers_1_0_0_0], Original ATen: [aten.convolution]
        buf666 = extern_kernels.convolution(buf557, primals_280, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf666, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf667 = buf602; del buf602  # reuse
        buf668 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf670 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_16], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf666, primals_1261, primals_1262, buf667, buf668, buf670, primals_1261, primals_1262, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1261
        del primals_1262
        # Source Nodes: [l__mod___stage3_1_fuse_layers_1_2_0], Original ATen: [aten.convolution]
        buf671 = extern_kernels.convolution(buf653, primals_283, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf671, (8, 36, 14, 14), (7056, 196, 14, 1))
        buf672 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf673 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf675 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_1_fuse_layers_1_2_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_25.run(buf671, primals_1264, primals_1265, buf672, buf673, buf675, primals_1264, primals_1265, 36, 1568, grid=grid(36), stream=stream0)
        del primals_1264
        del primals_1265
        buf676 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        buf677 = buf676; del buf676  # reuse
        # Source Nodes: [l__mod___stage3_1_fuse_layers_1_2_1, l__mod___stage3_1_fuse_layers_1_2_2, shortcut_41, y_16, y_17, y_18], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_27.run(buf677, buf666, buf667, buf668, primals_281, primals_282, buf605, buf465, buf671, buf672, buf673, primals_284, primals_285, 225792, grid=grid(225792), stream=stream0)
        del primals_282
        del primals_285
        # Source Nodes: [l__mod___stage3_1_fuse_layers_2_0_0_0], Original ATen: [aten.convolution]
        buf678 = extern_kernels.convolution(buf557, primals_286, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf678, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf679 = buf661; del buf661  # reuse
        buf680 = buf656; del buf656  # reuse
        buf682 = reinterpret_tensor(buf554, (18, ), (1, ), 0); del buf554  # reuse
        # Source Nodes: [l__mod___stage3_1_fuse_layers_2_0_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf678, primals_1267, primals_1268, buf679, buf680, buf682, primals_1267, primals_1268, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1267
        del primals_1268
        buf683 = empty((8, 18, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_1_fuse_layers_2_0_0_1, l__mod___stage3_1_fuse_layers_2_0_0_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_28.run(buf678, buf679, buf680, primals_287, primals_288, buf683, 112896, grid=grid(112896), stream=stream0)
        del primals_288
        # Source Nodes: [l__mod___stage3_1_fuse_layers_2_0_1_0], Original ATen: [aten.convolution]
        buf684 = extern_kernels.convolution(buf683, primals_289, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf684, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf685 = buf650; del buf650  # reuse
        buf686 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf688 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_19], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf684, primals_1270, primals_1271, buf685, buf686, buf688, primals_1270, primals_1271, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1270
        del primals_1271
        # Source Nodes: [l__mod___stage3_1_fuse_layers_2_1_0_0], Original ATen: [aten.convolution]
        buf689 = extern_kernels.convolution(buf605, primals_292, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf689, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf690 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf691 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf693 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_1_fuse_layers_2_1_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf689, primals_1273, primals_1274, buf690, buf691, buf693, primals_1273, primals_1274, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1273
        del primals_1274
        buf694 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        buf695 = buf694; del buf694  # reuse
        # Source Nodes: [l__mod___stage3_1_fuse_layers_2_1_0_1, shortcut_45, y_19, y_20, y_21], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_29.run(buf695, buf684, buf685, buf686, primals_290, primals_291, buf689, buf690, buf691, primals_293, primals_294, buf653, 112896, grid=grid(112896), stream=stream0)
        del primals_291
        del primals_294
        # Source Nodes: [x_342], Original ATen: [aten.convolution]
        buf696 = extern_kernels.convolution(buf665, primals_295, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf696, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf697 = reinterpret_tensor(buf691, (1, 18, 1, 1, 4), (72, 1, 72, 72, 18), 0); del buf691  # reuse
        buf698 = reinterpret_tensor(buf686, (1, 18, 1, 1, 4), (72, 1, 72, 72, 18), 0); del buf686  # reuse
        buf699 = empty_strided((1, 18, 1, 1, 4), (72, 1, 72, 72, 18), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_343], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf696, buf697, buf698, buf699, 72, 6272, grid=grid(72), stream=stream0)
        buf700 = buf680; del buf680  # reuse
        buf701 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf703 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_343], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf697, buf698, buf699, primals_1276, primals_1277, buf700, buf701, buf703, primals_1276, primals_1277, 18, 4, grid=grid(18), stream=stream0)
        del primals_1276
        del primals_1277
        buf704 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_343, x_345], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf696, buf700, buf701, primals_296, primals_297, buf704, 451584, grid=grid(451584), stream=stream0)
        del primals_297
        # Source Nodes: [x_347], Original ATen: [aten.convolution]
        buf705 = extern_kernels.convolution(buf704, primals_298, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf705, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf706 = buf699; del buf699  # reuse
        buf707 = buf698; del buf698  # reuse
        buf708 = buf697; del buf697  # reuse
        # Source Nodes: [x_348], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf705, buf706, buf707, buf708, 72, 6272, grid=grid(72), stream=stream0)
        buf709 = buf701; del buf701  # reuse
        buf710 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf712 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_348], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf706, buf707, buf708, primals_1279, primals_1280, buf709, buf710, buf712, primals_1279, primals_1280, 18, 4, grid=grid(18), stream=stream0)
        del primals_1279
        del primals_1280
        buf713 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_38, x_348, x_349], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf705, buf709, buf710, primals_299, primals_300, buf665, buf713, 451584, grid=grid(451584), stream=stream0)
        del primals_300
        # Source Nodes: [x_351], Original ATen: [aten.convolution]
        buf714 = extern_kernels.convolution(buf713, primals_301, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf714, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf715 = buf708; del buf708  # reuse
        buf716 = buf707; del buf707  # reuse
        buf717 = buf706; del buf706  # reuse
        # Source Nodes: [x_352], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf714, buf715, buf716, buf717, 72, 6272, grid=grid(72), stream=stream0)
        buf718 = buf710; del buf710  # reuse
        buf719 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf721 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_352], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf715, buf716, buf717, primals_1282, primals_1283, buf718, buf719, buf721, primals_1282, primals_1283, 18, 4, grid=grid(18), stream=stream0)
        del primals_1282
        del primals_1283
        buf722 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_352, x_354], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf714, buf718, buf719, primals_302, primals_303, buf722, 451584, grid=grid(451584), stream=stream0)
        del primals_303
        # Source Nodes: [x_356], Original ATen: [aten.convolution]
        buf723 = extern_kernels.convolution(buf722, primals_304, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf723, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf724 = buf717; del buf717  # reuse
        buf725 = buf716; del buf716  # reuse
        buf726 = buf715; del buf715  # reuse
        # Source Nodes: [x_357], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf723, buf724, buf725, buf726, 72, 6272, grid=grid(72), stream=stream0)
        buf727 = buf719; del buf719  # reuse
        buf728 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf730 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_357], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf724, buf725, buf726, primals_1285, primals_1286, buf727, buf728, buf730, primals_1285, primals_1286, 18, 4, grid=grid(18), stream=stream0)
        del primals_1285
        del primals_1286
        buf731 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_39, x_357, x_358], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf723, buf727, buf728, primals_305, primals_306, buf713, buf731, 451584, grid=grid(451584), stream=stream0)
        del primals_306
        # Source Nodes: [x_360], Original ATen: [aten.convolution]
        buf732 = extern_kernels.convolution(buf731, primals_307, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf732, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf733 = buf726; del buf726  # reuse
        buf734 = buf725; del buf725  # reuse
        buf735 = buf724; del buf724  # reuse
        # Source Nodes: [x_361], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf732, buf733, buf734, buf735, 72, 6272, grid=grid(72), stream=stream0)
        buf736 = buf728; del buf728  # reuse
        buf737 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf739 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_361], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf733, buf734, buf735, primals_1288, primals_1289, buf736, buf737, buf739, primals_1288, primals_1289, 18, 4, grid=grid(18), stream=stream0)
        del primals_1288
        del primals_1289
        buf740 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_361, x_363], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf732, buf736, buf737, primals_308, primals_309, buf740, 451584, grid=grid(451584), stream=stream0)
        del primals_309
        # Source Nodes: [x_365], Original ATen: [aten.convolution]
        buf741 = extern_kernels.convolution(buf740, primals_310, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf741, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf742 = buf735; del buf735  # reuse
        buf743 = buf734; del buf734  # reuse
        buf744 = buf733; del buf733  # reuse
        # Source Nodes: [x_366], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf741, buf742, buf743, buf744, 72, 6272, grid=grid(72), stream=stream0)
        buf745 = buf737; del buf737  # reuse
        buf746 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf748 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_366], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf742, buf743, buf744, primals_1291, primals_1292, buf745, buf746, buf748, primals_1291, primals_1292, 18, 4, grid=grid(18), stream=stream0)
        del primals_1291
        del primals_1292
        buf749 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_40, x_366, x_367], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf741, buf745, buf746, primals_311, primals_312, buf731, buf749, 451584, grid=grid(451584), stream=stream0)
        del primals_312
        # Source Nodes: [x_369], Original ATen: [aten.convolution]
        buf750 = extern_kernels.convolution(buf749, primals_313, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf750, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf751 = buf744; del buf744  # reuse
        buf752 = buf743; del buf743  # reuse
        buf753 = buf742; del buf742  # reuse
        # Source Nodes: [x_370], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf750, buf751, buf752, buf753, 72, 6272, grid=grid(72), stream=stream0)
        buf754 = buf746; del buf746  # reuse
        buf755 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf757 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_370], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf751, buf752, buf753, primals_1294, primals_1295, buf754, buf755, buf757, primals_1294, primals_1295, 18, 4, grid=grid(18), stream=stream0)
        del primals_1294
        del primals_1295
        buf758 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_370, x_372], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf750, buf754, buf755, primals_314, primals_315, buf758, 451584, grid=grid(451584), stream=stream0)
        del primals_315
        # Source Nodes: [x_374], Original ATen: [aten.convolution]
        buf759 = extern_kernels.convolution(buf758, primals_316, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf759, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf760 = buf753; del buf753  # reuse
        buf761 = buf752; del buf752  # reuse
        buf762 = buf751; del buf751  # reuse
        # Source Nodes: [x_375], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf759, buf760, buf761, buf762, 72, 6272, grid=grid(72), stream=stream0)
        buf763 = buf755; del buf755  # reuse
        buf764 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf766 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_375], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf760, buf761, buf762, primals_1297, primals_1298, buf763, buf764, buf766, primals_1297, primals_1298, 18, 4, grid=grid(18), stream=stream0)
        del primals_1297
        del primals_1298
        # Source Nodes: [x_378], Original ATen: [aten.convolution]
        buf768 = extern_kernels.convolution(buf677, primals_319, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf768, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf769 = buf673; del buf673  # reuse
        buf770 = buf668; del buf668  # reuse
        buf772 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_379], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf768, primals_1300, primals_1301, buf769, buf770, buf772, primals_1300, primals_1301, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1300
        del primals_1301
        buf773 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_379, x_381], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf768, buf769, buf770, primals_320, primals_321, buf773, 225792, grid=grid(225792), stream=stream0)
        del primals_321
        # Source Nodes: [x_383], Original ATen: [aten.convolution]
        buf774 = extern_kernels.convolution(buf773, primals_322, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf774, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf775 = buf770; del buf770  # reuse
        buf776 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf778 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_384], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf774, primals_1303, primals_1304, buf775, buf776, buf778, primals_1303, primals_1304, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1303
        del primals_1304
        buf779 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_42, x_384, x_385], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf774, buf775, buf776, primals_323, primals_324, buf677, buf779, 225792, grid=grid(225792), stream=stream0)
        del primals_324
        # Source Nodes: [x_387], Original ATen: [aten.convolution]
        buf780 = extern_kernels.convolution(buf779, primals_325, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf780, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf781 = buf776; del buf776  # reuse
        buf782 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf784 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_388], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf780, primals_1306, primals_1307, buf781, buf782, buf784, primals_1306, primals_1307, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1306
        del primals_1307
        buf785 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_388, x_390], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf780, buf781, buf782, primals_326, primals_327, buf785, 225792, grid=grid(225792), stream=stream0)
        del primals_327
        # Source Nodes: [x_392], Original ATen: [aten.convolution]
        buf786 = extern_kernels.convolution(buf785, primals_328, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf786, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf787 = buf782; del buf782  # reuse
        buf788 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf790 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_393], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf786, primals_1309, primals_1310, buf787, buf788, buf790, primals_1309, primals_1310, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1309
        del primals_1310
        buf791 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_43, x_393, x_394], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf786, buf787, buf788, primals_329, primals_330, buf779, buf791, 225792, grid=grid(225792), stream=stream0)
        del primals_330
        # Source Nodes: [x_396], Original ATen: [aten.convolution]
        buf792 = extern_kernels.convolution(buf791, primals_331, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf792, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf793 = buf788; del buf788  # reuse
        buf794 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf796 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_397], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf792, primals_1312, primals_1313, buf793, buf794, buf796, primals_1312, primals_1313, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1312
        del primals_1313
        buf797 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_397, x_399], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf792, buf793, buf794, primals_332, primals_333, buf797, 225792, grid=grid(225792), stream=stream0)
        del primals_333
        # Source Nodes: [x_401], Original ATen: [aten.convolution]
        buf798 = extern_kernels.convolution(buf797, primals_334, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf798, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf799 = buf794; del buf794  # reuse
        buf800 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf802 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_402], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf798, primals_1315, primals_1316, buf799, buf800, buf802, primals_1315, primals_1316, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1315
        del primals_1316
        buf803 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_44, x_402, x_403], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf798, buf799, buf800, primals_335, primals_336, buf791, buf803, 225792, grid=grid(225792), stream=stream0)
        del primals_336
        # Source Nodes: [x_405], Original ATen: [aten.convolution]
        buf804 = extern_kernels.convolution(buf803, primals_337, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf804, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf805 = buf800; del buf800  # reuse
        buf806 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf808 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_406], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf804, primals_1318, primals_1319, buf805, buf806, buf808, primals_1318, primals_1319, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1318
        del primals_1319
        buf809 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_406, x_408], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf804, buf805, buf806, primals_338, primals_339, buf809, 225792, grid=grid(225792), stream=stream0)
        del primals_339
        # Source Nodes: [x_410], Original ATen: [aten.convolution]
        buf810 = extern_kernels.convolution(buf809, primals_340, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf810, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf811 = buf806; del buf806  # reuse
        buf812 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf814 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_411], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf810, primals_1321, primals_1322, buf811, buf812, buf814, primals_1321, primals_1322, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1321
        del primals_1322
        buf815 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_411, x_412, x_413], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf810, buf811, buf812, primals_341, primals_342, buf803, buf815, 225792, grid=grid(225792), stream=stream0)
        del primals_342
        # Source Nodes: [l__mod___stage3_2_fuse_layers_0_1_0], Original ATen: [aten.convolution]
        buf864 = extern_kernels.convolution(buf815, primals_367, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf864, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf865 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf866 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf868 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_2_fuse_layers_0_1_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf864, primals_1348, primals_1349, buf865, buf866, buf868, primals_1348, primals_1349, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1348
        del primals_1349
        # Source Nodes: [x_414], Original ATen: [aten.convolution]
        buf816 = extern_kernels.convolution(buf695, primals_343, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf816, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf817 = reinterpret_tensor(buf762, (1, 72, 1, 1), (72, 1, 72, 72), 0); del buf762  # reuse
        buf818 = reinterpret_tensor(buf761, (1, 72, 1, 1), (72, 1, 72, 72), 0); del buf761  # reuse
        buf820 = reinterpret_tensor(buf760, (72, ), (1, ), 0); del buf760  # reuse
        # Source Nodes: [x_415], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf816, primals_1324, primals_1325, buf817, buf818, buf820, primals_1324, primals_1325, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1324
        del primals_1325
        buf821 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_415, x_417], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf816, buf817, buf818, primals_344, primals_345, buf821, 112896, grid=grid(112896), stream=stream0)
        del primals_345
        # Source Nodes: [x_419], Original ATen: [aten.convolution]
        buf822 = extern_kernels.convolution(buf821, primals_346, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf822, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf823 = buf818; del buf818  # reuse
        buf824 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf826 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_420], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf822, primals_1327, primals_1328, buf823, buf824, buf826, primals_1327, primals_1328, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1327
        del primals_1328
        buf827 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_46, x_420, x_421], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf822, buf823, buf824, primals_347, primals_348, buf695, buf827, 112896, grid=grid(112896), stream=stream0)
        del primals_348
        # Source Nodes: [x_423], Original ATen: [aten.convolution]
        buf828 = extern_kernels.convolution(buf827, primals_349, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf828, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf829 = buf824; del buf824  # reuse
        buf830 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf832 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_424], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf828, primals_1330, primals_1331, buf829, buf830, buf832, primals_1330, primals_1331, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1330
        del primals_1331
        buf833 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_424, x_426], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf828, buf829, buf830, primals_350, primals_351, buf833, 112896, grid=grid(112896), stream=stream0)
        del primals_351
        # Source Nodes: [x_428], Original ATen: [aten.convolution]
        buf834 = extern_kernels.convolution(buf833, primals_352, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf834, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf835 = buf830; del buf830  # reuse
        buf836 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf838 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_429], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf834, primals_1333, primals_1334, buf835, buf836, buf838, primals_1333, primals_1334, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1333
        del primals_1334
        buf839 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_47, x_429, x_430], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf834, buf835, buf836, primals_353, primals_354, buf827, buf839, 112896, grid=grid(112896), stream=stream0)
        del primals_354
        # Source Nodes: [x_432], Original ATen: [aten.convolution]
        buf840 = extern_kernels.convolution(buf839, primals_355, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf840, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf841 = buf836; del buf836  # reuse
        buf842 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf844 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_433], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf840, primals_1336, primals_1337, buf841, buf842, buf844, primals_1336, primals_1337, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1336
        del primals_1337
        buf845 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_433, x_435], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf840, buf841, buf842, primals_356, primals_357, buf845, 112896, grid=grid(112896), stream=stream0)
        del primals_357
        # Source Nodes: [x_437], Original ATen: [aten.convolution]
        buf846 = extern_kernels.convolution(buf845, primals_358, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf846, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf847 = buf842; del buf842  # reuse
        buf848 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf850 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_438], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf846, primals_1339, primals_1340, buf847, buf848, buf850, primals_1339, primals_1340, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1339
        del primals_1340
        buf851 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_48, x_438, x_439], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf846, buf847, buf848, primals_359, primals_360, buf839, buf851, 112896, grid=grid(112896), stream=stream0)
        del primals_360
        # Source Nodes: [x_441], Original ATen: [aten.convolution]
        buf852 = extern_kernels.convolution(buf851, primals_361, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf852, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf853 = buf848; del buf848  # reuse
        buf854 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf856 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_442], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf852, primals_1342, primals_1343, buf853, buf854, buf856, primals_1342, primals_1343, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1342
        del primals_1343
        buf857 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_442, x_444], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf852, buf853, buf854, primals_362, primals_363, buf857, 112896, grid=grid(112896), stream=stream0)
        del primals_363
        # Source Nodes: [x_446], Original ATen: [aten.convolution]
        buf858 = extern_kernels.convolution(buf857, primals_364, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf858, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf859 = buf854; del buf854  # reuse
        buf860 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf862 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_447], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf858, primals_1345, primals_1346, buf859, buf860, buf862, primals_1345, primals_1346, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1345
        del primals_1346
        buf863 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_447, x_448, x_449], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf858, buf859, buf860, primals_365, primals_366, buf851, buf863, 112896, grid=grid(112896), stream=stream0)
        del primals_366
        # Source Nodes: [l__mod___stage3_2_fuse_layers_0_2_0], Original ATen: [aten.convolution]
        buf869 = extern_kernels.convolution(buf863, primals_370, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf869, (8, 18, 14, 14), (3528, 196, 14, 1))
        buf870 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf871 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf873 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_2_fuse_layers_0_2_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_22.run(buf869, primals_1351, primals_1352, buf870, buf871, buf873, primals_1351, primals_1352, 18, 1568, grid=grid(18), stream=stream0)
        del primals_1351
        del primals_1352
        buf767 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        buf874 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        buf875 = buf874; del buf874  # reuse
        # Source Nodes: [l__mod___stage3_2_fuse_layers_0_1_1, l__mod___stage3_2_fuse_layers_0_1_2, l__mod___stage3_2_fuse_layers_0_2_1, l__mod___stage3_2_fuse_layers_0_2_2, shortcut_49, x_375, x_376, x_377, y_23, y_24], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_24.run(buf875, buf759, buf763, buf764, primals_317, primals_318, buf749, buf260, buf864, buf865, buf866, primals_368, primals_369, buf452, buf869, buf870, buf871, primals_371, primals_372, buf767, 451584, grid=grid(451584), stream=stream0)
        del primals_318
        del primals_369
        del primals_372
        # Source Nodes: [l__mod___stage3_2_fuse_layers_1_0_0_0], Original ATen: [aten.convolution]
        buf876 = extern_kernels.convolution(buf767, primals_373, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf876, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf877 = buf812; del buf812  # reuse
        buf878 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf880 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_25], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf876, primals_1354, primals_1355, buf877, buf878, buf880, primals_1354, primals_1355, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1354
        del primals_1355
        # Source Nodes: [l__mod___stage3_2_fuse_layers_1_2_0], Original ATen: [aten.convolution]
        buf881 = extern_kernels.convolution(buf863, primals_376, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf881, (8, 36, 14, 14), (7056, 196, 14, 1))
        buf882 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf883 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf885 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_2_fuse_layers_1_2_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_25.run(buf881, primals_1357, primals_1358, buf882, buf883, buf885, primals_1357, primals_1358, 36, 1568, grid=grid(36), stream=stream0)
        del primals_1357
        del primals_1358
        buf886 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        buf887 = buf886; del buf886  # reuse
        # Source Nodes: [l__mod___stage3_2_fuse_layers_1_2_1, l__mod___stage3_2_fuse_layers_1_2_2, shortcut_53, y_25, y_26, y_27], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_27.run(buf887, buf876, buf877, buf878, primals_374, primals_375, buf815, buf465, buf881, buf882, buf883, primals_377, primals_378, 225792, grid=grid(225792), stream=stream0)
        del primals_375
        del primals_378
        # Source Nodes: [l__mod___stage3_2_fuse_layers_2_0_0_0], Original ATen: [aten.convolution]
        buf888 = extern_kernels.convolution(buf767, primals_379, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf888, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf889 = buf871; del buf871  # reuse
        buf890 = buf866; del buf866  # reuse
        buf892 = reinterpret_tensor(buf764, (18, ), (1, ), 0); del buf764  # reuse
        # Source Nodes: [l__mod___stage3_2_fuse_layers_2_0_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf888, primals_1360, primals_1361, buf889, buf890, buf892, primals_1360, primals_1361, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1360
        del primals_1361
        buf893 = empty((8, 18, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_2_fuse_layers_2_0_0_1, l__mod___stage3_2_fuse_layers_2_0_0_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_28.run(buf888, buf889, buf890, primals_380, primals_381, buf893, 112896, grid=grid(112896), stream=stream0)
        del primals_381
        # Source Nodes: [l__mod___stage3_2_fuse_layers_2_0_1_0], Original ATen: [aten.convolution]
        buf894 = extern_kernels.convolution(buf893, primals_382, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf894, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf895 = buf860; del buf860  # reuse
        buf896 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf898 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_28], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf894, primals_1363, primals_1364, buf895, buf896, buf898, primals_1363, primals_1364, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1363
        del primals_1364
        # Source Nodes: [l__mod___stage3_2_fuse_layers_2_1_0_0], Original ATen: [aten.convolution]
        buf899 = extern_kernels.convolution(buf815, primals_385, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf899, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf900 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf901 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf903 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_2_fuse_layers_2_1_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf899, primals_1366, primals_1367, buf900, buf901, buf903, primals_1366, primals_1367, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1366
        del primals_1367
        buf904 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        buf905 = buf904; del buf904  # reuse
        # Source Nodes: [l__mod___stage3_2_fuse_layers_2_1_0_1, shortcut_57, y_28, y_29, y_30], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_29.run(buf905, buf894, buf895, buf896, primals_383, primals_384, buf899, buf900, buf901, primals_386, primals_387, buf863, 112896, grid=grid(112896), stream=stream0)
        del primals_384
        del primals_387
        # Source Nodes: [x_450], Original ATen: [aten.convolution]
        buf906 = extern_kernels.convolution(buf875, primals_388, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf906, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf907 = reinterpret_tensor(buf901, (1, 18, 1, 1, 4), (72, 1, 72, 72, 18), 0); del buf901  # reuse
        buf908 = reinterpret_tensor(buf896, (1, 18, 1, 1, 4), (72, 1, 72, 72, 18), 0); del buf896  # reuse
        buf909 = empty_strided((1, 18, 1, 1, 4), (72, 1, 72, 72, 18), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_451], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf906, buf907, buf908, buf909, 72, 6272, grid=grid(72), stream=stream0)
        buf910 = buf890; del buf890  # reuse
        buf911 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf913 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_451], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf907, buf908, buf909, primals_1369, primals_1370, buf910, buf911, buf913, primals_1369, primals_1370, 18, 4, grid=grid(18), stream=stream0)
        del primals_1369
        del primals_1370
        buf914 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_451, x_453], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf906, buf910, buf911, primals_389, primals_390, buf914, 451584, grid=grid(451584), stream=stream0)
        del primals_390
        # Source Nodes: [x_455], Original ATen: [aten.convolution]
        buf915 = extern_kernels.convolution(buf914, primals_391, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf915, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf916 = buf909; del buf909  # reuse
        buf917 = buf908; del buf908  # reuse
        buf918 = buf907; del buf907  # reuse
        # Source Nodes: [x_456], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf915, buf916, buf917, buf918, 72, 6272, grid=grid(72), stream=stream0)
        buf919 = buf911; del buf911  # reuse
        buf920 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf922 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_456], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf916, buf917, buf918, primals_1372, primals_1373, buf919, buf920, buf922, primals_1372, primals_1373, 18, 4, grid=grid(18), stream=stream0)
        del primals_1372
        del primals_1373
        buf923 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_50, x_456, x_457], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf915, buf919, buf920, primals_392, primals_393, buf875, buf923, 451584, grid=grid(451584), stream=stream0)
        del primals_393
        # Source Nodes: [x_459], Original ATen: [aten.convolution]
        buf924 = extern_kernels.convolution(buf923, primals_394, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf924, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf925 = buf918; del buf918  # reuse
        buf926 = buf917; del buf917  # reuse
        buf927 = buf916; del buf916  # reuse
        # Source Nodes: [x_460], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf924, buf925, buf926, buf927, 72, 6272, grid=grid(72), stream=stream0)
        buf928 = buf920; del buf920  # reuse
        buf929 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf931 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_460], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf925, buf926, buf927, primals_1375, primals_1376, buf928, buf929, buf931, primals_1375, primals_1376, 18, 4, grid=grid(18), stream=stream0)
        del primals_1375
        del primals_1376
        buf932 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_460, x_462], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf924, buf928, buf929, primals_395, primals_396, buf932, 451584, grid=grid(451584), stream=stream0)
        del primals_396
        # Source Nodes: [x_464], Original ATen: [aten.convolution]
        buf933 = extern_kernels.convolution(buf932, primals_397, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf933, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf934 = buf927; del buf927  # reuse
        buf935 = buf926; del buf926  # reuse
        buf936 = buf925; del buf925  # reuse
        # Source Nodes: [x_465], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf933, buf934, buf935, buf936, 72, 6272, grid=grid(72), stream=stream0)
        buf937 = buf929; del buf929  # reuse
        buf938 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf940 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_465], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf934, buf935, buf936, primals_1378, primals_1379, buf937, buf938, buf940, primals_1378, primals_1379, 18, 4, grid=grid(18), stream=stream0)
        del primals_1378
        del primals_1379
        buf941 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_51, x_465, x_466], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf933, buf937, buf938, primals_398, primals_399, buf923, buf941, 451584, grid=grid(451584), stream=stream0)
        del primals_399
        # Source Nodes: [x_468], Original ATen: [aten.convolution]
        buf942 = extern_kernels.convolution(buf941, primals_400, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf942, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf943 = buf936; del buf936  # reuse
        buf944 = buf935; del buf935  # reuse
        buf945 = buf934; del buf934  # reuse
        # Source Nodes: [x_469], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf942, buf943, buf944, buf945, 72, 6272, grid=grid(72), stream=stream0)
        buf946 = buf938; del buf938  # reuse
        buf947 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf949 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_469], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf943, buf944, buf945, primals_1381, primals_1382, buf946, buf947, buf949, primals_1381, primals_1382, 18, 4, grid=grid(18), stream=stream0)
        del primals_1381
        del primals_1382
        buf950 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_469, x_471], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf942, buf946, buf947, primals_401, primals_402, buf950, 451584, grid=grid(451584), stream=stream0)
        del primals_402
        # Source Nodes: [x_473], Original ATen: [aten.convolution]
        buf951 = extern_kernels.convolution(buf950, primals_403, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf951, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf952 = buf945; del buf945  # reuse
        buf953 = buf944; del buf944  # reuse
        buf954 = buf943; del buf943  # reuse
        # Source Nodes: [x_474], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf951, buf952, buf953, buf954, 72, 6272, grid=grid(72), stream=stream0)
        buf955 = buf947; del buf947  # reuse
        buf956 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf958 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_474], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf952, buf953, buf954, primals_1384, primals_1385, buf955, buf956, buf958, primals_1384, primals_1385, 18, 4, grid=grid(18), stream=stream0)
        del primals_1384
        del primals_1385
        buf959 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_52, x_474, x_475], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf951, buf955, buf956, primals_404, primals_405, buf941, buf959, 451584, grid=grid(451584), stream=stream0)
        del primals_405
        # Source Nodes: [x_477], Original ATen: [aten.convolution]
        buf960 = extern_kernels.convolution(buf959, primals_406, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf960, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf961 = buf954; del buf954  # reuse
        buf962 = buf953; del buf953  # reuse
        buf963 = buf952; del buf952  # reuse
        # Source Nodes: [x_478], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf960, buf961, buf962, buf963, 72, 6272, grid=grid(72), stream=stream0)
        buf964 = buf956; del buf956  # reuse
        buf965 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf967 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_478], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf961, buf962, buf963, primals_1387, primals_1388, buf964, buf965, buf967, primals_1387, primals_1388, 18, 4, grid=grid(18), stream=stream0)
        del primals_1387
        del primals_1388
        buf968 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_478, x_480], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf960, buf964, buf965, primals_407, primals_408, buf968, 451584, grid=grid(451584), stream=stream0)
        del primals_408
        # Source Nodes: [x_482], Original ATen: [aten.convolution]
        buf969 = extern_kernels.convolution(buf968, primals_409, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf969, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf970 = buf963; del buf963  # reuse
        buf971 = buf962; del buf962  # reuse
        buf972 = buf961; del buf961  # reuse
        # Source Nodes: [x_483], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf969, buf970, buf971, buf972, 72, 6272, grid=grid(72), stream=stream0)
        buf973 = buf965; del buf965  # reuse
        buf974 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf976 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_483], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf970, buf971, buf972, primals_1390, primals_1391, buf973, buf974, buf976, primals_1390, primals_1391, 18, 4, grid=grid(18), stream=stream0)
        del primals_1390
        del primals_1391
        # Source Nodes: [x_486], Original ATen: [aten.convolution]
        buf978 = extern_kernels.convolution(buf887, primals_412, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf978, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf979 = buf883; del buf883  # reuse
        buf980 = buf878; del buf878  # reuse
        buf982 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_487], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf978, primals_1393, primals_1394, buf979, buf980, buf982, primals_1393, primals_1394, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1393
        del primals_1394
        buf983 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_487, x_489], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf978, buf979, buf980, primals_413, primals_414, buf983, 225792, grid=grid(225792), stream=stream0)
        del primals_414
        # Source Nodes: [x_491], Original ATen: [aten.convolution]
        buf984 = extern_kernels.convolution(buf983, primals_415, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf984, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf985 = buf980; del buf980  # reuse
        buf986 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf988 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_492], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf984, primals_1396, primals_1397, buf985, buf986, buf988, primals_1396, primals_1397, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1396
        del primals_1397
        buf989 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_54, x_492, x_493], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf984, buf985, buf986, primals_416, primals_417, buf887, buf989, 225792, grid=grid(225792), stream=stream0)
        del primals_417
        # Source Nodes: [x_495], Original ATen: [aten.convolution]
        buf990 = extern_kernels.convolution(buf989, primals_418, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf990, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf991 = buf986; del buf986  # reuse
        buf992 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf994 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_496], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf990, primals_1399, primals_1400, buf991, buf992, buf994, primals_1399, primals_1400, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1399
        del primals_1400
        buf995 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_496, x_498], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf990, buf991, buf992, primals_419, primals_420, buf995, 225792, grid=grid(225792), stream=stream0)
        del primals_420
        # Source Nodes: [x_500], Original ATen: [aten.convolution]
        buf996 = extern_kernels.convolution(buf995, primals_421, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf996, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf997 = buf992; del buf992  # reuse
        buf998 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1000 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_501], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf996, primals_1402, primals_1403, buf997, buf998, buf1000, primals_1402, primals_1403, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1402
        del primals_1403
        buf1001 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_55, x_501, x_502], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf996, buf997, buf998, primals_422, primals_423, buf989, buf1001, 225792, grid=grid(225792), stream=stream0)
        del primals_423
        # Source Nodes: [x_504], Original ATen: [aten.convolution]
        buf1002 = extern_kernels.convolution(buf1001, primals_424, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1002, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1003 = buf998; del buf998  # reuse
        buf1004 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1006 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_505], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1002, primals_1405, primals_1406, buf1003, buf1004, buf1006, primals_1405, primals_1406, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1405
        del primals_1406
        buf1007 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_505, x_507], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf1002, buf1003, buf1004, primals_425, primals_426, buf1007, 225792, grid=grid(225792), stream=stream0)
        del primals_426
        # Source Nodes: [x_509], Original ATen: [aten.convolution]
        buf1008 = extern_kernels.convolution(buf1007, primals_427, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1008, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1009 = buf1004; del buf1004  # reuse
        buf1010 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1012 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_510], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1008, primals_1408, primals_1409, buf1009, buf1010, buf1012, primals_1408, primals_1409, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1408
        del primals_1409
        buf1013 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_56, x_510, x_511], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf1008, buf1009, buf1010, primals_428, primals_429, buf1001, buf1013, 225792, grid=grid(225792), stream=stream0)
        del primals_429
        # Source Nodes: [x_513], Original ATen: [aten.convolution]
        buf1014 = extern_kernels.convolution(buf1013, primals_430, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1014, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1015 = buf1010; del buf1010  # reuse
        buf1016 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1018 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_514], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1014, primals_1411, primals_1412, buf1015, buf1016, buf1018, primals_1411, primals_1412, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1411
        del primals_1412
        buf1019 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_514, x_516], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf1014, buf1015, buf1016, primals_431, primals_432, buf1019, 225792, grid=grid(225792), stream=stream0)
        del primals_432
        # Source Nodes: [x_518], Original ATen: [aten.convolution]
        buf1020 = extern_kernels.convolution(buf1019, primals_433, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1020, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1021 = buf1016; del buf1016  # reuse
        buf1022 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1024 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_519], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1020, primals_1414, primals_1415, buf1021, buf1022, buf1024, primals_1414, primals_1415, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1414
        del primals_1415
        buf1025 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_519, x_520, x_521], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf1020, buf1021, buf1022, primals_434, primals_435, buf1013, buf1025, 225792, grid=grid(225792), stream=stream0)
        del primals_435
        # Source Nodes: [l__mod___stage3_3_fuse_layers_0_1_0], Original ATen: [aten.convolution]
        buf1074 = extern_kernels.convolution(buf1025, primals_460, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1074, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf1075 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1076 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1078 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_3_fuse_layers_0_1_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf1074, primals_1441, primals_1442, buf1075, buf1076, buf1078, primals_1441, primals_1442, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1441
        del primals_1442
        # Source Nodes: [x_522], Original ATen: [aten.convolution]
        buf1026 = extern_kernels.convolution(buf905, primals_436, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1026, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1027 = reinterpret_tensor(buf972, (1, 72, 1, 1), (72, 1, 72, 72), 0); del buf972  # reuse
        buf1028 = reinterpret_tensor(buf971, (1, 72, 1, 1), (72, 1, 72, 72), 0); del buf971  # reuse
        buf1030 = reinterpret_tensor(buf970, (72, ), (1, ), 0); del buf970  # reuse
        # Source Nodes: [x_523], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1026, primals_1417, primals_1418, buf1027, buf1028, buf1030, primals_1417, primals_1418, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1417
        del primals_1418
        buf1031 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_523, x_525], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf1026, buf1027, buf1028, primals_437, primals_438, buf1031, 112896, grid=grid(112896), stream=stream0)
        del primals_438
        # Source Nodes: [x_527], Original ATen: [aten.convolution]
        buf1032 = extern_kernels.convolution(buf1031, primals_439, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1032, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1033 = buf1028; del buf1028  # reuse
        buf1034 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1036 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_528], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1032, primals_1420, primals_1421, buf1033, buf1034, buf1036, primals_1420, primals_1421, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1420
        del primals_1421
        buf1037 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_58, x_528, x_529], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf1032, buf1033, buf1034, primals_440, primals_441, buf905, buf1037, 112896, grid=grid(112896), stream=stream0)
        del primals_441
        # Source Nodes: [x_531], Original ATen: [aten.convolution]
        buf1038 = extern_kernels.convolution(buf1037, primals_442, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1038, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1039 = buf1034; del buf1034  # reuse
        buf1040 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1042 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_532], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1038, primals_1423, primals_1424, buf1039, buf1040, buf1042, primals_1423, primals_1424, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1423
        del primals_1424
        buf1043 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_532, x_534], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf1038, buf1039, buf1040, primals_443, primals_444, buf1043, 112896, grid=grid(112896), stream=stream0)
        del primals_444
        # Source Nodes: [x_536], Original ATen: [aten.convolution]
        buf1044 = extern_kernels.convolution(buf1043, primals_445, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1044, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1045 = buf1040; del buf1040  # reuse
        buf1046 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1048 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_537], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1044, primals_1426, primals_1427, buf1045, buf1046, buf1048, primals_1426, primals_1427, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1426
        del primals_1427
        buf1049 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_59, x_537, x_538], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf1044, buf1045, buf1046, primals_446, primals_447, buf1037, buf1049, 112896, grid=grid(112896), stream=stream0)
        del primals_447
        # Source Nodes: [x_540], Original ATen: [aten.convolution]
        buf1050 = extern_kernels.convolution(buf1049, primals_448, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1050, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1051 = buf1046; del buf1046  # reuse
        buf1052 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1054 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_541], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1050, primals_1429, primals_1430, buf1051, buf1052, buf1054, primals_1429, primals_1430, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1429
        del primals_1430
        buf1055 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_541, x_543], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf1050, buf1051, buf1052, primals_449, primals_450, buf1055, 112896, grid=grid(112896), stream=stream0)
        del primals_450
        # Source Nodes: [x_545], Original ATen: [aten.convolution]
        buf1056 = extern_kernels.convolution(buf1055, primals_451, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1056, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1057 = buf1052; del buf1052  # reuse
        buf1058 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1060 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_546], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1056, primals_1432, primals_1433, buf1057, buf1058, buf1060, primals_1432, primals_1433, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1432
        del primals_1433
        buf1061 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_60, x_546, x_547], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf1056, buf1057, buf1058, primals_452, primals_453, buf1049, buf1061, 112896, grid=grid(112896), stream=stream0)
        del primals_453
        # Source Nodes: [x_549], Original ATen: [aten.convolution]
        buf1062 = extern_kernels.convolution(buf1061, primals_454, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1062, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1063 = buf1058; del buf1058  # reuse
        buf1064 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1066 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_550], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1062, primals_1435, primals_1436, buf1063, buf1064, buf1066, primals_1435, primals_1436, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1435
        del primals_1436
        buf1067 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_550, x_552], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf1062, buf1063, buf1064, primals_455, primals_456, buf1067, 112896, grid=grid(112896), stream=stream0)
        del primals_456
        # Source Nodes: [x_554], Original ATen: [aten.convolution]
        buf1068 = extern_kernels.convolution(buf1067, primals_457, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1068, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1069 = buf1064; del buf1064  # reuse
        buf1070 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1072 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_555], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1068, primals_1438, primals_1439, buf1069, buf1070, buf1072, primals_1438, primals_1439, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1438
        del primals_1439
        buf1073 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_555, x_556, x_557], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf1068, buf1069, buf1070, primals_458, primals_459, buf1061, buf1073, 112896, grid=grid(112896), stream=stream0)
        del primals_459
        # Source Nodes: [l__mod___stage3_3_fuse_layers_0_2_0], Original ATen: [aten.convolution]
        buf1079 = extern_kernels.convolution(buf1073, primals_463, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1079, (8, 18, 14, 14), (3528, 196, 14, 1))
        buf1080 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1081 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1083 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_3_fuse_layers_0_2_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_22.run(buf1079, primals_1444, primals_1445, buf1080, buf1081, buf1083, primals_1444, primals_1445, 18, 1568, grid=grid(18), stream=stream0)
        del primals_1444
        del primals_1445
        buf977 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        buf1084 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        buf1085 = buf1084; del buf1084  # reuse
        # Source Nodes: [l__mod___stage3_3_fuse_layers_0_1_1, l__mod___stage3_3_fuse_layers_0_1_2, l__mod___stage3_3_fuse_layers_0_2_1, l__mod___stage3_3_fuse_layers_0_2_2, shortcut_61, x_483, x_484, x_485, y_32, y_33], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_24.run(buf1085, buf969, buf973, buf974, primals_410, primals_411, buf959, buf260, buf1074, buf1075, buf1076, primals_461, primals_462, buf452, buf1079, buf1080, buf1081, primals_464, primals_465, buf977, 451584, grid=grid(451584), stream=stream0)
        del primals_411
        del primals_462
        del primals_465
        # Source Nodes: [l__mod___stage3_3_fuse_layers_1_0_0_0], Original ATen: [aten.convolution]
        buf1086 = extern_kernels.convolution(buf977, primals_466, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1086, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1087 = buf1022; del buf1022  # reuse
        buf1088 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1090 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_34], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1086, primals_1447, primals_1448, buf1087, buf1088, buf1090, primals_1447, primals_1448, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1447
        del primals_1448
        # Source Nodes: [l__mod___stage3_3_fuse_layers_1_2_0], Original ATen: [aten.convolution]
        buf1091 = extern_kernels.convolution(buf1073, primals_469, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1091, (8, 36, 14, 14), (7056, 196, 14, 1))
        buf1092 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1093 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1095 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_3_fuse_layers_1_2_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_25.run(buf1091, primals_1450, primals_1451, buf1092, buf1093, buf1095, primals_1450, primals_1451, 36, 1568, grid=grid(36), stream=stream0)
        del primals_1450
        del primals_1451
        buf1096 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        buf1097 = buf1096; del buf1096  # reuse
        # Source Nodes: [l__mod___stage3_3_fuse_layers_1_2_1, l__mod___stage3_3_fuse_layers_1_2_2, shortcut_65, y_34, y_35, y_36], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_27.run(buf1097, buf1086, buf1087, buf1088, primals_467, primals_468, buf1025, buf465, buf1091, buf1092, buf1093, primals_470, primals_471, 225792, grid=grid(225792), stream=stream0)
        del primals_468
        del primals_471
        # Source Nodes: [l__mod___stage3_3_fuse_layers_2_0_0_0], Original ATen: [aten.convolution]
        buf1098 = extern_kernels.convolution(buf977, primals_472, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1098, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf1099 = buf974; del buf974  # reuse
        buf1100 = buf1081; del buf1081  # reuse
        buf1102 = reinterpret_tensor(buf1076, (18, ), (1, ), 0); del buf1076  # reuse
        # Source Nodes: [l__mod___stage3_3_fuse_layers_2_0_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf1098, primals_1453, primals_1454, buf1099, buf1100, buf1102, primals_1453, primals_1454, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1453
        del primals_1454
        buf1103 = empty((8, 18, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_3_fuse_layers_2_0_0_1, l__mod___stage3_3_fuse_layers_2_0_0_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_28.run(buf1098, buf1099, buf1100, primals_473, primals_474, buf1103, 112896, grid=grid(112896), stream=stream0)
        del primals_474
        # Source Nodes: [l__mod___stage3_3_fuse_layers_2_0_1_0], Original ATen: [aten.convolution]
        buf1104 = extern_kernels.convolution(buf1103, primals_475, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1104, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1105 = buf1070; del buf1070  # reuse
        buf1106 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1108 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_37], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1104, primals_1456, primals_1457, buf1105, buf1106, buf1108, primals_1456, primals_1457, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1456
        del primals_1457
        # Source Nodes: [l__mod___stage3_3_fuse_layers_2_1_0_0], Original ATen: [aten.convolution]
        buf1109 = extern_kernels.convolution(buf1025, primals_478, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1109, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1110 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1111 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1113 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage3_3_fuse_layers_2_1_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1109, primals_1459, primals_1460, buf1110, buf1111, buf1113, primals_1459, primals_1460, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1459
        del primals_1460
        buf1114 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        buf1115 = buf1114; del buf1114  # reuse
        # Source Nodes: [l__mod___stage3_3_fuse_layers_2_1_0_1, shortcut_69, y_37, y_38, y_39], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_29.run(buf1115, buf1104, buf1105, buf1106, primals_476, primals_477, buf1109, buf1110, buf1111, primals_479, primals_480, buf1073, 112896, grid=grid(112896), stream=stream0)
        del primals_477
        del primals_480
        # Source Nodes: [l__mod___transition3_3_0_0], Original ATen: [aten.convolution]
        buf1116 = extern_kernels.convolution(buf1115, primals_481, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1116, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1117 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1118 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1120 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___transition3_3_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1116, primals_1462, primals_1463, buf1117, buf1118, buf1120, primals_1462, primals_1463, 144, 392, grid=grid(144), stream=stream0)
        del primals_1462
        del primals_1463
        buf1121 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___transition3_3_0_1, shortcut_73], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_31.run(buf1116, buf1117, buf1118, primals_482, primals_483, buf1121, 56448, grid=grid(56448), stream=stream0)
        del primals_483
        # Source Nodes: [x_558], Original ATen: [aten.convolution]
        buf1122 = extern_kernels.convolution(buf1085, primals_484, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1122, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1123 = reinterpret_tensor(buf1111, (1, 18, 1, 1, 4), (72, 1, 72, 72, 18), 0); del buf1111  # reuse
        buf1124 = reinterpret_tensor(buf1106, (1, 18, 1, 1, 4), (72, 1, 72, 72, 18), 0); del buf1106  # reuse
        buf1125 = empty_strided((1, 18, 1, 1, 4), (72, 1, 72, 72, 18), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_559], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1122, buf1123, buf1124, buf1125, 72, 6272, grid=grid(72), stream=stream0)
        buf1126 = buf1100; del buf1100  # reuse
        buf1127 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1129 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_559], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1123, buf1124, buf1125, primals_1465, primals_1466, buf1126, buf1127, buf1129, primals_1465, primals_1466, 18, 4, grid=grid(18), stream=stream0)
        del primals_1465
        del primals_1466
        buf1130 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_559, x_561], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf1122, buf1126, buf1127, primals_485, primals_486, buf1130, 451584, grid=grid(451584), stream=stream0)
        del primals_486
        # Source Nodes: [x_563], Original ATen: [aten.convolution]
        buf1131 = extern_kernels.convolution(buf1130, primals_487, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1131, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1132 = buf1125; del buf1125  # reuse
        buf1133 = buf1124; del buf1124  # reuse
        buf1134 = buf1123; del buf1123  # reuse
        # Source Nodes: [x_564], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1131, buf1132, buf1133, buf1134, 72, 6272, grid=grid(72), stream=stream0)
        buf1135 = buf1127; del buf1127  # reuse
        buf1136 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1138 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_564], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1132, buf1133, buf1134, primals_1468, primals_1469, buf1135, buf1136, buf1138, primals_1468, primals_1469, 18, 4, grid=grid(18), stream=stream0)
        del primals_1468
        del primals_1469
        buf1139 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_62, x_564, x_565], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf1131, buf1135, buf1136, primals_488, primals_489, buf1085, buf1139, 451584, grid=grid(451584), stream=stream0)
        del primals_489
        # Source Nodes: [x_567], Original ATen: [aten.convolution]
        buf1140 = extern_kernels.convolution(buf1139, primals_490, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1140, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1141 = buf1134; del buf1134  # reuse
        buf1142 = buf1133; del buf1133  # reuse
        buf1143 = buf1132; del buf1132  # reuse
        # Source Nodes: [x_568], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1140, buf1141, buf1142, buf1143, 72, 6272, grid=grid(72), stream=stream0)
        buf1144 = buf1136; del buf1136  # reuse
        buf1145 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1147 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_568], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1141, buf1142, buf1143, primals_1471, primals_1472, buf1144, buf1145, buf1147, primals_1471, primals_1472, 18, 4, grid=grid(18), stream=stream0)
        del primals_1471
        del primals_1472
        buf1148 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_568, x_570], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf1140, buf1144, buf1145, primals_491, primals_492, buf1148, 451584, grid=grid(451584), stream=stream0)
        del primals_492
        # Source Nodes: [x_572], Original ATen: [aten.convolution]
        buf1149 = extern_kernels.convolution(buf1148, primals_493, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1149, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1150 = buf1143; del buf1143  # reuse
        buf1151 = buf1142; del buf1142  # reuse
        buf1152 = buf1141; del buf1141  # reuse
        # Source Nodes: [x_573], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1149, buf1150, buf1151, buf1152, 72, 6272, grid=grid(72), stream=stream0)
        buf1153 = buf1145; del buf1145  # reuse
        buf1154 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1156 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_573], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1150, buf1151, buf1152, primals_1474, primals_1475, buf1153, buf1154, buf1156, primals_1474, primals_1475, 18, 4, grid=grid(18), stream=stream0)
        del primals_1474
        del primals_1475
        buf1157 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_63, x_573, x_574], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf1149, buf1153, buf1154, primals_494, primals_495, buf1139, buf1157, 451584, grid=grid(451584), stream=stream0)
        del primals_495
        # Source Nodes: [x_576], Original ATen: [aten.convolution]
        buf1158 = extern_kernels.convolution(buf1157, primals_496, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1158, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1159 = buf1152; del buf1152  # reuse
        buf1160 = buf1151; del buf1151  # reuse
        buf1161 = buf1150; del buf1150  # reuse
        # Source Nodes: [x_577], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1158, buf1159, buf1160, buf1161, 72, 6272, grid=grid(72), stream=stream0)
        buf1162 = buf1154; del buf1154  # reuse
        buf1163 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1165 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_577], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1159, buf1160, buf1161, primals_1477, primals_1478, buf1162, buf1163, buf1165, primals_1477, primals_1478, 18, 4, grid=grid(18), stream=stream0)
        del primals_1477
        del primals_1478
        buf1166 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_577, x_579], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf1158, buf1162, buf1163, primals_497, primals_498, buf1166, 451584, grid=grid(451584), stream=stream0)
        del primals_498
        # Source Nodes: [x_581], Original ATen: [aten.convolution]
        buf1167 = extern_kernels.convolution(buf1166, primals_499, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1167, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1168 = buf1161; del buf1161  # reuse
        buf1169 = buf1160; del buf1160  # reuse
        buf1170 = buf1159; del buf1159  # reuse
        # Source Nodes: [x_582], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1167, buf1168, buf1169, buf1170, 72, 6272, grid=grid(72), stream=stream0)
        buf1171 = buf1163; del buf1163  # reuse
        buf1172 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1174 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_582], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1168, buf1169, buf1170, primals_1480, primals_1481, buf1171, buf1172, buf1174, primals_1480, primals_1481, 18, 4, grid=grid(18), stream=stream0)
        del primals_1480
        del primals_1481
        buf1175 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_64, x_582, x_583], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf1167, buf1171, buf1172, primals_500, primals_501, buf1157, buf1175, 451584, grid=grid(451584), stream=stream0)
        del primals_501
        # Source Nodes: [x_585], Original ATen: [aten.convolution]
        buf1176 = extern_kernels.convolution(buf1175, primals_502, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1176, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1177 = buf1170; del buf1170  # reuse
        buf1178 = buf1169; del buf1169  # reuse
        buf1179 = buf1168; del buf1168  # reuse
        # Source Nodes: [x_586], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1176, buf1177, buf1178, buf1179, 72, 6272, grid=grid(72), stream=stream0)
        buf1180 = buf1172; del buf1172  # reuse
        buf1181 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1183 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_586], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1177, buf1178, buf1179, primals_1483, primals_1484, buf1180, buf1181, buf1183, primals_1483, primals_1484, 18, 4, grid=grid(18), stream=stream0)
        del primals_1483
        del primals_1484
        buf1184 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_586, x_588], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf1176, buf1180, buf1181, primals_503, primals_504, buf1184, 451584, grid=grid(451584), stream=stream0)
        del primals_504
        # Source Nodes: [x_590], Original ATen: [aten.convolution]
        buf1185 = extern_kernels.convolution(buf1184, primals_505, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1185, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1186 = buf1179; del buf1179  # reuse
        buf1187 = buf1178; del buf1178  # reuse
        buf1188 = buf1177; del buf1177  # reuse
        # Source Nodes: [x_591], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1185, buf1186, buf1187, buf1188, 72, 6272, grid=grid(72), stream=stream0)
        buf1189 = buf1181; del buf1181  # reuse
        buf1190 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1192 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_591], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1186, buf1187, buf1188, primals_1486, primals_1487, buf1189, buf1190, buf1192, primals_1486, primals_1487, 18, 4, grid=grid(18), stream=stream0)
        del primals_1486
        del primals_1487
        # Source Nodes: [x_594], Original ATen: [aten.convolution]
        buf1194 = extern_kernels.convolution(buf1097, primals_508, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1194, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1195 = buf1093; del buf1093  # reuse
        buf1196 = buf1088; del buf1088  # reuse
        buf1198 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_595], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1194, primals_1489, primals_1490, buf1195, buf1196, buf1198, primals_1489, primals_1490, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1489
        del primals_1490
        buf1199 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_595, x_597], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf1194, buf1195, buf1196, primals_509, primals_510, buf1199, 225792, grid=grid(225792), stream=stream0)
        del primals_510
        # Source Nodes: [x_599], Original ATen: [aten.convolution]
        buf1200 = extern_kernels.convolution(buf1199, primals_511, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1200, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1201 = buf1196; del buf1196  # reuse
        buf1202 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1204 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_600], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1200, primals_1492, primals_1493, buf1201, buf1202, buf1204, primals_1492, primals_1493, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1492
        del primals_1493
        buf1205 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_66, x_600, x_601], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf1200, buf1201, buf1202, primals_512, primals_513, buf1097, buf1205, 225792, grid=grid(225792), stream=stream0)
        del primals_513
        # Source Nodes: [x_603], Original ATen: [aten.convolution]
        buf1206 = extern_kernels.convolution(buf1205, primals_514, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1206, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1207 = buf1202; del buf1202  # reuse
        buf1208 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1210 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_604], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1206, primals_1495, primals_1496, buf1207, buf1208, buf1210, primals_1495, primals_1496, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1495
        del primals_1496
        buf1211 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_604, x_606], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf1206, buf1207, buf1208, primals_515, primals_516, buf1211, 225792, grid=grid(225792), stream=stream0)
        del primals_516
        # Source Nodes: [x_608], Original ATen: [aten.convolution]
        buf1212 = extern_kernels.convolution(buf1211, primals_517, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1212, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1213 = buf1208; del buf1208  # reuse
        buf1214 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1216 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_609], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1212, primals_1498, primals_1499, buf1213, buf1214, buf1216, primals_1498, primals_1499, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1498
        del primals_1499
        buf1217 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_67, x_609, x_610], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf1212, buf1213, buf1214, primals_518, primals_519, buf1205, buf1217, 225792, grid=grid(225792), stream=stream0)
        del primals_519
        # Source Nodes: [x_612], Original ATen: [aten.convolution]
        buf1218 = extern_kernels.convolution(buf1217, primals_520, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1218, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1219 = buf1214; del buf1214  # reuse
        buf1220 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1222 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_613], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1218, primals_1501, primals_1502, buf1219, buf1220, buf1222, primals_1501, primals_1502, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1501
        del primals_1502
        buf1223 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_613, x_615], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf1218, buf1219, buf1220, primals_521, primals_522, buf1223, 225792, grid=grid(225792), stream=stream0)
        del primals_522
        # Source Nodes: [x_617], Original ATen: [aten.convolution]
        buf1224 = extern_kernels.convolution(buf1223, primals_523, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1224, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1225 = buf1220; del buf1220  # reuse
        buf1226 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1228 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_618], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1224, primals_1504, primals_1505, buf1225, buf1226, buf1228, primals_1504, primals_1505, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1504
        del primals_1505
        buf1229 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_68, x_618, x_619], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf1224, buf1225, buf1226, primals_524, primals_525, buf1217, buf1229, 225792, grid=grid(225792), stream=stream0)
        del primals_525
        # Source Nodes: [x_621], Original ATen: [aten.convolution]
        buf1230 = extern_kernels.convolution(buf1229, primals_526, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1230, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1231 = buf1226; del buf1226  # reuse
        buf1232 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1234 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_622], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1230, primals_1507, primals_1508, buf1231, buf1232, buf1234, primals_1507, primals_1508, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1507
        del primals_1508
        buf1235 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_622, x_624], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf1230, buf1231, buf1232, primals_527, primals_528, buf1235, 225792, grid=grid(225792), stream=stream0)
        del primals_528
        # Source Nodes: [x_626], Original ATen: [aten.convolution]
        buf1236 = extern_kernels.convolution(buf1235, primals_529, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1236, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1237 = buf1232; del buf1232  # reuse
        buf1238 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1240 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_627], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1236, primals_1510, primals_1511, buf1237, buf1238, buf1240, primals_1510, primals_1511, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1510
        del primals_1511
        buf1241 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_627, x_628, x_629], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf1236, buf1237, buf1238, primals_530, primals_531, buf1229, buf1241, 225792, grid=grid(225792), stream=stream0)
        del primals_531
        # Source Nodes: [l__mod___stage4_0_fuse_layers_0_1_0], Original ATen: [aten.convolution]
        buf1338 = extern_kernels.convolution(buf1241, primals_580, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1338, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf1339 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1340 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1342 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_0_fuse_layers_0_1_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf1338, primals_1561, primals_1562, buf1339, buf1340, buf1342, primals_1561, primals_1562, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1561
        del primals_1562
        # Source Nodes: [x_630], Original ATen: [aten.convolution]
        buf1242 = extern_kernels.convolution(buf1115, primals_532, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1242, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1243 = reinterpret_tensor(buf1188, (1, 72, 1, 1), (72, 1, 72, 72), 0); del buf1188  # reuse
        buf1244 = reinterpret_tensor(buf1187, (1, 72, 1, 1), (72, 1, 72, 72), 0); del buf1187  # reuse
        buf1246 = reinterpret_tensor(buf1186, (72, ), (1, ), 0); del buf1186  # reuse
        # Source Nodes: [x_631], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1242, primals_1513, primals_1514, buf1243, buf1244, buf1246, primals_1513, primals_1514, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1513
        del primals_1514
        buf1247 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_631, x_633], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf1242, buf1243, buf1244, primals_533, primals_534, buf1247, 112896, grid=grid(112896), stream=stream0)
        del primals_534
        # Source Nodes: [x_635], Original ATen: [aten.convolution]
        buf1248 = extern_kernels.convolution(buf1247, primals_535, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1248, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1249 = buf1244; del buf1244  # reuse
        buf1250 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1252 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_636], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1248, primals_1516, primals_1517, buf1249, buf1250, buf1252, primals_1516, primals_1517, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1516
        del primals_1517
        buf1253 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_70, x_636, x_637], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf1248, buf1249, buf1250, primals_536, primals_537, buf1115, buf1253, 112896, grid=grid(112896), stream=stream0)
        del primals_537
        # Source Nodes: [x_639], Original ATen: [aten.convolution]
        buf1254 = extern_kernels.convolution(buf1253, primals_538, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1254, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1255 = buf1250; del buf1250  # reuse
        buf1256 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1258 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_640], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1254, primals_1519, primals_1520, buf1255, buf1256, buf1258, primals_1519, primals_1520, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1519
        del primals_1520
        buf1259 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_640, x_642], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf1254, buf1255, buf1256, primals_539, primals_540, buf1259, 112896, grid=grid(112896), stream=stream0)
        del primals_540
        # Source Nodes: [x_644], Original ATen: [aten.convolution]
        buf1260 = extern_kernels.convolution(buf1259, primals_541, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1260, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1261 = buf1256; del buf1256  # reuse
        buf1262 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1264 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_645], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1260, primals_1522, primals_1523, buf1261, buf1262, buf1264, primals_1522, primals_1523, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1522
        del primals_1523
        buf1265 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_71, x_645, x_646], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf1260, buf1261, buf1262, primals_542, primals_543, buf1253, buf1265, 112896, grid=grid(112896), stream=stream0)
        del primals_543
        # Source Nodes: [x_648], Original ATen: [aten.convolution]
        buf1266 = extern_kernels.convolution(buf1265, primals_544, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1266, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1267 = buf1262; del buf1262  # reuse
        buf1268 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1270 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_649], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1266, primals_1525, primals_1526, buf1267, buf1268, buf1270, primals_1525, primals_1526, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1525
        del primals_1526
        buf1271 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_649, x_651], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf1266, buf1267, buf1268, primals_545, primals_546, buf1271, 112896, grid=grid(112896), stream=stream0)
        del primals_546
        # Source Nodes: [x_653], Original ATen: [aten.convolution]
        buf1272 = extern_kernels.convolution(buf1271, primals_547, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1272, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1273 = buf1268; del buf1268  # reuse
        buf1274 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1276 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_654], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1272, primals_1528, primals_1529, buf1273, buf1274, buf1276, primals_1528, primals_1529, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1528
        del primals_1529
        buf1277 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_72, x_654, x_655], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf1272, buf1273, buf1274, primals_548, primals_549, buf1265, buf1277, 112896, grid=grid(112896), stream=stream0)
        del primals_549
        # Source Nodes: [x_657], Original ATen: [aten.convolution]
        buf1278 = extern_kernels.convolution(buf1277, primals_550, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1278, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1279 = buf1274; del buf1274  # reuse
        buf1280 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1282 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_658], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1278, primals_1531, primals_1532, buf1279, buf1280, buf1282, primals_1531, primals_1532, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1531
        del primals_1532
        buf1283 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_658, x_660], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf1278, buf1279, buf1280, primals_551, primals_552, buf1283, 112896, grid=grid(112896), stream=stream0)
        del primals_552
        # Source Nodes: [x_662], Original ATen: [aten.convolution]
        buf1284 = extern_kernels.convolution(buf1283, primals_553, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1284, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1285 = buf1280; del buf1280  # reuse
        buf1286 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1288 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_663], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1284, primals_1534, primals_1535, buf1285, buf1286, buf1288, primals_1534, primals_1535, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1534
        del primals_1535
        buf1289 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_663, x_664, x_665], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf1284, buf1285, buf1286, primals_554, primals_555, buf1277, buf1289, 112896, grid=grid(112896), stream=stream0)
        del primals_555
        # Source Nodes: [l__mod___stage4_0_fuse_layers_0_2_0], Original ATen: [aten.convolution]
        buf1343 = extern_kernels.convolution(buf1289, primals_583, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1343, (8, 18, 14, 14), (3528, 196, 14, 1))
        buf1344 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1345 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1347 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_0_fuse_layers_0_2_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_22.run(buf1343, primals_1564, primals_1565, buf1344, buf1345, buf1347, primals_1564, primals_1565, 18, 1568, grid=grid(18), stream=stream0)
        del primals_1564
        del primals_1565
        # Source Nodes: [x_666], Original ATen: [aten.convolution]
        buf1290 = extern_kernels.convolution(buf1121, primals_556, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1290, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1291 = buf1118; del buf1118  # reuse
        buf1292 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1294 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_667], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1290, primals_1537, primals_1538, buf1291, buf1292, buf1294, primals_1537, primals_1538, 144, 392, grid=grid(144), stream=stream0)
        del primals_1537
        del primals_1538
        buf1295 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_667, x_669], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_31.run(buf1290, buf1291, buf1292, primals_557, primals_558, buf1295, 56448, grid=grid(56448), stream=stream0)
        del primals_558
        # Source Nodes: [x_671], Original ATen: [aten.convolution]
        buf1296 = extern_kernels.convolution(buf1295, primals_559, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1296, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1297 = buf1292; del buf1292  # reuse
        buf1298 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1300 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_672], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1296, primals_1540, primals_1541, buf1297, buf1298, buf1300, primals_1540, primals_1541, 144, 392, grid=grid(144), stream=stream0)
        del primals_1540
        del primals_1541
        buf1301 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_74, x_672, x_673], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_32.run(buf1296, buf1297, buf1298, primals_560, primals_561, buf1121, buf1301, 56448, grid=grid(56448), stream=stream0)
        del primals_561
        # Source Nodes: [x_675], Original ATen: [aten.convolution]
        buf1302 = extern_kernels.convolution(buf1301, primals_562, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1302, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1303 = buf1298; del buf1298  # reuse
        buf1304 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1306 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_676], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1302, primals_1543, primals_1544, buf1303, buf1304, buf1306, primals_1543, primals_1544, 144, 392, grid=grid(144), stream=stream0)
        del primals_1543
        del primals_1544
        buf1307 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_676, x_678], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_31.run(buf1302, buf1303, buf1304, primals_563, primals_564, buf1307, 56448, grid=grid(56448), stream=stream0)
        del primals_564
        # Source Nodes: [x_680], Original ATen: [aten.convolution]
        buf1308 = extern_kernels.convolution(buf1307, primals_565, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1308, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1309 = buf1304; del buf1304  # reuse
        buf1310 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1312 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_681], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1308, primals_1546, primals_1547, buf1309, buf1310, buf1312, primals_1546, primals_1547, 144, 392, grid=grid(144), stream=stream0)
        del primals_1546
        del primals_1547
        buf1313 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_75, x_681, x_682], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_32.run(buf1308, buf1309, buf1310, primals_566, primals_567, buf1301, buf1313, 56448, grid=grid(56448), stream=stream0)
        del primals_567
        # Source Nodes: [x_684], Original ATen: [aten.convolution]
        buf1314 = extern_kernels.convolution(buf1313, primals_568, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1314, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1315 = buf1310; del buf1310  # reuse
        buf1316 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1318 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_685], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1314, primals_1549, primals_1550, buf1315, buf1316, buf1318, primals_1549, primals_1550, 144, 392, grid=grid(144), stream=stream0)
        del primals_1549
        del primals_1550
        buf1319 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_685, x_687], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_31.run(buf1314, buf1315, buf1316, primals_569, primals_570, buf1319, 56448, grid=grid(56448), stream=stream0)
        del primals_570
        # Source Nodes: [x_689], Original ATen: [aten.convolution]
        buf1320 = extern_kernels.convolution(buf1319, primals_571, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1320, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1321 = buf1316; del buf1316  # reuse
        buf1322 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1324 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_690], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1320, primals_1552, primals_1553, buf1321, buf1322, buf1324, primals_1552, primals_1553, 144, 392, grid=grid(144), stream=stream0)
        del primals_1552
        del primals_1553
        buf1325 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_76, x_690, x_691], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_32.run(buf1320, buf1321, buf1322, primals_572, primals_573, buf1313, buf1325, 56448, grid=grid(56448), stream=stream0)
        del primals_573
        # Source Nodes: [x_693], Original ATen: [aten.convolution]
        buf1326 = extern_kernels.convolution(buf1325, primals_574, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1326, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1327 = buf1322; del buf1322  # reuse
        buf1328 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1330 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_694], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1326, primals_1555, primals_1556, buf1327, buf1328, buf1330, primals_1555, primals_1556, 144, 392, grid=grid(144), stream=stream0)
        del primals_1555
        del primals_1556
        buf1331 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_694, x_696], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_31.run(buf1326, buf1327, buf1328, primals_575, primals_576, buf1331, 56448, grid=grid(56448), stream=stream0)
        del primals_576
        # Source Nodes: [x_698], Original ATen: [aten.convolution]
        buf1332 = extern_kernels.convolution(buf1331, primals_577, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1332, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1333 = buf1328; del buf1328  # reuse
        buf1334 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1336 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_699], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1332, primals_1558, primals_1559, buf1333, buf1334, buf1336, primals_1558, primals_1559, 144, 392, grid=grid(144), stream=stream0)
        del primals_1558
        del primals_1559
        buf1337 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_699, x_700, x_701], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_32.run(buf1332, buf1333, buf1334, primals_578, primals_579, buf1325, buf1337, 56448, grid=grid(56448), stream=stream0)
        del primals_579
        # Source Nodes: [l__mod___stage4_0_fuse_layers_0_3_0], Original ATen: [aten.convolution]
        buf1349 = extern_kernels.convolution(buf1337, primals_586, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1349, (8, 18, 7, 7), (882, 49, 7, 1))
        buf1350 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1351 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1353 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_0_fuse_layers_0_3_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_33.run(buf1349, primals_1567, primals_1568, buf1350, buf1351, buf1353, primals_1567, primals_1568, 18, 392, grid=grid(18), stream=stream0)
        del primals_1567
        del primals_1568
        buf1354 = empty((56, ), device='cuda', dtype=torch.int64)
        # Source Nodes: [l__mod___stage2_0_fuse_layers_0_1_2, l__mod___stage4_0_fuse_layers_0_3_2], Original ATen: [aten._to_copy, aten.add, aten.arange, aten.mul]
        triton_poi_fused__to_copy_add_arange_mul_34.run(buf1354, 56, grid=grid(56), stream=stream0)
        buf1193 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        buf1348 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        buf1355 = buf1348; del buf1348  # reuse
        # Source Nodes: [l__mod___stage4_0_fuse_layers_0_1_1, l__mod___stage4_0_fuse_layers_0_1_2, l__mod___stage4_0_fuse_layers_0_2_1, l__mod___stage4_0_fuse_layers_0_2_2, l__mod___stage4_0_fuse_layers_0_3_1, l__mod___stage4_0_fuse_layers_0_3_2, shortcut_77, x_591, x_592, x_593, y_41, y_42, y_43], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_35.run(buf1355, buf1185, buf1189, buf1190, primals_506, primals_507, buf1175, buf260, buf1338, buf1339, buf1340, primals_581, primals_582, buf452, buf1343, buf1344, buf1345, primals_584, primals_585, buf1354, buf1349, buf1350, buf1351, primals_587, primals_588, buf1193, 451584, grid=grid(451584), stream=stream0)
        del primals_507
        del primals_582
        del primals_585
        del primals_588
        # Source Nodes: [l__mod___stage4_0_fuse_layers_1_0_0_0], Original ATen: [aten.convolution]
        buf1356 = extern_kernels.convolution(buf1193, primals_589, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1356, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1357 = buf1238; del buf1238  # reuse
        buf1358 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1360 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_44], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1356, primals_1570, primals_1571, buf1357, buf1358, buf1360, primals_1570, primals_1571, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1570
        del primals_1571
        # Source Nodes: [l__mod___stage4_0_fuse_layers_1_2_0], Original ATen: [aten.convolution]
        buf1361 = extern_kernels.convolution(buf1289, primals_592, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1361, (8, 36, 14, 14), (7056, 196, 14, 1))
        buf1362 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1363 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1365 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_0_fuse_layers_1_2_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_25.run(buf1361, primals_1573, primals_1574, buf1362, buf1363, buf1365, primals_1573, primals_1574, 36, 1568, grid=grid(36), stream=stream0)
        del primals_1573
        del primals_1574
        # Source Nodes: [l__mod___stage4_0_fuse_layers_1_3_0], Original ATen: [aten.convolution]
        buf1367 = extern_kernels.convolution(buf1337, primals_595, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1367, (8, 36, 7, 7), (1764, 49, 7, 1))
        buf1368 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1369 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1371 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_0_fuse_layers_1_3_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_36.run(buf1367, primals_1576, primals_1577, buf1368, buf1369, buf1371, primals_1576, primals_1577, 36, 392, grid=grid(36), stream=stream0)
        del primals_1576
        del primals_1577
        buf1372 = empty((28, ), device='cuda', dtype=torch.int64)
        # Source Nodes: [l__mod___stage3_0_fuse_layers_1_2_2, l__mod___stage4_0_fuse_layers_1_3_2], Original ATen: [aten._to_copy, aten.add, aten.arange, aten.mul]
        triton_poi_fused__to_copy_add_arange_mul_37.run(buf1372, 28, grid=grid(28), stream=stream0)
        buf1366 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        buf1373 = buf1366; del buf1366  # reuse
        # Source Nodes: [l__mod___stage4_0_fuse_layers_1_2_1, l__mod___stage4_0_fuse_layers_1_2_2, l__mod___stage4_0_fuse_layers_1_3_1, l__mod___stage4_0_fuse_layers_1_3_2, shortcut_81, y_44, y_45, y_46, y_47], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_38.run(buf1373, buf1356, buf1357, buf1358, primals_590, primals_591, buf1241, buf465, buf1361, buf1362, buf1363, primals_593, primals_594, buf1372, buf1367, buf1368, buf1369, primals_596, primals_597, 225792, grid=grid(225792), stream=stream0)
        del primals_591
        del primals_594
        del primals_597
        # Source Nodes: [l__mod___stage4_0_fuse_layers_2_0_0_0], Original ATen: [aten.convolution]
        buf1374 = extern_kernels.convolution(buf1193, primals_598, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1374, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf1375 = buf1351; del buf1351  # reuse
        buf1376 = buf1345; del buf1345  # reuse
        buf1378 = reinterpret_tensor(buf1340, (18, ), (1, ), 0); del buf1340  # reuse
        # Source Nodes: [l__mod___stage4_0_fuse_layers_2_0_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf1374, primals_1579, primals_1580, buf1375, buf1376, buf1378, primals_1579, primals_1580, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1579
        del primals_1580
        buf1379 = empty((8, 18, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_0_fuse_layers_2_0_0_1, l__mod___stage4_0_fuse_layers_2_0_0_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_28.run(buf1374, buf1375, buf1376, primals_599, primals_600, buf1379, 112896, grid=grid(112896), stream=stream0)
        del primals_600
        # Source Nodes: [l__mod___stage4_0_fuse_layers_2_0_1_0], Original ATen: [aten.convolution]
        buf1380 = extern_kernels.convolution(buf1379, primals_601, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1380, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1381 = buf1286; del buf1286  # reuse
        buf1382 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1384 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_48], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1380, primals_1582, primals_1583, buf1381, buf1382, buf1384, primals_1582, primals_1583, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1582
        del primals_1583
        # Source Nodes: [l__mod___stage4_0_fuse_layers_2_1_0_0], Original ATen: [aten.convolution]
        buf1385 = extern_kernels.convolution(buf1241, primals_604, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1385, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1386 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1387 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1389 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_0_fuse_layers_2_1_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1385, primals_1585, primals_1586, buf1386, buf1387, buf1389, primals_1585, primals_1586, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1585
        del primals_1586
        # Source Nodes: [l__mod___stage4_0_fuse_layers_2_3_0], Original ATen: [aten.convolution]
        buf1391 = extern_kernels.convolution(buf1337, primals_607, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1391, (8, 72, 7, 7), (3528, 49, 7, 1))
        buf1392 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1393 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1395 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_0_fuse_layers_2_3_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_39.run(buf1391, primals_1588, primals_1589, buf1392, buf1393, buf1395, primals_1588, primals_1589, 72, 392, grid=grid(72), stream=stream0)
        del primals_1588
        del primals_1589
        buf1396 = empty((14, ), device='cuda', dtype=torch.int64)
        # Source Nodes: [l__mod___stage4_0_fuse_layers_2_3_2], Original ATen: [aten._to_copy, aten.add, aten.arange, aten.mul]
        triton_poi_fused__to_copy_add_arange_mul_40.run(buf1396, 14, grid=grid(14), stream=stream0)
        buf1390 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        buf1397 = buf1390; del buf1390  # reuse
        buf1398 = buf1397; del buf1397  # reuse
        # Source Nodes: [l__mod___stage4_0_fuse_layers_2_1_0_1, l__mod___stage4_0_fuse_layers_2_3_1, l__mod___stage4_0_fuse_layers_2_3_2, shortcut_85, y_48, y_49, y_50, y_51], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_41.run(buf1398, buf1380, buf1381, buf1382, primals_602, primals_603, buf1385, buf1386, buf1387, primals_605, primals_606, buf1289, buf1396, buf1391, buf1392, buf1393, primals_608, primals_609, 112896, grid=grid(112896), stream=stream0)
        del primals_603
        del primals_606
        del primals_609
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_0_0_0], Original ATen: [aten.convolution]
        buf1399 = extern_kernels.convolution(buf1193, primals_610, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1399, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf1400 = buf1376; del buf1376  # reuse
        buf1401 = buf1190; del buf1190  # reuse
        buf1403 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_0_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf1399, primals_1591, primals_1592, buf1400, buf1401, buf1403, primals_1591, primals_1592, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1591
        del primals_1592
        buf1404 = empty((8, 18, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_0_0_1, l__mod___stage4_0_fuse_layers_3_0_0_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_28.run(buf1399, buf1400, buf1401, primals_611, primals_612, buf1404, 112896, grid=grid(112896), stream=stream0)
        del primals_612
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_0_1_0], Original ATen: [aten.convolution]
        buf1405 = extern_kernels.convolution(buf1404, primals_613, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1405, (8, 18, 14, 14), (3528, 196, 14, 1))
        buf1406 = buf1401; del buf1401  # reuse
        buf1407 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1409 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_0_1_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_22.run(buf1405, primals_1594, primals_1595, buf1406, buf1407, buf1409, primals_1594, primals_1595, 18, 1568, grid=grid(18), stream=stream0)
        del primals_1594
        del primals_1595
        buf1410 = empty((8, 18, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_0_1_1, l__mod___stage4_0_fuse_layers_3_0_1_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_42.run(buf1405, buf1406, buf1407, primals_614, primals_615, buf1410, 28224, grid=grid(28224), stream=stream0)
        del primals_615
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_0_2_0], Original ATen: [aten.convolution]
        buf1411 = extern_kernels.convolution(buf1410, primals_616, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1411, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1412 = buf1334; del buf1334  # reuse
        buf1413 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1415 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_52], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1411, primals_1597, primals_1598, buf1412, buf1413, buf1415, primals_1597, primals_1598, 144, 392, grid=grid(144), stream=stream0)
        del primals_1597
        del primals_1598
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_1_0_0], Original ATen: [aten.convolution]
        buf1416 = extern_kernels.convolution(buf1241, primals_619, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1416, (8, 36, 14, 14), (7056, 196, 14, 1))
        buf1417 = buf1369; del buf1369  # reuse
        buf1418 = buf1363; del buf1363  # reuse
        buf1420 = reinterpret_tensor(buf1358, (36, ), (1, ), 0); del buf1358  # reuse
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_1_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_25.run(buf1416, primals_1600, primals_1601, buf1417, buf1418, buf1420, primals_1600, primals_1601, 36, 1568, grid=grid(36), stream=stream0)
        del primals_1600
        del primals_1601
        buf1421 = empty((8, 36, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_1_0_1, l__mod___stage4_0_fuse_layers_3_1_0_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_43.run(buf1416, buf1417, buf1418, primals_620, primals_621, buf1421, 56448, grid=grid(56448), stream=stream0)
        del primals_621
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_1_1_0], Original ATen: [aten.convolution]
        buf1422 = extern_kernels.convolution(buf1421, primals_622, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1422, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1423 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1424 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1426 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_1_1_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1422, primals_1603, primals_1604, buf1423, buf1424, buf1426, primals_1603, primals_1604, 144, 392, grid=grid(144), stream=stream0)
        del primals_1603
        del primals_1604
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_2_0_0], Original ATen: [aten.convolution]
        buf1428 = extern_kernels.convolution(buf1289, primals_625, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1428, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1429 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1430 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1432 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_2_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1428, primals_1606, primals_1607, buf1429, buf1430, buf1432, primals_1606, primals_1607, 144, 392, grid=grid(144), stream=stream0)
        del primals_1606
        del primals_1607
        buf1427 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        buf1433 = buf1427; del buf1427  # reuse
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_1_1_1, l__mod___stage4_0_fuse_layers_3_2_0_1, shortcut_89, y_52, y_53, y_54, y_55], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_44.run(buf1433, buf1411, buf1412, buf1413, primals_617, primals_618, buf1422, buf1423, buf1424, primals_623, primals_624, buf1428, buf1429, buf1430, primals_626, primals_627, buf1337, 56448, grid=grid(56448), stream=stream0)
        del primals_618
        del primals_624
        del primals_627
        # Source Nodes: [x_702], Original ATen: [aten.convolution]
        buf1434 = extern_kernels.convolution(buf1355, primals_628, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1434, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1435 = reinterpret_tensor(buf1393, (1, 18, 1, 1, 4), (72, 1, 72, 72, 18), 0); del buf1393  # reuse
        buf1436 = reinterpret_tensor(buf1387, (1, 18, 1, 1, 4), (72, 1, 72, 72, 18), 0); del buf1387  # reuse
        buf1437 = reinterpret_tensor(buf1382, (1, 18, 1, 1, 4), (72, 1, 72, 72, 18), 0); del buf1382  # reuse
        # Source Nodes: [x_703], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1434, buf1435, buf1436, buf1437, 72, 6272, grid=grid(72), stream=stream0)
        buf1438 = buf1407; del buf1407  # reuse
        buf1439 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1441 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_703], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1435, buf1436, buf1437, primals_1609, primals_1610, buf1438, buf1439, buf1441, primals_1609, primals_1610, 18, 4, grid=grid(18), stream=stream0)
        del primals_1609
        del primals_1610
        buf1442 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_703, x_705], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf1434, buf1438, buf1439, primals_629, primals_630, buf1442, 451584, grid=grid(451584), stream=stream0)
        del primals_630
        # Source Nodes: [x_707], Original ATen: [aten.convolution]
        buf1443 = extern_kernels.convolution(buf1442, primals_631, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1443, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1444 = buf1437; del buf1437  # reuse
        buf1445 = buf1436; del buf1436  # reuse
        buf1446 = buf1435; del buf1435  # reuse
        # Source Nodes: [x_708], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1443, buf1444, buf1445, buf1446, 72, 6272, grid=grid(72), stream=stream0)
        buf1447 = buf1439; del buf1439  # reuse
        buf1448 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1450 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_708], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1444, buf1445, buf1446, primals_1612, primals_1613, buf1447, buf1448, buf1450, primals_1612, primals_1613, 18, 4, grid=grid(18), stream=stream0)
        del primals_1612
        del primals_1613
        buf1451 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_78, x_708, x_709], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf1443, buf1447, buf1448, primals_632, primals_633, buf1355, buf1451, 451584, grid=grid(451584), stream=stream0)
        del primals_633
        # Source Nodes: [x_711], Original ATen: [aten.convolution]
        buf1452 = extern_kernels.convolution(buf1451, primals_634, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1452, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1453 = buf1446; del buf1446  # reuse
        buf1454 = buf1445; del buf1445  # reuse
        buf1455 = buf1444; del buf1444  # reuse
        # Source Nodes: [x_712], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1452, buf1453, buf1454, buf1455, 72, 6272, grid=grid(72), stream=stream0)
        buf1456 = buf1448; del buf1448  # reuse
        buf1457 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1459 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_712], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1453, buf1454, buf1455, primals_1615, primals_1616, buf1456, buf1457, buf1459, primals_1615, primals_1616, 18, 4, grid=grid(18), stream=stream0)
        del primals_1615
        del primals_1616
        buf1460 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_712, x_714], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf1452, buf1456, buf1457, primals_635, primals_636, buf1460, 451584, grid=grid(451584), stream=stream0)
        del primals_636
        # Source Nodes: [x_716], Original ATen: [aten.convolution]
        buf1461 = extern_kernels.convolution(buf1460, primals_637, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1461, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1462 = buf1455; del buf1455  # reuse
        buf1463 = buf1454; del buf1454  # reuse
        buf1464 = buf1453; del buf1453  # reuse
        # Source Nodes: [x_717], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1461, buf1462, buf1463, buf1464, 72, 6272, grid=grid(72), stream=stream0)
        buf1465 = buf1457; del buf1457  # reuse
        buf1466 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1468 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_717], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1462, buf1463, buf1464, primals_1618, primals_1619, buf1465, buf1466, buf1468, primals_1618, primals_1619, 18, 4, grid=grid(18), stream=stream0)
        del primals_1618
        del primals_1619
        buf1469 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_79, x_717, x_718], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf1461, buf1465, buf1466, primals_638, primals_639, buf1451, buf1469, 451584, grid=grid(451584), stream=stream0)
        del primals_639
        # Source Nodes: [x_720], Original ATen: [aten.convolution]
        buf1470 = extern_kernels.convolution(buf1469, primals_640, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1470, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1471 = buf1464; del buf1464  # reuse
        buf1472 = buf1463; del buf1463  # reuse
        buf1473 = buf1462; del buf1462  # reuse
        # Source Nodes: [x_721], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1470, buf1471, buf1472, buf1473, 72, 6272, grid=grid(72), stream=stream0)
        buf1474 = buf1466; del buf1466  # reuse
        buf1475 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1477 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_721], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1471, buf1472, buf1473, primals_1621, primals_1622, buf1474, buf1475, buf1477, primals_1621, primals_1622, 18, 4, grid=grid(18), stream=stream0)
        del primals_1621
        del primals_1622
        buf1478 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_721, x_723], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf1470, buf1474, buf1475, primals_641, primals_642, buf1478, 451584, grid=grid(451584), stream=stream0)
        del primals_642
        # Source Nodes: [x_725], Original ATen: [aten.convolution]
        buf1479 = extern_kernels.convolution(buf1478, primals_643, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1479, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1480 = buf1473; del buf1473  # reuse
        buf1481 = buf1472; del buf1472  # reuse
        buf1482 = buf1471; del buf1471  # reuse
        # Source Nodes: [x_726], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1479, buf1480, buf1481, buf1482, 72, 6272, grid=grid(72), stream=stream0)
        buf1483 = buf1475; del buf1475  # reuse
        buf1484 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1486 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_726], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1480, buf1481, buf1482, primals_1624, primals_1625, buf1483, buf1484, buf1486, primals_1624, primals_1625, 18, 4, grid=grid(18), stream=stream0)
        del primals_1624
        del primals_1625
        buf1487 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_80, x_726, x_727], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf1479, buf1483, buf1484, primals_644, primals_645, buf1469, buf1487, 451584, grid=grid(451584), stream=stream0)
        del primals_645
        # Source Nodes: [x_729], Original ATen: [aten.convolution]
        buf1488 = extern_kernels.convolution(buf1487, primals_646, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1488, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1489 = buf1482; del buf1482  # reuse
        buf1490 = buf1481; del buf1481  # reuse
        buf1491 = buf1480; del buf1480  # reuse
        # Source Nodes: [x_730], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1488, buf1489, buf1490, buf1491, 72, 6272, grid=grid(72), stream=stream0)
        buf1492 = buf1484; del buf1484  # reuse
        buf1493 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1495 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_730], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1489, buf1490, buf1491, primals_1627, primals_1628, buf1492, buf1493, buf1495, primals_1627, primals_1628, 18, 4, grid=grid(18), stream=stream0)
        del primals_1627
        del primals_1628
        buf1496 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_730, x_732], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf1488, buf1492, buf1493, primals_647, primals_648, buf1496, 451584, grid=grid(451584), stream=stream0)
        del primals_648
        # Source Nodes: [x_734], Original ATen: [aten.convolution]
        buf1497 = extern_kernels.convolution(buf1496, primals_649, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1497, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1498 = buf1491; del buf1491  # reuse
        buf1499 = buf1490; del buf1490  # reuse
        buf1500 = buf1489; del buf1489  # reuse
        # Source Nodes: [x_735], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1497, buf1498, buf1499, buf1500, 72, 6272, grid=grid(72), stream=stream0)
        buf1501 = buf1493; del buf1493  # reuse
        buf1502 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1504 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_735], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1498, buf1499, buf1500, primals_1630, primals_1631, buf1501, buf1502, buf1504, primals_1630, primals_1631, 18, 4, grid=grid(18), stream=stream0)
        del primals_1630
        del primals_1631
        # Source Nodes: [x_738], Original ATen: [aten.convolution]
        buf1506 = extern_kernels.convolution(buf1373, primals_652, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1506, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1507 = buf1418; del buf1418  # reuse
        buf1508 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1510 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_739], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1506, primals_1633, primals_1634, buf1507, buf1508, buf1510, primals_1633, primals_1634, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1633
        del primals_1634
        buf1511 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_739, x_741], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf1506, buf1507, buf1508, primals_653, primals_654, buf1511, 225792, grid=grid(225792), stream=stream0)
        del primals_654
        # Source Nodes: [x_743], Original ATen: [aten.convolution]
        buf1512 = extern_kernels.convolution(buf1511, primals_655, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1512, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1513 = buf1508; del buf1508  # reuse
        buf1514 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1516 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_744], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1512, primals_1636, primals_1637, buf1513, buf1514, buf1516, primals_1636, primals_1637, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1636
        del primals_1637
        buf1517 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_82, x_744, x_745], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf1512, buf1513, buf1514, primals_656, primals_657, buf1373, buf1517, 225792, grid=grid(225792), stream=stream0)
        del primals_657
        # Source Nodes: [x_747], Original ATen: [aten.convolution]
        buf1518 = extern_kernels.convolution(buf1517, primals_658, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1518, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1519 = buf1514; del buf1514  # reuse
        buf1520 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1522 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_748], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1518, primals_1639, primals_1640, buf1519, buf1520, buf1522, primals_1639, primals_1640, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1639
        del primals_1640
        buf1523 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_748, x_750], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf1518, buf1519, buf1520, primals_659, primals_660, buf1523, 225792, grid=grid(225792), stream=stream0)
        del primals_660
        # Source Nodes: [x_752], Original ATen: [aten.convolution]
        buf1524 = extern_kernels.convolution(buf1523, primals_661, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1524, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1525 = buf1520; del buf1520  # reuse
        buf1526 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1528 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_753], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1524, primals_1642, primals_1643, buf1525, buf1526, buf1528, primals_1642, primals_1643, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1642
        del primals_1643
        buf1529 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_83, x_753, x_754], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf1524, buf1525, buf1526, primals_662, primals_663, buf1517, buf1529, 225792, grid=grid(225792), stream=stream0)
        del primals_663
        # Source Nodes: [x_756], Original ATen: [aten.convolution]
        buf1530 = extern_kernels.convolution(buf1529, primals_664, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1530, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1531 = buf1526; del buf1526  # reuse
        buf1532 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1534 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_757], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1530, primals_1645, primals_1646, buf1531, buf1532, buf1534, primals_1645, primals_1646, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1645
        del primals_1646
        buf1535 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_757, x_759], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf1530, buf1531, buf1532, primals_665, primals_666, buf1535, 225792, grid=grid(225792), stream=stream0)
        del primals_666
        # Source Nodes: [x_761], Original ATen: [aten.convolution]
        buf1536 = extern_kernels.convolution(buf1535, primals_667, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1536, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1537 = buf1532; del buf1532  # reuse
        buf1538 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1540 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_762], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1536, primals_1648, primals_1649, buf1537, buf1538, buf1540, primals_1648, primals_1649, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1648
        del primals_1649
        buf1541 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_84, x_762, x_763], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf1536, buf1537, buf1538, primals_668, primals_669, buf1529, buf1541, 225792, grid=grid(225792), stream=stream0)
        del primals_669
        # Source Nodes: [x_765], Original ATen: [aten.convolution]
        buf1542 = extern_kernels.convolution(buf1541, primals_670, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1542, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1543 = buf1538; del buf1538  # reuse
        buf1544 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1546 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_766], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1542, primals_1651, primals_1652, buf1543, buf1544, buf1546, primals_1651, primals_1652, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1651
        del primals_1652
        buf1547 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_766, x_768], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf1542, buf1543, buf1544, primals_671, primals_672, buf1547, 225792, grid=grid(225792), stream=stream0)
        del primals_672
        # Source Nodes: [x_770], Original ATen: [aten.convolution]
        buf1548 = extern_kernels.convolution(buf1547, primals_673, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1548, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1549 = buf1544; del buf1544  # reuse
        buf1550 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1552 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_771], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1548, primals_1654, primals_1655, buf1549, buf1550, buf1552, primals_1654, primals_1655, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1654
        del primals_1655
        buf1553 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_771, x_772, x_773], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf1548, buf1549, buf1550, primals_674, primals_675, buf1541, buf1553, 225792, grid=grid(225792), stream=stream0)
        del primals_675
        # Source Nodes: [l__mod___stage4_1_fuse_layers_0_1_0], Original ATen: [aten.convolution]
        buf1650 = extern_kernels.convolution(buf1553, primals_724, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1650, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf1651 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1652 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1654 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_1_fuse_layers_0_1_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf1650, primals_1705, primals_1706, buf1651, buf1652, buf1654, primals_1705, primals_1706, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1705
        del primals_1706
        # Source Nodes: [x_774], Original ATen: [aten.convolution]
        buf1554 = extern_kernels.convolution(buf1398, primals_676, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1554, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1555 = reinterpret_tensor(buf1500, (1, 72, 1, 1), (72, 1, 72, 72), 0); del buf1500  # reuse
        buf1556 = reinterpret_tensor(buf1499, (1, 72, 1, 1), (72, 1, 72, 72), 0); del buf1499  # reuse
        buf1558 = reinterpret_tensor(buf1498, (72, ), (1, ), 0); del buf1498  # reuse
        # Source Nodes: [x_775], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1554, primals_1657, primals_1658, buf1555, buf1556, buf1558, primals_1657, primals_1658, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1657
        del primals_1658
        buf1559 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_775, x_777], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf1554, buf1555, buf1556, primals_677, primals_678, buf1559, 112896, grid=grid(112896), stream=stream0)
        del primals_678
        # Source Nodes: [x_779], Original ATen: [aten.convolution]
        buf1560 = extern_kernels.convolution(buf1559, primals_679, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1560, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1561 = buf1556; del buf1556  # reuse
        buf1562 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1564 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_780], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1560, primals_1660, primals_1661, buf1561, buf1562, buf1564, primals_1660, primals_1661, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1660
        del primals_1661
        buf1565 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_86, x_780, x_781], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf1560, buf1561, buf1562, primals_680, primals_681, buf1398, buf1565, 112896, grid=grid(112896), stream=stream0)
        del primals_681
        # Source Nodes: [x_783], Original ATen: [aten.convolution]
        buf1566 = extern_kernels.convolution(buf1565, primals_682, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1566, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1567 = buf1562; del buf1562  # reuse
        buf1568 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1570 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_784], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1566, primals_1663, primals_1664, buf1567, buf1568, buf1570, primals_1663, primals_1664, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1663
        del primals_1664
        buf1571 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_784, x_786], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf1566, buf1567, buf1568, primals_683, primals_684, buf1571, 112896, grid=grid(112896), stream=stream0)
        del primals_684
        # Source Nodes: [x_788], Original ATen: [aten.convolution]
        buf1572 = extern_kernels.convolution(buf1571, primals_685, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1572, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1573 = buf1568; del buf1568  # reuse
        buf1574 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1576 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_789], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1572, primals_1666, primals_1667, buf1573, buf1574, buf1576, primals_1666, primals_1667, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1666
        del primals_1667
        buf1577 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_87, x_789, x_790], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf1572, buf1573, buf1574, primals_686, primals_687, buf1565, buf1577, 112896, grid=grid(112896), stream=stream0)
        del primals_687
        # Source Nodes: [x_792], Original ATen: [aten.convolution]
        buf1578 = extern_kernels.convolution(buf1577, primals_688, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1578, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1579 = buf1574; del buf1574  # reuse
        buf1580 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1582 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_793], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1578, primals_1669, primals_1670, buf1579, buf1580, buf1582, primals_1669, primals_1670, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1669
        del primals_1670
        buf1583 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_793, x_795], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf1578, buf1579, buf1580, primals_689, primals_690, buf1583, 112896, grid=grid(112896), stream=stream0)
        del primals_690
        # Source Nodes: [x_797], Original ATen: [aten.convolution]
        buf1584 = extern_kernels.convolution(buf1583, primals_691, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1584, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1585 = buf1580; del buf1580  # reuse
        buf1586 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1588 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_798], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1584, primals_1672, primals_1673, buf1585, buf1586, buf1588, primals_1672, primals_1673, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1672
        del primals_1673
        buf1589 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_88, x_798, x_799], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf1584, buf1585, buf1586, primals_692, primals_693, buf1577, buf1589, 112896, grid=grid(112896), stream=stream0)
        del primals_693
        # Source Nodes: [x_801], Original ATen: [aten.convolution]
        buf1590 = extern_kernels.convolution(buf1589, primals_694, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1590, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1591 = buf1586; del buf1586  # reuse
        buf1592 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1594 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_802], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1590, primals_1675, primals_1676, buf1591, buf1592, buf1594, primals_1675, primals_1676, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1675
        del primals_1676
        buf1595 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_802, x_804], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf1590, buf1591, buf1592, primals_695, primals_696, buf1595, 112896, grid=grid(112896), stream=stream0)
        del primals_696
        # Source Nodes: [x_806], Original ATen: [aten.convolution]
        buf1596 = extern_kernels.convolution(buf1595, primals_697, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1596, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1597 = buf1592; del buf1592  # reuse
        buf1598 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1600 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_807], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1596, primals_1678, primals_1679, buf1597, buf1598, buf1600, primals_1678, primals_1679, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1678
        del primals_1679
        buf1601 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_807, x_808, x_809], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf1596, buf1597, buf1598, primals_698, primals_699, buf1589, buf1601, 112896, grid=grid(112896), stream=stream0)
        del primals_699
        # Source Nodes: [l__mod___stage4_1_fuse_layers_0_2_0], Original ATen: [aten.convolution]
        buf1655 = extern_kernels.convolution(buf1601, primals_727, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1655, (8, 18, 14, 14), (3528, 196, 14, 1))
        buf1656 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1657 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1659 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_1_fuse_layers_0_2_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_22.run(buf1655, primals_1708, primals_1709, buf1656, buf1657, buf1659, primals_1708, primals_1709, 18, 1568, grid=grid(18), stream=stream0)
        del primals_1708
        del primals_1709
        # Source Nodes: [x_810], Original ATen: [aten.convolution]
        buf1602 = extern_kernels.convolution(buf1433, primals_700, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1602, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1603 = buf1430; del buf1430  # reuse
        buf1604 = buf1424; del buf1424  # reuse
        buf1606 = reinterpret_tensor(buf1413, (144, ), (1, ), 0); del buf1413  # reuse
        # Source Nodes: [x_811], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1602, primals_1681, primals_1682, buf1603, buf1604, buf1606, primals_1681, primals_1682, 144, 392, grid=grid(144), stream=stream0)
        del primals_1681
        del primals_1682
        buf1607 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_811, x_813], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_31.run(buf1602, buf1603, buf1604, primals_701, primals_702, buf1607, 56448, grid=grid(56448), stream=stream0)
        del primals_702
        # Source Nodes: [x_815], Original ATen: [aten.convolution]
        buf1608 = extern_kernels.convolution(buf1607, primals_703, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1608, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1609 = buf1604; del buf1604  # reuse
        buf1610 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1612 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_816], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1608, primals_1684, primals_1685, buf1609, buf1610, buf1612, primals_1684, primals_1685, 144, 392, grid=grid(144), stream=stream0)
        del primals_1684
        del primals_1685
        buf1613 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_90, x_816, x_817], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_32.run(buf1608, buf1609, buf1610, primals_704, primals_705, buf1433, buf1613, 56448, grid=grid(56448), stream=stream0)
        del primals_705
        # Source Nodes: [x_819], Original ATen: [aten.convolution]
        buf1614 = extern_kernels.convolution(buf1613, primals_706, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1614, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1615 = buf1610; del buf1610  # reuse
        buf1616 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1618 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_820], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1614, primals_1687, primals_1688, buf1615, buf1616, buf1618, primals_1687, primals_1688, 144, 392, grid=grid(144), stream=stream0)
        del primals_1687
        del primals_1688
        buf1619 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_820, x_822], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_31.run(buf1614, buf1615, buf1616, primals_707, primals_708, buf1619, 56448, grid=grid(56448), stream=stream0)
        del primals_708
        # Source Nodes: [x_824], Original ATen: [aten.convolution]
        buf1620 = extern_kernels.convolution(buf1619, primals_709, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1620, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1621 = buf1616; del buf1616  # reuse
        buf1622 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1624 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_825], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1620, primals_1690, primals_1691, buf1621, buf1622, buf1624, primals_1690, primals_1691, 144, 392, grid=grid(144), stream=stream0)
        del primals_1690
        del primals_1691
        buf1625 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_91, x_825, x_826], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_32.run(buf1620, buf1621, buf1622, primals_710, primals_711, buf1613, buf1625, 56448, grid=grid(56448), stream=stream0)
        del primals_711
        # Source Nodes: [x_828], Original ATen: [aten.convolution]
        buf1626 = extern_kernels.convolution(buf1625, primals_712, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1626, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1627 = buf1622; del buf1622  # reuse
        buf1628 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1630 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_829], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1626, primals_1693, primals_1694, buf1627, buf1628, buf1630, primals_1693, primals_1694, 144, 392, grid=grid(144), stream=stream0)
        del primals_1693
        del primals_1694
        buf1631 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_829, x_831], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_31.run(buf1626, buf1627, buf1628, primals_713, primals_714, buf1631, 56448, grid=grid(56448), stream=stream0)
        del primals_714
        # Source Nodes: [x_833], Original ATen: [aten.convolution]
        buf1632 = extern_kernels.convolution(buf1631, primals_715, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1632, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1633 = buf1628; del buf1628  # reuse
        buf1634 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1636 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_834], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1632, primals_1696, primals_1697, buf1633, buf1634, buf1636, primals_1696, primals_1697, 144, 392, grid=grid(144), stream=stream0)
        del primals_1696
        del primals_1697
        buf1637 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_92, x_834, x_835], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_32.run(buf1632, buf1633, buf1634, primals_716, primals_717, buf1625, buf1637, 56448, grid=grid(56448), stream=stream0)
        del primals_717
        # Source Nodes: [x_837], Original ATen: [aten.convolution]
        buf1638 = extern_kernels.convolution(buf1637, primals_718, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1638, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1639 = buf1634; del buf1634  # reuse
        buf1640 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1642 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_838], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1638, primals_1699, primals_1700, buf1639, buf1640, buf1642, primals_1699, primals_1700, 144, 392, grid=grid(144), stream=stream0)
        del primals_1699
        del primals_1700
        buf1643 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_838, x_840], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_31.run(buf1638, buf1639, buf1640, primals_719, primals_720, buf1643, 56448, grid=grid(56448), stream=stream0)
        del primals_720
        # Source Nodes: [x_842], Original ATen: [aten.convolution]
        buf1644 = extern_kernels.convolution(buf1643, primals_721, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1644, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1645 = buf1640; del buf1640  # reuse
        buf1646 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1648 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_843], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1644, primals_1702, primals_1703, buf1645, buf1646, buf1648, primals_1702, primals_1703, 144, 392, grid=grid(144), stream=stream0)
        del primals_1702
        del primals_1703
        buf1649 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_843, x_844, x_845], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_32.run(buf1644, buf1645, buf1646, primals_722, primals_723, buf1637, buf1649, 56448, grid=grid(56448), stream=stream0)
        del primals_723
        # Source Nodes: [l__mod___stage4_1_fuse_layers_0_3_0], Original ATen: [aten.convolution]
        buf1661 = extern_kernels.convolution(buf1649, primals_730, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1661, (8, 18, 7, 7), (882, 49, 7, 1))
        buf1662 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1663 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1665 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_1_fuse_layers_0_3_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_33.run(buf1661, primals_1711, primals_1712, buf1662, buf1663, buf1665, primals_1711, primals_1712, 18, 392, grid=grid(18), stream=stream0)
        del primals_1711
        del primals_1712
        buf1505 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        buf1660 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        buf1666 = buf1660; del buf1660  # reuse
        # Source Nodes: [l__mod___stage4_1_fuse_layers_0_1_1, l__mod___stage4_1_fuse_layers_0_1_2, l__mod___stage4_1_fuse_layers_0_2_1, l__mod___stage4_1_fuse_layers_0_2_2, l__mod___stage4_1_fuse_layers_0_3_1, l__mod___stage4_1_fuse_layers_0_3_2, shortcut_93, x_735, x_736, x_737, y_57, y_58, y_59], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_35.run(buf1666, buf1497, buf1501, buf1502, primals_650, primals_651, buf1487, buf260, buf1650, buf1651, buf1652, primals_725, primals_726, buf452, buf1655, buf1656, buf1657, primals_728, primals_729, buf1354, buf1661, buf1662, buf1663, primals_731, primals_732, buf1505, 451584, grid=grid(451584), stream=stream0)
        del primals_651
        del primals_726
        del primals_729
        del primals_732
        # Source Nodes: [l__mod___stage4_1_fuse_layers_1_0_0_0], Original ATen: [aten.convolution]
        buf1667 = extern_kernels.convolution(buf1505, primals_733, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1667, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1668 = buf1550; del buf1550  # reuse
        buf1669 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1671 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_60], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1667, primals_1714, primals_1715, buf1668, buf1669, buf1671, primals_1714, primals_1715, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1714
        del primals_1715
        # Source Nodes: [l__mod___stage4_1_fuse_layers_1_2_0], Original ATen: [aten.convolution]
        buf1672 = extern_kernels.convolution(buf1601, primals_736, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1672, (8, 36, 14, 14), (7056, 196, 14, 1))
        buf1673 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1674 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1676 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_1_fuse_layers_1_2_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_25.run(buf1672, primals_1717, primals_1718, buf1673, buf1674, buf1676, primals_1717, primals_1718, 36, 1568, grid=grid(36), stream=stream0)
        del primals_1717
        del primals_1718
        # Source Nodes: [l__mod___stage4_1_fuse_layers_1_3_0], Original ATen: [aten.convolution]
        buf1678 = extern_kernels.convolution(buf1649, primals_739, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1678, (8, 36, 7, 7), (1764, 49, 7, 1))
        buf1679 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1680 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1682 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_1_fuse_layers_1_3_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_36.run(buf1678, primals_1720, primals_1721, buf1679, buf1680, buf1682, primals_1720, primals_1721, 36, 392, grid=grid(36), stream=stream0)
        del primals_1720
        del primals_1721
        buf1677 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        buf1683 = buf1677; del buf1677  # reuse
        # Source Nodes: [l__mod___stage4_1_fuse_layers_1_2_1, l__mod___stage4_1_fuse_layers_1_2_2, l__mod___stage4_1_fuse_layers_1_3_1, l__mod___stage4_1_fuse_layers_1_3_2, shortcut_97, y_60, y_61, y_62, y_63], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_38.run(buf1683, buf1667, buf1668, buf1669, primals_734, primals_735, buf1553, buf465, buf1672, buf1673, buf1674, primals_737, primals_738, buf1372, buf1678, buf1679, buf1680, primals_740, primals_741, 225792, grid=grid(225792), stream=stream0)
        del primals_735
        del primals_738
        del primals_741
        # Source Nodes: [l__mod___stage4_1_fuse_layers_2_0_0_0], Original ATen: [aten.convolution]
        buf1684 = extern_kernels.convolution(buf1505, primals_742, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1684, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf1685 = buf1663; del buf1663  # reuse
        buf1686 = buf1657; del buf1657  # reuse
        buf1688 = reinterpret_tensor(buf1652, (18, ), (1, ), 0); del buf1652  # reuse
        # Source Nodes: [l__mod___stage4_1_fuse_layers_2_0_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf1684, primals_1723, primals_1724, buf1685, buf1686, buf1688, primals_1723, primals_1724, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1723
        del primals_1724
        buf1689 = empty((8, 18, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_1_fuse_layers_2_0_0_1, l__mod___stage4_1_fuse_layers_2_0_0_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_28.run(buf1684, buf1685, buf1686, primals_743, primals_744, buf1689, 112896, grid=grid(112896), stream=stream0)
        del primals_744
        # Source Nodes: [l__mod___stage4_1_fuse_layers_2_0_1_0], Original ATen: [aten.convolution]
        buf1690 = extern_kernels.convolution(buf1689, primals_745, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1690, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1691 = buf1598; del buf1598  # reuse
        buf1692 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1694 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_64], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1690, primals_1726, primals_1727, buf1691, buf1692, buf1694, primals_1726, primals_1727, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1726
        del primals_1727
        # Source Nodes: [l__mod___stage4_1_fuse_layers_2_1_0_0], Original ATen: [aten.convolution]
        buf1695 = extern_kernels.convolution(buf1553, primals_748, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1695, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1696 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1697 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1699 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_1_fuse_layers_2_1_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1695, primals_1729, primals_1730, buf1696, buf1697, buf1699, primals_1729, primals_1730, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1729
        del primals_1730
        # Source Nodes: [l__mod___stage4_1_fuse_layers_2_3_0], Original ATen: [aten.convolution]
        buf1701 = extern_kernels.convolution(buf1649, primals_751, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1701, (8, 72, 7, 7), (3528, 49, 7, 1))
        buf1702 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1703 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1705 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_1_fuse_layers_2_3_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_39.run(buf1701, primals_1732, primals_1733, buf1702, buf1703, buf1705, primals_1732, primals_1733, 72, 392, grid=grid(72), stream=stream0)
        del primals_1732
        del primals_1733
        buf1700 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        buf1706 = buf1700; del buf1700  # reuse
        buf1707 = buf1706; del buf1706  # reuse
        # Source Nodes: [l__mod___stage4_1_fuse_layers_2_1_0_1, l__mod___stage4_1_fuse_layers_2_3_1, l__mod___stage4_1_fuse_layers_2_3_2, shortcut_101, y_64, y_65, y_66, y_67], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_41.run(buf1707, buf1690, buf1691, buf1692, primals_746, primals_747, buf1695, buf1696, buf1697, primals_749, primals_750, buf1601, buf1396, buf1701, buf1702, buf1703, primals_752, primals_753, 112896, grid=grid(112896), stream=stream0)
        del primals_747
        del primals_750
        del primals_753
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_0_0_0], Original ATen: [aten.convolution]
        buf1708 = extern_kernels.convolution(buf1505, primals_754, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1708, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf1709 = buf1686; del buf1686  # reuse
        buf1710 = buf1502; del buf1502  # reuse
        buf1712 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_0_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf1708, primals_1735, primals_1736, buf1709, buf1710, buf1712, primals_1735, primals_1736, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1735
        del primals_1736
        buf1713 = empty((8, 18, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_0_0_1, l__mod___stage4_1_fuse_layers_3_0_0_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_28.run(buf1708, buf1709, buf1710, primals_755, primals_756, buf1713, 112896, grid=grid(112896), stream=stream0)
        del primals_756
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_0_1_0], Original ATen: [aten.convolution]
        buf1714 = extern_kernels.convolution(buf1713, primals_757, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1714, (8, 18, 14, 14), (3528, 196, 14, 1))
        buf1715 = buf1710; del buf1710  # reuse
        buf1716 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1718 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_0_1_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_22.run(buf1714, primals_1738, primals_1739, buf1715, buf1716, buf1718, primals_1738, primals_1739, 18, 1568, grid=grid(18), stream=stream0)
        del primals_1738
        del primals_1739
        buf1719 = empty((8, 18, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_0_1_1, l__mod___stage4_1_fuse_layers_3_0_1_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_42.run(buf1714, buf1715, buf1716, primals_758, primals_759, buf1719, 28224, grid=grid(28224), stream=stream0)
        del primals_759
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_0_2_0], Original ATen: [aten.convolution]
        buf1720 = extern_kernels.convolution(buf1719, primals_760, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1720, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1721 = buf1646; del buf1646  # reuse
        buf1722 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1724 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_68], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1720, primals_1741, primals_1742, buf1721, buf1722, buf1724, primals_1741, primals_1742, 144, 392, grid=grid(144), stream=stream0)
        del primals_1741
        del primals_1742
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_1_0_0], Original ATen: [aten.convolution]
        buf1725 = extern_kernels.convolution(buf1553, primals_763, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1725, (8, 36, 14, 14), (7056, 196, 14, 1))
        buf1726 = buf1680; del buf1680  # reuse
        buf1727 = buf1674; del buf1674  # reuse
        buf1729 = reinterpret_tensor(buf1669, (36, ), (1, ), 0); del buf1669  # reuse
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_1_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_25.run(buf1725, primals_1744, primals_1745, buf1726, buf1727, buf1729, primals_1744, primals_1745, 36, 1568, grid=grid(36), stream=stream0)
        del primals_1744
        del primals_1745
        buf1730 = empty((8, 36, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_1_0_1, l__mod___stage4_1_fuse_layers_3_1_0_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_43.run(buf1725, buf1726, buf1727, primals_764, primals_765, buf1730, 56448, grid=grid(56448), stream=stream0)
        del primals_765
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_1_1_0], Original ATen: [aten.convolution]
        buf1731 = extern_kernels.convolution(buf1730, primals_766, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1731, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1732 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1733 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1735 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_1_1_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1731, primals_1747, primals_1748, buf1732, buf1733, buf1735, primals_1747, primals_1748, 144, 392, grid=grid(144), stream=stream0)
        del primals_1747
        del primals_1748
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_2_0_0], Original ATen: [aten.convolution]
        buf1737 = extern_kernels.convolution(buf1601, primals_769, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1737, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1738 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1739 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1741 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_2_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1737, primals_1750, primals_1751, buf1738, buf1739, buf1741, primals_1750, primals_1751, 144, 392, grid=grid(144), stream=stream0)
        del primals_1750
        del primals_1751
        buf1736 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        buf1742 = buf1736; del buf1736  # reuse
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_1_1_1, l__mod___stage4_1_fuse_layers_3_2_0_1, shortcut_105, y_68, y_69, y_70, y_71], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_44.run(buf1742, buf1720, buf1721, buf1722, primals_761, primals_762, buf1731, buf1732, buf1733, primals_767, primals_768, buf1737, buf1738, buf1739, primals_770, primals_771, buf1649, 56448, grid=grid(56448), stream=stream0)
        del primals_762
        del primals_768
        del primals_771
        # Source Nodes: [x_846], Original ATen: [aten.convolution]
        buf1743 = extern_kernels.convolution(buf1666, primals_772, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1743, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1744 = reinterpret_tensor(buf1703, (1, 18, 1, 1, 4), (72, 1, 72, 72, 18), 0); del buf1703  # reuse
        buf1745 = reinterpret_tensor(buf1697, (1, 18, 1, 1, 4), (72, 1, 72, 72, 18), 0); del buf1697  # reuse
        buf1746 = reinterpret_tensor(buf1692, (1, 18, 1, 1, 4), (72, 1, 72, 72, 18), 0); del buf1692  # reuse
        # Source Nodes: [x_847], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1743, buf1744, buf1745, buf1746, 72, 6272, grid=grid(72), stream=stream0)
        buf1747 = buf1716; del buf1716  # reuse
        buf1748 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1750 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_847], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1744, buf1745, buf1746, primals_1753, primals_1754, buf1747, buf1748, buf1750, primals_1753, primals_1754, 18, 4, grid=grid(18), stream=stream0)
        del primals_1753
        del primals_1754
        buf1751 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_847, x_849], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf1743, buf1747, buf1748, primals_773, primals_774, buf1751, 451584, grid=grid(451584), stream=stream0)
        del primals_774
        # Source Nodes: [x_851], Original ATen: [aten.convolution]
        buf1752 = extern_kernels.convolution(buf1751, primals_775, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1752, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1753 = buf1746; del buf1746  # reuse
        buf1754 = buf1745; del buf1745  # reuse
        buf1755 = buf1744; del buf1744  # reuse
        # Source Nodes: [x_852], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1752, buf1753, buf1754, buf1755, 72, 6272, grid=grid(72), stream=stream0)
        buf1756 = buf1748; del buf1748  # reuse
        buf1757 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1759 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_852], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1753, buf1754, buf1755, primals_1756, primals_1757, buf1756, buf1757, buf1759, primals_1756, primals_1757, 18, 4, grid=grid(18), stream=stream0)
        del primals_1756
        del primals_1757
        buf1760 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_94, x_852, x_853], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf1752, buf1756, buf1757, primals_776, primals_777, buf1666, buf1760, 451584, grid=grid(451584), stream=stream0)
        del primals_777
        # Source Nodes: [x_855], Original ATen: [aten.convolution]
        buf1761 = extern_kernels.convolution(buf1760, primals_778, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1761, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1762 = buf1755; del buf1755  # reuse
        buf1763 = buf1754; del buf1754  # reuse
        buf1764 = buf1753; del buf1753  # reuse
        # Source Nodes: [x_856], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1761, buf1762, buf1763, buf1764, 72, 6272, grid=grid(72), stream=stream0)
        buf1765 = buf1757; del buf1757  # reuse
        buf1766 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1768 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_856], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1762, buf1763, buf1764, primals_1759, primals_1760, buf1765, buf1766, buf1768, primals_1759, primals_1760, 18, 4, grid=grid(18), stream=stream0)
        del primals_1759
        del primals_1760
        buf1769 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_856, x_858], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf1761, buf1765, buf1766, primals_779, primals_780, buf1769, 451584, grid=grid(451584), stream=stream0)
        del primals_780
        # Source Nodes: [x_860], Original ATen: [aten.convolution]
        buf1770 = extern_kernels.convolution(buf1769, primals_781, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1770, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1771 = buf1764; del buf1764  # reuse
        buf1772 = buf1763; del buf1763  # reuse
        buf1773 = buf1762; del buf1762  # reuse
        # Source Nodes: [x_861], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1770, buf1771, buf1772, buf1773, 72, 6272, grid=grid(72), stream=stream0)
        buf1774 = buf1766; del buf1766  # reuse
        buf1775 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1777 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_861], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1771, buf1772, buf1773, primals_1762, primals_1763, buf1774, buf1775, buf1777, primals_1762, primals_1763, 18, 4, grid=grid(18), stream=stream0)
        del primals_1762
        del primals_1763
        buf1778 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_95, x_861, x_862], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf1770, buf1774, buf1775, primals_782, primals_783, buf1760, buf1778, 451584, grid=grid(451584), stream=stream0)
        del primals_783
        # Source Nodes: [x_864], Original ATen: [aten.convolution]
        buf1779 = extern_kernels.convolution(buf1778, primals_784, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1779, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1780 = buf1773; del buf1773  # reuse
        buf1781 = buf1772; del buf1772  # reuse
        buf1782 = buf1771; del buf1771  # reuse
        # Source Nodes: [x_865], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1779, buf1780, buf1781, buf1782, 72, 6272, grid=grid(72), stream=stream0)
        buf1783 = buf1775; del buf1775  # reuse
        buf1784 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1786 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_865], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1780, buf1781, buf1782, primals_1765, primals_1766, buf1783, buf1784, buf1786, primals_1765, primals_1766, 18, 4, grid=grid(18), stream=stream0)
        del primals_1765
        del primals_1766
        buf1787 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_865, x_867], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf1779, buf1783, buf1784, primals_785, primals_786, buf1787, 451584, grid=grid(451584), stream=stream0)
        del primals_786
        # Source Nodes: [x_869], Original ATen: [aten.convolution]
        buf1788 = extern_kernels.convolution(buf1787, primals_787, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1788, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1789 = buf1782; del buf1782  # reuse
        buf1790 = buf1781; del buf1781  # reuse
        buf1791 = buf1780; del buf1780  # reuse
        # Source Nodes: [x_870], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1788, buf1789, buf1790, buf1791, 72, 6272, grid=grid(72), stream=stream0)
        buf1792 = buf1784; del buf1784  # reuse
        buf1793 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1795 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_870], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1789, buf1790, buf1791, primals_1768, primals_1769, buf1792, buf1793, buf1795, primals_1768, primals_1769, 18, 4, grid=grid(18), stream=stream0)
        del primals_1768
        del primals_1769
        buf1796 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_96, x_870, x_871], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_14.run(buf1788, buf1792, buf1793, primals_788, primals_789, buf1778, buf1796, 451584, grid=grid(451584), stream=stream0)
        del primals_789
        # Source Nodes: [x_873], Original ATen: [aten.convolution]
        buf1797 = extern_kernels.convolution(buf1796, primals_790, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1797, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1798 = buf1791; del buf1791  # reuse
        buf1799 = buf1790; del buf1790  # reuse
        buf1800 = buf1789; del buf1789  # reuse
        # Source Nodes: [x_874], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1797, buf1798, buf1799, buf1800, 72, 6272, grid=grid(72), stream=stream0)
        buf1801 = buf1793; del buf1793  # reuse
        buf1802 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1804 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_874], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1798, buf1799, buf1800, primals_1771, primals_1772, buf1801, buf1802, buf1804, primals_1771, primals_1772, 18, 4, grid=grid(18), stream=stream0)
        del primals_1771
        del primals_1772
        buf1805 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_874, x_876], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_11.run(buf1797, buf1801, buf1802, primals_791, primals_792, buf1805, 451584, grid=grid(451584), stream=stream0)
        del primals_792
        # Source Nodes: [x_878], Original ATen: [aten.convolution]
        buf1806 = extern_kernels.convolution(buf1805, primals_793, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1806, (8, 18, 56, 56), (56448, 3136, 56, 1))
        buf1807 = buf1800; del buf1800  # reuse
        buf1808 = buf1799; del buf1799  # reuse
        buf1809 = buf1798; del buf1798  # reuse
        # Source Nodes: [x_879], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_9.run(buf1806, buf1807, buf1808, buf1809, 72, 6272, grid=grid(72), stream=stream0)
        buf1810 = buf1802; del buf1802  # reuse
        buf1811 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1813 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_879], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_10.run(buf1807, buf1808, buf1809, primals_1774, primals_1775, buf1810, buf1811, buf1813, primals_1774, primals_1775, 18, 4, grid=grid(18), stream=stream0)
        del primals_1774
        del primals_1775
        # Source Nodes: [x_882], Original ATen: [aten.convolution]
        buf1815 = extern_kernels.convolution(buf1683, primals_796, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1815, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1816 = buf1727; del buf1727  # reuse
        buf1817 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1819 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_883], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1815, primals_1777, primals_1778, buf1816, buf1817, buf1819, primals_1777, primals_1778, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1777
        del primals_1778
        buf1820 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_883, x_885], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf1815, buf1816, buf1817, primals_797, primals_798, buf1820, 225792, grid=grid(225792), stream=stream0)
        del primals_798
        # Source Nodes: [x_887], Original ATen: [aten.convolution]
        buf1821 = extern_kernels.convolution(buf1820, primals_799, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1821, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1822 = buf1817; del buf1817  # reuse
        buf1823 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1825 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_888], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1821, primals_1780, primals_1781, buf1822, buf1823, buf1825, primals_1780, primals_1781, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1780
        del primals_1781
        buf1826 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_98, x_888, x_889], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf1821, buf1822, buf1823, primals_800, primals_801, buf1683, buf1826, 225792, grid=grid(225792), stream=stream0)
        del primals_801
        # Source Nodes: [x_891], Original ATen: [aten.convolution]
        buf1827 = extern_kernels.convolution(buf1826, primals_802, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1827, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1828 = buf1823; del buf1823  # reuse
        buf1829 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1831 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_892], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1827, primals_1783, primals_1784, buf1828, buf1829, buf1831, primals_1783, primals_1784, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1783
        del primals_1784
        buf1832 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_892, x_894], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf1827, buf1828, buf1829, primals_803, primals_804, buf1832, 225792, grid=grid(225792), stream=stream0)
        del primals_804
        # Source Nodes: [x_896], Original ATen: [aten.convolution]
        buf1833 = extern_kernels.convolution(buf1832, primals_805, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1833, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1834 = buf1829; del buf1829  # reuse
        buf1835 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1837 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_897], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1833, primals_1786, primals_1787, buf1834, buf1835, buf1837, primals_1786, primals_1787, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1786
        del primals_1787
        buf1838 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_99, x_897, x_898], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf1833, buf1834, buf1835, primals_806, primals_807, buf1826, buf1838, 225792, grid=grid(225792), stream=stream0)
        del primals_807
        # Source Nodes: [x_900], Original ATen: [aten.convolution]
        buf1839 = extern_kernels.convolution(buf1838, primals_808, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1839, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1840 = buf1835; del buf1835  # reuse
        buf1841 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1843 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_901], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1839, primals_1789, primals_1790, buf1840, buf1841, buf1843, primals_1789, primals_1790, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1789
        del primals_1790
        buf1844 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_901, x_903], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf1839, buf1840, buf1841, primals_809, primals_810, buf1844, 225792, grid=grid(225792), stream=stream0)
        del primals_810
        # Source Nodes: [x_905], Original ATen: [aten.convolution]
        buf1845 = extern_kernels.convolution(buf1844, primals_811, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1845, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1846 = buf1841; del buf1841  # reuse
        buf1847 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1849 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_906], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1845, primals_1792, primals_1793, buf1846, buf1847, buf1849, primals_1792, primals_1793, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1792
        del primals_1793
        buf1850 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_100, x_906, x_907], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf1845, buf1846, buf1847, primals_812, primals_813, buf1838, buf1850, 225792, grid=grid(225792), stream=stream0)
        del primals_813
        # Source Nodes: [x_909], Original ATen: [aten.convolution]
        buf1851 = extern_kernels.convolution(buf1850, primals_814, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1851, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1852 = buf1847; del buf1847  # reuse
        buf1853 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1855 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_910], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1851, primals_1795, primals_1796, buf1852, buf1853, buf1855, primals_1795, primals_1796, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1795
        del primals_1796
        buf1856 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_910, x_912], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_13.run(buf1851, buf1852, buf1853, primals_815, primals_816, buf1856, 225792, grid=grid(225792), stream=stream0)
        del primals_816
        # Source Nodes: [x_914], Original ATen: [aten.convolution]
        buf1857 = extern_kernels.convolution(buf1856, primals_817, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1857, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1858 = buf1853; del buf1853  # reuse
        buf1859 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1861 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_915], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1857, primals_1798, primals_1799, buf1858, buf1859, buf1861, primals_1798, primals_1799, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1798
        del primals_1799
        buf1862 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_915, x_916, x_917], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf1857, buf1858, buf1859, primals_818, primals_819, buf1850, buf1862, 225792, grid=grid(225792), stream=stream0)
        del primals_819
        # Source Nodes: [l__mod___stage4_2_fuse_layers_0_1_0], Original ATen: [aten.convolution]
        buf1959 = extern_kernels.convolution(buf1862, primals_868, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1959, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf1960 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1961 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1963 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_2_fuse_layers_0_1_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf1959, primals_1849, primals_1850, buf1960, buf1961, buf1963, primals_1849, primals_1850, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1849
        del primals_1850
        # Source Nodes: [x_918], Original ATen: [aten.convolution]
        buf1863 = extern_kernels.convolution(buf1707, primals_820, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1863, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1864 = reinterpret_tensor(buf1809, (1, 72, 1, 1), (72, 1, 72, 72), 0); del buf1809  # reuse
        buf1865 = reinterpret_tensor(buf1808, (1, 72, 1, 1), (72, 1, 72, 72), 0); del buf1808  # reuse
        buf1867 = reinterpret_tensor(buf1807, (72, ), (1, ), 0); del buf1807  # reuse
        # Source Nodes: [x_919], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1863, primals_1801, primals_1802, buf1864, buf1865, buf1867, primals_1801, primals_1802, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1801
        del primals_1802
        buf1868 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_919, x_921], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf1863, buf1864, buf1865, primals_821, primals_822, buf1868, 112896, grid=grid(112896), stream=stream0)
        del primals_822
        # Source Nodes: [x_923], Original ATen: [aten.convolution]
        buf1869 = extern_kernels.convolution(buf1868, primals_823, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1869, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1870 = buf1865; del buf1865  # reuse
        buf1871 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1873 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_924], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1869, primals_1804, primals_1805, buf1870, buf1871, buf1873, primals_1804, primals_1805, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1804
        del primals_1805
        buf1874 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_102, x_924, x_925], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf1869, buf1870, buf1871, primals_824, primals_825, buf1707, buf1874, 112896, grid=grid(112896), stream=stream0)
        del primals_825
        # Source Nodes: [x_927], Original ATen: [aten.convolution]
        buf1875 = extern_kernels.convolution(buf1874, primals_826, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1875, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1876 = buf1871; del buf1871  # reuse
        buf1877 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1879 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_928], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1875, primals_1807, primals_1808, buf1876, buf1877, buf1879, primals_1807, primals_1808, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1807
        del primals_1808
        buf1880 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_928, x_930], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf1875, buf1876, buf1877, primals_827, primals_828, buf1880, 112896, grid=grid(112896), stream=stream0)
        del primals_828
        # Source Nodes: [x_932], Original ATen: [aten.convolution]
        buf1881 = extern_kernels.convolution(buf1880, primals_829, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1881, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1882 = buf1877; del buf1877  # reuse
        buf1883 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1885 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_933], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1881, primals_1810, primals_1811, buf1882, buf1883, buf1885, primals_1810, primals_1811, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1810
        del primals_1811
        buf1886 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_103, x_933, x_934], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf1881, buf1882, buf1883, primals_830, primals_831, buf1874, buf1886, 112896, grid=grid(112896), stream=stream0)
        del primals_831
        # Source Nodes: [x_936], Original ATen: [aten.convolution]
        buf1887 = extern_kernels.convolution(buf1886, primals_832, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1887, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1888 = buf1883; del buf1883  # reuse
        buf1889 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1891 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_937], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1887, primals_1813, primals_1814, buf1888, buf1889, buf1891, primals_1813, primals_1814, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1813
        del primals_1814
        buf1892 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_937, x_939], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf1887, buf1888, buf1889, primals_833, primals_834, buf1892, 112896, grid=grid(112896), stream=stream0)
        del primals_834
        # Source Nodes: [x_941], Original ATen: [aten.convolution]
        buf1893 = extern_kernels.convolution(buf1892, primals_835, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1893, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1894 = buf1889; del buf1889  # reuse
        buf1895 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1897 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_942], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1893, primals_1816, primals_1817, buf1894, buf1895, buf1897, primals_1816, primals_1817, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1816
        del primals_1817
        buf1898 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_104, x_942, x_943], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf1893, buf1894, buf1895, primals_836, primals_837, buf1886, buf1898, 112896, grid=grid(112896), stream=stream0)
        del primals_837
        # Source Nodes: [x_945], Original ATen: [aten.convolution]
        buf1899 = extern_kernels.convolution(buf1898, primals_838, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1899, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1900 = buf1895; del buf1895  # reuse
        buf1901 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1903 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_946], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1899, primals_1819, primals_1820, buf1900, buf1901, buf1903, primals_1819, primals_1820, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1819
        del primals_1820
        buf1904 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_946, x_948], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_20.run(buf1899, buf1900, buf1901, primals_839, primals_840, buf1904, 112896, grid=grid(112896), stream=stream0)
        del primals_840
        # Source Nodes: [x_950], Original ATen: [aten.convolution]
        buf1905 = extern_kernels.convolution(buf1904, primals_841, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1905, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf1906 = buf1901; del buf1901  # reuse
        buf1907 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf1909 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_951], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1905, primals_1822, primals_1823, buf1906, buf1907, buf1909, primals_1822, primals_1823, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1822
        del primals_1823
        buf1910 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_951, x_952, x_953], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf1905, buf1906, buf1907, primals_842, primals_843, buf1898, buf1910, 112896, grid=grid(112896), stream=stream0)
        del primals_843
        # Source Nodes: [l__mod___stage4_2_fuse_layers_0_2_0], Original ATen: [aten.convolution]
        buf1964 = extern_kernels.convolution(buf1910, primals_871, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1964, (8, 18, 14, 14), (3528, 196, 14, 1))
        buf1965 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1966 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1968 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_2_fuse_layers_0_2_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_22.run(buf1964, primals_1852, primals_1853, buf1965, buf1966, buf1968, primals_1852, primals_1853, 18, 1568, grid=grid(18), stream=stream0)
        del primals_1852
        del primals_1853
        # Source Nodes: [x_954], Original ATen: [aten.convolution]
        buf1911 = extern_kernels.convolution(buf1742, primals_844, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1911, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1912 = buf1739; del buf1739  # reuse
        buf1913 = buf1733; del buf1733  # reuse
        buf1915 = reinterpret_tensor(buf1722, (144, ), (1, ), 0); del buf1722  # reuse
        # Source Nodes: [x_955], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1911, primals_1825, primals_1826, buf1912, buf1913, buf1915, primals_1825, primals_1826, 144, 392, grid=grid(144), stream=stream0)
        del primals_1825
        del primals_1826
        buf1916 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_955, x_957], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_31.run(buf1911, buf1912, buf1913, primals_845, primals_846, buf1916, 56448, grid=grid(56448), stream=stream0)
        del primals_846
        # Source Nodes: [x_959], Original ATen: [aten.convolution]
        buf1917 = extern_kernels.convolution(buf1916, primals_847, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1917, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1918 = buf1913; del buf1913  # reuse
        buf1919 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1921 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_960], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1917, primals_1828, primals_1829, buf1918, buf1919, buf1921, primals_1828, primals_1829, 144, 392, grid=grid(144), stream=stream0)
        del primals_1828
        del primals_1829
        buf1922 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_106, x_960, x_961], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_32.run(buf1917, buf1918, buf1919, primals_848, primals_849, buf1742, buf1922, 56448, grid=grid(56448), stream=stream0)
        del primals_849
        # Source Nodes: [x_963], Original ATen: [aten.convolution]
        buf1923 = extern_kernels.convolution(buf1922, primals_850, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1923, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1924 = buf1919; del buf1919  # reuse
        buf1925 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1927 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_964], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1923, primals_1831, primals_1832, buf1924, buf1925, buf1927, primals_1831, primals_1832, 144, 392, grid=grid(144), stream=stream0)
        del primals_1831
        del primals_1832
        buf1928 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_964, x_966], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_31.run(buf1923, buf1924, buf1925, primals_851, primals_852, buf1928, 56448, grid=grid(56448), stream=stream0)
        del primals_852
        # Source Nodes: [x_968], Original ATen: [aten.convolution]
        buf1929 = extern_kernels.convolution(buf1928, primals_853, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1929, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1930 = buf1925; del buf1925  # reuse
        buf1931 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1933 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_969], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1929, primals_1834, primals_1835, buf1930, buf1931, buf1933, primals_1834, primals_1835, 144, 392, grid=grid(144), stream=stream0)
        del primals_1834
        del primals_1835
        buf1934 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_107, x_969, x_970], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_32.run(buf1929, buf1930, buf1931, primals_854, primals_855, buf1922, buf1934, 56448, grid=grid(56448), stream=stream0)
        del primals_855
        # Source Nodes: [x_972], Original ATen: [aten.convolution]
        buf1935 = extern_kernels.convolution(buf1934, primals_856, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1935, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1936 = buf1931; del buf1931  # reuse
        buf1937 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1939 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_973], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1935, primals_1837, primals_1838, buf1936, buf1937, buf1939, primals_1837, primals_1838, 144, 392, grid=grid(144), stream=stream0)
        del primals_1837
        del primals_1838
        buf1940 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_973, x_975], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_31.run(buf1935, buf1936, buf1937, primals_857, primals_858, buf1940, 56448, grid=grid(56448), stream=stream0)
        del primals_858
        # Source Nodes: [x_977], Original ATen: [aten.convolution]
        buf1941 = extern_kernels.convolution(buf1940, primals_859, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1941, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1942 = buf1937; del buf1937  # reuse
        buf1943 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1945 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_978], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1941, primals_1840, primals_1841, buf1942, buf1943, buf1945, primals_1840, primals_1841, 144, 392, grid=grid(144), stream=stream0)
        del primals_1840
        del primals_1841
        buf1946 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_108, x_978, x_979], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_32.run(buf1941, buf1942, buf1943, primals_860, primals_861, buf1934, buf1946, 56448, grid=grid(56448), stream=stream0)
        del primals_861
        # Source Nodes: [x_981], Original ATen: [aten.convolution]
        buf1947 = extern_kernels.convolution(buf1946, primals_862, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1947, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1948 = buf1943; del buf1943  # reuse
        buf1949 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1951 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_982], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1947, primals_1843, primals_1844, buf1948, buf1949, buf1951, primals_1843, primals_1844, 144, 392, grid=grid(144), stream=stream0)
        del primals_1843
        del primals_1844
        buf1952 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_982, x_984], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_31.run(buf1947, buf1948, buf1949, primals_863, primals_864, buf1952, 56448, grid=grid(56448), stream=stream0)
        del primals_864
        # Source Nodes: [x_986], Original ATen: [aten.convolution]
        buf1953 = extern_kernels.convolution(buf1952, primals_865, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1953, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf1954 = buf1949; del buf1949  # reuse
        buf1955 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf1957 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_987], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf1953, primals_1846, primals_1847, buf1954, buf1955, buf1957, primals_1846, primals_1847, 144, 392, grid=grid(144), stream=stream0)
        del primals_1846
        del primals_1847
        buf1958 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_987, x_988, x_989], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_32.run(buf1953, buf1954, buf1955, primals_866, primals_867, buf1946, buf1958, 56448, grid=grid(56448), stream=stream0)
        del primals_867
        # Source Nodes: [l__mod___stage4_2_fuse_layers_0_3_0], Original ATen: [aten.convolution]
        buf1970 = extern_kernels.convolution(buf1958, primals_874, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1970, (8, 18, 7, 7), (882, 49, 7, 1))
        buf1971 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1972 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf1974 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_2_fuse_layers_0_3_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_33.run(buf1970, primals_1855, primals_1856, buf1971, buf1972, buf1974, primals_1855, primals_1856, 18, 392, grid=grid(18), stream=stream0)
        del primals_1855
        del primals_1856
        buf1814 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        buf1969 = empty((8, 18, 56, 56), device='cuda', dtype=torch.float32)
        buf1975 = buf1969; del buf1969  # reuse
        # Source Nodes: [l__mod___stage4_2_fuse_layers_0_1_1, l__mod___stage4_2_fuse_layers_0_1_2, l__mod___stage4_2_fuse_layers_0_2_1, l__mod___stage4_2_fuse_layers_0_2_2, l__mod___stage4_2_fuse_layers_0_3_1, l__mod___stage4_2_fuse_layers_0_3_2, shortcut_109, x_879, x_880, x_881, y_73, y_74, y_75], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_35.run(buf1975, buf1806, buf1810, buf1811, primals_794, primals_795, buf1796, buf260, buf1959, buf1960, buf1961, primals_869, primals_870, buf452, buf1964, buf1965, buf1966, primals_872, primals_873, buf1354, buf1970, buf1971, buf1972, primals_875, primals_876, buf1814, 451584, grid=grid(451584), stream=stream0)
        del primals_795
        del primals_870
        del primals_873
        del primals_876
        # Source Nodes: [l__mod___stage4_2_fuse_layers_1_0_0_0], Original ATen: [aten.convolution]
        buf1976 = extern_kernels.convolution(buf1814, primals_877, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1976, (8, 36, 28, 28), (28224, 784, 28, 1))
        buf1977 = buf1859; del buf1859  # reuse
        buf1978 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1980 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_76], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_12.run(buf1976, primals_1858, primals_1859, buf1977, buf1978, buf1980, primals_1858, primals_1859, 36, 6272, grid=grid(36), stream=stream0)
        del primals_1858
        del primals_1859
        # Source Nodes: [l__mod___stage4_2_fuse_layers_1_2_0], Original ATen: [aten.convolution]
        buf1981 = extern_kernels.convolution(buf1910, primals_880, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1981, (8, 36, 14, 14), (7056, 196, 14, 1))
        buf1982 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1983 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1985 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_2_fuse_layers_1_2_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_25.run(buf1981, primals_1861, primals_1862, buf1982, buf1983, buf1985, primals_1861, primals_1862, 36, 1568, grid=grid(36), stream=stream0)
        del primals_1861
        del primals_1862
        # Source Nodes: [l__mod___stage4_2_fuse_layers_1_3_0], Original ATen: [aten.convolution]
        buf1987 = extern_kernels.convolution(buf1958, primals_883, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1987, (8, 36, 7, 7), (1764, 49, 7, 1))
        buf1988 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1989 = empty_strided((1, 36, 1, 1), (36, 1, 36, 36), device='cuda', dtype=torch.float32)
        buf1991 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_2_fuse_layers_1_3_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_36.run(buf1987, primals_1864, primals_1865, buf1988, buf1989, buf1991, primals_1864, primals_1865, 36, 392, grid=grid(36), stream=stream0)
        del primals_1864
        del primals_1865
        buf1986 = empty((8, 36, 28, 28), device='cuda', dtype=torch.float32)
        buf1992 = buf1986; del buf1986  # reuse
        # Source Nodes: [l__mod___stage4_2_fuse_layers_1_2_1, l__mod___stage4_2_fuse_layers_1_2_2, l__mod___stage4_2_fuse_layers_1_3_1, l__mod___stage4_2_fuse_layers_1_3_2, shortcut_111, y_76, y_77, y_78, y_79], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_38.run(buf1992, buf1976, buf1977, buf1978, primals_878, primals_879, buf1862, buf465, buf1981, buf1982, buf1983, primals_881, primals_882, buf1372, buf1987, buf1988, buf1989, primals_884, primals_885, 225792, grid=grid(225792), stream=stream0)
        del primals_879
        del primals_882
        del primals_885
        # Source Nodes: [l__mod___stage4_2_fuse_layers_2_0_0_0], Original ATen: [aten.convolution]
        buf1993 = extern_kernels.convolution(buf1814, primals_886, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1993, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf1994 = buf1972; del buf1972  # reuse
        buf1995 = buf1966; del buf1966  # reuse
        buf1997 = reinterpret_tensor(buf1961, (18, ), (1, ), 0); del buf1961  # reuse
        # Source Nodes: [l__mod___stage4_2_fuse_layers_2_0_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf1993, primals_1867, primals_1868, buf1994, buf1995, buf1997, primals_1867, primals_1868, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1867
        del primals_1868
        buf1998 = empty((8, 18, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_2_fuse_layers_2_0_0_1, l__mod___stage4_2_fuse_layers_2_0_0_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_28.run(buf1993, buf1994, buf1995, primals_887, primals_888, buf1998, 112896, grid=grid(112896), stream=stream0)
        del primals_888
        # Source Nodes: [l__mod___stage4_2_fuse_layers_2_0_1_0], Original ATen: [aten.convolution]
        buf1999 = extern_kernels.convolution(buf1998, primals_889, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf1999, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf2000 = buf1907; del buf1907  # reuse
        buf2001 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf2003 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_80], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf1999, primals_1870, primals_1871, buf2000, buf2001, buf2003, primals_1870, primals_1871, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1870
        del primals_1871
        # Source Nodes: [l__mod___stage4_2_fuse_layers_2_1_0_0], Original ATen: [aten.convolution]
        buf2004 = extern_kernels.convolution(buf1862, primals_892, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2004, (8, 72, 14, 14), (14112, 196, 14, 1))
        buf2005 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf2006 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf2008 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_2_fuse_layers_2_1_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_19.run(buf2004, primals_1873, primals_1874, buf2005, buf2006, buf2008, primals_1873, primals_1874, 72, 1568, grid=grid(72), stream=stream0)
        del primals_1873
        del primals_1874
        # Source Nodes: [l__mod___stage4_2_fuse_layers_2_3_0], Original ATen: [aten.convolution]
        buf2010 = extern_kernels.convolution(buf1958, primals_895, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2010, (8, 72, 7, 7), (3528, 49, 7, 1))
        buf2011 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf2012 = empty_strided((1, 72, 1, 1), (72, 1, 72, 72), device='cuda', dtype=torch.float32)
        buf2014 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_2_fuse_layers_2_3_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_39.run(buf2010, primals_1876, primals_1877, buf2011, buf2012, buf2014, primals_1876, primals_1877, 72, 392, grid=grid(72), stream=stream0)
        del primals_1876
        del primals_1877
        buf2009 = empty((8, 72, 14, 14), device='cuda', dtype=torch.float32)
        buf2015 = buf2009; del buf2009  # reuse
        buf2016 = buf2015; del buf2015  # reuse
        # Source Nodes: [l__mod___stage4_2_fuse_layers_2_1_0_1, l__mod___stage4_2_fuse_layers_2_3_1, l__mod___stage4_2_fuse_layers_2_3_2, shortcut_113, y_80, y_81, y_82, y_83], Original ATen: [aten._native_batch_norm_legit_functional, aten._unsafe_index, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional__unsafe_index_add_relu_41.run(buf2016, buf1999, buf2000, buf2001, primals_890, primals_891, buf2004, buf2005, buf2006, primals_893, primals_894, buf1910, buf1396, buf2010, buf2011, buf2012, primals_896, primals_897, 112896, grid=grid(112896), stream=stream0)
        del buf2001
        del buf2006
        del buf2012
        del primals_891
        del primals_894
        del primals_897
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_0_0_0], Original ATen: [aten.convolution]
        buf2017 = extern_kernels.convolution(buf1814, primals_898, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2017, (8, 18, 28, 28), (14112, 784, 28, 1))
        buf2018 = buf1995; del buf1995  # reuse
        buf2019 = buf1811; del buf1811  # reuse
        buf2021 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_0_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_16.run(buf2017, primals_1879, primals_1880, buf2018, buf2019, buf2021, primals_1879, primals_1880, 18, 6272, grid=grid(18), stream=stream0)
        del primals_1879
        del primals_1880
        buf2022 = empty((8, 18, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_0_0_1, l__mod___stage4_2_fuse_layers_3_0_0_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_28.run(buf2017, buf2018, buf2019, primals_899, primals_900, buf2022, 112896, grid=grid(112896), stream=stream0)
        del primals_900
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_0_1_0], Original ATen: [aten.convolution]
        buf2023 = extern_kernels.convolution(buf2022, primals_901, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2023, (8, 18, 14, 14), (3528, 196, 14, 1))
        buf2024 = buf2019; del buf2019  # reuse
        buf2025 = empty_strided((1, 18, 1, 1), (18, 1, 18, 18), device='cuda', dtype=torch.float32)
        buf2027 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_0_1_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_22.run(buf2023, primals_1882, primals_1883, buf2024, buf2025, buf2027, primals_1882, primals_1883, 18, 1568, grid=grid(18), stream=stream0)
        del primals_1882
        del primals_1883
        buf2028 = empty((8, 18, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_0_1_1, l__mod___stage4_2_fuse_layers_3_0_1_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_42.run(buf2023, buf2024, buf2025, primals_902, primals_903, buf2028, 28224, grid=grid(28224), stream=stream0)
        del buf2025
        del primals_903
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_0_2_0], Original ATen: [aten.convolution]
        buf2029 = extern_kernels.convolution(buf2028, primals_904, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2029, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf2030 = buf1955; del buf1955  # reuse
        buf2031 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf2033 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [y_84], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf2029, primals_1885, primals_1886, buf2030, buf2031, buf2033, primals_1885, primals_1886, 144, 392, grid=grid(144), stream=stream0)
        del primals_1885
        del primals_1886
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_1_0_0], Original ATen: [aten.convolution]
        buf2034 = extern_kernels.convolution(buf1862, primals_907, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2034, (8, 36, 14, 14), (7056, 196, 14, 1))
        buf2035 = buf1989; del buf1989  # reuse
        buf2036 = buf1983; del buf1983  # reuse
        buf2038 = reinterpret_tensor(buf1978, (36, ), (1, ), 0); del buf1978  # reuse
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_1_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_25.run(buf2034, primals_1888, primals_1889, buf2035, buf2036, buf2038, primals_1888, primals_1889, 36, 1568, grid=grid(36), stream=stream0)
        del primals_1888
        del primals_1889
        buf2039 = empty((8, 36, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_1_0_1, l__mod___stage4_2_fuse_layers_3_1_0_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_43.run(buf2034, buf2035, buf2036, primals_908, primals_909, buf2039, 56448, grid=grid(56448), stream=stream0)
        del buf2036
        del primals_909
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_1_1_0], Original ATen: [aten.convolution]
        buf2040 = extern_kernels.convolution(buf2039, primals_910, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2040, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf2041 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf2042 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf2044 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_1_1_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf2040, primals_1891, primals_1892, buf2041, buf2042, buf2044, primals_1891, primals_1892, 144, 392, grid=grid(144), stream=stream0)
        del primals_1891
        del primals_1892
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_2_0_0], Original ATen: [aten.convolution]
        buf2046 = extern_kernels.convolution(buf1910, primals_913, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2046, (8, 144, 7, 7), (7056, 49, 7, 1))
        buf2047 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf2048 = empty_strided((1, 144, 1, 1), (144, 1, 144, 144), device='cuda', dtype=torch.float32)
        buf2050 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_2_0_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_30.run(buf2046, primals_1894, primals_1895, buf2047, buf2048, buf2050, primals_1894, primals_1895, 144, 392, grid=grid(144), stream=stream0)
        del primals_1894
        del primals_1895
        buf2045 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        buf2051 = buf2045; del buf2045  # reuse
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_1_1_1, l__mod___stage4_2_fuse_layers_3_2_0_1, shortcut_115, y_84, y_85, y_86, y_87], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_44.run(buf2051, buf2029, buf2030, buf2031, primals_905, primals_906, buf2040, buf2041, buf2042, primals_911, primals_912, buf2046, buf2047, buf2048, primals_914, primals_915, buf1958, 56448, grid=grid(56448), stream=stream0)
        del buf2031
        del buf2042
        del buf2048
        del primals_906
        del primals_912
        del primals_915
        # Source Nodes: [x_990], Original ATen: [aten.convolution]
        buf2052 = extern_kernels.convolution(buf1975, primals_916, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2052, (8, 32, 56, 56), (100352, 3136, 56, 1))
        buf2053 = empty_strided((1, 32, 1, 1, 4), (128, 1, 128, 128, 32), device='cuda', dtype=torch.float32)
        buf2054 = empty_strided((1, 32, 1, 1, 4), (128, 1, 128, 128, 32), device='cuda', dtype=torch.float32)
        buf2055 = empty_strided((1, 32, 1, 1, 4), (128, 1, 128, 128, 32), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_991], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_45.run(buf2052, buf2053, buf2054, buf2055, 128, 6272, grid=grid(128), stream=stream0)
        buf2056 = empty_strided((1, 32, 1, 1), (32, 1, 32, 32), device='cuda', dtype=torch.float32)
        buf2057 = empty_strided((1, 32, 1, 1), (32, 1, 32, 32), device='cuda', dtype=torch.float32)
        buf2059 = empty((32, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_991], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_46.run(buf2053, buf2054, buf2055, primals_1897, primals_1898, buf2056, buf2057, buf2059, primals_1897, primals_1898, 32, 4, grid=grid(32), stream=stream0)
        del primals_1897
        del primals_1898
        buf2060 = empty((8, 32, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_991, x_992], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_47.run(buf2052, buf2056, buf2057, primals_917, primals_918, buf2060, 802816, grid=grid(802816), stream=stream0)
        del primals_918
        # Source Nodes: [x_993], Original ATen: [aten.convolution]
        buf2061 = extern_kernels.convolution(buf2060, primals_919, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2061, (8, 32, 56, 56), (100352, 3136, 56, 1))
        buf2062 = buf2055; del buf2055  # reuse
        buf2063 = buf2054; del buf2054  # reuse
        buf2064 = buf2053; del buf2053  # reuse
        # Source Nodes: [x_994], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_45.run(buf2061, buf2062, buf2063, buf2064, 128, 6272, grid=grid(128), stream=stream0)
        buf2065 = buf2057; del buf2057  # reuse
        buf2066 = empty_strided((1, 32, 1, 1), (32, 1, 32, 32), device='cuda', dtype=torch.float32)
        buf2068 = empty((32, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_994], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_46.run(buf2062, buf2063, buf2064, primals_1900, primals_1901, buf2065, buf2066, buf2068, primals_1900, primals_1901, 32, 4, grid=grid(32), stream=stream0)
        del primals_1900
        del primals_1901
        buf2069 = empty((8, 32, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_994, x_996], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_47.run(buf2061, buf2065, buf2066, primals_920, primals_921, buf2069, 802816, grid=grid(802816), stream=stream0)
        del buf2066
        del primals_921
        # Source Nodes: [x_998], Original ATen: [aten.convolution]
        buf2070 = extern_kernels.convolution(buf2069, primals_922, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2070, (8, 128, 56, 56), (401408, 3136, 56, 1))
        buf2071 = empty_strided((1, 128, 1, 1, 4), (512, 1, 512, 512, 128), device='cuda', dtype=torch.float32)
        buf2072 = empty_strided((1, 128, 1, 1, 4), (512, 1, 512, 512, 128), device='cuda', dtype=torch.float32)
        buf2073 = empty_strided((1, 128, 1, 1, 4), (512, 1, 512, 512, 128), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_999], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_48.run(buf2070, buf2071, buf2072, buf2073, 512, 6272, grid=grid(512), stream=stream0)
        buf2074 = reinterpret_tensor(buf2064, (1, 128, 1, 1), (128, 1, 128, 128), 0); del buf2064  # reuse
        buf2075 = reinterpret_tensor(buf2063, (1, 128, 1, 1), (128, 1, 128, 128), 0); del buf2063  # reuse
        buf2077 = reinterpret_tensor(buf2062, (128, ), (1, ), 0); del buf2062  # reuse
        # Source Nodes: [x_999], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_49.run(buf2071, buf2072, buf2073, primals_1903, primals_1904, buf2074, buf2075, buf2077, primals_1903, primals_1904, 128, 4, grid=grid(128), stream=stream0)
        del primals_1903
        del primals_1904
        # Source Nodes: [getattr_l__mod___incre_modules_0___0___downsample_0], Original ATen: [aten.convolution]
        buf2078 = extern_kernels.convolution(buf1975, primals_925, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2078, (8, 128, 56, 56), (401408, 3136, 56, 1))
        buf2079 = buf2073; del buf2073  # reuse
        buf2080 = buf2072; del buf2072  # reuse
        buf2081 = buf2071; del buf2071  # reuse
        # Source Nodes: [shortcut_110], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_48.run(buf2078, buf2079, buf2080, buf2081, 512, 6272, grid=grid(512), stream=stream0)
        buf2082 = empty_strided((1, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)
        buf2083 = empty_strided((1, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)
        buf2085 = empty((128, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_110], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_49.run(buf2079, buf2080, buf2081, primals_1906, primals_1907, buf2082, buf2083, buf2085, primals_1906, primals_1907, 128, 4, grid=grid(128), stream=stream0)
        del primals_1906
        del primals_1907
        buf2086 = empty((8, 128, 56, 56), device='cuda', dtype=torch.float32)
        buf2087 = buf2086; del buf2086  # reuse
        # Source Nodes: [shortcut_110, x_1000, x_999, y_88], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_50.run(buf2087, buf2070, buf2074, buf2075, primals_923, primals_924, buf2078, buf2082, buf2083, primals_926, primals_927, 3211264, grid=grid(3211264), stream=stream0)
        del primals_924
        del primals_927
        # Source Nodes: [x_1002], Original ATen: [aten.convolution]
        buf2088 = extern_kernels.convolution(buf1992, primals_928, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2088, (8, 64, 28, 28), (50176, 784, 28, 1))
        buf2089 = buf110; del buf110  # reuse
        buf2090 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
        buf2092 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1003], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_51.run(buf2088, primals_1909, primals_1910, buf2089, buf2090, buf2092, primals_1909, primals_1910, 64, 6272, grid=grid(64), stream=stream0)
        del primals_1909
        del primals_1910
        buf2093 = empty((8, 64, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1003, x_1004], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_52.run(buf2088, buf2089, buf2090, primals_929, primals_930, buf2093, 401408, grid=grid(401408), stream=stream0)
        del primals_930
        # Source Nodes: [x_1005], Original ATen: [aten.convolution]
        buf2094 = extern_kernels.convolution(buf2093, primals_931, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2094, (8, 64, 28, 28), (50176, 784, 28, 1))
        buf2095 = buf2090; del buf2090  # reuse
        buf2096 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
        buf2098 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1006], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_51.run(buf2094, primals_1912, primals_1913, buf2095, buf2096, buf2098, primals_1912, primals_1913, 64, 6272, grid=grid(64), stream=stream0)
        del primals_1912
        del primals_1913
        buf2099 = empty((8, 64, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1006, x_1008], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_52.run(buf2094, buf2095, buf2096, primals_932, primals_933, buf2099, 401408, grid=grid(401408), stream=stream0)
        del buf2096
        del primals_933
        # Source Nodes: [x_1010], Original ATen: [aten.convolution]
        buf2100 = extern_kernels.convolution(buf2099, primals_934, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2100, (8, 256, 28, 28), (200704, 784, 28, 1))
        buf2101 = buf116; del buf116  # reuse
        buf2102 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
        buf2104 = empty((256, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1011], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_53.run(buf2100, primals_1915, primals_1916, buf2101, buf2102, buf2104, primals_1915, primals_1916, 256, 6272, grid=grid(256), stream=stream0)
        del primals_1915
        del primals_1916
        # Source Nodes: [getattr_l__mod___incre_modules_1___0___downsample_0], Original ATen: [aten.convolution]
        buf2105 = extern_kernels.convolution(buf1992, primals_937, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2105, (8, 256, 28, 28), (200704, 784, 28, 1))
        buf2106 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
        buf2107 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
        buf2109 = empty((256, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_112], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_53.run(buf2105, primals_1918, primals_1919, buf2106, buf2107, buf2109, primals_1918, primals_1919, 256, 6272, grid=grid(256), stream=stream0)
        del primals_1918
        del primals_1919
        # Source Nodes: [forward], Original ATen: [aten.convolution]
        buf2111 = extern_kernels.convolution(buf2087, primals_940, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2111, (8, 256, 28, 28), (200704, 784, 28, 1))
        buf2112 = buf2111; del buf2111  # reuse
        # Source Nodes: [forward], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_54.run(buf2112, primals_941, 1605632, grid=grid(1605632), stream=stream0)
        del primals_941
        buf2113 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
        buf2114 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
        buf2116 = empty((256, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [forward], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_53.run(buf2112, primals_1921, primals_1922, buf2113, buf2114, buf2116, primals_1921, primals_1922, 256, 6272, grid=grid(256), stream=stream0)
        del primals_1921
        del primals_1922
        buf2118 = empty((8, 256, 28, 28), device='cuda', dtype=torch.float32)
        buf2196 = empty((8, 256, 28, 28), device='cuda', dtype=torch.bool)
        buf2197 = empty((8, 256, 28, 28), device='cuda', dtype=torch.bool)
        # Source Nodes: [forward, shortcut_112, x_1011, x_1012, x_1013, y_89], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu, aten.threshold_backward]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_threshold_backward_55.run(buf2100, buf2101, buf2102, primals_935, primals_936, buf2105, buf2106, buf2107, primals_938, primals_939, buf2112, buf2113, buf2114, primals_942, primals_943, buf2118, buf2196, buf2197, 1605632, grid=grid(1605632), stream=stream0)
        del primals_936
        del primals_939
        del primals_943
        # Source Nodes: [x_1014], Original ATen: [aten.convolution]
        buf2119 = extern_kernels.convolution(buf2016, primals_944, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2119, (8, 128, 14, 14), (25088, 196, 14, 1))
        buf2120 = buf2083; del buf2083  # reuse
        buf2121 = buf2075; del buf2075  # reuse
        buf2123 = empty((128, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1015], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_56.run(buf2119, primals_1924, primals_1925, buf2120, buf2121, buf2123, primals_1924, primals_1925, 128, 1568, grid=grid(128), stream=stream0)
        del primals_1924
        del primals_1925
        buf2124 = empty((8, 128, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1015, x_1016], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_57.run(buf2119, buf2120, buf2121, primals_945, primals_946, buf2124, 200704, grid=grid(200704), stream=stream0)
        del primals_946
        # Source Nodes: [x_1017], Original ATen: [aten.convolution]
        buf2125 = extern_kernels.convolution(buf2124, primals_947, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2125, (8, 128, 14, 14), (25088, 196, 14, 1))
        buf2126 = buf2121; del buf2121  # reuse
        buf2127 = empty_strided((1, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)
        buf2129 = empty((128, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1018], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_56.run(buf2125, primals_1927, primals_1928, buf2126, buf2127, buf2129, primals_1927, primals_1928, 128, 1568, grid=grid(128), stream=stream0)
        del primals_1927
        del primals_1928
        buf2130 = empty((8, 128, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1018, x_1020], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_57.run(buf2125, buf2126, buf2127, primals_948, primals_949, buf2130, 200704, grid=grid(200704), stream=stream0)
        del buf2127
        del primals_949
        # Source Nodes: [x_1022], Original ATen: [aten.convolution]
        buf2131 = extern_kernels.convolution(buf2130, primals_950, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2131, (8, 512, 14, 14), (100352, 196, 14, 1))
        buf2132 = reinterpret_tensor(buf2081, (1, 512, 1, 1), (512, 1, 512, 512), 0); del buf2081  # reuse
        buf2133 = reinterpret_tensor(buf2080, (1, 512, 1, 1), (512, 1, 512, 512), 0); del buf2080  # reuse
        buf2135 = reinterpret_tensor(buf2079, (512, ), (1, ), 0); del buf2079  # reuse
        # Source Nodes: [x_1023], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_58.run(buf2131, primals_1930, primals_1931, buf2132, buf2133, buf2135, primals_1930, primals_1931, 512, 1568, grid=grid(512), stream=stream0)
        del primals_1930
        del primals_1931
        # Source Nodes: [getattr_l__mod___incre_modules_2___0___downsample_0], Original ATen: [aten.convolution]
        buf2136 = extern_kernels.convolution(buf2016, primals_953, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2136, (8, 512, 14, 14), (100352, 196, 14, 1))
        buf2137 = empty_strided((1, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)
        buf2138 = empty_strided((1, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)
        buf2140 = empty((512, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_114], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_58.run(buf2136, primals_1933, primals_1934, buf2137, buf2138, buf2140, primals_1933, primals_1934, 512, 1568, grid=grid(512), stream=stream0)
        del primals_1933
        del primals_1934
        # Source Nodes: [forward_1], Original ATen: [aten.convolution]
        buf2142 = extern_kernels.convolution(buf2118, primals_956, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2142, (8, 512, 14, 14), (100352, 196, 14, 1))
        buf2143 = buf2142; del buf2142  # reuse
        # Source Nodes: [forward_1], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_59.run(buf2143, primals_957, 802816, grid=grid(802816), stream=stream0)
        del primals_957
        buf2144 = empty_strided((1, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)
        buf2145 = empty_strided((1, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)
        buf2147 = empty((512, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [forward_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_red_fused__native_batch_norm_legit_functional_58.run(buf2143, primals_1936, primals_1937, buf2144, buf2145, buf2147, primals_1936, primals_1937, 512, 1568, grid=grid(512), stream=stream0)
        del primals_1936
        del primals_1937
        buf2149 = empty((8, 512, 14, 14), device='cuda', dtype=torch.float32)
        buf2194 = empty((8, 512, 14, 14), device='cuda', dtype=torch.bool)
        buf2195 = empty((8, 512, 14, 14), device='cuda', dtype=torch.bool)
        # Source Nodes: [forward_1, shortcut_114, x_1023, x_1024, x_1025, y_90], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu, aten.threshold_backward]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_threshold_backward_60.run(buf2131, buf2132, buf2133, primals_951, primals_952, buf2136, buf2137, buf2138, primals_954, primals_955, buf2143, buf2144, buf2145, primals_958, primals_959, buf2149, buf2194, buf2195, 802816, grid=grid(802816), stream=stream0)
        del buf2133
        del buf2138
        del buf2145
        del primals_952
        del primals_955
        del primals_959
        # Source Nodes: [x_1026], Original ATen: [aten.convolution]
        buf2150 = extern_kernels.convolution(buf2051, primals_960, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2150, (8, 256, 7, 7), (12544, 49, 7, 1))
        buf2151 = buf2114; del buf2114  # reuse
        buf2152 = buf2107; del buf2107  # reuse
        buf2154 = reinterpret_tensor(buf2102, (256, ), (1, ), 0); del buf2102  # reuse
        # Source Nodes: [x_1027], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_61.run(buf2150, primals_1939, primals_1940, buf2151, buf2152, buf2154, primals_1939, primals_1940, 256, 392, grid=grid(256), stream=stream0)
        del primals_1939
        del primals_1940
        buf2155 = empty((8, 256, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1027, x_1028], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_62.run(buf2150, buf2151, buf2152, primals_961, primals_962, buf2155, 100352, grid=grid(100352), stream=stream0)
        del primals_962
        # Source Nodes: [x_1029], Original ATen: [aten.convolution]
        buf2156 = extern_kernels.convolution(buf2155, primals_963, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2156, (8, 256, 7, 7), (12544, 49, 7, 1))
        buf2157 = buf2152; del buf2152  # reuse
        buf2158 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
        buf2160 = empty((256, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1030], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_61.run(buf2156, primals_1942, primals_1943, buf2157, buf2158, buf2160, primals_1942, primals_1943, 256, 392, grid=grid(256), stream=stream0)
        del primals_1942
        del primals_1943
        buf2161 = empty((8, 256, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1030, x_1032], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
        triton_poi_fused__native_batch_norm_legit_functional_relu_62.run(buf2156, buf2157, buf2158, primals_964, primals_965, buf2161, 100352, grid=grid(100352), stream=stream0)
        del buf2158
        del primals_965
        # Source Nodes: [x_1034], Original ATen: [aten.convolution]
        buf2162 = extern_kernels.convolution(buf2161, primals_966, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2162, (8, 1024, 7, 7), (50176, 49, 7, 1))
        buf2163 = empty_strided((1, 1024, 1, 1), (1024, 1, 1024, 1024), device='cuda', dtype=torch.float32)
        buf2164 = empty_strided((1, 1024, 1, 1), (1024, 1, 1024, 1024), device='cuda', dtype=torch.float32)
        buf2166 = empty((1024, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [x_1035], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_63.run(buf2162, primals_1945, primals_1946, buf2163, buf2164, buf2166, primals_1945, primals_1946, 1024, 392, grid=grid(1024), stream=stream0)
        del primals_1945
        del primals_1946
        # Source Nodes: [getattr_l__mod___incre_modules_3___0___downsample_0], Original ATen: [aten.convolution]
        buf2167 = extern_kernels.convolution(buf2051, primals_969, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2167, (8, 1024, 7, 7), (50176, 49, 7, 1))
        buf2168 = empty_strided((1, 1024, 1, 1), (1024, 1, 1024, 1024), device='cuda', dtype=torch.float32)
        buf2169 = empty_strided((1, 1024, 1, 1), (1024, 1, 1024, 1024), device='cuda', dtype=torch.float32)
        buf2171 = empty((1024, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [shortcut_116], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_63.run(buf2167, primals_1948, primals_1949, buf2168, buf2169, buf2171, primals_1948, primals_1949, 1024, 392, grid=grid(1024), stream=stream0)
        del primals_1948
        del primals_1949
        # Source Nodes: [forward_2], Original ATen: [aten.convolution]
        buf2173 = extern_kernels.convolution(buf2149, primals_972, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2173, (8, 1024, 7, 7), (50176, 49, 7, 1))
        buf2174 = buf2173; del buf2173  # reuse
        # Source Nodes: [forward_2], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_64.run(buf2174, primals_973, 401408, grid=grid(401408), stream=stream0)
        del primals_973
        buf2175 = empty_strided((1, 1024, 1, 1), (1024, 1, 1024, 1024), device='cuda', dtype=torch.float32)
        buf2176 = empty_strided((1, 1024, 1, 1), (1024, 1, 1024, 1024), device='cuda', dtype=torch.float32)
        buf2178 = empty((1024, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [forward_2], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_63.run(buf2174, primals_1951, primals_1952, buf2175, buf2176, buf2178, primals_1951, primals_1952, 1024, 392, grid=grid(1024), stream=stream0)
        del primals_1951
        del primals_1952
        buf2180 = empty((8, 1024, 7, 7), device='cuda', dtype=torch.float32)
        buf2192 = empty((8, 1024, 7, 7), device='cuda', dtype=torch.bool)
        buf2193 = empty((8, 1024, 7, 7), device='cuda', dtype=torch.bool)
        # Source Nodes: [forward_2, shortcut_116, x_1035, x_1036, x_1037, y_91], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu, aten.threshold_backward]
        triton_poi_fused__native_batch_norm_legit_functional_add_relu_threshold_backward_65.run(buf2162, buf2163, buf2164, primals_967, primals_968, buf2167, buf2168, buf2169, primals_970, primals_971, buf2174, buf2175, buf2176, primals_974, primals_975, buf2180, buf2192, buf2193, 401408, grid=grid(401408), stream=stream0)
        del buf2164
        del buf2169
        del buf2176
        del primals_968
        del primals_971
        del primals_975
        # Source Nodes: [l__mod___final_layer_0], Original ATen: [aten.convolution]
        buf2181 = extern_kernels.convolution(buf2180, primals_976, stride=(1, 1), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
        assert_size_stride(buf2181, (8, 2048, 7, 7), (100352, 49, 7, 1))
        buf2182 = buf2181; del buf2181  # reuse
        # Source Nodes: [l__mod___final_layer_0], Original ATen: [aten.convolution]
        triton_poi_fused_convolution_66.run(buf2182, primals_977, 802816, grid=grid(802816), stream=stream0)
        del primals_977
        buf2183 = empty_strided((1, 2048, 1, 1), (2048, 1, 2048, 2048), device='cuda', dtype=torch.float32)
        buf2184 = empty_strided((1, 2048, 1, 1), (2048, 1, 2048, 2048), device='cuda', dtype=torch.float32)
        buf2186 = empty((2048, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [l__mod___final_layer_1], Original ATen: [aten._native_batch_norm_legit_functional]
        triton_per_fused__native_batch_norm_legit_functional_67.run(buf2182, primals_1954, primals_1955, buf2183, buf2184, buf2186, primals_1954, primals_1955, 2048, 392, grid=grid(2048), stream=stream0)
        del primals_1954
        del primals_1955
        buf2191 = empty((8, 2048, 7, 7), device='cuda', dtype=torch.bool)
        buf2188 = empty_strided((8, 2048, 1, 1), (2048, 1, 16384, 16384), device='cuda', dtype=torch.float32)
        buf2189 = reinterpret_tensor(buf2188, (8, 2048), (2048, 1), 0); del buf2188  # reuse
        # Source Nodes: [l__mod___final_layer_1, x_1038, x_1040, y_93], Original ATen: [aten._native_batch_norm_legit_functional, aten.mean, aten.relu, aten.threshold_backward, aten.view]
        triton_per_fused__native_batch_norm_legit_functional_mean_relu_threshold_backward_view_68.run(buf2189, buf2182, buf2183, buf2184, primals_978, primals_979, buf2191, 16384, 49, grid=grid(16384), stream=stream0)
        del buf2184
        del primals_979
        buf2190 = empty((8, 1000), device='cuda', dtype=torch.float32)
        # Source Nodes: [pred], Original ATen: [aten.addmm]
        extern_kernels.addmm(primals_981, buf2189, reinterpret_tensor(primals_980, (2048, 1000), (1, 2048), 0), alpha=1, beta=1, out=buf2190)
        del primals_981
        # Source Nodes: [x_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_984, primals_984, 1, grid=grid(1), stream=stream0)
        del primals_984
        # Source Nodes: [x_4], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_987, primals_987, 1, grid=grid(1), stream=stream0)
        del primals_987
        # Source Nodes: [x_7], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_990, primals_990, 1, grid=grid(1), stream=stream0)
        del primals_990
        # Source Nodes: [x_10], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_993, primals_993, 1, grid=grid(1), stream=stream0)
        del primals_993
        # Source Nodes: [x_15], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_996, primals_996, 1, grid=grid(1), stream=stream0)
        del primals_996
        # Source Nodes: [shortcut_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_999, primals_999, 1, grid=grid(1), stream=stream0)
        del primals_999
        # Source Nodes: [x_19], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1002, primals_1002, 1, grid=grid(1), stream=stream0)
        del primals_1002
        # Source Nodes: [x_22], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1005, primals_1005, 1, grid=grid(1), stream=stream0)
        del primals_1005
        # Source Nodes: [x_27], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1008, primals_1008, 1, grid=grid(1), stream=stream0)
        del primals_1008
        # Source Nodes: [x_31], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1011, primals_1011, 1, grid=grid(1), stream=stream0)
        del primals_1011
        # Source Nodes: [x_34], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1014, primals_1014, 1, grid=grid(1), stream=stream0)
        del primals_1014
        # Source Nodes: [x_39], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1017, primals_1017, 1, grid=grid(1), stream=stream0)
        del primals_1017
        # Source Nodes: [x_43], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1020, primals_1020, 1, grid=grid(1), stream=stream0)
        del primals_1020
        # Source Nodes: [x_46], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1023, primals_1023, 1, grid=grid(1), stream=stream0)
        del primals_1023
        # Source Nodes: [x_51], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1026, primals_1026, 1, grid=grid(1), stream=stream0)
        del primals_1026
        # Source Nodes: [l__mod___transition1_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1029, primals_1029, 1, grid=grid(1), stream=stream0)
        del primals_1029
        # Source Nodes: [l__mod___transition1_1_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1032, primals_1032, 1, grid=grid(1), stream=stream0)
        del primals_1032
        # Source Nodes: [x_55], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1035, primals_1035, 1, grid=grid(1), stream=stream0)
        del primals_1035
        # Source Nodes: [x_60], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1038, primals_1038, 1, grid=grid(1), stream=stream0)
        del primals_1038
        # Source Nodes: [x_64], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1041, primals_1041, 1, grid=grid(1), stream=stream0)
        del primals_1041
        # Source Nodes: [x_69], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1044, primals_1044, 1, grid=grid(1), stream=stream0)
        del primals_1044
        # Source Nodes: [x_73], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1047, primals_1047, 1, grid=grid(1), stream=stream0)
        del primals_1047
        # Source Nodes: [x_78], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1050, primals_1050, 1, grid=grid(1), stream=stream0)
        del primals_1050
        # Source Nodes: [x_82], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1053, primals_1053, 1, grid=grid(1), stream=stream0)
        del primals_1053
        # Source Nodes: [x_87], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1056, primals_1056, 1, grid=grid(1), stream=stream0)
        del primals_1056
        # Source Nodes: [x_91], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1059, primals_1059, 1, grid=grid(1), stream=stream0)
        del primals_1059
        # Source Nodes: [x_96], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1062, primals_1062, 1, grid=grid(1), stream=stream0)
        del primals_1062
        # Source Nodes: [x_100], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1065, primals_1065, 1, grid=grid(1), stream=stream0)
        del primals_1065
        # Source Nodes: [x_105], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1068, primals_1068, 1, grid=grid(1), stream=stream0)
        del primals_1068
        # Source Nodes: [x_109], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1071, primals_1071, 1, grid=grid(1), stream=stream0)
        del primals_1071
        # Source Nodes: [x_114], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1074, primals_1074, 1, grid=grid(1), stream=stream0)
        del primals_1074
        # Source Nodes: [x_118], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1077, primals_1077, 1, grid=grid(1), stream=stream0)
        del primals_1077
        # Source Nodes: [x_123], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1080, primals_1080, 1, grid=grid(1), stream=stream0)
        del primals_1080
        # Source Nodes: [l__mod___stage2_0_fuse_layers_0_1_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1083, primals_1083, 1, grid=grid(1), stream=stream0)
        del primals_1083
        # Source Nodes: [y_2], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1086, primals_1086, 1, grid=grid(1), stream=stream0)
        del primals_1086
        # Source Nodes: [l__mod___transition2_2_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1089, primals_1089, 1, grid=grid(1), stream=stream0)
        del primals_1089
        # Source Nodes: [x_127], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1092, primals_1092, 1, grid=grid(1), stream=stream0)
        del primals_1092
        # Source Nodes: [x_132], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1095, primals_1095, 1, grid=grid(1), stream=stream0)
        del primals_1095
        # Source Nodes: [x_136], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1098, primals_1098, 1, grid=grid(1), stream=stream0)
        del primals_1098
        # Source Nodes: [x_141], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1101, primals_1101, 1, grid=grid(1), stream=stream0)
        del primals_1101
        # Source Nodes: [x_145], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1104, primals_1104, 1, grid=grid(1), stream=stream0)
        del primals_1104
        # Source Nodes: [x_150], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1107, primals_1107, 1, grid=grid(1), stream=stream0)
        del primals_1107
        # Source Nodes: [x_154], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1110, primals_1110, 1, grid=grid(1), stream=stream0)
        del primals_1110
        # Source Nodes: [x_159], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1113, primals_1113, 1, grid=grid(1), stream=stream0)
        del primals_1113
        # Source Nodes: [x_163], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1116, primals_1116, 1, grid=grid(1), stream=stream0)
        del primals_1116
        # Source Nodes: [x_168], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1119, primals_1119, 1, grid=grid(1), stream=stream0)
        del primals_1119
        # Source Nodes: [x_172], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1122, primals_1122, 1, grid=grid(1), stream=stream0)
        del primals_1122
        # Source Nodes: [x_177], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1125, primals_1125, 1, grid=grid(1), stream=stream0)
        del primals_1125
        # Source Nodes: [x_181], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1128, primals_1128, 1, grid=grid(1), stream=stream0)
        del primals_1128
        # Source Nodes: [x_186], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1131, primals_1131, 1, grid=grid(1), stream=stream0)
        del primals_1131
        # Source Nodes: [x_190], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1134, primals_1134, 1, grid=grid(1), stream=stream0)
        del primals_1134
        # Source Nodes: [x_195], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1137, primals_1137, 1, grid=grid(1), stream=stream0)
        del primals_1137
        # Source Nodes: [x_199], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1140, primals_1140, 1, grid=grid(1), stream=stream0)
        del primals_1140
        # Source Nodes: [x_204], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1143, primals_1143, 1, grid=grid(1), stream=stream0)
        del primals_1143
        # Source Nodes: [x_208], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1146, primals_1146, 1, grid=grid(1), stream=stream0)
        del primals_1146
        # Source Nodes: [x_213], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1149, primals_1149, 1, grid=grid(1), stream=stream0)
        del primals_1149
        # Source Nodes: [x_217], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1152, primals_1152, 1, grid=grid(1), stream=stream0)
        del primals_1152
        # Source Nodes: [x_222], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1155, primals_1155, 1, grid=grid(1), stream=stream0)
        del primals_1155
        # Source Nodes: [x_226], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1158, primals_1158, 1, grid=grid(1), stream=stream0)
        del primals_1158
        # Source Nodes: [x_231], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1161, primals_1161, 1, grid=grid(1), stream=stream0)
        del primals_1161
        # Source Nodes: [l__mod___stage3_0_fuse_layers_0_1_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1164, primals_1164, 1, grid=grid(1), stream=stream0)
        del primals_1164
        # Source Nodes: [l__mod___stage3_0_fuse_layers_0_2_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1167, primals_1167, 1, grid=grid(1), stream=stream0)
        del primals_1167
        # Source Nodes: [y_7], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1170, primals_1170, 1, grid=grid(1), stream=stream0)
        del primals_1170
        # Source Nodes: [l__mod___stage3_0_fuse_layers_1_2_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1173, primals_1173, 1, grid=grid(1), stream=stream0)
        del primals_1173
        # Source Nodes: [l__mod___stage3_0_fuse_layers_2_0_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1176, primals_1176, 1, grid=grid(1), stream=stream0)
        del primals_1176
        # Source Nodes: [y_10], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1179, primals_1179, 1, grid=grid(1), stream=stream0)
        del primals_1179
        # Source Nodes: [l__mod___stage3_0_fuse_layers_2_1_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1182, primals_1182, 1, grid=grid(1), stream=stream0)
        del primals_1182
        # Source Nodes: [x_235], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1185, primals_1185, 1, grid=grid(1), stream=stream0)
        del primals_1185
        # Source Nodes: [x_240], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1188, primals_1188, 1, grid=grid(1), stream=stream0)
        del primals_1188
        # Source Nodes: [x_244], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1191, primals_1191, 1, grid=grid(1), stream=stream0)
        del primals_1191
        # Source Nodes: [x_249], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1194, primals_1194, 1, grid=grid(1), stream=stream0)
        del primals_1194
        # Source Nodes: [x_253], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1197, primals_1197, 1, grid=grid(1), stream=stream0)
        del primals_1197
        # Source Nodes: [x_258], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1200, primals_1200, 1, grid=grid(1), stream=stream0)
        del primals_1200
        # Source Nodes: [x_262], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1203, primals_1203, 1, grid=grid(1), stream=stream0)
        del primals_1203
        # Source Nodes: [x_267], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1206, primals_1206, 1, grid=grid(1), stream=stream0)
        del primals_1206
        # Source Nodes: [x_271], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1209, primals_1209, 1, grid=grid(1), stream=stream0)
        del primals_1209
        # Source Nodes: [x_276], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1212, primals_1212, 1, grid=grid(1), stream=stream0)
        del primals_1212
        # Source Nodes: [x_280], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1215, primals_1215, 1, grid=grid(1), stream=stream0)
        del primals_1215
        # Source Nodes: [x_285], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1218, primals_1218, 1, grid=grid(1), stream=stream0)
        del primals_1218
        # Source Nodes: [x_289], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1221, primals_1221, 1, grid=grid(1), stream=stream0)
        del primals_1221
        # Source Nodes: [x_294], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1224, primals_1224, 1, grid=grid(1), stream=stream0)
        del primals_1224
        # Source Nodes: [x_298], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1227, primals_1227, 1, grid=grid(1), stream=stream0)
        del primals_1227
        # Source Nodes: [x_303], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1230, primals_1230, 1, grid=grid(1), stream=stream0)
        del primals_1230
        # Source Nodes: [x_307], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1233, primals_1233, 1, grid=grid(1), stream=stream0)
        del primals_1233
        # Source Nodes: [x_312], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1236, primals_1236, 1, grid=grid(1), stream=stream0)
        del primals_1236
        # Source Nodes: [x_316], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1239, primals_1239, 1, grid=grid(1), stream=stream0)
        del primals_1239
        # Source Nodes: [x_321], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1242, primals_1242, 1, grid=grid(1), stream=stream0)
        del primals_1242
        # Source Nodes: [x_325], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1245, primals_1245, 1, grid=grid(1), stream=stream0)
        del primals_1245
        # Source Nodes: [x_330], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1248, primals_1248, 1, grid=grid(1), stream=stream0)
        del primals_1248
        # Source Nodes: [x_334], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1251, primals_1251, 1, grid=grid(1), stream=stream0)
        del primals_1251
        # Source Nodes: [x_339], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1254, primals_1254, 1, grid=grid(1), stream=stream0)
        del primals_1254
        # Source Nodes: [l__mod___stage3_1_fuse_layers_0_1_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1257, primals_1257, 1, grid=grid(1), stream=stream0)
        del primals_1257
        # Source Nodes: [l__mod___stage3_1_fuse_layers_0_2_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1260, primals_1260, 1, grid=grid(1), stream=stream0)
        del primals_1260
        # Source Nodes: [y_16], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1263, primals_1263, 1, grid=grid(1), stream=stream0)
        del primals_1263
        # Source Nodes: [l__mod___stage3_1_fuse_layers_1_2_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1266, primals_1266, 1, grid=grid(1), stream=stream0)
        del primals_1266
        # Source Nodes: [l__mod___stage3_1_fuse_layers_2_0_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1269, primals_1269, 1, grid=grid(1), stream=stream0)
        del primals_1269
        # Source Nodes: [y_19], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1272, primals_1272, 1, grid=grid(1), stream=stream0)
        del primals_1272
        # Source Nodes: [l__mod___stage3_1_fuse_layers_2_1_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1275, primals_1275, 1, grid=grid(1), stream=stream0)
        del primals_1275
        # Source Nodes: [x_343], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1278, primals_1278, 1, grid=grid(1), stream=stream0)
        del primals_1278
        # Source Nodes: [x_348], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1281, primals_1281, 1, grid=grid(1), stream=stream0)
        del primals_1281
        # Source Nodes: [x_352], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1284, primals_1284, 1, grid=grid(1), stream=stream0)
        del primals_1284
        # Source Nodes: [x_357], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1287, primals_1287, 1, grid=grid(1), stream=stream0)
        del primals_1287
        # Source Nodes: [x_361], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1290, primals_1290, 1, grid=grid(1), stream=stream0)
        del primals_1290
        # Source Nodes: [x_366], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1293, primals_1293, 1, grid=grid(1), stream=stream0)
        del primals_1293
        # Source Nodes: [x_370], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1296, primals_1296, 1, grid=grid(1), stream=stream0)
        del primals_1296
        # Source Nodes: [x_375], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1299, primals_1299, 1, grid=grid(1), stream=stream0)
        del primals_1299
        # Source Nodes: [x_379], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1302, primals_1302, 1, grid=grid(1), stream=stream0)
        del primals_1302
        # Source Nodes: [x_384], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1305, primals_1305, 1, grid=grid(1), stream=stream0)
        del primals_1305
        # Source Nodes: [x_388], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1308, primals_1308, 1, grid=grid(1), stream=stream0)
        del primals_1308
        # Source Nodes: [x_393], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1311, primals_1311, 1, grid=grid(1), stream=stream0)
        del primals_1311
        # Source Nodes: [x_397], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1314, primals_1314, 1, grid=grid(1), stream=stream0)
        del primals_1314
        # Source Nodes: [x_402], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1317, primals_1317, 1, grid=grid(1), stream=stream0)
        del primals_1317
        # Source Nodes: [x_406], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1320, primals_1320, 1, grid=grid(1), stream=stream0)
        del primals_1320
        # Source Nodes: [x_411], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1323, primals_1323, 1, grid=grid(1), stream=stream0)
        del primals_1323
        # Source Nodes: [x_415], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1326, primals_1326, 1, grid=grid(1), stream=stream0)
        del primals_1326
        # Source Nodes: [x_420], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1329, primals_1329, 1, grid=grid(1), stream=stream0)
        del primals_1329
        # Source Nodes: [x_424], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1332, primals_1332, 1, grid=grid(1), stream=stream0)
        del primals_1332
        # Source Nodes: [x_429], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1335, primals_1335, 1, grid=grid(1), stream=stream0)
        del primals_1335
        # Source Nodes: [x_433], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1338, primals_1338, 1, grid=grid(1), stream=stream0)
        del primals_1338
        # Source Nodes: [x_438], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1341, primals_1341, 1, grid=grid(1), stream=stream0)
        del primals_1341
        # Source Nodes: [x_442], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1344, primals_1344, 1, grid=grid(1), stream=stream0)
        del primals_1344
        # Source Nodes: [x_447], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1347, primals_1347, 1, grid=grid(1), stream=stream0)
        del primals_1347
        # Source Nodes: [l__mod___stage3_2_fuse_layers_0_1_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1350, primals_1350, 1, grid=grid(1), stream=stream0)
        del primals_1350
        # Source Nodes: [l__mod___stage3_2_fuse_layers_0_2_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1353, primals_1353, 1, grid=grid(1), stream=stream0)
        del primals_1353
        # Source Nodes: [y_25], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1356, primals_1356, 1, grid=grid(1), stream=stream0)
        del primals_1356
        # Source Nodes: [l__mod___stage3_2_fuse_layers_1_2_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1359, primals_1359, 1, grid=grid(1), stream=stream0)
        del primals_1359
        # Source Nodes: [l__mod___stage3_2_fuse_layers_2_0_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1362, primals_1362, 1, grid=grid(1), stream=stream0)
        del primals_1362
        # Source Nodes: [y_28], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1365, primals_1365, 1, grid=grid(1), stream=stream0)
        del primals_1365
        # Source Nodes: [l__mod___stage3_2_fuse_layers_2_1_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1368, primals_1368, 1, grid=grid(1), stream=stream0)
        del primals_1368
        # Source Nodes: [x_451], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1371, primals_1371, 1, grid=grid(1), stream=stream0)
        del primals_1371
        # Source Nodes: [x_456], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1374, primals_1374, 1, grid=grid(1), stream=stream0)
        del primals_1374
        # Source Nodes: [x_460], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1377, primals_1377, 1, grid=grid(1), stream=stream0)
        del primals_1377
        # Source Nodes: [x_465], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1380, primals_1380, 1, grid=grid(1), stream=stream0)
        del primals_1380
        # Source Nodes: [x_469], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1383, primals_1383, 1, grid=grid(1), stream=stream0)
        del primals_1383
        # Source Nodes: [x_474], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1386, primals_1386, 1, grid=grid(1), stream=stream0)
        del primals_1386
        # Source Nodes: [x_478], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1389, primals_1389, 1, grid=grid(1), stream=stream0)
        del primals_1389
        # Source Nodes: [x_483], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1392, primals_1392, 1, grid=grid(1), stream=stream0)
        del primals_1392
        # Source Nodes: [x_487], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1395, primals_1395, 1, grid=grid(1), stream=stream0)
        del primals_1395
        # Source Nodes: [x_492], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1398, primals_1398, 1, grid=grid(1), stream=stream0)
        del primals_1398
        # Source Nodes: [x_496], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1401, primals_1401, 1, grid=grid(1), stream=stream0)
        del primals_1401
        # Source Nodes: [x_501], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1404, primals_1404, 1, grid=grid(1), stream=stream0)
        del primals_1404
        # Source Nodes: [x_505], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1407, primals_1407, 1, grid=grid(1), stream=stream0)
        del primals_1407
        # Source Nodes: [x_510], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1410, primals_1410, 1, grid=grid(1), stream=stream0)
        del primals_1410
        # Source Nodes: [x_514], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1413, primals_1413, 1, grid=grid(1), stream=stream0)
        del primals_1413
        # Source Nodes: [x_519], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1416, primals_1416, 1, grid=grid(1), stream=stream0)
        del primals_1416
        # Source Nodes: [x_523], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1419, primals_1419, 1, grid=grid(1), stream=stream0)
        del primals_1419
        # Source Nodes: [x_528], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1422, primals_1422, 1, grid=grid(1), stream=stream0)
        del primals_1422
        # Source Nodes: [x_532], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1425, primals_1425, 1, grid=grid(1), stream=stream0)
        del primals_1425
        # Source Nodes: [x_537], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1428, primals_1428, 1, grid=grid(1), stream=stream0)
        del primals_1428
        # Source Nodes: [x_541], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1431, primals_1431, 1, grid=grid(1), stream=stream0)
        del primals_1431
        # Source Nodes: [x_546], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1434, primals_1434, 1, grid=grid(1), stream=stream0)
        del primals_1434
        # Source Nodes: [x_550], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1437, primals_1437, 1, grid=grid(1), stream=stream0)
        del primals_1437
        # Source Nodes: [x_555], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1440, primals_1440, 1, grid=grid(1), stream=stream0)
        del primals_1440
        # Source Nodes: [l__mod___stage3_3_fuse_layers_0_1_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1443, primals_1443, 1, grid=grid(1), stream=stream0)
        del primals_1443
        # Source Nodes: [l__mod___stage3_3_fuse_layers_0_2_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1446, primals_1446, 1, grid=grid(1), stream=stream0)
        del primals_1446
        # Source Nodes: [y_34], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1449, primals_1449, 1, grid=grid(1), stream=stream0)
        del primals_1449
        # Source Nodes: [l__mod___stage3_3_fuse_layers_1_2_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1452, primals_1452, 1, grid=grid(1), stream=stream0)
        del primals_1452
        # Source Nodes: [l__mod___stage3_3_fuse_layers_2_0_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1455, primals_1455, 1, grid=grid(1), stream=stream0)
        del primals_1455
        # Source Nodes: [y_37], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1458, primals_1458, 1, grid=grid(1), stream=stream0)
        del primals_1458
        # Source Nodes: [l__mod___stage3_3_fuse_layers_2_1_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1461, primals_1461, 1, grid=grid(1), stream=stream0)
        del primals_1461
        # Source Nodes: [l__mod___transition3_3_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1464, primals_1464, 1, grid=grid(1), stream=stream0)
        del primals_1464
        # Source Nodes: [x_559], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1467, primals_1467, 1, grid=grid(1), stream=stream0)
        del primals_1467
        # Source Nodes: [x_564], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1470, primals_1470, 1, grid=grid(1), stream=stream0)
        del primals_1470
        # Source Nodes: [x_568], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1473, primals_1473, 1, grid=grid(1), stream=stream0)
        del primals_1473
        # Source Nodes: [x_573], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1476, primals_1476, 1, grid=grid(1), stream=stream0)
        del primals_1476
        # Source Nodes: [x_577], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1479, primals_1479, 1, grid=grid(1), stream=stream0)
        del primals_1479
        # Source Nodes: [x_582], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1482, primals_1482, 1, grid=grid(1), stream=stream0)
        del primals_1482
        # Source Nodes: [x_586], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1485, primals_1485, 1, grid=grid(1), stream=stream0)
        del primals_1485
        # Source Nodes: [x_591], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1488, primals_1488, 1, grid=grid(1), stream=stream0)
        del primals_1488
        # Source Nodes: [x_595], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1491, primals_1491, 1, grid=grid(1), stream=stream0)
        del primals_1491
        # Source Nodes: [x_600], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1494, primals_1494, 1, grid=grid(1), stream=stream0)
        del primals_1494
        # Source Nodes: [x_604], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1497, primals_1497, 1, grid=grid(1), stream=stream0)
        del primals_1497
        # Source Nodes: [x_609], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1500, primals_1500, 1, grid=grid(1), stream=stream0)
        del primals_1500
        # Source Nodes: [x_613], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1503, primals_1503, 1, grid=grid(1), stream=stream0)
        del primals_1503
        # Source Nodes: [x_618], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1506, primals_1506, 1, grid=grid(1), stream=stream0)
        del primals_1506
        # Source Nodes: [x_622], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1509, primals_1509, 1, grid=grid(1), stream=stream0)
        del primals_1509
        # Source Nodes: [x_627], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1512, primals_1512, 1, grid=grid(1), stream=stream0)
        del primals_1512
        # Source Nodes: [x_631], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1515, primals_1515, 1, grid=grid(1), stream=stream0)
        del primals_1515
        # Source Nodes: [x_636], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1518, primals_1518, 1, grid=grid(1), stream=stream0)
        del primals_1518
        # Source Nodes: [x_640], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1521, primals_1521, 1, grid=grid(1), stream=stream0)
        del primals_1521
        # Source Nodes: [x_645], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1524, primals_1524, 1, grid=grid(1), stream=stream0)
        del primals_1524
        # Source Nodes: [x_649], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1527, primals_1527, 1, grid=grid(1), stream=stream0)
        del primals_1527
        # Source Nodes: [x_654], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1530, primals_1530, 1, grid=grid(1), stream=stream0)
        del primals_1530
        # Source Nodes: [x_658], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1533, primals_1533, 1, grid=grid(1), stream=stream0)
        del primals_1533
        # Source Nodes: [x_663], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1536, primals_1536, 1, grid=grid(1), stream=stream0)
        del primals_1536
        # Source Nodes: [x_667], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1539, primals_1539, 1, grid=grid(1), stream=stream0)
        del primals_1539
        # Source Nodes: [x_672], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1542, primals_1542, 1, grid=grid(1), stream=stream0)
        del primals_1542
        # Source Nodes: [x_676], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1545, primals_1545, 1, grid=grid(1), stream=stream0)
        del primals_1545
        # Source Nodes: [x_681], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1548, primals_1548, 1, grid=grid(1), stream=stream0)
        del primals_1548
        # Source Nodes: [x_685], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1551, primals_1551, 1, grid=grid(1), stream=stream0)
        del primals_1551
        # Source Nodes: [x_690], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1554, primals_1554, 1, grid=grid(1), stream=stream0)
        del primals_1554
        # Source Nodes: [x_694], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1557, primals_1557, 1, grid=grid(1), stream=stream0)
        del primals_1557
        # Source Nodes: [x_699], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1560, primals_1560, 1, grid=grid(1), stream=stream0)
        del primals_1560
        # Source Nodes: [l__mod___stage4_0_fuse_layers_0_1_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1563, primals_1563, 1, grid=grid(1), stream=stream0)
        del primals_1563
        # Source Nodes: [l__mod___stage4_0_fuse_layers_0_2_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1566, primals_1566, 1, grid=grid(1), stream=stream0)
        del primals_1566
        # Source Nodes: [l__mod___stage4_0_fuse_layers_0_3_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1569, primals_1569, 1, grid=grid(1), stream=stream0)
        del primals_1569
        # Source Nodes: [y_44], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1572, primals_1572, 1, grid=grid(1), stream=stream0)
        del primals_1572
        # Source Nodes: [l__mod___stage4_0_fuse_layers_1_2_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1575, primals_1575, 1, grid=grid(1), stream=stream0)
        del primals_1575
        # Source Nodes: [l__mod___stage4_0_fuse_layers_1_3_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1578, primals_1578, 1, grid=grid(1), stream=stream0)
        del primals_1578
        # Source Nodes: [l__mod___stage4_0_fuse_layers_2_0_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1581, primals_1581, 1, grid=grid(1), stream=stream0)
        del primals_1581
        # Source Nodes: [y_48], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1584, primals_1584, 1, grid=grid(1), stream=stream0)
        del primals_1584
        # Source Nodes: [l__mod___stage4_0_fuse_layers_2_1_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1587, primals_1587, 1, grid=grid(1), stream=stream0)
        del primals_1587
        # Source Nodes: [l__mod___stage4_0_fuse_layers_2_3_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1590, primals_1590, 1, grid=grid(1), stream=stream0)
        del primals_1590
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_0_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1593, primals_1593, 1, grid=grid(1), stream=stream0)
        del primals_1593
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_0_1_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1596, primals_1596, 1, grid=grid(1), stream=stream0)
        del primals_1596
        # Source Nodes: [y_52], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1599, primals_1599, 1, grid=grid(1), stream=stream0)
        del primals_1599
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_1_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1602, primals_1602, 1, grid=grid(1), stream=stream0)
        del primals_1602
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_1_1_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1605, primals_1605, 1, grid=grid(1), stream=stream0)
        del primals_1605
        # Source Nodes: [l__mod___stage4_0_fuse_layers_3_2_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1608, primals_1608, 1, grid=grid(1), stream=stream0)
        del primals_1608
        # Source Nodes: [x_703], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1611, primals_1611, 1, grid=grid(1), stream=stream0)
        del primals_1611
        # Source Nodes: [x_708], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1614, primals_1614, 1, grid=grid(1), stream=stream0)
        del primals_1614
        # Source Nodes: [x_712], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1617, primals_1617, 1, grid=grid(1), stream=stream0)
        del primals_1617
        # Source Nodes: [x_717], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1620, primals_1620, 1, grid=grid(1), stream=stream0)
        del primals_1620
        # Source Nodes: [x_721], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1623, primals_1623, 1, grid=grid(1), stream=stream0)
        del primals_1623
        # Source Nodes: [x_726], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1626, primals_1626, 1, grid=grid(1), stream=stream0)
        del primals_1626
        # Source Nodes: [x_730], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1629, primals_1629, 1, grid=grid(1), stream=stream0)
        del primals_1629
        # Source Nodes: [x_735], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1632, primals_1632, 1, grid=grid(1), stream=stream0)
        del primals_1632
        # Source Nodes: [x_739], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1635, primals_1635, 1, grid=grid(1), stream=stream0)
        del primals_1635
        # Source Nodes: [x_744], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1638, primals_1638, 1, grid=grid(1), stream=stream0)
        del primals_1638
        # Source Nodes: [x_748], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1641, primals_1641, 1, grid=grid(1), stream=stream0)
        del primals_1641
        # Source Nodes: [x_753], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1644, primals_1644, 1, grid=grid(1), stream=stream0)
        del primals_1644
        # Source Nodes: [x_757], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1647, primals_1647, 1, grid=grid(1), stream=stream0)
        del primals_1647
        # Source Nodes: [x_762], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1650, primals_1650, 1, grid=grid(1), stream=stream0)
        del primals_1650
        # Source Nodes: [x_766], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1653, primals_1653, 1, grid=grid(1), stream=stream0)
        del primals_1653
        # Source Nodes: [x_771], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1656, primals_1656, 1, grid=grid(1), stream=stream0)
        del primals_1656
        # Source Nodes: [x_775], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1659, primals_1659, 1, grid=grid(1), stream=stream0)
        del primals_1659
        # Source Nodes: [x_780], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1662, primals_1662, 1, grid=grid(1), stream=stream0)
        del primals_1662
        # Source Nodes: [x_784], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1665, primals_1665, 1, grid=grid(1), stream=stream0)
        del primals_1665
        # Source Nodes: [x_789], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1668, primals_1668, 1, grid=grid(1), stream=stream0)
        del primals_1668
        # Source Nodes: [x_793], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1671, primals_1671, 1, grid=grid(1), stream=stream0)
        del primals_1671
        # Source Nodes: [x_798], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1674, primals_1674, 1, grid=grid(1), stream=stream0)
        del primals_1674
        # Source Nodes: [x_802], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1677, primals_1677, 1, grid=grid(1), stream=stream0)
        del primals_1677
        # Source Nodes: [x_807], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1680, primals_1680, 1, grid=grid(1), stream=stream0)
        del primals_1680
        # Source Nodes: [x_811], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1683, primals_1683, 1, grid=grid(1), stream=stream0)
        del primals_1683
        # Source Nodes: [x_816], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1686, primals_1686, 1, grid=grid(1), stream=stream0)
        del primals_1686
        # Source Nodes: [x_820], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1689, primals_1689, 1, grid=grid(1), stream=stream0)
        del primals_1689
        # Source Nodes: [x_825], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1692, primals_1692, 1, grid=grid(1), stream=stream0)
        del primals_1692
        # Source Nodes: [x_829], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1695, primals_1695, 1, grid=grid(1), stream=stream0)
        del primals_1695
        # Source Nodes: [x_834], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1698, primals_1698, 1, grid=grid(1), stream=stream0)
        del primals_1698
        # Source Nodes: [x_838], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1701, primals_1701, 1, grid=grid(1), stream=stream0)
        del primals_1701
        # Source Nodes: [x_843], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1704, primals_1704, 1, grid=grid(1), stream=stream0)
        del primals_1704
        # Source Nodes: [l__mod___stage4_1_fuse_layers_0_1_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1707, primals_1707, 1, grid=grid(1), stream=stream0)
        del primals_1707
        # Source Nodes: [l__mod___stage4_1_fuse_layers_0_2_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1710, primals_1710, 1, grid=grid(1), stream=stream0)
        del primals_1710
        # Source Nodes: [l__mod___stage4_1_fuse_layers_0_3_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1713, primals_1713, 1, grid=grid(1), stream=stream0)
        del primals_1713
        # Source Nodes: [y_60], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1716, primals_1716, 1, grid=grid(1), stream=stream0)
        del primals_1716
        # Source Nodes: [l__mod___stage4_1_fuse_layers_1_2_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1719, primals_1719, 1, grid=grid(1), stream=stream0)
        del primals_1719
        # Source Nodes: [l__mod___stage4_1_fuse_layers_1_3_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1722, primals_1722, 1, grid=grid(1), stream=stream0)
        del primals_1722
        # Source Nodes: [l__mod___stage4_1_fuse_layers_2_0_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1725, primals_1725, 1, grid=grid(1), stream=stream0)
        del primals_1725
        # Source Nodes: [y_64], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1728, primals_1728, 1, grid=grid(1), stream=stream0)
        del primals_1728
        # Source Nodes: [l__mod___stage4_1_fuse_layers_2_1_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1731, primals_1731, 1, grid=grid(1), stream=stream0)
        del primals_1731
        # Source Nodes: [l__mod___stage4_1_fuse_layers_2_3_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1734, primals_1734, 1, grid=grid(1), stream=stream0)
        del primals_1734
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_0_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1737, primals_1737, 1, grid=grid(1), stream=stream0)
        del primals_1737
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_0_1_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1740, primals_1740, 1, grid=grid(1), stream=stream0)
        del primals_1740
        # Source Nodes: [y_68], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1743, primals_1743, 1, grid=grid(1), stream=stream0)
        del primals_1743
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_1_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1746, primals_1746, 1, grid=grid(1), stream=stream0)
        del primals_1746
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_1_1_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1749, primals_1749, 1, grid=grid(1), stream=stream0)
        del primals_1749
        # Source Nodes: [l__mod___stage4_1_fuse_layers_3_2_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1752, primals_1752, 1, grid=grid(1), stream=stream0)
        del primals_1752
        # Source Nodes: [x_847], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1755, primals_1755, 1, grid=grid(1), stream=stream0)
        del primals_1755
        # Source Nodes: [x_852], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1758, primals_1758, 1, grid=grid(1), stream=stream0)
        del primals_1758
        # Source Nodes: [x_856], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1761, primals_1761, 1, grid=grid(1), stream=stream0)
        del primals_1761
        # Source Nodes: [x_861], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1764, primals_1764, 1, grid=grid(1), stream=stream0)
        del primals_1764
        # Source Nodes: [x_865], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1767, primals_1767, 1, grid=grid(1), stream=stream0)
        del primals_1767
        # Source Nodes: [x_870], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1770, primals_1770, 1, grid=grid(1), stream=stream0)
        del primals_1770
        # Source Nodes: [x_874], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1773, primals_1773, 1, grid=grid(1), stream=stream0)
        del primals_1773
        # Source Nodes: [x_879], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1776, primals_1776, 1, grid=grid(1), stream=stream0)
        del primals_1776
        # Source Nodes: [x_883], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1779, primals_1779, 1, grid=grid(1), stream=stream0)
        del primals_1779
        # Source Nodes: [x_888], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1782, primals_1782, 1, grid=grid(1), stream=stream0)
        del primals_1782
        # Source Nodes: [x_892], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1785, primals_1785, 1, grid=grid(1), stream=stream0)
        del primals_1785
        # Source Nodes: [x_897], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1788, primals_1788, 1, grid=grid(1), stream=stream0)
        del primals_1788
        # Source Nodes: [x_901], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1791, primals_1791, 1, grid=grid(1), stream=stream0)
        del primals_1791
        # Source Nodes: [x_906], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1794, primals_1794, 1, grid=grid(1), stream=stream0)
        del primals_1794
        # Source Nodes: [x_910], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1797, primals_1797, 1, grid=grid(1), stream=stream0)
        del primals_1797
        # Source Nodes: [x_915], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1800, primals_1800, 1, grid=grid(1), stream=stream0)
        del primals_1800
        # Source Nodes: [x_919], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1803, primals_1803, 1, grid=grid(1), stream=stream0)
        del primals_1803
        # Source Nodes: [x_924], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1806, primals_1806, 1, grid=grid(1), stream=stream0)
        del primals_1806
        # Source Nodes: [x_928], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1809, primals_1809, 1, grid=grid(1), stream=stream0)
        del primals_1809
        # Source Nodes: [x_933], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1812, primals_1812, 1, grid=grid(1), stream=stream0)
        del primals_1812
        # Source Nodes: [x_937], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1815, primals_1815, 1, grid=grid(1), stream=stream0)
        del primals_1815
        # Source Nodes: [x_942], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1818, primals_1818, 1, grid=grid(1), stream=stream0)
        del primals_1818
        # Source Nodes: [x_946], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1821, primals_1821, 1, grid=grid(1), stream=stream0)
        del primals_1821
        # Source Nodes: [x_951], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1824, primals_1824, 1, grid=grid(1), stream=stream0)
        del primals_1824
        # Source Nodes: [x_955], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1827, primals_1827, 1, grid=grid(1), stream=stream0)
        del primals_1827
        # Source Nodes: [x_960], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1830, primals_1830, 1, grid=grid(1), stream=stream0)
        del primals_1830
        # Source Nodes: [x_964], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1833, primals_1833, 1, grid=grid(1), stream=stream0)
        del primals_1833
        # Source Nodes: [x_969], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1836, primals_1836, 1, grid=grid(1), stream=stream0)
        del primals_1836
        # Source Nodes: [x_973], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1839, primals_1839, 1, grid=grid(1), stream=stream0)
        del primals_1839
        # Source Nodes: [x_978], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1842, primals_1842, 1, grid=grid(1), stream=stream0)
        del primals_1842
        # Source Nodes: [x_982], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1845, primals_1845, 1, grid=grid(1), stream=stream0)
        del primals_1845
        # Source Nodes: [x_987], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1848, primals_1848, 1, grid=grid(1), stream=stream0)
        del primals_1848
        # Source Nodes: [l__mod___stage4_2_fuse_layers_0_1_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1851, primals_1851, 1, grid=grid(1), stream=stream0)
        del primals_1851
        # Source Nodes: [l__mod___stage4_2_fuse_layers_0_2_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1854, primals_1854, 1, grid=grid(1), stream=stream0)
        del primals_1854
        # Source Nodes: [l__mod___stage4_2_fuse_layers_0_3_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1857, primals_1857, 1, grid=grid(1), stream=stream0)
        del primals_1857
        # Source Nodes: [y_76], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1860, primals_1860, 1, grid=grid(1), stream=stream0)
        del primals_1860
        # Source Nodes: [l__mod___stage4_2_fuse_layers_1_2_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1863, primals_1863, 1, grid=grid(1), stream=stream0)
        del primals_1863
        # Source Nodes: [l__mod___stage4_2_fuse_layers_1_3_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1866, primals_1866, 1, grid=grid(1), stream=stream0)
        del primals_1866
        # Source Nodes: [l__mod___stage4_2_fuse_layers_2_0_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1869, primals_1869, 1, grid=grid(1), stream=stream0)
        del primals_1869
        # Source Nodes: [y_80], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1872, primals_1872, 1, grid=grid(1), stream=stream0)
        del primals_1872
        # Source Nodes: [l__mod___stage4_2_fuse_layers_2_1_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1875, primals_1875, 1, grid=grid(1), stream=stream0)
        del primals_1875
        # Source Nodes: [l__mod___stage4_2_fuse_layers_2_3_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1878, primals_1878, 1, grid=grid(1), stream=stream0)
        del primals_1878
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_0_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1881, primals_1881, 1, grid=grid(1), stream=stream0)
        del primals_1881
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_0_1_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1884, primals_1884, 1, grid=grid(1), stream=stream0)
        del primals_1884
        # Source Nodes: [y_84], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1887, primals_1887, 1, grid=grid(1), stream=stream0)
        del primals_1887
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_1_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1890, primals_1890, 1, grid=grid(1), stream=stream0)
        del primals_1890
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_1_1_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1893, primals_1893, 1, grid=grid(1), stream=stream0)
        del primals_1893
        # Source Nodes: [l__mod___stage4_2_fuse_layers_3_2_0_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1896, primals_1896, 1, grid=grid(1), stream=stream0)
        del primals_1896
        # Source Nodes: [x_991], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1899, primals_1899, 1, grid=grid(1), stream=stream0)
        del primals_1899
        # Source Nodes: [x_994], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1902, primals_1902, 1, grid=grid(1), stream=stream0)
        del primals_1902
        # Source Nodes: [x_999], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1905, primals_1905, 1, grid=grid(1), stream=stream0)
        del primals_1905
        # Source Nodes: [shortcut_110], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1908, primals_1908, 1, grid=grid(1), stream=stream0)
        del primals_1908
        # Source Nodes: [x_1003], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1911, primals_1911, 1, grid=grid(1), stream=stream0)
        del primals_1911
        # Source Nodes: [x_1006], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1914, primals_1914, 1, grid=grid(1), stream=stream0)
        del primals_1914
        # Source Nodes: [x_1011], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1917, primals_1917, 1, grid=grid(1), stream=stream0)
        del primals_1917
        # Source Nodes: [shortcut_112], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1920, primals_1920, 1, grid=grid(1), stream=stream0)
        del primals_1920
        # Source Nodes: [forward], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1923, primals_1923, 1, grid=grid(1), stream=stream0)
        del primals_1923
        # Source Nodes: [x_1015], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1926, primals_1926, 1, grid=grid(1), stream=stream0)
        del primals_1926
        # Source Nodes: [x_1018], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1929, primals_1929, 1, grid=grid(1), stream=stream0)
        del primals_1929
        # Source Nodes: [x_1023], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1932, primals_1932, 1, grid=grid(1), stream=stream0)
        del primals_1932
        # Source Nodes: [shortcut_114], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1935, primals_1935, 1, grid=grid(1), stream=stream0)
        del primals_1935
        # Source Nodes: [forward_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1938, primals_1938, 1, grid=grid(1), stream=stream0)
        del primals_1938
        # Source Nodes: [x_1027], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1941, primals_1941, 1, grid=grid(1), stream=stream0)
        del primals_1941
        # Source Nodes: [x_1030], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1944, primals_1944, 1, grid=grid(1), stream=stream0)
        del primals_1944
        # Source Nodes: [x_1035], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1947, primals_1947, 1, grid=grid(1), stream=stream0)
        del primals_1947
        # Source Nodes: [shortcut_116], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1950, primals_1950, 1, grid=grid(1), stream=stream0)
        del primals_1950
        # Source Nodes: [forward_2], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1953, primals_1953, 1, grid=grid(1), stream=stream0)
        del primals_1953
        # Source Nodes: [l__mod___final_layer_1], Original ATen: [aten.add]
        triton_poi_fused_add_69.run(primals_1956, primals_1956, 1, grid=grid(1), stream=stream0)
        del primals_1956
        return (buf2190, primals_1, primals_2, primals_4, primals_5, primals_7, primals_8, primals_10, primals_11, primals_13, primals_14, primals_16, primals_17, primals_19, primals_20, primals_22, primals_23, primals_25, primals_26, primals_28, primals_29, primals_31, primals_32, primals_34, primals_35, primals_37, primals_38, primals_40, primals_41, primals_43, primals_44, primals_46, primals_47, primals_49, primals_50, primals_52, primals_53, primals_55, primals_56, primals_58, primals_59, primals_61, primals_62, primals_64, primals_65, primals_67, primals_68, primals_70, primals_71, primals_73, primals_74, primals_76, primals_77, primals_79, primals_80, primals_82, primals_83, primals_85, primals_86, primals_88, primals_89, primals_91, primals_92, primals_94, primals_95, primals_97, primals_98, primals_100, primals_101, primals_103, primals_104, primals_106, primals_107, primals_109, primals_110, primals_112, primals_113, primals_115, primals_116, primals_118, primals_119, primals_121, primals_122, primals_124, primals_125, primals_127, primals_128, primals_130, primals_131, primals_133, primals_134, primals_136, primals_137, primals_139, primals_140, primals_142, primals_143, primals_145, primals_146, primals_148, primals_149, primals_151, primals_152, primals_154, primals_155, primals_157, primals_158, primals_160, primals_161, primals_163, primals_164, primals_166, primals_167, primals_169, primals_170, primals_172, primals_173, primals_175, primals_176, primals_178, primals_179, primals_181, primals_182, primals_184, primals_185, primals_187, primals_188, primals_190, primals_191, primals_193, primals_194, primals_196, primals_197, primals_199, primals_200, primals_202, primals_203, primals_205, primals_206, primals_208, primals_209, primals_211, primals_212, primals_214, primals_215, primals_217, primals_218, primals_220, primals_221, primals_223, primals_224, primals_226, primals_227, primals_229, primals_230, primals_232, primals_233, primals_235, primals_236, primals_238, primals_239, primals_241, primals_242, primals_244, primals_245, primals_247, primals_248, primals_250, primals_251, primals_253, primals_254, primals_256, primals_257, primals_259, primals_260, primals_262, primals_263, primals_265, primals_266, primals_268, primals_269, primals_271, primals_272, primals_274, primals_275, primals_277, primals_278, primals_280, primals_281, primals_283, primals_284, primals_286, primals_287, primals_289, primals_290, primals_292, primals_293, primals_295, primals_296, primals_298, primals_299, primals_301, primals_302, primals_304, primals_305, primals_307, primals_308, primals_310, primals_311, primals_313, primals_314, primals_316, primals_317, primals_319, primals_320, primals_322, primals_323, primals_325, primals_326, primals_328, primals_329, primals_331, primals_332, primals_334, primals_335, primals_337, primals_338, primals_340, primals_341, primals_343, primals_344, primals_346, primals_347, primals_349, primals_350, primals_352, primals_353, primals_355, primals_356, primals_358, primals_359, primals_361, primals_362, primals_364, primals_365, primals_367, primals_368, primals_370, primals_371, primals_373, primals_374, primals_376, primals_377, primals_379, primals_380, primals_382, primals_383, primals_385, primals_386, primals_388, primals_389, primals_391, primals_392, primals_394, primals_395, primals_397, primals_398, primals_400, primals_401, primals_403, primals_404, primals_406, primals_407, primals_409, primals_410, primals_412, primals_413, primals_415, primals_416, primals_418, primals_419, primals_421, primals_422, primals_424, primals_425, primals_427, primals_428, primals_430, primals_431, primals_433, primals_434, primals_436, primals_437, primals_439, primals_440, primals_442, primals_443, primals_445, primals_446, primals_448, primals_449, primals_451, primals_452, primals_454, primals_455, primals_457, primals_458, primals_460, primals_461, primals_463, primals_464, primals_466, primals_467, primals_469, primals_470, primals_472, primals_473, primals_475, primals_476, primals_478, primals_479, primals_481, primals_482, primals_484, primals_485, primals_487, primals_488, primals_490, primals_491, primals_493, primals_494, primals_496, primals_497, primals_499, primals_500, primals_502, primals_503, primals_505, primals_506, primals_508, primals_509, primals_511, primals_512, primals_514, primals_515, primals_517, primals_518, primals_520, primals_521, primals_523, primals_524, primals_526, primals_527, primals_529, primals_530, primals_532, primals_533, primals_535, primals_536, primals_538, primals_539, primals_541, primals_542, primals_544, primals_545, primals_547, primals_548, primals_550, primals_551, primals_553, primals_554, primals_556, primals_557, primals_559, primals_560, primals_562, primals_563, primals_565, primals_566, primals_568, primals_569, primals_571, primals_572, primals_574, primals_575, primals_577, primals_578, primals_580, primals_581, primals_583, primals_584, primals_586, primals_587, primals_589, primals_590, primals_592, primals_593, primals_595, primals_596, primals_598, primals_599, primals_601, primals_602, primals_604, primals_605, primals_607, primals_608, primals_610, primals_611, primals_613, primals_614, primals_616, primals_617, primals_619, primals_620, primals_622, primals_623, primals_625, primals_626, primals_628, primals_629, primals_631, primals_632, primals_634, primals_635, primals_637, primals_638, primals_640, primals_641, primals_643, primals_644, primals_646, primals_647, primals_649, primals_650, primals_652, primals_653, primals_655, primals_656, primals_658, primals_659, primals_661, primals_662, primals_664, primals_665, primals_667, primals_668, primals_670, primals_671, primals_673, primals_674, primals_676, primals_677, primals_679, primals_680, primals_682, primals_683, primals_685, primals_686, primals_688, primals_689, primals_691, primals_692, primals_694, primals_695, primals_697, primals_698, primals_700, primals_701, primals_703, primals_704, primals_706, primals_707, primals_709, primals_710, primals_712, primals_713, primals_715, primals_716, primals_718, primals_719, primals_721, primals_722, primals_724, primals_725, primals_727, primals_728, primals_730, primals_731, primals_733, primals_734, primals_736, primals_737, primals_739, primals_740, primals_742, primals_743, primals_745, primals_746, primals_748, primals_749, primals_751, primals_752, primals_754, primals_755, primals_757, primals_758, primals_760, primals_761, primals_763, primals_764, primals_766, primals_767, primals_769, primals_770, primals_772, primals_773, primals_775, primals_776, primals_778, primals_779, primals_781, primals_782, primals_784, primals_785, primals_787, primals_788, primals_790, primals_791, primals_793, primals_794, primals_796, primals_797, primals_799, primals_800, primals_802, primals_803, primals_805, primals_806, primals_808, primals_809, primals_811, primals_812, primals_814, primals_815, primals_817, primals_818, primals_820, primals_821, primals_823, primals_824, primals_826, primals_827, primals_829, primals_830, primals_832, primals_833, primals_835, primals_836, primals_838, primals_839, primals_841, primals_842, primals_844, primals_845, primals_847, primals_848, primals_850, primals_851, primals_853, primals_854, primals_856, primals_857, primals_859, primals_860, primals_862, primals_863, primals_865, primals_866, primals_868, primals_869, primals_871, primals_872, primals_874, primals_875, primals_877, primals_878, primals_880, primals_881, primals_883, primals_884, primals_886, primals_887, primals_889, primals_890, primals_892, primals_893, primals_895, primals_896, primals_898, primals_899, primals_901, primals_902, primals_904, primals_905, primals_907, primals_908, primals_910, primals_911, primals_913, primals_914, primals_916, primals_917, primals_919, primals_920, primals_922, primals_923, primals_925, primals_926, primals_928, primals_929, primals_931, primals_932, primals_934, primals_935, primals_937, primals_938, primals_940, primals_942, primals_944, primals_945, primals_947, primals_948, primals_950, primals_951, primals_953, primals_954, primals_956, primals_958, primals_960, primals_961, primals_963, primals_964, primals_966, primals_967, primals_969, primals_970, primals_972, primals_974, primals_976, primals_978, primals_1957, buf0, buf7, buf8, buf9, buf16, buf17, buf18, buf25, buf26, buf27, buf34, buf35, buf36, buf40, buf41, buf45, buf47, buf48, buf55, buf56, buf57, buf64, buf65, buf66, buf70, buf71, buf72, buf79, buf80, buf81, buf88, buf89, buf90, buf94, buf95, buf96, buf103, buf104, buf105, buf112, buf113, buf114, buf118, buf119, buf120, buf127, buf128, buf129, buf133, buf134, buf135, buf142, buf143, buf144, buf151, buf152, buf153, buf160, buf161, buf162, buf169, buf170, buf171, buf178, buf179, buf180, buf187, buf188, buf189, buf196, buf197, buf198, buf205, buf206, buf207, buf211, buf212, buf213, buf217, buf218, buf219, buf223, buf224, buf225, buf229, buf230, buf231, buf235, buf236, buf237, buf241, buf242, buf243, buf247, buf248, buf249, buf253, buf254, buf255, buf259, buf260, reinterpret_tensor(buf260, (56, 1), (1, 1), 0), buf261, buf262, buf266, buf267, buf268, buf272, buf273, buf274, buf281, buf282, buf283, buf290, buf291, buf292, buf299, buf300, buf301, buf308, buf309, buf310, buf317, buf318, buf319, buf326, buf327, buf328, buf335, buf336, buf337, buf344, buf345, buf346, buf350, buf351, buf352, buf356, buf357, buf358, buf362, buf363, buf364, buf368, buf369, buf370, buf374, buf375, buf376, buf380, buf381, buf382, buf386, buf387, buf388, buf392, buf393, buf394, buf398, buf399, buf400, buf404, buf405, buf406, buf410, buf411, buf412, buf416, buf417, buf418, buf422, buf423, buf424, buf428, buf429, buf430, buf434, buf435, buf436, buf440, buf441, buf442, buf446, buf447, buf451, buf452, reinterpret_tensor(buf452, (56, 1), (1, 1), 0), buf454, buf455, buf459, buf460, buf464, buf465, reinterpret_tensor(buf465, (28, 1), (1, 1), 0), buf467, buf468, buf472, buf473, buf474, buf478, buf479, buf483, buf485, buf486, buf493, buf494, buf495, buf502, buf503, buf504, buf511, buf512, buf513, buf520, buf521, buf522, buf529, buf530, buf531, buf538, buf539, buf540, buf547, buf548, buf549, buf556, buf557, buf558, buf562, buf563, buf564, buf568, buf569, buf570, buf574, buf575, buf576, buf580, buf581, buf582, buf586, buf587, buf588, buf592, buf593, buf594, buf598, buf599, buf600, buf604, buf605, buf606, buf610, buf611, buf612, buf616, buf617, buf618, buf622, buf623, buf624, buf628, buf629, buf630, buf634, buf635, buf636, buf640, buf641, buf642, buf646, buf647, buf648, buf652, buf653, buf654, buf658, buf659, buf663, buf665, buf666, buf670, buf671, buf675, buf677, buf678, buf682, buf683, buf684, buf688, buf689, buf693, buf695, buf696, buf703, buf704, buf705, buf712, buf713, buf714, buf721, buf722, buf723, buf730, buf731, buf732, buf739, buf740, buf741, buf748, buf749, buf750, buf757, buf758, buf759, buf766, buf767, buf768, buf772, buf773, buf774, buf778, buf779, buf780, buf784, buf785, buf786, buf790, buf791, buf792, buf796, buf797, buf798, buf802, buf803, buf804, buf808, buf809, buf810, buf814, buf815, buf816, buf820, buf821, buf822, buf826, buf827, buf828, buf832, buf833, buf834, buf838, buf839, buf840, buf844, buf845, buf846, buf850, buf851, buf852, buf856, buf857, buf858, buf862, buf863, buf864, buf868, buf869, buf873, buf875, buf876, buf880, buf881, buf885, buf887, buf888, buf892, buf893, buf894, buf898, buf899, buf903, buf905, buf906, buf913, buf914, buf915, buf922, buf923, buf924, buf931, buf932, buf933, buf940, buf941, buf942, buf949, buf950, buf951, buf958, buf959, buf960, buf967, buf968, buf969, buf976, buf977, buf978, buf982, buf983, buf984, buf988, buf989, buf990, buf994, buf995, buf996, buf1000, buf1001, buf1002, buf1006, buf1007, buf1008, buf1012, buf1013, buf1014, buf1018, buf1019, buf1020, buf1024, buf1025, buf1026, buf1030, buf1031, buf1032, buf1036, buf1037, buf1038, buf1042, buf1043, buf1044, buf1048, buf1049, buf1050, buf1054, buf1055, buf1056, buf1060, buf1061, buf1062, buf1066, buf1067, buf1068, buf1072, buf1073, buf1074, buf1078, buf1079, buf1083, buf1085, buf1086, buf1090, buf1091, buf1095, buf1097, buf1098, buf1102, buf1103, buf1104, buf1108, buf1109, buf1113, buf1115, buf1116, buf1120, buf1121, buf1122, buf1129, buf1130, buf1131, buf1138, buf1139, buf1140, buf1147, buf1148, buf1149, buf1156, buf1157, buf1158, buf1165, buf1166, buf1167, buf1174, buf1175, buf1176, buf1183, buf1184, buf1185, buf1192, buf1193, buf1194, buf1198, buf1199, buf1200, buf1204, buf1205, buf1206, buf1210, buf1211, buf1212, buf1216, buf1217, buf1218, buf1222, buf1223, buf1224, buf1228, buf1229, buf1230, buf1234, buf1235, buf1236, buf1240, buf1241, buf1242, buf1246, buf1247, buf1248, buf1252, buf1253, buf1254, buf1258, buf1259, buf1260, buf1264, buf1265, buf1266, buf1270, buf1271, buf1272, buf1276, buf1277, buf1278, buf1282, buf1283, buf1284, buf1288, buf1289, buf1290, buf1294, buf1295, buf1296, buf1300, buf1301, buf1302, buf1306, buf1307, buf1308, buf1312, buf1313, buf1314, buf1318, buf1319, buf1320, buf1324, buf1325, buf1326, buf1330, buf1331, buf1332, buf1336, buf1337, buf1338, buf1342, buf1343, buf1347, buf1349, buf1353, buf1354, reinterpret_tensor(buf1354, (56, 1), (1, 1), 0), buf1355, buf1356, buf1360, buf1361, buf1365, buf1367, buf1371, buf1372, reinterpret_tensor(buf1372, (28, 1), (1, 1), 0), buf1373, buf1374, buf1378, buf1379, buf1380, buf1384, buf1385, buf1389, buf1391, buf1395, buf1396, reinterpret_tensor(buf1396, (14, 1), (1, 1), 0), buf1398, buf1399, buf1403, buf1404, buf1405, buf1409, buf1410, buf1411, buf1415, buf1416, buf1420, buf1421, buf1422, buf1426, buf1428, buf1432, buf1433, buf1434, buf1441, buf1442, buf1443, buf1450, buf1451, buf1452, buf1459, buf1460, buf1461, buf1468, buf1469, buf1470, buf1477, buf1478, buf1479, buf1486, buf1487, buf1488, buf1495, buf1496, buf1497, buf1504, buf1505, buf1506, buf1510, buf1511, buf1512, buf1516, buf1517, buf1518, buf1522, buf1523, buf1524, buf1528, buf1529, buf1530, buf1534, buf1535, buf1536, buf1540, buf1541, buf1542, buf1546, buf1547, buf1548, buf1552, buf1553, buf1554, buf1558, buf1559, buf1560, buf1564, buf1565, buf1566, buf1570, buf1571, buf1572, buf1576, buf1577, buf1578, buf1582, buf1583, buf1584, buf1588, buf1589, buf1590, buf1594, buf1595, buf1596, buf1600, buf1601, buf1602, buf1606, buf1607, buf1608, buf1612, buf1613, buf1614, buf1618, buf1619, buf1620, buf1624, buf1625, buf1626, buf1630, buf1631, buf1632, buf1636, buf1637, buf1638, buf1642, buf1643, buf1644, buf1648, buf1649, buf1650, buf1654, buf1655, buf1659, buf1661, buf1665, buf1666, buf1667, buf1671, buf1672, buf1676, buf1678, buf1682, buf1683, buf1684, buf1688, buf1689, buf1690, buf1694, buf1695, buf1699, buf1701, buf1705, buf1707, buf1708, buf1712, buf1713, buf1714, buf1718, buf1719, buf1720, buf1724, buf1725, buf1729, buf1730, buf1731, buf1735, buf1737, buf1741, buf1742, buf1743, buf1750, buf1751, buf1752, buf1759, buf1760, buf1761, buf1768, buf1769, buf1770, buf1777, buf1778, buf1779, buf1786, buf1787, buf1788, buf1795, buf1796, buf1797, buf1804, buf1805, buf1806, buf1813, buf1814, buf1815, buf1819, buf1820, buf1821, buf1825, buf1826, buf1827, buf1831, buf1832, buf1833, buf1837, buf1838, buf1839, buf1843, buf1844, buf1845, buf1849, buf1850, buf1851, buf1855, buf1856, buf1857, buf1861, buf1862, buf1863, buf1867, buf1868, buf1869, buf1873, buf1874, buf1875, buf1879, buf1880, buf1881, buf1885, buf1886, buf1887, buf1891, buf1892, buf1893, buf1897, buf1898, buf1899, buf1903, buf1904, buf1905, buf1909, buf1910, buf1911, buf1915, buf1916, buf1917, buf1921, buf1922, buf1923, buf1927, buf1928, buf1929, buf1933, buf1934, buf1935, buf1939, buf1940, buf1941, buf1945, buf1946, buf1947, buf1951, buf1952, buf1953, buf1957, buf1958, buf1959, buf1963, buf1964, buf1968, buf1970, buf1974, buf1975, buf1976, buf1980, buf1981, buf1985, buf1987, buf1991, buf1992, buf1993, buf1997, buf1998, buf1999, buf2003, buf2004, buf2008, buf2010, buf2014, buf2016, buf2017, buf2021, buf2022, buf2023, buf2027, buf2028, buf2029, buf2033, buf2034, buf2038, buf2039, buf2040, buf2044, buf2046, buf2050, buf2051, buf2052, buf2059, buf2060, buf2061, buf2068, buf2069, buf2070, buf2077, buf2078, buf2085, buf2087, buf2088, buf2092, buf2093, buf2094, buf2098, buf2099, buf2100, buf2104, buf2105, buf2109, buf2112, buf2116, buf2118, buf2119, buf2123, buf2124, buf2125, buf2129, buf2130, buf2131, buf2135, buf2136, buf2140, buf2143, buf2147, buf2149, buf2150, buf2154, buf2155, buf2156, buf2160, buf2161, buf2162, buf2166, buf2167, buf2171, buf2174, buf2178, buf2180, buf2182, buf2186, buf2189, reinterpret_tensor(primals_980, (1000, 2048), (2048, 1), 0), buf2191, reinterpret_tensor(buf2183, (1, 2048, 1, 1), (2048, 1, 1, 1), 0), buf2192, reinterpret_tensor(buf2175, (1, 1024, 1, 1), (1024, 1, 1, 1), 0), buf2193, reinterpret_tensor(buf2168, (1, 1024, 1, 1), (1024, 1, 1, 1), 0), reinterpret_tensor(buf2163, (1, 1024, 1, 1), (1024, 1, 1, 1), 0), reinterpret_tensor(buf2157, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf2151, (1, 256, 1, 1), (256, 1, 1, 1), 0), buf2194, reinterpret_tensor(buf2144, (1, 512, 1, 1), (512, 1, 1, 1), 0), buf2195, reinterpret_tensor(buf2137, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf2132, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf2126, (1, 128, 1, 1), (128, 1, 1, 1), 0), reinterpret_tensor(buf2120, (1, 128, 1, 1), (128, 1, 1, 1), 0), buf2196, reinterpret_tensor(buf2113, (1, 256, 1, 1), (256, 1, 1, 1), 0), buf2197, reinterpret_tensor(buf2106, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf2101, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf2095, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf2089, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf2082, (1, 128, 1, 1), (128, 1, 1, 1), 0), reinterpret_tensor(buf2074, (1, 128, 1, 1), (128, 1, 1, 1), 0), reinterpret_tensor(buf2065, (1, 32, 1, 1), (32, 1, 1, 1), 0), reinterpret_tensor(buf2056, (1, 32, 1, 1), (32, 1, 1, 1), 0), reinterpret_tensor(buf2047, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf2041, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf2035, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf2030, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf2024, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf2018, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf2011, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf2005, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf2000, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1994, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1988, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1982, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1977, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1971, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1965, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1960, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1954, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1948, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1942, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1936, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1930, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1924, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1918, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1912, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1906, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1900, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1894, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1888, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1882, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1876, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1870, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1864, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1858, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1852, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1846, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1840, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1834, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1828, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1822, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1816, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1810, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1801, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1792, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1783, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1774, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1765, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1756, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1747, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1738, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1732, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1726, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1721, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1715, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1709, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1702, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1696, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1691, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1685, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1679, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1673, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1668, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1662, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1656, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1651, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1645, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1639, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1633, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1627, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1621, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1615, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1609, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1603, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1597, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1591, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1585, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1579, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1573, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1567, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1561, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1555, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1549, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1543, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1537, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1531, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1525, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1519, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1513, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1507, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1501, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1492, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1483, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1474, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1465, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1456, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1447, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1438, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1429, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1423, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1417, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1412, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1406, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1400, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1392, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1386, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1381, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1375, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1368, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1362, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1357, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1350, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1344, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1339, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1333, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1327, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1321, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1315, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1309, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1303, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1297, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1291, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1285, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1279, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1273, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1267, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1261, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1255, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1249, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1243, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1237, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1231, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1225, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1219, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1213, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1207, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1201, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1195, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1189, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1180, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1171, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1162, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1153, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1144, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1135, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1126, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1117, (1, 144, 1, 1), (144, 1, 1, 1), 0), reinterpret_tensor(buf1110, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1105, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1099, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1092, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1087, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1080, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1075, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf1069, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1063, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1057, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1051, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1045, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1039, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1033, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1027, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf1021, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1015, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1009, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf1003, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf997, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf991, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf985, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf979, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf973, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf964, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf955, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf946, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf937, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf928, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf919, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf910, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf900, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf895, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf889, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf882, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf877, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf870, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf865, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf859, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf853, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf847, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf841, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf835, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf829, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf823, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf817, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf811, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf805, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf799, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf793, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf787, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf781, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf775, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf769, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf763, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf754, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf745, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf736, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf727, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf718, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf709, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf700, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf690, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf685, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf679, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf672, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf667, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf660, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf655, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf649, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf643, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf637, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf631, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf625, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf619, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf613, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf607, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf601, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf595, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf589, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf583, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf577, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf571, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf565, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf559, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf553, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf544, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf535, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf526, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf517, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf508, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf499, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf490, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf480, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf475, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf469, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf461, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf456, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf448, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf443, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf437, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf431, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf425, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf419, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf413, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf407, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf401, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf395, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf389, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf383, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf377, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf371, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf365, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf359, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf353, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf347, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf341, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf332, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf323, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf314, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf305, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf296, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf287, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf278, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf269, (1, 72, 1, 1), (72, 1, 1, 1), 0), reinterpret_tensor(buf263, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf256, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf250, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf244, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf238, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf232, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf226, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf220, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf214, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf208, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf202, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf193, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf184, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf175, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf166, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf157, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf148, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf139, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf130, (1, 36, 1, 1), (36, 1, 1, 1), 0), reinterpret_tensor(buf124, (1, 18, 1, 1), (18, 1, 1, 1), 0), reinterpret_tensor(buf115, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf109, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf100, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf91, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf85, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf76, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf67, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf61, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf52, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf42, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf37, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf31, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf22, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf13, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf4, (1, 64, 1, 1), (64, 1, 1, 1), 0), )


def benchmark_compiled_module(times=10, repeat=10):
    from torch._dynamo.testing import rand_strided
    from torch._inductor.utils import print_performance
    primals_1 = rand_strided((64, 3, 3, 3), (27, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_2 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_3 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_4 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_5 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_6 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_7 = rand_strided((64, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_8 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_9 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_10 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_11 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_12 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_13 = rand_strided((256, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_14 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_15 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_16 = rand_strided((256, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_17 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_18 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_19 = rand_strided((64, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_20 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_21 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_22 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_23 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_24 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_25 = rand_strided((256, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_26 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_27 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_28 = rand_strided((64, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_29 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_30 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_31 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_32 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_33 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_34 = rand_strided((256, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_35 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_36 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_37 = rand_strided((64, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_38 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_39 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_40 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_41 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_42 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_43 = rand_strided((256, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_44 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_45 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_46 = rand_strided((18, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_47 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_48 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_49 = rand_strided((36, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_50 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_51 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_52 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_53 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_54 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_55 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_56 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_57 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_58 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_59 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_60 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_61 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_62 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_63 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_64 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_65 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_66 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_67 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_68 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_69 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_70 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_71 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_72 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_73 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_74 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_75 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_76 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_77 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_78 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_79 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_80 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_81 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_82 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_83 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_84 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_85 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_86 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_87 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_88 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_89 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_90 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_91 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_92 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_93 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_94 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_95 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_96 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_97 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_98 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_99 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_100 = rand_strided((18, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_101 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_102 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_103 = rand_strided((36, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_104 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_105 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_106 = rand_strided((72, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_107 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_108 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_109 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_110 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_111 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_112 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_113 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_114 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_115 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_116 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_117 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_118 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_119 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_120 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_121 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_122 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_123 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_124 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_125 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_126 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_127 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_128 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_129 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_130 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_131 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_132 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_133 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_134 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_135 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_136 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_137 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_138 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_139 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_140 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_141 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_142 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_143 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_144 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_145 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_146 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_147 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_148 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_149 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_150 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_151 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_152 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_153 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_154 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_155 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_156 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_157 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_158 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_159 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_160 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_161 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_162 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_163 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_164 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_165 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_166 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_167 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_168 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_169 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_170 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_171 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_172 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_173 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_174 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_175 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_176 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_177 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_178 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_179 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_180 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_181 = rand_strided((18, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_182 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_183 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_184 = rand_strided((18, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_185 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_186 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_187 = rand_strided((36, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_188 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_189 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_190 = rand_strided((36, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_191 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_192 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_193 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_194 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_195 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_196 = rand_strided((72, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_197 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_198 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_199 = rand_strided((72, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_200 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_201 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_202 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_203 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_204 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_205 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_206 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_207 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_208 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_209 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_210 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_211 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_212 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_213 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_214 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_215 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_216 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_217 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_218 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_219 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_220 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_221 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_222 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_223 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_224 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_225 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_226 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_227 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_228 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_229 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_230 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_231 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_232 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_233 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_234 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_235 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_236 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_237 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_238 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_239 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_240 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_241 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_242 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_243 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_244 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_245 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_246 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_247 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_248 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_249 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_250 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_251 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_252 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_253 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_254 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_255 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_256 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_257 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_258 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_259 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_260 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_261 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_262 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_263 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_264 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_265 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_266 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_267 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_268 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_269 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_270 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_271 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_272 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_273 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_274 = rand_strided((18, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_275 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_276 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_277 = rand_strided((18, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_278 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_279 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_280 = rand_strided((36, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_281 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_282 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_283 = rand_strided((36, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_284 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_285 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_286 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_287 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_288 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_289 = rand_strided((72, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_290 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_291 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_292 = rand_strided((72, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_293 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_294 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_295 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_296 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_297 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_298 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_299 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_300 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_301 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_302 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_303 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_304 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_305 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_306 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_307 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_308 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_309 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_310 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_311 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_312 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_313 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_314 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_315 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_316 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_317 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_318 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_319 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_320 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_321 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_322 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_323 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_324 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_325 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_326 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_327 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_328 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_329 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_330 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_331 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_332 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_333 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_334 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_335 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_336 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_337 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_338 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_339 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_340 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_341 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_342 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_343 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_344 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_345 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_346 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_347 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_348 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_349 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_350 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_351 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_352 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_353 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_354 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_355 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_356 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_357 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_358 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_359 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_360 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_361 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_362 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_363 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_364 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_365 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_366 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_367 = rand_strided((18, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_368 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_369 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_370 = rand_strided((18, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_371 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_372 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_373 = rand_strided((36, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_374 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_375 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_376 = rand_strided((36, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_377 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_378 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_379 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_380 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_381 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_382 = rand_strided((72, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_383 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_384 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_385 = rand_strided((72, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_386 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_387 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_388 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_389 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_390 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_391 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_392 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_393 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_394 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_395 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_396 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_397 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_398 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_399 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_400 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_401 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_402 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_403 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_404 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_405 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_406 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_407 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_408 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_409 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_410 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_411 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_412 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_413 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_414 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_415 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_416 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_417 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_418 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_419 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_420 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_421 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_422 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_423 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_424 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_425 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_426 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_427 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_428 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_429 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_430 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_431 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_432 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_433 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_434 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_435 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_436 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_437 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_438 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_439 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_440 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_441 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_442 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_443 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_444 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_445 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_446 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_447 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_448 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_449 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_450 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_451 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_452 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_453 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_454 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_455 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_456 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_457 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_458 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_459 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_460 = rand_strided((18, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_461 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_462 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_463 = rand_strided((18, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_464 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_465 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_466 = rand_strided((36, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_467 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_468 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_469 = rand_strided((36, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_470 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_471 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_472 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_473 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_474 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_475 = rand_strided((72, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_476 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_477 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_478 = rand_strided((72, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_479 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_480 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_481 = rand_strided((144, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_482 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_483 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_484 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_485 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_486 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_487 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_488 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_489 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_490 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_491 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_492 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_493 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_494 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_495 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_496 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_497 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_498 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_499 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_500 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_501 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_502 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_503 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_504 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_505 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_506 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_507 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_508 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_509 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_510 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_511 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_512 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_513 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_514 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_515 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_516 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_517 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_518 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_519 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_520 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_521 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_522 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_523 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_524 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_525 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_526 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_527 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_528 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_529 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_530 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_531 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_532 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_533 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_534 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_535 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_536 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_537 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_538 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_539 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_540 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_541 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_542 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_543 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_544 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_545 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_546 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_547 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_548 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_549 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_550 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_551 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_552 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_553 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_554 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_555 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_556 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_557 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_558 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_559 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_560 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_561 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_562 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_563 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_564 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_565 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_566 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_567 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_568 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_569 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_570 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_571 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_572 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_573 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_574 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_575 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_576 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_577 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_578 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_579 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_580 = rand_strided((18, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_581 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_582 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_583 = rand_strided((18, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_584 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_585 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_586 = rand_strided((18, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_587 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_588 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_589 = rand_strided((36, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_590 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_591 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_592 = rand_strided((36, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_593 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_594 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_595 = rand_strided((36, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_596 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_597 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_598 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_599 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_600 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_601 = rand_strided((72, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_602 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_603 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_604 = rand_strided((72, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_605 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_606 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_607 = rand_strided((72, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_608 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_609 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_610 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_611 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_612 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_613 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_614 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_615 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_616 = rand_strided((144, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_617 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_618 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_619 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_620 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_621 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_622 = rand_strided((144, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_623 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_624 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_625 = rand_strided((144, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_626 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_627 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_628 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_629 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_630 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_631 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_632 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_633 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_634 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_635 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_636 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_637 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_638 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_639 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_640 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_641 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_642 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_643 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_644 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_645 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_646 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_647 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_648 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_649 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_650 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_651 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_652 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_653 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_654 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_655 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_656 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_657 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_658 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_659 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_660 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_661 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_662 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_663 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_664 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_665 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_666 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_667 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_668 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_669 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_670 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_671 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_672 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_673 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_674 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_675 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_676 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_677 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_678 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_679 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_680 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_681 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_682 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_683 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_684 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_685 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_686 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_687 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_688 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_689 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_690 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_691 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_692 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_693 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_694 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_695 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_696 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_697 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_698 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_699 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_700 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_701 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_702 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_703 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_704 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_705 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_706 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_707 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_708 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_709 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_710 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_711 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_712 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_713 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_714 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_715 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_716 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_717 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_718 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_719 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_720 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_721 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_722 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_723 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_724 = rand_strided((18, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_725 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_726 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_727 = rand_strided((18, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_728 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_729 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_730 = rand_strided((18, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_731 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_732 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_733 = rand_strided((36, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_734 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_735 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_736 = rand_strided((36, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_737 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_738 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_739 = rand_strided((36, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_740 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_741 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_742 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_743 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_744 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_745 = rand_strided((72, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_746 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_747 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_748 = rand_strided((72, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_749 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_750 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_751 = rand_strided((72, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_752 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_753 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_754 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_755 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_756 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_757 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_758 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_759 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_760 = rand_strided((144, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_761 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_762 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_763 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_764 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_765 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_766 = rand_strided((144, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_767 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_768 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_769 = rand_strided((144, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_770 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_771 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_772 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_773 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_774 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_775 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_776 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_777 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_778 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_779 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_780 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_781 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_782 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_783 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_784 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_785 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_786 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_787 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_788 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_789 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_790 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_791 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_792 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_793 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_794 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_795 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_796 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_797 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_798 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_799 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_800 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_801 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_802 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_803 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_804 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_805 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_806 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_807 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_808 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_809 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_810 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_811 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_812 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_813 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_814 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_815 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_816 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_817 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_818 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_819 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_820 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_821 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_822 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_823 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_824 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_825 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_826 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_827 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_828 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_829 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_830 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_831 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_832 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_833 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_834 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_835 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_836 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_837 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_838 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_839 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_840 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_841 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_842 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_843 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_844 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_845 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_846 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_847 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_848 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_849 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_850 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_851 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_852 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_853 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_854 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_855 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_856 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_857 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_858 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_859 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_860 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_861 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_862 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_863 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_864 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_865 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_866 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_867 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_868 = rand_strided((18, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_869 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_870 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_871 = rand_strided((18, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_872 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_873 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_874 = rand_strided((18, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_875 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_876 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_877 = rand_strided((36, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_878 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_879 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_880 = rand_strided((36, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_881 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_882 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_883 = rand_strided((36, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_884 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_885 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_886 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_887 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_888 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_889 = rand_strided((72, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_890 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_891 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_892 = rand_strided((72, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_893 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_894 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_895 = rand_strided((72, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_896 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_897 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_898 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_899 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_900 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_901 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_902 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_903 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_904 = rand_strided((144, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_905 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_906 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_907 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_908 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_909 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_910 = rand_strided((144, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_911 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_912 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_913 = rand_strided((144, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_914 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_915 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_916 = rand_strided((32, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_917 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_918 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_919 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_920 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_921 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_922 = rand_strided((128, 32, 1, 1), (32, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_923 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_924 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_925 = rand_strided((128, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_926 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_927 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_928 = rand_strided((64, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_929 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_930 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_931 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_932 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_933 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_934 = rand_strided((256, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_935 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_936 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_937 = rand_strided((256, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_938 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_939 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_940 = rand_strided((256, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_941 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_942 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_943 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_944 = rand_strided((128, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_945 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_946 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_947 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_948 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_949 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_950 = rand_strided((512, 128, 1, 1), (128, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_951 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_952 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_953 = rand_strided((512, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_954 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_955 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_956 = rand_strided((512, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_957 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_958 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_959 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_960 = rand_strided((256, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_961 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_962 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_963 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_964 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_965 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_966 = rand_strided((1024, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_967 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_968 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_969 = rand_strided((1024, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_970 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_971 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_972 = rand_strided((1024, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_973 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_974 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_975 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_976 = rand_strided((2048, 1024, 1, 1), (1024, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_977 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_978 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_979 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_980 = rand_strided((1000, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
    primals_981 = rand_strided((1000, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_982 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_983 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_984 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_985 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_986 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_987 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_988 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_989 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_990 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_991 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_992 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_993 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_994 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_995 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_996 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_997 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_998 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_999 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1000 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1001 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1002 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1003 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1004 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1005 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1006 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1007 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1008 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1009 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1010 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1011 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1012 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1013 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1014 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1015 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1016 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1017 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1018 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1019 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1020 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1021 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1022 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1023 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1024 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1025 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1026 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1027 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1028 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1029 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1030 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1031 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1032 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1033 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1034 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1035 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1036 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1037 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1038 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1039 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1040 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1041 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1042 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1043 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1044 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1045 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1046 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1047 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1048 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1049 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1050 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1051 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1052 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1053 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1054 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1055 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1056 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1057 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1058 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1059 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1060 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1061 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1062 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1063 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1064 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1065 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1066 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1067 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1068 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1069 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1070 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1071 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1072 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1073 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1074 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1075 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1076 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1077 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1078 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1079 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1080 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1081 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1082 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1083 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1084 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1085 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1086 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1087 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1088 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1089 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1090 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1091 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1092 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1093 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1094 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1095 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1096 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1097 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1098 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1099 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1100 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1101 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1102 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1103 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1104 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1105 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1106 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1107 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1108 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1109 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1110 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1111 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1112 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1113 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1114 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1115 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1116 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1117 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1118 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1119 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1120 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1121 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1122 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1123 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1124 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1125 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1126 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1127 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1128 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1129 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1130 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1131 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1132 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1133 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1134 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1135 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1136 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1137 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1138 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1139 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1140 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1141 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1142 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1143 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1144 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1145 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1146 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1147 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1148 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1149 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1150 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1151 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1152 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1153 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1154 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1155 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1156 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1157 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1158 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1159 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1160 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1161 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1162 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1163 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1164 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1165 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1166 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1167 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1168 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1169 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1170 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1171 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1172 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1173 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1174 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1175 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1176 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1177 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1178 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1179 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1180 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1181 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1182 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1183 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1184 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1185 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1186 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1187 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1188 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1189 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1190 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1191 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1192 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1193 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1194 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1195 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1196 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1197 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1198 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1199 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1200 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1201 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1202 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1203 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1204 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1205 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1206 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1207 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1208 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1209 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1210 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1211 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1212 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1213 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1214 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1215 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1216 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1217 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1218 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1219 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1220 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1221 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1222 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1223 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1224 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1225 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1226 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1227 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1228 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1229 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1230 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1231 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1232 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1233 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1234 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1235 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1236 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1237 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1238 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1239 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1240 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1241 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1242 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1243 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1244 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1245 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1246 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1247 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1248 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1249 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1250 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1251 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1252 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1253 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1254 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1255 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1256 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1257 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1258 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1259 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1260 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1261 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1262 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1263 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1264 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1265 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1266 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1267 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1268 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1269 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1270 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1271 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1272 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1273 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1274 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1275 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1276 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1277 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1278 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1279 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1280 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1281 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1282 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1283 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1284 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1285 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1286 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1287 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1288 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1289 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1290 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1291 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1292 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1293 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1294 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1295 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1296 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1297 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1298 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1299 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1300 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1301 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1302 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1303 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1304 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1305 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1306 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1307 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1308 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1309 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1310 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1311 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1312 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1313 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1314 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1315 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1316 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1317 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1318 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1319 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1320 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1321 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1322 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1323 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1324 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1325 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1326 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1327 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1328 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1329 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1330 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1331 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1332 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1333 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1334 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1335 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1336 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1337 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1338 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1339 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1340 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1341 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1342 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1343 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1344 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1345 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1346 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1347 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1348 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1349 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1350 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1351 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1352 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1353 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1354 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1355 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1356 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1357 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1358 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1359 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1360 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1361 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1362 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1363 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1364 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1365 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1366 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1367 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1368 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1369 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1370 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1371 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1372 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1373 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1374 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1375 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1376 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1377 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1378 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1379 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1380 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1381 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1382 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1383 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1384 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1385 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1386 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1387 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1388 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1389 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1390 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1391 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1392 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1393 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1394 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1395 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1396 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1397 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1398 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1399 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1400 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1401 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1402 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1403 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1404 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1405 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1406 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1407 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1408 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1409 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1410 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1411 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1412 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1413 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1414 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1415 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1416 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1417 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1418 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1419 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1420 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1421 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1422 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1423 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1424 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1425 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1426 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1427 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1428 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1429 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1430 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1431 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1432 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1433 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1434 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1435 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1436 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1437 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1438 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1439 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1440 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1441 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1442 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1443 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1444 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1445 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1446 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1447 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1448 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1449 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1450 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1451 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1452 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1453 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1454 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1455 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1456 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1457 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1458 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1459 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1460 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1461 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1462 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1463 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1464 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1465 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1466 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1467 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1468 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1469 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1470 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1471 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1472 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1473 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1474 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1475 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1476 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1477 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1478 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1479 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1480 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1481 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1482 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1483 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1484 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1485 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1486 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1487 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1488 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1489 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1490 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1491 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1492 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1493 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1494 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1495 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1496 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1497 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1498 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1499 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1500 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1501 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1502 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1503 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1504 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1505 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1506 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1507 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1508 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1509 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1510 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1511 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1512 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1513 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1514 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1515 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1516 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1517 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1518 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1519 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1520 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1521 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1522 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1523 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1524 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1525 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1526 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1527 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1528 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1529 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1530 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1531 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1532 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1533 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1534 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1535 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1536 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1537 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1538 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1539 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1540 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1541 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1542 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1543 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1544 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1545 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1546 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1547 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1548 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1549 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1550 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1551 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1552 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1553 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1554 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1555 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1556 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1557 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1558 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1559 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1560 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1561 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1562 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1563 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1564 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1565 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1566 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1567 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1568 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1569 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1570 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1571 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1572 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1573 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1574 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1575 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1576 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1577 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1578 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1579 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1580 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1581 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1582 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1583 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1584 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1585 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1586 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1587 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1588 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1589 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1590 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1591 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1592 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1593 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1594 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1595 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1596 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1597 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1598 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1599 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1600 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1601 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1602 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1603 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1604 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1605 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1606 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1607 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1608 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1609 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1610 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1611 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1612 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1613 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1614 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1615 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1616 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1617 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1618 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1619 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1620 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1621 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1622 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1623 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1624 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1625 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1626 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1627 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1628 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1629 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1630 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1631 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1632 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1633 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1634 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1635 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1636 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1637 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1638 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1639 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1640 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1641 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1642 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1643 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1644 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1645 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1646 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1647 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1648 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1649 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1650 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1651 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1652 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1653 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1654 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1655 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1656 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1657 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1658 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1659 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1660 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1661 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1662 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1663 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1664 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1665 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1666 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1667 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1668 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1669 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1670 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1671 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1672 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1673 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1674 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1675 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1676 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1677 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1678 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1679 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1680 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1681 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1682 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1683 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1684 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1685 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1686 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1687 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1688 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1689 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1690 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1691 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1692 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1693 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1694 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1695 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1696 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1697 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1698 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1699 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1700 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1701 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1702 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1703 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1704 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1705 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1706 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1707 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1708 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1709 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1710 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1711 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1712 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1713 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1714 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1715 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1716 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1717 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1718 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1719 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1720 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1721 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1722 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1723 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1724 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1725 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1726 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1727 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1728 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1729 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1730 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1731 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1732 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1733 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1734 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1735 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1736 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1737 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1738 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1739 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1740 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1741 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1742 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1743 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1744 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1745 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1746 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1747 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1748 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1749 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1750 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1751 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1752 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1753 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1754 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1755 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1756 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1757 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1758 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1759 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1760 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1761 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1762 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1763 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1764 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1765 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1766 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1767 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1768 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1769 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1770 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1771 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1772 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1773 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1774 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1775 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1776 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1777 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1778 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1779 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1780 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1781 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1782 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1783 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1784 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1785 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1786 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1787 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1788 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1789 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1790 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1791 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1792 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1793 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1794 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1795 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1796 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1797 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1798 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1799 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1800 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1801 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1802 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1803 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1804 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1805 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1806 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1807 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1808 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1809 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1810 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1811 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1812 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1813 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1814 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1815 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1816 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1817 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1818 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1819 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1820 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1821 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1822 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1823 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1824 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1825 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1826 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1827 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1828 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1829 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1830 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1831 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1832 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1833 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1834 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1835 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1836 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1837 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1838 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1839 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1840 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1841 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1842 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1843 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1844 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1845 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1846 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1847 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1848 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1849 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1850 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1851 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1852 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1853 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1854 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1855 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1856 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1857 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1858 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1859 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1860 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1861 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1862 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1863 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1864 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1865 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1866 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1867 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1868 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1869 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1870 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1871 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1872 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1873 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1874 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1875 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1876 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1877 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1878 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1879 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1880 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1881 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1882 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1883 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1884 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1885 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1886 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1887 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1888 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1889 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1890 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1891 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1892 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1893 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1894 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1895 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1896 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1897 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1898 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1899 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1900 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1901 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1902 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1903 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1904 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1905 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1906 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1907 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1908 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1909 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1910 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1911 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1912 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1913 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1914 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1915 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1916 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1917 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1918 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1919 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1920 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1921 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1922 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1923 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1924 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1925 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1926 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1927 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1928 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1929 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1930 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1931 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1932 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1933 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1934 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1935 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1936 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1937 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1938 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1939 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1940 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1941 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1942 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1943 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1944 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1945 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1946 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1947 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1948 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1949 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1950 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1951 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1952 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1953 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1954 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1955 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1956 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
    primals_1957 = rand_strided((8, 3, 224, 224), (150528, 50176, 224, 1), device='cuda:0', dtype=torch.float32)
    return print_performance(lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190, primals_191, primals_192, primals_193, primals_194, primals_195, primals_196, primals_197, primals_198, primals_199, primals_200, primals_201, primals_202, primals_203, primals_204, primals_205, primals_206, primals_207, primals_208, primals_209, primals_210, primals_211, primals_212, primals_213, primals_214, primals_215, primals_216, primals_217, primals_218, primals_219, primals_220, primals_221, primals_222, primals_223, primals_224, primals_225, primals_226, primals_227, primals_228, primals_229, primals_230, primals_231, primals_232, primals_233, primals_234, primals_235, primals_236, primals_237, primals_238, primals_239, primals_240, primals_241, primals_242, primals_243, primals_244, primals_245, primals_246, primals_247, primals_248, primals_249, primals_250, primals_251, primals_252, primals_253, primals_254, primals_255, primals_256, primals_257, primals_258, primals_259, primals_260, primals_261, primals_262, primals_263, primals_264, primals_265, primals_266, primals_267, primals_268, primals_269, primals_270, primals_271, primals_272, primals_273, primals_274, primals_275, primals_276, primals_277, primals_278, primals_279, primals_280, primals_281, primals_282, primals_283, primals_284, primals_285, primals_286, primals_287, primals_288, primals_289, primals_290, primals_291, primals_292, primals_293, primals_294, primals_295, primals_296, primals_297, primals_298, primals_299, primals_300, primals_301, primals_302, primals_303, primals_304, primals_305, primals_306, primals_307, primals_308, primals_309, primals_310, primals_311, primals_312, primals_313, primals_314, primals_315, primals_316, primals_317, primals_318, primals_319, primals_320, primals_321, primals_322, primals_323, primals_324, primals_325, primals_326, primals_327, primals_328, primals_329, primals_330, primals_331, primals_332, primals_333, primals_334, primals_335, primals_336, primals_337, primals_338, primals_339, primals_340, primals_341, primals_342, primals_343, primals_344, primals_345, primals_346, primals_347, primals_348, primals_349, primals_350, primals_351, primals_352, primals_353, primals_354, primals_355, primals_356, primals_357, primals_358, primals_359, primals_360, primals_361, primals_362, primals_363, primals_364, primals_365, primals_366, primals_367, primals_368, primals_369, primals_370, primals_371, primals_372, primals_373, primals_374, primals_375, primals_376, primals_377, primals_378, primals_379, primals_380, primals_381, primals_382, primals_383, primals_384, primals_385, primals_386, primals_387, primals_388, primals_389, primals_390, primals_391, primals_392, primals_393, primals_394, primals_395, primals_396, primals_397, primals_398, primals_399, primals_400, primals_401, primals_402, primals_403, primals_404, primals_405, primals_406, primals_407, primals_408, primals_409, primals_410, primals_411, primals_412, primals_413, primals_414, primals_415, primals_416, primals_417, primals_418, primals_419, primals_420, primals_421, primals_422, primals_423, primals_424, primals_425, primals_426, primals_427, primals_428, primals_429, primals_430, primals_431, primals_432, primals_433, primals_434, primals_435, primals_436, primals_437, primals_438, primals_439, primals_440, primals_441, primals_442, primals_443, primals_444, primals_445, primals_446, primals_447, primals_448, primals_449, primals_450, primals_451, primals_452, primals_453, primals_454, primals_455, primals_456, primals_457, primals_458, primals_459, primals_460, primals_461, primals_462, primals_463, primals_464, primals_465, primals_466, primals_467, primals_468, primals_469, primals_470, primals_471, primals_472, primals_473, primals_474, primals_475, primals_476, primals_477, primals_478, primals_479, primals_480, primals_481, primals_482, primals_483, primals_484, primals_485, primals_486, primals_487, primals_488, primals_489, primals_490, primals_491, primals_492, primals_493, primals_494, primals_495, primals_496, primals_497, primals_498, primals_499, primals_500, primals_501, primals_502, primals_503, primals_504, primals_505, primals_506, primals_507, primals_508, primals_509, primals_510, primals_511, primals_512, primals_513, primals_514, primals_515, primals_516, primals_517, primals_518, primals_519, primals_520, primals_521, primals_522, primals_523, primals_524, primals_525, primals_526, primals_527, primals_528, primals_529, primals_530, primals_531, primals_532, primals_533, primals_534, primals_535, primals_536, primals_537, primals_538, primals_539, primals_540, primals_541, primals_542, primals_543, primals_544, primals_545, primals_546, primals_547, primals_548, primals_549, primals_550, primals_551, primals_552, primals_553, primals_554, primals_555, primals_556, primals_557, primals_558, primals_559, primals_560, primals_561, primals_562, primals_563, primals_564, primals_565, primals_566, primals_567, primals_568, primals_569, primals_570, primals_571, primals_572, primals_573, primals_574, primals_575, primals_576, primals_577, primals_578, primals_579, primals_580, primals_581, primals_582, primals_583, primals_584, primals_585, primals_586, primals_587, primals_588, primals_589, primals_590, primals_591, primals_592, primals_593, primals_594, primals_595, primals_596, primals_597, primals_598, primals_599, primals_600, primals_601, primals_602, primals_603, primals_604, primals_605, primals_606, primals_607, primals_608, primals_609, primals_610, primals_611, primals_612, primals_613, primals_614, primals_615, primals_616, primals_617, primals_618, primals_619, primals_620, primals_621, primals_622, primals_623, primals_624, primals_625, primals_626, primals_627, primals_628, primals_629, primals_630, primals_631, primals_632, primals_633, primals_634, primals_635, primals_636, primals_637, primals_638, primals_639, primals_640, primals_641, primals_642, primals_643, primals_644, primals_645, primals_646, primals_647, primals_648, primals_649, primals_650, primals_651, primals_652, primals_653, primals_654, primals_655, primals_656, primals_657, primals_658, primals_659, primals_660, primals_661, primals_662, primals_663, primals_664, primals_665, primals_666, primals_667, primals_668, primals_669, primals_670, primals_671, primals_672, primals_673, primals_674, primals_675, primals_676, primals_677, primals_678, primals_679, primals_680, primals_681, primals_682, primals_683, primals_684, primals_685, primals_686, primals_687, primals_688, primals_689, primals_690, primals_691, primals_692, primals_693, primals_694, primals_695, primals_696, primals_697, primals_698, primals_699, primals_700, primals_701, primals_702, primals_703, primals_704, primals_705, primals_706, primals_707, primals_708, primals_709, primals_710, primals_711, primals_712, primals_713, primals_714, primals_715, primals_716, primals_717, primals_718, primals_719, primals_720, primals_721, primals_722, primals_723, primals_724, primals_725, primals_726, primals_727, primals_728, primals_729, primals_730, primals_731, primals_732, primals_733, primals_734, primals_735, primals_736, primals_737, primals_738, primals_739, primals_740, primals_741, primals_742, primals_743, primals_744, primals_745, primals_746, primals_747, primals_748, primals_749, primals_750, primals_751, primals_752, primals_753, primals_754, primals_755, primals_756, primals_757, primals_758, primals_759, primals_760, primals_761, primals_762, primals_763, primals_764, primals_765, primals_766, primals_767, primals_768, primals_769, primals_770, primals_771, primals_772, primals_773, primals_774, primals_775, primals_776, primals_777, primals_778, primals_779, primals_780, primals_781, primals_782, primals_783, primals_784, primals_785, primals_786, primals_787, primals_788, primals_789, primals_790, primals_791, primals_792, primals_793, primals_794, primals_795, primals_796, primals_797, primals_798, primals_799, primals_800, primals_801, primals_802, primals_803, primals_804, primals_805, primals_806, primals_807, primals_808, primals_809, primals_810, primals_811, primals_812, primals_813, primals_814, primals_815, primals_816, primals_817, primals_818, primals_819, primals_820, primals_821, primals_822, primals_823, primals_824, primals_825, primals_826, primals_827, primals_828, primals_829, primals_830, primals_831, primals_832, primals_833, primals_834, primals_835, primals_836, primals_837, primals_838, primals_839, primals_840, primals_841, primals_842, primals_843, primals_844, primals_845, primals_846, primals_847, primals_848, primals_849, primals_850, primals_851, primals_852, primals_853, primals_854, primals_855, primals_856, primals_857, primals_858, primals_859, primals_860, primals_861, primals_862, primals_863, primals_864, primals_865, primals_866, primals_867, primals_868, primals_869, primals_870, primals_871, primals_872, primals_873, primals_874, primals_875, primals_876, primals_877, primals_878, primals_879, primals_880, primals_881, primals_882, primals_883, primals_884, primals_885, primals_886, primals_887, primals_888, primals_889, primals_890, primals_891, primals_892, primals_893, primals_894, primals_895, primals_896, primals_897, primals_898, primals_899, primals_900, primals_901, primals_902, primals_903, primals_904, primals_905, primals_906, primals_907, primals_908, primals_909, primals_910, primals_911, primals_912, primals_913, primals_914, primals_915, primals_916, primals_917, primals_918, primals_919, primals_920, primals_921, primals_922, primals_923, primals_924, primals_925, primals_926, primals_927, primals_928, primals_929, primals_930, primals_931, primals_932, primals_933, primals_934, primals_935, primals_936, primals_937, primals_938, primals_939, primals_940, primals_941, primals_942, primals_943, primals_944, primals_945, primals_946, primals_947, primals_948, primals_949, primals_950, primals_951, primals_952, primals_953, primals_954, primals_955, primals_956, primals_957, primals_958, primals_959, primals_960, primals_961, primals_962, primals_963, primals_964, primals_965, primals_966, primals_967, primals_968, primals_969, primals_970, primals_971, primals_972, primals_973, primals_974, primals_975, primals_976, primals_977, primals_978, primals_979, primals_980, primals_981, primals_982, primals_983, primals_984, primals_985, primals_986, primals_987, primals_988, primals_989, primals_990, primals_991, primals_992, primals_993, primals_994, primals_995, primals_996, primals_997, primals_998, primals_999, primals_1000, primals_1001, primals_1002, primals_1003, primals_1004, primals_1005, primals_1006, primals_1007, primals_1008, primals_1009, primals_1010, primals_1011, primals_1012, primals_1013, primals_1014, primals_1015, primals_1016, primals_1017, primals_1018, primals_1019, primals_1020, primals_1021, primals_1022, primals_1023, primals_1024, primals_1025, primals_1026, primals_1027, primals_1028, primals_1029, primals_1030, primals_1031, primals_1032, primals_1033, primals_1034, primals_1035, primals_1036, primals_1037, primals_1038, primals_1039, primals_1040, primals_1041, primals_1042, primals_1043, primals_1044, primals_1045, primals_1046, primals_1047, primals_1048, primals_1049, primals_1050, primals_1051, primals_1052, primals_1053, primals_1054, primals_1055, primals_1056, primals_1057, primals_1058, primals_1059, primals_1060, primals_1061, primals_1062, primals_1063, primals_1064, primals_1065, primals_1066, primals_1067, primals_1068, primals_1069, primals_1070, primals_1071, primals_1072, primals_1073, primals_1074, primals_1075, primals_1076, primals_1077, primals_1078, primals_1079, primals_1080, primals_1081, primals_1082, primals_1083, primals_1084, primals_1085, primals_1086, primals_1087, primals_1088, primals_1089, primals_1090, primals_1091, primals_1092, primals_1093, primals_1094, primals_1095, primals_1096, primals_1097, primals_1098, primals_1099, primals_1100, primals_1101, primals_1102, primals_1103, primals_1104, primals_1105, primals_1106, primals_1107, primals_1108, primals_1109, primals_1110, primals_1111, primals_1112, primals_1113, primals_1114, primals_1115, primals_1116, primals_1117, primals_1118, primals_1119, primals_1120, primals_1121, primals_1122, primals_1123, primals_1124, primals_1125, primals_1126, primals_1127, primals_1128, primals_1129, primals_1130, primals_1131, primals_1132, primals_1133, primals_1134, primals_1135, primals_1136, primals_1137, primals_1138, primals_1139, primals_1140, primals_1141, primals_1142, primals_1143, primals_1144, primals_1145, primals_1146, primals_1147, primals_1148, primals_1149, primals_1150, primals_1151, primals_1152, primals_1153, primals_1154, primals_1155, primals_1156, primals_1157, primals_1158, primals_1159, primals_1160, primals_1161, primals_1162, primals_1163, primals_1164, primals_1165, primals_1166, primals_1167, primals_1168, primals_1169, primals_1170, primals_1171, primals_1172, primals_1173, primals_1174, primals_1175, primals_1176, primals_1177, primals_1178, primals_1179, primals_1180, primals_1181, primals_1182, primals_1183, primals_1184, primals_1185, primals_1186, primals_1187, primals_1188, primals_1189, primals_1190, primals_1191, primals_1192, primals_1193, primals_1194, primals_1195, primals_1196, primals_1197, primals_1198, primals_1199, primals_1200, primals_1201, primals_1202, primals_1203, primals_1204, primals_1205, primals_1206, primals_1207, primals_1208, primals_1209, primals_1210, primals_1211, primals_1212, primals_1213, primals_1214, primals_1215, primals_1216, primals_1217, primals_1218, primals_1219, primals_1220, primals_1221, primals_1222, primals_1223, primals_1224, primals_1225, primals_1226, primals_1227, primals_1228, primals_1229, primals_1230, primals_1231, primals_1232, primals_1233, primals_1234, primals_1235, primals_1236, primals_1237, primals_1238, primals_1239, primals_1240, primals_1241, primals_1242, primals_1243, primals_1244, primals_1245, primals_1246, primals_1247, primals_1248, primals_1249, primals_1250, primals_1251, primals_1252, primals_1253, primals_1254, primals_1255, primals_1256, primals_1257, primals_1258, primals_1259, primals_1260, primals_1261, primals_1262, primals_1263, primals_1264, primals_1265, primals_1266, primals_1267, primals_1268, primals_1269, primals_1270, primals_1271, primals_1272, primals_1273, primals_1274, primals_1275, primals_1276, primals_1277, primals_1278, primals_1279, primals_1280, primals_1281, primals_1282, primals_1283, primals_1284, primals_1285, primals_1286, primals_1287, primals_1288, primals_1289, primals_1290, primals_1291, primals_1292, primals_1293, primals_1294, primals_1295, primals_1296, primals_1297, primals_1298, primals_1299, primals_1300, primals_1301, primals_1302, primals_1303, primals_1304, primals_1305, primals_1306, primals_1307, primals_1308, primals_1309, primals_1310, primals_1311, primals_1312, primals_1313, primals_1314, primals_1315, primals_1316, primals_1317, primals_1318, primals_1319, primals_1320, primals_1321, primals_1322, primals_1323, primals_1324, primals_1325, primals_1326, primals_1327, primals_1328, primals_1329, primals_1330, primals_1331, primals_1332, primals_1333, primals_1334, primals_1335, primals_1336, primals_1337, primals_1338, primals_1339, primals_1340, primals_1341, primals_1342, primals_1343, primals_1344, primals_1345, primals_1346, primals_1347, primals_1348, primals_1349, primals_1350, primals_1351, primals_1352, primals_1353, primals_1354, primals_1355, primals_1356, primals_1357, primals_1358, primals_1359, primals_1360, primals_1361, primals_1362, primals_1363, primals_1364, primals_1365, primals_1366, primals_1367, primals_1368, primals_1369, primals_1370, primals_1371, primals_1372, primals_1373, primals_1374, primals_1375, primals_1376, primals_1377, primals_1378, primals_1379, primals_1380, primals_1381, primals_1382, primals_1383, primals_1384, primals_1385, primals_1386, primals_1387, primals_1388, primals_1389, primals_1390, primals_1391, primals_1392, primals_1393, primals_1394, primals_1395, primals_1396, primals_1397, primals_1398, primals_1399, primals_1400, primals_1401, primals_1402, primals_1403, primals_1404, primals_1405, primals_1406, primals_1407, primals_1408, primals_1409, primals_1410, primals_1411, primals_1412, primals_1413, primals_1414, primals_1415, primals_1416, primals_1417, primals_1418, primals_1419, primals_1420, primals_1421, primals_1422, primals_1423, primals_1424, primals_1425, primals_1426, primals_1427, primals_1428, primals_1429, primals_1430, primals_1431, primals_1432, primals_1433, primals_1434, primals_1435, primals_1436, primals_1437, primals_1438, primals_1439, primals_1440, primals_1441, primals_1442, primals_1443, primals_1444, primals_1445, primals_1446, primals_1447, primals_1448, primals_1449, primals_1450, primals_1451, primals_1452, primals_1453, primals_1454, primals_1455, primals_1456, primals_1457, primals_1458, primals_1459, primals_1460, primals_1461, primals_1462, primals_1463, primals_1464, primals_1465, primals_1466, primals_1467, primals_1468, primals_1469, primals_1470, primals_1471, primals_1472, primals_1473, primals_1474, primals_1475, primals_1476, primals_1477, primals_1478, primals_1479, primals_1480, primals_1481, primals_1482, primals_1483, primals_1484, primals_1485, primals_1486, primals_1487, primals_1488, primals_1489, primals_1490, primals_1491, primals_1492, primals_1493, primals_1494, primals_1495, primals_1496, primals_1497, primals_1498, primals_1499, primals_1500, primals_1501, primals_1502, primals_1503, primals_1504, primals_1505, primals_1506, primals_1507, primals_1508, primals_1509, primals_1510, primals_1511, primals_1512, primals_1513, primals_1514, primals_1515, primals_1516, primals_1517, primals_1518, primals_1519, primals_1520, primals_1521, primals_1522, primals_1523, primals_1524, primals_1525, primals_1526, primals_1527, primals_1528, primals_1529, primals_1530, primals_1531, primals_1532, primals_1533, primals_1534, primals_1535, primals_1536, primals_1537, primals_1538, primals_1539, primals_1540, primals_1541, primals_1542, primals_1543, primals_1544, primals_1545, primals_1546, primals_1547, primals_1548, primals_1549, primals_1550, primals_1551, primals_1552, primals_1553, primals_1554, primals_1555, primals_1556, primals_1557, primals_1558, primals_1559, primals_1560, primals_1561, primals_1562, primals_1563, primals_1564, primals_1565, primals_1566, primals_1567, primals_1568, primals_1569, primals_1570, primals_1571, primals_1572, primals_1573, primals_1574, primals_1575, primals_1576, primals_1577, primals_1578, primals_1579, primals_1580, primals_1581, primals_1582, primals_1583, primals_1584, primals_1585, primals_1586, primals_1587, primals_1588, primals_1589, primals_1590, primals_1591, primals_1592, primals_1593, primals_1594, primals_1595, primals_1596, primals_1597, primals_1598, primals_1599, primals_1600, primals_1601, primals_1602, primals_1603, primals_1604, primals_1605, primals_1606, primals_1607, primals_1608, primals_1609, primals_1610, primals_1611, primals_1612, primals_1613, primals_1614, primals_1615, primals_1616, primals_1617, primals_1618, primals_1619, primals_1620, primals_1621, primals_1622, primals_1623, primals_1624, primals_1625, primals_1626, primals_1627, primals_1628, primals_1629, primals_1630, primals_1631, primals_1632, primals_1633, primals_1634, primals_1635, primals_1636, primals_1637, primals_1638, primals_1639, primals_1640, primals_1641, primals_1642, primals_1643, primals_1644, primals_1645, primals_1646, primals_1647, primals_1648, primals_1649, primals_1650, primals_1651, primals_1652, primals_1653, primals_1654, primals_1655, primals_1656, primals_1657, primals_1658, primals_1659, primals_1660, primals_1661, primals_1662, primals_1663, primals_1664, primals_1665, primals_1666, primals_1667, primals_1668, primals_1669, primals_1670, primals_1671, primals_1672, primals_1673, primals_1674, primals_1675, primals_1676, primals_1677, primals_1678, primals_1679, primals_1680, primals_1681, primals_1682, primals_1683, primals_1684, primals_1685, primals_1686, primals_1687, primals_1688, primals_1689, primals_1690, primals_1691, primals_1692, primals_1693, primals_1694, primals_1695, primals_1696, primals_1697, primals_1698, primals_1699, primals_1700, primals_1701, primals_1702, primals_1703, primals_1704, primals_1705, primals_1706, primals_1707, primals_1708, primals_1709, primals_1710, primals_1711, primals_1712, primals_1713, primals_1714, primals_1715, primals_1716, primals_1717, primals_1718, primals_1719, primals_1720, primals_1721, primals_1722, primals_1723, primals_1724, primals_1725, primals_1726, primals_1727, primals_1728, primals_1729, primals_1730, primals_1731, primals_1732, primals_1733, primals_1734, primals_1735, primals_1736, primals_1737, primals_1738, primals_1739, primals_1740, primals_1741, primals_1742, primals_1743, primals_1744, primals_1745, primals_1746, primals_1747, primals_1748, primals_1749, primals_1750, primals_1751, primals_1752, primals_1753, primals_1754, primals_1755, primals_1756, primals_1757, primals_1758, primals_1759, primals_1760, primals_1761, primals_1762, primals_1763, primals_1764, primals_1765, primals_1766, primals_1767, primals_1768, primals_1769, primals_1770, primals_1771, primals_1772, primals_1773, primals_1774, primals_1775, primals_1776, primals_1777, primals_1778, primals_1779, primals_1780, primals_1781, primals_1782, primals_1783, primals_1784, primals_1785, primals_1786, primals_1787, primals_1788, primals_1789, primals_1790, primals_1791, primals_1792, primals_1793, primals_1794, primals_1795, primals_1796, primals_1797, primals_1798, primals_1799, primals_1800, primals_1801, primals_1802, primals_1803, primals_1804, primals_1805, primals_1806, primals_1807, primals_1808, primals_1809, primals_1810, primals_1811, primals_1812, primals_1813, primals_1814, primals_1815, primals_1816, primals_1817, primals_1818, primals_1819, primals_1820, primals_1821, primals_1822, primals_1823, primals_1824, primals_1825, primals_1826, primals_1827, primals_1828, primals_1829, primals_1830, primals_1831, primals_1832, primals_1833, primals_1834, primals_1835, primals_1836, primals_1837, primals_1838, primals_1839, primals_1840, primals_1841, primals_1842, primals_1843, primals_1844, primals_1845, primals_1846, primals_1847, primals_1848, primals_1849, primals_1850, primals_1851, primals_1852, primals_1853, primals_1854, primals_1855, primals_1856, primals_1857, primals_1858, primals_1859, primals_1860, primals_1861, primals_1862, primals_1863, primals_1864, primals_1865, primals_1866, primals_1867, primals_1868, primals_1869, primals_1870, primals_1871, primals_1872, primals_1873, primals_1874, primals_1875, primals_1876, primals_1877, primals_1878, primals_1879, primals_1880, primals_1881, primals_1882, primals_1883, primals_1884, primals_1885, primals_1886, primals_1887, primals_1888, primals_1889, primals_1890, primals_1891, primals_1892, primals_1893, primals_1894, primals_1895, primals_1896, primals_1897, primals_1898, primals_1899, primals_1900, primals_1901, primals_1902, primals_1903, primals_1904, primals_1905, primals_1906, primals_1907, primals_1908, primals_1909, primals_1910, primals_1911, primals_1912, primals_1913, primals_1914, primals_1915, primals_1916, primals_1917, primals_1918, primals_1919, primals_1920, primals_1921, primals_1922, primals_1923, primals_1924, primals_1925, primals_1926, primals_1927, primals_1928, primals_1929, primals_1930, primals_1931, primals_1932, primals_1933, primals_1934, primals_1935, primals_1936, primals_1937, primals_1938, primals_1939, primals_1940, primals_1941, primals_1942, primals_1943, primals_1944, primals_1945, primals_1946, primals_1947, primals_1948, primals_1949, primals_1950, primals_1951, primals_1952, primals_1953, primals_1954, primals_1955, primals_1956, primals_1957]), times=times, repeat=repeat)


if __name__ == "__main__":
    from torch._inductor.wrapper_benchmark import compiled_module_main
    compiled_module_main('hrnet_w18', benchmark_compiled_module)
