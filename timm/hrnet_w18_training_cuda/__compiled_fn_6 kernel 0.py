
from ctypes import c_void_p, c_long
import torch
import math
import random
import os
import tempfile
from math import inf, nan
from torch._inductor.hooks import run_intermediate_hooks
from torch._inductor.utils import maybe_profile
from torch._inductor.codegen.memory_planning import _align as align

from torch import device, empty, empty_strided
from torch._inductor.codecache import AsyncCompile
from torch._inductor.select_algorithm import extern_kernels

aten = torch.ops.aten
inductor_ops = torch.ops.inductor
assert_size_stride = torch._C._dynamo.guards.assert_size_stride
alloc_from_pool = torch.ops.inductor._alloc_from_pool
reinterpret_tensor = torch.ops.inductor._reinterpret_tensor
async_compile = AsyncCompile()


# kernel path: /tmp/torchinductor_youkaichao/qt/cqtcbt4g57hrviadj7jcv3toxxh4xcnjikjw4nylbesjf4s5onol.py
# Source Nodes: [], Original ATen: [aten.sum]

triton_per_fused_sum_0 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[1024, 8],
    reduction_hint=ReductionHint.DEFAULT,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2, 3))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_sum_0', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 1000
    rnumel = 8
    RBLOCK: tl.constexpr = 8
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (1000*r1)), rmask & xmask, other=0.0)
    tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.sum(tmp3, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp4, xmask)
''')

import triton
import triton.language as tl
from torch._inductor.triton_heuristics import grid, start_graph, end_graph
from torch._C import _cuda_getCurrentRawStream as get_cuda_stream


# kernel path: /tmp/torchinductor_youkaichao/5c/c5ck7uyonbkvn3c7zpbiyu6fi6hvdpmvibmjal3fin7q3ff6bufe.py
# Source Nodes: [], Original ATen: [aten.div, aten.native_batch_norm_backward, aten.threshold_backward]

triton_per_fused_div_native_batch_norm_backward_threshold_backward_1 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[2048, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*i1', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_div_native_batch_norm_backward_threshold_backward_1', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel):
    xnumel = 2048
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (100352*r2)), rmask).to(tl.int1)
    tmp1 = tl.load(in_ptr1 + (x0 + (2048*r2)), rmask, eviction_policy='evict_last', other=0.0)
    tmp10 = tl.load(in_ptr2 + (r1 + (49*x0) + (100352*r2)), rmask, other=0.0)
    tmp11 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
    tmp18 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
    tmp2 = 49.0
    tmp3 = tmp1 / tmp2
    tmp4 = 0.0
    tmp5 = tl.where(tmp0, tmp4, tmp3)
    tmp6 = tl.broadcast_to(tmp5, [RBLOCK])
    tmp8 = tl.where(rmask, tmp6, 0)
    tmp9 = triton_helpers.promote_to_tensor(tl.sum(tmp8, 0))
    tmp12 = tmp10 - tmp11
    tmp13 = tmp5 * tmp12
    tmp14 = tl.broadcast_to(tmp13, [RBLOCK])
    tmp16 = tl.where(rmask, tmp14, 0)
    tmp17 = triton_helpers.promote_to_tensor(tl.sum(tmp16, 0))
    tmp19 = tmp17 * tmp18
    tl.store(out_ptr2 + (x0), tmp19, None)
    tl.store(out_ptr0 + (x0), tmp9, None)
    tl.store(out_ptr1 + (x0), tmp17, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/hz/chzxppkv3bbtlhjawodx6kp3gkervpus5hw4vevbr26yduttfdmv.py
# Source Nodes: [], Original ATen: [aten.div, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_div_native_batch_norm_backward_threshold_backward_2 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1048576], 
    filename=__file__,
    triton_meta={'signature': {0: '*i1', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_div_native_batch_norm_backward_threshold_backward_2', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 802816
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x4 = (xindex // 49)
    x1 = (xindex // 49) % 2048
    tmp0 = tl.load(in_ptr0 + (x3), None).to(tl.int1)
    tmp1 = tl.load(in_ptr1 + (x4), None, eviction_policy='evict_last')
    tmp6 = tl.load(in_ptr2 + (x3), None)
    tmp7 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp9 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr5 + (x1), None, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp20 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
    tmp2 = 49.0
    tmp3 = tmp1 / tmp2
    tmp4 = 0.0
    tmp5 = tl.where(tmp0, tmp4, tmp3)
    tmp8 = tmp6 - tmp7
    tmp10 = 0.002551020408163265
    tmp11 = tmp9 * tmp10
    tmp13 = tmp12 * tmp12
    tmp14 = tmp11 * tmp13
    tmp15 = tmp8 * tmp14
    tmp16 = tmp5 - tmp15
    tmp18 = tmp17 * tmp10
    tmp19 = tmp16 - tmp18
    tmp21 = tmp12 * tmp20
    tmp22 = tmp19 * tmp21
    tl.store(out_ptr0 + (x3), tmp22, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/mt/cmtds5yfdtwzpiedrtk3t5zf6hudtsewx563mrvtgg5ienlpgcus.py
# Source Nodes: [], Original ATen: [aten.convolution_backward]

triton_per_fused_convolution_backward_3 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[2048, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2, 3))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_convolution_backward_3', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, rnumel):
    xnumel = 2048
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (100352*r2)), rmask, other=0.0)
    tmp1 = tl.broadcast_to(tmp0, [RBLOCK])
    tmp3 = tl.where(rmask, tmp1, 0)
    tmp4 = triton_helpers.promote_to_tensor(tl.sum(tmp3, 0))
    tl.store(out_ptr0 + (x0), tmp4, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/7a/c7av2mle7jxvtuclqirmqpq2j2rm6qtop7272yg5vmm3llu3hocf.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_per_fused_native_batch_norm_backward_threshold_backward_4 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[1024, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*i1', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*i1', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: '*fp32', 18: '*fp32', 19: '*fp32', 20: 'i32', 21: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(20, 21))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_threshold_backward_4', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, out_ptr5, out_ptr6, out_ptr7, xnumel, rnumel):
    xnumel = 1024
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (50176*r2)), rmask & xmask).to(tl.int1)
    tmp1 = tl.load(in_ptr1 + (r1 + (49*x0) + (50176*r2)), rmask & xmask, other=0.0)
    tmp8 = tl.load(in_ptr2 + (r1 + (49*x0) + (50176*r2)), rmask & xmask, other=0.0)
    tmp9 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr4 + (r1 + (49*x0) + (50176*r2)), rmask & xmask).to(tl.int1)
    tmp22 = tl.load(in_ptr5 + (r1 + (49*x0) + (50176*r2)), rmask & xmask, other=0.0)
    tmp23 = tl.load(in_ptr6 + (x0), xmask, eviction_policy='evict_last')
    tmp30 = tl.load(in_ptr7 + (r1 + (49*x0) + (50176*r2)), rmask & xmask, other=0.0)
    tmp31 = tl.load(in_ptr8 + (x0), xmask, eviction_policy='evict_last')
    tmp38 = tl.load(in_ptr9 + (x0), xmask, eviction_policy='evict_last')
    tmp40 = tl.load(in_ptr10 + (x0), xmask, eviction_policy='evict_last')
    tmp42 = tl.load(in_ptr11 + (x0), xmask, eviction_policy='evict_last')
    tmp2 = 0.0
    tmp3 = tl.where(tmp0, tmp2, tmp1)
    tmp4 = tl.broadcast_to(tmp3, [RBLOCK])
    tmp6 = tl.where(rmask & xmask, tmp4, 0)
    tmp7 = triton_helpers.promote_to_tensor(tl.sum(tmp6, 0))
    tmp10 = tmp8 - tmp9
    tmp11 = tmp3 * tmp10
    tmp12 = tl.broadcast_to(tmp11, [RBLOCK])
    tmp14 = tl.where(rmask & xmask, tmp12, 0)
    tmp15 = triton_helpers.promote_to_tensor(tl.sum(tmp14, 0))
    tmp17 = tl.where(tmp16, tmp2, tmp1)
    tmp18 = tl.broadcast_to(tmp17, [RBLOCK])
    tmp20 = tl.where(rmask & xmask, tmp18, 0)
    tmp21 = triton_helpers.promote_to_tensor(tl.sum(tmp20, 0))
    tmp24 = tmp22 - tmp23
    tmp25 = tmp17 * tmp24
    tmp26 = tl.broadcast_to(tmp25, [RBLOCK])
    tmp28 = tl.where(rmask & xmask, tmp26, 0)
    tmp29 = triton_helpers.promote_to_tensor(tl.sum(tmp28, 0))
    tmp32 = tmp30 - tmp31
    tmp33 = tmp17 * tmp32
    tmp34 = tl.broadcast_to(tmp33, [RBLOCK])
    tmp36 = tl.where(rmask & xmask, tmp34, 0)
    tmp37 = triton_helpers.promote_to_tensor(tl.sum(tmp36, 0))
    tmp39 = tmp29 * tmp38
    tmp41 = tmp37 * tmp40
    tmp43 = tmp15 * tmp42
    tl.store(out_ptr5 + (x0), tmp39, xmask)
    tl.store(out_ptr6 + (x0), tmp41, xmask)
    tl.store(out_ptr7 + (x0), tmp43, xmask)
    tl.store(out_ptr0 + (x0), tmp7, xmask)
    tl.store(out_ptr1 + (x0), tmp15, xmask)
    tl.store(out_ptr2 + (x0), tmp21, xmask)
    tl.store(out_ptr3 + (x0), tmp29, xmask)
    tl.store(out_ptr4 + (x0), tmp37, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/5s/c5sntdk4x343xxnyuu6ezqa7nwg3xuenrcgzqncpwkgcrfxam5fu.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_5 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*i1', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*i1', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: '*fp32', 18: '*fp32', 19: '*fp32', 20: '*fp32', 21: '*fp32', 22: '*fp32', 23: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(23,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_5', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, out_ptr0, out_ptr1, out_ptr2, xnumel, XBLOCK : tl.constexpr):
    xnumel = 401408
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 1024
    tmp0 = tl.load(in_ptr0 + (x3), None).to(tl.int1)
    tmp1 = tl.load(in_ptr1 + (x3), None)
    tmp4 = tl.load(in_ptr2 + (x3), None)
    tmp5 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr5 + (x1), None, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp18 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr8 + (x3), None).to(tl.int1)
    tmp23 = tl.load(in_ptr9 + (x3), None)
    tmp24 = tl.load(in_ptr10 + (x1), None, eviction_policy='evict_last')
    tmp26 = tl.load(in_ptr11 + (x1), None, eviction_policy='evict_last')
    tmp28 = tl.load(in_ptr12 + (x1), None, eviction_policy='evict_last')
    tmp33 = tl.load(in_ptr13 + (x1), None, eviction_policy='evict_last')
    tmp36 = tl.load(in_ptr14 + (x1), None, eviction_policy='evict_last')
    tmp39 = tl.load(in_ptr15 + (x3), None)
    tmp40 = tl.load(in_ptr16 + (x1), None, eviction_policy='evict_last')
    tmp42 = tl.load(in_ptr17 + (x1), None, eviction_policy='evict_last')
    tmp44 = tl.load(in_ptr18 + (x1), None, eviction_policy='evict_last')
    tmp50 = tl.load(in_ptr19 + (x1), None, eviction_policy='evict_last')
    tmp2 = 0.0
    tmp3 = tl.where(tmp0, tmp2, tmp1)
    tmp6 = tmp4 - tmp5
    tmp8 = 0.002551020408163265
    tmp9 = tmp7 * tmp8
    tmp11 = tmp10 * tmp10
    tmp12 = tmp9 * tmp11
    tmp13 = tmp6 * tmp12
    tmp14 = tmp3 - tmp13
    tmp16 = tmp15 * tmp8
    tmp17 = tmp14 - tmp16
    tmp19 = tmp10 * tmp18
    tmp20 = tmp17 * tmp19
    tmp22 = tl.where(tmp21, tmp2, tmp1)
    tmp25 = tmp23 - tmp24
    tmp27 = tmp26 * tmp8
    tmp29 = tmp28 * tmp28
    tmp30 = tmp27 * tmp29
    tmp31 = tmp25 * tmp30
    tmp32 = tmp22 - tmp31
    tmp34 = tmp33 * tmp8
    tmp35 = tmp32 - tmp34
    tmp37 = tmp28 * tmp36
    tmp38 = tmp35 * tmp37
    tmp41 = tmp39 - tmp40
    tmp43 = tmp42 * tmp8
    tmp45 = tmp44 * tmp44
    tmp46 = tmp43 * tmp45
    tmp47 = tmp41 * tmp46
    tmp48 = tmp22 - tmp47
    tmp49 = tmp48 - tmp34
    tmp51 = tmp44 * tmp50
    tmp52 = tmp49 * tmp51
    tl.store(out_ptr0 + (x3), tmp20, None)
    tl.store(out_ptr1 + (x3), tmp38, None)
    tl.store(out_ptr2 + (x3), tmp52, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/sz/cszwf77v57pzvi54tnx7wugyeutxfuxo5a5qpac2ocyko6athfgn.py
# Source Nodes: [], Original ATen: [aten.convolution_backward]

triton_per_fused_convolution_backward_6 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[1024, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2, 3))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_convolution_backward_6', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, rnumel):
    xnumel = 1024
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (50176*r2)), rmask & xmask, other=0.0)
    tmp1 = tl.broadcast_to(tmp0, [RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = triton_helpers.promote_to_tensor(tl.sum(tmp3, 0))
    tl.store(out_ptr0 + (x0), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/3e/c3eot5n4x2475qjppoleyfrsmykznosgb5wx4at7a2xcrrbrklju.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_per_fused_native_batch_norm_backward_threshold_backward_7 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[256, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_threshold_backward_7', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel):
    xnumel = 256
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (12544*r2)), rmask & xmask, other=0.0)
    tmp3 = tl.load(in_ptr1 + (r1 + (49*x0) + (12544*r2)), rmask & xmask, other=0.0)
    tmp9 = tl.load(in_ptr2 + (r1 + (49*x0) + (12544*r2)), rmask & xmask, other=0.0)
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tl.where(tmp2, tmp1, tmp3)
    tmp5 = tl.broadcast_to(tmp4, [RBLOCK])
    tmp7 = tl.where(rmask & xmask, tmp5, 0)
    tmp8 = triton_helpers.promote_to_tensor(tl.sum(tmp7, 0))
    tmp11 = tmp9 - tmp10
    tmp12 = tmp4 * tmp11
    tmp13 = tl.broadcast_to(tmp12, [RBLOCK])
    tmp15 = tl.where(rmask & xmask, tmp13, 0)
    tmp16 = triton_helpers.promote_to_tensor(tl.sum(tmp15, 0))
    tmp18 = tmp16 * tmp17
    tl.store(out_ptr2 + (x0), tmp18, xmask)
    tl.store(out_ptr0 + (x0), tmp8, xmask)
    tl.store(out_ptr1 + (x0), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/cc/cccfgw2ormjzg7mhclbarvp6qhjq4gr5li2mrnhpoiamtk6bswmo.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_8 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_8', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 100352
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 256
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp3 = tl.load(in_out_ptr0 + (x3), None)
    tmp5 = tl.load(in_ptr1 + (x3), None)
    tmp6 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp8 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr5 + (x1), None, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tl.where(tmp2, tmp1, tmp3)
    tmp7 = tmp5 - tmp6
    tmp9 = 0.002551020408163265
    tmp10 = tmp8 * tmp9
    tmp12 = tmp11 * tmp11
    tmp13 = tmp10 * tmp12
    tmp14 = tmp7 * tmp13
    tmp15 = tmp4 - tmp14
    tmp17 = tmp16 * tmp9
    tmp18 = tmp15 - tmp17
    tmp20 = tmp11 * tmp19
    tmp21 = tmp18 * tmp20
    tl.store(in_out_ptr0 + (x3), tmp21, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/zv/czv5jyp3rc422qcrvuxbq26vu4kdcmp7wf23ps7dbz25uc3grjer.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_native_batch_norm_backward_threshold_backward_9 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[512, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*i1', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*i1', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: '*fp32', 18: '*fp32', 19: '*fp32', 20: 'i32', 21: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(20, 21))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_threshold_backward_9', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, out_ptr5, out_ptr6, out_ptr7, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 512
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp5 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp8 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    _tmp12 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    _tmp17 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp20 = tl.load(in_ptr6 + (x0), xmask, eviction_policy='evict_last')
    _tmp24 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp27 = tl.load(in_ptr8 + (x0), xmask, eviction_policy='evict_last')
    _tmp31 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (100352*r2)), rmask & xmask, eviction_policy='evict_first').to(tl.int1)
        tmp1 = tl.load(in_ptr1 + (r1 + (196*x0) + (100352*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp7 = tl.load(in_ptr2 + (r1 + (196*x0) + (100352*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp14 = tl.load(in_ptr4 + (r1 + (196*x0) + (100352*r2)), rmask & xmask, eviction_policy='evict_first').to(tl.int1)
        tmp19 = tl.load(in_ptr5 + (r1 + (196*x0) + (100352*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp26 = tl.load(in_ptr7 + (r1 + (196*x0) + (100352*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp2 = 0.0
        tmp3 = tl.where(tmp0, tmp2, tmp1)
        tmp4 = tl.broadcast_to(tmp3, [XBLOCK, RBLOCK])
        tmp6 = _tmp5 + tmp4
        _tmp5 = tl.where(rmask & xmask, tmp6, _tmp5)
        tmp9 = tmp7 - tmp8
        tmp10 = tmp3 * tmp9
        tmp11 = tl.broadcast_to(tmp10, [XBLOCK, RBLOCK])
        tmp13 = _tmp12 + tmp11
        _tmp12 = tl.where(rmask & xmask, tmp13, _tmp12)
        tmp15 = tl.where(tmp14, tmp2, tmp1)
        tmp16 = tl.broadcast_to(tmp15, [XBLOCK, RBLOCK])
        tmp18 = _tmp17 + tmp16
        _tmp17 = tl.where(rmask & xmask, tmp18, _tmp17)
        tmp21 = tmp19 - tmp20
        tmp22 = tmp15 * tmp21
        tmp23 = tl.broadcast_to(tmp22, [XBLOCK, RBLOCK])
        tmp25 = _tmp24 + tmp23
        _tmp24 = tl.where(rmask & xmask, tmp25, _tmp24)
        tmp28 = tmp26 - tmp27
        tmp29 = tmp15 * tmp28
        tmp30 = tl.broadcast_to(tmp29, [XBLOCK, RBLOCK])
        tmp32 = _tmp31 + tmp30
        _tmp31 = tl.where(rmask & xmask, tmp32, _tmp31)
    tmp5 = tl.sum(_tmp5, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp5, xmask)
    tmp12 = tl.sum(_tmp12, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp12, xmask)
    tmp17 = tl.sum(_tmp17, 1)[:, None]
    tl.store(out_ptr2 + (x0), tmp17, xmask)
    tmp24 = tl.sum(_tmp24, 1)[:, None]
    tl.store(out_ptr3 + (x0), tmp24, xmask)
    tmp31 = tl.sum(_tmp31, 1)[:, None]
    tl.store(out_ptr4 + (x0), tmp31, xmask)
    tmp33 = tl.load(in_ptr9 + (x0), xmask, eviction_policy='evict_last')
    tmp35 = tl.load(in_ptr10 + (x0), xmask, eviction_policy='evict_last')
    tmp37 = tl.load(in_ptr11 + (x0), xmask, eviction_policy='evict_last')
    tmp34 = tmp24 * tmp33
    tmp36 = tmp31 * tmp35
    tmp38 = tmp12 * tmp37
    tl.store(out_ptr5 + (x0), tmp34, xmask)
    tl.store(out_ptr6 + (x0), tmp36, xmask)
    tl.store(out_ptr7 + (x0), tmp38, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/hh/chhvyxp4we7lang2777w2xeugkziy4y73tjqku5riy2byrtsy6dh.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_10 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1048576], 
    filename=__file__,
    triton_meta={'signature': {0: '*i1', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*i1', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: '*fp32', 18: '*fp32', 19: '*fp32', 20: '*fp32', 21: '*fp32', 22: '*fp32', 23: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(23,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_10', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, out_ptr0, out_ptr1, out_ptr2, xnumel, XBLOCK : tl.constexpr):
    xnumel = 802816
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 512
    tmp0 = tl.load(in_ptr0 + (x3), None).to(tl.int1)
    tmp1 = tl.load(in_ptr1 + (x3), None)
    tmp4 = tl.load(in_ptr2 + (x3), None)
    tmp5 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr5 + (x1), None, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp18 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr8 + (x3), None).to(tl.int1)
    tmp23 = tl.load(in_ptr9 + (x3), None)
    tmp24 = tl.load(in_ptr10 + (x1), None, eviction_policy='evict_last')
    tmp26 = tl.load(in_ptr11 + (x1), None, eviction_policy='evict_last')
    tmp28 = tl.load(in_ptr12 + (x1), None, eviction_policy='evict_last')
    tmp33 = tl.load(in_ptr13 + (x1), None, eviction_policy='evict_last')
    tmp36 = tl.load(in_ptr14 + (x1), None, eviction_policy='evict_last')
    tmp39 = tl.load(in_ptr15 + (x3), None)
    tmp40 = tl.load(in_ptr16 + (x1), None, eviction_policy='evict_last')
    tmp42 = tl.load(in_ptr17 + (x1), None, eviction_policy='evict_last')
    tmp44 = tl.load(in_ptr18 + (x1), None, eviction_policy='evict_last')
    tmp50 = tl.load(in_ptr19 + (x1), None, eviction_policy='evict_last')
    tmp2 = 0.0
    tmp3 = tl.where(tmp0, tmp2, tmp1)
    tmp6 = tmp4 - tmp5
    tmp8 = 0.0006377551020408163
    tmp9 = tmp7 * tmp8
    tmp11 = tmp10 * tmp10
    tmp12 = tmp9 * tmp11
    tmp13 = tmp6 * tmp12
    tmp14 = tmp3 - tmp13
    tmp16 = tmp15 * tmp8
    tmp17 = tmp14 - tmp16
    tmp19 = tmp10 * tmp18
    tmp20 = tmp17 * tmp19
    tmp22 = tl.where(tmp21, tmp2, tmp1)
    tmp25 = tmp23 - tmp24
    tmp27 = tmp26 * tmp8
    tmp29 = tmp28 * tmp28
    tmp30 = tmp27 * tmp29
    tmp31 = tmp25 * tmp30
    tmp32 = tmp22 - tmp31
    tmp34 = tmp33 * tmp8
    tmp35 = tmp32 - tmp34
    tmp37 = tmp28 * tmp36
    tmp38 = tmp35 * tmp37
    tmp41 = tmp39 - tmp40
    tmp43 = tmp42 * tmp8
    tmp45 = tmp44 * tmp44
    tmp46 = tmp43 * tmp45
    tmp47 = tmp41 * tmp46
    tmp48 = tmp22 - tmp47
    tmp49 = tmp48 - tmp34
    tmp51 = tmp44 * tmp50
    tmp52 = tmp49 * tmp51
    tl.store(out_ptr0 + (x3), tmp20, None)
    tl.store(out_ptr1 + (x3), tmp38, None)
    tl.store(out_ptr2 + (x3), tmp52, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/nq/cnqhiviecitho35h5nebzoey72gre347n7fc33x24nt46ajkqfun.py
# Source Nodes: [], Original ATen: [aten.convolution_backward]

triton_red_fused_convolution_backward_11 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[512, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2, 3))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_convolution_backward_11', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 512
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (100352*r2)), rmask & xmask, eviction_policy='evict_last', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = _tmp2 + tmp1
        _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
    tmp2 = tl.sum(_tmp2, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/74/c74ua47wvlt7b3odekay3gbx2uxy4szlfnigwehqicppd254bye6.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_native_batch_norm_backward_threshold_backward_12 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_threshold_backward_12', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 128
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp9 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    _tmp13 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (25088*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + (r1 + (196*x0) + (25088*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp8 = tl.load(in_ptr2 + (r1 + (196*x0) + (25088*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
        tmp7 = _tmp6 + tmp5
        _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp10 = tmp8 - tmp9
        tmp11 = tmp4 * tmp10
        tmp12 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp14 = _tmp13 + tmp12
        _tmp13 = tl.where(rmask & xmask, tmp14, _tmp13)
    tmp6 = tl.sum(_tmp6, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp6, xmask)
    tmp13 = tl.sum(_tmp13, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp13, xmask)
    tmp15 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp16 = tmp13 * tmp15
    tl.store(out_ptr2 + (x0), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/hh/chhjxfkjxs4dvzakrplqgmcgtu27hn4cmof5uik4f62jedk4nctm.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_13 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_13', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 200704
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 128
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp3 = tl.load(in_out_ptr0 + (x3), None)
    tmp5 = tl.load(in_ptr1 + (x3), None)
    tmp6 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp8 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr5 + (x1), None, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tl.where(tmp2, tmp1, tmp3)
    tmp7 = tmp5 - tmp6
    tmp9 = 0.0006377551020408163
    tmp10 = tmp8 * tmp9
    tmp12 = tmp11 * tmp11
    tmp13 = tmp10 * tmp12
    tmp14 = tmp7 * tmp13
    tmp15 = tmp4 - tmp14
    tmp17 = tmp16 * tmp9
    tmp18 = tmp15 - tmp17
    tmp20 = tmp11 * tmp19
    tmp21 = tmp18 * tmp20
    tl.store(in_out_ptr0 + (x3), tmp21, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/ib/cibgrd35yhschg33qlowayd2xzk3wtqzlsrl6sqzqr6nz2mcxnlb.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_native_batch_norm_backward_threshold_backward_14 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[256, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*i1', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*i1', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: '*fp32', 18: '*fp32', 19: '*fp32', 20: 'i32', 21: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(20, 21))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_threshold_backward_14', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, out_ptr5, out_ptr6, out_ptr7, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 256
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp5 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp8 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    _tmp12 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    _tmp17 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp20 = tl.load(in_ptr6 + (x0), xmask, eviction_policy='evict_last')
    _tmp24 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp27 = tl.load(in_ptr8 + (x0), xmask, eviction_policy='evict_last')
    _tmp31 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 784
        r2 = (rindex // 784)
        tmp0 = tl.load(in_ptr0 + (r1 + (784*x0) + (200704*r2)), rmask & xmask, eviction_policy='evict_first').to(tl.int1)
        tmp1 = tl.load(in_ptr1 + (r1 + (784*x0) + (200704*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp7 = tl.load(in_ptr2 + (r1 + (784*x0) + (200704*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp14 = tl.load(in_ptr4 + (r1 + (784*x0) + (200704*r2)), rmask & xmask, eviction_policy='evict_first').to(tl.int1)
        tmp19 = tl.load(in_ptr5 + (r1 + (784*x0) + (200704*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp26 = tl.load(in_ptr7 + (r1 + (784*x0) + (200704*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp2 = 0.0
        tmp3 = tl.where(tmp0, tmp2, tmp1)
        tmp4 = tl.broadcast_to(tmp3, [XBLOCK, RBLOCK])
        tmp6 = _tmp5 + tmp4
        _tmp5 = tl.where(rmask & xmask, tmp6, _tmp5)
        tmp9 = tmp7 - tmp8
        tmp10 = tmp3 * tmp9
        tmp11 = tl.broadcast_to(tmp10, [XBLOCK, RBLOCK])
        tmp13 = _tmp12 + tmp11
        _tmp12 = tl.where(rmask & xmask, tmp13, _tmp12)
        tmp15 = tl.where(tmp14, tmp2, tmp1)
        tmp16 = tl.broadcast_to(tmp15, [XBLOCK, RBLOCK])
        tmp18 = _tmp17 + tmp16
        _tmp17 = tl.where(rmask & xmask, tmp18, _tmp17)
        tmp21 = tmp19 - tmp20
        tmp22 = tmp15 * tmp21
        tmp23 = tl.broadcast_to(tmp22, [XBLOCK, RBLOCK])
        tmp25 = _tmp24 + tmp23
        _tmp24 = tl.where(rmask & xmask, tmp25, _tmp24)
        tmp28 = tmp26 - tmp27
        tmp29 = tmp15 * tmp28
        tmp30 = tl.broadcast_to(tmp29, [XBLOCK, RBLOCK])
        tmp32 = _tmp31 + tmp30
        _tmp31 = tl.where(rmask & xmask, tmp32, _tmp31)
    tmp5 = tl.sum(_tmp5, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp5, xmask)
    tmp12 = tl.sum(_tmp12, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp12, xmask)
    tmp17 = tl.sum(_tmp17, 1)[:, None]
    tl.store(out_ptr2 + (x0), tmp17, xmask)
    tmp24 = tl.sum(_tmp24, 1)[:, None]
    tl.store(out_ptr3 + (x0), tmp24, xmask)
    tmp31 = tl.sum(_tmp31, 1)[:, None]
    tl.store(out_ptr4 + (x0), tmp31, xmask)
    tmp33 = tl.load(in_ptr9 + (x0), xmask, eviction_policy='evict_last')
    tmp35 = tl.load(in_ptr10 + (x0), xmask, eviction_policy='evict_last')
    tmp37 = tl.load(in_ptr11 + (x0), xmask, eviction_policy='evict_last')
    tmp34 = tmp24 * tmp33
    tmp36 = tmp31 * tmp35
    tmp38 = tmp12 * tmp37
    tl.store(out_ptr5 + (x0), tmp34, xmask)
    tl.store(out_ptr6 + (x0), tmp36, xmask)
    tl.store(out_ptr7 + (x0), tmp38, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ka/ckaf3jwjd3moouf2aymioln44khxixl7ymmi2petzzld77ea5h5e.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_15 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2097152], 
    filename=__file__,
    triton_meta={'signature': {0: '*i1', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*i1', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: '*fp32', 18: '*fp32', 19: '*fp32', 20: '*fp32', 21: '*fp32', 22: '*fp32', 23: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(23,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_15', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, out_ptr0, out_ptr1, out_ptr2, xnumel, XBLOCK : tl.constexpr):
    xnumel = 1605632
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 784) % 256
    tmp0 = tl.load(in_ptr0 + (x3), None).to(tl.int1)
    tmp1 = tl.load(in_ptr1 + (x3), None)
    tmp4 = tl.load(in_ptr2 + (x3), None)
    tmp5 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr5 + (x1), None, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp18 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr8 + (x3), None).to(tl.int1)
    tmp23 = tl.load(in_ptr9 + (x3), None)
    tmp24 = tl.load(in_ptr10 + (x1), None, eviction_policy='evict_last')
    tmp26 = tl.load(in_ptr11 + (x1), None, eviction_policy='evict_last')
    tmp28 = tl.load(in_ptr12 + (x1), None, eviction_policy='evict_last')
    tmp33 = tl.load(in_ptr13 + (x1), None, eviction_policy='evict_last')
    tmp36 = tl.load(in_ptr14 + (x1), None, eviction_policy='evict_last')
    tmp39 = tl.load(in_ptr15 + (x3), None)
    tmp40 = tl.load(in_ptr16 + (x1), None, eviction_policy='evict_last')
    tmp42 = tl.load(in_ptr17 + (x1), None, eviction_policy='evict_last')
    tmp44 = tl.load(in_ptr18 + (x1), None, eviction_policy='evict_last')
    tmp50 = tl.load(in_ptr19 + (x1), None, eviction_policy='evict_last')
    tmp2 = 0.0
    tmp3 = tl.where(tmp0, tmp2, tmp1)
    tmp6 = tmp4 - tmp5
    tmp8 = 0.00015943877551020407
    tmp9 = tmp7 * tmp8
    tmp11 = tmp10 * tmp10
    tmp12 = tmp9 * tmp11
    tmp13 = tmp6 * tmp12
    tmp14 = tmp3 - tmp13
    tmp16 = tmp15 * tmp8
    tmp17 = tmp14 - tmp16
    tmp19 = tmp10 * tmp18
    tmp20 = tmp17 * tmp19
    tmp22 = tl.where(tmp21, tmp2, tmp1)
    tmp25 = tmp23 - tmp24
    tmp27 = tmp26 * tmp8
    tmp29 = tmp28 * tmp28
    tmp30 = tmp27 * tmp29
    tmp31 = tmp25 * tmp30
    tmp32 = tmp22 - tmp31
    tmp34 = tmp33 * tmp8
    tmp35 = tmp32 - tmp34
    tmp37 = tmp28 * tmp36
    tmp38 = tmp35 * tmp37
    tmp41 = tmp39 - tmp40
    tmp43 = tmp42 * tmp8
    tmp45 = tmp44 * tmp44
    tmp46 = tmp43 * tmp45
    tmp47 = tmp41 * tmp46
    tmp48 = tmp22 - tmp47
    tmp49 = tmp48 - tmp34
    tmp51 = tmp44 * tmp50
    tmp52 = tmp49 * tmp51
    tl.store(out_ptr0 + (x3), tmp20, None)
    tl.store(out_ptr1 + (x3), tmp38, None)
    tl.store(out_ptr2 + (x3), tmp52, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/zw/czwbgiyf3kxvpcqevyl2cgokablpromcykmsdnkxmm2pkx4cthtz.py
# Source Nodes: [], Original ATen: [aten.convolution_backward]

triton_red_fused_convolution_backward_16 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[256, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2, 3))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_convolution_backward_16', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 256
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 784
        r2 = (rindex // 784)
        tmp0 = tl.load(in_ptr0 + (r1 + (784*x0) + (200704*r2)), rmask & xmask, eviction_policy='evict_last', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = _tmp2 + tmp1
        _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
    tmp2 = tl.sum(_tmp2, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/44/c443d45tlgpb3vj4ng3pul545i5vfjvu4kc64rjymb3gg6i52xzd.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_native_batch_norm_backward_threshold_backward_17 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[64, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_threshold_backward_17', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 64
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp9 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    _tmp13 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 784
        r2 = (rindex // 784)
        tmp0 = tl.load(in_ptr0 + (r1 + (784*x0) + (50176*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + (r1 + (784*x0) + (50176*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp8 = tl.load(in_ptr2 + (r1 + (784*x0) + (50176*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
        tmp7 = _tmp6 + tmp5
        _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp10 = tmp8 - tmp9
        tmp11 = tmp4 * tmp10
        tmp12 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp14 = _tmp13 + tmp12
        _tmp13 = tl.where(rmask & xmask, tmp14, _tmp13)
    tmp6 = tl.sum(_tmp6, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp6, xmask)
    tmp13 = tl.sum(_tmp13, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp13, xmask)
    tmp15 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp16 = tmp13 * tmp15
    tl.store(out_ptr2 + (x0), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/bp/cbps2prvicit3dvy7muu2327nufx5rv4tcflizvddqsyn357pwtk.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_18 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_18', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 401408
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 784) % 64
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp3 = tl.load(in_out_ptr0 + (x3), None)
    tmp5 = tl.load(in_ptr1 + (x3), None)
    tmp6 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp8 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr5 + (x1), None, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tl.where(tmp2, tmp1, tmp3)
    tmp7 = tmp5 - tmp6
    tmp9 = 0.00015943877551020407
    tmp10 = tmp8 * tmp9
    tmp12 = tmp11 * tmp11
    tmp13 = tmp10 * tmp12
    tmp14 = tmp7 * tmp13
    tmp15 = tmp4 - tmp14
    tmp17 = tmp16 * tmp9
    tmp18 = tmp15 - tmp17
    tmp20 = tmp11 * tmp19
    tmp21 = tmp18 * tmp20
    tl.store(in_out_ptr0 + (x3), tmp21, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/ii/ciiqeny6sjxxcgtt7vykssl7aq2i3pcg3576qpyf4wdwzh26tnko.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_native_batch_norm_backward_threshold_backward_19 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[512, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32', 10: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9, 10))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_threshold_backward_19', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 512
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 128
    x1 = (xindex // 128)
    _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    x3 = xindex
    tmp9 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    _tmp13 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp16 = tl.load(in_ptr5 + (x0), xmask, eviction_policy='evict_last')
    _tmp20 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + ((3136*x0) + (401408*(r2 // 3136)) + (802816*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + ((3136*x0) + (401408*(r2 // 3136)) + (802816*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp8 = tl.load(in_ptr2 + ((3136*x0) + (401408*(r2 // 3136)) + (802816*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp15 = tl.load(in_ptr4 + ((3136*x0) + (401408*(r2 // 3136)) + (802816*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
        tmp7 = _tmp6 + tmp5
        _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp10 = tmp8 - tmp9
        tmp11 = tmp4 * tmp10
        tmp12 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp14 = _tmp13 + tmp12
        _tmp13 = tl.where(rmask & xmask, tmp14, _tmp13)
        tmp17 = tmp15 - tmp16
        tmp18 = tmp4 * tmp17
        tmp19 = tl.broadcast_to(tmp18, [XBLOCK, RBLOCK])
        tmp21 = _tmp20 + tmp19
        _tmp20 = tl.where(rmask & xmask, tmp21, _tmp20)
    tmp6 = tl.sum(_tmp6, 1)[:, None]
    tl.store(out_ptr0 + (x3), tmp6, xmask)
    tmp13 = tl.sum(_tmp13, 1)[:, None]
    tl.store(out_ptr1 + (x3), tmp13, xmask)
    tmp20 = tl.sum(_tmp20, 1)[:, None]
    tl.store(out_ptr2 + (x3), tmp20, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/zi/czig6hd6yghgsmdlhe2mx4c7qtppnd6q5q4logkiuqgefggvjxzc.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_per_fused_native_batch_norm_backward_threshold_backward_20 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[128, 4],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_threshold_backward_20', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 128
    rnumel = 4
    RBLOCK: tl.constexpr = 4
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
    tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.sum(tmp3, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/qo/cqo45h6soxmicm3xbik4zmit6qytwmyytlwytpqnq4rbtgu4vrfu.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_per_fused_native_batch_norm_backward_threshold_backward_21 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[128, 4],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_threshold_backward_21', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, out_ptr0, out_ptr1, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 128
    rnumel = 4
    RBLOCK: tl.constexpr = 4
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0.0)
    tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.sum(tmp3, 1)[:, None]
    tmp6 = tmp4 * tmp5
    tl.store(out_ptr1 + (x0), tmp6, xmask)
    tl.store(out_ptr0 + (x0), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/na/cnau4s4ehzcmtgh4jpkrd27nxjr4fg7blf4wwlaa2hxbzn2lrscn.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_22 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[4194304], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(15,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_22', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 3211264
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 128
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp3 = tl.load(in_ptr1 + (x3), None)
    tmp5 = tl.load(in_ptr2 + (x3), None)
    tmp6 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp8 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr5 + (x1), None, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
    tmp22 = tl.load(in_ptr8 + (x3), None)
    tmp23 = tl.load(in_ptr9 + (x1), None, eviction_policy='evict_last')
    tmp25 = tl.load(in_ptr10 + (x1), None, eviction_policy='evict_last')
    tmp27 = tl.load(in_ptr11 + (x1), None, eviction_policy='evict_last')
    tmp33 = tl.load(in_ptr12 + (x1), None, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tl.where(tmp2, tmp1, tmp3)
    tmp7 = tmp5 - tmp6
    tmp9 = 3.985969387755102e-05
    tmp10 = tmp8 * tmp9
    tmp12 = tmp11 * tmp11
    tmp13 = tmp10 * tmp12
    tmp14 = tmp7 * tmp13
    tmp15 = tmp4 - tmp14
    tmp17 = tmp16 * tmp9
    tmp18 = tmp15 - tmp17
    tmp20 = tmp11 * tmp19
    tmp21 = tmp18 * tmp20
    tmp24 = tmp22 - tmp23
    tmp26 = tmp25 * tmp9
    tmp28 = tmp27 * tmp27
    tmp29 = tmp26 * tmp28
    tmp30 = tmp24 * tmp29
    tmp31 = tmp4 - tmp30
    tmp32 = tmp31 - tmp17
    tmp34 = tmp27 * tmp33
    tmp35 = tmp32 * tmp34
    tl.store(out_ptr0 + (x3), tmp21, None)
    tl.store(out_ptr1 + (x3), tmp35, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/g4/cg4pixja77cgxioxhonshpk7zkfusy2cloeadniabjgotma3zvrt.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_native_batch_norm_backward_threshold_backward_23 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6, 7))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_threshold_backward_23', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 128
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 32
    x1 = (xindex // 32)
    _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    x3 = xindex
    tmp9 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    _tmp13 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + ((3136*x0) + (100352*(r2 // 3136)) + (200704*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + ((3136*x0) + (100352*(r2 // 3136)) + (200704*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp8 = tl.load(in_ptr2 + ((3136*x0) + (100352*(r2 // 3136)) + (200704*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
        tmp7 = _tmp6 + tmp5
        _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp10 = tmp8 - tmp9
        tmp11 = tmp4 * tmp10
        tmp12 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp14 = _tmp13 + tmp12
        _tmp13 = tl.where(rmask & xmask, tmp14, _tmp13)
    tmp6 = tl.sum(_tmp6, 1)[:, None]
    tl.store(out_ptr0 + (x3), tmp6, xmask)
    tmp13 = tl.sum(_tmp13, 1)[:, None]
    tl.store(out_ptr1 + (x3), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/dz/cdzwzktcwgpp77lynakb2uzdbdxmig46szyq7djtljbrxwvr3mtl.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_per_fused_native_batch_norm_backward_threshold_backward_24 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[32, 4],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_threshold_backward_24', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 32
    rnumel = 4
    RBLOCK: tl.constexpr = 4
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (32*r1)), rmask & xmask, other=0.0)
    tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.sum(tmp3, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ou/coui7aejmdv2zzrbi6hliwuyzukhhpmya2eworrgs5amvx5iikvr.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_per_fused_native_batch_norm_backward_threshold_backward_25 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[32, 4],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_threshold_backward_25', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, out_ptr0, out_ptr1, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 32
    rnumel = 4
    RBLOCK: tl.constexpr = 4
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (32*r1)), rmask & xmask, other=0.0)
    tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.sum(tmp3, 1)[:, None]
    tmp6 = tmp4 * tmp5
    tl.store(out_ptr1 + (x0), tmp6, xmask)
    tl.store(out_ptr0 + (x0), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/pc/cpc7flv6owew75ww5yqpivrt5m5e6nxch3fdavqpwu642fedmsmf.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_26 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[1048576], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_26', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 802816
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 32
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp3 = tl.load(in_out_ptr0 + (x3), None)
    tmp5 = tl.load(in_ptr1 + (x3), None)
    tmp6 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp8 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr5 + (x1), None, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tl.where(tmp2, tmp1, tmp3)
    tmp7 = tmp5 - tmp6
    tmp9 = 3.985969387755102e-05
    tmp10 = tmp8 * tmp9
    tmp12 = tmp11 * tmp11
    tmp13 = tmp10 * tmp12
    tmp14 = tmp7 * tmp13
    tmp15 = tmp4 - tmp14
    tmp17 = tmp16 * tmp9
    tmp18 = tmp15 - tmp17
    tmp20 = tmp11 * tmp19
    tmp21 = tmp18 * tmp20
    tl.store(in_out_ptr0 + (x3), tmp21, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/2h/c2heqfabnehogha4pu7eyu4pnw5klwwz7pcjaduiy6vgzwm5wjvo.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_per_fused_add_native_batch_norm_backward_threshold_backward_27 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[256, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: '*fp32', 18: '*fp32', 19: 'i32', 20: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(19, 20))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_batch_norm_backward_threshold_backward_27', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, out_ptr5, out_ptr6, xnumel, rnumel):
    xnumel = 144
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp3 = tl.load(in_ptr1 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp4 = tl.load(in_ptr2 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp11 = tl.load(in_ptr3 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr5 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp20 = tl.load(in_ptr6 + (x0), xmask, eviction_policy='evict_last')
    tmp27 = tl.load(in_ptr7 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp28 = tl.load(in_ptr8 + (x0), xmask, eviction_policy='evict_last')
    tmp35 = tl.load(in_ptr9 + (x0), xmask, eviction_policy='evict_last')
    tmp37 = tl.load(in_ptr10 + (x0), xmask, eviction_policy='evict_last')
    tmp39 = tl.load(in_ptr11 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp6 = tl.where(tmp2, tmp1, tmp5)
    tmp7 = tl.broadcast_to(tmp6, [RBLOCK])
    tmp9 = tl.where(rmask & xmask, tmp7, 0)
    tmp10 = triton_helpers.promote_to_tensor(tl.sum(tmp9, 0))
    tmp13 = tmp11 - tmp12
    tmp14 = tmp6 * tmp13
    tmp15 = tl.broadcast_to(tmp14, [RBLOCK])
    tmp17 = tl.where(rmask & xmask, tmp15, 0)
    tmp18 = triton_helpers.promote_to_tensor(tl.sum(tmp17, 0))
    tmp21 = tmp19 - tmp20
    tmp22 = tmp6 * tmp21
    tmp23 = tl.broadcast_to(tmp22, [RBLOCK])
    tmp25 = tl.where(rmask & xmask, tmp23, 0)
    tmp26 = triton_helpers.promote_to_tensor(tl.sum(tmp25, 0))
    tmp29 = tmp27 - tmp28
    tmp30 = tmp6 * tmp29
    tmp31 = tl.broadcast_to(tmp30, [RBLOCK])
    tmp33 = tl.where(rmask & xmask, tmp31, 0)
    tmp34 = triton_helpers.promote_to_tensor(tl.sum(tmp33, 0))
    tmp36 = tmp18 * tmp35
    tmp38 = tmp26 * tmp37
    tmp40 = tmp34 * tmp39
    tl.store(out_ptr4 + (x0), tmp36, xmask)
    tl.store(out_ptr5 + (x0), tmp38, xmask)
    tl.store(out_ptr6 + (x0), tmp40, xmask)
    tl.store(out_ptr0 + (x0), tmp10, xmask)
    tl.store(out_ptr1 + (x0), tmp18, xmask)
    tl.store(out_ptr2 + (x0), tmp26, xmask)
    tl.store(out_ptr3 + (x0), tmp34, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ll/cll3sy4dtxxyrmas3yv4cs4uolokwdw5futitpsp44mi23uss726.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_add_native_batch_norm_backward_threshold_backward_28 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: '*fp32', 18: '*fp32', 19: '*fp32', 20: '*fp32', 21: '*fp32', 22: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(22,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_native_batch_norm_backward_threshold_backward_28', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, out_ptr0, out_ptr1, out_ptr2, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 144
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp3 = tl.load(in_ptr1 + (x3), xmask)
    tmp4 = tl.load(in_ptr2 + (x3), xmask)
    tmp7 = tl.load(in_ptr3 + (x3), xmask)
    tmp8 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp18 = tl.load(in_ptr7 + (x1), xmask, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x3), xmask)
    tmp25 = tl.load(in_ptr10 + (x1), xmask, eviction_policy='evict_last')
    tmp27 = tl.load(in_ptr11 + (x1), xmask, eviction_policy='evict_last')
    tmp29 = tl.load(in_ptr12 + (x1), xmask, eviction_policy='evict_last')
    tmp35 = tl.load(in_ptr13 + (x1), xmask, eviction_policy='evict_last')
    tmp38 = tl.load(in_ptr14 + (x3), xmask)
    tmp39 = tl.load(in_ptr15 + (x1), xmask, eviction_policy='evict_last')
    tmp41 = tl.load(in_ptr16 + (x1), xmask, eviction_policy='evict_last')
    tmp43 = tl.load(in_ptr17 + (x1), xmask, eviction_policy='evict_last')
    tmp49 = tl.load(in_ptr18 + (x1), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp6 = tl.where(tmp2, tmp1, tmp5)
    tmp9 = tmp7 - tmp8
    tmp11 = 0.002551020408163265
    tmp12 = tmp10 * tmp11
    tmp14 = tmp13 * tmp13
    tmp15 = tmp12 * tmp14
    tmp16 = tmp9 * tmp15
    tmp17 = tmp6 - tmp16
    tmp19 = tmp18 * tmp11
    tmp20 = tmp17 - tmp19
    tmp22 = tmp13 * tmp21
    tmp23 = tmp20 * tmp22
    tmp26 = tmp24 - tmp25
    tmp28 = tmp27 * tmp11
    tmp30 = tmp29 * tmp29
    tmp31 = tmp28 * tmp30
    tmp32 = tmp26 * tmp31
    tmp33 = tmp6 - tmp32
    tmp34 = tmp33 - tmp19
    tmp36 = tmp29 * tmp35
    tmp37 = tmp34 * tmp36
    tmp40 = tmp38 - tmp39
    tmp42 = tmp41 * tmp11
    tmp44 = tmp43 * tmp43
    tmp45 = tmp42 * tmp44
    tmp46 = tmp40 * tmp45
    tmp47 = tmp6 - tmp46
    tmp48 = tmp47 - tmp19
    tmp50 = tmp43 * tmp49
    tmp51 = tmp48 * tmp50
    tl.store(out_ptr0 + (x3), tmp23, xmask)
    tl.store(out_ptr1 + (x3), tmp37, xmask)
    tl.store(out_ptr2 + (x3), tmp51, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/qs/cqscydkeh7f74vomoq4qvjsvjkuv2jdbxiecj5efvq66gzmkf5tr.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_native_batch_norm_backward_threshold_backward_29 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[64, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_threshold_backward_29', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 36
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp9 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    _tmp13 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (7056*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + (r1 + (196*x0) + (7056*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp8 = tl.load(in_ptr2 + (r1 + (196*x0) + (7056*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
        tmp7 = _tmp6 + tmp5
        _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp10 = tmp8 - tmp9
        tmp11 = tmp4 * tmp10
        tmp12 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp14 = _tmp13 + tmp12
        _tmp13 = tl.where(rmask & xmask, tmp14, _tmp13)
    tmp6 = tl.sum(_tmp6, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp6, xmask)
    tmp13 = tl.sum(_tmp13, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp13, xmask)
    tmp15 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp16 = tmp13 * tmp15
    tl.store(out_ptr2 + (x0), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/xh/cxh6hc56sqzqa6ajmujyqbt7tnxsg5vad4y2juwlvkp57ygpmd5m.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_30 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_30', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 36
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp3 = tl.load(in_out_ptr0 + (x3), xmask)
    tmp5 = tl.load(in_ptr1 + (x3), xmask)
    tmp6 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp8 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tl.where(tmp2, tmp1, tmp3)
    tmp7 = tmp5 - tmp6
    tmp9 = 0.0006377551020408163
    tmp10 = tmp8 * tmp9
    tmp12 = tmp11 * tmp11
    tmp13 = tmp10 * tmp12
    tmp14 = tmp7 * tmp13
    tmp15 = tmp4 - tmp14
    tmp17 = tmp16 * tmp9
    tmp18 = tmp15 - tmp17
    tmp20 = tmp11 * tmp19
    tmp21 = tmp18 * tmp20
    tl.store(in_out_ptr0 + (x3), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/7e/c7erylrwb2nmdwnbtwqdvy2yyxsv7yn2aprctsaezgdywrza5fi2.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_native_batch_norm_backward_threshold_backward_31 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[32, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_threshold_backward_31', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 18
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp9 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    _tmp13 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (3528*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + (r1 + (196*x0) + (3528*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp8 = tl.load(in_ptr2 + (r1 + (196*x0) + (3528*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
        tmp7 = _tmp6 + tmp5
        _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp10 = tmp8 - tmp9
        tmp11 = tmp4 * tmp10
        tmp12 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp14 = _tmp13 + tmp12
        _tmp13 = tl.where(rmask & xmask, tmp14, _tmp13)
    tmp6 = tl.sum(_tmp6, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp6, xmask)
    tmp13 = tl.sum(_tmp13, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp13, xmask)
    tmp15 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp16 = tmp13 * tmp15
    tl.store(out_ptr2 + (x0), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/6z/c6zm76t3tqm3fsj2xcefg3xjm5t6radli23qgfi36kdp6gzedcys.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_32 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[32768], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_32', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 28224
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 18
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp3 = tl.load(in_out_ptr0 + (x3), xmask)
    tmp5 = tl.load(in_ptr1 + (x3), xmask)
    tmp6 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp8 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tl.where(tmp2, tmp1, tmp3)
    tmp7 = tmp5 - tmp6
    tmp9 = 0.0006377551020408163
    tmp10 = tmp8 * tmp9
    tmp12 = tmp11 * tmp11
    tmp13 = tmp10 * tmp12
    tmp14 = tmp7 * tmp13
    tmp15 = tmp4 - tmp14
    tmp17 = tmp16 * tmp9
    tmp18 = tmp15 - tmp17
    tmp20 = tmp11 * tmp19
    tmp21 = tmp18 * tmp20
    tl.store(in_out_ptr0 + (x3), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/et/cetzgv4ibfh3eyncy4wfae3nhw2vwa2fpqbdjw6lwwml345cbeat.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_native_batch_norm_backward_threshold_backward_33 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[32, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_threshold_backward_33', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 18
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp9 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    _tmp13 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 784
        r2 = (rindex // 784)
        tmp0 = tl.load(in_ptr0 + (r1 + (784*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + (r1 + (784*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp8 = tl.load(in_ptr2 + (r1 + (784*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
        tmp7 = _tmp6 + tmp5
        _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp10 = tmp8 - tmp9
        tmp11 = tmp4 * tmp10
        tmp12 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp14 = _tmp13 + tmp12
        _tmp13 = tl.where(rmask & xmask, tmp14, _tmp13)
    tmp6 = tl.sum(_tmp6, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp6, xmask)
    tmp13 = tl.sum(_tmp13, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp13, xmask)
    tmp15 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp16 = tmp13 * tmp15
    tl.store(out_ptr2 + (x0), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/62/c62a3ux65anxwrbd5pdusoel4dn25qnhhajfviozeqybqmcilev6.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_34 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_34', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 784) % 18
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp3 = tl.load(in_out_ptr0 + (x3), xmask)
    tmp5 = tl.load(in_ptr1 + (x3), xmask)
    tmp6 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp8 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tl.where(tmp2, tmp1, tmp3)
    tmp7 = tmp5 - tmp6
    tmp9 = 0.00015943877551020407
    tmp10 = tmp8 * tmp9
    tmp12 = tmp11 * tmp11
    tmp13 = tmp10 * tmp12
    tmp14 = tmp7 * tmp13
    tmp15 = tmp4 - tmp14
    tmp17 = tmp16 * tmp9
    tmp18 = tmp15 - tmp17
    tmp20 = tmp11 * tmp19
    tmp21 = tmp18 * tmp20
    tl.store(in_out_ptr0 + (x3), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/f7/cf7evnm4a653pa4jdozevdjgzlyszzxo2o4uslpolf5o6qhcwtol.py
# Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.add, aten.new_zeros, aten.threshold_backward]

triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_35 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[32768], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(1,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_35', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 28224
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = 0.0
    tl.store(out_ptr0 + (x0), tmp0, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/kb/ckbjuqks66o5lk7dfycbfhb7yr3vi7zpwxqhs73wzxwy3r7g7fib.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_36 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_36', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp4 = tl.load(in_ptr1 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp6 = tl.where(tmp2, tmp1, tmp5)
    tl.store(in_out_ptr0 + (x0), tmp6, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/cg/ccgjxswl4cy7nli7by53q34lq2vvbfvgfmre4rd7dkj2r2qtiufr.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]

triton_per_fused_native_batch_norm_backward_37 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[128, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7, 8))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_37', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel):
    xnumel = 72
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (3528*r2)), rmask & xmask, other=0.0)
    tmp5 = tl.load(in_ptr1 + (r1 + (49*x0) + (3528*r2)), rmask & xmask, other=0.0)
    tmp6 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = triton_helpers.promote_to_tensor(tl.sum(tmp3, 0))
    tmp7 = tmp5 - tmp6
    tmp8 = tmp0 * tmp7
    tmp9 = tl.broadcast_to(tmp8, [RBLOCK])
    tmp11 = tl.where(rmask & xmask, tmp9, 0)
    tmp12 = triton_helpers.promote_to_tensor(tl.sum(tmp11, 0))
    tmp14 = tmp12 * tmp13
    tl.store(out_ptr2 + (x0), tmp14, xmask)
    tl.store(out_ptr0 + (x0), tmp4, xmask)
    tl.store(out_ptr1 + (x0), tmp12, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/kq/ckqe7icaze2nvzt4cglfxg53hkifrf5mv33kmmhvm42rqnlvwlrw.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_38 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[32768], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_38', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 28224
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 72
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x3), xmask)
    tmp2 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 0.002551020408163265
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tl.store(in_out_ptr0 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/4f/c4fbkpgmjl262pallay2oxrykvukeb5kebt3hwyrejs6sxwetsus.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]

triton_red_fused_native_batch_norm_backward_39 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: 'i32', 13: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(12, 13))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_39', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 72
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    _tmp9 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    _tmp16 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr1 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp11 = tl.load(in_ptr3 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = _tmp2 + tmp1
        _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp6 = tmp4 - tmp5
        tmp7 = tmp0 * tmp6
        tmp8 = tl.broadcast_to(tmp7, [XBLOCK, RBLOCK])
        tmp10 = _tmp9 + tmp8
        _tmp9 = tl.where(rmask & xmask, tmp10, _tmp9)
        tmp13 = tmp11 - tmp12
        tmp14 = tmp0 * tmp13
        tmp15 = tl.broadcast_to(tmp14, [XBLOCK, RBLOCK])
        tmp17 = _tmp16 + tmp15
        _tmp16 = tl.where(rmask & xmask, tmp17, _tmp16)
    tmp2 = tl.sum(_tmp2, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tmp9 = tl.sum(_tmp9, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp9, xmask)
    tmp16 = tl.sum(_tmp16, 1)[:, None]
    tl.store(out_ptr2 + (x0), tmp16, xmask)
    tmp18 = tl.load(in_ptr5 + (x0), xmask, eviction_policy='evict_last')
    tmp20 = tl.load(in_ptr6 + (x0), xmask, eviction_policy='evict_last')
    tmp19 = tmp9 * tmp18
    tmp21 = tmp16 * tmp20
    tl.store(out_ptr3 + (x0), tmp19, xmask)
    tl.store(out_ptr4 + (x0), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/zf/czfoyx7gffw3ov3p3cagk3hmqfityczlj63fgvotjxl45nqjyzqn.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_40 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(14,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_40', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 72
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x3), xmask)
    tmp2 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp18 = tl.load(in_ptr7 + (x3), xmask)
    tmp19 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr9 + (x1), xmask, eviction_policy='evict_last')
    tmp23 = tl.load(in_ptr10 + (x1), xmask, eviction_policy='evict_last')
    tmp29 = tl.load(in_ptr11 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 0.0006377551020408163
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tmp20 = tmp18 - tmp19
    tmp22 = tmp21 * tmp5
    tmp24 = tmp23 * tmp23
    tmp25 = tmp22 * tmp24
    tmp26 = tmp20 * tmp25
    tmp27 = tmp0 - tmp26
    tmp28 = tmp27 - tmp13
    tmp30 = tmp23 * tmp29
    tmp31 = tmp28 * tmp30
    tl.store(out_ptr0 + (x3), tmp17, xmask)
    tl.store(out_ptr1 + (x3), tmp31, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/hd/chdlri7ynnli3f2vihbk2ppx7oxaozm72cqcr6gqmce3jzjrx62a.py
# Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.add, aten.new_zeros, aten.threshold_backward]

triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_41 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16384], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(1,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_41', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 14112
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = 0.0
    tl.store(out_ptr0 + (x0), tmp0, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/54/c547plca6s4csnhwmjaawx7l4u72y5l5pzil2pwrt7ovrvzyeou5.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_42 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_42', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 225792
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp4 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp6 = tl.where(tmp2, tmp1, tmp5)
    tl.store(in_out_ptr0 + (x0), tmp6, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/a6/ca6pgq7sbqe5rgmmveehqabom4rkwdnkm5tinb45yygiyb5xlejd.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]

triton_per_fused_native_batch_norm_backward_43 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[64, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_43', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel):
    xnumel = 36
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (1764*r2)), rmask & xmask, other=0.0)
    tmp5 = tl.load(in_ptr1 + (r1 + (49*x0) + (1764*r2)), rmask & xmask, other=0.0)
    tmp6 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = triton_helpers.promote_to_tensor(tl.sum(tmp3, 0))
    tmp7 = tmp5 - tmp6
    tmp8 = tmp0 * tmp7
    tmp9 = tl.broadcast_to(tmp8, [RBLOCK])
    tmp11 = tl.where(rmask & xmask, tmp9, 0)
    tmp12 = triton_helpers.promote_to_tensor(tl.sum(tmp11, 0))
    tmp14 = tmp12 * tmp13
    tl.store(out_ptr2 + (x0), tmp14, xmask)
    tl.store(out_ptr0 + (x0), tmp4, xmask)
    tl.store(out_ptr1 + (x0), tmp12, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/bp/cbpb7ocz2su3oxvhrmvsqpvqu4tjkfjkaxtp4ipdvk264psnto7r.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_44 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[16384], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_44', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 14112
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 36
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x3), xmask)
    tmp2 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 0.002551020408163265
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tl.store(in_out_ptr0 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ih/cihdnume4wqwu3cw2hzjtuk5aestngfodyijwlwyyot7raoyptxe.py
# Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]

triton_poi_fused__unsafe_index_put_new_zeros_45 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(1,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_put_new_zeros_45', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = 0.0
    tl.store(out_ptr0 + (x0), tmp0, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/hd/chd3rsecnzpmzygfrfv7lb4gf2zdgnt33ypoddbdyqkidbsxcqxd.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]

triton_red_fused_native_batch_norm_backward_46 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[64, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_46', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 36
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    _tmp9 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (7056*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr1 + (r1 + (196*x0) + (7056*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = _tmp2 + tmp1
        _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp6 = tmp4 - tmp5
        tmp7 = tmp0 * tmp6
        tmp8 = tl.broadcast_to(tmp7, [XBLOCK, RBLOCK])
        tmp10 = _tmp9 + tmp8
        _tmp9 = tl.where(rmask & xmask, tmp10, _tmp9)
    tmp2 = tl.sum(_tmp2, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tmp9 = tl.sum(_tmp9, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp9, xmask)
    tmp11 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tmp9 * tmp11
    tl.store(out_ptr2 + (x0), tmp12, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ug/cugdld747qnk4mairkj4m22foulbtqbhkj4lownkidrogjzj56so.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_47 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_47', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 36
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x3), xmask)
    tmp2 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 0.0006377551020408163
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tl.store(in_out_ptr0 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/47/c47t4kfgwgqmxrsexdjdlcfon6swnhakorrzys42hextd2mxwgdp.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]

triton_red_fused_native_batch_norm_backward_48 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[64, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_48', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 36
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    _tmp9 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 784
        r2 = (rindex // 784)
        tmp0 = tl.load(in_ptr0 + (r1 + (784*x0) + (28224*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr1 + (r1 + (784*x0) + (28224*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = _tmp2 + tmp1
        _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp6 = tmp4 - tmp5
        tmp7 = tmp0 * tmp6
        tmp8 = tl.broadcast_to(tmp7, [XBLOCK, RBLOCK])
        tmp10 = _tmp9 + tmp8
        _tmp9 = tl.where(rmask & xmask, tmp10, _tmp9)
    tmp2 = tl.sum(_tmp2, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tmp9 = tl.sum(_tmp9, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp9, xmask)
    tmp11 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tmp9 * tmp11
    tl.store(out_ptr2 + (x0), tmp12, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/si/csi7rl55le3mlbvkf3sjkbj5kjj5izq46rcl2rwajehc5zgdy4mm.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_49 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_49', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 225792
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 784) % 36
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x3), xmask)
    tmp2 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 0.00015943877551020407
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tl.store(out_ptr0 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/f3/cf355tw4o4cogo2b3grwksnpq2jjgdlxnavw3c2yjzslerukvsv5.py
# Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.add, aten.new_zeros, aten.threshold_backward]

triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_50 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8192], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(1,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_50', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 7056
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = 0.0
    tl.store(out_ptr0 + (x0), tmp0, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/qg/cqgfjy5w5y5r3f5mvxxmzs7o2quo7qr25le647sixnx6vsnqnij3.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_51 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_51', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_out_ptr1, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp4 = tl.load(in_ptr1 + (x0), xmask)
    tmp7 = tl.load(in_ptr2 + (x0), xmask)
    tmp9 = tl.load(in_out_ptr1 + (x0), xmask)
    tmp10 = tl.load(in_ptr3 + (x0), xmask)
    tmp12 = tl.load(in_ptr4 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp6 = tl.where(tmp2, tmp1, tmp5)
    tmp8 = tmp7 <= tmp1
    tmp11 = tmp9 + tmp10
    tmp13 = tmp11 + tmp12
    tmp14 = tmp13 + tmp6
    tmp15 = tl.where(tmp8, tmp1, tmp14)
    tl.store(in_out_ptr0 + (x0), tmp6, xmask)
    tl.store(in_out_ptr1 + (x0), tmp15, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/fx/cfx6u5idooetsjtoijyn76pkihuz2tgdrumo6h73oidfhla3xjd3.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]

triton_per_fused_native_batch_norm_backward_52 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[32, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_52', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel):
    xnumel = 18
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (882*r2)), rmask & xmask, other=0.0)
    tmp5 = tl.load(in_ptr1 + (r1 + (49*x0) + (882*r2)), rmask & xmask, other=0.0)
    tmp6 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = triton_helpers.promote_to_tensor(tl.sum(tmp3, 0))
    tmp7 = tmp5 - tmp6
    tmp8 = tmp0 * tmp7
    tmp9 = tl.broadcast_to(tmp8, [RBLOCK])
    tmp11 = tl.where(rmask & xmask, tmp9, 0)
    tmp12 = triton_helpers.promote_to_tensor(tl.sum(tmp11, 0))
    tmp14 = tmp12 * tmp13
    tl.store(out_ptr2 + (x0), tmp14, xmask)
    tl.store(out_ptr0 + (x0), tmp4, xmask)
    tl.store(out_ptr1 + (x0), tmp12, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ah/cahpblznflnj7ea6ikd2vprnjwu73gmmp7nqhnatpkeyx7adusxe.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_53 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8192], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_53', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 7056
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 18
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x3), xmask)
    tmp2 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 0.002551020408163265
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tl.store(in_out_ptr0 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/pw/cpwvaq4kjk7ffxtsxe27jmte6z2k4s5xwdl52drl2f4ximcvc33c.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]

triton_red_fused_native_batch_norm_backward_54 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[32, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_54', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 18
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    _tmp9 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (3528*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr1 + (r1 + (196*x0) + (3528*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = _tmp2 + tmp1
        _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp6 = tmp4 - tmp5
        tmp7 = tmp0 * tmp6
        tmp8 = tl.broadcast_to(tmp7, [XBLOCK, RBLOCK])
        tmp10 = _tmp9 + tmp8
        _tmp9 = tl.where(rmask & xmask, tmp10, _tmp9)
    tmp2 = tl.sum(_tmp2, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tmp9 = tl.sum(_tmp9, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp9, xmask)
    tmp11 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tmp9 * tmp11
    tl.store(out_ptr2 + (x0), tmp12, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/a5/ca5n3b56rahfpje56vcnbcfbswvsn3x6ne7yt6qvjli2eg7m255k.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_55 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[32768], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_55', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 28224
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 18
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x3), xmask)
    tmp2 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 0.0006377551020408163
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tl.store(in_out_ptr0 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/cg/ccg2gy7cs4bpq2lcjwd7fxkc3scy5h4jevwxkqm2mlzbdotolhvh.py
# Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]

triton_poi_fused__unsafe_index_put_new_zeros_56 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(1,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_put_new_zeros_56', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = 0.0
    tl.store(out_ptr0 + (x0), tmp0, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/cb/ccbinj4teftpxjflsls6xi632e4ogqwzgxh566oe2lmgf2wq4oec.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]

triton_red_fused_native_batch_norm_backward_57 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[32, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_57', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 18
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    _tmp9 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 784
        r2 = (rindex // 784)
        tmp0 = tl.load(in_ptr0 + (r1 + (784*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr1 + (r1 + (784*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = _tmp2 + tmp1
        _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp6 = tmp4 - tmp5
        tmp7 = tmp0 * tmp6
        tmp8 = tl.broadcast_to(tmp7, [XBLOCK, RBLOCK])
        tmp10 = _tmp9 + tmp8
        _tmp9 = tl.where(rmask & xmask, tmp10, _tmp9)
    tmp2 = tl.sum(_tmp2, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tmp9 = tl.sum(_tmp9, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp9, xmask)
    tmp11 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tmp9 * tmp11
    tl.store(out_ptr2 + (x0), tmp12, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/sa/csao2wktcka24sypy6pi3qhefox7d5vclq6dzgxknfzc227s5frd.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_58 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_58', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 784) % 18
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x3), xmask)
    tmp2 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 0.00015943877551020407
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tl.store(in_out_ptr0 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/g2/cg2xb63bczmr2jkqhzpt452ydbubpe4z6zpmas4uzs3jzsljsy4c.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_59 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_59', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp5 = tl.load(in_ptr2 + (x0), xmask)
    tmp6 = tl.load(in_ptr3 + (x0), xmask)
    tmp9 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp11 = tl.load(in_ptr4 + (x0), xmask)
    tmp13 = tl.load(in_ptr5 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tmp3 <= tmp1
    tmp7 = tmp5 + tmp6
    tmp8 = tl.where(tmp4, tmp1, tmp7)
    tmp10 = tmp8 + tmp9
    tmp12 = tmp10 + tmp11
    tmp14 = tmp12 + tmp13
    tmp15 = tl.where(tmp2, tmp1, tmp14)
    tl.store(in_out_ptr0 + (x0), tmp15, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/nz/cnzhek2csdojw2ph2iyqpn6vfzs5ek7yfxjgjjt2u5xiwlx4p3ej.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]

triton_per_fused_native_batch_norm_backward_60 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[256, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7, 8))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_60', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel):
    xnumel = 144
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp5 = tl.load(in_ptr1 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp6 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = triton_helpers.promote_to_tensor(tl.sum(tmp3, 0))
    tmp7 = tmp5 - tmp6
    tmp8 = tmp0 * tmp7
    tmp9 = tl.broadcast_to(tmp8, [RBLOCK])
    tmp11 = tl.where(rmask & xmask, tmp9, 0)
    tmp12 = triton_helpers.promote_to_tensor(tl.sum(tmp11, 0))
    tmp14 = tmp12 * tmp13
    tl.store(out_ptr2 + (x0), tmp14, xmask)
    tl.store(out_ptr0 + (x0), tmp4, xmask)
    tl.store(out_ptr1 + (x0), tmp12, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ft/cftymmq6vfbcvw74zxlwyhhlx5r6vn7sypsjhflnvyrxt62knijv.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_61 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_61', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 144
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x3), xmask)
    tmp2 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 0.002551020408163265
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tl.store(out_ptr0 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ru/crugijfykzenrgbhfpeyqxgmxt2ck2kb56x276vmsekuiylab6k5.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_per_fused_native_batch_norm_backward_threshold_backward_62 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[256, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_threshold_backward_62', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel):
    xnumel = 144
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp3 = tl.load(in_ptr1 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp9 = tl.load(in_ptr2 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp17 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tl.where(tmp2, tmp1, tmp3)
    tmp5 = tl.broadcast_to(tmp4, [RBLOCK])
    tmp7 = tl.where(rmask & xmask, tmp5, 0)
    tmp8 = triton_helpers.promote_to_tensor(tl.sum(tmp7, 0))
    tmp11 = tmp9 - tmp10
    tmp12 = tmp4 * tmp11
    tmp13 = tl.broadcast_to(tmp12, [RBLOCK])
    tmp15 = tl.where(rmask & xmask, tmp13, 0)
    tmp16 = triton_helpers.promote_to_tensor(tl.sum(tmp15, 0))
    tmp18 = tmp16 * tmp17
    tl.store(out_ptr2 + (x0), tmp18, xmask)
    tl.store(out_ptr0 + (x0), tmp8, xmask)
    tl.store(out_ptr1 + (x0), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/vn/cvndgvtkkvcuj5hvxthaid3sang3ds46pirnhsycjmxlkq4cui65.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_63 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_63', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 144
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp3 = tl.load(in_out_ptr0 + (x3), xmask)
    tmp5 = tl.load(in_ptr1 + (x3), xmask)
    tmp6 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp8 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tl.where(tmp2, tmp1, tmp3)
    tmp7 = tmp5 - tmp6
    tmp9 = 0.002551020408163265
    tmp10 = tmp8 * tmp9
    tmp12 = tmp11 * tmp11
    tmp13 = tmp10 * tmp12
    tmp14 = tmp7 * tmp13
    tmp15 = tmp4 - tmp14
    tmp17 = tmp16 * tmp9
    tmp18 = tmp15 - tmp17
    tmp20 = tmp11 * tmp19
    tmp21 = tmp18 * tmp20
    tl.store(in_out_ptr0 + (x3), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/iu/ciu7vjnbygngslra7lxmcubykulsfgartmfl2vnsmmoae3xovhv5.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_per_fused_add_native_batch_norm_backward_threshold_backward_64 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[256, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32', 10: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9, 10))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_batch_norm_backward_threshold_backward_64', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel):
    xnumel = 144
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp3 = tl.load(in_ptr1 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp4 = tl.load(in_ptr2 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp11 = tl.load(in_ptr3 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr5 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp6 = tl.where(tmp2, tmp1, tmp5)
    tmp7 = tl.broadcast_to(tmp6, [RBLOCK])
    tmp9 = tl.where(rmask & xmask, tmp7, 0)
    tmp10 = triton_helpers.promote_to_tensor(tl.sum(tmp9, 0))
    tmp13 = tmp11 - tmp12
    tmp14 = tmp6 * tmp13
    tmp15 = tl.broadcast_to(tmp14, [RBLOCK])
    tmp17 = tl.where(rmask & xmask, tmp15, 0)
    tmp18 = triton_helpers.promote_to_tensor(tl.sum(tmp17, 0))
    tmp20 = tmp18 * tmp19
    tl.store(out_ptr2 + (x0), tmp20, xmask)
    tl.store(out_ptr0 + (x0), tmp10, xmask)
    tl.store(out_ptr1 + (x0), tmp18, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ph/cphb7gkehlwm32sfrw6g4ppeau5rtubbajrpimylfodenhyimsrj.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_add_native_batch_norm_backward_threshold_backward_65 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_native_batch_norm_backward_threshold_backward_65', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 144
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp3 = tl.load(in_ptr1 + (x3), xmask)
    tmp4 = tl.load(in_ptr2 + (x3), xmask)
    tmp7 = tl.load(in_ptr3 + (x3), xmask)
    tmp8 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp18 = tl.load(in_ptr7 + (x1), xmask, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp6 = tl.where(tmp2, tmp1, tmp5)
    tmp9 = tmp7 - tmp8
    tmp11 = 0.002551020408163265
    tmp12 = tmp10 * tmp11
    tmp14 = tmp13 * tmp13
    tmp15 = tmp12 * tmp14
    tmp16 = tmp9 * tmp15
    tmp17 = tmp6 - tmp16
    tmp19 = tmp18 * tmp11
    tmp20 = tmp17 - tmp19
    tmp22 = tmp13 * tmp21
    tmp23 = tmp20 * tmp22
    tl.store(out_ptr0 + (x3), tmp23, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/eo/ceojpxuhqucizhp4553cy5k4iv774bqwlegxcyncy5f6ubov3gsv.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_66 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_66', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp5 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp6 = tl.load(in_ptr2 + (x0), xmask)
    tmp9 = tl.load(in_ptr3 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tmp3 <= tmp1
    tmp7 = tmp5 + tmp6
    tmp8 = tl.where(tmp4, tmp1, tmp7)
    tmp10 = tmp8 + tmp9
    tmp11 = tl.where(tmp2, tmp1, tmp10)
    tl.store(in_out_ptr0 + (x0), tmp11, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/m2/cm2ka3vk6gkxauu4eczcy7brqipb3ufp6s7peupmrlnrh2yz27cd.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_67 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_67', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp4 = tl.load(in_ptr1 + (x0), xmask)
    tmp6 = tl.load(in_ptr2 + (x0), xmask)
    tmp8 = tl.load(in_ptr3 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp7 = tmp5 + tmp6
    tmp9 = tmp7 + tmp8
    tmp10 = tl.where(tmp2, tmp1, tmp9)
    tl.store(in_out_ptr0 + (x0), tmp10, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/xj/cxji7eh7xwfgsuiwsvmutr2oeann2jbglvytpm2hzvtz7khlvrrt.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]

triton_red_fused_native_batch_norm_backward_68 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7, 8))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_68', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 72
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    _tmp9 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr1 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = _tmp2 + tmp1
        _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp6 = tmp4 - tmp5
        tmp7 = tmp0 * tmp6
        tmp8 = tl.broadcast_to(tmp7, [XBLOCK, RBLOCK])
        tmp10 = _tmp9 + tmp8
        _tmp9 = tl.where(rmask & xmask, tmp10, _tmp9)
    tmp2 = tl.sum(_tmp2, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tmp9 = tl.sum(_tmp9, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp9, xmask)
    tmp11 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tmp9 * tmp11
    tl.store(out_ptr2 + (x0), tmp12, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/da/cdahessl3bw5rs4ecr24zgbkx3r443nwridyhueumhppi2fqnxhs.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_69 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_69', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 72
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x3), xmask)
    tmp2 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 0.0006377551020408163
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tl.store(out_ptr0 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ap/capmy3f4f5u2r4jp2tz4d2orhi3jktmjhoffsogk7ut54e4daxnc.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_native_batch_norm_backward_threshold_backward_70 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_threshold_backward_70', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 72
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp9 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    _tmp13 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp8 = tl.load(in_ptr2 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
        tmp7 = _tmp6 + tmp5
        _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp10 = tmp8 - tmp9
        tmp11 = tmp4 * tmp10
        tmp12 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp14 = _tmp13 + tmp12
        _tmp13 = tl.where(rmask & xmask, tmp14, _tmp13)
    tmp6 = tl.sum(_tmp6, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp6, xmask)
    tmp13 = tl.sum(_tmp13, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp13, xmask)
    tmp15 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp16 = tmp13 * tmp15
    tl.store(out_ptr2 + (x0), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/al/calymlnjzp3tn4hwv2pzhgclzy5erclblrqbg6i7aet4avb3ncry.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 72
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp3 = tl.load(in_out_ptr0 + (x3), xmask)
    tmp5 = tl.load(in_ptr1 + (x3), xmask)
    tmp6 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp8 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tl.where(tmp2, tmp1, tmp3)
    tmp7 = tmp5 - tmp6
    tmp9 = 0.0006377551020408163
    tmp10 = tmp8 * tmp9
    tmp12 = tmp11 * tmp11
    tmp13 = tmp10 * tmp12
    tmp14 = tmp7 * tmp13
    tmp15 = tmp4 - tmp14
    tmp17 = tmp16 * tmp9
    tmp18 = tmp15 - tmp17
    tmp20 = tmp11 * tmp19
    tmp21 = tmp18 * tmp20
    tl.store(in_out_ptr0 + (x3), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/65/c65zoraf64qnj7wmfe6oeb5hlbqwlngx6ce5rtxgobmickez5tbi.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_add_native_batch_norm_backward_threshold_backward_72 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32', 10: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9, 10))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_batch_norm_backward_threshold_backward_72', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 72
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp8 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp11 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    _tmp15 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr2 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp10 = tl.load(in_ptr3 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp5 = tmp3 + tmp4
        tmp6 = tl.where(tmp2, tmp1, tmp5)
        tmp7 = tl.broadcast_to(tmp6, [XBLOCK, RBLOCK])
        tmp9 = _tmp8 + tmp7
        _tmp8 = tl.where(rmask & xmask, tmp9, _tmp8)
        tmp12 = tmp10 - tmp11
        tmp13 = tmp6 * tmp12
        tmp14 = tl.broadcast_to(tmp13, [XBLOCK, RBLOCK])
        tmp16 = _tmp15 + tmp14
        _tmp15 = tl.where(rmask & xmask, tmp16, _tmp15)
    tmp8 = tl.sum(_tmp8, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp8, xmask)
    tmp15 = tl.sum(_tmp15, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp15, xmask)
    tmp17 = tl.load(in_ptr5 + (x0), xmask, eviction_policy='evict_last')
    tmp18 = tmp15 * tmp17
    tl.store(out_ptr2 + (x0), tmp18, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/4w/c4wzle4tujpzwscaiaswiup4jbzskxsw3pea63yl47qthcauoq5v.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_add_native_batch_norm_backward_threshold_backward_73 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_native_batch_norm_backward_threshold_backward_73', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 72
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp3 = tl.load(in_ptr1 + (x3), xmask)
    tmp4 = tl.load(in_ptr2 + (x3), xmask)
    tmp7 = tl.load(in_ptr3 + (x3), xmask)
    tmp8 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp18 = tl.load(in_ptr7 + (x1), xmask, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp6 = tl.where(tmp2, tmp1, tmp5)
    tmp9 = tmp7 - tmp8
    tmp11 = 0.0006377551020408163
    tmp12 = tmp10 * tmp11
    tmp14 = tmp13 * tmp13
    tmp15 = tmp12 * tmp14
    tmp16 = tmp9 * tmp15
    tmp17 = tmp6 - tmp16
    tmp19 = tmp18 * tmp11
    tmp20 = tmp17 - tmp19
    tmp22 = tmp13 * tmp21
    tmp23 = tmp20 * tmp22
    tl.store(out_ptr0 + (x3), tmp23, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/sc/cscotdaoromwns7t7fji6o4q5edx2pmroa4ny27ishs7hu3rr3pf.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_74 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_74', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp5 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp6 = tl.load(in_ptr2 + (x0), xmask)
    tmp9 = tl.load(in_ptr3 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tmp3 <= tmp1
    tmp7 = tmp5 + tmp6
    tmp8 = tl.where(tmp4, tmp1, tmp7)
    tmp10 = tmp8 + tmp9
    tmp11 = tl.where(tmp2, tmp1, tmp10)
    tl.store(in_out_ptr0 + (x0), tmp11, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/le/cle4hzwq4z2rjqrudwcxxpvfkczop3rkv6lcktfwdzym5w6n3afk.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_75 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_75', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
    xnumel = 225792
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp4 = tl.load(in_ptr1 + (x0), xmask)
    tmp6 = tl.load(in_ptr2 + (x0), xmask)
    tmp8 = tl.load(in_ptr3 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp7 = tmp5 + tmp6
    tmp9 = tmp7 + tmp8
    tmp10 = tl.where(tmp2, tmp1, tmp9)
    tl.store(in_out_ptr0 + (x0), tmp10, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/6b/c6bvyc2t6ay5h46mwwouj3bvpxtxhgealsno545td4qe2ri6uf24.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_native_batch_norm_backward_threshold_backward_76 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[64, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_threshold_backward_76', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 36
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp9 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    _tmp13 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 784
        r2 = (rindex // 784)
        tmp0 = tl.load(in_ptr0 + (r1 + (784*x0) + (28224*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + (r1 + (784*x0) + (28224*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp8 = tl.load(in_ptr2 + (r1 + (784*x0) + (28224*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
        tmp7 = _tmp6 + tmp5
        _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp10 = tmp8 - tmp9
        tmp11 = tmp4 * tmp10
        tmp12 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp14 = _tmp13 + tmp12
        _tmp13 = tl.where(rmask & xmask, tmp14, _tmp13)
    tmp6 = tl.sum(_tmp6, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp6, xmask)
    tmp13 = tl.sum(_tmp13, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp13, xmask)
    tmp15 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp16 = tmp13 * tmp15
    tl.store(out_ptr2 + (x0), tmp16, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/oe/coehomgjxyjxaj2v2bjmmwpbmyf7cy7bkbzxxalh2wwx7f6xcuko.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 225792
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 784) % 36
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp3 = tl.load(in_out_ptr0 + (x3), xmask)
    tmp5 = tl.load(in_ptr1 + (x3), xmask)
    tmp6 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp8 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tl.where(tmp2, tmp1, tmp3)
    tmp7 = tmp5 - tmp6
    tmp9 = 0.00015943877551020407
    tmp10 = tmp8 * tmp9
    tmp12 = tmp11 * tmp11
    tmp13 = tmp10 * tmp12
    tmp14 = tmp7 * tmp13
    tmp15 = tmp4 - tmp14
    tmp17 = tmp16 * tmp9
    tmp18 = tmp15 - tmp17
    tmp20 = tmp11 * tmp19
    tmp21 = tmp18 * tmp20
    tl.store(in_out_ptr0 + (x3), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/e6/ce6gvmpo2dknlto3rw2f2m4pwajdyuopbaudahjeduwhfc4ympx7.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_add_native_batch_norm_backward_threshold_backward_78 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[64, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32', 10: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_batch_norm_backward_threshold_backward_78', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 36
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp8 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp11 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    _tmp15 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 784
        r2 = (rindex // 784)
        tmp0 = tl.load(in_ptr0 + (r1 + (784*x0) + (28224*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + (r1 + (784*x0) + (28224*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr2 + (r1 + (784*x0) + (28224*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp10 = tl.load(in_ptr3 + (r1 + (784*x0) + (28224*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp5 = tmp3 + tmp4
        tmp6 = tl.where(tmp2, tmp1, tmp5)
        tmp7 = tl.broadcast_to(tmp6, [XBLOCK, RBLOCK])
        tmp9 = _tmp8 + tmp7
        _tmp8 = tl.where(rmask & xmask, tmp9, _tmp8)
        tmp12 = tmp10 - tmp11
        tmp13 = tmp6 * tmp12
        tmp14 = tl.broadcast_to(tmp13, [XBLOCK, RBLOCK])
        tmp16 = _tmp15 + tmp14
        _tmp15 = tl.where(rmask & xmask, tmp16, _tmp15)
    tmp8 = tl.sum(_tmp8, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp8, xmask)
    tmp15 = tl.sum(_tmp15, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp15, xmask)
    tmp17 = tl.load(in_ptr5 + (x0), xmask, eviction_policy='evict_last')
    tmp18 = tmp15 * tmp17
    tl.store(out_ptr2 + (x0), tmp18, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/dt/cdt2dvf6zrrfvhsagi6p35twyii7k6p7cqpjtzuuzhjtu26ts2hz.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_add_native_batch_norm_backward_threshold_backward_79 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_native_batch_norm_backward_threshold_backward_79', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 225792
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 784) % 36
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp3 = tl.load(in_ptr1 + (x3), xmask)
    tmp4 = tl.load(in_ptr2 + (x3), xmask)
    tmp7 = tl.load(in_ptr3 + (x3), xmask)
    tmp8 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp18 = tl.load(in_ptr7 + (x1), xmask, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp6 = tl.where(tmp2, tmp1, tmp5)
    tmp9 = tmp7 - tmp8
    tmp11 = 0.00015943877551020407
    tmp12 = tmp10 * tmp11
    tmp14 = tmp13 * tmp13
    tmp15 = tmp12 * tmp14
    tmp16 = tmp9 * tmp15
    tmp17 = tmp6 - tmp16
    tmp19 = tmp18 * tmp11
    tmp20 = tmp17 - tmp19
    tmp22 = tmp13 * tmp21
    tmp23 = tmp20 * tmp22
    tl.store(out_ptr0 + (x3), tmp23, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/4d/c4d6josiz4zc52bd64ef5ptsx6e4ffdxisksrn6j2524xzftgbfo.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_80 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_80', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
    xnumel = 225792
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp5 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp6 = tl.load(in_ptr2 + (x0), xmask)
    tmp9 = tl.load(in_ptr3 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tmp3 <= tmp1
    tmp7 = tmp5 + tmp6
    tmp8 = tl.where(tmp4, tmp1, tmp7)
    tmp10 = tmp8 + tmp9
    tmp11 = tl.where(tmp2, tmp1, tmp10)
    tl.store(in_out_ptr0 + (x0), tmp11, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/rg/crglvviamq6qakfpkkuvyoqm6irazy7dgdul72sz774jt5elnpnm.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]

triton_red_fused_native_batch_norm_backward_81 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5, 6))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_81', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 72
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 18
    x1 = (xindex // 18)
    _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    x3 = xindex
    tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    _tmp9 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + ((3136*x0) + (56448*(r2 // 3136)) + (112896*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr1 + ((3136*x0) + (56448*(r2 // 3136)) + (112896*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = _tmp2 + tmp1
        _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp6 = tmp4 - tmp5
        tmp7 = tmp0 * tmp6
        tmp8 = tl.broadcast_to(tmp7, [XBLOCK, RBLOCK])
        tmp10 = _tmp9 + tmp8
        _tmp9 = tl.where(rmask & xmask, tmp10, _tmp9)
    tmp2 = tl.sum(_tmp2, 1)[:, None]
    tl.store(out_ptr0 + (x3), tmp2, xmask)
    tmp9 = tl.sum(_tmp9, 1)[:, None]
    tl.store(out_ptr1 + (x3), tmp9, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/fp/cfpl2w3sedwiebzdtdr2cs4lzyqodicr755onwykuokwijiw64of.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]

triton_per_fused_native_batch_norm_backward_82 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[32, 4],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_82', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 18
    rnumel = 4
    RBLOCK: tl.constexpr = 4
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (18*r1)), rmask & xmask, other=0.0)
    tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.sum(tmp3, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/hu/chuvv4aei5ao7u5vk3gcnryotfw6sefsklfmnzxtpogb6nhab3cy.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]

triton_per_fused_native_batch_norm_backward_83 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[32, 4],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_83', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, out_ptr0, out_ptr1, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 18
    rnumel = 4
    RBLOCK: tl.constexpr = 4
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (18*r1)), rmask & xmask, other=0.0)
    tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.sum(tmp3, 1)[:, None]
    tmp6 = tmp4 * tmp5
    tl.store(out_ptr1 + (x0), tmp6, xmask)
    tl.store(out_ptr0 + (x0), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/tj/ctjq6y63as4cvecrs2xg3szt4ift627wmdc5pibvzj5ttjfshrir.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_84 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_84', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 18
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x3), xmask)
    tmp2 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 3.985969387755102e-05
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tl.store(out_ptr0 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/sz/cszogh6qqkn5nn4nnh4eets3q57g3d2esjgzfal5r6utcxvlhuka.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_native_batch_norm_backward_threshold_backward_85 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6, 7))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_threshold_backward_85', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 72
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 18
    x1 = (xindex // 18)
    _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    x3 = xindex
    tmp9 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    _tmp13 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + ((3136*x0) + (56448*(r2 // 3136)) + (112896*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + ((3136*x0) + (56448*(r2 // 3136)) + (112896*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp8 = tl.load(in_ptr2 + ((3136*x0) + (56448*(r2 // 3136)) + (112896*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
        tmp7 = _tmp6 + tmp5
        _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp10 = tmp8 - tmp9
        tmp11 = tmp4 * tmp10
        tmp12 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp14 = _tmp13 + tmp12
        _tmp13 = tl.where(rmask & xmask, tmp14, _tmp13)
    tmp6 = tl.sum(_tmp6, 1)[:, None]
    tl.store(out_ptr0 + (x3), tmp6, xmask)
    tmp13 = tl.sum(_tmp13, 1)[:, None]
    tl.store(out_ptr1 + (x3), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/l4/cl4dvgl3vn7hxawlzbpefroeuwxga5e4fuyaji4hlllkiarlysfj.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 18
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp3 = tl.load(in_out_ptr0 + (x3), xmask)
    tmp5 = tl.load(in_ptr1 + (x3), xmask)
    tmp6 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp8 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tl.where(tmp2, tmp1, tmp3)
    tmp7 = tmp5 - tmp6
    tmp9 = 3.985969387755102e-05
    tmp10 = tmp8 * tmp9
    tmp12 = tmp11 * tmp11
    tmp13 = tmp10 * tmp12
    tmp14 = tmp7 * tmp13
    tmp15 = tmp4 - tmp14
    tmp17 = tmp16 * tmp9
    tmp18 = tmp15 - tmp17
    tmp20 = tmp11 * tmp19
    tmp21 = tmp18 * tmp20
    tl.store(in_out_ptr0 + (x3), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/t6/ct6alnik43k2rrkmc633km4vk2jhhx2n7zpuiem3aroocqyl7clj.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_add_native_batch_norm_backward_threshold_backward_87 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7, 8))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_batch_norm_backward_threshold_backward_87', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 72
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 18
    x1 = (xindex // 18)
    _tmp8 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    x3 = xindex
    tmp11 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    _tmp15 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + ((3136*x0) + (56448*(r2 // 3136)) + (112896*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + ((3136*x0) + (56448*(r2 // 3136)) + (112896*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr2 + ((3136*x0) + (56448*(r2 // 3136)) + (112896*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp10 = tl.load(in_ptr3 + ((3136*x0) + (56448*(r2 // 3136)) + (112896*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp5 = tmp3 + tmp4
        tmp6 = tl.where(tmp2, tmp1, tmp5)
        tmp7 = tl.broadcast_to(tmp6, [XBLOCK, RBLOCK])
        tmp9 = _tmp8 + tmp7
        _tmp8 = tl.where(rmask & xmask, tmp9, _tmp8)
        tmp12 = tmp10 - tmp11
        tmp13 = tmp6 * tmp12
        tmp14 = tl.broadcast_to(tmp13, [XBLOCK, RBLOCK])
        tmp16 = _tmp15 + tmp14
        _tmp15 = tl.where(rmask & xmask, tmp16, _tmp15)
    tmp8 = tl.sum(_tmp8, 1)[:, None]
    tl.store(out_ptr0 + (x3), tmp8, xmask)
    tmp15 = tl.sum(_tmp15, 1)[:, None]
    tl.store(out_ptr1 + (x3), tmp15, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/dg/cdg3l5yinthwdoulx2cxcjfr3rkpegofvyu6zhzwtujfjtr4tjt4.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_add_native_batch_norm_backward_threshold_backward_88 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_native_batch_norm_backward_threshold_backward_88', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 18
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp3 = tl.load(in_ptr1 + (x3), xmask)
    tmp4 = tl.load(in_ptr2 + (x3), xmask)
    tmp7 = tl.load(in_ptr3 + (x3), xmask)
    tmp8 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp18 = tl.load(in_ptr7 + (x1), xmask, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp6 = tl.where(tmp2, tmp1, tmp5)
    tmp9 = tmp7 - tmp8
    tmp11 = 3.985969387755102e-05
    tmp12 = tmp10 * tmp11
    tmp14 = tmp13 * tmp13
    tmp15 = tmp12 * tmp14
    tmp16 = tmp9 * tmp15
    tmp17 = tmp6 - tmp16
    tmp19 = tmp18 * tmp11
    tmp20 = tmp17 - tmp19
    tmp22 = tmp13 * tmp21
    tmp23 = tmp20 * tmp22
    tl.store(out_ptr0 + (x3), tmp23, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/im/cimkf6oq7h6jfvx6uw5zhrru66risojfhfluq2jxf3lhupgoawhi.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_89 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_89', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp5 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp6 = tl.load(in_ptr2 + (x0), xmask)
    tmp9 = tl.load(in_ptr3 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tmp3 <= tmp1
    tmp7 = tmp5 + tmp6
    tmp8 = tl.where(tmp4, tmp1, tmp7)
    tmp10 = tmp8 + tmp9
    tmp11 = tl.where(tmp2, tmp1, tmp10)
    tl.store(in_out_ptr0 + (x0), tmp11, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ug/cugyheeezxejewciv2753swefz27mnogjkjc37rg3cgqgduosxct.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]

triton_per_fused_native_batch_norm_backward_90 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[256, 512],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: 'i32', 18: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(17, 18))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_90', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, out_ptr5, out_ptr6, xnumel, rnumel):
    xnumel = 144
    XBLOCK: tl.constexpr = 1
    rnumel = 392
    RBLOCK: tl.constexpr = 512
    xoffset = tl.program_id(0) * XBLOCK
    xindex = tl.full([1], xoffset, tl.int32)
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[:]
    rmask = rindex < rnumel
    r1 = rindex % 49
    r2 = (rindex // 49)
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp5 = tl.load(in_ptr1 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp6 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr3 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp14 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr5 + (r1 + (49*x0) + (7056*r2)), rmask & xmask, other=0.0)
    tmp22 = tl.load(in_ptr6 + (x0), xmask, eviction_policy='evict_last')
    tmp29 = tl.load(in_ptr7 + (x0), xmask, eviction_policy='evict_last')
    tmp31 = tl.load(in_ptr8 + (x0), xmask, eviction_policy='evict_last')
    tmp33 = tl.load(in_ptr9 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = triton_helpers.promote_to_tensor(tl.sum(tmp3, 0))
    tmp7 = tmp5 - tmp6
    tmp8 = tmp0 * tmp7
    tmp9 = tl.broadcast_to(tmp8, [RBLOCK])
    tmp11 = tl.where(rmask & xmask, tmp9, 0)
    tmp12 = triton_helpers.promote_to_tensor(tl.sum(tmp11, 0))
    tmp15 = tmp13 - tmp14
    tmp16 = tmp0 * tmp15
    tmp17 = tl.broadcast_to(tmp16, [RBLOCK])
    tmp19 = tl.where(rmask & xmask, tmp17, 0)
    tmp20 = triton_helpers.promote_to_tensor(tl.sum(tmp19, 0))
    tmp23 = tmp21 - tmp22
    tmp24 = tmp0 * tmp23
    tmp25 = tl.broadcast_to(tmp24, [RBLOCK])
    tmp27 = tl.where(rmask & xmask, tmp25, 0)
    tmp28 = triton_helpers.promote_to_tensor(tl.sum(tmp27, 0))
    tmp30 = tmp12 * tmp29
    tmp32 = tmp20 * tmp31
    tmp34 = tmp28 * tmp33
    tl.store(out_ptr4 + (x0), tmp30, xmask)
    tl.store(out_ptr5 + (x0), tmp32, xmask)
    tl.store(out_ptr6 + (x0), tmp34, xmask)
    tl.store(out_ptr0 + (x0), tmp4, xmask)
    tl.store(out_ptr1 + (x0), tmp12, xmask)
    tl.store(out_ptr2 + (x0), tmp20, xmask)
    tl.store(out_ptr3 + (x0), tmp28, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/h3/ch3bmm4nvm4leifgcluxjb4i45w66cyrxgqkhos7nyxgxacbcost.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_91 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: '*fp32', 18: '*fp32', 19: '*fp32', 20: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(20,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_91', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, out_ptr0, out_ptr1, out_ptr2, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 144
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x3), xmask)
    tmp2 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp18 = tl.load(in_ptr7 + (x3), xmask)
    tmp19 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr9 + (x1), xmask, eviction_policy='evict_last')
    tmp23 = tl.load(in_ptr10 + (x1), xmask, eviction_policy='evict_last')
    tmp29 = tl.load(in_ptr11 + (x1), xmask, eviction_policy='evict_last')
    tmp32 = tl.load(in_ptr12 + (x3), xmask)
    tmp33 = tl.load(in_ptr13 + (x1), xmask, eviction_policy='evict_last')
    tmp35 = tl.load(in_ptr14 + (x1), xmask, eviction_policy='evict_last')
    tmp37 = tl.load(in_ptr15 + (x1), xmask, eviction_policy='evict_last')
    tmp43 = tl.load(in_ptr16 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 0.002551020408163265
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tmp20 = tmp18 - tmp19
    tmp22 = tmp21 * tmp5
    tmp24 = tmp23 * tmp23
    tmp25 = tmp22 * tmp24
    tmp26 = tmp20 * tmp25
    tmp27 = tmp0 - tmp26
    tmp28 = tmp27 - tmp13
    tmp30 = tmp23 * tmp29
    tmp31 = tmp28 * tmp30
    tmp34 = tmp32 - tmp33
    tmp36 = tmp35 * tmp5
    tmp38 = tmp37 * tmp37
    tmp39 = tmp36 * tmp38
    tmp40 = tmp34 * tmp39
    tmp41 = tmp0 - tmp40
    tmp42 = tmp41 - tmp13
    tmp44 = tmp37 * tmp43
    tmp45 = tmp42 * tmp44
    tl.store(out_ptr0 + (x3), tmp17, xmask)
    tl.store(out_ptr1 + (x3), tmp31, xmask)
    tl.store(out_ptr2 + (x3), tmp45, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/bp/cbpxj67b22as6vxbc4ic7jj7ga323kqkl42aehlwul7f2drfafwl.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_92 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_92', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_out_ptr1, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp5 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp6 = tl.load(in_ptr2 + (x0), xmask)
    tmp9 = tl.load(in_ptr3 + (x0), xmask)
    tmp12 = tl.load(in_ptr4 + (x0), xmask)
    tmp14 = tl.load(in_out_ptr1 + (x0), xmask)
    tmp15 = tl.load(in_ptr5 + (x0), xmask)
    tmp17 = tl.load(in_ptr6 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tmp3 <= tmp1
    tmp7 = tmp5 + tmp6
    tmp8 = tl.where(tmp4, tmp1, tmp7)
    tmp10 = tmp8 + tmp9
    tmp11 = tl.where(tmp2, tmp1, tmp10)
    tmp13 = tmp12 <= tmp1
    tmp16 = tmp14 + tmp15
    tmp18 = tmp16 + tmp17
    tmp19 = tmp18 + tmp11
    tmp20 = tl.where(tmp13, tmp1, tmp19)
    tl.store(in_out_ptr0 + (x0), tmp11, xmask)
    tl.store(in_out_ptr1 + (x0), tmp20, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/3h/c3h57kprsy7xbqv55xn7fgvcuazf5fhg7dosif3yivibm5r4kk75.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_93 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_93', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp4 = tl.load(in_ptr1 + (x0), xmask)
    tmp6 = tl.load(in_ptr2 + (x0), xmask)
    tmp8 = tl.load(in_ptr3 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp7 = tmp5 + tmp6
    tmp9 = tmp7 + tmp8
    tmp10 = tl.where(tmp2, tmp1, tmp9)
    tl.store(in_out_ptr0 + (x0), tmp10, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ci/ccitbzew24vbpewq7lihawtpcrouatc3j7pjcit6knbu4e4ehjfn.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_94 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_94', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_out_ptr1, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp5 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp6 = tl.load(in_ptr2 + (x0), xmask)
    tmp9 = tl.load(in_ptr3 + (x0), xmask)
    tmp12 = tl.load(in_ptr4 + (x0), xmask)
    tmp14 = tl.load(in_ptr5 + (x0), xmask)
    tmp15 = tl.load(in_ptr6 + (x0), xmask)
    tmp17 = tl.load(in_out_ptr1 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tmp3 <= tmp1
    tmp7 = tmp5 + tmp6
    tmp8 = tl.where(tmp4, tmp1, tmp7)
    tmp10 = tmp8 + tmp9
    tmp11 = tl.where(tmp2, tmp1, tmp10)
    tmp13 = tmp12 <= tmp1
    tmp16 = tmp14 + tmp15
    tmp18 = tmp16 + tmp17
    tmp19 = tmp18 + tmp11
    tmp20 = tl.where(tmp13, tmp1, tmp19)
    tl.store(in_out_ptr0 + (x0), tmp11, xmask)
    tl.store(in_out_ptr1 + (x0), tmp20, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/bm/cbmqsr5wz6libmhqoimpuk5vh7r46jlurmmluanifhaczj7eome7.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_95 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_95', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp4 = tl.load(in_ptr2 + (x0), xmask)
    tmp6 = tl.load(in_ptr3 + (x0), xmask)
    tmp8 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp7 = tmp5 + tmp6
    tmp9 = tmp7 + tmp8
    tmp10 = tl.where(tmp2, tmp1, tmp9)
    tl.store(in_out_ptr0 + (x0), tmp10, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ci/cciqdqfh6eoh3k2anapnxfizyzdfnsiug2d4wivtcsqwwuausmtv.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_96 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_96', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp4 = tl.load(in_ptr2 + (x0), xmask)
    tmp6 = tl.load(in_ptr3 + (x0), xmask)
    tmp8 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp7 = tmp5 + tmp6
    tmp9 = tmp7 + tmp8
    tmp10 = tl.where(tmp2, tmp1, tmp9)
    tl.store(in_out_ptr0 + (x0), tmp10, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/jy/cjylwz5wkdlpn53anuc4ehdq3oia727g272imcmngwjmbkidcjbb.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_97 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_97', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
    xnumel = 225792
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp4 = tl.load(in_ptr2 + (x0), xmask)
    tmp6 = tl.load(in_ptr3 + (x0), xmask)
    tmp8 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp7 = tmp5 + tmp6
    tmp9 = tmp7 + tmp8
    tmp10 = tl.where(tmp2, tmp1, tmp9)
    tl.store(in_out_ptr0 + (x0), tmp10, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/zn/czn4m6o5k7l4uevxhqbfxt2rz3eofpn7gbans3tievrzbcdbb7ux.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_98 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[65536], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_98', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, xnumel, XBLOCK : tl.constexpr):
    xnumel = 56448
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 49) % 144
    tmp0 = tl.load(in_out_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr0 + (x3), xmask)
    tmp2 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 0.002551020408163265
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tl.store(in_out_ptr0 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/oa/coaqz5bkls2qtmf4ar3e35i5g3gzv3gpzbyrmrp3j274ygszior4.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_99 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_99', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp5 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp6 = tl.load(in_ptr2 + (x0), xmask)
    tmp9 = tl.load(in_ptr3 + (x0), xmask)
    tmp11 = tl.load(in_ptr4 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tmp3 <= tmp1
    tmp7 = tmp5 + tmp6
    tmp8 = tl.where(tmp4, tmp1, tmp7)
    tmp10 = tmp8 + tmp9
    tmp12 = tmp10 + tmp11
    tmp13 = tl.where(tmp2, tmp1, tmp12)
    tl.store(in_out_ptr0 + (x0), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/xj/cxjwag6664dmf7rnxqo6mjqxlncns52mbui5kawynsn4dvj3as6r.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_add_native_batch_norm_backward_threshold_backward_100 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: '*fp32', 18: '*fp32', 19: '*fp32', 20: '*fp32', 21: 'i32', 22: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(21, 22))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_batch_norm_backward_threshold_backward_100', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, out_ptr5, out_ptr6, out_ptr7, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 72
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    _tmp9 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    _tmp16 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    _tmp27 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp30 = tl.load(in_ptr9 + (x0), xmask, eviction_policy='evict_last')
    _tmp34 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr1 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp11 = tl.load(in_ptr3 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp18 = tl.load(in_ptr5 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp21 = tl.load(in_ptr6 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp23 = tl.load(in_ptr7 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp29 = tl.load(in_ptr8 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = _tmp2 + tmp1
        _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp6 = tmp4 - tmp5
        tmp7 = tmp0 * tmp6
        tmp8 = tl.broadcast_to(tmp7, [XBLOCK, RBLOCK])
        tmp10 = _tmp9 + tmp8
        _tmp9 = tl.where(rmask & xmask, tmp10, _tmp9)
        tmp13 = tmp11 - tmp12
        tmp14 = tmp0 * tmp13
        tmp15 = tl.broadcast_to(tmp14, [XBLOCK, RBLOCK])
        tmp17 = _tmp16 + tmp15
        _tmp16 = tl.where(rmask & xmask, tmp17, _tmp16)
        tmp19 = 0.0
        tmp20 = tmp18 <= tmp19
        tmp22 = tmp0 + tmp21
        tmp24 = tmp22 + tmp23
        tmp25 = tl.where(tmp20, tmp19, tmp24)
        tmp26 = tl.broadcast_to(tmp25, [XBLOCK, RBLOCK])
        tmp28 = _tmp27 + tmp26
        _tmp27 = tl.where(rmask & xmask, tmp28, _tmp27)
        tmp31 = tmp29 - tmp30
        tmp32 = tmp25 * tmp31
        tmp33 = tl.broadcast_to(tmp32, [XBLOCK, RBLOCK])
        tmp35 = _tmp34 + tmp33
        _tmp34 = tl.where(rmask & xmask, tmp35, _tmp34)
    tmp2 = tl.sum(_tmp2, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tmp9 = tl.sum(_tmp9, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp9, xmask)
    tmp16 = tl.sum(_tmp16, 1)[:, None]
    tl.store(out_ptr2 + (x0), tmp16, xmask)
    tmp27 = tl.sum(_tmp27, 1)[:, None]
    tl.store(out_ptr3 + (x0), tmp27, xmask)
    tmp34 = tl.sum(_tmp34, 1)[:, None]
    tl.store(out_ptr4 + (x0), tmp34, xmask)
    tmp36 = tl.load(in_ptr10 + (x0), xmask, eviction_policy='evict_last')
    tmp38 = tl.load(in_ptr11 + (x0), xmask, eviction_policy='evict_last')
    tmp40 = tl.load(in_ptr12 + (x0), xmask, eviction_policy='evict_last')
    tmp37 = tmp9 * tmp36
    tmp39 = tmp16 * tmp38
    tmp41 = tmp34 * tmp40
    tl.store(out_ptr5 + (x0), tmp37, xmask)
    tl.store(out_ptr6 + (x0), tmp39, xmask)
    tl.store(out_ptr7 + (x0), tmp41, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/li/clixjebxcokjpdm2sciglxahp2gyv6pe3xtsd4ms6a45446cn2p2.py
# Source Nodes: [], Original ATen: [aten.add, aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_101 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: '*fp32', 18: '*fp32', 19: '*fp32', 20: '*fp32', 21: '*fp32', 22: '*fp32', 23: '*fp32', 24: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(24,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_101', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, in_ptr20, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 72
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x3), xmask)
    tmp2 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp18 = tl.load(in_ptr7 + (x3), xmask)
    tmp19 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr9 + (x1), xmask, eviction_policy='evict_last')
    tmp23 = tl.load(in_ptr10 + (x1), xmask, eviction_policy='evict_last')
    tmp29 = tl.load(in_ptr11 + (x1), xmask, eviction_policy='evict_last')
    tmp32 = tl.load(in_ptr12 + (x3), xmask)
    tmp35 = tl.load(in_ptr13 + (x3), xmask)
    tmp37 = tl.load(in_ptr14 + (x3), xmask)
    tmp40 = tl.load(in_ptr15 + (x3), xmask)
    tmp41 = tl.load(in_ptr16 + (x1), xmask, eviction_policy='evict_last')
    tmp43 = tl.load(in_ptr17 + (x1), xmask, eviction_policy='evict_last')
    tmp45 = tl.load(in_ptr18 + (x1), xmask, eviction_policy='evict_last')
    tmp50 = tl.load(in_ptr19 + (x1), xmask, eviction_policy='evict_last')
    tmp53 = tl.load(in_ptr20 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 0.0006377551020408163
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tmp20 = tmp18 - tmp19
    tmp22 = tmp21 * tmp5
    tmp24 = tmp23 * tmp23
    tmp25 = tmp22 * tmp24
    tmp26 = tmp20 * tmp25
    tmp27 = tmp0 - tmp26
    tmp28 = tmp27 - tmp13
    tmp30 = tmp23 * tmp29
    tmp31 = tmp28 * tmp30
    tmp33 = 0.0
    tmp34 = tmp32 <= tmp33
    tmp36 = tmp0 + tmp35
    tmp38 = tmp36 + tmp37
    tmp39 = tl.where(tmp34, tmp33, tmp38)
    tmp42 = tmp40 - tmp41
    tmp44 = tmp43 * tmp5
    tmp46 = tmp45 * tmp45
    tmp47 = tmp44 * tmp46
    tmp48 = tmp42 * tmp47
    tmp49 = tmp39 - tmp48
    tmp51 = tmp50 * tmp5
    tmp52 = tmp49 - tmp51
    tmp54 = tmp45 * tmp53
    tmp55 = tmp52 * tmp54
    tl.store(out_ptr0 + (x3), tmp17, xmask)
    tl.store(out_ptr1 + (x3), tmp31, xmask)
    tl.store(in_out_ptr0 + (x3), tmp55, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/fy/cfyfjf3hxbsyud64lob6ddzxt3uwhrevujn5z2ijujtr3y7iwpox.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_102 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_102', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp5 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp6 = tl.load(in_ptr2 + (x0), xmask)
    tmp8 = tl.load(in_ptr3 + (x0), xmask)
    tmp11 = tl.load(in_ptr4 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tmp3 <= tmp1
    tmp7 = tmp5 + tmp6
    tmp9 = tmp7 + tmp8
    tmp10 = tl.where(tmp4, tmp1, tmp9)
    tmp12 = tmp10 + tmp11
    tmp13 = tl.where(tmp2, tmp1, tmp12)
    tl.store(in_out_ptr0 + (x0), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ti/ctiynymlac7aj4qlxyqfzwmek2rmqocvzrc4l7j2jy7a2kduw6hx.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_add_native_batch_norm_backward_threshold_backward_103 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[64, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_batch_norm_backward_threshold_backward_103', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 36
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp10 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp13 = tl.load(in_ptr5 + (x0), xmask, eviction_policy='evict_last')
    _tmp17 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 784
        r2 = (rindex // 784)
        tmp0 = tl.load(in_ptr0 + (r1 + (784*x0) + (28224*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + (r1 + (784*x0) + (28224*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr2 + (r1 + (784*x0) + (28224*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp6 = tl.load(in_ptr3 + (r1 + (784*x0) + (28224*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp12 = tl.load(in_ptr4 + (r1 + (784*x0) + (28224*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp5 = tmp3 + tmp4
        tmp7 = tmp5 + tmp6
        tmp8 = tl.where(tmp2, tmp1, tmp7)
        tmp9 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
        tmp11 = _tmp10 + tmp9
        _tmp10 = tl.where(rmask & xmask, tmp11, _tmp10)
        tmp14 = tmp12 - tmp13
        tmp15 = tmp8 * tmp14
        tmp16 = tl.broadcast_to(tmp15, [XBLOCK, RBLOCK])
        tmp18 = _tmp17 + tmp16
        _tmp17 = tl.where(rmask & xmask, tmp18, _tmp17)
    tmp10 = tl.sum(_tmp10, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp10, xmask)
    tmp17 = tl.sum(_tmp17, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp17, xmask)
    tmp19 = tl.load(in_ptr6 + (x0), xmask, eviction_policy='evict_last')
    tmp20 = tmp17 * tmp19
    tl.store(out_ptr2 + (x0), tmp20, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/25/c25yfcy5qiec25trrnmfroot576z2rzzntuhg7zwei6rb7zdmwqc.py
# Source Nodes: [], Original ATen: [aten.add, aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_104 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_104', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, xnumel, XBLOCK : tl.constexpr):
    xnumel = 225792
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 784) % 36
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp3 = tl.load(in_ptr1 + (x3), xmask)
    tmp4 = tl.load(in_ptr2 + (x3), xmask)
    tmp6 = tl.load(in_ptr3 + (x3), xmask)
    tmp9 = tl.load(in_ptr4 + (x3), xmask)
    tmp10 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr7 + (x1), xmask, eviction_policy='evict_last')
    tmp20 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp23 = tl.load(in_ptr9 + (x1), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp7 = tmp5 + tmp6
    tmp8 = tl.where(tmp2, tmp1, tmp7)
    tmp11 = tmp9 - tmp10
    tmp13 = 0.00015943877551020407
    tmp14 = tmp12 * tmp13
    tmp16 = tmp15 * tmp15
    tmp17 = tmp14 * tmp16
    tmp18 = tmp11 * tmp17
    tmp19 = tmp8 - tmp18
    tmp21 = tmp20 * tmp13
    tmp22 = tmp19 - tmp21
    tmp24 = tmp15 * tmp23
    tmp25 = tmp22 * tmp24
    tl.store(in_out_ptr0 + (x3), tmp25, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/et/cet3jopju3nopwudm2in7ymci5hry6xwm3fcnvsowswgb4t6vuak.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_105 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_105', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, xnumel, XBLOCK : tl.constexpr):
    xnumel = 225792
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp5 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp6 = tl.load(in_ptr2 + (x0), xmask)
    tmp8 = tl.load(in_ptr3 + (x0), xmask)
    tmp11 = tl.load(in_ptr4 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tmp3 <= tmp1
    tmp7 = tmp5 + tmp6
    tmp9 = tmp7 + tmp8
    tmp10 = tl.where(tmp4, tmp1, tmp9)
    tmp12 = tmp10 + tmp11
    tmp13 = tl.where(tmp2, tmp1, tmp12)
    tl.store(in_out_ptr0 + (x0), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/k4/ck4q4zx33lxtl4jqaizke35dtxk77unggmguwtceovl2vcginj4m.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_add_native_batch_norm_backward_threshold_backward_106 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_batch_norm_backward_threshold_backward_106', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, out_ptr1, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 72
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 18
    x1 = (xindex // 18)
    _tmp10 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    x3 = xindex
    tmp13 = tl.load(in_ptr5 + (x0), xmask, eviction_policy='evict_last')
    _tmp17 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + ((3136*x0) + (56448*(r2 // 3136)) + (112896*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + ((3136*x0) + (56448*(r2 // 3136)) + (112896*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr2 + ((3136*x0) + (56448*(r2 // 3136)) + (112896*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp6 = tl.load(in_ptr3 + ((3136*x0) + (56448*(r2 // 3136)) + (112896*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp12 = tl.load(in_ptr4 + ((3136*x0) + (56448*(r2 // 3136)) + (112896*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp5 = tmp3 + tmp4
        tmp7 = tmp5 + tmp6
        tmp8 = tl.where(tmp2, tmp1, tmp7)
        tmp9 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
        tmp11 = _tmp10 + tmp9
        _tmp10 = tl.where(rmask & xmask, tmp11, _tmp10)
        tmp14 = tmp12 - tmp13
        tmp15 = tmp8 * tmp14
        tmp16 = tl.broadcast_to(tmp15, [XBLOCK, RBLOCK])
        tmp18 = _tmp17 + tmp16
        _tmp17 = tl.where(rmask & xmask, tmp18, _tmp17)
    tmp10 = tl.sum(_tmp10, 1)[:, None]
    tl.store(out_ptr0 + (x3), tmp10, xmask)
    tmp17 = tl.sum(_tmp17, 1)[:, None]
    tl.store(out_ptr1 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/j4/cj467jtfiftjlhocderudebav44eoyaeztaf4kmb2krjzip4myzo.py
# Source Nodes: [], Original ATen: [aten.add, aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_107 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_107', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 18
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp3 = tl.load(in_ptr1 + (x3), xmask)
    tmp4 = tl.load(in_ptr2 + (x3), xmask)
    tmp6 = tl.load(in_ptr3 + (x3), xmask)
    tmp9 = tl.load(in_ptr4 + (x3), xmask)
    tmp10 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr7 + (x1), xmask, eviction_policy='evict_last')
    tmp20 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp23 = tl.load(in_ptr9 + (x1), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp7 = tmp5 + tmp6
    tmp8 = tl.where(tmp2, tmp1, tmp7)
    tmp11 = tmp9 - tmp10
    tmp13 = 3.985969387755102e-05
    tmp14 = tmp12 * tmp13
    tmp16 = tmp15 * tmp15
    tmp17 = tmp14 * tmp16
    tmp18 = tmp11 * tmp17
    tmp19 = tmp8 - tmp18
    tmp21 = tmp20 * tmp13
    tmp22 = tmp19 - tmp21
    tmp24 = tmp15 * tmp23
    tmp25 = tmp22 * tmp24
    tl.store(in_out_ptr0 + (x3), tmp25, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/4t/c4t3z5bxlyciahfycrfvwt7hyk4uwudlcxkteomeon6iqjfpoza5.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_108 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_108', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp5 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp6 = tl.load(in_ptr2 + (x0), xmask)
    tmp8 = tl.load(in_ptr3 + (x0), xmask)
    tmp11 = tl.load(in_ptr4 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tmp3 <= tmp1
    tmp7 = tmp5 + tmp6
    tmp9 = tmp7 + tmp8
    tmp10 = tl.where(tmp4, tmp1, tmp9)
    tmp12 = tmp10 + tmp11
    tmp13 = tl.where(tmp2, tmp1, tmp12)
    tl.store(in_out_ptr0 + (x0), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/3h/c3hbv7nqamnlkwjcer5drksp22ggaxl2dmygo5ps454fik3xe2x7.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_add_native_batch_norm_backward_threshold_backward_109 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[128, 2048],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: 'i32', 15: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(14, 15))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_batch_norm_backward_threshold_backward_109', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 72
    rnumel = 1568
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp8 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp11 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    _tmp15 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp18 = tl.load(in_ptr6 + (x0), xmask, eviction_policy='evict_last')
    _tmp22 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 196
        r2 = (rindex // 196)
        tmp0 = tl.load(in_ptr0 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr2 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp10 = tl.load(in_ptr3 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp17 = tl.load(in_ptr5 + (r1 + (196*x0) + (14112*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp5 = tmp3 + tmp4
        tmp6 = tl.where(tmp2, tmp1, tmp5)
        tmp7 = tl.broadcast_to(tmp6, [XBLOCK, RBLOCK])
        tmp9 = _tmp8 + tmp7
        _tmp8 = tl.where(rmask & xmask, tmp9, _tmp8)
        tmp12 = tmp10 - tmp11
        tmp13 = tmp6 * tmp12
        tmp14 = tl.broadcast_to(tmp13, [XBLOCK, RBLOCK])
        tmp16 = _tmp15 + tmp14
        _tmp15 = tl.where(rmask & xmask, tmp16, _tmp15)
        tmp19 = tmp17 - tmp18
        tmp20 = tmp6 * tmp19
        tmp21 = tl.broadcast_to(tmp20, [XBLOCK, RBLOCK])
        tmp23 = _tmp22 + tmp21
        _tmp22 = tl.where(rmask & xmask, tmp23, _tmp22)
    tmp8 = tl.sum(_tmp8, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp8, xmask)
    tmp15 = tl.sum(_tmp15, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp15, xmask)
    tmp22 = tl.sum(_tmp22, 1)[:, None]
    tl.store(out_ptr2 + (x0), tmp22, xmask)
    tmp24 = tl.load(in_ptr7 + (x0), xmask, eviction_policy='evict_last')
    tmp26 = tl.load(in_ptr8 + (x0), xmask, eviction_policy='evict_last')
    tmp25 = tmp15 * tmp24
    tmp27 = tmp22 * tmp26
    tl.store(out_ptr3 + (x0), tmp25, xmask)
    tl.store(out_ptr4 + (x0), tmp27, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/wo/cwottxj3q5lm7cxvv4uxextekcrlhghvdaf2iy72s4mejbhfzsil.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_110 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_110', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 225792
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp4 = tl.load(in_ptr1 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp6 = tl.where(tmp2, tmp1, tmp5)
    tl.store(in_out_ptr0 + (x0), tmp6, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/al/caltafa4gacpdtgqlxptytp7rabrmtuu4ksbhzwwlz4ph46taboj.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_111 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_111', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp4 = tl.load(in_ptr1 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp6 = tl.where(tmp2, tmp1, tmp5)
    tl.store(in_out_ptr0 + (x0), tmp6, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/zq/czqhvciuc4a7ajc3xq34yrugnza5rfy2fzp2d3fo5qch44qrwkee.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_add_native_batch_norm_backward_threshold_backward_112 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: '*fp32', 15: '*fp32', 16: '*fp32', 17: '*fp32', 18: '*fp32', 19: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(19,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_native_batch_norm_backward_threshold_backward_112', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 72
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp3 = tl.load(in_ptr1 + (x3), xmask)
    tmp4 = tl.load(in_ptr2 + (x3), xmask)
    tmp7 = tl.load(in_ptr3 + (x3), xmask)
    tmp8 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp18 = tl.load(in_ptr7 + (x1), xmask, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp24 = tl.load(in_ptr9 + (x3), xmask)
    tmp25 = tl.load(in_ptr10 + (x1), xmask, eviction_policy='evict_last')
    tmp27 = tl.load(in_ptr11 + (x1), xmask, eviction_policy='evict_last')
    tmp29 = tl.load(in_ptr12 + (x1), xmask, eviction_policy='evict_last')
    tmp35 = tl.load(in_ptr13 + (x1), xmask, eviction_policy='evict_last')
    tmp38 = tl.load(in_ptr14 + (x3), xmask)
    tmp40 = tl.load(in_out_ptr0 + (x3), xmask)
    tmp42 = tl.load(in_ptr15 + (x3), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp6 = tl.where(tmp2, tmp1, tmp5)
    tmp9 = tmp7 - tmp8
    tmp11 = 0.0006377551020408163
    tmp12 = tmp10 * tmp11
    tmp14 = tmp13 * tmp13
    tmp15 = tmp12 * tmp14
    tmp16 = tmp9 * tmp15
    tmp17 = tmp6 - tmp16
    tmp19 = tmp18 * tmp11
    tmp20 = tmp17 - tmp19
    tmp22 = tmp13 * tmp21
    tmp23 = tmp20 * tmp22
    tmp26 = tmp24 - tmp25
    tmp28 = tmp27 * tmp11
    tmp30 = tmp29 * tmp29
    tmp31 = tmp28 * tmp30
    tmp32 = tmp26 * tmp31
    tmp33 = tmp6 - tmp32
    tmp34 = tmp33 - tmp19
    tmp36 = tmp29 * tmp35
    tmp37 = tmp34 * tmp36
    tmp39 = tmp38 <= tmp1
    tmp41 = tmp6 + tmp40
    tmp43 = tmp41 + tmp42
    tmp44 = tl.where(tmp39, tmp1, tmp43)
    tl.store(out_ptr0 + (x3), tmp23, xmask)
    tl.store(out_ptr1 + (x3), tmp37, xmask)
    tl.store(in_out_ptr0 + (x3), tmp44, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/xi/cxiyxhwq3vuhtyxtkqzzvr4mfjngicnvmorpj6p3wv57rgqmjckd.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_113 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[131072], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_113', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, xnumel, XBLOCK : tl.constexpr):
    xnumel = 112896
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 196) % 72
    tmp0 = tl.load(in_out_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr0 + (x3), xmask)
    tmp2 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 0.0006377551020408163
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tl.store(in_out_ptr0 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/2b/c2bnp3cdfa5jib62okiuyo5auif2l2nv3jmiurhuobvnyistiqqt.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_114 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_114', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp4 = tl.load(in_ptr2 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp6 = tl.where(tmp2, tmp1, tmp5)
    tl.store(out_ptr0 + (x0), tmp6, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/lt/cltni3s5wuwh3o3vjeefht7c66xdqtvpmcnkpnookfnbggd2ikaw.py
# Source Nodes: [], Original ATen: [aten.add, aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_115 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(13,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_115', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_out_ptr1, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, xnumel, XBLOCK : tl.constexpr):
    xnumel = 225792
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 784) % 36
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp3 = tl.load(in_ptr1 + (x3), xmask)
    tmp4 = tl.load(in_ptr2 + (x3), xmask)
    tmp6 = tl.load(in_ptr3 + (x3), xmask)
    tmp9 = tl.load(in_ptr4 + (x3), xmask)
    tmp10 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr7 + (x1), xmask, eviction_policy='evict_last')
    tmp20 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
    tmp23 = tl.load(in_ptr9 + (x3), xmask)
    tmp25 = tl.load(in_out_ptr0 + (x3), xmask)
    tmp28 = tl.load(in_ptr10 + (x1), xmask, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp7 = tmp5 + tmp6
    tmp8 = tl.where(tmp2, tmp1, tmp7)
    tmp11 = tmp9 - tmp10
    tmp13 = 0.00015943877551020407
    tmp14 = tmp12 * tmp13
    tmp16 = tmp15 * tmp15
    tmp17 = tmp14 * tmp16
    tmp18 = tmp11 * tmp17
    tmp19 = tmp8 - tmp18
    tmp21 = tmp20 * tmp13
    tmp22 = tmp19 - tmp21
    tmp24 = tmp23 <= tmp1
    tmp26 = tmp8 + tmp25
    tmp27 = tl.where(tmp24, tmp1, tmp26)
    tmp29 = tmp15 * tmp28
    tmp30 = tmp22 * tmp29
    tl.store(in_out_ptr0 + (x3), tmp27, xmask)
    tl.store(in_out_ptr1 + (x3), tmp30, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/36/c36xge7ztt6gxudovfsjzov23wfrzdfyrnzteqbhlurwjq2irtpc.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_116 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_116', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp3 = tl.load(in_ptr1 + (x0), xmask)
    tmp4 = tl.load(in_ptr2 + (x0), xmask)
    tmp6 = tl.load(in_out_ptr0 + (x0), xmask)
    tmp7 = tl.load(in_ptr3 + (x0), xmask)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp4 <= tmp1
    tmp8 = tmp6 + tmp7
    tmp9 = tl.where(tmp5, tmp1, tmp8)
    tmp10 = tmp3 + tmp9
    tmp11 = tl.where(tmp2, tmp1, tmp10)
    tl.store(in_out_ptr0 + (x0), tmp11, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/hu/chuoh6mg7q7qcfaxldakclnxfs7ijjsh7fr5tgvjiox64wa3eida.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_117 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[262144], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_117', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, xnumel, XBLOCK : tl.constexpr):
    xnumel = 225792
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 784) % 36
    tmp0 = tl.load(in_out_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr0 + (x3), xmask)
    tmp2 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 0.00015943877551020407
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tl.store(in_out_ptr0 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/7a/c7ajrwdl3bplbktn2a5nyt7trpirohbxj5ncuc5zk7xel2pjmbc7.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_118 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[524288], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_118', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, xnumel, XBLOCK : tl.constexpr):
    xnumel = 451584
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 18
    tmp0 = tl.load(in_out_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr0 + (x3), xmask)
    tmp2 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 3.985969387755102e-05
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tl.store(in_out_ptr0 + (x3), tmp17, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/hh/chhmbcr7sihlqx7u7prgarm36mdj5exkdgkjlepsv2jzywltqlo7.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_add_native_batch_norm_backward_threshold_backward_119 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[256, 32768],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32', 10: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9, 10))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_batch_norm_backward_threshold_backward_119', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 256
    rnumel = 25088
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp8 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp11 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    _tmp15 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 3136
        r2 = (rindex // 3136)
        tmp0 = tl.load(in_ptr0 + (r1 + (3136*x0) + (802816*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + (r1 + (3136*x0) + (802816*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr2 + (r1 + (3136*x0) + (802816*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp10 = tl.load(in_ptr3 + (r1 + (3136*x0) + (802816*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp5 = tmp3 + tmp4
        tmp6 = tl.where(tmp2, tmp1, tmp5)
        tmp7 = tl.broadcast_to(tmp6, [XBLOCK, RBLOCK])
        tmp9 = _tmp8 + tmp7
        _tmp8 = tl.where(rmask & xmask, tmp9, _tmp8)
        tmp12 = tmp10 - tmp11
        tmp13 = tmp6 * tmp12
        tmp14 = tl.broadcast_to(tmp13, [XBLOCK, RBLOCK])
        tmp16 = _tmp15 + tmp14
        _tmp15 = tl.where(rmask & xmask, tmp16, _tmp15)
    tmp8 = tl.sum(_tmp8, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp8, xmask)
    tmp15 = tl.sum(_tmp15, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp15, xmask)
    tmp17 = tl.load(in_ptr5 + (x0), xmask, eviction_policy='evict_last')
    tmp18 = tmp15 * tmp17
    tl.store(out_ptr2 + (x0), tmp18, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/ms/cmsb447v3bwiy36txj7f2tplvrjro56fbkrznobukqvsljur3kgi.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_add_native_batch_norm_backward_threshold_backward_120 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_native_batch_norm_backward_threshold_backward_120', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6422528
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 256
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp3 = tl.load(in_ptr1 + (x3), None)
    tmp4 = tl.load(in_ptr2 + (x3), None)
    tmp7 = tl.load(in_ptr3 + (x3), None)
    tmp8 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr5 + (x1), None, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp18 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr8 + (x1), None, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp6 = tl.where(tmp2, tmp1, tmp5)
    tmp9 = tmp7 - tmp8
    tmp11 = 3.985969387755102e-05
    tmp12 = tmp10 * tmp11
    tmp14 = tmp13 * tmp13
    tmp15 = tmp12 * tmp14
    tmp16 = tmp9 * tmp15
    tmp17 = tmp6 - tmp16
    tmp19 = tmp18 * tmp11
    tmp20 = tmp17 - tmp19
    tmp22 = tmp13 * tmp21
    tmp23 = tmp20 * tmp22
    tl.store(out_ptr0 + (x3), tmp23, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/tp/ctpdlzospyk3oq22oafzztr2mq64kf3uyiijlzxdo6aj4b652f2k.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_native_batch_norm_backward_threshold_backward_121 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[256, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6, 7))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_threshold_backward_121', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 256
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 64
    x1 = (xindex // 64)
    _tmp6 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    x3 = xindex
    tmp9 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    _tmp13 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + ((3136*x0) + (200704*(r2 // 3136)) + (401408*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + ((3136*x0) + (200704*(r2 // 3136)) + (401408*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp8 = tl.load(in_ptr2 + ((3136*x0) + (200704*(r2 // 3136)) + (401408*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp4 = tl.where(tmp2, tmp1, tmp3)
        tmp5 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
        tmp7 = _tmp6 + tmp5
        _tmp6 = tl.where(rmask & xmask, tmp7, _tmp6)
        tmp10 = tmp8 - tmp9
        tmp11 = tmp4 * tmp10
        tmp12 = tl.broadcast_to(tmp11, [XBLOCK, RBLOCK])
        tmp14 = _tmp13 + tmp12
        _tmp13 = tl.where(rmask & xmask, tmp14, _tmp13)
    tmp6 = tl.sum(_tmp6, 1)[:, None]
    tl.store(out_ptr0 + (x3), tmp6, xmask)
    tmp13 = tl.sum(_tmp13, 1)[:, None]
    tl.store(out_ptr1 + (x3), tmp13, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/wv/cwv53onizogt7324ahaqz5opdm7mgihjqxv7tdqd5vkew7iyza6c.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_per_fused_native_batch_norm_backward_threshold_backward_122 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[64, 4],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_threshold_backward_122', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 64
    rnumel = 4
    RBLOCK: tl.constexpr = 4
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
    tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.sum(tmp3, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/hn/chnsqbsl4m67x5jbiqtislfktiellh23t4txxc5tafe2ffawabnf.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_per_fused_native_batch_norm_backward_threshold_backward_123 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[64, 4],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_threshold_backward_123', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, out_ptr0, out_ptr1, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 64
    rnumel = 4
    RBLOCK: tl.constexpr = 4
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0.0)
    tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.sum(tmp3, 1)[:, None]
    tmp6 = tmp4 * tmp5
    tl.store(out_ptr1 + (x0), tmp6, xmask)
    tl.store(out_ptr0 + (x0), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/4u/c4ujbgmrrhho7ksertrfdiutlx7hp3kbni6o75lsuqmsfqdarv36.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_124 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2097152], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_124', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 1605632
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 64
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp3 = tl.load(in_out_ptr0 + (x3), None)
    tmp5 = tl.load(in_ptr1 + (x3), None)
    tmp6 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp8 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr5 + (x1), None, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tl.where(tmp2, tmp1, tmp3)
    tmp7 = tmp5 - tmp6
    tmp9 = 3.985969387755102e-05
    tmp10 = tmp8 * tmp9
    tmp12 = tmp11 * tmp11
    tmp13 = tmp10 * tmp12
    tmp14 = tmp7 * tmp13
    tmp15 = tmp4 - tmp14
    tmp17 = tmp16 * tmp9
    tmp18 = tmp15 - tmp17
    tmp20 = tmp11 * tmp19
    tmp21 = tmp18 * tmp20
    tl.store(in_out_ptr0 + (x3), tmp21, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/4h/c4holjcyw2vryixoddt43uhajxpkvwrtf4vjxd2zu3ximktu6efq.py
# Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]

triton_poi_fused_add_threshold_backward_125 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(5,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_threshold_backward_125', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6422528
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), None)
    tmp3 = tl.load(in_ptr1 + (x0), None)
    tmp5 = tl.load(in_out_ptr0 + (x0), None)
    tmp6 = tl.load(in_ptr2 + (x0), None)
    tmp9 = tl.load(in_ptr3 + (x0), None)
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tmp3 <= tmp1
    tmp7 = tmp5 + tmp6
    tmp8 = tl.where(tmp4, tmp1, tmp7)
    tmp10 = tmp8 + tmp9
    tmp11 = tl.where(tmp2, tmp1, tmp10)
    tl.store(in_out_ptr0 + (x0), tmp11, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/ag/cagnzyskuvdxmmgb7gjtgbh7jjfo2rpcbhwhejmdgpw3z6iv23jq.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]

triton_red_fused_native_batch_norm_backward_126 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[256, 32768],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7, 8))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_126', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 256
    rnumel = 25088
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    _tmp9 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 3136
        r2 = (rindex // 3136)
        tmp0 = tl.load(in_ptr0 + (r1 + (3136*x0) + (802816*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr1 + (r1 + (3136*x0) + (802816*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = _tmp2 + tmp1
        _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp6 = tmp4 - tmp5
        tmp7 = tmp0 * tmp6
        tmp8 = tl.broadcast_to(tmp7, [XBLOCK, RBLOCK])
        tmp10 = _tmp9 + tmp8
        _tmp9 = tl.where(rmask & xmask, tmp10, _tmp9)
    tmp2 = tl.sum(_tmp2, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tmp9 = tl.sum(_tmp9, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp9, xmask)
    tmp11 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
    tmp12 = tmp9 * tmp11
    tl.store(out_ptr2 + (x0), tmp12, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/zu/czuj3knzceb6rwn3yyuo3rqfsb2nkaoygp56vieflgxw7qz4vj4a.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_127 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_127', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6422528
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 256
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr1 + (x3), None)
    tmp2 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr5 + (x1), None, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 3.985969387755102e-05
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tl.store(out_ptr0 + (x3), tmp17, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/e5/ce5bcjri7x3zsbwfx6u4m73x2vud6ng4gmif2az6scpztbaxtyus.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]

triton_red_fused_native_batch_norm_backward_128 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[256, 32768],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: 'i32', 13: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(12, 13))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_128', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 256
    rnumel = 25088
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
    _tmp9 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    tmp12 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    _tmp16 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 3136
        r2 = (rindex // 3136)
        tmp0 = tl.load(in_ptr0 + (r1 + (3136*x0) + (802816*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr1 + (r1 + (3136*x0) + (802816*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp11 = tl.load(in_ptr3 + (r1 + (3136*x0) + (802816*r2)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
        tmp3 = _tmp2 + tmp1
        _tmp2 = tl.where(rmask & xmask, tmp3, _tmp2)
        tmp6 = tmp4 - tmp5
        tmp7 = tmp0 * tmp6
        tmp8 = tl.broadcast_to(tmp7, [XBLOCK, RBLOCK])
        tmp10 = _tmp9 + tmp8
        _tmp9 = tl.where(rmask & xmask, tmp10, _tmp9)
        tmp13 = tmp11 - tmp12
        tmp14 = tmp0 * tmp13
        tmp15 = tl.broadcast_to(tmp14, [XBLOCK, RBLOCK])
        tmp17 = _tmp16 + tmp15
        _tmp16 = tl.where(rmask & xmask, tmp17, _tmp16)
    tmp2 = tl.sum(_tmp2, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp2, xmask)
    tmp9 = tl.sum(_tmp9, 1)[:, None]
    tl.store(out_ptr1 + (x0), tmp9, xmask)
    tmp16 = tl.sum(_tmp16, 1)[:, None]
    tl.store(out_ptr2 + (x0), tmp16, xmask)
    tmp18 = tl.load(in_ptr5 + (x0), xmask, eviction_policy='evict_last')
    tmp20 = tl.load(in_ptr6 + (x0), xmask, eviction_policy='evict_last')
    tmp19 = tmp9 * tmp18
    tmp21 = tmp16 * tmp20
    tl.store(out_ptr3 + (x0), tmp19, xmask)
    tl.store(out_ptr4 + (x0), tmp21, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/a7/ca7wi5o7toph4tiioof6zhhrslcfm7ibt3ucn664c7426lnpfes7.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_129 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: '*fp32', 12: '*fp32', 13: '*fp32', 14: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(14,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_129', 'mutated_arg_names': []},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6422528
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 256
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp1 = tl.load(in_ptr1 + (x3), None)
    tmp2 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp4 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp7 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp12 = tl.load(in_ptr5 + (x1), None, eviction_policy='evict_last')
    tmp15 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp18 = tl.load(in_ptr7 + (x3), None)
    tmp19 = tl.load(in_ptr8 + (x1), None, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr9 + (x1), None, eviction_policy='evict_last')
    tmp23 = tl.load(in_ptr10 + (x1), None, eviction_policy='evict_last')
    tmp29 = tl.load(in_ptr11 + (x1), None, eviction_policy='evict_last')
    tmp3 = tmp1 - tmp2
    tmp5 = 3.985969387755102e-05
    tmp6 = tmp4 * tmp5
    tmp8 = tmp7 * tmp7
    tmp9 = tmp6 * tmp8
    tmp10 = tmp3 * tmp9
    tmp11 = tmp0 - tmp10
    tmp13 = tmp12 * tmp5
    tmp14 = tmp11 - tmp13
    tmp16 = tmp7 * tmp15
    tmp17 = tmp14 * tmp16
    tmp20 = tmp18 - tmp19
    tmp22 = tmp21 * tmp5
    tmp24 = tmp23 * tmp23
    tmp25 = tmp22 * tmp24
    tmp26 = tmp20 * tmp25
    tmp27 = tmp0 - tmp26
    tmp28 = tmp27 - tmp13
    tmp30 = tmp23 * tmp29
    tmp31 = tmp28 * tmp30
    tl.store(out_ptr0 + (x3), tmp17, None)
    tl.store(out_ptr1 + (x3), tmp31, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/a4/ca4t24nkz5uknxwxru5bnyvyxz22ablkuch7qcn5u5sk3frzi2eh.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_add_native_batch_norm_backward_threshold_backward_130 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[256, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7, 8))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_batch_norm_backward_threshold_backward_130', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 256
    rnumel = 6272
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 64
    x1 = (xindex // 64)
    _tmp8 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    x3 = xindex
    tmp11 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
    _tmp15 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = tl.load(in_ptr0 + ((3136*x0) + (200704*(r2 // 3136)) + (401408*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp3 = tl.load(in_ptr1 + ((3136*x0) + (200704*(r2 // 3136)) + (401408*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp4 = tl.load(in_ptr2 + ((3136*x0) + (200704*(r2 // 3136)) + (401408*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp10 = tl.load(in_ptr3 + ((3136*x0) + (200704*(r2 // 3136)) + (401408*x1) + (r2 % 3136)), rmask & xmask, eviction_policy='evict_first', other=0.0)
        tmp1 = 0.0
        tmp2 = tmp0 <= tmp1
        tmp5 = tmp3 + tmp4
        tmp6 = tl.where(tmp2, tmp1, tmp5)
        tmp7 = tl.broadcast_to(tmp6, [XBLOCK, RBLOCK])
        tmp9 = _tmp8 + tmp7
        _tmp8 = tl.where(rmask & xmask, tmp9, _tmp8)
        tmp12 = tmp10 - tmp11
        tmp13 = tmp6 * tmp12
        tmp14 = tl.broadcast_to(tmp13, [XBLOCK, RBLOCK])
        tmp16 = _tmp15 + tmp14
        _tmp15 = tl.where(rmask & xmask, tmp16, _tmp15)
    tmp8 = tl.sum(_tmp8, 1)[:, None]
    tl.store(out_ptr0 + (x3), tmp8, xmask)
    tmp15 = tl.sum(_tmp15, 1)[:, None]
    tl.store(out_ptr1 + (x3), tmp15, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/up/cupvmgijvffdzf6wqpscnolxm3drguygwoinzry7fe5q77thsqup.py
# Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_add_native_batch_norm_backward_threshold_backward_131 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[2097152], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(9,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_native_batch_norm_backward_threshold_backward_131', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, xnumel, XBLOCK : tl.constexpr):
    xnumel = 1605632
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3136) % 64
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp3 = tl.load(in_out_ptr0 + (x3), None)
    tmp4 = tl.load(in_ptr1 + (x3), None)
    tmp7 = tl.load(in_ptr2 + (x3), None)
    tmp8 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp10 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp13 = tl.load(in_ptr5 + (x1), None, eviction_policy='evict_last')
    tmp18 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp21 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp5 = tmp3 + tmp4
    tmp6 = tl.where(tmp2, tmp1, tmp5)
    tmp9 = tmp7 - tmp8
    tmp11 = 3.985969387755102e-05
    tmp12 = tmp10 * tmp11
    tmp14 = tmp13 * tmp13
    tmp15 = tmp12 * tmp14
    tmp16 = tmp9 * tmp15
    tmp17 = tmp6 - tmp16
    tmp19 = tmp18 * tmp11
    tmp20 = tmp17 - tmp19
    tmp22 = tmp13 * tmp21
    tmp23 = tmp20 * tmp22
    tl.store(in_out_ptr0 + (x3), tmp23, None)
''')


# kernel path: /tmp/torchinductor_youkaichao/gx/cgxg6oyrbk2fcxxjqyzl76hyou5vgilurwdojstky4jg4cymluqp.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_red_fused_native_batch_norm_backward_threshold_backward_132 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@reduction(
    size_hints=[1024, 8192],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6, 7))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_threshold_backward_132', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 832
    rnumel = 7720
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex % 13
    x1 = (xindex // 13)
    _tmp11 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    x3 = xindex
    _tmp20 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r2 = rindex
        tmp0 = r2 + (7720*x0)
        tmp1 = tl.full([1, 1], 100352, tl.int32)
        tmp2 = tmp0 < tmp1
        tmp3 = tl.load(in_ptr0 + ((12544*x1) + (802816*(((r2 + (7720*x0)) // 12544) % 8)) + ((r2 + (7720*x0)) % 12544)), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp4 = 0.0
        tmp5 = tmp3 <= tmp4
        tmp6 = tl.load(in_ptr1 + ((12544*x1) + (802816*(((r2 + (7720*x0)) // 12544) % 8)) + ((r2 + (7720*x0)) % 12544)), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp7 = tl.where(tmp5, tmp4, tmp6)
        tmp8 = tl.full(tmp7.shape, 0, tmp7.dtype)
        tmp9 = tl.where(tmp2, tmp7, tmp8)
        tmp10 = tl.broadcast_to(tmp9, [XBLOCK, RBLOCK])
        tmp12 = _tmp11 + tmp10
        _tmp11 = tl.where(rmask & xmask, tmp12, _tmp11)
        tmp13 = tl.load(in_ptr2 + ((12544*x1) + (802816*(((r2 + (7720*x0)) // 12544) % 8)) + ((r2 + (7720*x0)) % 12544)), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp14 = tl.load(in_ptr3 + (tl.broadcast_to(x1, [XBLOCK, RBLOCK])), rmask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
        tmp15 = tmp13 - tmp14
        tmp16 = tmp7 * tmp15
        tmp17 = tl.full(tmp16.shape, 0, tmp16.dtype)
        tmp18 = tl.where(tmp2, tmp16, tmp17)
        tmp19 = tl.broadcast_to(tmp18, [XBLOCK, RBLOCK])
        tmp21 = _tmp20 + tmp19
        _tmp20 = tl.where(rmask & xmask, tmp21, _tmp20)
    tmp11 = tl.sum(_tmp11, 1)[:, None]
    tl.store(out_ptr0 + (x3), tmp11, xmask)
    tmp20 = tl.sum(_tmp20, 1)[:, None]
    tl.store(out_ptr1 + (x3), tmp20, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/os/cosmh7cru4tpsdk2e5nmq33lnxa5wp2efuprbr7flzyl65vkzw6h.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_per_fused_native_batch_norm_backward_threshold_backward_133 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[64, 16],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_threshold_backward_133', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 64
    rnumel = 13
    RBLOCK: tl.constexpr = 16
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (13*x0)), rmask & xmask, other=0.0)
    tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.sum(tmp3, 1)[:, None]
    tl.store(out_ptr0 + (x0), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/pt/cptwkjzm25m2gv3dlbzf2oeyxzv44k273amnmuqkq7atgrcrfbc4.py
# Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]

triton_per_fused_native_batch_norm_backward_threshold_backward_134 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@persistent_reduction(
    size_hints=[64, 16],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_threshold_backward_134', 'mutated_arg_names': []}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, out_ptr0, out_ptr1, xnumel, rnumel, XBLOCK : tl.constexpr):
    xnumel = 64
    rnumel = 13
    RBLOCK: tl.constexpr = 16
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rindex = tl.arange(0, RBLOCK)[None, :]
    rmask = rindex < rnumel
    r1 = rindex
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (r1 + (13*x0)), rmask & xmask, other=0.0)
    tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
    tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
    tmp3 = tl.where(rmask & xmask, tmp1, 0)
    tmp4 = tl.sum(tmp3, 1)[:, None]
    tmp6 = tmp4 * tmp5
    tl.store(out_ptr1 + (x0), tmp6, xmask)
    tl.store(out_ptr0 + (x0), tmp4, xmask)
''')


# kernel path: /tmp/torchinductor_youkaichao/yg/cyg235mtviiuvej74d3gjpq4erluyxw4fzohsqgch7lywxitihkm.py
# Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]

triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_135 = async_compile.triton('triton_', '''
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_heuristics import AutotuneHint, pointwise
from torch._inductor.utils import instance_descriptor
from torch._inductor import triton_helpers

@pointwise(
    size_hints=[8388608], 
    filename=__file__,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]},
    inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_135', 'mutated_arg_names': ['in_out_ptr0']},
    min_elem_per_thread=0
)
@triton.jit
def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, xnumel, XBLOCK : tl.constexpr):
    xnumel = 6422528
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:]
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 12544) % 64
    tmp0 = tl.load(in_ptr0 + (x3), None)
    tmp3 = tl.load(in_out_ptr0 + (x3), None)
    tmp5 = tl.load(in_ptr1 + (x3), None)
    tmp6 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
    tmp8 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
    tmp11 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
    tmp16 = tl.load(in_ptr5 + (x1), None, eviction_policy='evict_last')
    tmp19 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
    tmp1 = 0.0
    tmp2 = tmp0 <= tmp1
    tmp4 = tl.where(tmp2, tmp1, tmp3)
    tmp7 = tmp5 - tmp6
    tmp9 = 9.964923469387754e-06
    tmp10 = tmp8 * tmp9
    tmp12 = tmp11 * tmp11
    tmp13 = tmp10 * tmp12
    tmp14 = tmp7 * tmp13
    tmp15 = tmp4 - tmp14
    tmp17 = tmp16 * tmp9
    tmp18 = tmp15 - tmp17
    tmp20 = tmp11 * tmp19
    tmp21 = tmp18 * tmp20
    tl.store(in_out_ptr0 + (x3), tmp21, None)
''')


async_compile.wait(globals())
del async_compile

def call(args):
    primals_1, primals_2, primals_4, primals_5, primals_7, primals_8, primals_10, primals_11, primals_13, primals_14, primals_16, primals_17, primals_19, primals_20, primals_22, primals_23, primals_25, primals_26, primals_28, primals_29, primals_31, primals_32, primals_34, primals_35, primals_37, primals_38, primals_40, primals_41, primals_43, primals_44, primals_46, primals_47, primals_49, primals_50, primals_52, primals_53, primals_55, primals_56, primals_58, primals_59, primals_61, primals_62, primals_64, primals_65, primals_67, primals_68, primals_70, primals_71, primals_73, primals_74, primals_76, primals_77, primals_79, primals_80, primals_82, primals_83, primals_85, primals_86, primals_88, primals_89, primals_91, primals_92, primals_94, primals_95, primals_97, primals_98, primals_100, primals_101, primals_103, primals_104, primals_106, primals_107, primals_109, primals_110, primals_112, primals_113, primals_115, primals_116, primals_118, primals_119, primals_121, primals_122, primals_124, primals_125, primals_127, primals_128, primals_130, primals_131, primals_133, primals_134, primals_136, primals_137, primals_139, primals_140, primals_142, primals_143, primals_145, primals_146, primals_148, primals_149, primals_151, primals_152, primals_154, primals_155, primals_157, primals_158, primals_160, primals_161, primals_163, primals_164, primals_166, primals_167, primals_169, primals_170, primals_172, primals_173, primals_175, primals_176, primals_178, primals_179, primals_181, primals_182, primals_184, primals_185, primals_187, primals_188, primals_190, primals_191, primals_193, primals_194, primals_196, primals_197, primals_199, primals_200, primals_202, primals_203, primals_205, primals_206, primals_208, primals_209, primals_211, primals_212, primals_214, primals_215, primals_217, primals_218, primals_220, primals_221, primals_223, primals_224, primals_226, primals_227, primals_229, primals_230, primals_232, primals_233, primals_235, primals_236, primals_238, primals_239, primals_241, primals_242, primals_244, primals_245, primals_247, primals_248, primals_250, primals_251, primals_253, primals_254, primals_256, primals_257, primals_259, primals_260, primals_262, primals_263, primals_265, primals_266, primals_268, primals_269, primals_271, primals_272, primals_274, primals_275, primals_277, primals_278, primals_280, primals_281, primals_283, primals_284, primals_286, primals_287, primals_289, primals_290, primals_292, primals_293, primals_295, primals_296, primals_298, primals_299, primals_301, primals_302, primals_304, primals_305, primals_307, primals_308, primals_310, primals_311, primals_313, primals_314, primals_316, primals_317, primals_319, primals_320, primals_322, primals_323, primals_325, primals_326, primals_328, primals_329, primals_331, primals_332, primals_334, primals_335, primals_337, primals_338, primals_340, primals_341, primals_343, primals_344, primals_346, primals_347, primals_349, primals_350, primals_352, primals_353, primals_355, primals_356, primals_358, primals_359, primals_361, primals_362, primals_364, primals_365, primals_367, primals_368, primals_370, primals_371, primals_373, primals_374, primals_376, primals_377, primals_379, primals_380, primals_382, primals_383, primals_385, primals_386, primals_388, primals_389, primals_391, primals_392, primals_394, primals_395, primals_397, primals_398, primals_400, primals_401, primals_403, primals_404, primals_406, primals_407, primals_409, primals_410, primals_412, primals_413, primals_415, primals_416, primals_418, primals_419, primals_421, primals_422, primals_424, primals_425, primals_427, primals_428, primals_430, primals_431, primals_433, primals_434, primals_436, primals_437, primals_439, primals_440, primals_442, primals_443, primals_445, primals_446, primals_448, primals_449, primals_451, primals_452, primals_454, primals_455, primals_457, primals_458, primals_460, primals_461, primals_463, primals_464, primals_466, primals_467, primals_469, primals_470, primals_472, primals_473, primals_475, primals_476, primals_478, primals_479, primals_481, primals_482, primals_484, primals_485, primals_487, primals_488, primals_490, primals_491, primals_493, primals_494, primals_496, primals_497, primals_499, primals_500, primals_502, primals_503, primals_505, primals_506, primals_508, primals_509, primals_511, primals_512, primals_514, primals_515, primals_517, primals_518, primals_520, primals_521, primals_523, primals_524, primals_526, primals_527, primals_529, primals_530, primals_532, primals_533, primals_535, primals_536, primals_538, primals_539, primals_541, primals_542, primals_544, primals_545, primals_547, primals_548, primals_550, primals_551, primals_553, primals_554, primals_556, primals_557, primals_559, primals_560, primals_562, primals_563, primals_565, primals_566, primals_568, primals_569, primals_571, primals_572, primals_574, primals_575, primals_577, primals_578, primals_580, primals_581, primals_583, primals_584, primals_586, primals_587, primals_589, primals_590, primals_592, primals_593, primals_595, primals_596, primals_598, primals_599, primals_601, primals_602, primals_604, primals_605, primals_607, primals_608, primals_610, primals_611, primals_613, primals_614, primals_616, primals_617, primals_619, primals_620, primals_622, primals_623, primals_625, primals_626, primals_628, primals_629, primals_631, primals_632, primals_634, primals_635, primals_637, primals_638, primals_640, primals_641, primals_643, primals_644, primals_646, primals_647, primals_649, primals_650, primals_652, primals_653, primals_655, primals_656, primals_658, primals_659, primals_661, primals_662, primals_664, primals_665, primals_667, primals_668, primals_670, primals_671, primals_673, primals_674, primals_676, primals_677, primals_679, primals_680, primals_682, primals_683, primals_685, primals_686, primals_688, primals_689, primals_691, primals_692, primals_694, primals_695, primals_697, primals_698, primals_700, primals_701, primals_703, primals_704, primals_706, primals_707, primals_709, primals_710, primals_712, primals_713, primals_715, primals_716, primals_718, primals_719, primals_721, primals_722, primals_724, primals_725, primals_727, primals_728, primals_730, primals_731, primals_733, primals_734, primals_736, primals_737, primals_739, primals_740, primals_742, primals_743, primals_745, primals_746, primals_748, primals_749, primals_751, primals_752, primals_754, primals_755, primals_757, primals_758, primals_760, primals_761, primals_763, primals_764, primals_766, primals_767, primals_769, primals_770, primals_772, primals_773, primals_775, primals_776, primals_778, primals_779, primals_781, primals_782, primals_784, primals_785, primals_787, primals_788, primals_790, primals_791, primals_793, primals_794, primals_796, primals_797, primals_799, primals_800, primals_802, primals_803, primals_805, primals_806, primals_808, primals_809, primals_811, primals_812, primals_814, primals_815, primals_817, primals_818, primals_820, primals_821, primals_823, primals_824, primals_826, primals_827, primals_829, primals_830, primals_832, primals_833, primals_835, primals_836, primals_838, primals_839, primals_841, primals_842, primals_844, primals_845, primals_847, primals_848, primals_850, primals_851, primals_853, primals_854, primals_856, primals_857, primals_859, primals_860, primals_862, primals_863, primals_865, primals_866, primals_868, primals_869, primals_871, primals_872, primals_874, primals_875, primals_877, primals_878, primals_880, primals_881, primals_883, primals_884, primals_886, primals_887, primals_889, primals_890, primals_892, primals_893, primals_895, primals_896, primals_898, primals_899, primals_901, primals_902, primals_904, primals_905, primals_907, primals_908, primals_910, primals_911, primals_913, primals_914, primals_916, primals_917, primals_919, primals_920, primals_922, primals_923, primals_925, primals_926, primals_928, primals_929, primals_931, primals_932, primals_934, primals_935, primals_937, primals_938, primals_940, primals_942, primals_944, primals_945, primals_947, primals_948, primals_950, primals_951, primals_953, primals_954, primals_956, primals_958, primals_960, primals_961, primals_963, primals_964, primals_966, primals_967, primals_969, primals_970, primals_972, primals_974, primals_976, primals_978, primals_1957, convolution, squeeze_1, relu, convolution_1, squeeze_4, relu_1, convolution_2, squeeze_7, relu_2, convolution_3, squeeze_10, relu_3, convolution_4, squeeze_13, convolution_5, squeeze_16, relu_4, convolution_6, squeeze_19, relu_5, convolution_7, squeeze_22, relu_6, convolution_8, squeeze_25, relu_7, convolution_9, squeeze_28, relu_8, convolution_10, squeeze_31, relu_9, convolution_11, squeeze_34, relu_10, convolution_12, squeeze_37, relu_11, convolution_13, squeeze_40, relu_12, convolution_14, squeeze_43, relu_13, convolution_15, squeeze_46, relu_14, convolution_16, squeeze_49, relu_15, convolution_17, squeeze_52, relu_16, convolution_18, squeeze_55, relu_17, convolution_19, squeeze_58, relu_18, convolution_20, squeeze_61, relu_19, convolution_21, squeeze_64, relu_20, convolution_22, squeeze_67, relu_21, convolution_23, squeeze_70, relu_22, convolution_24, squeeze_73, relu_23, convolution_25, squeeze_76, relu_24, convolution_26, squeeze_79, relu_25, convolution_27, squeeze_82, relu_26, convolution_28, squeeze_85, relu_27, convolution_29, squeeze_88, relu_28, convolution_30, squeeze_91, relu_29, convolution_31, squeeze_94, relu_30, convolution_32, squeeze_97, relu_31, convolution_33, squeeze_100, convert_element_type_1, unsqueeze_136, relu_32, convolution_34, squeeze_103, relu_33, convolution_35, squeeze_106, relu_34, convolution_36, squeeze_109, relu_35, convolution_37, squeeze_112, relu_36, convolution_38, squeeze_115, relu_37, convolution_39, squeeze_118, relu_38, convolution_40, squeeze_121, relu_39, convolution_41, squeeze_124, relu_40, convolution_42, squeeze_127, relu_41, convolution_43, squeeze_130, relu_42, convolution_44, squeeze_133, relu_43, convolution_45, squeeze_136, relu_44, convolution_46, squeeze_139, relu_45, convolution_47, squeeze_142, relu_46, convolution_48, squeeze_145, relu_47, convolution_49, squeeze_148, relu_48, convolution_50, squeeze_151, relu_49, convolution_51, squeeze_154, relu_50, convolution_52, squeeze_157, relu_51, convolution_53, squeeze_160, relu_52, convolution_54, squeeze_163, relu_53, convolution_55, squeeze_166, relu_54, convolution_56, squeeze_169, relu_55, convolution_57, squeeze_172, relu_56, convolution_58, squeeze_175, relu_57, convolution_59, squeeze_178, relu_58, convolution_60, squeeze_181, convolution_61, squeeze_184, convert_element_type_9, unsqueeze_250, relu_59, convolution_62, squeeze_187, convolution_63, squeeze_190, convert_element_type_13, unsqueeze_259, relu_60, convolution_64, squeeze_193, relu_61, convolution_65, squeeze_196, convolution_66, squeeze_199, relu_62, convolution_67, squeeze_202, relu_63, convolution_68, squeeze_205, relu_64, convolution_69, squeeze_208, relu_65, convolution_70, squeeze_211, relu_66, convolution_71, squeeze_214, relu_67, convolution_72, squeeze_217, relu_68, convolution_73, squeeze_220, relu_69, convolution_74, squeeze_223, relu_70, convolution_75, squeeze_226, relu_71, convolution_76, squeeze_229, relu_72, convolution_77, squeeze_232, relu_73, convolution_78, squeeze_235, relu_74, convolution_79, squeeze_238, relu_75, convolution_80, squeeze_241, relu_76, convolution_81, squeeze_244, relu_77, convolution_82, squeeze_247, relu_78, convolution_83, squeeze_250, relu_79, convolution_84, squeeze_253, relu_80, convolution_85, squeeze_256, relu_81, convolution_86, squeeze_259, relu_82, convolution_87, squeeze_262, relu_83, convolution_88, squeeze_265, relu_84, convolution_89, squeeze_268, relu_85, convolution_90, squeeze_271, relu_86, convolution_91, squeeze_274, convolution_92, squeeze_277, relu_87, convolution_93, squeeze_280, convolution_94, squeeze_283, relu_88, convolution_95, squeeze_286, relu_89, convolution_96, squeeze_289, convolution_97, squeeze_292, relu_90, convolution_98, squeeze_295, relu_91, convolution_99, squeeze_298, relu_92, convolution_100, squeeze_301, relu_93, convolution_101, squeeze_304, relu_94, convolution_102, squeeze_307, relu_95, convolution_103, squeeze_310, relu_96, convolution_104, squeeze_313, relu_97, convolution_105, squeeze_316, relu_98, convolution_106, squeeze_319, relu_99, convolution_107, squeeze_322, relu_100, convolution_108, squeeze_325, relu_101, convolution_109, squeeze_328, relu_102, convolution_110, squeeze_331, relu_103, convolution_111, squeeze_334, relu_104, convolution_112, squeeze_337, relu_105, convolution_113, squeeze_340, relu_106, convolution_114, squeeze_343, relu_107, convolution_115, squeeze_346, relu_108, convolution_116, squeeze_349, relu_109, convolution_117, squeeze_352, relu_110, convolution_118, squeeze_355, relu_111, convolution_119, squeeze_358, relu_112, convolution_120, squeeze_361, relu_113, convolution_121, squeeze_364, relu_114, convolution_122, squeeze_367, convolution_123, squeeze_370, relu_115, convolution_124, squeeze_373, convolution_125, squeeze_376, relu_116, convolution_126, squeeze_379, relu_117, convolution_127, squeeze_382, convolution_128, squeeze_385, relu_118, convolution_129, squeeze_388, relu_119, convolution_130, squeeze_391, relu_120, convolution_131, squeeze_394, relu_121, convolution_132, squeeze_397, relu_122, convolution_133, squeeze_400, relu_123, convolution_134, squeeze_403, relu_124, convolution_135, squeeze_406, relu_125, convolution_136, squeeze_409, relu_126, convolution_137, squeeze_412, relu_127, convolution_138, squeeze_415, relu_128, convolution_139, squeeze_418, relu_129, convolution_140, squeeze_421, relu_130, convolution_141, squeeze_424, relu_131, convolution_142, squeeze_427, relu_132, convolution_143, squeeze_430, relu_133, convolution_144, squeeze_433, relu_134, convolution_145, squeeze_436, relu_135, convolution_146, squeeze_439, relu_136, convolution_147, squeeze_442, relu_137, convolution_148, squeeze_445, relu_138, convolution_149, squeeze_448, relu_139, convolution_150, squeeze_451, relu_140, convolution_151, squeeze_454, relu_141, convolution_152, squeeze_457, relu_142, convolution_153, squeeze_460, convolution_154, squeeze_463, relu_143, convolution_155, squeeze_466, convolution_156, squeeze_469, relu_144, convolution_157, squeeze_472, relu_145, convolution_158, squeeze_475, convolution_159, squeeze_478, relu_146, convolution_160, squeeze_481, relu_147, convolution_161, squeeze_484, relu_148, convolution_162, squeeze_487, relu_149, convolution_163, squeeze_490, relu_150, convolution_164, squeeze_493, relu_151, convolution_165, squeeze_496, relu_152, convolution_166, squeeze_499, relu_153, convolution_167, squeeze_502, relu_154, convolution_168, squeeze_505, relu_155, convolution_169, squeeze_508, relu_156, convolution_170, squeeze_511, relu_157, convolution_171, squeeze_514, relu_158, convolution_172, squeeze_517, relu_159, convolution_173, squeeze_520, relu_160, convolution_174, squeeze_523, relu_161, convolution_175, squeeze_526, relu_162, convolution_176, squeeze_529, relu_163, convolution_177, squeeze_532, relu_164, convolution_178, squeeze_535, relu_165, convolution_179, squeeze_538, relu_166, convolution_180, squeeze_541, relu_167, convolution_181, squeeze_544, relu_168, convolution_182, squeeze_547, relu_169, convolution_183, squeeze_550, relu_170, convolution_184, squeeze_553, relu_171, convolution_185, squeeze_556, relu_172, convolution_186, squeeze_559, relu_173, convolution_187, squeeze_562, relu_174, convolution_188, squeeze_565, relu_175, convolution_189, squeeze_568, relu_176, convolution_190, squeeze_571, relu_177, convolution_191, squeeze_574, relu_178, convolution_192, squeeze_577, relu_179, convolution_193, squeeze_580, convolution_194, squeeze_583, convolution_195, squeeze_586, convert_element_type_61, unsqueeze_799, relu_180, convolution_196, squeeze_589, convolution_197, squeeze_592, convolution_198, squeeze_595, convert_element_type_69, unsqueeze_813, relu_181, convolution_199, squeeze_598, relu_182, convolution_200, squeeze_601, convolution_201, squeeze_604, convolution_202, squeeze_607, convert_element_type_73, unsqueeze_830, relu_183, convolution_203, squeeze_610, relu_184, convolution_204, squeeze_613, relu_185, convolution_205, squeeze_616, convolution_206, squeeze_619, relu_186, convolution_207, squeeze_622, convolution_208, squeeze_625, relu_187, convolution_209, squeeze_628, relu_188, convolution_210, squeeze_631, relu_189, convolution_211, squeeze_634, relu_190, convolution_212, squeeze_637, relu_191, convolution_213, squeeze_640, relu_192, convolution_214, squeeze_643, relu_193, convolution_215, squeeze_646, relu_194, convolution_216, squeeze_649, relu_195, convolution_217, squeeze_652, relu_196, convolution_218, squeeze_655, relu_197, convolution_219, squeeze_658, relu_198, convolution_220, squeeze_661, relu_199, convolution_221, squeeze_664, relu_200, convolution_222, squeeze_667, relu_201, convolution_223, squeeze_670, relu_202, convolution_224, squeeze_673, relu_203, convolution_225, squeeze_676, relu_204, convolution_226, squeeze_679, relu_205, convolution_227, squeeze_682, relu_206, convolution_228, squeeze_685, relu_207, convolution_229, squeeze_688, relu_208, convolution_230, squeeze_691, relu_209, convolution_231, squeeze_694, relu_210, convolution_232, squeeze_697, relu_211, convolution_233, squeeze_700, relu_212, convolution_234, squeeze_703, relu_213, convolution_235, squeeze_706, relu_214, convolution_236, squeeze_709, relu_215, convolution_237, squeeze_712, relu_216, convolution_238, squeeze_715, relu_217, convolution_239, squeeze_718, relu_218, convolution_240, squeeze_721, relu_219, convolution_241, squeeze_724, convolution_242, squeeze_727, convolution_243, squeeze_730, relu_220, convolution_244, squeeze_733, convolution_245, squeeze_736, convolution_246, squeeze_739, relu_221, convolution_247, squeeze_742, relu_222, convolution_248, squeeze_745, convolution_249, squeeze_748, convolution_250, squeeze_751, relu_223, convolution_251, squeeze_754, relu_224, convolution_252, squeeze_757, relu_225, convolution_253, squeeze_760, convolution_254, squeeze_763, relu_226, convolution_255, squeeze_766, convolution_256, squeeze_769, relu_227, convolution_257, squeeze_772, relu_228, convolution_258, squeeze_775, relu_229, convolution_259, squeeze_778, relu_230, convolution_260, squeeze_781, relu_231, convolution_261, squeeze_784, relu_232, convolution_262, squeeze_787, relu_233, convolution_263, squeeze_790, relu_234, convolution_264, squeeze_793, relu_235, convolution_265, squeeze_796, relu_236, convolution_266, squeeze_799, relu_237, convolution_267, squeeze_802, relu_238, convolution_268, squeeze_805, relu_239, convolution_269, squeeze_808, relu_240, convolution_270, squeeze_811, relu_241, convolution_271, squeeze_814, relu_242, convolution_272, squeeze_817, relu_243, convolution_273, squeeze_820, relu_244, convolution_274, squeeze_823, relu_245, convolution_275, squeeze_826, relu_246, convolution_276, squeeze_829, relu_247, convolution_277, squeeze_832, relu_248, convolution_278, squeeze_835, relu_249, convolution_279, squeeze_838, relu_250, convolution_280, squeeze_841, relu_251, convolution_281, squeeze_844, relu_252, convolution_282, squeeze_847, relu_253, convolution_283, squeeze_850, relu_254, convolution_284, squeeze_853, relu_255, convolution_285, squeeze_856, relu_256, convolution_286, squeeze_859, relu_257, convolution_287, squeeze_862, relu_258, convolution_288, squeeze_865, relu_259, convolution_289, squeeze_868, convolution_290, squeeze_871, convolution_291, squeeze_874, relu_260, convolution_292, squeeze_877, convolution_293, squeeze_880, convolution_294, squeeze_883, relu_261, convolution_295, squeeze_886, relu_262, convolution_296, squeeze_889, convolution_297, squeeze_892, convolution_298, squeeze_895, relu_263, convolution_299, squeeze_898, relu_264, convolution_300, squeeze_901, relu_265, convolution_301, squeeze_904, convolution_302, squeeze_907, relu_266, convolution_303, squeeze_910, convolution_304, squeeze_913, relu_267, convolution_305, squeeze_916, relu_268, convolution_306, squeeze_919, relu_269, convolution_307, squeeze_922, convolution_308, squeeze_925, relu_270, convolution_309, squeeze_928, relu_271, convolution_310, squeeze_931, relu_272, convolution_311, squeeze_934, convolution_312, squeeze_937, convolution_313, squeeze_940, add_1866, convolution_314, squeeze_943, relu_275, convolution_315, squeeze_946, relu_276, convolution_316, squeeze_949, convolution_317, squeeze_952, convolution_318, squeeze_955, add_1893, convolution_319, squeeze_958, relu_279, convolution_320, squeeze_961, relu_280, convolution_321, squeeze_964, convolution_322, squeeze_967, convolution_323, squeeze_970, add_1920, convolution_324, squeeze_973, clone, permute_1, le, unsqueeze_1333, le_1, unsqueeze_1345, le_2, unsqueeze_1357, unsqueeze_1369, unsqueeze_1381, unsqueeze_1393, le_5, unsqueeze_1405, le_6, unsqueeze_1417, unsqueeze_1429, unsqueeze_1441, unsqueeze_1453, le_9, unsqueeze_1465, le_10, unsqueeze_1477, unsqueeze_1489, unsqueeze_1501, unsqueeze_1513, unsqueeze_1525, unsqueeze_1537, unsqueeze_1549, unsqueeze_1561, unsqueeze_1573, unsqueeze_1585, unsqueeze_1597, unsqueeze_1609, unsqueeze_1621, unsqueeze_1633, unsqueeze_1645, unsqueeze_1657, unsqueeze_1669, unsqueeze_1681, unsqueeze_1693, unsqueeze_1705, unsqueeze_1717, unsqueeze_1729, unsqueeze_1741, unsqueeze_1753, unsqueeze_1765, unsqueeze_1777, unsqueeze_1789, unsqueeze_1801, unsqueeze_1813, unsqueeze_1825, unsqueeze_1837, unsqueeze_1849, unsqueeze_1861, unsqueeze_1873, unsqueeze_1885, unsqueeze_1897, unsqueeze_1909, unsqueeze_1921, unsqueeze_1933, unsqueeze_1945, unsqueeze_1957, unsqueeze_1969, unsqueeze_1981, unsqueeze_1993, unsqueeze_2005, unsqueeze_2017, unsqueeze_2029, unsqueeze_2041, unsqueeze_2053, unsqueeze_2065, unsqueeze_2077, unsqueeze_2089, unsqueeze_2101, unsqueeze_2113, unsqueeze_2125, unsqueeze_2137, unsqueeze_2149, unsqueeze_2161, unsqueeze_2173, unsqueeze_2185, unsqueeze_2197, unsqueeze_2209, unsqueeze_2221, unsqueeze_2233, unsqueeze_2245, unsqueeze_2257, unsqueeze_2269, unsqueeze_2281, unsqueeze_2293, unsqueeze_2305, unsqueeze_2317, unsqueeze_2329, unsqueeze_2341, unsqueeze_2353, unsqueeze_2365, unsqueeze_2377, unsqueeze_2389, unsqueeze_2401, unsqueeze_2413, unsqueeze_2425, unsqueeze_2437, unsqueeze_2449, unsqueeze_2461, unsqueeze_2473, unsqueeze_2485, unsqueeze_2497, unsqueeze_2509, unsqueeze_2521, unsqueeze_2533, unsqueeze_2545, unsqueeze_2557, unsqueeze_2569, unsqueeze_2581, unsqueeze_2593, unsqueeze_2605, unsqueeze_2617, unsqueeze_2629, unsqueeze_2641, unsqueeze_2653, unsqueeze_2665, unsqueeze_2677, unsqueeze_2689, unsqueeze_2701, unsqueeze_2713, unsqueeze_2725, unsqueeze_2737, unsqueeze_2749, unsqueeze_2761, unsqueeze_2773, unsqueeze_2785, unsqueeze_2797, unsqueeze_2809, unsqueeze_2821, unsqueeze_2833, unsqueeze_2845, unsqueeze_2857, unsqueeze_2869, unsqueeze_2881, unsqueeze_2893, unsqueeze_2905, unsqueeze_2917, unsqueeze_2929, unsqueeze_2941, unsqueeze_2953, unsqueeze_2965, unsqueeze_2977, unsqueeze_2989, unsqueeze_3001, unsqueeze_3013, unsqueeze_3025, unsqueeze_3037, unsqueeze_3049, unsqueeze_3061, unsqueeze_3073, unsqueeze_3085, unsqueeze_3097, unsqueeze_3109, unsqueeze_3121, unsqueeze_3133, unsqueeze_3145, unsqueeze_3157, unsqueeze_3169, unsqueeze_3181, unsqueeze_3193, unsqueeze_3205, unsqueeze_3217, unsqueeze_3229, unsqueeze_3241, unsqueeze_3253, unsqueeze_3265, unsqueeze_3277, unsqueeze_3289, unsqueeze_3301, unsqueeze_3313, unsqueeze_3325, unsqueeze_3337, unsqueeze_3349, unsqueeze_3361, unsqueeze_3373, unsqueeze_3385, unsqueeze_3397, unsqueeze_3409, unsqueeze_3421, unsqueeze_3433, unsqueeze_3445, unsqueeze_3457, unsqueeze_3469, unsqueeze_3481, unsqueeze_3493, unsqueeze_3505, unsqueeze_3517, unsqueeze_3529, unsqueeze_3541, unsqueeze_3553, unsqueeze_3565, unsqueeze_3577, unsqueeze_3589, unsqueeze_3601, unsqueeze_3613, unsqueeze_3625, unsqueeze_3637, unsqueeze_3649, unsqueeze_3661, unsqueeze_3673, unsqueeze_3685, unsqueeze_3697, unsqueeze_3709, unsqueeze_3721, unsqueeze_3733, unsqueeze_3745, unsqueeze_3757, unsqueeze_3769, unsqueeze_3781, unsqueeze_3793, unsqueeze_3805, unsqueeze_3817, unsqueeze_3829, unsqueeze_3841, unsqueeze_3853, unsqueeze_3865, unsqueeze_3877, unsqueeze_3889, unsqueeze_3901, unsqueeze_3913, unsqueeze_3925, unsqueeze_3937, unsqueeze_3949, unsqueeze_3961, unsqueeze_3973, unsqueeze_3985, unsqueeze_3997, unsqueeze_4009, unsqueeze_4021, unsqueeze_4033, unsqueeze_4045, unsqueeze_4057, unsqueeze_4069, unsqueeze_4081, unsqueeze_4093, unsqueeze_4105, unsqueeze_4117, unsqueeze_4129, unsqueeze_4141, unsqueeze_4153, unsqueeze_4165, unsqueeze_4177, unsqueeze_4189, unsqueeze_4201, unsqueeze_4213, unsqueeze_4225, unsqueeze_4237, unsqueeze_4249, unsqueeze_4261, unsqueeze_4273, unsqueeze_4285, unsqueeze_4297, unsqueeze_4309, unsqueeze_4321, unsqueeze_4333, unsqueeze_4345, unsqueeze_4357, unsqueeze_4369, unsqueeze_4381, unsqueeze_4393, unsqueeze_4405, unsqueeze_4417, unsqueeze_4429, unsqueeze_4441, unsqueeze_4453, unsqueeze_4465, unsqueeze_4477, unsqueeze_4489, unsqueeze_4501, unsqueeze_4513, unsqueeze_4525, unsqueeze_4537, unsqueeze_4549, unsqueeze_4561, unsqueeze_4573, unsqueeze_4585, unsqueeze_4597, unsqueeze_4609, unsqueeze_4621, unsqueeze_4633, unsqueeze_4645, unsqueeze_4657, unsqueeze_4669, unsqueeze_4681, unsqueeze_4693, unsqueeze_4705, unsqueeze_4717, unsqueeze_4729, unsqueeze_4741, unsqueeze_4753, unsqueeze_4765, unsqueeze_4777, unsqueeze_4789, unsqueeze_4801, unsqueeze_4813, unsqueeze_4825, unsqueeze_4837, unsqueeze_4849, unsqueeze_4861, unsqueeze_4873, unsqueeze_4885, unsqueeze_4897, unsqueeze_4909, unsqueeze_4921, unsqueeze_4933, unsqueeze_4945, unsqueeze_4957, unsqueeze_4969, unsqueeze_4981, unsqueeze_4993, unsqueeze_5005, unsqueeze_5017, unsqueeze_5029, unsqueeze_5041, unsqueeze_5053, unsqueeze_5065, unsqueeze_5077, unsqueeze_5089, unsqueeze_5101, unsqueeze_5113, unsqueeze_5125, unsqueeze_5137, unsqueeze_5149, unsqueeze_5161, unsqueeze_5173, unsqueeze_5185, unsqueeze_5197, unsqueeze_5209, unsqueeze_5221, tangents_1 = args
    args.clear()
    assert_size_stride(primals_1, (64, 3, 3, 3), (27, 9, 3, 1))
    assert_size_stride(primals_2, (64, ), (1, ))
    assert_size_stride(primals_4, (64, 64, 3, 3), (576, 9, 3, 1))
    assert_size_stride(primals_5, (64, ), (1, ))
    assert_size_stride(primals_7, (64, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(primals_8, (64, ), (1, ))
    assert_size_stride(primals_10, (64, 64, 3, 3), (576, 9, 3, 1))
    assert_size_stride(primals_11, (64, ), (1, ))
    assert_size_stride(primals_13, (256, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(primals_14, (256, ), (1, ))
    assert_size_stride(primals_16, (256, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(primals_17, (256, ), (1, ))
    assert_size_stride(primals_19, (64, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(primals_20, (64, ), (1, ))
    assert_size_stride(primals_22, (64, 64, 3, 3), (576, 9, 3, 1))
    assert_size_stride(primals_23, (64, ), (1, ))
    assert_size_stride(primals_25, (256, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(primals_26, (256, ), (1, ))
    assert_size_stride(primals_28, (64, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(primals_29, (64, ), (1, ))
    assert_size_stride(primals_31, (64, 64, 3, 3), (576, 9, 3, 1))
    assert_size_stride(primals_32, (64, ), (1, ))
    assert_size_stride(primals_34, (256, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(primals_35, (256, ), (1, ))
    assert_size_stride(primals_37, (64, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(primals_38, (64, ), (1, ))
    assert_size_stride(primals_40, (64, 64, 3, 3), (576, 9, 3, 1))
    assert_size_stride(primals_41, (64, ), (1, ))
    assert_size_stride(primals_43, (256, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(primals_44, (256, ), (1, ))
    assert_size_stride(primals_46, (18, 256, 3, 3), (2304, 9, 3, 1))
    assert_size_stride(primals_47, (18, ), (1, ))
    assert_size_stride(primals_49, (36, 256, 3, 3), (2304, 9, 3, 1))
    assert_size_stride(primals_50, (36, ), (1, ))
    assert_size_stride(primals_52, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_53, (18, ), (1, ))
    assert_size_stride(primals_55, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_56, (18, ), (1, ))
    assert_size_stride(primals_58, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_59, (18, ), (1, ))
    assert_size_stride(primals_61, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_62, (18, ), (1, ))
    assert_size_stride(primals_64, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_65, (18, ), (1, ))
    assert_size_stride(primals_67, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_68, (18, ), (1, ))
    assert_size_stride(primals_70, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_71, (18, ), (1, ))
    assert_size_stride(primals_73, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_74, (18, ), (1, ))
    assert_size_stride(primals_76, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_77, (36, ), (1, ))
    assert_size_stride(primals_79, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_80, (36, ), (1, ))
    assert_size_stride(primals_82, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_83, (36, ), (1, ))
    assert_size_stride(primals_85, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_86, (36, ), (1, ))
    assert_size_stride(primals_88, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_89, (36, ), (1, ))
    assert_size_stride(primals_91, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_92, (36, ), (1, ))
    assert_size_stride(primals_94, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_95, (36, ), (1, ))
    assert_size_stride(primals_97, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_98, (36, ), (1, ))
    assert_size_stride(primals_100, (18, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_101, (18, ), (1, ))
    assert_size_stride(primals_103, (36, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_104, (36, ), (1, ))
    assert_size_stride(primals_106, (72, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_107, (72, ), (1, ))
    assert_size_stride(primals_109, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_110, (18, ), (1, ))
    assert_size_stride(primals_112, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_113, (18, ), (1, ))
    assert_size_stride(primals_115, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_116, (18, ), (1, ))
    assert_size_stride(primals_118, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_119, (18, ), (1, ))
    assert_size_stride(primals_121, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_122, (18, ), (1, ))
    assert_size_stride(primals_124, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_125, (18, ), (1, ))
    assert_size_stride(primals_127, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_128, (18, ), (1, ))
    assert_size_stride(primals_130, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_131, (18, ), (1, ))
    assert_size_stride(primals_133, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_134, (36, ), (1, ))
    assert_size_stride(primals_136, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_137, (36, ), (1, ))
    assert_size_stride(primals_139, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_140, (36, ), (1, ))
    assert_size_stride(primals_142, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_143, (36, ), (1, ))
    assert_size_stride(primals_145, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_146, (36, ), (1, ))
    assert_size_stride(primals_148, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_149, (36, ), (1, ))
    assert_size_stride(primals_151, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_152, (36, ), (1, ))
    assert_size_stride(primals_154, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_155, (36, ), (1, ))
    assert_size_stride(primals_157, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_158, (72, ), (1, ))
    assert_size_stride(primals_160, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_161, (72, ), (1, ))
    assert_size_stride(primals_163, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_164, (72, ), (1, ))
    assert_size_stride(primals_166, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_167, (72, ), (1, ))
    assert_size_stride(primals_169, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_170, (72, ), (1, ))
    assert_size_stride(primals_172, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_173, (72, ), (1, ))
    assert_size_stride(primals_175, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_176, (72, ), (1, ))
    assert_size_stride(primals_178, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_179, (72, ), (1, ))
    assert_size_stride(primals_181, (18, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_182, (18, ), (1, ))
    assert_size_stride(primals_184, (18, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_185, (18, ), (1, ))
    assert_size_stride(primals_187, (36, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_188, (36, ), (1, ))
    assert_size_stride(primals_190, (36, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_191, (36, ), (1, ))
    assert_size_stride(primals_193, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_194, (18, ), (1, ))
    assert_size_stride(primals_196, (72, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_197, (72, ), (1, ))
    assert_size_stride(primals_199, (72, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_200, (72, ), (1, ))
    assert_size_stride(primals_202, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_203, (18, ), (1, ))
    assert_size_stride(primals_205, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_206, (18, ), (1, ))
    assert_size_stride(primals_208, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_209, (18, ), (1, ))
    assert_size_stride(primals_211, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_212, (18, ), (1, ))
    assert_size_stride(primals_214, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_215, (18, ), (1, ))
    assert_size_stride(primals_217, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_218, (18, ), (1, ))
    assert_size_stride(primals_220, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_221, (18, ), (1, ))
    assert_size_stride(primals_223, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_224, (18, ), (1, ))
    assert_size_stride(primals_226, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_227, (36, ), (1, ))
    assert_size_stride(primals_229, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_230, (36, ), (1, ))
    assert_size_stride(primals_232, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_233, (36, ), (1, ))
    assert_size_stride(primals_235, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_236, (36, ), (1, ))
    assert_size_stride(primals_238, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_239, (36, ), (1, ))
    assert_size_stride(primals_241, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_242, (36, ), (1, ))
    assert_size_stride(primals_244, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_245, (36, ), (1, ))
    assert_size_stride(primals_247, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_248, (36, ), (1, ))
    assert_size_stride(primals_250, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_251, (72, ), (1, ))
    assert_size_stride(primals_253, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_254, (72, ), (1, ))
    assert_size_stride(primals_256, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_257, (72, ), (1, ))
    assert_size_stride(primals_259, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_260, (72, ), (1, ))
    assert_size_stride(primals_262, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_263, (72, ), (1, ))
    assert_size_stride(primals_265, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_266, (72, ), (1, ))
    assert_size_stride(primals_268, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_269, (72, ), (1, ))
    assert_size_stride(primals_271, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_272, (72, ), (1, ))
    assert_size_stride(primals_274, (18, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_275, (18, ), (1, ))
    assert_size_stride(primals_277, (18, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_278, (18, ), (1, ))
    assert_size_stride(primals_280, (36, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_281, (36, ), (1, ))
    assert_size_stride(primals_283, (36, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_284, (36, ), (1, ))
    assert_size_stride(primals_286, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_287, (18, ), (1, ))
    assert_size_stride(primals_289, (72, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_290, (72, ), (1, ))
    assert_size_stride(primals_292, (72, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_293, (72, ), (1, ))
    assert_size_stride(primals_295, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_296, (18, ), (1, ))
    assert_size_stride(primals_298, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_299, (18, ), (1, ))
    assert_size_stride(primals_301, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_302, (18, ), (1, ))
    assert_size_stride(primals_304, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_305, (18, ), (1, ))
    assert_size_stride(primals_307, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_308, (18, ), (1, ))
    assert_size_stride(primals_310, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_311, (18, ), (1, ))
    assert_size_stride(primals_313, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_314, (18, ), (1, ))
    assert_size_stride(primals_316, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_317, (18, ), (1, ))
    assert_size_stride(primals_319, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_320, (36, ), (1, ))
    assert_size_stride(primals_322, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_323, (36, ), (1, ))
    assert_size_stride(primals_325, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_326, (36, ), (1, ))
    assert_size_stride(primals_328, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_329, (36, ), (1, ))
    assert_size_stride(primals_331, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_332, (36, ), (1, ))
    assert_size_stride(primals_334, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_335, (36, ), (1, ))
    assert_size_stride(primals_337, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_338, (36, ), (1, ))
    assert_size_stride(primals_340, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_341, (36, ), (1, ))
    assert_size_stride(primals_343, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_344, (72, ), (1, ))
    assert_size_stride(primals_346, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_347, (72, ), (1, ))
    assert_size_stride(primals_349, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_350, (72, ), (1, ))
    assert_size_stride(primals_352, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_353, (72, ), (1, ))
    assert_size_stride(primals_355, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_356, (72, ), (1, ))
    assert_size_stride(primals_358, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_359, (72, ), (1, ))
    assert_size_stride(primals_361, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_362, (72, ), (1, ))
    assert_size_stride(primals_364, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_365, (72, ), (1, ))
    assert_size_stride(primals_367, (18, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_368, (18, ), (1, ))
    assert_size_stride(primals_370, (18, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_371, (18, ), (1, ))
    assert_size_stride(primals_373, (36, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_374, (36, ), (1, ))
    assert_size_stride(primals_376, (36, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_377, (36, ), (1, ))
    assert_size_stride(primals_379, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_380, (18, ), (1, ))
    assert_size_stride(primals_382, (72, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_383, (72, ), (1, ))
    assert_size_stride(primals_385, (72, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_386, (72, ), (1, ))
    assert_size_stride(primals_388, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_389, (18, ), (1, ))
    assert_size_stride(primals_391, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_392, (18, ), (1, ))
    assert_size_stride(primals_394, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_395, (18, ), (1, ))
    assert_size_stride(primals_397, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_398, (18, ), (1, ))
    assert_size_stride(primals_400, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_401, (18, ), (1, ))
    assert_size_stride(primals_403, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_404, (18, ), (1, ))
    assert_size_stride(primals_406, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_407, (18, ), (1, ))
    assert_size_stride(primals_409, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_410, (18, ), (1, ))
    assert_size_stride(primals_412, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_413, (36, ), (1, ))
    assert_size_stride(primals_415, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_416, (36, ), (1, ))
    assert_size_stride(primals_418, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_419, (36, ), (1, ))
    assert_size_stride(primals_421, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_422, (36, ), (1, ))
    assert_size_stride(primals_424, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_425, (36, ), (1, ))
    assert_size_stride(primals_427, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_428, (36, ), (1, ))
    assert_size_stride(primals_430, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_431, (36, ), (1, ))
    assert_size_stride(primals_433, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_434, (36, ), (1, ))
    assert_size_stride(primals_436, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_437, (72, ), (1, ))
    assert_size_stride(primals_439, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_440, (72, ), (1, ))
    assert_size_stride(primals_442, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_443, (72, ), (1, ))
    assert_size_stride(primals_445, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_446, (72, ), (1, ))
    assert_size_stride(primals_448, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_449, (72, ), (1, ))
    assert_size_stride(primals_451, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_452, (72, ), (1, ))
    assert_size_stride(primals_454, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_455, (72, ), (1, ))
    assert_size_stride(primals_457, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_458, (72, ), (1, ))
    assert_size_stride(primals_460, (18, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_461, (18, ), (1, ))
    assert_size_stride(primals_463, (18, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_464, (18, ), (1, ))
    assert_size_stride(primals_466, (36, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_467, (36, ), (1, ))
    assert_size_stride(primals_469, (36, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_470, (36, ), (1, ))
    assert_size_stride(primals_472, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_473, (18, ), (1, ))
    assert_size_stride(primals_475, (72, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_476, (72, ), (1, ))
    assert_size_stride(primals_478, (72, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_479, (72, ), (1, ))
    assert_size_stride(primals_481, (144, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_482, (144, ), (1, ))
    assert_size_stride(primals_484, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_485, (18, ), (1, ))
    assert_size_stride(primals_487, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_488, (18, ), (1, ))
    assert_size_stride(primals_490, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_491, (18, ), (1, ))
    assert_size_stride(primals_493, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_494, (18, ), (1, ))
    assert_size_stride(primals_496, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_497, (18, ), (1, ))
    assert_size_stride(primals_499, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_500, (18, ), (1, ))
    assert_size_stride(primals_502, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_503, (18, ), (1, ))
    assert_size_stride(primals_505, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_506, (18, ), (1, ))
    assert_size_stride(primals_508, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_509, (36, ), (1, ))
    assert_size_stride(primals_511, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_512, (36, ), (1, ))
    assert_size_stride(primals_514, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_515, (36, ), (1, ))
    assert_size_stride(primals_517, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_518, (36, ), (1, ))
    assert_size_stride(primals_520, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_521, (36, ), (1, ))
    assert_size_stride(primals_523, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_524, (36, ), (1, ))
    assert_size_stride(primals_526, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_527, (36, ), (1, ))
    assert_size_stride(primals_529, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_530, (36, ), (1, ))
    assert_size_stride(primals_532, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_533, (72, ), (1, ))
    assert_size_stride(primals_535, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_536, (72, ), (1, ))
    assert_size_stride(primals_538, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_539, (72, ), (1, ))
    assert_size_stride(primals_541, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_542, (72, ), (1, ))
    assert_size_stride(primals_544, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_545, (72, ), (1, ))
    assert_size_stride(primals_547, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_548, (72, ), (1, ))
    assert_size_stride(primals_550, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_551, (72, ), (1, ))
    assert_size_stride(primals_553, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_554, (72, ), (1, ))
    assert_size_stride(primals_556, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_557, (144, ), (1, ))
    assert_size_stride(primals_559, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_560, (144, ), (1, ))
    assert_size_stride(primals_562, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_563, (144, ), (1, ))
    assert_size_stride(primals_565, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_566, (144, ), (1, ))
    assert_size_stride(primals_568, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_569, (144, ), (1, ))
    assert_size_stride(primals_571, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_572, (144, ), (1, ))
    assert_size_stride(primals_574, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_575, (144, ), (1, ))
    assert_size_stride(primals_577, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_578, (144, ), (1, ))
    assert_size_stride(primals_580, (18, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_581, (18, ), (1, ))
    assert_size_stride(primals_583, (18, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_584, (18, ), (1, ))
    assert_size_stride(primals_586, (18, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_587, (18, ), (1, ))
    assert_size_stride(primals_589, (36, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_590, (36, ), (1, ))
    assert_size_stride(primals_592, (36, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_593, (36, ), (1, ))
    assert_size_stride(primals_595, (36, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_596, (36, ), (1, ))
    assert_size_stride(primals_598, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_599, (18, ), (1, ))
    assert_size_stride(primals_601, (72, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_602, (72, ), (1, ))
    assert_size_stride(primals_604, (72, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_605, (72, ), (1, ))
    assert_size_stride(primals_607, (72, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_608, (72, ), (1, ))
    assert_size_stride(primals_610, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_611, (18, ), (1, ))
    assert_size_stride(primals_613, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_614, (18, ), (1, ))
    assert_size_stride(primals_616, (144, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_617, (144, ), (1, ))
    assert_size_stride(primals_619, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_620, (36, ), (1, ))
    assert_size_stride(primals_622, (144, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_623, (144, ), (1, ))
    assert_size_stride(primals_625, (144, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_626, (144, ), (1, ))
    assert_size_stride(primals_628, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_629, (18, ), (1, ))
    assert_size_stride(primals_631, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_632, (18, ), (1, ))
    assert_size_stride(primals_634, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_635, (18, ), (1, ))
    assert_size_stride(primals_637, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_638, (18, ), (1, ))
    assert_size_stride(primals_640, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_641, (18, ), (1, ))
    assert_size_stride(primals_643, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_644, (18, ), (1, ))
    assert_size_stride(primals_646, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_647, (18, ), (1, ))
    assert_size_stride(primals_649, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_650, (18, ), (1, ))
    assert_size_stride(primals_652, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_653, (36, ), (1, ))
    assert_size_stride(primals_655, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_656, (36, ), (1, ))
    assert_size_stride(primals_658, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_659, (36, ), (1, ))
    assert_size_stride(primals_661, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_662, (36, ), (1, ))
    assert_size_stride(primals_664, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_665, (36, ), (1, ))
    assert_size_stride(primals_667, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_668, (36, ), (1, ))
    assert_size_stride(primals_670, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_671, (36, ), (1, ))
    assert_size_stride(primals_673, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_674, (36, ), (1, ))
    assert_size_stride(primals_676, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_677, (72, ), (1, ))
    assert_size_stride(primals_679, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_680, (72, ), (1, ))
    assert_size_stride(primals_682, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_683, (72, ), (1, ))
    assert_size_stride(primals_685, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_686, (72, ), (1, ))
    assert_size_stride(primals_688, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_689, (72, ), (1, ))
    assert_size_stride(primals_691, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_692, (72, ), (1, ))
    assert_size_stride(primals_694, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_695, (72, ), (1, ))
    assert_size_stride(primals_697, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_698, (72, ), (1, ))
    assert_size_stride(primals_700, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_701, (144, ), (1, ))
    assert_size_stride(primals_703, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_704, (144, ), (1, ))
    assert_size_stride(primals_706, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_707, (144, ), (1, ))
    assert_size_stride(primals_709, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_710, (144, ), (1, ))
    assert_size_stride(primals_712, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_713, (144, ), (1, ))
    assert_size_stride(primals_715, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_716, (144, ), (1, ))
    assert_size_stride(primals_718, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_719, (144, ), (1, ))
    assert_size_stride(primals_721, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_722, (144, ), (1, ))
    assert_size_stride(primals_724, (18, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_725, (18, ), (1, ))
    assert_size_stride(primals_727, (18, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_728, (18, ), (1, ))
    assert_size_stride(primals_730, (18, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_731, (18, ), (1, ))
    assert_size_stride(primals_733, (36, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_734, (36, ), (1, ))
    assert_size_stride(primals_736, (36, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_737, (36, ), (1, ))
    assert_size_stride(primals_739, (36, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_740, (36, ), (1, ))
    assert_size_stride(primals_742, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_743, (18, ), (1, ))
    assert_size_stride(primals_745, (72, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_746, (72, ), (1, ))
    assert_size_stride(primals_748, (72, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_749, (72, ), (1, ))
    assert_size_stride(primals_751, (72, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_752, (72, ), (1, ))
    assert_size_stride(primals_754, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_755, (18, ), (1, ))
    assert_size_stride(primals_757, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_758, (18, ), (1, ))
    assert_size_stride(primals_760, (144, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_761, (144, ), (1, ))
    assert_size_stride(primals_763, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_764, (36, ), (1, ))
    assert_size_stride(primals_766, (144, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_767, (144, ), (1, ))
    assert_size_stride(primals_769, (144, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_770, (144, ), (1, ))
    assert_size_stride(primals_772, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_773, (18, ), (1, ))
    assert_size_stride(primals_775, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_776, (18, ), (1, ))
    assert_size_stride(primals_778, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_779, (18, ), (1, ))
    assert_size_stride(primals_781, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_782, (18, ), (1, ))
    assert_size_stride(primals_784, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_785, (18, ), (1, ))
    assert_size_stride(primals_787, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_788, (18, ), (1, ))
    assert_size_stride(primals_790, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_791, (18, ), (1, ))
    assert_size_stride(primals_793, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_794, (18, ), (1, ))
    assert_size_stride(primals_796, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_797, (36, ), (1, ))
    assert_size_stride(primals_799, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_800, (36, ), (1, ))
    assert_size_stride(primals_802, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_803, (36, ), (1, ))
    assert_size_stride(primals_805, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_806, (36, ), (1, ))
    assert_size_stride(primals_808, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_809, (36, ), (1, ))
    assert_size_stride(primals_811, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_812, (36, ), (1, ))
    assert_size_stride(primals_814, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_815, (36, ), (1, ))
    assert_size_stride(primals_817, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_818, (36, ), (1, ))
    assert_size_stride(primals_820, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_821, (72, ), (1, ))
    assert_size_stride(primals_823, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_824, (72, ), (1, ))
    assert_size_stride(primals_826, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_827, (72, ), (1, ))
    assert_size_stride(primals_829, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_830, (72, ), (1, ))
    assert_size_stride(primals_832, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_833, (72, ), (1, ))
    assert_size_stride(primals_835, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_836, (72, ), (1, ))
    assert_size_stride(primals_838, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_839, (72, ), (1, ))
    assert_size_stride(primals_841, (72, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_842, (72, ), (1, ))
    assert_size_stride(primals_844, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_845, (144, ), (1, ))
    assert_size_stride(primals_847, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_848, (144, ), (1, ))
    assert_size_stride(primals_850, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_851, (144, ), (1, ))
    assert_size_stride(primals_853, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_854, (144, ), (1, ))
    assert_size_stride(primals_856, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_857, (144, ), (1, ))
    assert_size_stride(primals_859, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_860, (144, ), (1, ))
    assert_size_stride(primals_862, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_863, (144, ), (1, ))
    assert_size_stride(primals_865, (144, 144, 3, 3), (1296, 9, 3, 1))
    assert_size_stride(primals_866, (144, ), (1, ))
    assert_size_stride(primals_868, (18, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_869, (18, ), (1, ))
    assert_size_stride(primals_871, (18, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_872, (18, ), (1, ))
    assert_size_stride(primals_874, (18, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_875, (18, ), (1, ))
    assert_size_stride(primals_877, (36, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_878, (36, ), (1, ))
    assert_size_stride(primals_880, (36, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_881, (36, ), (1, ))
    assert_size_stride(primals_883, (36, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_884, (36, ), (1, ))
    assert_size_stride(primals_886, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_887, (18, ), (1, ))
    assert_size_stride(primals_889, (72, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_890, (72, ), (1, ))
    assert_size_stride(primals_892, (72, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_893, (72, ), (1, ))
    assert_size_stride(primals_895, (72, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_896, (72, ), (1, ))
    assert_size_stride(primals_898, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_899, (18, ), (1, ))
    assert_size_stride(primals_901, (18, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_902, (18, ), (1, ))
    assert_size_stride(primals_904, (144, 18, 3, 3), (162, 9, 3, 1))
    assert_size_stride(primals_905, (144, ), (1, ))
    assert_size_stride(primals_907, (36, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_908, (36, ), (1, ))
    assert_size_stride(primals_910, (144, 36, 3, 3), (324, 9, 3, 1))
    assert_size_stride(primals_911, (144, ), (1, ))
    assert_size_stride(primals_913, (144, 72, 3, 3), (648, 9, 3, 1))
    assert_size_stride(primals_914, (144, ), (1, ))
    assert_size_stride(primals_916, (32, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(primals_917, (32, ), (1, ))
    assert_size_stride(primals_919, (32, 32, 3, 3), (288, 9, 3, 1))
    assert_size_stride(primals_920, (32, ), (1, ))
    assert_size_stride(primals_922, (128, 32, 1, 1), (32, 1, 1, 1))
    assert_size_stride(primals_923, (128, ), (1, ))
    assert_size_stride(primals_925, (128, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(primals_926, (128, ), (1, ))
    assert_size_stride(primals_928, (64, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_929, (64, ), (1, ))
    assert_size_stride(primals_931, (64, 64, 3, 3), (576, 9, 3, 1))
    assert_size_stride(primals_932, (64, ), (1, ))
    assert_size_stride(primals_934, (256, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(primals_935, (256, ), (1, ))
    assert_size_stride(primals_937, (256, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(primals_938, (256, ), (1, ))
    assert_size_stride(primals_940, (256, 128, 3, 3), (1152, 9, 3, 1))
    assert_size_stride(primals_942, (256, ), (1, ))
    assert_size_stride(primals_944, (128, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_945, (128, ), (1, ))
    assert_size_stride(primals_947, (128, 128, 3, 3), (1152, 9, 3, 1))
    assert_size_stride(primals_948, (128, ), (1, ))
    assert_size_stride(primals_950, (512, 128, 1, 1), (128, 1, 1, 1))
    assert_size_stride(primals_951, (512, ), (1, ))
    assert_size_stride(primals_953, (512, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(primals_954, (512, ), (1, ))
    assert_size_stride(primals_956, (512, 256, 3, 3), (2304, 9, 3, 1))
    assert_size_stride(primals_958, (512, ), (1, ))
    assert_size_stride(primals_960, (256, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_961, (256, ), (1, ))
    assert_size_stride(primals_963, (256, 256, 3, 3), (2304, 9, 3, 1))
    assert_size_stride(primals_964, (256, ), (1, ))
    assert_size_stride(primals_966, (1024, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(primals_967, (1024, ), (1, ))
    assert_size_stride(primals_969, (1024, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(primals_970, (1024, ), (1, ))
    assert_size_stride(primals_972, (1024, 512, 3, 3), (4608, 9, 3, 1))
    assert_size_stride(primals_974, (1024, ), (1, ))
    assert_size_stride(primals_976, (2048, 1024, 1, 1), (1024, 1, 1, 1))
    assert_size_stride(primals_978, (2048, ), (1, ))
    assert_size_stride(primals_1957, (8, 3, 224, 224), (150528, 50176, 224, 1))
    assert_size_stride(convolution, (8, 64, 112, 112), (802816, 12544, 112, 1))
    assert_size_stride(squeeze_1, (64, ), (1, ))
    assert_size_stride(relu, (8, 64, 112, 112), (802816, 12544, 112, 1))
    assert_size_stride(convolution_1, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(squeeze_4, (64, ), (1, ))
    assert_size_stride(relu_1, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(convolution_2, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(squeeze_7, (64, ), (1, ))
    assert_size_stride(relu_2, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(convolution_3, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(squeeze_10, (64, ), (1, ))
    assert_size_stride(relu_3, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(convolution_4, (8, 256, 56, 56), (802816, 3136, 56, 1))
    assert_size_stride(squeeze_13, (256, ), (1, ))
    assert_size_stride(convolution_5, (8, 256, 56, 56), (802816, 3136, 56, 1))
    assert_size_stride(squeeze_16, (256, ), (1, ))
    assert_size_stride(relu_4, (8, 256, 56, 56), (802816, 3136, 56, 1))
    assert_size_stride(convolution_6, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(squeeze_19, (64, ), (1, ))
    assert_size_stride(relu_5, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(convolution_7, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(squeeze_22, (64, ), (1, ))
    assert_size_stride(relu_6, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(convolution_8, (8, 256, 56, 56), (802816, 3136, 56, 1))
    assert_size_stride(squeeze_25, (256, ), (1, ))
    assert_size_stride(relu_7, (8, 256, 56, 56), (802816, 3136, 56, 1))
    assert_size_stride(convolution_9, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(squeeze_28, (64, ), (1, ))
    assert_size_stride(relu_8, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(convolution_10, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(squeeze_31, (64, ), (1, ))
    assert_size_stride(relu_9, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(convolution_11, (8, 256, 56, 56), (802816, 3136, 56, 1))
    assert_size_stride(squeeze_34, (256, ), (1, ))
    assert_size_stride(relu_10, (8, 256, 56, 56), (802816, 3136, 56, 1))
    assert_size_stride(convolution_12, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(squeeze_37, (64, ), (1, ))
    assert_size_stride(relu_11, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(convolution_13, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(squeeze_40, (64, ), (1, ))
    assert_size_stride(relu_12, (8, 64, 56, 56), (200704, 3136, 56, 1))
    assert_size_stride(convolution_14, (8, 256, 56, 56), (802816, 3136, 56, 1))
    assert_size_stride(squeeze_43, (256, ), (1, ))
    assert_size_stride(relu_13, (8, 256, 56, 56), (802816, 3136, 56, 1))
    assert_size_stride(convolution_15, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_46, (18, ), (1, ))
    assert_size_stride(relu_14, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_16, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_49, (36, ), (1, ))
    assert_size_stride(relu_15, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_17, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_52, (18, ), (1, ))
    assert_size_stride(relu_16, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_18, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_55, (18, ), (1, ))
    assert_size_stride(relu_17, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_19, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_58, (18, ), (1, ))
    assert_size_stride(relu_18, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_20, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_61, (18, ), (1, ))
    assert_size_stride(relu_19, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_21, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_64, (18, ), (1, ))
    assert_size_stride(relu_20, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_22, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_67, (18, ), (1, ))
    assert_size_stride(relu_21, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_23, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_70, (18, ), (1, ))
    assert_size_stride(relu_22, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_24, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_73, (18, ), (1, ))
    assert_size_stride(relu_23, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_25, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_76, (36, ), (1, ))
    assert_size_stride(relu_24, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_26, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_79, (36, ), (1, ))
    assert_size_stride(relu_25, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_27, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_82, (36, ), (1, ))
    assert_size_stride(relu_26, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_28, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_85, (36, ), (1, ))
    assert_size_stride(relu_27, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_29, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_88, (36, ), (1, ))
    assert_size_stride(relu_28, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_30, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_91, (36, ), (1, ))
    assert_size_stride(relu_29, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_31, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_94, (36, ), (1, ))
    assert_size_stride(relu_30, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_32, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_97, (36, ), (1, ))
    assert_size_stride(relu_31, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_33, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_100, (18, ), (1, ))
    assert_size_stride(convert_element_type_1, (56, ), (1, ))
    assert_size_stride(unsqueeze_136, (56, 1), (1, 1))
    assert_size_stride(relu_32, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_34, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_103, (36, ), (1, ))
    assert_size_stride(relu_33, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_35, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_106, (72, ), (1, ))
    assert_size_stride(relu_34, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_36, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_109, (18, ), (1, ))
    assert_size_stride(relu_35, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_37, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_112, (18, ), (1, ))
    assert_size_stride(relu_36, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_38, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_115, (18, ), (1, ))
    assert_size_stride(relu_37, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_39, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_118, (18, ), (1, ))
    assert_size_stride(relu_38, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_40, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_121, (18, ), (1, ))
    assert_size_stride(relu_39, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_41, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_124, (18, ), (1, ))
    assert_size_stride(relu_40, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_42, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_127, (18, ), (1, ))
    assert_size_stride(relu_41, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_43, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_130, (18, ), (1, ))
    assert_size_stride(relu_42, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_44, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_133, (36, ), (1, ))
    assert_size_stride(relu_43, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_45, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_136, (36, ), (1, ))
    assert_size_stride(relu_44, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_46, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_139, (36, ), (1, ))
    assert_size_stride(relu_45, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_47, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_142, (36, ), (1, ))
    assert_size_stride(relu_46, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_48, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_145, (36, ), (1, ))
    assert_size_stride(relu_47, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_49, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_148, (36, ), (1, ))
    assert_size_stride(relu_48, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_50, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_151, (36, ), (1, ))
    assert_size_stride(relu_49, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_51, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_154, (36, ), (1, ))
    assert_size_stride(relu_50, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_52, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_157, (72, ), (1, ))
    assert_size_stride(relu_51, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_53, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_160, (72, ), (1, ))
    assert_size_stride(relu_52, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_54, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_163, (72, ), (1, ))
    assert_size_stride(relu_53, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_55, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_166, (72, ), (1, ))
    assert_size_stride(relu_54, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_56, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_169, (72, ), (1, ))
    assert_size_stride(relu_55, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_57, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_172, (72, ), (1, ))
    assert_size_stride(relu_56, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_58, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_175, (72, ), (1, ))
    assert_size_stride(relu_57, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_59, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_178, (72, ), (1, ))
    assert_size_stride(relu_58, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_60, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_181, (18, ), (1, ))
    assert_size_stride(convolution_61, (8, 18, 14, 14), (3528, 196, 14, 1))
    assert_size_stride(squeeze_184, (18, ), (1, ))
    assert_size_stride(convert_element_type_9, (56, ), (1, ))
    assert_size_stride(unsqueeze_250, (56, 1), (1, 1))
    assert_size_stride(relu_59, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_62, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_187, (36, ), (1, ))
    assert_size_stride(convolution_63, (8, 36, 14, 14), (7056, 196, 14, 1))
    assert_size_stride(squeeze_190, (36, ), (1, ))
    assert_size_stride(convert_element_type_13, (28, ), (1, ))
    assert_size_stride(unsqueeze_259, (28, 1), (1, 1))
    assert_size_stride(relu_60, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_64, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_193, (18, ), (1, ))
    assert_size_stride(relu_61, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(convolution_65, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_196, (72, ), (1, ))
    assert_size_stride(convolution_66, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_199, (72, ), (1, ))
    assert_size_stride(relu_62, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_67, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_202, (18, ), (1, ))
    assert_size_stride(relu_63, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_68, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_205, (18, ), (1, ))
    assert_size_stride(relu_64, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_69, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_208, (18, ), (1, ))
    assert_size_stride(relu_65, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_70, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_211, (18, ), (1, ))
    assert_size_stride(relu_66, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_71, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_214, (18, ), (1, ))
    assert_size_stride(relu_67, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_72, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_217, (18, ), (1, ))
    assert_size_stride(relu_68, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_73, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_220, (18, ), (1, ))
    assert_size_stride(relu_69, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_74, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_223, (18, ), (1, ))
    assert_size_stride(relu_70, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_75, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_226, (36, ), (1, ))
    assert_size_stride(relu_71, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_76, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_229, (36, ), (1, ))
    assert_size_stride(relu_72, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_77, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_232, (36, ), (1, ))
    assert_size_stride(relu_73, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_78, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_235, (36, ), (1, ))
    assert_size_stride(relu_74, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_79, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_238, (36, ), (1, ))
    assert_size_stride(relu_75, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_80, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_241, (36, ), (1, ))
    assert_size_stride(relu_76, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_81, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_244, (36, ), (1, ))
    assert_size_stride(relu_77, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_82, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_247, (36, ), (1, ))
    assert_size_stride(relu_78, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_83, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_250, (72, ), (1, ))
    assert_size_stride(relu_79, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_84, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_253, (72, ), (1, ))
    assert_size_stride(relu_80, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_85, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_256, (72, ), (1, ))
    assert_size_stride(relu_81, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_86, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_259, (72, ), (1, ))
    assert_size_stride(relu_82, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_87, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_262, (72, ), (1, ))
    assert_size_stride(relu_83, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_88, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_265, (72, ), (1, ))
    assert_size_stride(relu_84, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_89, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_268, (72, ), (1, ))
    assert_size_stride(relu_85, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_90, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_271, (72, ), (1, ))
    assert_size_stride(relu_86, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_91, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_274, (18, ), (1, ))
    assert_size_stride(convolution_92, (8, 18, 14, 14), (3528, 196, 14, 1))
    assert_size_stride(squeeze_277, (18, ), (1, ))
    assert_size_stride(relu_87, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_93, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_280, (36, ), (1, ))
    assert_size_stride(convolution_94, (8, 36, 14, 14), (7056, 196, 14, 1))
    assert_size_stride(squeeze_283, (36, ), (1, ))
    assert_size_stride(relu_88, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_95, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_286, (18, ), (1, ))
    assert_size_stride(relu_89, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(convolution_96, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_289, (72, ), (1, ))
    assert_size_stride(convolution_97, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_292, (72, ), (1, ))
    assert_size_stride(relu_90, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_98, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_295, (18, ), (1, ))
    assert_size_stride(relu_91, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_99, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_298, (18, ), (1, ))
    assert_size_stride(relu_92, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_100, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_301, (18, ), (1, ))
    assert_size_stride(relu_93, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_101, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_304, (18, ), (1, ))
    assert_size_stride(relu_94, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_102, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_307, (18, ), (1, ))
    assert_size_stride(relu_95, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_103, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_310, (18, ), (1, ))
    assert_size_stride(relu_96, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_104, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_313, (18, ), (1, ))
    assert_size_stride(relu_97, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_105, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_316, (18, ), (1, ))
    assert_size_stride(relu_98, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_106, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_319, (36, ), (1, ))
    assert_size_stride(relu_99, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_107, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_322, (36, ), (1, ))
    assert_size_stride(relu_100, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_108, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_325, (36, ), (1, ))
    assert_size_stride(relu_101, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_109, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_328, (36, ), (1, ))
    assert_size_stride(relu_102, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_110, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_331, (36, ), (1, ))
    assert_size_stride(relu_103, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_111, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_334, (36, ), (1, ))
    assert_size_stride(relu_104, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_112, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_337, (36, ), (1, ))
    assert_size_stride(relu_105, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_113, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_340, (36, ), (1, ))
    assert_size_stride(relu_106, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_114, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_343, (72, ), (1, ))
    assert_size_stride(relu_107, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_115, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_346, (72, ), (1, ))
    assert_size_stride(relu_108, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_116, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_349, (72, ), (1, ))
    assert_size_stride(relu_109, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_117, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_352, (72, ), (1, ))
    assert_size_stride(relu_110, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_118, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_355, (72, ), (1, ))
    assert_size_stride(relu_111, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_119, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_358, (72, ), (1, ))
    assert_size_stride(relu_112, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_120, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_361, (72, ), (1, ))
    assert_size_stride(relu_113, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_121, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_364, (72, ), (1, ))
    assert_size_stride(relu_114, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_122, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_367, (18, ), (1, ))
    assert_size_stride(convolution_123, (8, 18, 14, 14), (3528, 196, 14, 1))
    assert_size_stride(squeeze_370, (18, ), (1, ))
    assert_size_stride(relu_115, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_124, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_373, (36, ), (1, ))
    assert_size_stride(convolution_125, (8, 36, 14, 14), (7056, 196, 14, 1))
    assert_size_stride(squeeze_376, (36, ), (1, ))
    assert_size_stride(relu_116, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_126, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_379, (18, ), (1, ))
    assert_size_stride(relu_117, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(convolution_127, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_382, (72, ), (1, ))
    assert_size_stride(convolution_128, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_385, (72, ), (1, ))
    assert_size_stride(relu_118, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_129, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_388, (18, ), (1, ))
    assert_size_stride(relu_119, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_130, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_391, (18, ), (1, ))
    assert_size_stride(relu_120, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_131, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_394, (18, ), (1, ))
    assert_size_stride(relu_121, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_132, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_397, (18, ), (1, ))
    assert_size_stride(relu_122, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_133, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_400, (18, ), (1, ))
    assert_size_stride(relu_123, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_134, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_403, (18, ), (1, ))
    assert_size_stride(relu_124, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_135, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_406, (18, ), (1, ))
    assert_size_stride(relu_125, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_136, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_409, (18, ), (1, ))
    assert_size_stride(relu_126, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_137, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_412, (36, ), (1, ))
    assert_size_stride(relu_127, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_138, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_415, (36, ), (1, ))
    assert_size_stride(relu_128, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_139, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_418, (36, ), (1, ))
    assert_size_stride(relu_129, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_140, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_421, (36, ), (1, ))
    assert_size_stride(relu_130, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_141, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_424, (36, ), (1, ))
    assert_size_stride(relu_131, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_142, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_427, (36, ), (1, ))
    assert_size_stride(relu_132, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_143, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_430, (36, ), (1, ))
    assert_size_stride(relu_133, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_144, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_433, (36, ), (1, ))
    assert_size_stride(relu_134, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_145, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_436, (72, ), (1, ))
    assert_size_stride(relu_135, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_146, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_439, (72, ), (1, ))
    assert_size_stride(relu_136, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_147, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_442, (72, ), (1, ))
    assert_size_stride(relu_137, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_148, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_445, (72, ), (1, ))
    assert_size_stride(relu_138, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_149, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_448, (72, ), (1, ))
    assert_size_stride(relu_139, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_150, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_451, (72, ), (1, ))
    assert_size_stride(relu_140, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_151, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_454, (72, ), (1, ))
    assert_size_stride(relu_141, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_152, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_457, (72, ), (1, ))
    assert_size_stride(relu_142, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_153, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_460, (18, ), (1, ))
    assert_size_stride(convolution_154, (8, 18, 14, 14), (3528, 196, 14, 1))
    assert_size_stride(squeeze_463, (18, ), (1, ))
    assert_size_stride(relu_143, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_155, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_466, (36, ), (1, ))
    assert_size_stride(convolution_156, (8, 36, 14, 14), (7056, 196, 14, 1))
    assert_size_stride(squeeze_469, (36, ), (1, ))
    assert_size_stride(relu_144, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_157, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_472, (18, ), (1, ))
    assert_size_stride(relu_145, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(convolution_158, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_475, (72, ), (1, ))
    assert_size_stride(convolution_159, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_478, (72, ), (1, ))
    assert_size_stride(relu_146, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_160, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_481, (144, ), (1, ))
    assert_size_stride(relu_147, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_161, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_484, (18, ), (1, ))
    assert_size_stride(relu_148, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_162, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_487, (18, ), (1, ))
    assert_size_stride(relu_149, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_163, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_490, (18, ), (1, ))
    assert_size_stride(relu_150, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_164, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_493, (18, ), (1, ))
    assert_size_stride(relu_151, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_165, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_496, (18, ), (1, ))
    assert_size_stride(relu_152, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_166, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_499, (18, ), (1, ))
    assert_size_stride(relu_153, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_167, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_502, (18, ), (1, ))
    assert_size_stride(relu_154, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_168, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_505, (18, ), (1, ))
    assert_size_stride(relu_155, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_169, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_508, (36, ), (1, ))
    assert_size_stride(relu_156, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_170, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_511, (36, ), (1, ))
    assert_size_stride(relu_157, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_171, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_514, (36, ), (1, ))
    assert_size_stride(relu_158, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_172, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_517, (36, ), (1, ))
    assert_size_stride(relu_159, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_173, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_520, (36, ), (1, ))
    assert_size_stride(relu_160, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_174, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_523, (36, ), (1, ))
    assert_size_stride(relu_161, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_175, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_526, (36, ), (1, ))
    assert_size_stride(relu_162, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_176, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_529, (36, ), (1, ))
    assert_size_stride(relu_163, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_177, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_532, (72, ), (1, ))
    assert_size_stride(relu_164, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_178, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_535, (72, ), (1, ))
    assert_size_stride(relu_165, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_179, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_538, (72, ), (1, ))
    assert_size_stride(relu_166, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_180, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_541, (72, ), (1, ))
    assert_size_stride(relu_167, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_181, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_544, (72, ), (1, ))
    assert_size_stride(relu_168, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_182, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_547, (72, ), (1, ))
    assert_size_stride(relu_169, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_183, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_550, (72, ), (1, ))
    assert_size_stride(relu_170, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_184, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_553, (72, ), (1, ))
    assert_size_stride(relu_171, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_185, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_556, (144, ), (1, ))
    assert_size_stride(relu_172, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_186, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_559, (144, ), (1, ))
    assert_size_stride(relu_173, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_187, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_562, (144, ), (1, ))
    assert_size_stride(relu_174, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_188, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_565, (144, ), (1, ))
    assert_size_stride(relu_175, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_189, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_568, (144, ), (1, ))
    assert_size_stride(relu_176, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_190, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_571, (144, ), (1, ))
    assert_size_stride(relu_177, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_191, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_574, (144, ), (1, ))
    assert_size_stride(relu_178, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_192, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_577, (144, ), (1, ))
    assert_size_stride(relu_179, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_193, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_580, (18, ), (1, ))
    assert_size_stride(convolution_194, (8, 18, 14, 14), (3528, 196, 14, 1))
    assert_size_stride(squeeze_583, (18, ), (1, ))
    assert_size_stride(convolution_195, (8, 18, 7, 7), (882, 49, 7, 1))
    assert_size_stride(squeeze_586, (18, ), (1, ))
    assert_size_stride(convert_element_type_61, (56, ), (1, ))
    assert_size_stride(unsqueeze_799, (56, 1), (1, 1))
    assert_size_stride(relu_180, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_196, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_589, (36, ), (1, ))
    assert_size_stride(convolution_197, (8, 36, 14, 14), (7056, 196, 14, 1))
    assert_size_stride(squeeze_592, (36, ), (1, ))
    assert_size_stride(convolution_198, (8, 36, 7, 7), (1764, 49, 7, 1))
    assert_size_stride(squeeze_595, (36, ), (1, ))
    assert_size_stride(convert_element_type_69, (28, ), (1, ))
    assert_size_stride(unsqueeze_813, (28, 1), (1, 1))
    assert_size_stride(relu_181, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_199, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_598, (18, ), (1, ))
    assert_size_stride(relu_182, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(convolution_200, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_601, (72, ), (1, ))
    assert_size_stride(convolution_201, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_604, (72, ), (1, ))
    assert_size_stride(convolution_202, (8, 72, 7, 7), (3528, 49, 7, 1))
    assert_size_stride(squeeze_607, (72, ), (1, ))
    assert_size_stride(convert_element_type_73, (14, ), (1, ))
    assert_size_stride(unsqueeze_830, (14, 1), (1, 1))
    assert_size_stride(relu_183, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_203, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_610, (18, ), (1, ))
    assert_size_stride(relu_184, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(convolution_204, (8, 18, 14, 14), (3528, 196, 14, 1))
    assert_size_stride(squeeze_613, (18, ), (1, ))
    assert_size_stride(relu_185, (8, 18, 14, 14), (3528, 196, 14, 1))
    assert_size_stride(convolution_205, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_616, (144, ), (1, ))
    assert_size_stride(convolution_206, (8, 36, 14, 14), (7056, 196, 14, 1))
    assert_size_stride(squeeze_619, (36, ), (1, ))
    assert_size_stride(relu_186, (8, 36, 14, 14), (7056, 196, 14, 1))
    assert_size_stride(convolution_207, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_622, (144, ), (1, ))
    assert_size_stride(convolution_208, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_625, (144, ), (1, ))
    assert_size_stride(relu_187, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_209, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_628, (18, ), (1, ))
    assert_size_stride(relu_188, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_210, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_631, (18, ), (1, ))
    assert_size_stride(relu_189, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_211, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_634, (18, ), (1, ))
    assert_size_stride(relu_190, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_212, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_637, (18, ), (1, ))
    assert_size_stride(relu_191, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_213, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_640, (18, ), (1, ))
    assert_size_stride(relu_192, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_214, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_643, (18, ), (1, ))
    assert_size_stride(relu_193, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_215, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_646, (18, ), (1, ))
    assert_size_stride(relu_194, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_216, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_649, (18, ), (1, ))
    assert_size_stride(relu_195, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_217, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_652, (36, ), (1, ))
    assert_size_stride(relu_196, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_218, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_655, (36, ), (1, ))
    assert_size_stride(relu_197, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_219, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_658, (36, ), (1, ))
    assert_size_stride(relu_198, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_220, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_661, (36, ), (1, ))
    assert_size_stride(relu_199, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_221, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_664, (36, ), (1, ))
    assert_size_stride(relu_200, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_222, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_667, (36, ), (1, ))
    assert_size_stride(relu_201, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_223, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_670, (36, ), (1, ))
    assert_size_stride(relu_202, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_224, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_673, (36, ), (1, ))
    assert_size_stride(relu_203, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_225, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_676, (72, ), (1, ))
    assert_size_stride(relu_204, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_226, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_679, (72, ), (1, ))
    assert_size_stride(relu_205, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_227, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_682, (72, ), (1, ))
    assert_size_stride(relu_206, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_228, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_685, (72, ), (1, ))
    assert_size_stride(relu_207, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_229, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_688, (72, ), (1, ))
    assert_size_stride(relu_208, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_230, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_691, (72, ), (1, ))
    assert_size_stride(relu_209, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_231, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_694, (72, ), (1, ))
    assert_size_stride(relu_210, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_232, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_697, (72, ), (1, ))
    assert_size_stride(relu_211, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_233, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_700, (144, ), (1, ))
    assert_size_stride(relu_212, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_234, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_703, (144, ), (1, ))
    assert_size_stride(relu_213, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_235, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_706, (144, ), (1, ))
    assert_size_stride(relu_214, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_236, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_709, (144, ), (1, ))
    assert_size_stride(relu_215, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_237, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_712, (144, ), (1, ))
    assert_size_stride(relu_216, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_238, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_715, (144, ), (1, ))
    assert_size_stride(relu_217, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_239, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_718, (144, ), (1, ))
    assert_size_stride(relu_218, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_240, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_721, (144, ), (1, ))
    assert_size_stride(relu_219, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_241, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_724, (18, ), (1, ))
    assert_size_stride(convolution_242, (8, 18, 14, 14), (3528, 196, 14, 1))
    assert_size_stride(squeeze_727, (18, ), (1, ))
    assert_size_stride(convolution_243, (8, 18, 7, 7), (882, 49, 7, 1))
    assert_size_stride(squeeze_730, (18, ), (1, ))
    assert_size_stride(relu_220, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_244, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_733, (36, ), (1, ))
    assert_size_stride(convolution_245, (8, 36, 14, 14), (7056, 196, 14, 1))
    assert_size_stride(squeeze_736, (36, ), (1, ))
    assert_size_stride(convolution_246, (8, 36, 7, 7), (1764, 49, 7, 1))
    assert_size_stride(squeeze_739, (36, ), (1, ))
    assert_size_stride(relu_221, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_247, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_742, (18, ), (1, ))
    assert_size_stride(relu_222, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(convolution_248, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_745, (72, ), (1, ))
    assert_size_stride(convolution_249, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_748, (72, ), (1, ))
    assert_size_stride(convolution_250, (8, 72, 7, 7), (3528, 49, 7, 1))
    assert_size_stride(squeeze_751, (72, ), (1, ))
    assert_size_stride(relu_223, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_251, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_754, (18, ), (1, ))
    assert_size_stride(relu_224, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(convolution_252, (8, 18, 14, 14), (3528, 196, 14, 1))
    assert_size_stride(squeeze_757, (18, ), (1, ))
    assert_size_stride(relu_225, (8, 18, 14, 14), (3528, 196, 14, 1))
    assert_size_stride(convolution_253, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_760, (144, ), (1, ))
    assert_size_stride(convolution_254, (8, 36, 14, 14), (7056, 196, 14, 1))
    assert_size_stride(squeeze_763, (36, ), (1, ))
    assert_size_stride(relu_226, (8, 36, 14, 14), (7056, 196, 14, 1))
    assert_size_stride(convolution_255, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_766, (144, ), (1, ))
    assert_size_stride(convolution_256, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_769, (144, ), (1, ))
    assert_size_stride(relu_227, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_257, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_772, (18, ), (1, ))
    assert_size_stride(relu_228, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_258, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_775, (18, ), (1, ))
    assert_size_stride(relu_229, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_259, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_778, (18, ), (1, ))
    assert_size_stride(relu_230, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_260, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_781, (18, ), (1, ))
    assert_size_stride(relu_231, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_261, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_784, (18, ), (1, ))
    assert_size_stride(relu_232, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_262, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_787, (18, ), (1, ))
    assert_size_stride(relu_233, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_263, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_790, (18, ), (1, ))
    assert_size_stride(relu_234, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_264, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(squeeze_793, (18, ), (1, ))
    assert_size_stride(relu_235, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_265, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_796, (36, ), (1, ))
    assert_size_stride(relu_236, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_266, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_799, (36, ), (1, ))
    assert_size_stride(relu_237, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_267, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_802, (36, ), (1, ))
    assert_size_stride(relu_238, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_268, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_805, (36, ), (1, ))
    assert_size_stride(relu_239, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_269, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_808, (36, ), (1, ))
    assert_size_stride(relu_240, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_270, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_811, (36, ), (1, ))
    assert_size_stride(relu_241, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_271, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_814, (36, ), (1, ))
    assert_size_stride(relu_242, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_272, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_817, (36, ), (1, ))
    assert_size_stride(relu_243, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_273, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_820, (72, ), (1, ))
    assert_size_stride(relu_244, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_274, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_823, (72, ), (1, ))
    assert_size_stride(relu_245, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_275, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_826, (72, ), (1, ))
    assert_size_stride(relu_246, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_276, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_829, (72, ), (1, ))
    assert_size_stride(relu_247, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_277, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_832, (72, ), (1, ))
    assert_size_stride(relu_248, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_278, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_835, (72, ), (1, ))
    assert_size_stride(relu_249, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_279, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_838, (72, ), (1, ))
    assert_size_stride(relu_250, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_280, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_841, (72, ), (1, ))
    assert_size_stride(relu_251, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_281, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_844, (144, ), (1, ))
    assert_size_stride(relu_252, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_282, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_847, (144, ), (1, ))
    assert_size_stride(relu_253, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_283, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_850, (144, ), (1, ))
    assert_size_stride(relu_254, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_284, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_853, (144, ), (1, ))
    assert_size_stride(relu_255, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_285, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_856, (144, ), (1, ))
    assert_size_stride(relu_256, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_286, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_859, (144, ), (1, ))
    assert_size_stride(relu_257, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_287, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_862, (144, ), (1, ))
    assert_size_stride(relu_258, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_288, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_865, (144, ), (1, ))
    assert_size_stride(relu_259, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_289, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_868, (18, ), (1, ))
    assert_size_stride(convolution_290, (8, 18, 14, 14), (3528, 196, 14, 1))
    assert_size_stride(squeeze_871, (18, ), (1, ))
    assert_size_stride(convolution_291, (8, 18, 7, 7), (882, 49, 7, 1))
    assert_size_stride(squeeze_874, (18, ), (1, ))
    assert_size_stride(relu_260, (8, 18, 56, 56), (56448, 3136, 56, 1))
    assert_size_stride(convolution_292, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(squeeze_877, (36, ), (1, ))
    assert_size_stride(convolution_293, (8, 36, 14, 14), (7056, 196, 14, 1))
    assert_size_stride(squeeze_880, (36, ), (1, ))
    assert_size_stride(convolution_294, (8, 36, 7, 7), (1764, 49, 7, 1))
    assert_size_stride(squeeze_883, (36, ), (1, ))
    assert_size_stride(relu_261, (8, 36, 28, 28), (28224, 784, 28, 1))
    assert_size_stride(convolution_295, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_886, (18, ), (1, ))
    assert_size_stride(relu_262, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(convolution_296, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_889, (72, ), (1, ))
    assert_size_stride(convolution_297, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(squeeze_892, (72, ), (1, ))
    assert_size_stride(convolution_298, (8, 72, 7, 7), (3528, 49, 7, 1))
    assert_size_stride(squeeze_895, (72, ), (1, ))
    assert_size_stride(relu_263, (8, 72, 14, 14), (14112, 196, 14, 1))
    assert_size_stride(convolution_299, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(squeeze_898, (18, ), (1, ))
    assert_size_stride(relu_264, (8, 18, 28, 28), (14112, 784, 28, 1))
    assert_size_stride(convolution_300, (8, 18, 14, 14), (3528, 196, 14, 1))
    assert_size_stride(squeeze_901, (18, ), (1, ))
    assert_size_stride(relu_265, (8, 18, 14, 14), (3528, 196, 14, 1))
    assert_size_stride(convolution_301, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_904, (144, ), (1, ))
    assert_size_stride(convolution_302, (8, 36, 14, 14), (7056, 196, 14, 1))
    assert_size_stride(squeeze_907, (36, ), (1, ))
    assert_size_stride(relu_266, (8, 36, 14, 14), (7056, 196, 14, 1))
    assert_size_stride(convolution_303, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_910, (144, ), (1, ))
    assert_size_stride(convolution_304, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(squeeze_913, (144, ), (1, ))
    assert_size_stride(relu_267, (8, 144, 7, 7), (7056, 49, 7, 1))
    assert_size_stride(convolution_305, (8, 32, 56, 56), (100352, 3136, 56, 1))
    assert_size_stride(squeeze_916, (32, ), (1, ))
    assert_size_stride(relu_268, (8, 32, 56, 56), (100352, 3136, 56, 1))
    assert_size_stride(convolution_306, (8, 32, 56, 56), (100352, 3136, 56, 1))
    assert_size_stride(squeeze_919, (32, ), (1, ))
    assert_size_stride(relu_269, (8, 32, 56, 56), (100352, 3136, 56, 1))
    assert_size_stride(convolution_307, (8, 128, 56, 56), (401408, 3136, 56, 1))
    assert_size_stride(squeeze_922, (128, ), (1, ))
    assert_size_stride(convolution_308, (8, 128, 56, 56), (401408, 3136, 56, 1))
    assert_size_stride(squeeze_925, (128, ), (1, ))
    assert_size_stride(relu_270, (8, 128, 56, 56), (401408, 3136, 56, 1))
    assert_size_stride(convolution_309, (8, 64, 28, 28), (50176, 784, 28, 1))
    assert_size_stride(squeeze_928, (64, ), (1, ))
    assert_size_stride(relu_271, (8, 64, 28, 28), (50176, 784, 28, 1))
    assert_size_stride(convolution_310, (8, 64, 28, 28), (50176, 784, 28, 1))
    assert_size_stride(squeeze_931, (64, ), (1, ))
    assert_size_stride(relu_272, (8, 64, 28, 28), (50176, 784, 28, 1))
    assert_size_stride(convolution_311, (8, 256, 28, 28), (200704, 784, 28, 1))
    assert_size_stride(squeeze_934, (256, ), (1, ))
    assert_size_stride(convolution_312, (8, 256, 28, 28), (200704, 784, 28, 1))
    assert_size_stride(squeeze_937, (256, ), (1, ))
    assert_size_stride(convolution_313, (8, 256, 28, 28), (200704, 784, 28, 1))
    assert_size_stride(squeeze_940, (256, ), (1, ))
    assert_size_stride(add_1866, (8, 256, 28, 28), (200704, 784, 28, 1))
    assert_size_stride(convolution_314, (8, 128, 14, 14), (25088, 196, 14, 1))
    assert_size_stride(squeeze_943, (128, ), (1, ))
    assert_size_stride(relu_275, (8, 128, 14, 14), (25088, 196, 14, 1))
    assert_size_stride(convolution_315, (8, 128, 14, 14), (25088, 196, 14, 1))
    assert_size_stride(squeeze_946, (128, ), (1, ))
    assert_size_stride(relu_276, (8, 128, 14, 14), (25088, 196, 14, 1))
    assert_size_stride(convolution_316, (8, 512, 14, 14), (100352, 196, 14, 1))
    assert_size_stride(squeeze_949, (512, ), (1, ))
    assert_size_stride(convolution_317, (8, 512, 14, 14), (100352, 196, 14, 1))
    assert_size_stride(squeeze_952, (512, ), (1, ))
    assert_size_stride(convolution_318, (8, 512, 14, 14), (100352, 196, 14, 1))
    assert_size_stride(squeeze_955, (512, ), (1, ))
    assert_size_stride(add_1893, (8, 512, 14, 14), (100352, 196, 14, 1))
    assert_size_stride(convolution_319, (8, 256, 7, 7), (12544, 49, 7, 1))
    assert_size_stride(squeeze_958, (256, ), (1, ))
    assert_size_stride(relu_279, (8, 256, 7, 7), (12544, 49, 7, 1))
    assert_size_stride(convolution_320, (8, 256, 7, 7), (12544, 49, 7, 1))
    assert_size_stride(squeeze_961, (256, ), (1, ))
    assert_size_stride(relu_280, (8, 256, 7, 7), (12544, 49, 7, 1))
    assert_size_stride(convolution_321, (8, 1024, 7, 7), (50176, 49, 7, 1))
    assert_size_stride(squeeze_964, (1024, ), (1, ))
    assert_size_stride(convolution_322, (8, 1024, 7, 7), (50176, 49, 7, 1))
    assert_size_stride(squeeze_967, (1024, ), (1, ))
    assert_size_stride(convolution_323, (8, 1024, 7, 7), (50176, 49, 7, 1))
    assert_size_stride(squeeze_970, (1024, ), (1, ))
    assert_size_stride(add_1920, (8, 1024, 7, 7), (50176, 49, 7, 1))
    assert_size_stride(convolution_324, (8, 2048, 7, 7), (100352, 49, 7, 1))
    assert_size_stride(squeeze_973, (2048, ), (1, ))
    assert_size_stride(clone, (8, 2048), (2048, 1))
    assert_size_stride(permute_1, (1000, 2048), (2048, 1))
    assert_size_stride(le, (8, 2048, 7, 7), (100352, 49, 7, 1))
    assert_size_stride(unsqueeze_1333, (1, 2048, 1, 1), (2048, 1, 1, 1))
    assert_size_stride(le_1, (8, 1024, 7, 7), (50176, 49, 7, 1))
    assert_size_stride(unsqueeze_1345, (1, 1024, 1, 1), (1024, 1, 1, 1))
    assert_size_stride(le_2, (8, 1024, 7, 7), (50176, 49, 7, 1))
    assert_size_stride(unsqueeze_1357, (1, 1024, 1, 1), (1024, 1, 1, 1))
    assert_size_stride(unsqueeze_1369, (1, 1024, 1, 1), (1024, 1, 1, 1))
    assert_size_stride(unsqueeze_1381, (1, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(unsqueeze_1393, (1, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(le_5, (8, 512, 14, 14), (100352, 196, 14, 1))
    assert_size_stride(unsqueeze_1405, (1, 512, 1, 1), (512, 1, 1, 1))
    assert_size_stride(le_6, (8, 512, 14, 14), (100352, 196, 14, 1))
    assert_size_stride(unsqueeze_1417, (1, 512, 1, 1), (512, 1, 1, 1))
    assert_size_stride(unsqueeze_1429, (1, 512, 1, 1), (512, 1, 1, 1))
    assert_size_stride(unsqueeze_1441, (1, 128, 1, 1), (128, 1, 1, 1))
    assert_size_stride(unsqueeze_1453, (1, 128, 1, 1), (128, 1, 1, 1))
    assert_size_stride(le_9, (8, 256, 28, 28), (200704, 784, 28, 1))
    assert_size_stride(unsqueeze_1465, (1, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(le_10, (8, 256, 28, 28), (200704, 784, 28, 1))
    assert_size_stride(unsqueeze_1477, (1, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(unsqueeze_1489, (1, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(unsqueeze_1501, (1, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(unsqueeze_1513, (1, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(unsqueeze_1525, (1, 128, 1, 1), (128, 1, 1, 1))
    assert_size_stride(unsqueeze_1537, (1, 128, 1, 1), (128, 1, 1, 1))
    assert_size_stride(unsqueeze_1549, (1, 32, 1, 1), (32, 1, 1, 1))
    assert_size_stride(unsqueeze_1561, (1, 32, 1, 1), (32, 1, 1, 1))
    assert_size_stride(unsqueeze_1573, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_1585, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_1597, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_1609, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_1621, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_1633, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_1645, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_1657, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_1669, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_1681, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_1693, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_1705, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_1717, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_1729, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_1741, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_1753, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_1765, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_1777, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_1789, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_1801, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_1813, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_1825, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_1837, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_1849, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_1861, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_1873, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_1885, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_1897, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_1909, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_1921, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_1933, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_1945, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_1957, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_1969, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_1981, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_1993, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2005, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2017, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2029, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2041, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2053, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2065, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2077, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2089, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2101, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2113, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2125, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2137, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2149, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2161, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2173, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2185, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2197, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2209, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2221, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_2233, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_2245, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_2257, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2269, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2281, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2293, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2305, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2317, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2329, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2341, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2353, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2365, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2377, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2389, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2401, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2413, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2425, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2437, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_2449, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_2461, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_2473, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_2485, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_2497, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_2509, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_2521, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_2533, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2545, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2557, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2569, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2581, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2593, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2605, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2617, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2629, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2641, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2653, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2665, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2677, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2689, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2701, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2713, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2725, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2737, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2749, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2761, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2773, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2785, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2797, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_2809, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_2821, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_2833, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2845, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2857, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2869, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_2881, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2893, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2905, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_2917, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2929, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2941, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2953, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2965, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2977, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_2989, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_3001, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_3013, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3025, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3037, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3049, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3061, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3073, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3085, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3097, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3109, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3121, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3133, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3145, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3157, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3169, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3181, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3193, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3205, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3217, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3229, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3241, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3253, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3265, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3277, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3289, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3301, (1, 144, 1, 1), (144, 1, 1, 1))
    assert_size_stride(unsqueeze_3313, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3325, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3337, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3349, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3361, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3373, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3385, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3397, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3409, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3421, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3433, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3445, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3457, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3469, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3481, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3493, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3505, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3517, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3529, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3541, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3553, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3565, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3577, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3589, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3601, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3613, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3625, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3637, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3649, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3661, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3673, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3685, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3697, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3709, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3721, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3733, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3745, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3757, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3769, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3781, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3793, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3805, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3817, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3829, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3841, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3853, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_3865, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3877, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3889, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3901, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3913, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3925, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3937, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3949, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_3961, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3973, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3985, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_3997, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4009, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4021, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4033, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4045, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4057, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4069, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4081, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4093, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4105, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4117, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4129, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4141, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4153, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4165, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4177, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4189, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4201, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4213, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4225, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4237, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4249, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4261, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4273, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4285, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4297, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4309, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4321, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4333, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4345, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4357, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4369, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4381, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4393, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4405, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4417, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4429, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4441, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4453, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4465, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4477, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4489, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4501, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4513, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4525, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4537, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4549, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4561, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4573, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4585, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4597, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4609, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4621, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4633, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4645, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4657, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4669, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4681, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4693, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4705, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4717, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4729, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4741, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4753, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4765, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4777, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4789, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4801, (1, 72, 1, 1), (72, 1, 1, 1))
    assert_size_stride(unsqueeze_4813, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4825, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4837, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4849, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4861, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4873, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4885, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4897, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4909, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4921, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_4933, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4945, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4957, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4969, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4981, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_4993, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_5005, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_5017, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_5029, (1, 36, 1, 1), (36, 1, 1, 1))
    assert_size_stride(unsqueeze_5041, (1, 18, 1, 1), (18, 1, 1, 1))
    assert_size_stride(unsqueeze_5053, (1, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(unsqueeze_5065, (1, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(unsqueeze_5077, (1, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(unsqueeze_5089, (1, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(unsqueeze_5101, (1, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(unsqueeze_5113, (1, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(unsqueeze_5125, (1, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(unsqueeze_5137, (1, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(unsqueeze_5149, (1, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(unsqueeze_5161, (1, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(unsqueeze_5173, (1, 256, 1, 1), (256, 1, 1, 1))
    assert_size_stride(unsqueeze_5185, (1, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(unsqueeze_5197, (1, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(unsqueeze_5209, (1, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(unsqueeze_5221, (1, 64, 1, 1), (64, 1, 1, 1))
    assert_size_stride(tangents_1, (8, 1000), (1000, 1))
    with torch.cuda._DeviceGuard(0):
        torch.cuda.set_device(0) # no-op to ensure context
        buf0 = empty((8, 2048), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.mm]
        extern_kernels.mm(tangents_1, permute_1, out=buf0)
        del permute_1
        buf1 = empty((1000, 2048), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.mm]
        extern_kernels.mm(reinterpret_tensor(tangents_1, (1000, 8), (1, 1000), 0), clone, out=buf1)
        del clone
        buf2 = empty((1, 1000), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.sum]
        stream0 = get_cuda_stream(0)
        triton_per_fused_sum_0.run(tangents_1, buf2, 1000, 8, grid=grid(1000), stream=stream0)
        del tangents_1
        buf3 = empty((2048, ), device='cuda', dtype=torch.float32)
        buf4 = empty((2048, ), device='cuda', dtype=torch.float32)
        buf6 = empty((2048, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.div, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_div_native_batch_norm_backward_threshold_backward_1.run(le, buf0, convolution_324, unsqueeze_1333, squeeze_973, buf3, buf4, buf6, 2048, 392, grid=grid(2048), stream=stream0)
        buf5 = empty((8, 2048, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.div, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_div_native_batch_norm_backward_threshold_backward_2.run(le, buf0, convolution_324, unsqueeze_1333, buf4, squeeze_973, buf3, primals_978, buf5, 802816, grid=grid(802816), stream=stream0)
        del buf0
        del convolution_324
        del le
        del primals_978
        del squeeze_973
        del unsqueeze_1333
        buf7 = buf4; del buf4  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        triton_per_fused_convolution_backward_3.run(buf5, buf7, 2048, 392, grid=grid(2048), stream=stream0)
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf8 = aten.convolution_backward(buf5, add_1920, primals_976, [2048], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del add_1920
        del primals_976
        buf9 = buf8[0]
        buf10 = buf8[1]
        del buf8
        buf11 = empty((1024, ), device='cuda', dtype=torch.float32)
        buf12 = empty((1024, ), device='cuda', dtype=torch.float32)
        buf19 = empty((1024, ), device='cuda', dtype=torch.float32)
        buf20 = empty((1024, ), device='cuda', dtype=torch.float32)
        buf26 = empty((1024, ), device='cuda', dtype=torch.float32)
        buf21 = empty((1024, ), device='cuda', dtype=torch.float32)
        buf27 = empty((1024, ), device='cuda', dtype=torch.float32)
        buf14 = empty((1024, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_4.run(le_1, buf9, convolution_323, unsqueeze_1345, le_2, convolution_322, unsqueeze_1357, convolution_321, unsqueeze_1369, squeeze_967, squeeze_964, squeeze_970, buf11, buf12, buf19, buf20, buf26, buf21, buf27, buf14, 1024, 392, grid=grid(1024), stream=stream0)
        buf13 = empty((8, 1024, 7, 7), device='cuda', dtype=torch.float32)
        buf22 = empty((8, 1024, 7, 7), device='cuda', dtype=torch.float32)
        buf28 = empty((8, 1024, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_5.run(le_1, buf9, convolution_323, unsqueeze_1345, buf12, squeeze_970, buf11, primals_974, le_2, convolution_322, unsqueeze_1357, buf20, squeeze_967, buf19, primals_970, convolution_321, unsqueeze_1369, buf26, squeeze_964, primals_967, buf13, buf22, buf28, 401408, grid=grid(401408), stream=stream0)
        del buf12
        del buf20
        del buf9
        del convolution_321
        del convolution_322
        del convolution_323
        del le_1
        del le_2
        del primals_967
        del primals_970
        del primals_974
        del squeeze_964
        del squeeze_967
        del squeeze_970
        del unsqueeze_1345
        del unsqueeze_1357
        del unsqueeze_1369
        buf15 = buf26; del buf26  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        triton_per_fused_convolution_backward_6.run(buf13, buf15, 1024, 392, grid=grid(1024), stream=stream0)
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf16 = aten.convolution_backward(buf13, add_1893, primals_972, [1024], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del add_1893
        del buf13
        del primals_972
        buf17 = buf16[0]
        buf18 = buf16[1]
        del buf16
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf23 = aten.convolution_backward(buf22, relu_267, primals_969, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf22
        del primals_969
        buf24 = buf23[0]
        buf25 = buf23[1]
        del buf23
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf29 = aten.convolution_backward(buf28, relu_280, primals_966, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf28
        del primals_966
        buf30 = buf29[0]
        buf31 = buf29[1]
        del buf29
        buf32 = empty((256, ), device='cuda', dtype=torch.float32)
        buf33 = empty((256, ), device='cuda', dtype=torch.float32)
        buf34 = empty((256, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_7.run(relu_280, buf30, convolution_320, unsqueeze_1381, squeeze_961, buf32, buf33, buf34, 256, 392, grid=grid(256), stream=stream0)
        buf35 = buf30; del buf30  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_8.run(buf35, relu_280, convolution_320, unsqueeze_1381, buf33, squeeze_961, buf32, primals_964, 100352, grid=grid(100352), stream=stream0)
        del convolution_320
        del primals_964
        del relu_280
        del squeeze_961
        del unsqueeze_1381
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf36 = aten.convolution_backward(buf35, relu_279, primals_963, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf35
        del primals_963
        buf37 = buf36[0]
        buf38 = buf36[1]
        del buf36
        buf39 = buf33; del buf33  # reuse
        buf40 = empty((256, ), device='cuda', dtype=torch.float32)
        buf41 = empty((256, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_7.run(relu_279, buf37, convolution_319, unsqueeze_1393, squeeze_958, buf39, buf40, buf41, 256, 392, grid=grid(256), stream=stream0)
        buf42 = buf37; del buf37  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_8.run(buf42, relu_279, convolution_319, unsqueeze_1393, buf40, squeeze_958, buf39, primals_961, 100352, grid=grid(100352), stream=stream0)
        del convolution_319
        del primals_961
        del relu_279
        del squeeze_958
        del unsqueeze_1393
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf43 = aten.convolution_backward(buf42, relu_267, primals_960, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf42
        del primals_960
        buf44 = buf43[0]
        buf45 = buf43[1]
        del buf43
        buf46 = empty((512, ), device='cuda', dtype=torch.float32)
        buf47 = empty((512, ), device='cuda', dtype=torch.float32)
        buf54 = empty((512, ), device='cuda', dtype=torch.float32)
        buf55 = empty((512, ), device='cuda', dtype=torch.float32)
        buf61 = empty((512, ), device='cuda', dtype=torch.float32)
        buf56 = empty((512, ), device='cuda', dtype=torch.float32)
        buf62 = empty((512, ), device='cuda', dtype=torch.float32)
        buf49 = empty((512, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_9.run(le_5, buf17, convolution_318, unsqueeze_1405, le_6, convolution_317, unsqueeze_1417, convolution_316, unsqueeze_1429, squeeze_952, squeeze_949, squeeze_955, buf46, buf47, buf54, buf55, buf61, buf56, buf62, buf49, 512, 1568, grid=grid(512), stream=stream0)
        buf48 = reinterpret_tensor(buf5, (8, 512, 14, 14), (100352, 196, 14, 1), 0); del buf5  # reuse
        buf57 = empty((8, 512, 14, 14), device='cuda', dtype=torch.float32)
        buf63 = empty((8, 512, 14, 14), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_10.run(le_5, buf17, convolution_318, unsqueeze_1405, buf47, squeeze_955, buf46, primals_958, le_6, convolution_317, unsqueeze_1417, buf55, squeeze_952, buf54, primals_954, convolution_316, unsqueeze_1429, buf61, squeeze_949, primals_951, buf48, buf57, buf63, 802816, grid=grid(802816), stream=stream0)
        del buf17
        del convolution_316
        del convolution_317
        del convolution_318
        del le_5
        del le_6
        del primals_951
        del primals_954
        del primals_958
        del squeeze_949
        del squeeze_952
        del squeeze_955
        del unsqueeze_1405
        del unsqueeze_1417
        del unsqueeze_1429
        buf50 = buf61; del buf61  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        triton_red_fused_convolution_backward_11.run(buf48, buf50, 512, 1568, grid=grid(512), stream=stream0)
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf51 = aten.convolution_backward(buf48, add_1866, primals_956, [512], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del add_1866
        del buf48
        del primals_956
        buf52 = buf51[0]
        buf53 = buf51[1]
        del buf51
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf58 = aten.convolution_backward(buf57, relu_263, primals_953, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf57
        del primals_953
        buf59 = buf58[0]
        buf60 = buf58[1]
        del buf58
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf64 = aten.convolution_backward(buf63, relu_276, primals_950, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf63
        del primals_950
        buf65 = buf64[0]
        buf66 = buf64[1]
        del buf64
        buf67 = empty((128, ), device='cuda', dtype=torch.float32)
        buf68 = empty((128, ), device='cuda', dtype=torch.float32)
        buf69 = empty((128, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_12.run(relu_276, buf65, convolution_315, unsqueeze_1441, squeeze_946, buf67, buf68, buf69, 128, 1568, grid=grid(128), stream=stream0)
        buf70 = buf65; del buf65  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_13.run(buf70, relu_276, convolution_315, unsqueeze_1441, buf68, squeeze_946, buf67, primals_948, 200704, grid=grid(200704), stream=stream0)
        del convolution_315
        del primals_948
        del relu_276
        del squeeze_946
        del unsqueeze_1441
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf71 = aten.convolution_backward(buf70, relu_275, primals_947, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf70
        del primals_947
        buf72 = buf71[0]
        buf73 = buf71[1]
        del buf71
        buf74 = buf68; del buf68  # reuse
        buf75 = empty((128, ), device='cuda', dtype=torch.float32)
        buf76 = empty((128, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_12.run(relu_275, buf72, convolution_314, unsqueeze_1453, squeeze_943, buf74, buf75, buf76, 128, 1568, grid=grid(128), stream=stream0)
        buf77 = buf72; del buf72  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_13.run(buf77, relu_275, convolution_314, unsqueeze_1453, buf75, squeeze_943, buf74, primals_945, 200704, grid=grid(200704), stream=stream0)
        del convolution_314
        del primals_945
        del relu_275
        del squeeze_943
        del unsqueeze_1453
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf78 = aten.convolution_backward(buf77, relu_263, primals_944, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf77
        del primals_944
        buf79 = buf78[0]
        buf80 = buf78[1]
        del buf78
        buf81 = buf40; del buf40  # reuse
        buf82 = empty((256, ), device='cuda', dtype=torch.float32)
        buf89 = empty((256, ), device='cuda', dtype=torch.float32)
        buf90 = empty((256, ), device='cuda', dtype=torch.float32)
        buf96 = empty((256, ), device='cuda', dtype=torch.float32)
        buf91 = empty((256, ), device='cuda', dtype=torch.float32)
        buf97 = empty((256, ), device='cuda', dtype=torch.float32)
        buf84 = empty((256, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_14.run(le_9, buf52, convolution_313, unsqueeze_1465, le_10, convolution_312, unsqueeze_1477, convolution_311, unsqueeze_1489, squeeze_937, squeeze_934, squeeze_940, buf81, buf82, buf89, buf90, buf96, buf91, buf97, buf84, 256, 6272, grid=grid(256), stream=stream0)
        buf83 = empty((8, 256, 28, 28), device='cuda', dtype=torch.float32)
        buf92 = empty((8, 256, 28, 28), device='cuda', dtype=torch.float32)
        buf98 = empty((8, 256, 28, 28), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_15.run(le_9, buf52, convolution_313, unsqueeze_1465, buf82, squeeze_940, buf81, primals_942, le_10, convolution_312, unsqueeze_1477, buf90, squeeze_937, buf89, primals_938, convolution_311, unsqueeze_1489, buf96, squeeze_934, primals_935, buf83, buf92, buf98, 1605632, grid=grid(1605632), stream=stream0)
        del buf52
        del convolution_311
        del convolution_312
        del convolution_313
        del le_10
        del le_9
        del primals_935
        del primals_938
        del primals_942
        del squeeze_934
        del squeeze_937
        del squeeze_940
        del unsqueeze_1465
        del unsqueeze_1477
        del unsqueeze_1489
        buf85 = buf96; del buf96  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        triton_red_fused_convolution_backward_16.run(buf83, buf85, 256, 6272, grid=grid(256), stream=stream0)
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf86 = aten.convolution_backward(buf83, relu_270, primals_940, [256], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf83
        del primals_940
        buf87 = buf86[0]
        buf88 = buf86[1]
        del buf86
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf93 = aten.convolution_backward(buf92, relu_261, primals_937, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf92
        del primals_937
        buf94 = buf93[0]
        buf95 = buf93[1]
        del buf93
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf99 = aten.convolution_backward(buf98, relu_272, primals_934, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf98
        del primals_934
        buf100 = buf99[0]
        buf101 = buf99[1]
        del buf99
        buf102 = empty((64, ), device='cuda', dtype=torch.float32)
        buf103 = empty((64, ), device='cuda', dtype=torch.float32)
        buf104 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_17.run(relu_272, buf100, convolution_310, unsqueeze_1501, squeeze_931, buf102, buf103, buf104, 64, 6272, grid=grid(64), stream=stream0)
        buf105 = buf100; del buf100  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_18.run(buf105, relu_272, convolution_310, unsqueeze_1501, buf103, squeeze_931, buf102, primals_932, 401408, grid=grid(401408), stream=stream0)
        del convolution_310
        del primals_932
        del relu_272
        del squeeze_931
        del unsqueeze_1501
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf106 = aten.convolution_backward(buf105, relu_271, primals_931, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf105
        del primals_931
        buf107 = buf106[0]
        buf108 = buf106[1]
        del buf106
        buf109 = buf103; del buf103  # reuse
        buf110 = empty((64, ), device='cuda', dtype=torch.float32)
        buf111 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_17.run(relu_271, buf107, convolution_309, unsqueeze_1513, squeeze_928, buf109, buf110, buf111, 64, 6272, grid=grid(64), stream=stream0)
        buf112 = buf107; del buf107  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_18.run(buf112, relu_271, convolution_309, unsqueeze_1513, buf110, squeeze_928, buf109, primals_929, 401408, grid=grid(401408), stream=stream0)
        del convolution_309
        del primals_929
        del relu_271
        del squeeze_928
        del unsqueeze_1513
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf113 = aten.convolution_backward(buf112, relu_261, primals_928, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf112
        del primals_928
        buf114 = buf113[0]
        buf115 = buf113[1]
        del buf113
        buf116 = reinterpret_tensor(buf55, (128, 4), (1, 128), 0); del buf55  # reuse
        buf118 = reinterpret_tensor(buf47, (128, 4), (1, 128), 0); del buf47  # reuse
        buf125 = empty_strided((128, 4), (1, 128), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_19.run(relu_270, buf87, convolution_308, unsqueeze_1525, convolution_307, unsqueeze_1537, buf116, buf118, buf125, 512, 6272, grid=grid(512), stream=stream0)
        buf117 = buf75; del buf75  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_20.run(buf116, buf117, 128, 4, grid=grid(128), stream=stream0)
        del buf116
        buf119 = empty((128, ), device='cuda', dtype=torch.float32)
        buf120 = empty((128, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_21.run(buf118, squeeze_925, buf119, buf120, 128, 4, grid=grid(128), stream=stream0)
        del buf118
        buf126 = empty((128, ), device='cuda', dtype=torch.float32)
        buf127 = empty((128, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_21.run(buf125, squeeze_922, buf126, buf127, 128, 4, grid=grid(128), stream=stream0)
        del buf125
        buf121 = empty((8, 128, 56, 56), device='cuda', dtype=torch.float32)
        buf128 = empty((8, 128, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_22.run(relu_270, buf87, convolution_308, unsqueeze_1525, buf119, squeeze_925, buf117, primals_926, convolution_307, unsqueeze_1537, buf126, squeeze_922, primals_923, buf121, buf128, 3211264, grid=grid(3211264), stream=stream0)
        del buf87
        del convolution_307
        del convolution_308
        del primals_923
        del primals_926
        del relu_270
        del squeeze_922
        del squeeze_925
        del unsqueeze_1525
        del unsqueeze_1537
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf122 = aten.convolution_backward(buf121, relu_260, primals_925, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf121
        del primals_925
        buf123 = buf122[0]
        buf124 = buf122[1]
        del buf122
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf129 = aten.convolution_backward(buf128, relu_269, primals_922, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf128
        del primals_922
        buf130 = buf129[0]
        buf131 = buf129[1]
        del buf129
        buf132 = reinterpret_tensor(buf126, (32, 4), (1, 32), 0); del buf126  # reuse
        buf134 = reinterpret_tensor(buf119, (32, 4), (1, 32), 0); del buf119  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_23.run(relu_269, buf130, convolution_306, unsqueeze_1549, buf132, buf134, 128, 6272, grid=grid(128), stream=stream0)
        buf133 = empty((32, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_24.run(buf132, buf133, 32, 4, grid=grid(32), stream=stream0)
        buf135 = empty((32, ), device='cuda', dtype=torch.float32)
        buf136 = empty((32, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_25.run(buf134, squeeze_919, buf135, buf136, 32, 4, grid=grid(32), stream=stream0)
        buf137 = buf130; del buf130  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_26.run(buf137, relu_269, convolution_306, unsqueeze_1549, buf135, squeeze_919, buf133, primals_920, 802816, grid=grid(802816), stream=stream0)
        del convolution_306
        del primals_920
        del relu_269
        del squeeze_919
        del unsqueeze_1549
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf138 = aten.convolution_backward(buf137, relu_268, primals_919, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf137
        del primals_919
        buf139 = buf138[0]
        buf140 = buf138[1]
        del buf138
        buf141 = buf134; del buf134  # reuse
        buf143 = buf132; del buf132  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_23.run(relu_268, buf139, convolution_305, unsqueeze_1561, buf141, buf143, 128, 6272, grid=grid(128), stream=stream0)
        buf142 = buf135; del buf135  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_24.run(buf141, buf142, 32, 4, grid=grid(32), stream=stream0)
        del buf141
        buf144 = empty((32, ), device='cuda', dtype=torch.float32)
        buf145 = empty((32, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_25.run(buf143, squeeze_916, buf144, buf145, 32, 4, grid=grid(32), stream=stream0)
        del buf143
        buf146 = buf139; del buf139  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_26.run(buf146, relu_268, convolution_305, unsqueeze_1561, buf144, squeeze_916, buf142, primals_917, 802816, grid=grid(802816), stream=stream0)
        del buf144
        del convolution_305
        del primals_917
        del relu_268
        del squeeze_916
        del unsqueeze_1561
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf147 = aten.convolution_backward(buf146, relu_260, primals_916, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf146
        del primals_916
        buf148 = buf147[0]
        buf149 = buf147[1]
        del buf147
        buf150 = empty((144, ), device='cuda', dtype=torch.float32)
        buf151 = empty((144, ), device='cuda', dtype=torch.float32)
        buf157 = empty((144, ), device='cuda', dtype=torch.float32)
        buf170 = empty((144, ), device='cuda', dtype=torch.float32)
        buf153 = empty((144, ), device='cuda', dtype=torch.float32)
        buf159 = empty((144, ), device='cuda', dtype=torch.float32)
        buf172 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_add_native_batch_norm_backward_threshold_backward_27.run(relu_267, buf24, buf44, convolution_304, unsqueeze_1573, convolution_303, unsqueeze_1585, convolution_301, unsqueeze_1609, squeeze_913, squeeze_910, squeeze_904, buf150, buf151, buf157, buf170, buf153, buf159, buf172, 144, 392, grid=grid(144), stream=stream0)
        buf152 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        buf158 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        buf171 = empty((8, 144, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_28.run(relu_267, buf24, buf44, convolution_304, unsqueeze_1573, buf151, squeeze_913, buf150, primals_914, convolution_303, unsqueeze_1585, buf157, squeeze_910, primals_911, convolution_301, unsqueeze_1609, buf170, squeeze_904, primals_905, buf152, buf158, buf171, 56448, grid=grid(56448), stream=stream0)
        del convolution_301
        del convolution_303
        del convolution_304
        del primals_905
        del primals_911
        del primals_914
        del squeeze_904
        del squeeze_910
        del squeeze_913
        del unsqueeze_1573
        del unsqueeze_1585
        del unsqueeze_1609
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf154 = aten.convolution_backward(buf152, relu_251, primals_913, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf152
        del primals_913
        buf155 = buf154[0]
        buf156 = buf154[1]
        del buf154
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf160 = aten.convolution_backward(buf158, relu_266, primals_910, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf158
        del primals_910
        buf161 = buf160[0]
        buf162 = buf160[1]
        del buf160
        buf163 = empty((36, ), device='cuda', dtype=torch.float32)
        buf164 = empty((36, ), device='cuda', dtype=torch.float32)
        buf165 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_29.run(relu_266, buf161, convolution_302, unsqueeze_1597, squeeze_907, buf163, buf164, buf165, 36, 1568, grid=grid(36), stream=stream0)
        buf166 = buf161; del buf161  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_30.run(buf166, relu_266, convolution_302, unsqueeze_1597, buf164, squeeze_907, buf163, primals_908, 56448, grid=grid(56448), stream=stream0)
        del convolution_302
        del primals_908
        del relu_266
        del squeeze_907
        del unsqueeze_1597
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf167 = aten.convolution_backward(buf166, relu_243, primals_907, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_907
        buf168 = buf167[0]
        buf169 = buf167[1]
        del buf167
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf173 = aten.convolution_backward(buf171, relu_265, primals_904, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_904
        buf174 = buf173[0]
        buf175 = buf173[1]
        del buf173
        buf176 = empty((18, ), device='cuda', dtype=torch.float32)
        buf177 = empty((18, ), device='cuda', dtype=torch.float32)
        buf178 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_31.run(relu_265, buf174, convolution_300, unsqueeze_1621, squeeze_901, buf176, buf177, buf178, 18, 1568, grid=grid(18), stream=stream0)
        buf179 = buf174; del buf174  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_32.run(buf179, relu_265, convolution_300, unsqueeze_1621, buf177, squeeze_901, buf176, primals_902, 28224, grid=grid(28224), stream=stream0)
        del convolution_300
        del primals_902
        del relu_265
        del squeeze_901
        del unsqueeze_1621
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf180 = aten.convolution_backward(buf179, relu_264, primals_901, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_901
        buf181 = buf180[0]
        buf182 = buf180[1]
        del buf180
        buf183 = buf177; del buf177  # reuse
        buf184 = empty((18, ), device='cuda', dtype=torch.float32)
        buf185 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_33.run(relu_264, buf181, convolution_299, unsqueeze_1633, squeeze_898, buf183, buf184, buf185, 18, 6272, grid=grid(18), stream=stream0)
        buf186 = buf181; del buf181  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_34.run(buf186, relu_264, convolution_299, unsqueeze_1633, buf184, squeeze_898, buf183, primals_899, 112896, grid=grid(112896), stream=stream0)
        del convolution_299
        del primals_899
        del relu_264
        del squeeze_898
        del unsqueeze_1633
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf187 = aten.convolution_backward(buf186, relu_235, primals_898, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_898
        buf188 = buf187[0]
        buf189 = buf187[1]
        del buf187
        buf190 = reinterpret_tensor(buf179, (8, 72, 7, 7), (3528, 49, 7, 1), 0); del buf179  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.add, aten.new_zeros, aten.threshold_backward]
        triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_35.run(buf190, 28224, grid=grid(28224), stream=stream0)
        buf191 = buf59; del buf59  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_36.run(buf191, relu_263, buf79, 112896, grid=grid(112896), stream=stream0)
        del relu_263
        aten.index_put_(buf190, [None, None, unsqueeze_830, convert_element_type_73], buf191, True)
        buf194 = empty((72, ), device='cuda', dtype=torch.float32)
        buf195 = empty((72, ), device='cuda', dtype=torch.float32)
        buf196 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_37.run(buf190, convolution_298, unsqueeze_1645, squeeze_895, buf194, buf195, buf196, 72, 392, grid=grid(72), stream=stream0)
        buf193 = empty((8, 72, 7, 7), device='cuda', dtype=torch.float32)
        buf197 = buf193; del buf193  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_38.run(buf197, buf190, convolution_298, unsqueeze_1645, buf195, squeeze_895, buf194, primals_896, 28224, grid=grid(28224), stream=stream0)
        del convolution_298
        del primals_896
        del squeeze_895
        del unsqueeze_1645
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf198 = aten.convolution_backward(buf197, relu_259, primals_895, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_895
        buf199 = buf198[0]
        buf200 = buf198[1]
        del buf198
        buf201 = buf195; del buf195  # reuse
        buf202 = empty((72, ), device='cuda', dtype=torch.float32)
        buf208 = empty((72, ), device='cuda', dtype=torch.float32)
        buf203 = empty((72, ), device='cuda', dtype=torch.float32)
        buf209 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_39.run(buf191, convolution_297, unsqueeze_1657, convolution_296, unsqueeze_1669, squeeze_892, squeeze_889, buf201, buf202, buf208, buf203, buf209, 72, 1568, grid=grid(72), stream=stream0)
        buf204 = buf79; del buf79  # reuse
        buf210 = reinterpret_tensor(buf186, (8, 72, 14, 14), (14112, 196, 14, 1), 0); del buf186  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_40.run(buf191, convolution_297, unsqueeze_1657, buf202, squeeze_892, buf201, primals_893, convolution_296, unsqueeze_1669, buf208, squeeze_889, primals_890, buf204, buf210, 112896, grid=grid(112896), stream=stream0)
        del convolution_296
        del convolution_297
        del primals_890
        del primals_893
        del squeeze_889
        del squeeze_892
        del unsqueeze_1657
        del unsqueeze_1669
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf205 = aten.convolution_backward(buf204, relu_243, primals_892, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf204
        del primals_892
        buf206 = buf205[0]
        buf207 = buf205[1]
        del buf205
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf211 = aten.convolution_backward(buf210, relu_262, primals_889, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_889
        buf212 = buf211[0]
        buf213 = buf211[1]
        del buf211
        buf214 = buf184; del buf184  # reuse
        buf215 = empty((18, ), device='cuda', dtype=torch.float32)
        buf216 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_33.run(relu_262, buf212, convolution_295, unsqueeze_1681, squeeze_886, buf214, buf215, buf216, 18, 6272, grid=grid(18), stream=stream0)
        buf217 = buf212; del buf212  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_34.run(buf217, relu_262, convolution_295, unsqueeze_1681, buf215, squeeze_886, buf214, primals_887, 112896, grid=grid(112896), stream=stream0)
        del convolution_295
        del primals_887
        del relu_262
        del squeeze_886
        del unsqueeze_1681
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf218 = aten.convolution_backward(buf217, relu_235, primals_886, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_886
        buf219 = buf218[0]
        buf220 = buf218[1]
        del buf218
        buf221 = empty((8, 36, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.add, aten.new_zeros, aten.threshold_backward]
        triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_41.run(buf221, 14112, grid=grid(14112), stream=stream0)
        buf222 = buf114; del buf114  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_42.run(buf222, relu_261, buf94, 225792, grid=grid(225792), stream=stream0)
        del relu_261
        aten.index_put_(buf221, [None, None, unsqueeze_813, convert_element_type_69], buf222, True)
        buf225 = buf164; del buf164  # reuse
        buf226 = empty((36, ), device='cuda', dtype=torch.float32)
        buf227 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_43.run(buf221, convolution_294, unsqueeze_1693, squeeze_883, buf225, buf226, buf227, 36, 392, grid=grid(36), stream=stream0)
        buf224 = empty((8, 36, 7, 7), device='cuda', dtype=torch.float32)
        buf228 = buf224; del buf224  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_44.run(buf228, buf221, convolution_294, unsqueeze_1693, buf226, squeeze_883, buf225, primals_884, 14112, grid=grid(14112), stream=stream0)
        del convolution_294
        del primals_884
        del squeeze_883
        del unsqueeze_1693
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf229 = aten.convolution_backward(buf228, relu_259, primals_883, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_883
        buf230 = buf229[0]
        buf231 = buf229[1]
        del buf229
        buf232 = reinterpret_tensor(buf171, (8, 36, 14, 14), (7056, 196, 14, 1), 0); del buf171  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_new_zeros_45.run(buf232, 56448, grid=grid(56448), stream=stream0)
        aten.index_put_(buf232, [None, None, unsqueeze_259, convert_element_type_13], buf222, True)
        buf235 = buf226; del buf226  # reuse
        buf236 = empty((36, ), device='cuda', dtype=torch.float32)
        buf237 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_46.run(buf232, convolution_293, unsqueeze_1705, squeeze_880, buf235, buf236, buf237, 36, 1568, grid=grid(36), stream=stream0)
        buf234 = buf166; del buf166  # reuse
        buf238 = buf234; del buf234  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_47.run(buf238, buf232, convolution_293, unsqueeze_1705, buf236, squeeze_880, buf235, primals_881, 56448, grid=grid(56448), stream=stream0)
        del buf232
        del convolution_293
        del primals_881
        del squeeze_880
        del unsqueeze_1705
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf239 = aten.convolution_backward(buf238, relu_251, primals_880, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf238
        del primals_880
        buf240 = buf239[0]
        buf241 = buf239[1]
        del buf239
        buf242 = buf236; del buf236  # reuse
        buf243 = empty((36, ), device='cuda', dtype=torch.float32)
        buf244 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf222, convolution_292, unsqueeze_1717, squeeze_877, buf242, buf243, buf244, 36, 6272, grid=grid(36), stream=stream0)
        buf245 = buf94; del buf94  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf222, convolution_292, unsqueeze_1717, buf243, squeeze_877, buf242, primals_878, buf245, 225792, grid=grid(225792), stream=stream0)
        del convolution_292
        del primals_878
        del squeeze_877
        del unsqueeze_1717
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf246 = aten.convolution_backward(buf245, relu_235, primals_877, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf245
        del primals_877
        buf247 = buf246[0]
        buf248 = buf246[1]
        del buf246
        buf249 = empty((8, 18, 7, 7), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.add, aten.new_zeros, aten.threshold_backward]
        triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_50.run(buf249, 7056, grid=grid(7056), stream=stream0)
        buf250 = buf123; del buf123  # reuse
        buf454 = buf188; del buf188  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_51.run(buf250, buf454, relu_260, buf148, relu_235, buf219, buf247, 451584, grid=grid(451584), stream=stream0)
        del buf148
        del buf219
        del buf247
        del relu_235
        del relu_260
        aten.index_put_(buf249, [None, None, unsqueeze_799, convert_element_type_61], buf250, True)
        buf253 = buf215; del buf215  # reuse
        buf254 = empty((18, ), device='cuda', dtype=torch.float32)
        buf255 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_52.run(buf249, convolution_291, unsqueeze_1729, squeeze_874, buf253, buf254, buf255, 18, 392, grid=grid(18), stream=stream0)
        buf252 = empty((8, 18, 7, 7), device='cuda', dtype=torch.float32)
        buf256 = buf252; del buf252  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_53.run(buf256, buf249, convolution_291, unsqueeze_1729, buf254, squeeze_874, buf253, primals_875, 7056, grid=grid(7056), stream=stream0)
        del convolution_291
        del primals_875
        del squeeze_874
        del unsqueeze_1729
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf257 = aten.convolution_backward(buf256, relu_259, primals_874, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_874
        buf258 = buf257[0]
        buf259 = buf257[1]
        del buf257
        buf260 = reinterpret_tensor(buf197, (8, 18, 14, 14), (3528, 196, 14, 1), 0); del buf197  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_35.run(buf260, 28224, grid=grid(28224), stream=stream0)
        aten.index_put_(buf260, [None, None, unsqueeze_250, convert_element_type_9], buf250, True)
        buf263 = buf254; del buf254  # reuse
        buf264 = empty((18, ), device='cuda', dtype=torch.float32)
        buf265 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_54.run(buf260, convolution_290, unsqueeze_1741, squeeze_871, buf263, buf264, buf265, 18, 1568, grid=grid(18), stream=stream0)
        buf262 = reinterpret_tensor(buf190, (8, 18, 14, 14), (3528, 196, 14, 1), 0); del buf190  # reuse
        buf266 = buf262; del buf262  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_55.run(buf266, buf260, convolution_290, unsqueeze_1741, buf264, squeeze_871, buf263, primals_872, 28224, grid=grid(28224), stream=stream0)
        del buf260
        del convolution_290
        del primals_872
        del squeeze_871
        del unsqueeze_1741
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf267 = aten.convolution_backward(buf266, relu_251, primals_871, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_871
        buf268 = buf267[0]
        buf269 = buf267[1]
        del buf267
        buf270 = buf217; del buf217  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_new_zeros_56.run(buf270, 112896, grid=grid(112896), stream=stream0)
        aten.index_put_(buf270, [None, None, unsqueeze_136, convert_element_type_1], buf250, True)
        buf273 = buf264; del buf264  # reuse
        buf274 = empty((18, ), device='cuda', dtype=torch.float32)
        buf275 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_57.run(buf270, convolution_289, unsqueeze_1753, squeeze_868, buf273, buf274, buf275, 18, 6272, grid=grid(18), stream=stream0)
        buf272 = reinterpret_tensor(buf210, (8, 18, 28, 28), (14112, 784, 28, 1), 0); del buf210  # reuse
        buf276 = buf272; del buf272  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_58.run(buf276, buf270, convolution_289, unsqueeze_1753, buf274, squeeze_868, buf273, primals_869, 112896, grid=grid(112896), stream=stream0)
        del buf270
        del convolution_289
        del primals_869
        del squeeze_868
        del unsqueeze_1753
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf277 = aten.convolution_backward(buf276, relu_243, primals_868, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf276
        del primals_868
        buf278 = buf277[0]
        buf279 = buf277[1]
        del buf277
        buf280 = buf199; del buf199  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_59.run(buf280, relu_259, relu_267, buf24, buf44, buf230, buf258, 56448, grid=grid(56448), stream=stream0)
        del buf230
        del buf24
        del buf258
        del relu_259
        del relu_267
        buf281 = buf170; del buf170  # reuse
        buf282 = buf157; del buf157  # reuse
        buf283 = buf151; del buf151  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_60.run(buf280, convolution_288, unsqueeze_1765, squeeze_865, buf281, buf282, buf283, 144, 392, grid=grid(144), stream=stream0)
        buf284 = buf44; del buf44  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_61.run(buf280, convolution_288, unsqueeze_1765, buf282, squeeze_865, buf281, primals_866, buf284, 56448, grid=grid(56448), stream=stream0)
        del convolution_288
        del primals_866
        del squeeze_865
        del unsqueeze_1765
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf285 = aten.convolution_backward(buf284, relu_258, primals_865, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf284
        del primals_865
        buf286 = buf285[0]
        buf287 = buf285[1]
        del buf285
        buf288 = buf282; del buf282  # reuse
        buf289 = empty((144, ), device='cuda', dtype=torch.float32)
        buf290 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_62.run(relu_258, buf286, convolution_287, unsqueeze_1777, squeeze_862, buf288, buf289, buf290, 144, 392, grid=grid(144), stream=stream0)
        buf291 = buf286; del buf286  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_63.run(buf291, relu_258, convolution_287, unsqueeze_1777, buf289, squeeze_862, buf288, primals_863, 56448, grid=grid(56448), stream=stream0)
        del convolution_287
        del primals_863
        del relu_258
        del squeeze_862
        del unsqueeze_1777
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf292 = aten.convolution_backward(buf291, relu_257, primals_862, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_862
        buf293 = buf292[0]
        buf294 = buf292[1]
        del buf292
        buf295 = buf289; del buf289  # reuse
        buf296 = empty((144, ), device='cuda', dtype=torch.float32)
        buf298 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_add_native_batch_norm_backward_threshold_backward_64.run(relu_257, buf280, buf293, convolution_286, unsqueeze_1789, squeeze_859, buf295, buf296, buf298, 144, 392, grid=grid(144), stream=stream0)
        buf297 = buf291; del buf291  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_65.run(relu_257, buf280, buf293, convolution_286, unsqueeze_1789, buf296, squeeze_859, buf295, primals_860, buf297, 56448, grid=grid(56448), stream=stream0)
        del convolution_286
        del primals_860
        del squeeze_859
        del unsqueeze_1789
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf299 = aten.convolution_backward(buf297, relu_256, primals_859, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf297
        del primals_859
        buf300 = buf299[0]
        buf301 = buf299[1]
        del buf299
        buf302 = buf296; del buf296  # reuse
        buf303 = empty((144, ), device='cuda', dtype=torch.float32)
        buf304 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_62.run(relu_256, buf300, convolution_285, unsqueeze_1801, squeeze_856, buf302, buf303, buf304, 144, 392, grid=grid(144), stream=stream0)
        buf305 = buf300; del buf300  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_63.run(buf305, relu_256, convolution_285, unsqueeze_1801, buf303, squeeze_856, buf302, primals_857, 56448, grid=grid(56448), stream=stream0)
        del convolution_285
        del primals_857
        del relu_256
        del squeeze_856
        del unsqueeze_1801
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf306 = aten.convolution_backward(buf305, relu_255, primals_856, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf305
        del primals_856
        buf307 = buf306[0]
        buf308 = buf306[1]
        del buf306
        buf309 = buf280; del buf280  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_66.run(buf309, relu_255, relu_257, buf293, buf307, 56448, grid=grid(56448), stream=stream0)
        del buf293
        del relu_255
        del relu_257
        buf310 = buf303; del buf303  # reuse
        buf311 = empty((144, ), device='cuda', dtype=torch.float32)
        buf312 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_60.run(buf309, convolution_284, unsqueeze_1813, squeeze_853, buf310, buf311, buf312, 144, 392, grid=grid(144), stream=stream0)
        buf313 = buf307; del buf307  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_61.run(buf309, convolution_284, unsqueeze_1813, buf311, squeeze_853, buf310, primals_854, buf313, 56448, grid=grid(56448), stream=stream0)
        del convolution_284
        del primals_854
        del squeeze_853
        del unsqueeze_1813
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf314 = aten.convolution_backward(buf313, relu_254, primals_853, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf313
        del primals_853
        buf315 = buf314[0]
        buf316 = buf314[1]
        del buf314
        buf317 = buf311; del buf311  # reuse
        buf318 = empty((144, ), device='cuda', dtype=torch.float32)
        buf319 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_62.run(relu_254, buf315, convolution_283, unsqueeze_1825, squeeze_850, buf317, buf318, buf319, 144, 392, grid=grid(144), stream=stream0)
        buf320 = buf315; del buf315  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_63.run(buf320, relu_254, convolution_283, unsqueeze_1825, buf318, squeeze_850, buf317, primals_851, 56448, grid=grid(56448), stream=stream0)
        del convolution_283
        del primals_851
        del relu_254
        del squeeze_850
        del unsqueeze_1825
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf321 = aten.convolution_backward(buf320, relu_253, primals_850, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_850
        buf322 = buf321[0]
        buf323 = buf321[1]
        del buf321
        buf324 = buf318; del buf318  # reuse
        buf325 = empty((144, ), device='cuda', dtype=torch.float32)
        buf327 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_add_native_batch_norm_backward_threshold_backward_64.run(relu_253, buf309, buf322, convolution_282, unsqueeze_1837, squeeze_847, buf324, buf325, buf327, 144, 392, grid=grid(144), stream=stream0)
        buf326 = buf320; del buf320  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_65.run(relu_253, buf309, buf322, convolution_282, unsqueeze_1837, buf325, squeeze_847, buf324, primals_848, buf326, 56448, grid=grid(56448), stream=stream0)
        del convolution_282
        del primals_848
        del squeeze_847
        del unsqueeze_1837
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf328 = aten.convolution_backward(buf326, relu_252, primals_847, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf326
        del primals_847
        buf329 = buf328[0]
        buf330 = buf328[1]
        del buf328
        buf331 = buf325; del buf325  # reuse
        buf332 = empty((144, ), device='cuda', dtype=torch.float32)
        buf333 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_62.run(relu_252, buf329, convolution_281, unsqueeze_1849, squeeze_844, buf331, buf332, buf333, 144, 392, grid=grid(144), stream=stream0)
        buf334 = buf329; del buf329  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_63.run(buf334, relu_252, convolution_281, unsqueeze_1849, buf332, squeeze_844, buf331, primals_845, 56448, grid=grid(56448), stream=stream0)
        del convolution_281
        del primals_845
        del relu_252
        del squeeze_844
        del unsqueeze_1849
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf335 = aten.convolution_backward(buf334, relu_227, primals_844, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_844
        buf336 = buf335[0]
        buf337 = buf335[1]
        del buf335
        buf338 = buf155; del buf155  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_67.run(buf338, relu_251, buf191, buf240, buf268, 112896, grid=grid(112896), stream=stream0)
        del buf191
        del buf240
        del relu_251
        buf339 = buf208; del buf208  # reuse
        buf340 = buf202; del buf202  # reuse
        buf341 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_68.run(buf338, convolution_280, unsqueeze_1861, squeeze_841, buf339, buf340, buf341, 72, 1568, grid=grid(72), stream=stream0)
        buf342 = buf268; del buf268  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_69.run(buf338, convolution_280, unsqueeze_1861, buf340, squeeze_841, buf339, primals_842, buf342, 112896, grid=grid(112896), stream=stream0)
        del convolution_280
        del primals_842
        del squeeze_841
        del unsqueeze_1861
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf343 = aten.convolution_backward(buf342, relu_250, primals_841, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf342
        del primals_841
        buf344 = buf343[0]
        buf345 = buf343[1]
        del buf343
        buf346 = buf340; del buf340  # reuse
        buf347 = empty((72, ), device='cuda', dtype=torch.float32)
        buf348 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_250, buf344, convolution_279, unsqueeze_1873, squeeze_838, buf346, buf347, buf348, 72, 1568, grid=grid(72), stream=stream0)
        buf349 = buf344; del buf344  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf349, relu_250, convolution_279, unsqueeze_1873, buf347, squeeze_838, buf346, primals_839, 112896, grid=grid(112896), stream=stream0)
        del convolution_279
        del primals_839
        del relu_250
        del squeeze_838
        del unsqueeze_1873
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf350 = aten.convolution_backward(buf349, relu_249, primals_838, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_838
        buf351 = buf350[0]
        buf352 = buf350[1]
        del buf350
        buf353 = buf347; del buf347  # reuse
        buf354 = empty((72, ), device='cuda', dtype=torch.float32)
        buf356 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_72.run(relu_249, buf338, buf351, convolution_278, unsqueeze_1885, squeeze_835, buf353, buf354, buf356, 72, 1568, grid=grid(72), stream=stream0)
        buf355 = buf349; del buf349  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_73.run(relu_249, buf338, buf351, convolution_278, unsqueeze_1885, buf354, squeeze_835, buf353, primals_836, buf355, 112896, grid=grid(112896), stream=stream0)
        del convolution_278
        del primals_836
        del squeeze_835
        del unsqueeze_1885
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf357 = aten.convolution_backward(buf355, relu_248, primals_835, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf355
        del primals_835
        buf358 = buf357[0]
        buf359 = buf357[1]
        del buf357
        buf360 = buf354; del buf354  # reuse
        buf361 = empty((72, ), device='cuda', dtype=torch.float32)
        buf362 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_248, buf358, convolution_277, unsqueeze_1897, squeeze_832, buf360, buf361, buf362, 72, 1568, grid=grid(72), stream=stream0)
        buf363 = buf358; del buf358  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf363, relu_248, convolution_277, unsqueeze_1897, buf361, squeeze_832, buf360, primals_833, 112896, grid=grid(112896), stream=stream0)
        del convolution_277
        del primals_833
        del relu_248
        del squeeze_832
        del unsqueeze_1897
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf364 = aten.convolution_backward(buf363, relu_247, primals_832, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf363
        del primals_832
        buf365 = buf364[0]
        buf366 = buf364[1]
        del buf364
        buf367 = buf338; del buf338  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_74.run(buf367, relu_247, relu_249, buf351, buf365, 112896, grid=grid(112896), stream=stream0)
        del buf351
        del relu_247
        del relu_249
        buf368 = buf361; del buf361  # reuse
        buf369 = empty((72, ), device='cuda', dtype=torch.float32)
        buf370 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_68.run(buf367, convolution_276, unsqueeze_1909, squeeze_829, buf368, buf369, buf370, 72, 1568, grid=grid(72), stream=stream0)
        buf371 = buf365; del buf365  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_69.run(buf367, convolution_276, unsqueeze_1909, buf369, squeeze_829, buf368, primals_830, buf371, 112896, grid=grid(112896), stream=stream0)
        del convolution_276
        del primals_830
        del squeeze_829
        del unsqueeze_1909
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf372 = aten.convolution_backward(buf371, relu_246, primals_829, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf371
        del primals_829
        buf373 = buf372[0]
        buf374 = buf372[1]
        del buf372
        buf375 = buf369; del buf369  # reuse
        buf376 = empty((72, ), device='cuda', dtype=torch.float32)
        buf377 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_246, buf373, convolution_275, unsqueeze_1921, squeeze_826, buf375, buf376, buf377, 72, 1568, grid=grid(72), stream=stream0)
        buf378 = buf373; del buf373  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf378, relu_246, convolution_275, unsqueeze_1921, buf376, squeeze_826, buf375, primals_827, 112896, grid=grid(112896), stream=stream0)
        del convolution_275
        del primals_827
        del relu_246
        del squeeze_826
        del unsqueeze_1921
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf379 = aten.convolution_backward(buf378, relu_245, primals_826, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_826
        buf380 = buf379[0]
        buf381 = buf379[1]
        del buf379
        buf382 = buf376; del buf376  # reuse
        buf383 = empty((72, ), device='cuda', dtype=torch.float32)
        buf385 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_72.run(relu_245, buf367, buf380, convolution_274, unsqueeze_1933, squeeze_823, buf382, buf383, buf385, 72, 1568, grid=grid(72), stream=stream0)
        buf384 = buf378; del buf378  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_73.run(relu_245, buf367, buf380, convolution_274, unsqueeze_1933, buf383, squeeze_823, buf382, primals_824, buf384, 112896, grid=grid(112896), stream=stream0)
        del convolution_274
        del primals_824
        del squeeze_823
        del unsqueeze_1933
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf386 = aten.convolution_backward(buf384, relu_244, primals_823, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf384
        del primals_823
        buf387 = buf386[0]
        buf388 = buf386[1]
        del buf386
        buf389 = buf383; del buf383  # reuse
        buf390 = empty((72, ), device='cuda', dtype=torch.float32)
        buf391 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_244, buf387, convolution_273, unsqueeze_1945, squeeze_820, buf389, buf390, buf391, 72, 1568, grid=grid(72), stream=stream0)
        buf392 = buf387; del buf387  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf392, relu_244, convolution_273, unsqueeze_1945, buf390, squeeze_820, buf389, primals_821, 112896, grid=grid(112896), stream=stream0)
        del convolution_273
        del primals_821
        del relu_244
        del squeeze_820
        del unsqueeze_1945
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf393 = aten.convolution_backward(buf392, relu_223, primals_820, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf392
        del primals_820
        buf394 = buf393[0]
        buf395 = buf393[1]
        del buf393
        buf396 = buf168; del buf168  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_75.run(buf396, relu_243, buf206, buf222, buf278, 225792, grid=grid(225792), stream=stream0)
        del buf206
        del buf222
        del relu_243
        buf397 = buf243; del buf243  # reuse
        buf398 = empty((36, ), device='cuda', dtype=torch.float32)
        buf399 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf396, convolution_272, unsqueeze_1957, squeeze_817, buf397, buf398, buf399, 36, 6272, grid=grid(36), stream=stream0)
        buf400 = buf278; del buf278  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf396, convolution_272, unsqueeze_1957, buf398, squeeze_817, buf397, primals_818, buf400, 225792, grid=grid(225792), stream=stream0)
        del convolution_272
        del primals_818
        del squeeze_817
        del unsqueeze_1957
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf401 = aten.convolution_backward(buf400, relu_242, primals_817, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf400
        del primals_817
        buf402 = buf401[0]
        buf403 = buf401[1]
        del buf401
        buf404 = buf398; del buf398  # reuse
        buf405 = empty((36, ), device='cuda', dtype=torch.float32)
        buf406 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_242, buf402, convolution_271, unsqueeze_1969, squeeze_814, buf404, buf405, buf406, 36, 6272, grid=grid(36), stream=stream0)
        buf407 = buf402; del buf402  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf407, relu_242, convolution_271, unsqueeze_1969, buf405, squeeze_814, buf404, primals_815, 225792, grid=grid(225792), stream=stream0)
        del convolution_271
        del primals_815
        del relu_242
        del squeeze_814
        del unsqueeze_1969
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf408 = aten.convolution_backward(buf407, relu_241, primals_814, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_814
        buf409 = buf408[0]
        buf410 = buf408[1]
        del buf408
        buf411 = buf405; del buf405  # reuse
        buf412 = empty((36, ), device='cuda', dtype=torch.float32)
        buf414 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_78.run(relu_241, buf396, buf409, convolution_270, unsqueeze_1981, squeeze_811, buf411, buf412, buf414, 36, 6272, grid=grid(36), stream=stream0)
        buf413 = buf407; del buf407  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_79.run(relu_241, buf396, buf409, convolution_270, unsqueeze_1981, buf412, squeeze_811, buf411, primals_812, buf413, 225792, grid=grid(225792), stream=stream0)
        del convolution_270
        del primals_812
        del squeeze_811
        del unsqueeze_1981
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf415 = aten.convolution_backward(buf413, relu_240, primals_811, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf413
        del primals_811
        buf416 = buf415[0]
        buf417 = buf415[1]
        del buf415
        buf418 = buf412; del buf412  # reuse
        buf419 = empty((36, ), device='cuda', dtype=torch.float32)
        buf420 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_240, buf416, convolution_269, unsqueeze_1993, squeeze_808, buf418, buf419, buf420, 36, 6272, grid=grid(36), stream=stream0)
        buf421 = buf416; del buf416  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf421, relu_240, convolution_269, unsqueeze_1993, buf419, squeeze_808, buf418, primals_809, 225792, grid=grid(225792), stream=stream0)
        del convolution_269
        del primals_809
        del relu_240
        del squeeze_808
        del unsqueeze_1993
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf422 = aten.convolution_backward(buf421, relu_239, primals_808, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf421
        del primals_808
        buf423 = buf422[0]
        buf424 = buf422[1]
        del buf422
        buf425 = buf396; del buf396  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_80.run(buf425, relu_239, relu_241, buf409, buf423, 225792, grid=grid(225792), stream=stream0)
        del buf409
        del relu_239
        del relu_241
        buf426 = buf419; del buf419  # reuse
        buf427 = empty((36, ), device='cuda', dtype=torch.float32)
        buf428 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf425, convolution_268, unsqueeze_2005, squeeze_805, buf426, buf427, buf428, 36, 6272, grid=grid(36), stream=stream0)
        buf429 = buf423; del buf423  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf425, convolution_268, unsqueeze_2005, buf427, squeeze_805, buf426, primals_806, buf429, 225792, grid=grid(225792), stream=stream0)
        del convolution_268
        del primals_806
        del squeeze_805
        del unsqueeze_2005
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf430 = aten.convolution_backward(buf429, relu_238, primals_805, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf429
        del primals_805
        buf431 = buf430[0]
        buf432 = buf430[1]
        del buf430
        buf433 = buf427; del buf427  # reuse
        buf434 = empty((36, ), device='cuda', dtype=torch.float32)
        buf435 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_238, buf431, convolution_267, unsqueeze_2017, squeeze_802, buf433, buf434, buf435, 36, 6272, grid=grid(36), stream=stream0)
        buf436 = buf431; del buf431  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf436, relu_238, convolution_267, unsqueeze_2017, buf434, squeeze_802, buf433, primals_803, 225792, grid=grid(225792), stream=stream0)
        del convolution_267
        del primals_803
        del relu_238
        del squeeze_802
        del unsqueeze_2017
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf437 = aten.convolution_backward(buf436, relu_237, primals_802, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_802
        buf438 = buf437[0]
        buf439 = buf437[1]
        del buf437
        buf440 = buf434; del buf434  # reuse
        buf441 = empty((36, ), device='cuda', dtype=torch.float32)
        buf443 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_78.run(relu_237, buf425, buf438, convolution_266, unsqueeze_2029, squeeze_799, buf440, buf441, buf443, 36, 6272, grid=grid(36), stream=stream0)
        buf442 = buf436; del buf436  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_79.run(relu_237, buf425, buf438, convolution_266, unsqueeze_2029, buf441, squeeze_799, buf440, primals_800, buf442, 225792, grid=grid(225792), stream=stream0)
        del convolution_266
        del primals_800
        del squeeze_799
        del unsqueeze_2029
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf444 = aten.convolution_backward(buf442, relu_236, primals_799, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf442
        del primals_799
        buf445 = buf444[0]
        buf446 = buf444[1]
        del buf444
        buf447 = buf441; del buf441  # reuse
        buf448 = empty((36, ), device='cuda', dtype=torch.float32)
        buf449 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_236, buf445, convolution_265, unsqueeze_2041, squeeze_796, buf447, buf448, buf449, 36, 6272, grid=grid(36), stream=stream0)
        buf450 = buf445; del buf445  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf450, relu_236, convolution_265, unsqueeze_2041, buf448, squeeze_796, buf447, primals_797, 225792, grid=grid(225792), stream=stream0)
        del convolution_265
        del primals_797
        del relu_236
        del squeeze_796
        del unsqueeze_2041
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf451 = aten.convolution_backward(buf450, relu_221, primals_796, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf450
        del primals_796
        buf452 = buf451[0]
        buf453 = buf451[1]
        del buf451
        buf455 = reinterpret_tensor(buf390, (18, 4), (1, 18), 0); del buf390  # reuse
        buf457 = empty_strided((18, 4), (1, 18), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf454, convolution_264, unsqueeze_2053, buf455, buf457, 72, 6272, grid=grid(72), stream=stream0)
        buf456 = buf274; del buf274  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf455, buf456, 18, 4, grid=grid(18), stream=stream0)
        buf458 = empty((18, ), device='cuda', dtype=torch.float32)
        buf459 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf457, squeeze_793, buf458, buf459, 18, 4, grid=grid(18), stream=stream0)
        buf460 = buf250; del buf250  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_84.run(buf454, convolution_264, unsqueeze_2053, buf458, squeeze_793, buf456, primals_794, buf460, 451584, grid=grid(451584), stream=stream0)
        del convolution_264
        del primals_794
        del squeeze_793
        del unsqueeze_2053
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf461 = aten.convolution_backward(buf460, relu_234, primals_793, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf460
        del primals_793
        buf462 = buf461[0]
        buf463 = buf461[1]
        del buf461
        buf464 = buf457; del buf457  # reuse
        buf466 = buf455; del buf455  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_234, buf462, convolution_263, unsqueeze_2065, buf464, buf466, 72, 6272, grid=grid(72), stream=stream0)
        buf465 = buf458; del buf458  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf464, buf465, 18, 4, grid=grid(18), stream=stream0)
        buf467 = empty((18, ), device='cuda', dtype=torch.float32)
        buf468 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf466, squeeze_790, buf467, buf468, 18, 4, grid=grid(18), stream=stream0)
        buf469 = buf462; del buf462  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf469, relu_234, convolution_263, unsqueeze_2065, buf467, squeeze_790, buf465, primals_791, 451584, grid=grid(451584), stream=stream0)
        del convolution_263
        del primals_791
        del relu_234
        del squeeze_790
        del unsqueeze_2065
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf470 = aten.convolution_backward(buf469, relu_233, primals_790, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_790
        buf471 = buf470[0]
        buf472 = buf470[1]
        del buf470
        buf473 = buf466; del buf466  # reuse
        buf475 = buf464; del buf464  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_87.run(relu_233, buf454, buf471, convolution_262, unsqueeze_2077, buf473, buf475, 72, 6272, grid=grid(72), stream=stream0)
        buf474 = buf467; del buf467  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf473, buf474, 18, 4, grid=grid(18), stream=stream0)
        buf476 = empty((18, ), device='cuda', dtype=torch.float32)
        buf478 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf475, squeeze_787, buf476, buf478, 18, 4, grid=grid(18), stream=stream0)
        buf477 = buf469; del buf469  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_88.run(relu_233, buf454, buf471, convolution_262, unsqueeze_2077, buf476, squeeze_787, buf474, primals_788, buf477, 451584, grid=grid(451584), stream=stream0)
        del convolution_262
        del primals_788
        del squeeze_787
        del unsqueeze_2077
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf479 = aten.convolution_backward(buf477, relu_232, primals_787, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf477
        del primals_787
        buf480 = buf479[0]
        buf481 = buf479[1]
        del buf479
        buf482 = buf475; del buf475  # reuse
        buf484 = buf473; del buf473  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_232, buf480, convolution_261, unsqueeze_2089, buf482, buf484, 72, 6272, grid=grid(72), stream=stream0)
        buf483 = buf476; del buf476  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf482, buf483, 18, 4, grid=grid(18), stream=stream0)
        buf485 = empty((18, ), device='cuda', dtype=torch.float32)
        buf486 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf484, squeeze_784, buf485, buf486, 18, 4, grid=grid(18), stream=stream0)
        buf487 = buf480; del buf480  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf487, relu_232, convolution_261, unsqueeze_2089, buf485, squeeze_784, buf483, primals_785, 451584, grid=grid(451584), stream=stream0)
        del convolution_261
        del primals_785
        del relu_232
        del squeeze_784
        del unsqueeze_2089
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf488 = aten.convolution_backward(buf487, relu_231, primals_784, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf487
        del primals_784
        buf489 = buf488[0]
        buf490 = buf488[1]
        del buf488
        buf491 = buf454; del buf454  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_89.run(buf491, relu_231, relu_233, buf471, buf489, 451584, grid=grid(451584), stream=stream0)
        del buf471
        del relu_231
        del relu_233
        buf492 = buf484; del buf484  # reuse
        buf494 = buf482; del buf482  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf491, convolution_260, unsqueeze_2101, buf492, buf494, 72, 6272, grid=grid(72), stream=stream0)
        buf493 = buf485; del buf485  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf492, buf493, 18, 4, grid=grid(18), stream=stream0)
        buf495 = empty((18, ), device='cuda', dtype=torch.float32)
        buf496 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf494, squeeze_781, buf495, buf496, 18, 4, grid=grid(18), stream=stream0)
        buf497 = buf489; del buf489  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_84.run(buf491, convolution_260, unsqueeze_2101, buf495, squeeze_781, buf493, primals_782, buf497, 451584, grid=grid(451584), stream=stream0)
        del convolution_260
        del primals_782
        del squeeze_781
        del unsqueeze_2101
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf498 = aten.convolution_backward(buf497, relu_230, primals_781, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf497
        del primals_781
        buf499 = buf498[0]
        buf500 = buf498[1]
        del buf498
        buf501 = buf494; del buf494  # reuse
        buf503 = buf492; del buf492  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_230, buf499, convolution_259, unsqueeze_2113, buf501, buf503, 72, 6272, grid=grid(72), stream=stream0)
        buf502 = buf495; del buf495  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf501, buf502, 18, 4, grid=grid(18), stream=stream0)
        buf504 = empty((18, ), device='cuda', dtype=torch.float32)
        buf505 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf503, squeeze_778, buf504, buf505, 18, 4, grid=grid(18), stream=stream0)
        buf506 = buf499; del buf499  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf506, relu_230, convolution_259, unsqueeze_2113, buf504, squeeze_778, buf502, primals_779, 451584, grid=grid(451584), stream=stream0)
        del convolution_259
        del primals_779
        del relu_230
        del squeeze_778
        del unsqueeze_2113
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf507 = aten.convolution_backward(buf506, relu_229, primals_778, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_778
        buf508 = buf507[0]
        buf509 = buf507[1]
        del buf507
        buf510 = buf503; del buf503  # reuse
        buf512 = buf501; del buf501  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_87.run(relu_229, buf491, buf508, convolution_258, unsqueeze_2125, buf510, buf512, 72, 6272, grid=grid(72), stream=stream0)
        buf511 = buf504; del buf504  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf510, buf511, 18, 4, grid=grid(18), stream=stream0)
        buf513 = empty((18, ), device='cuda', dtype=torch.float32)
        buf515 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf512, squeeze_775, buf513, buf515, 18, 4, grid=grid(18), stream=stream0)
        buf514 = buf506; del buf506  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_88.run(relu_229, buf491, buf508, convolution_258, unsqueeze_2125, buf513, squeeze_775, buf511, primals_776, buf514, 451584, grid=grid(451584), stream=stream0)
        del convolution_258
        del primals_776
        del squeeze_775
        del unsqueeze_2125
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf516 = aten.convolution_backward(buf514, relu_228, primals_775, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf514
        del primals_775
        buf517 = buf516[0]
        buf518 = buf516[1]
        del buf516
        buf519 = buf512; del buf512  # reuse
        buf521 = buf510; del buf510  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_228, buf517, convolution_257, unsqueeze_2137, buf519, buf521, 72, 6272, grid=grid(72), stream=stream0)
        buf520 = buf513; del buf513  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf519, buf520, 18, 4, grid=grid(18), stream=stream0)
        buf522 = empty((18, ), device='cuda', dtype=torch.float32)
        buf523 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf521, squeeze_772, buf522, buf523, 18, 4, grid=grid(18), stream=stream0)
        buf524 = buf517; del buf517  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf524, relu_228, convolution_257, unsqueeze_2137, buf522, squeeze_772, buf520, primals_773, 451584, grid=grid(451584), stream=stream0)
        del convolution_257
        del primals_773
        del relu_228
        del squeeze_772
        del unsqueeze_2137
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf525 = aten.convolution_backward(buf524, relu_220, primals_772, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf524
        del primals_772
        buf526 = buf525[0]
        buf527 = buf525[1]
        del buf525
        buf528 = buf309; del buf309  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_66.run(buf528, relu_227, relu_253, buf322, buf336, 56448, grid=grid(56448), stream=stream0)
        del relu_227
        del relu_253
        buf529 = buf332; del buf332  # reuse
        buf530 = empty((144, ), device='cuda', dtype=torch.float32)
        buf536 = empty((144, ), device='cuda', dtype=torch.float32)
        buf549 = empty((144, ), device='cuda', dtype=torch.float32)
        buf531 = empty((144, ), device='cuda', dtype=torch.float32)
        buf537 = empty((144, ), device='cuda', dtype=torch.float32)
        buf550 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_90.run(buf528, convolution_256, unsqueeze_2149, convolution_255, unsqueeze_2161, convolution_253, unsqueeze_2185, squeeze_769, squeeze_766, squeeze_760, buf529, buf530, buf536, buf549, buf531, buf537, buf550, 144, 392, grid=grid(144), stream=stream0)
        buf532 = buf336; del buf336  # reuse
        buf538 = buf322; del buf322  # reuse
        buf551 = buf334; del buf334  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_91.run(buf528, convolution_256, unsqueeze_2149, buf530, squeeze_769, buf529, primals_770, convolution_255, unsqueeze_2161, buf536, squeeze_766, primals_767, convolution_253, unsqueeze_2185, buf549, squeeze_760, primals_761, buf532, buf538, buf551, 56448, grid=grid(56448), stream=stream0)
        del convolution_253
        del convolution_255
        del convolution_256
        del primals_761
        del primals_767
        del primals_770
        del squeeze_760
        del squeeze_766
        del squeeze_769
        del unsqueeze_2149
        del unsqueeze_2161
        del unsqueeze_2185
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf533 = aten.convolution_backward(buf532, relu_211, primals_769, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf532
        del primals_769
        buf534 = buf533[0]
        buf535 = buf533[1]
        del buf533
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf539 = aten.convolution_backward(buf538, relu_226, primals_766, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf538
        del primals_766
        buf540 = buf539[0]
        buf541 = buf539[1]
        del buf539
        buf542 = buf448; del buf448  # reuse
        buf543 = empty((36, ), device='cuda', dtype=torch.float32)
        buf544 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_29.run(relu_226, buf540, convolution_254, unsqueeze_2173, squeeze_763, buf542, buf543, buf544, 36, 1568, grid=grid(36), stream=stream0)
        buf545 = buf540; del buf540  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_30.run(buf545, relu_226, convolution_254, unsqueeze_2173, buf543, squeeze_763, buf542, primals_764, 56448, grid=grid(56448), stream=stream0)
        del convolution_254
        del primals_764
        del relu_226
        del squeeze_763
        del unsqueeze_2173
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf546 = aten.convolution_backward(buf545, relu_203, primals_763, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_763
        buf547 = buf546[0]
        buf548 = buf546[1]
        del buf546
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf552 = aten.convolution_backward(buf551, relu_225, primals_760, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_760
        buf553 = buf552[0]
        buf554 = buf552[1]
        del buf552
        buf555 = buf522; del buf522  # reuse
        buf556 = empty((18, ), device='cuda', dtype=torch.float32)
        buf557 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_31.run(relu_225, buf553, convolution_252, unsqueeze_2197, squeeze_757, buf555, buf556, buf557, 18, 1568, grid=grid(18), stream=stream0)
        buf558 = buf553; del buf553  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_32.run(buf558, relu_225, convolution_252, unsqueeze_2197, buf556, squeeze_757, buf555, primals_758, 28224, grid=grid(28224), stream=stream0)
        del convolution_252
        del primals_758
        del relu_225
        del squeeze_757
        del unsqueeze_2197
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf559 = aten.convolution_backward(buf558, relu_224, primals_757, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_757
        buf560 = buf559[0]
        buf561 = buf559[1]
        del buf559
        buf562 = buf556; del buf556  # reuse
        buf563 = empty((18, ), device='cuda', dtype=torch.float32)
        buf564 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_33.run(relu_224, buf560, convolution_251, unsqueeze_2209, squeeze_754, buf562, buf563, buf564, 18, 6272, grid=grid(18), stream=stream0)
        buf565 = buf560; del buf560  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_34.run(buf565, relu_224, convolution_251, unsqueeze_2209, buf563, squeeze_754, buf562, primals_755, 112896, grid=grid(112896), stream=stream0)
        del convolution_251
        del primals_755
        del relu_224
        del squeeze_754
        del unsqueeze_2209
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf566 = aten.convolution_backward(buf565, relu_195, primals_754, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf565
        del primals_754
        buf567 = buf566[0]
        buf568 = buf566[1]
        del buf566
        buf569 = buf367; del buf367  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_74.run(buf569, relu_223, relu_245, buf380, buf394, 112896, grid=grid(112896), stream=stream0)
        del relu_223
        del relu_245
        buf570 = reinterpret_tensor(buf558, (8, 72, 7, 7), (3528, 49, 7, 1), 0); del buf558  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_35.run(buf570, 28224, grid=grid(28224), stream=stream0)
        aten.index_put_(buf570, [None, None, unsqueeze_830, convert_element_type_73], buf569, True)
        buf573 = reinterpret_tensor(buf521, (72, ), (1, ), 0); del buf521  # reuse
        buf574 = reinterpret_tensor(buf519, (72, ), (1, ), 0); del buf519  # reuse
        buf575 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_37.run(buf570, convolution_250, unsqueeze_2221, squeeze_751, buf573, buf574, buf575, 72, 392, grid=grid(72), stream=stream0)
        buf572 = reinterpret_tensor(buf266, (8, 72, 7, 7), (3528, 49, 7, 1), 0); del buf266  # reuse
        buf576 = buf572; del buf572  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_38.run(buf576, buf570, convolution_250, unsqueeze_2221, buf574, squeeze_751, buf573, primals_752, 28224, grid=grid(28224), stream=stream0)
        del convolution_250
        del primals_752
        del squeeze_751
        del unsqueeze_2221
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf577 = aten.convolution_backward(buf576, relu_219, primals_751, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_751
        buf578 = buf577[0]
        buf579 = buf577[1]
        del buf577
        buf580 = buf574; del buf574  # reuse
        buf581 = empty((72, ), device='cuda', dtype=torch.float32)
        buf587 = empty((72, ), device='cuda', dtype=torch.float32)
        buf582 = empty((72, ), device='cuda', dtype=torch.float32)
        buf588 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_39.run(buf569, convolution_249, unsqueeze_2233, convolution_248, unsqueeze_2245, squeeze_748, squeeze_745, buf580, buf581, buf587, buf582, buf588, 72, 1568, grid=grid(72), stream=stream0)
        buf583 = buf394; del buf394  # reuse
        buf589 = buf380; del buf380  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_40.run(buf569, convolution_249, unsqueeze_2233, buf581, squeeze_748, buf580, primals_749, convolution_248, unsqueeze_2245, buf587, squeeze_745, primals_746, buf583, buf589, 112896, grid=grid(112896), stream=stream0)
        del convolution_248
        del convolution_249
        del primals_746
        del primals_749
        del squeeze_745
        del squeeze_748
        del unsqueeze_2233
        del unsqueeze_2245
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf584 = aten.convolution_backward(buf583, relu_203, primals_748, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf583
        del primals_748
        buf585 = buf584[0]
        buf586 = buf584[1]
        del buf584
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf590 = aten.convolution_backward(buf589, relu_222, primals_745, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_745
        buf591 = buf590[0]
        buf592 = buf590[1]
        del buf590
        buf593 = buf563; del buf563  # reuse
        buf594 = empty((18, ), device='cuda', dtype=torch.float32)
        buf595 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_33.run(relu_222, buf591, convolution_247, unsqueeze_2257, squeeze_742, buf593, buf594, buf595, 18, 6272, grid=grid(18), stream=stream0)
        buf596 = buf591; del buf591  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_34.run(buf596, relu_222, convolution_247, unsqueeze_2257, buf594, squeeze_742, buf593, primals_743, 112896, grid=grid(112896), stream=stream0)
        del convolution_247
        del primals_743
        del relu_222
        del squeeze_742
        del unsqueeze_2257
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf597 = aten.convolution_backward(buf596, relu_195, primals_742, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_742
        buf598 = buf597[0]
        buf599 = buf597[1]
        del buf597
        buf600 = buf425; del buf425  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_80.run(buf600, relu_221, relu_237, buf438, buf452, 225792, grid=grid(225792), stream=stream0)
        del buf438
        del relu_221
        del relu_237
        buf601 = buf228; del buf228  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_41.run(buf601, 14112, grid=grid(14112), stream=stream0)
        aten.index_put_(buf601, [None, None, unsqueeze_813, convert_element_type_69], buf600, True)
        buf604 = buf543; del buf543  # reuse
        buf605 = empty((36, ), device='cuda', dtype=torch.float32)
        buf606 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_43.run(buf601, convolution_246, unsqueeze_2269, squeeze_739, buf604, buf605, buf606, 36, 392, grid=grid(36), stream=stream0)
        buf603 = buf221; del buf221  # reuse
        buf607 = buf603; del buf603  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_44.run(buf607, buf601, convolution_246, unsqueeze_2269, buf605, squeeze_739, buf604, primals_740, 14112, grid=grid(14112), stream=stream0)
        del convolution_246
        del primals_740
        del squeeze_739
        del unsqueeze_2269
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf608 = aten.convolution_backward(buf607, relu_219, primals_739, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_739
        buf609 = buf608[0]
        buf610 = buf608[1]
        del buf608
        buf611 = reinterpret_tensor(buf551, (8, 36, 14, 14), (7056, 196, 14, 1), 0); del buf551  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_new_zeros_45.run(buf611, 56448, grid=grid(56448), stream=stream0)
        aten.index_put_(buf611, [None, None, unsqueeze_259, convert_element_type_13], buf600, True)
        buf614 = buf605; del buf605  # reuse
        buf615 = empty((36, ), device='cuda', dtype=torch.float32)
        buf616 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_46.run(buf611, convolution_245, unsqueeze_2281, squeeze_736, buf614, buf615, buf616, 36, 1568, grid=grid(36), stream=stream0)
        buf613 = buf545; del buf545  # reuse
        buf617 = buf613; del buf613  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_47.run(buf617, buf611, convolution_245, unsqueeze_2281, buf615, squeeze_736, buf614, primals_737, 56448, grid=grid(56448), stream=stream0)
        del buf611
        del convolution_245
        del primals_737
        del squeeze_736
        del unsqueeze_2281
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf618 = aten.convolution_backward(buf617, relu_211, primals_736, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf617
        del primals_736
        buf619 = buf618[0]
        buf620 = buf618[1]
        del buf618
        buf621 = buf615; del buf615  # reuse
        buf622 = empty((36, ), device='cuda', dtype=torch.float32)
        buf623 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf600, convolution_244, unsqueeze_2293, squeeze_733, buf621, buf622, buf623, 36, 6272, grid=grid(36), stream=stream0)
        buf624 = buf452; del buf452  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf600, convolution_244, unsqueeze_2293, buf622, squeeze_733, buf621, primals_734, buf624, 225792, grid=grid(225792), stream=stream0)
        del convolution_244
        del primals_734
        del squeeze_733
        del unsqueeze_2293
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf625 = aten.convolution_backward(buf624, relu_195, primals_733, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf624
        del primals_733
        buf626 = buf625[0]
        buf627 = buf625[1]
        del buf625
        buf628 = buf491; del buf491  # reuse
        buf833 = buf567; del buf567  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_92.run(buf628, buf833, relu_220, relu_229, buf508, buf526, relu_195, buf598, buf626, 451584, grid=grid(451584), stream=stream0)
        del buf508
        del buf526
        del buf598
        del buf626
        del relu_195
        del relu_220
        del relu_229
        buf629 = buf256; del buf256  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_50.run(buf629, 7056, grid=grid(7056), stream=stream0)
        aten.index_put_(buf629, [None, None, unsqueeze_799, convert_element_type_61], buf628, True)
        buf632 = buf594; del buf594  # reuse
        buf633 = empty((18, ), device='cuda', dtype=torch.float32)
        buf634 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_52.run(buf629, convolution_243, unsqueeze_2305, squeeze_730, buf632, buf633, buf634, 18, 392, grid=grid(18), stream=stream0)
        buf631 = buf249; del buf249  # reuse
        buf635 = buf631; del buf631  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_53.run(buf635, buf629, convolution_243, unsqueeze_2305, buf633, squeeze_730, buf632, primals_731, 7056, grid=grid(7056), stream=stream0)
        del convolution_243
        del primals_731
        del squeeze_730
        del unsqueeze_2305
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf636 = aten.convolution_backward(buf635, relu_219, primals_730, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_730
        buf637 = buf636[0]
        buf638 = buf636[1]
        del buf636
        buf639 = reinterpret_tensor(buf576, (8, 18, 14, 14), (3528, 196, 14, 1), 0); del buf576  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_35.run(buf639, 28224, grid=grid(28224), stream=stream0)
        aten.index_put_(buf639, [None, None, unsqueeze_250, convert_element_type_9], buf628, True)
        buf642 = buf633; del buf633  # reuse
        buf643 = empty((18, ), device='cuda', dtype=torch.float32)
        buf644 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_54.run(buf639, convolution_242, unsqueeze_2317, squeeze_727, buf642, buf643, buf644, 18, 1568, grid=grid(18), stream=stream0)
        buf641 = reinterpret_tensor(buf570, (8, 18, 14, 14), (3528, 196, 14, 1), 0); del buf570  # reuse
        buf645 = buf641; del buf641  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_55.run(buf645, buf639, convolution_242, unsqueeze_2317, buf643, squeeze_727, buf642, primals_728, 28224, grid=grid(28224), stream=stream0)
        del buf639
        del convolution_242
        del primals_728
        del squeeze_727
        del unsqueeze_2317
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf646 = aten.convolution_backward(buf645, relu_211, primals_727, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_727
        buf647 = buf646[0]
        buf648 = buf646[1]
        del buf646
        buf649 = buf596; del buf596  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_new_zeros_56.run(buf649, 112896, grid=grid(112896), stream=stream0)
        aten.index_put_(buf649, [None, None, unsqueeze_136, convert_element_type_1], buf628, True)
        buf652 = buf643; del buf643  # reuse
        buf653 = empty((18, ), device='cuda', dtype=torch.float32)
        buf654 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_57.run(buf649, convolution_241, unsqueeze_2329, squeeze_724, buf652, buf653, buf654, 18, 6272, grid=grid(18), stream=stream0)
        buf651 = reinterpret_tensor(buf589, (8, 18, 28, 28), (14112, 784, 28, 1), 0); del buf589  # reuse
        buf655 = buf651; del buf651  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_58.run(buf655, buf649, convolution_241, unsqueeze_2329, buf653, squeeze_724, buf652, primals_725, 112896, grid=grid(112896), stream=stream0)
        del buf649
        del convolution_241
        del primals_725
        del squeeze_724
        del unsqueeze_2329
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf656 = aten.convolution_backward(buf655, relu_203, primals_724, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf655
        del primals_724
        buf657 = buf656[0]
        buf658 = buf656[1]
        del buf656
        buf659 = buf528; del buf528  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_93.run(buf659, relu_219, buf578, buf609, buf637, 56448, grid=grid(56448), stream=stream0)
        del buf578
        del buf609
        del relu_219
        buf660 = buf549; del buf549  # reuse
        buf661 = buf536; del buf536  # reuse
        buf662 = buf530; del buf530  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_60.run(buf659, convolution_240, unsqueeze_2341, squeeze_721, buf660, buf661, buf662, 144, 392, grid=grid(144), stream=stream0)
        buf663 = buf637; del buf637  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_61.run(buf659, convolution_240, unsqueeze_2341, buf661, squeeze_721, buf660, primals_722, buf663, 56448, grid=grid(56448), stream=stream0)
        del convolution_240
        del primals_722
        del squeeze_721
        del unsqueeze_2341
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf664 = aten.convolution_backward(buf663, relu_218, primals_721, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf663
        del primals_721
        buf665 = buf664[0]
        buf666 = buf664[1]
        del buf664
        buf667 = buf661; del buf661  # reuse
        buf668 = empty((144, ), device='cuda', dtype=torch.float32)
        buf669 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_62.run(relu_218, buf665, convolution_239, unsqueeze_2353, squeeze_718, buf667, buf668, buf669, 144, 392, grid=grid(144), stream=stream0)
        buf670 = buf665; del buf665  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_63.run(buf670, relu_218, convolution_239, unsqueeze_2353, buf668, squeeze_718, buf667, primals_719, 56448, grid=grid(56448), stream=stream0)
        del convolution_239
        del primals_719
        del relu_218
        del squeeze_718
        del unsqueeze_2353
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf671 = aten.convolution_backward(buf670, relu_217, primals_718, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_718
        buf672 = buf671[0]
        buf673 = buf671[1]
        del buf671
        buf674 = buf668; del buf668  # reuse
        buf675 = empty((144, ), device='cuda', dtype=torch.float32)
        buf677 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_add_native_batch_norm_backward_threshold_backward_64.run(relu_217, buf659, buf672, convolution_238, unsqueeze_2365, squeeze_715, buf674, buf675, buf677, 144, 392, grid=grid(144), stream=stream0)
        buf676 = buf670; del buf670  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_65.run(relu_217, buf659, buf672, convolution_238, unsqueeze_2365, buf675, squeeze_715, buf674, primals_716, buf676, 56448, grid=grid(56448), stream=stream0)
        del convolution_238
        del primals_716
        del squeeze_715
        del unsqueeze_2365
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf678 = aten.convolution_backward(buf676, relu_216, primals_715, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf676
        del primals_715
        buf679 = buf678[0]
        buf680 = buf678[1]
        del buf678
        buf681 = buf675; del buf675  # reuse
        buf682 = empty((144, ), device='cuda', dtype=torch.float32)
        buf683 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_62.run(relu_216, buf679, convolution_237, unsqueeze_2377, squeeze_712, buf681, buf682, buf683, 144, 392, grid=grid(144), stream=stream0)
        buf684 = buf679; del buf679  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_63.run(buf684, relu_216, convolution_237, unsqueeze_2377, buf682, squeeze_712, buf681, primals_713, 56448, grid=grid(56448), stream=stream0)
        del convolution_237
        del primals_713
        del relu_216
        del squeeze_712
        del unsqueeze_2377
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf685 = aten.convolution_backward(buf684, relu_215, primals_712, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf684
        del primals_712
        buf686 = buf685[0]
        buf687 = buf685[1]
        del buf685
        buf688 = buf659; del buf659  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_66.run(buf688, relu_215, relu_217, buf672, buf686, 56448, grid=grid(56448), stream=stream0)
        del buf672
        del relu_215
        del relu_217
        buf689 = buf682; del buf682  # reuse
        buf690 = empty((144, ), device='cuda', dtype=torch.float32)
        buf691 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_60.run(buf688, convolution_236, unsqueeze_2389, squeeze_709, buf689, buf690, buf691, 144, 392, grid=grid(144), stream=stream0)
        buf692 = buf686; del buf686  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_61.run(buf688, convolution_236, unsqueeze_2389, buf690, squeeze_709, buf689, primals_710, buf692, 56448, grid=grid(56448), stream=stream0)
        del convolution_236
        del primals_710
        del squeeze_709
        del unsqueeze_2389
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf693 = aten.convolution_backward(buf692, relu_214, primals_709, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf692
        del primals_709
        buf694 = buf693[0]
        buf695 = buf693[1]
        del buf693
        buf696 = buf690; del buf690  # reuse
        buf697 = empty((144, ), device='cuda', dtype=torch.float32)
        buf698 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_62.run(relu_214, buf694, convolution_235, unsqueeze_2401, squeeze_706, buf696, buf697, buf698, 144, 392, grid=grid(144), stream=stream0)
        buf699 = buf694; del buf694  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_63.run(buf699, relu_214, convolution_235, unsqueeze_2401, buf697, squeeze_706, buf696, primals_707, 56448, grid=grid(56448), stream=stream0)
        del convolution_235
        del primals_707
        del relu_214
        del squeeze_706
        del unsqueeze_2401
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf700 = aten.convolution_backward(buf699, relu_213, primals_706, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_706
        buf701 = buf700[0]
        buf702 = buf700[1]
        del buf700
        buf703 = buf697; del buf697  # reuse
        buf704 = empty((144, ), device='cuda', dtype=torch.float32)
        buf706 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_add_native_batch_norm_backward_threshold_backward_64.run(relu_213, buf688, buf701, convolution_234, unsqueeze_2413, squeeze_703, buf703, buf704, buf706, 144, 392, grid=grid(144), stream=stream0)
        buf705 = buf699; del buf699  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_65.run(relu_213, buf688, buf701, convolution_234, unsqueeze_2413, buf704, squeeze_703, buf703, primals_704, buf705, 56448, grid=grid(56448), stream=stream0)
        del convolution_234
        del primals_704
        del squeeze_703
        del unsqueeze_2413
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf707 = aten.convolution_backward(buf705, relu_212, primals_703, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf705
        del primals_703
        buf708 = buf707[0]
        buf709 = buf707[1]
        del buf707
        buf710 = buf704; del buf704  # reuse
        buf711 = empty((144, ), device='cuda', dtype=torch.float32)
        buf712 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_62.run(relu_212, buf708, convolution_233, unsqueeze_2425, squeeze_700, buf710, buf711, buf712, 144, 392, grid=grid(144), stream=stream0)
        buf713 = buf708; del buf708  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_63.run(buf713, relu_212, convolution_233, unsqueeze_2425, buf711, squeeze_700, buf710, primals_701, 56448, grid=grid(56448), stream=stream0)
        del convolution_233
        del primals_701
        del relu_212
        del squeeze_700
        del unsqueeze_2425
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf714 = aten.convolution_backward(buf713, relu_187, primals_700, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_700
        buf715 = buf714[0]
        buf716 = buf714[1]
        del buf714
        buf717 = buf534; del buf534  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_67.run(buf717, relu_211, buf569, buf619, buf647, 112896, grid=grid(112896), stream=stream0)
        del buf569
        del buf619
        del relu_211
        buf718 = buf587; del buf587  # reuse
        buf719 = buf581; del buf581  # reuse
        buf720 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_68.run(buf717, convolution_232, unsqueeze_2437, squeeze_697, buf718, buf719, buf720, 72, 1568, grid=grid(72), stream=stream0)
        buf721 = buf647; del buf647  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_69.run(buf717, convolution_232, unsqueeze_2437, buf719, squeeze_697, buf718, primals_698, buf721, 112896, grid=grid(112896), stream=stream0)
        del convolution_232
        del primals_698
        del squeeze_697
        del unsqueeze_2437
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf722 = aten.convolution_backward(buf721, relu_210, primals_697, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf721
        del primals_697
        buf723 = buf722[0]
        buf724 = buf722[1]
        del buf722
        buf725 = buf719; del buf719  # reuse
        buf726 = empty((72, ), device='cuda', dtype=torch.float32)
        buf727 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_210, buf723, convolution_231, unsqueeze_2449, squeeze_694, buf725, buf726, buf727, 72, 1568, grid=grid(72), stream=stream0)
        buf728 = buf723; del buf723  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf728, relu_210, convolution_231, unsqueeze_2449, buf726, squeeze_694, buf725, primals_695, 112896, grid=grid(112896), stream=stream0)
        del convolution_231
        del primals_695
        del relu_210
        del squeeze_694
        del unsqueeze_2449
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf729 = aten.convolution_backward(buf728, relu_209, primals_694, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_694
        buf730 = buf729[0]
        buf731 = buf729[1]
        del buf729
        buf732 = buf726; del buf726  # reuse
        buf733 = empty((72, ), device='cuda', dtype=torch.float32)
        buf735 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_72.run(relu_209, buf717, buf730, convolution_230, unsqueeze_2461, squeeze_691, buf732, buf733, buf735, 72, 1568, grid=grid(72), stream=stream0)
        buf734 = buf728; del buf728  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_73.run(relu_209, buf717, buf730, convolution_230, unsqueeze_2461, buf733, squeeze_691, buf732, primals_692, buf734, 112896, grid=grid(112896), stream=stream0)
        del convolution_230
        del primals_692
        del squeeze_691
        del unsqueeze_2461
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf736 = aten.convolution_backward(buf734, relu_208, primals_691, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf734
        del primals_691
        buf737 = buf736[0]
        buf738 = buf736[1]
        del buf736
        buf739 = buf733; del buf733  # reuse
        buf740 = empty((72, ), device='cuda', dtype=torch.float32)
        buf741 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_208, buf737, convolution_229, unsqueeze_2473, squeeze_688, buf739, buf740, buf741, 72, 1568, grid=grid(72), stream=stream0)
        buf742 = buf737; del buf737  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf742, relu_208, convolution_229, unsqueeze_2473, buf740, squeeze_688, buf739, primals_689, 112896, grid=grid(112896), stream=stream0)
        del convolution_229
        del primals_689
        del relu_208
        del squeeze_688
        del unsqueeze_2473
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf743 = aten.convolution_backward(buf742, relu_207, primals_688, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf742
        del primals_688
        buf744 = buf743[0]
        buf745 = buf743[1]
        del buf743
        buf746 = buf717; del buf717  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_74.run(buf746, relu_207, relu_209, buf730, buf744, 112896, grid=grid(112896), stream=stream0)
        del buf730
        del relu_207
        del relu_209
        buf747 = buf740; del buf740  # reuse
        buf748 = empty((72, ), device='cuda', dtype=torch.float32)
        buf749 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_68.run(buf746, convolution_228, unsqueeze_2485, squeeze_685, buf747, buf748, buf749, 72, 1568, grid=grid(72), stream=stream0)
        buf750 = buf744; del buf744  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_69.run(buf746, convolution_228, unsqueeze_2485, buf748, squeeze_685, buf747, primals_686, buf750, 112896, grid=grid(112896), stream=stream0)
        del convolution_228
        del primals_686
        del squeeze_685
        del unsqueeze_2485
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf751 = aten.convolution_backward(buf750, relu_206, primals_685, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf750
        del primals_685
        buf752 = buf751[0]
        buf753 = buf751[1]
        del buf751
        buf754 = buf748; del buf748  # reuse
        buf755 = empty((72, ), device='cuda', dtype=torch.float32)
        buf756 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_206, buf752, convolution_227, unsqueeze_2497, squeeze_682, buf754, buf755, buf756, 72, 1568, grid=grid(72), stream=stream0)
        buf757 = buf752; del buf752  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf757, relu_206, convolution_227, unsqueeze_2497, buf755, squeeze_682, buf754, primals_683, 112896, grid=grid(112896), stream=stream0)
        del convolution_227
        del primals_683
        del relu_206
        del squeeze_682
        del unsqueeze_2497
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf758 = aten.convolution_backward(buf757, relu_205, primals_682, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_682
        buf759 = buf758[0]
        buf760 = buf758[1]
        del buf758
        buf761 = buf755; del buf755  # reuse
        buf762 = empty((72, ), device='cuda', dtype=torch.float32)
        buf764 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_72.run(relu_205, buf746, buf759, convolution_226, unsqueeze_2509, squeeze_679, buf761, buf762, buf764, 72, 1568, grid=grid(72), stream=stream0)
        buf763 = buf757; del buf757  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_73.run(relu_205, buf746, buf759, convolution_226, unsqueeze_2509, buf762, squeeze_679, buf761, primals_680, buf763, 112896, grid=grid(112896), stream=stream0)
        del convolution_226
        del primals_680
        del squeeze_679
        del unsqueeze_2509
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf765 = aten.convolution_backward(buf763, relu_204, primals_679, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf763
        del primals_679
        buf766 = buf765[0]
        buf767 = buf765[1]
        del buf765
        buf768 = buf762; del buf762  # reuse
        buf769 = empty((72, ), device='cuda', dtype=torch.float32)
        buf770 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_204, buf766, convolution_225, unsqueeze_2521, squeeze_676, buf768, buf769, buf770, 72, 1568, grid=grid(72), stream=stream0)
        buf771 = buf766; del buf766  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf771, relu_204, convolution_225, unsqueeze_2521, buf769, squeeze_676, buf768, primals_677, 112896, grid=grid(112896), stream=stream0)
        del convolution_225
        del primals_677
        del relu_204
        del squeeze_676
        del unsqueeze_2521
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf772 = aten.convolution_backward(buf771, relu_183, primals_676, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf771
        del primals_676
        buf773 = buf772[0]
        buf774 = buf772[1]
        del buf772
        buf775 = buf547; del buf547  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_75.run(buf775, relu_203, buf585, buf600, buf657, 225792, grid=grid(225792), stream=stream0)
        del buf585
        del buf600
        del relu_203
        buf776 = buf622; del buf622  # reuse
        buf777 = empty((36, ), device='cuda', dtype=torch.float32)
        buf778 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf775, convolution_224, unsqueeze_2533, squeeze_673, buf776, buf777, buf778, 36, 6272, grid=grid(36), stream=stream0)
        buf779 = buf657; del buf657  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf775, convolution_224, unsqueeze_2533, buf777, squeeze_673, buf776, primals_674, buf779, 225792, grid=grid(225792), stream=stream0)
        del convolution_224
        del primals_674
        del squeeze_673
        del unsqueeze_2533
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf780 = aten.convolution_backward(buf779, relu_202, primals_673, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf779
        del primals_673
        buf781 = buf780[0]
        buf782 = buf780[1]
        del buf780
        buf783 = buf777; del buf777  # reuse
        buf784 = empty((36, ), device='cuda', dtype=torch.float32)
        buf785 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_202, buf781, convolution_223, unsqueeze_2545, squeeze_670, buf783, buf784, buf785, 36, 6272, grid=grid(36), stream=stream0)
        buf786 = buf781; del buf781  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf786, relu_202, convolution_223, unsqueeze_2545, buf784, squeeze_670, buf783, primals_671, 225792, grid=grid(225792), stream=stream0)
        del convolution_223
        del primals_671
        del relu_202
        del squeeze_670
        del unsqueeze_2545
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf787 = aten.convolution_backward(buf786, relu_201, primals_670, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_670
        buf788 = buf787[0]
        buf789 = buf787[1]
        del buf787
        buf790 = buf784; del buf784  # reuse
        buf791 = empty((36, ), device='cuda', dtype=torch.float32)
        buf793 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_78.run(relu_201, buf775, buf788, convolution_222, unsqueeze_2557, squeeze_667, buf790, buf791, buf793, 36, 6272, grid=grid(36), stream=stream0)
        buf792 = buf786; del buf786  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_79.run(relu_201, buf775, buf788, convolution_222, unsqueeze_2557, buf791, squeeze_667, buf790, primals_668, buf792, 225792, grid=grid(225792), stream=stream0)
        del convolution_222
        del primals_668
        del squeeze_667
        del unsqueeze_2557
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf794 = aten.convolution_backward(buf792, relu_200, primals_667, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf792
        del primals_667
        buf795 = buf794[0]
        buf796 = buf794[1]
        del buf794
        buf797 = buf791; del buf791  # reuse
        buf798 = empty((36, ), device='cuda', dtype=torch.float32)
        buf799 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_200, buf795, convolution_221, unsqueeze_2569, squeeze_664, buf797, buf798, buf799, 36, 6272, grid=grid(36), stream=stream0)
        buf800 = buf795; del buf795  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf800, relu_200, convolution_221, unsqueeze_2569, buf798, squeeze_664, buf797, primals_665, 225792, grid=grid(225792), stream=stream0)
        del convolution_221
        del primals_665
        del relu_200
        del squeeze_664
        del unsqueeze_2569
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf801 = aten.convolution_backward(buf800, relu_199, primals_664, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf800
        del primals_664
        buf802 = buf801[0]
        buf803 = buf801[1]
        del buf801
        buf804 = buf775; del buf775  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_80.run(buf804, relu_199, relu_201, buf788, buf802, 225792, grid=grid(225792), stream=stream0)
        del buf788
        del relu_199
        del relu_201
        buf805 = buf798; del buf798  # reuse
        buf806 = empty((36, ), device='cuda', dtype=torch.float32)
        buf807 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf804, convolution_220, unsqueeze_2581, squeeze_661, buf805, buf806, buf807, 36, 6272, grid=grid(36), stream=stream0)
        buf808 = buf802; del buf802  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf804, convolution_220, unsqueeze_2581, buf806, squeeze_661, buf805, primals_662, buf808, 225792, grid=grid(225792), stream=stream0)
        del convolution_220
        del primals_662
        del squeeze_661
        del unsqueeze_2581
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf809 = aten.convolution_backward(buf808, relu_198, primals_661, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf808
        del primals_661
        buf810 = buf809[0]
        buf811 = buf809[1]
        del buf809
        buf812 = buf806; del buf806  # reuse
        buf813 = empty((36, ), device='cuda', dtype=torch.float32)
        buf814 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_198, buf810, convolution_219, unsqueeze_2593, squeeze_658, buf812, buf813, buf814, 36, 6272, grid=grid(36), stream=stream0)
        buf815 = buf810; del buf810  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf815, relu_198, convolution_219, unsqueeze_2593, buf813, squeeze_658, buf812, primals_659, 225792, grid=grid(225792), stream=stream0)
        del convolution_219
        del primals_659
        del relu_198
        del squeeze_658
        del unsqueeze_2593
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf816 = aten.convolution_backward(buf815, relu_197, primals_658, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_658
        buf817 = buf816[0]
        buf818 = buf816[1]
        del buf816
        buf819 = buf813; del buf813  # reuse
        buf820 = empty((36, ), device='cuda', dtype=torch.float32)
        buf822 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_78.run(relu_197, buf804, buf817, convolution_218, unsqueeze_2605, squeeze_655, buf819, buf820, buf822, 36, 6272, grid=grid(36), stream=stream0)
        buf821 = buf815; del buf815  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_79.run(relu_197, buf804, buf817, convolution_218, unsqueeze_2605, buf820, squeeze_655, buf819, primals_656, buf821, 225792, grid=grid(225792), stream=stream0)
        del convolution_218
        del primals_656
        del squeeze_655
        del unsqueeze_2605
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf823 = aten.convolution_backward(buf821, relu_196, primals_655, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf821
        del primals_655
        buf824 = buf823[0]
        buf825 = buf823[1]
        del buf823
        buf826 = buf820; del buf820  # reuse
        buf827 = empty((36, ), device='cuda', dtype=torch.float32)
        buf828 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_196, buf824, convolution_217, unsqueeze_2617, squeeze_652, buf826, buf827, buf828, 36, 6272, grid=grid(36), stream=stream0)
        buf829 = buf824; del buf824  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf829, relu_196, convolution_217, unsqueeze_2617, buf827, squeeze_652, buf826, primals_653, 225792, grid=grid(225792), stream=stream0)
        del convolution_217
        del primals_653
        del relu_196
        del squeeze_652
        del unsqueeze_2617
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf830 = aten.convolution_backward(buf829, relu_181, primals_652, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf829
        del primals_652
        buf831 = buf830[0]
        buf832 = buf830[1]
        del buf830
        buf834 = reinterpret_tensor(buf769, (18, 4), (1, 18), 0); del buf769  # reuse
        buf836 = empty_strided((18, 4), (1, 18), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf833, convolution_216, unsqueeze_2629, buf834, buf836, 72, 6272, grid=grid(72), stream=stream0)
        buf835 = buf653; del buf653  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf834, buf835, 18, 4, grid=grid(18), stream=stream0)
        buf837 = empty((18, ), device='cuda', dtype=torch.float32)
        buf838 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf836, squeeze_649, buf837, buf838, 18, 4, grid=grid(18), stream=stream0)
        buf839 = buf628; del buf628  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_84.run(buf833, convolution_216, unsqueeze_2629, buf837, squeeze_649, buf835, primals_650, buf839, 451584, grid=grid(451584), stream=stream0)
        del convolution_216
        del primals_650
        del squeeze_649
        del unsqueeze_2629
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf840 = aten.convolution_backward(buf839, relu_194, primals_649, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf839
        del primals_649
        buf841 = buf840[0]
        buf842 = buf840[1]
        del buf840
        buf843 = buf836; del buf836  # reuse
        buf845 = buf834; del buf834  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_194, buf841, convolution_215, unsqueeze_2641, buf843, buf845, 72, 6272, grid=grid(72), stream=stream0)
        buf844 = buf837; del buf837  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf843, buf844, 18, 4, grid=grid(18), stream=stream0)
        buf846 = empty((18, ), device='cuda', dtype=torch.float32)
        buf847 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf845, squeeze_646, buf846, buf847, 18, 4, grid=grid(18), stream=stream0)
        buf848 = buf841; del buf841  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf848, relu_194, convolution_215, unsqueeze_2641, buf846, squeeze_646, buf844, primals_647, 451584, grid=grid(451584), stream=stream0)
        del convolution_215
        del primals_647
        del relu_194
        del squeeze_646
        del unsqueeze_2641
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf849 = aten.convolution_backward(buf848, relu_193, primals_646, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_646
        buf850 = buf849[0]
        buf851 = buf849[1]
        del buf849
        buf852 = buf845; del buf845  # reuse
        buf854 = buf843; del buf843  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_87.run(relu_193, buf833, buf850, convolution_214, unsqueeze_2653, buf852, buf854, 72, 6272, grid=grid(72), stream=stream0)
        buf853 = buf846; del buf846  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf852, buf853, 18, 4, grid=grid(18), stream=stream0)
        buf855 = empty((18, ), device='cuda', dtype=torch.float32)
        buf857 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf854, squeeze_643, buf855, buf857, 18, 4, grid=grid(18), stream=stream0)
        buf856 = buf848; del buf848  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_88.run(relu_193, buf833, buf850, convolution_214, unsqueeze_2653, buf855, squeeze_643, buf853, primals_644, buf856, 451584, grid=grid(451584), stream=stream0)
        del convolution_214
        del primals_644
        del squeeze_643
        del unsqueeze_2653
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf858 = aten.convolution_backward(buf856, relu_192, primals_643, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf856
        del primals_643
        buf859 = buf858[0]
        buf860 = buf858[1]
        del buf858
        buf861 = buf854; del buf854  # reuse
        buf863 = buf852; del buf852  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_192, buf859, convolution_213, unsqueeze_2665, buf861, buf863, 72, 6272, grid=grid(72), stream=stream0)
        buf862 = buf855; del buf855  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf861, buf862, 18, 4, grid=grid(18), stream=stream0)
        buf864 = empty((18, ), device='cuda', dtype=torch.float32)
        buf865 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf863, squeeze_640, buf864, buf865, 18, 4, grid=grid(18), stream=stream0)
        buf866 = buf859; del buf859  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf866, relu_192, convolution_213, unsqueeze_2665, buf864, squeeze_640, buf862, primals_641, 451584, grid=grid(451584), stream=stream0)
        del convolution_213
        del primals_641
        del relu_192
        del squeeze_640
        del unsqueeze_2665
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf867 = aten.convolution_backward(buf866, relu_191, primals_640, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf866
        del primals_640
        buf868 = buf867[0]
        buf869 = buf867[1]
        del buf867
        buf870 = buf833; del buf833  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_89.run(buf870, relu_191, relu_193, buf850, buf868, 451584, grid=grid(451584), stream=stream0)
        del buf850
        del relu_191
        del relu_193
        buf871 = buf863; del buf863  # reuse
        buf873 = buf861; del buf861  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf870, convolution_212, unsqueeze_2677, buf871, buf873, 72, 6272, grid=grid(72), stream=stream0)
        buf872 = buf864; del buf864  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf871, buf872, 18, 4, grid=grid(18), stream=stream0)
        buf874 = empty((18, ), device='cuda', dtype=torch.float32)
        buf875 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf873, squeeze_637, buf874, buf875, 18, 4, grid=grid(18), stream=stream0)
        buf876 = buf868; del buf868  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_84.run(buf870, convolution_212, unsqueeze_2677, buf874, squeeze_637, buf872, primals_638, buf876, 451584, grid=grid(451584), stream=stream0)
        del convolution_212
        del primals_638
        del squeeze_637
        del unsqueeze_2677
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf877 = aten.convolution_backward(buf876, relu_190, primals_637, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf876
        del primals_637
        buf878 = buf877[0]
        buf879 = buf877[1]
        del buf877
        buf880 = buf873; del buf873  # reuse
        buf882 = buf871; del buf871  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_190, buf878, convolution_211, unsqueeze_2689, buf880, buf882, 72, 6272, grid=grid(72), stream=stream0)
        buf881 = buf874; del buf874  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf880, buf881, 18, 4, grid=grid(18), stream=stream0)
        buf883 = empty((18, ), device='cuda', dtype=torch.float32)
        buf884 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf882, squeeze_634, buf883, buf884, 18, 4, grid=grid(18), stream=stream0)
        buf885 = buf878; del buf878  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf885, relu_190, convolution_211, unsqueeze_2689, buf883, squeeze_634, buf881, primals_635, 451584, grid=grid(451584), stream=stream0)
        del convolution_211
        del primals_635
        del relu_190
        del squeeze_634
        del unsqueeze_2689
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf886 = aten.convolution_backward(buf885, relu_189, primals_634, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_634
        buf887 = buf886[0]
        buf888 = buf886[1]
        del buf886
        buf889 = buf882; del buf882  # reuse
        buf891 = buf880; del buf880  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_87.run(relu_189, buf870, buf887, convolution_210, unsqueeze_2701, buf889, buf891, 72, 6272, grid=grid(72), stream=stream0)
        buf890 = buf883; del buf883  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf889, buf890, 18, 4, grid=grid(18), stream=stream0)
        buf892 = empty((18, ), device='cuda', dtype=torch.float32)
        buf894 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf891, squeeze_631, buf892, buf894, 18, 4, grid=grid(18), stream=stream0)
        buf893 = buf885; del buf885  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_88.run(relu_189, buf870, buf887, convolution_210, unsqueeze_2701, buf892, squeeze_631, buf890, primals_632, buf893, 451584, grid=grid(451584), stream=stream0)
        del convolution_210
        del primals_632
        del squeeze_631
        del unsqueeze_2701
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf895 = aten.convolution_backward(buf893, relu_188, primals_631, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf893
        del primals_631
        buf896 = buf895[0]
        buf897 = buf895[1]
        del buf895
        buf898 = buf891; del buf891  # reuse
        buf900 = buf889; del buf889  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_188, buf896, convolution_209, unsqueeze_2713, buf898, buf900, 72, 6272, grid=grid(72), stream=stream0)
        buf899 = buf892; del buf892  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf898, buf899, 18, 4, grid=grid(18), stream=stream0)
        buf901 = empty((18, ), device='cuda', dtype=torch.float32)
        buf902 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf900, squeeze_628, buf901, buf902, 18, 4, grid=grid(18), stream=stream0)
        buf903 = buf896; del buf896  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf903, relu_188, convolution_209, unsqueeze_2713, buf901, squeeze_628, buf899, primals_629, 451584, grid=grid(451584), stream=stream0)
        del convolution_209
        del primals_629
        del relu_188
        del squeeze_628
        del unsqueeze_2713
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf904 = aten.convolution_backward(buf903, relu_180, primals_628, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf903
        del primals_628
        buf905 = buf904[0]
        buf906 = buf904[1]
        del buf904
        buf907 = buf688; del buf688  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_66.run(buf907, relu_187, relu_213, buf701, buf715, 56448, grid=grid(56448), stream=stream0)
        del relu_187
        del relu_213
        buf908 = buf711; del buf711  # reuse
        buf909 = empty((144, ), device='cuda', dtype=torch.float32)
        buf915 = empty((144, ), device='cuda', dtype=torch.float32)
        buf928 = empty((144, ), device='cuda', dtype=torch.float32)
        buf910 = empty((144, ), device='cuda', dtype=torch.float32)
        buf916 = empty((144, ), device='cuda', dtype=torch.float32)
        buf929 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_90.run(buf907, convolution_208, unsqueeze_2725, convolution_207, unsqueeze_2737, convolution_205, unsqueeze_2761, squeeze_625, squeeze_622, squeeze_616, buf908, buf909, buf915, buf928, buf910, buf916, buf929, 144, 392, grid=grid(144), stream=stream0)
        buf911 = buf715; del buf715  # reuse
        buf917 = buf701; del buf701  # reuse
        buf930 = buf713; del buf713  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_91.run(buf907, convolution_208, unsqueeze_2725, buf909, squeeze_625, buf908, primals_626, convolution_207, unsqueeze_2737, buf915, squeeze_622, primals_623, convolution_205, unsqueeze_2761, buf928, squeeze_616, primals_617, buf911, buf917, buf930, 56448, grid=grid(56448), stream=stream0)
        del convolution_205
        del convolution_207
        del convolution_208
        del primals_617
        del primals_623
        del primals_626
        del squeeze_616
        del squeeze_622
        del squeeze_625
        del unsqueeze_2725
        del unsqueeze_2737
        del unsqueeze_2761
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf912 = aten.convolution_backward(buf911, relu_171, primals_625, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf911
        del primals_625
        buf913 = buf912[0]
        buf914 = buf912[1]
        del buf912
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf918 = aten.convolution_backward(buf917, relu_186, primals_622, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf917
        del primals_622
        buf919 = buf918[0]
        buf920 = buf918[1]
        del buf918
        buf921 = buf827; del buf827  # reuse
        buf922 = empty((36, ), device='cuda', dtype=torch.float32)
        buf923 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_29.run(relu_186, buf919, convolution_206, unsqueeze_2749, squeeze_619, buf921, buf922, buf923, 36, 1568, grid=grid(36), stream=stream0)
        buf924 = buf919; del buf919  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_30.run(buf924, relu_186, convolution_206, unsqueeze_2749, buf922, squeeze_619, buf921, primals_620, 56448, grid=grid(56448), stream=stream0)
        del convolution_206
        del primals_620
        del relu_186
        del squeeze_619
        del unsqueeze_2749
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf925 = aten.convolution_backward(buf924, relu_163, primals_619, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_619
        buf926 = buf925[0]
        buf927 = buf925[1]
        del buf925
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf931 = aten.convolution_backward(buf930, relu_185, primals_616, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_616
        buf932 = buf931[0]
        buf933 = buf931[1]
        del buf931
        buf934 = buf901; del buf901  # reuse
        buf935 = empty((18, ), device='cuda', dtype=torch.float32)
        buf936 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_31.run(relu_185, buf932, convolution_204, unsqueeze_2773, squeeze_613, buf934, buf935, buf936, 18, 1568, grid=grid(18), stream=stream0)
        buf937 = buf932; del buf932  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_32.run(buf937, relu_185, convolution_204, unsqueeze_2773, buf935, squeeze_613, buf934, primals_614, 28224, grid=grid(28224), stream=stream0)
        del convolution_204
        del primals_614
        del relu_185
        del squeeze_613
        del unsqueeze_2773
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf938 = aten.convolution_backward(buf937, relu_184, primals_613, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_613
        buf939 = buf938[0]
        buf940 = buf938[1]
        del buf938
        buf941 = buf935; del buf935  # reuse
        buf942 = empty((18, ), device='cuda', dtype=torch.float32)
        buf943 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_33.run(relu_184, buf939, convolution_203, unsqueeze_2785, squeeze_610, buf941, buf942, buf943, 18, 6272, grid=grid(18), stream=stream0)
        buf944 = buf939; del buf939  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_34.run(buf944, relu_184, convolution_203, unsqueeze_2785, buf942, squeeze_610, buf941, primals_611, 112896, grid=grid(112896), stream=stream0)
        del convolution_203
        del primals_611
        del relu_184
        del squeeze_610
        del unsqueeze_2785
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf945 = aten.convolution_backward(buf944, relu_155, primals_610, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf944
        del primals_610
        buf946 = buf945[0]
        buf947 = buf945[1]
        del buf945
        buf948 = buf746; del buf746  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_74.run(buf948, relu_183, relu_205, buf759, buf773, 112896, grid=grid(112896), stream=stream0)
        del relu_183
        del relu_205
        buf949 = reinterpret_tensor(buf937, (8, 72, 7, 7), (3528, 49, 7, 1), 0); del buf937  # reuse
        # Source Nodes: [], Original ATen: [aten.new_zeros]
        triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_35.run(buf949, 28224, grid=grid(28224), stream=stream0)
        aten.index_put_(buf949, [None, None, unsqueeze_830, convert_element_type_73], buf948, True)
        del convert_element_type_73
        del unsqueeze_830
        buf952 = reinterpret_tensor(buf900, (72, ), (1, ), 0); del buf900  # reuse
        buf953 = reinterpret_tensor(buf898, (72, ), (1, ), 0); del buf898  # reuse
        buf954 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_37.run(buf949, convolution_202, unsqueeze_2797, squeeze_607, buf952, buf953, buf954, 72, 392, grid=grid(72), stream=stream0)
        buf951 = reinterpret_tensor(buf645, (8, 72, 7, 7), (3528, 49, 7, 1), 0); del buf645  # reuse
        buf955 = buf951; del buf951  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_38.run(buf955, buf949, convolution_202, unsqueeze_2797, buf953, squeeze_607, buf952, primals_608, 28224, grid=grid(28224), stream=stream0)
        del convolution_202
        del primals_608
        del squeeze_607
        del unsqueeze_2797
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf956 = aten.convolution_backward(buf955, relu_179, primals_607, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_607
        buf957 = buf956[0]
        buf958 = buf956[1]
        del buf956
        buf959 = buf953; del buf953  # reuse
        buf960 = empty((72, ), device='cuda', dtype=torch.float32)
        buf966 = empty((72, ), device='cuda', dtype=torch.float32)
        buf961 = empty((72, ), device='cuda', dtype=torch.float32)
        buf967 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_39.run(buf948, convolution_201, unsqueeze_2809, convolution_200, unsqueeze_2821, squeeze_604, squeeze_601, buf959, buf960, buf966, buf961, buf967, 72, 1568, grid=grid(72), stream=stream0)
        buf962 = buf773; del buf773  # reuse
        buf968 = buf759; del buf759  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_40.run(buf948, convolution_201, unsqueeze_2809, buf960, squeeze_604, buf959, primals_605, convolution_200, unsqueeze_2821, buf966, squeeze_601, primals_602, buf962, buf968, 112896, grid=grid(112896), stream=stream0)
        del convolution_200
        del convolution_201
        del primals_602
        del primals_605
        del squeeze_601
        del squeeze_604
        del unsqueeze_2809
        del unsqueeze_2821
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf963 = aten.convolution_backward(buf962, relu_163, primals_604, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf962
        del primals_604
        buf964 = buf963[0]
        buf965 = buf963[1]
        del buf963
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf969 = aten.convolution_backward(buf968, relu_182, primals_601, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_601
        buf970 = buf969[0]
        buf971 = buf969[1]
        del buf969
        buf972 = buf942; del buf942  # reuse
        buf973 = empty((18, ), device='cuda', dtype=torch.float32)
        buf974 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_33.run(relu_182, buf970, convolution_199, unsqueeze_2833, squeeze_598, buf972, buf973, buf974, 18, 6272, grid=grid(18), stream=stream0)
        buf975 = buf970; del buf970  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_34.run(buf975, relu_182, convolution_199, unsqueeze_2833, buf973, squeeze_598, buf972, primals_599, 112896, grid=grid(112896), stream=stream0)
        del convolution_199
        del primals_599
        del relu_182
        del squeeze_598
        del unsqueeze_2833
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf976 = aten.convolution_backward(buf975, relu_155, primals_598, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_598
        buf977 = buf976[0]
        buf978 = buf976[1]
        del buf976
        buf979 = buf804; del buf804  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_80.run(buf979, relu_181, relu_197, buf817, buf831, 225792, grid=grid(225792), stream=stream0)
        del buf817
        del relu_181
        del relu_197
        buf980 = buf607; del buf607  # reuse
        # Source Nodes: [], Original ATen: [aten.new_zeros]
        triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_41.run(buf980, 14112, grid=grid(14112), stream=stream0)
        aten.index_put_(buf980, [None, None, unsqueeze_813, convert_element_type_69], buf979, True)
        del convert_element_type_69
        del unsqueeze_813
        buf983 = buf922; del buf922  # reuse
        buf984 = empty((36, ), device='cuda', dtype=torch.float32)
        buf985 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_43.run(buf980, convolution_198, unsqueeze_2845, squeeze_595, buf983, buf984, buf985, 36, 392, grid=grid(36), stream=stream0)
        buf982 = buf601; del buf601  # reuse
        buf986 = buf982; del buf982  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_44.run(buf986, buf980, convolution_198, unsqueeze_2845, buf984, squeeze_595, buf983, primals_596, 14112, grid=grid(14112), stream=stream0)
        del buf980
        del convolution_198
        del primals_596
        del squeeze_595
        del unsqueeze_2845
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf987 = aten.convolution_backward(buf986, relu_179, primals_595, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf986
        del primals_595
        buf988 = buf987[0]
        buf989 = buf987[1]
        del buf987
        buf990 = reinterpret_tensor(buf930, (8, 36, 14, 14), (7056, 196, 14, 1), 0); del buf930  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_new_zeros_45.run(buf990, 56448, grid=grid(56448), stream=stream0)
        aten.index_put_(buf990, [None, None, unsqueeze_259, convert_element_type_13], buf979, True)
        buf993 = buf984; del buf984  # reuse
        buf994 = empty((36, ), device='cuda', dtype=torch.float32)
        buf995 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_46.run(buf990, convolution_197, unsqueeze_2857, squeeze_592, buf993, buf994, buf995, 36, 1568, grid=grid(36), stream=stream0)
        buf992 = buf924; del buf924  # reuse
        buf996 = buf992; del buf992  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_47.run(buf996, buf990, convolution_197, unsqueeze_2857, buf994, squeeze_592, buf993, primals_593, 56448, grid=grid(56448), stream=stream0)
        del buf990
        del convolution_197
        del primals_593
        del squeeze_592
        del unsqueeze_2857
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf997 = aten.convolution_backward(buf996, relu_171, primals_592, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf996
        del primals_592
        buf998 = buf997[0]
        buf999 = buf997[1]
        del buf997
        buf1000 = buf994; del buf994  # reuse
        buf1001 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1002 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf979, convolution_196, unsqueeze_2869, squeeze_589, buf1000, buf1001, buf1002, 36, 6272, grid=grid(36), stream=stream0)
        buf1003 = buf831; del buf831  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf979, convolution_196, unsqueeze_2869, buf1001, squeeze_589, buf1000, primals_590, buf1003, 225792, grid=grid(225792), stream=stream0)
        del convolution_196
        del primals_590
        del squeeze_589
        del unsqueeze_2869
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1004 = aten.convolution_backward(buf1003, relu_155, primals_589, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1003
        del primals_589
        buf1005 = buf1004[0]
        buf1006 = buf1004[1]
        del buf1004
        buf1007 = buf870; del buf870  # reuse
        buf1212 = buf1005; del buf1005  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_94.run(buf1007, buf1212, relu_180, relu_189, buf887, buf905, relu_155, buf946, buf977, 451584, grid=grid(451584), stream=stream0)
        del buf887
        del buf905
        del buf946
        del buf977
        del relu_155
        del relu_180
        del relu_189
        buf1008 = buf635; del buf635  # reuse
        # Source Nodes: [], Original ATen: [aten.new_zeros]
        triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_50.run(buf1008, 7056, grid=grid(7056), stream=stream0)
        aten.index_put_(buf1008, [None, None, unsqueeze_799, convert_element_type_61], buf1007, True)
        del convert_element_type_61
        del unsqueeze_799
        buf1011 = buf973; del buf973  # reuse
        buf1012 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1013 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_52.run(buf1008, convolution_195, unsqueeze_2881, squeeze_586, buf1011, buf1012, buf1013, 18, 392, grid=grid(18), stream=stream0)
        buf1010 = buf629; del buf629  # reuse
        buf1014 = buf1010; del buf1010  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_53.run(buf1014, buf1008, convolution_195, unsqueeze_2881, buf1012, squeeze_586, buf1011, primals_587, 7056, grid=grid(7056), stream=stream0)
        del buf1008
        del convolution_195
        del primals_587
        del squeeze_586
        del unsqueeze_2881
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1015 = aten.convolution_backward(buf1014, relu_179, primals_586, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1014
        del primals_586
        buf1016 = buf1015[0]
        buf1017 = buf1015[1]
        del buf1015
        buf1018 = reinterpret_tensor(buf955, (8, 18, 14, 14), (3528, 196, 14, 1), 0); del buf955  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_35.run(buf1018, 28224, grid=grid(28224), stream=stream0)
        aten.index_put_(buf1018, [None, None, unsqueeze_250, convert_element_type_9], buf1007, True)
        buf1021 = buf1012; del buf1012  # reuse
        buf1022 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1023 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_54.run(buf1018, convolution_194, unsqueeze_2893, squeeze_583, buf1021, buf1022, buf1023, 18, 1568, grid=grid(18), stream=stream0)
        buf1020 = reinterpret_tensor(buf949, (8, 18, 14, 14), (3528, 196, 14, 1), 0); del buf949  # reuse
        buf1024 = buf1020; del buf1020  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_55.run(buf1024, buf1018, convolution_194, unsqueeze_2893, buf1022, squeeze_583, buf1021, primals_584, 28224, grid=grid(28224), stream=stream0)
        del convolution_194
        del primals_584
        del squeeze_583
        del unsqueeze_2893
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1025 = aten.convolution_backward(buf1024, relu_171, primals_583, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_583
        buf1026 = buf1025[0]
        buf1027 = buf1025[1]
        del buf1025
        buf1028 = buf975; del buf975  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_new_zeros_56.run(buf1028, 112896, grid=grid(112896), stream=stream0)
        aten.index_put_(buf1028, [None, None, unsqueeze_136, convert_element_type_1], buf1007, True)
        buf1031 = buf1022; del buf1022  # reuse
        buf1032 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1033 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_57.run(buf1028, convolution_193, unsqueeze_2905, squeeze_580, buf1031, buf1032, buf1033, 18, 6272, grid=grid(18), stream=stream0)
        buf1030 = reinterpret_tensor(buf968, (8, 18, 28, 28), (14112, 784, 28, 1), 0); del buf968  # reuse
        buf1034 = buf1030; del buf1030  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_58.run(buf1034, buf1028, convolution_193, unsqueeze_2905, buf1032, squeeze_580, buf1031, primals_581, 112896, grid=grid(112896), stream=stream0)
        del buf1028
        del convolution_193
        del primals_581
        del squeeze_580
        del unsqueeze_2905
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1035 = aten.convolution_backward(buf1034, relu_163, primals_580, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1034
        del primals_580
        buf1036 = buf1035[0]
        buf1037 = buf1035[1]
        del buf1035
        buf1038 = buf1016; del buf1016  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_95.run(buf1038, relu_179, buf907, buf957, buf988, 56448, grid=grid(56448), stream=stream0)
        del buf907
        del buf957
        del relu_179
        buf1039 = buf928; del buf928  # reuse
        buf1040 = buf915; del buf915  # reuse
        buf1041 = buf909; del buf909  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_60.run(buf1038, convolution_192, unsqueeze_2917, squeeze_577, buf1039, buf1040, buf1041, 144, 392, grid=grid(144), stream=stream0)
        buf1042 = buf988; del buf988  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_61.run(buf1038, convolution_192, unsqueeze_2917, buf1040, squeeze_577, buf1039, primals_578, buf1042, 56448, grid=grid(56448), stream=stream0)
        del convolution_192
        del primals_578
        del squeeze_577
        del unsqueeze_2917
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1043 = aten.convolution_backward(buf1042, relu_178, primals_577, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1042
        del primals_577
        buf1044 = buf1043[0]
        buf1045 = buf1043[1]
        del buf1043
        buf1046 = buf1040; del buf1040  # reuse
        buf1047 = empty((144, ), device='cuda', dtype=torch.float32)
        buf1048 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_62.run(relu_178, buf1044, convolution_191, unsqueeze_2929, squeeze_574, buf1046, buf1047, buf1048, 144, 392, grid=grid(144), stream=stream0)
        buf1049 = buf1044; del buf1044  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_63.run(buf1049, relu_178, convolution_191, unsqueeze_2929, buf1047, squeeze_574, buf1046, primals_575, 56448, grid=grid(56448), stream=stream0)
        del convolution_191
        del primals_575
        del relu_178
        del squeeze_574
        del unsqueeze_2929
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1050 = aten.convolution_backward(buf1049, relu_177, primals_574, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_574
        buf1051 = buf1050[0]
        buf1052 = buf1050[1]
        del buf1050
        buf1053 = buf1047; del buf1047  # reuse
        buf1054 = empty((144, ), device='cuda', dtype=torch.float32)
        buf1056 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_add_native_batch_norm_backward_threshold_backward_64.run(relu_177, buf1038, buf1051, convolution_190, unsqueeze_2941, squeeze_571, buf1053, buf1054, buf1056, 144, 392, grid=grid(144), stream=stream0)
        buf1055 = buf1049; del buf1049  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_65.run(relu_177, buf1038, buf1051, convolution_190, unsqueeze_2941, buf1054, squeeze_571, buf1053, primals_572, buf1055, 56448, grid=grid(56448), stream=stream0)
        del convolution_190
        del primals_572
        del squeeze_571
        del unsqueeze_2941
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1057 = aten.convolution_backward(buf1055, relu_176, primals_571, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1055
        del primals_571
        buf1058 = buf1057[0]
        buf1059 = buf1057[1]
        del buf1057
        buf1060 = buf1054; del buf1054  # reuse
        buf1061 = empty((144, ), device='cuda', dtype=torch.float32)
        buf1062 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_62.run(relu_176, buf1058, convolution_189, unsqueeze_2953, squeeze_568, buf1060, buf1061, buf1062, 144, 392, grid=grid(144), stream=stream0)
        buf1063 = buf1058; del buf1058  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_63.run(buf1063, relu_176, convolution_189, unsqueeze_2953, buf1061, squeeze_568, buf1060, primals_569, 56448, grid=grid(56448), stream=stream0)
        del convolution_189
        del primals_569
        del relu_176
        del squeeze_568
        del unsqueeze_2953
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1064 = aten.convolution_backward(buf1063, relu_175, primals_568, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1063
        del primals_568
        buf1065 = buf1064[0]
        buf1066 = buf1064[1]
        del buf1064
        buf1067 = buf1038; del buf1038  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_66.run(buf1067, relu_175, relu_177, buf1051, buf1065, 56448, grid=grid(56448), stream=stream0)
        del buf1051
        del relu_175
        del relu_177
        buf1068 = buf1061; del buf1061  # reuse
        buf1069 = empty((144, ), device='cuda', dtype=torch.float32)
        buf1070 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_60.run(buf1067, convolution_188, unsqueeze_2965, squeeze_565, buf1068, buf1069, buf1070, 144, 392, grid=grid(144), stream=stream0)
        buf1071 = buf1065; del buf1065  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_61.run(buf1067, convolution_188, unsqueeze_2965, buf1069, squeeze_565, buf1068, primals_566, buf1071, 56448, grid=grid(56448), stream=stream0)
        del convolution_188
        del primals_566
        del squeeze_565
        del unsqueeze_2965
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1072 = aten.convolution_backward(buf1071, relu_174, primals_565, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1071
        del primals_565
        buf1073 = buf1072[0]
        buf1074 = buf1072[1]
        del buf1072
        buf1075 = buf1069; del buf1069  # reuse
        buf1076 = empty((144, ), device='cuda', dtype=torch.float32)
        buf1077 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_62.run(relu_174, buf1073, convolution_187, unsqueeze_2977, squeeze_562, buf1075, buf1076, buf1077, 144, 392, grid=grid(144), stream=stream0)
        buf1078 = buf1073; del buf1073  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_63.run(buf1078, relu_174, convolution_187, unsqueeze_2977, buf1076, squeeze_562, buf1075, primals_563, 56448, grid=grid(56448), stream=stream0)
        del convolution_187
        del primals_563
        del relu_174
        del squeeze_562
        del unsqueeze_2977
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1079 = aten.convolution_backward(buf1078, relu_173, primals_562, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_562
        buf1080 = buf1079[0]
        buf1081 = buf1079[1]
        del buf1079
        buf1082 = buf1076; del buf1076  # reuse
        buf1083 = empty((144, ), device='cuda', dtype=torch.float32)
        buf1085 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_add_native_batch_norm_backward_threshold_backward_64.run(relu_173, buf1067, buf1080, convolution_186, unsqueeze_2989, squeeze_559, buf1082, buf1083, buf1085, 144, 392, grid=grid(144), stream=stream0)
        buf1084 = buf1078; del buf1078  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_65.run(relu_173, buf1067, buf1080, convolution_186, unsqueeze_2989, buf1083, squeeze_559, buf1082, primals_560, buf1084, 56448, grid=grid(56448), stream=stream0)
        del convolution_186
        del primals_560
        del squeeze_559
        del unsqueeze_2989
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1086 = aten.convolution_backward(buf1084, relu_172, primals_559, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1084
        del primals_559
        buf1087 = buf1086[0]
        buf1088 = buf1086[1]
        del buf1086
        buf1089 = buf1083; del buf1083  # reuse
        buf1090 = empty((144, ), device='cuda', dtype=torch.float32)
        buf1091 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_62.run(relu_172, buf1087, convolution_185, unsqueeze_3001, squeeze_556, buf1089, buf1090, buf1091, 144, 392, grid=grid(144), stream=stream0)
        buf1092 = buf1087; del buf1087  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_63.run(buf1092, relu_172, convolution_185, unsqueeze_3001, buf1090, squeeze_556, buf1089, primals_557, 56448, grid=grid(56448), stream=stream0)
        del convolution_185
        del primals_557
        del relu_172
        del squeeze_556
        del unsqueeze_3001
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1093 = aten.convolution_backward(buf1092, relu_147, primals_556, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1092
        del primals_556
        buf1094 = buf1093[0]
        buf1095 = buf1093[1]
        del buf1093
        buf1096 = buf1026; del buf1026  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_96.run(buf1096, relu_171, buf913, buf948, buf998, 112896, grid=grid(112896), stream=stream0)
        del buf913
        del buf948
        del relu_171
        buf1097 = buf966; del buf966  # reuse
        buf1098 = buf960; del buf960  # reuse
        buf1099 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_68.run(buf1096, convolution_184, unsqueeze_3013, squeeze_553, buf1097, buf1098, buf1099, 72, 1568, grid=grid(72), stream=stream0)
        buf1100 = buf998; del buf998  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_69.run(buf1096, convolution_184, unsqueeze_3013, buf1098, squeeze_553, buf1097, primals_554, buf1100, 112896, grid=grid(112896), stream=stream0)
        del convolution_184
        del primals_554
        del squeeze_553
        del unsqueeze_3013
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1101 = aten.convolution_backward(buf1100, relu_170, primals_553, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1100
        del primals_553
        buf1102 = buf1101[0]
        buf1103 = buf1101[1]
        del buf1101
        buf1104 = buf1098; del buf1098  # reuse
        buf1105 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1106 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_170, buf1102, convolution_183, unsqueeze_3025, squeeze_550, buf1104, buf1105, buf1106, 72, 1568, grid=grid(72), stream=stream0)
        buf1107 = buf1102; del buf1102  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf1107, relu_170, convolution_183, unsqueeze_3025, buf1105, squeeze_550, buf1104, primals_551, 112896, grid=grid(112896), stream=stream0)
        del convolution_183
        del primals_551
        del relu_170
        del squeeze_550
        del unsqueeze_3025
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1108 = aten.convolution_backward(buf1107, relu_169, primals_550, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_550
        buf1109 = buf1108[0]
        buf1110 = buf1108[1]
        del buf1108
        buf1111 = buf1105; del buf1105  # reuse
        buf1112 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1114 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_72.run(relu_169, buf1096, buf1109, convolution_182, unsqueeze_3037, squeeze_547, buf1111, buf1112, buf1114, 72, 1568, grid=grid(72), stream=stream0)
        buf1113 = buf1107; del buf1107  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_73.run(relu_169, buf1096, buf1109, convolution_182, unsqueeze_3037, buf1112, squeeze_547, buf1111, primals_548, buf1113, 112896, grid=grid(112896), stream=stream0)
        del convolution_182
        del primals_548
        del squeeze_547
        del unsqueeze_3037
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1115 = aten.convolution_backward(buf1113, relu_168, primals_547, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1113
        del primals_547
        buf1116 = buf1115[0]
        buf1117 = buf1115[1]
        del buf1115
        buf1118 = buf1112; del buf1112  # reuse
        buf1119 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1120 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_168, buf1116, convolution_181, unsqueeze_3049, squeeze_544, buf1118, buf1119, buf1120, 72, 1568, grid=grid(72), stream=stream0)
        buf1121 = buf1116; del buf1116  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf1121, relu_168, convolution_181, unsqueeze_3049, buf1119, squeeze_544, buf1118, primals_545, 112896, grid=grid(112896), stream=stream0)
        del convolution_181
        del primals_545
        del relu_168
        del squeeze_544
        del unsqueeze_3049
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1122 = aten.convolution_backward(buf1121, relu_167, primals_544, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1121
        del primals_544
        buf1123 = buf1122[0]
        buf1124 = buf1122[1]
        del buf1122
        buf1125 = buf1096; del buf1096  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_74.run(buf1125, relu_167, relu_169, buf1109, buf1123, 112896, grid=grid(112896), stream=stream0)
        del buf1109
        del relu_167
        del relu_169
        buf1126 = buf1119; del buf1119  # reuse
        buf1127 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1128 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_68.run(buf1125, convolution_180, unsqueeze_3061, squeeze_541, buf1126, buf1127, buf1128, 72, 1568, grid=grid(72), stream=stream0)
        buf1129 = buf1123; del buf1123  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_69.run(buf1125, convolution_180, unsqueeze_3061, buf1127, squeeze_541, buf1126, primals_542, buf1129, 112896, grid=grid(112896), stream=stream0)
        del convolution_180
        del primals_542
        del squeeze_541
        del unsqueeze_3061
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1130 = aten.convolution_backward(buf1129, relu_166, primals_541, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1129
        del primals_541
        buf1131 = buf1130[0]
        buf1132 = buf1130[1]
        del buf1130
        buf1133 = buf1127; del buf1127  # reuse
        buf1134 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1135 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_166, buf1131, convolution_179, unsqueeze_3073, squeeze_538, buf1133, buf1134, buf1135, 72, 1568, grid=grid(72), stream=stream0)
        buf1136 = buf1131; del buf1131  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf1136, relu_166, convolution_179, unsqueeze_3073, buf1134, squeeze_538, buf1133, primals_539, 112896, grid=grid(112896), stream=stream0)
        del convolution_179
        del primals_539
        del relu_166
        del squeeze_538
        del unsqueeze_3073
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1137 = aten.convolution_backward(buf1136, relu_165, primals_538, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_538
        buf1138 = buf1137[0]
        buf1139 = buf1137[1]
        del buf1137
        buf1140 = buf1134; del buf1134  # reuse
        buf1141 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1143 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_72.run(relu_165, buf1125, buf1138, convolution_178, unsqueeze_3085, squeeze_535, buf1140, buf1141, buf1143, 72, 1568, grid=grid(72), stream=stream0)
        buf1142 = buf1136; del buf1136  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_73.run(relu_165, buf1125, buf1138, convolution_178, unsqueeze_3085, buf1141, squeeze_535, buf1140, primals_536, buf1142, 112896, grid=grid(112896), stream=stream0)
        del convolution_178
        del primals_536
        del squeeze_535
        del unsqueeze_3085
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1144 = aten.convolution_backward(buf1142, relu_164, primals_535, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1142
        del primals_535
        buf1145 = buf1144[0]
        buf1146 = buf1144[1]
        del buf1144
        buf1147 = buf1141; del buf1141  # reuse
        buf1148 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1149 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_164, buf1145, convolution_177, unsqueeze_3097, squeeze_532, buf1147, buf1148, buf1149, 72, 1568, grid=grid(72), stream=stream0)
        buf1150 = buf1145; del buf1145  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf1150, relu_164, convolution_177, unsqueeze_3097, buf1148, squeeze_532, buf1147, primals_533, 112896, grid=grid(112896), stream=stream0)
        del convolution_177
        del primals_533
        del relu_164
        del squeeze_532
        del unsqueeze_3097
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1151 = aten.convolution_backward(buf1150, relu_146, primals_532, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1150
        del primals_532
        buf1152 = buf1151[0]
        buf1153 = buf1151[1]
        del buf1151
        buf1154 = buf1036; del buf1036  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_97.run(buf1154, relu_163, buf926, buf964, buf979, 225792, grid=grid(225792), stream=stream0)
        del buf926
        del buf964
        del relu_163
        buf1155 = buf1001; del buf1001  # reuse
        buf1156 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1157 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf1154, convolution_176, unsqueeze_3109, squeeze_529, buf1155, buf1156, buf1157, 36, 6272, grid=grid(36), stream=stream0)
        buf1158 = buf979; del buf979  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf1154, convolution_176, unsqueeze_3109, buf1156, squeeze_529, buf1155, primals_530, buf1158, 225792, grid=grid(225792), stream=stream0)
        del convolution_176
        del primals_530
        del squeeze_529
        del unsqueeze_3109
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1159 = aten.convolution_backward(buf1158, relu_162, primals_529, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1158
        del primals_529
        buf1160 = buf1159[0]
        buf1161 = buf1159[1]
        del buf1159
        buf1162 = buf1156; del buf1156  # reuse
        buf1163 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1164 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_162, buf1160, convolution_175, unsqueeze_3121, squeeze_526, buf1162, buf1163, buf1164, 36, 6272, grid=grid(36), stream=stream0)
        buf1165 = buf1160; del buf1160  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf1165, relu_162, convolution_175, unsqueeze_3121, buf1163, squeeze_526, buf1162, primals_527, 225792, grid=grid(225792), stream=stream0)
        del convolution_175
        del primals_527
        del relu_162
        del squeeze_526
        del unsqueeze_3121
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1166 = aten.convolution_backward(buf1165, relu_161, primals_526, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_526
        buf1167 = buf1166[0]
        buf1168 = buf1166[1]
        del buf1166
        buf1169 = buf1163; del buf1163  # reuse
        buf1170 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1172 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_78.run(relu_161, buf1154, buf1167, convolution_174, unsqueeze_3133, squeeze_523, buf1169, buf1170, buf1172, 36, 6272, grid=grid(36), stream=stream0)
        buf1171 = buf1165; del buf1165  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_79.run(relu_161, buf1154, buf1167, convolution_174, unsqueeze_3133, buf1170, squeeze_523, buf1169, primals_524, buf1171, 225792, grid=grid(225792), stream=stream0)
        del convolution_174
        del primals_524
        del squeeze_523
        del unsqueeze_3133
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1173 = aten.convolution_backward(buf1171, relu_160, primals_523, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1171
        del primals_523
        buf1174 = buf1173[0]
        buf1175 = buf1173[1]
        del buf1173
        buf1176 = buf1170; del buf1170  # reuse
        buf1177 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1178 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_160, buf1174, convolution_173, unsqueeze_3145, squeeze_520, buf1176, buf1177, buf1178, 36, 6272, grid=grid(36), stream=stream0)
        buf1179 = buf1174; del buf1174  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf1179, relu_160, convolution_173, unsqueeze_3145, buf1177, squeeze_520, buf1176, primals_521, 225792, grid=grid(225792), stream=stream0)
        del convolution_173
        del primals_521
        del relu_160
        del squeeze_520
        del unsqueeze_3145
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1180 = aten.convolution_backward(buf1179, relu_159, primals_520, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1179
        del primals_520
        buf1181 = buf1180[0]
        buf1182 = buf1180[1]
        del buf1180
        buf1183 = buf1154; del buf1154  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_80.run(buf1183, relu_159, relu_161, buf1167, buf1181, 225792, grid=grid(225792), stream=stream0)
        del buf1167
        del relu_159
        del relu_161
        buf1184 = buf1177; del buf1177  # reuse
        buf1185 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1186 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf1183, convolution_172, unsqueeze_3157, squeeze_517, buf1184, buf1185, buf1186, 36, 6272, grid=grid(36), stream=stream0)
        buf1187 = buf1181; del buf1181  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf1183, convolution_172, unsqueeze_3157, buf1185, squeeze_517, buf1184, primals_518, buf1187, 225792, grid=grid(225792), stream=stream0)
        del convolution_172
        del primals_518
        del squeeze_517
        del unsqueeze_3157
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1188 = aten.convolution_backward(buf1187, relu_158, primals_517, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1187
        del primals_517
        buf1189 = buf1188[0]
        buf1190 = buf1188[1]
        del buf1188
        buf1191 = buf1185; del buf1185  # reuse
        buf1192 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1193 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_158, buf1189, convolution_171, unsqueeze_3169, squeeze_514, buf1191, buf1192, buf1193, 36, 6272, grid=grid(36), stream=stream0)
        buf1194 = buf1189; del buf1189  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf1194, relu_158, convolution_171, unsqueeze_3169, buf1192, squeeze_514, buf1191, primals_515, 225792, grid=grid(225792), stream=stream0)
        del convolution_171
        del primals_515
        del relu_158
        del squeeze_514
        del unsqueeze_3169
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1195 = aten.convolution_backward(buf1194, relu_157, primals_514, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_514
        buf1196 = buf1195[0]
        buf1197 = buf1195[1]
        del buf1195
        buf1198 = buf1192; del buf1192  # reuse
        buf1199 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1201 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_78.run(relu_157, buf1183, buf1196, convolution_170, unsqueeze_3181, squeeze_511, buf1198, buf1199, buf1201, 36, 6272, grid=grid(36), stream=stream0)
        buf1200 = buf1194; del buf1194  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_79.run(relu_157, buf1183, buf1196, convolution_170, unsqueeze_3181, buf1199, squeeze_511, buf1198, primals_512, buf1200, 225792, grid=grid(225792), stream=stream0)
        del convolution_170
        del primals_512
        del squeeze_511
        del unsqueeze_3181
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1202 = aten.convolution_backward(buf1200, relu_156, primals_511, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1200
        del primals_511
        buf1203 = buf1202[0]
        buf1204 = buf1202[1]
        del buf1202
        buf1205 = buf1199; del buf1199  # reuse
        buf1206 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1207 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_156, buf1203, convolution_169, unsqueeze_3193, squeeze_508, buf1205, buf1206, buf1207, 36, 6272, grid=grid(36), stream=stream0)
        buf1208 = buf1203; del buf1203  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf1208, relu_156, convolution_169, unsqueeze_3193, buf1206, squeeze_508, buf1205, primals_509, 225792, grid=grid(225792), stream=stream0)
        del convolution_169
        del primals_509
        del relu_156
        del squeeze_508
        del unsqueeze_3193
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1209 = aten.convolution_backward(buf1208, relu_144, primals_508, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1208
        del primals_508
        buf1210 = buf1209[0]
        buf1211 = buf1209[1]
        del buf1209
        buf1213 = reinterpret_tensor(buf1148, (18, 4), (1, 18), 0); del buf1148  # reuse
        buf1215 = empty_strided((18, 4), (1, 18), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf1212, convolution_168, unsqueeze_3205, buf1213, buf1215, 72, 6272, grid=grid(72), stream=stream0)
        buf1214 = buf1032; del buf1032  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1213, buf1214, 18, 4, grid=grid(18), stream=stream0)
        buf1216 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1217 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1215, squeeze_505, buf1216, buf1217, 18, 4, grid=grid(18), stream=stream0)
        buf1218 = buf1007; del buf1007  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_84.run(buf1212, convolution_168, unsqueeze_3205, buf1216, squeeze_505, buf1214, primals_506, buf1218, 451584, grid=grid(451584), stream=stream0)
        del convolution_168
        del primals_506
        del squeeze_505
        del unsqueeze_3205
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1219 = aten.convolution_backward(buf1218, relu_154, primals_505, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1218
        del primals_505
        buf1220 = buf1219[0]
        buf1221 = buf1219[1]
        del buf1219
        buf1222 = buf1215; del buf1215  # reuse
        buf1224 = buf1213; del buf1213  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_154, buf1220, convolution_167, unsqueeze_3217, buf1222, buf1224, 72, 6272, grid=grid(72), stream=stream0)
        buf1223 = buf1216; del buf1216  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1222, buf1223, 18, 4, grid=grid(18), stream=stream0)
        buf1225 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1226 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1224, squeeze_502, buf1225, buf1226, 18, 4, grid=grid(18), stream=stream0)
        buf1227 = buf1220; del buf1220  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf1227, relu_154, convolution_167, unsqueeze_3217, buf1225, squeeze_502, buf1223, primals_503, 451584, grid=grid(451584), stream=stream0)
        del convolution_167
        del primals_503
        del relu_154
        del squeeze_502
        del unsqueeze_3217
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1228 = aten.convolution_backward(buf1227, relu_153, primals_502, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_502
        buf1229 = buf1228[0]
        buf1230 = buf1228[1]
        del buf1228
        buf1231 = buf1224; del buf1224  # reuse
        buf1233 = buf1222; del buf1222  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_87.run(relu_153, buf1212, buf1229, convolution_166, unsqueeze_3229, buf1231, buf1233, 72, 6272, grid=grid(72), stream=stream0)
        buf1232 = buf1225; del buf1225  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1231, buf1232, 18, 4, grid=grid(18), stream=stream0)
        buf1234 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1236 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1233, squeeze_499, buf1234, buf1236, 18, 4, grid=grid(18), stream=stream0)
        buf1235 = buf1227; del buf1227  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_88.run(relu_153, buf1212, buf1229, convolution_166, unsqueeze_3229, buf1234, squeeze_499, buf1232, primals_500, buf1235, 451584, grid=grid(451584), stream=stream0)
        del convolution_166
        del primals_500
        del squeeze_499
        del unsqueeze_3229
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1237 = aten.convolution_backward(buf1235, relu_152, primals_499, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1235
        del primals_499
        buf1238 = buf1237[0]
        buf1239 = buf1237[1]
        del buf1237
        buf1240 = buf1233; del buf1233  # reuse
        buf1242 = buf1231; del buf1231  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_152, buf1238, convolution_165, unsqueeze_3241, buf1240, buf1242, 72, 6272, grid=grid(72), stream=stream0)
        buf1241 = buf1234; del buf1234  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1240, buf1241, 18, 4, grid=grid(18), stream=stream0)
        buf1243 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1244 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1242, squeeze_496, buf1243, buf1244, 18, 4, grid=grid(18), stream=stream0)
        buf1245 = buf1238; del buf1238  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf1245, relu_152, convolution_165, unsqueeze_3241, buf1243, squeeze_496, buf1241, primals_497, 451584, grid=grid(451584), stream=stream0)
        del convolution_165
        del primals_497
        del relu_152
        del squeeze_496
        del unsqueeze_3241
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1246 = aten.convolution_backward(buf1245, relu_151, primals_496, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1245
        del primals_496
        buf1247 = buf1246[0]
        buf1248 = buf1246[1]
        del buf1246
        buf1249 = buf1212; del buf1212  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_89.run(buf1249, relu_151, relu_153, buf1229, buf1247, 451584, grid=grid(451584), stream=stream0)
        del buf1229
        del relu_151
        del relu_153
        buf1250 = buf1242; del buf1242  # reuse
        buf1252 = buf1240; del buf1240  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf1249, convolution_164, unsqueeze_3253, buf1250, buf1252, 72, 6272, grid=grid(72), stream=stream0)
        buf1251 = buf1243; del buf1243  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1250, buf1251, 18, 4, grid=grid(18), stream=stream0)
        buf1253 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1254 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1252, squeeze_493, buf1253, buf1254, 18, 4, grid=grid(18), stream=stream0)
        buf1255 = buf1247; del buf1247  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_84.run(buf1249, convolution_164, unsqueeze_3253, buf1253, squeeze_493, buf1251, primals_494, buf1255, 451584, grid=grid(451584), stream=stream0)
        del convolution_164
        del primals_494
        del squeeze_493
        del unsqueeze_3253
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1256 = aten.convolution_backward(buf1255, relu_150, primals_493, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1255
        del primals_493
        buf1257 = buf1256[0]
        buf1258 = buf1256[1]
        del buf1256
        buf1259 = buf1252; del buf1252  # reuse
        buf1261 = buf1250; del buf1250  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_150, buf1257, convolution_163, unsqueeze_3265, buf1259, buf1261, 72, 6272, grid=grid(72), stream=stream0)
        buf1260 = buf1253; del buf1253  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1259, buf1260, 18, 4, grid=grid(18), stream=stream0)
        buf1262 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1263 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1261, squeeze_490, buf1262, buf1263, 18, 4, grid=grid(18), stream=stream0)
        buf1264 = buf1257; del buf1257  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf1264, relu_150, convolution_163, unsqueeze_3265, buf1262, squeeze_490, buf1260, primals_491, 451584, grid=grid(451584), stream=stream0)
        del convolution_163
        del primals_491
        del relu_150
        del squeeze_490
        del unsqueeze_3265
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1265 = aten.convolution_backward(buf1264, relu_149, primals_490, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_490
        buf1266 = buf1265[0]
        buf1267 = buf1265[1]
        del buf1265
        buf1268 = buf1261; del buf1261  # reuse
        buf1270 = buf1259; del buf1259  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_87.run(relu_149, buf1249, buf1266, convolution_162, unsqueeze_3277, buf1268, buf1270, 72, 6272, grid=grid(72), stream=stream0)
        buf1269 = buf1262; del buf1262  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1268, buf1269, 18, 4, grid=grid(18), stream=stream0)
        buf1271 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1273 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1270, squeeze_487, buf1271, buf1273, 18, 4, grid=grid(18), stream=stream0)
        buf1272 = buf1264; del buf1264  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_88.run(relu_149, buf1249, buf1266, convolution_162, unsqueeze_3277, buf1271, squeeze_487, buf1269, primals_488, buf1272, 451584, grid=grid(451584), stream=stream0)
        del convolution_162
        del primals_488
        del squeeze_487
        del unsqueeze_3277
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1274 = aten.convolution_backward(buf1272, relu_148, primals_487, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1272
        del primals_487
        buf1275 = buf1274[0]
        buf1276 = buf1274[1]
        del buf1274
        buf1277 = buf1270; del buf1270  # reuse
        buf1279 = buf1268; del buf1268  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_148, buf1275, convolution_161, unsqueeze_3289, buf1277, buf1279, 72, 6272, grid=grid(72), stream=stream0)
        buf1278 = buf1271; del buf1271  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1277, buf1278, 18, 4, grid=grid(18), stream=stream0)
        buf1280 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1281 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1279, squeeze_484, buf1280, buf1281, 18, 4, grid=grid(18), stream=stream0)
        buf1282 = buf1275; del buf1275  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf1282, relu_148, convolution_161, unsqueeze_3289, buf1280, squeeze_484, buf1278, primals_485, 451584, grid=grid(451584), stream=stream0)
        del convolution_161
        del primals_485
        del relu_148
        del squeeze_484
        del unsqueeze_3289
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1283 = aten.convolution_backward(buf1282, relu_143, primals_484, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1282
        del primals_484
        buf1284 = buf1283[0]
        buf1285 = buf1283[1]
        del buf1283
        buf1286 = buf1067; del buf1067  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_66.run(buf1286, relu_147, relu_173, buf1080, buf1094, 56448, grid=grid(56448), stream=stream0)
        del buf1080
        del relu_147
        del relu_173
        buf1287 = buf1090; del buf1090  # reuse
        buf1288 = empty((144, ), device='cuda', dtype=torch.float32)
        buf1289 = empty((144, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_60.run(buf1286, convolution_160, unsqueeze_3301, squeeze_481, buf1287, buf1288, buf1289, 144, 392, grid=grid(144), stream=stream0)
        buf1290 = buf1286; del buf1286  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_98.run(buf1290, convolution_160, unsqueeze_3301, buf1288, squeeze_481, buf1287, primals_482, 56448, grid=grid(56448), stream=stream0)
        del buf1288
        del convolution_160
        del primals_482
        del squeeze_481
        del unsqueeze_3301
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1291 = aten.convolution_backward(buf1290, relu_146, primals_481, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_481
        buf1292 = buf1291[0]
        buf1293 = buf1291[1]
        del buf1291
        buf1294 = buf1125; del buf1125  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_99.run(buf1294, relu_146, relu_165, buf1138, buf1152, buf1292, 112896, grid=grid(112896), stream=stream0)
        del relu_146
        del relu_165
        buf1315 = buf1183; del buf1183  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_80.run(buf1315, relu_144, relu_157, buf1196, buf1210, 225792, grid=grid(225792), stream=stream0)
        del buf1196
        del relu_144
        del relu_157
        buf1316 = reinterpret_tensor(buf1290, (8, 36, 14, 14), (7056, 196, 14, 1), 0); del buf1290  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_new_zeros_45.run(buf1316, 56448, grid=grid(56448), stream=stream0)
        aten.index_put_(buf1316, [None, None, unsqueeze_259, convert_element_type_13], buf1315, True)
        buf1319 = buf1206; del buf1206  # reuse
        buf1320 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1321 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_46.run(buf1316, convolution_156, unsqueeze_3349, squeeze_469, buf1319, buf1320, buf1321, 36, 1568, grid=grid(36), stream=stream0)
        buf1318 = reinterpret_tensor(buf1094, (8, 36, 14, 14), (7056, 196, 14, 1), 0); del buf1094  # reuse
        buf1322 = buf1318; del buf1318  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_47.run(buf1322, buf1316, convolution_156, unsqueeze_3349, buf1320, squeeze_469, buf1319, primals_470, 56448, grid=grid(56448), stream=stream0)
        del convolution_156
        del primals_470
        del squeeze_469
        del unsqueeze_3349
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1323 = aten.convolution_backward(buf1322, relu_142, primals_469, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_469
        buf1324 = buf1323[0]
        buf1333 = buf1249; del buf1249  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_89.run(buf1333, relu_143, relu_149, buf1266, buf1284, 451584, grid=grid(451584), stream=stream0)
        del buf1266
        del relu_143
        del relu_149
        buf1334 = buf1024; del buf1024  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_35.run(buf1334, 28224, grid=grid(28224), stream=stream0)
        aten.index_put_(buf1334, [None, None, unsqueeze_250, convert_element_type_9], buf1333, True)
        buf1337 = buf1280; del buf1280  # reuse
        buf1338 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1339 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_54.run(buf1334, convolution_154, unsqueeze_3373, squeeze_463, buf1337, buf1338, buf1339, 18, 1568, grid=grid(18), stream=stream0)
        buf1336 = buf1018; del buf1018  # reuse
        buf1340 = buf1336; del buf1336  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_55.run(buf1340, buf1334, convolution_154, unsqueeze_3373, buf1338, squeeze_463, buf1337, primals_464, 28224, grid=grid(28224), stream=stream0)
        del convolution_154
        del primals_464
        del squeeze_463
        del unsqueeze_3373
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1341 = aten.convolution_backward(buf1340, relu_142, primals_463, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_463
        buf1342 = buf1341[0]
        buf1295 = reinterpret_tensor(buf1279, (72, ), (1, ), 0); del buf1279  # reuse
        buf1296 = reinterpret_tensor(buf1277, (72, ), (1, ), 0); del buf1277  # reuse
        buf1302 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1354 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1355 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1297 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1303 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1357 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_100.run(buf1294, convolution_159, unsqueeze_3313, convolution_158, unsqueeze_3325, relu_142, buf1324, buf1342, convolution_152, unsqueeze_3397, squeeze_478, squeeze_475, squeeze_457, buf1295, buf1296, buf1302, buf1354, buf1355, buf1297, buf1303, buf1357, 72, 1568, grid=grid(72), stream=stream0)
        buf1298 = buf1292; del buf1292  # reuse
        buf1304 = buf1152; del buf1152  # reuse
        buf1356 = buf1138; del buf1138  # reuse
        buf1358 = buf1356; del buf1356  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_101.run(buf1358, buf1294, convolution_159, unsqueeze_3313, buf1296, squeeze_478, buf1295, primals_479, convolution_158, unsqueeze_3325, buf1302, squeeze_475, primals_476, relu_142, buf1324, buf1342, convolution_152, unsqueeze_3397, buf1355, squeeze_457, buf1354, primals_458, buf1298, buf1304, 112896, grid=grid(112896), stream=stream0)
        del convolution_152
        del convolution_158
        del convolution_159
        del primals_458
        del primals_476
        del primals_479
        del squeeze_457
        del squeeze_475
        del squeeze_478
        del unsqueeze_3313
        del unsqueeze_3325
        del unsqueeze_3397
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1299 = aten.convolution_backward(buf1298, relu_134, primals_478, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1298
        del primals_478
        buf1300 = buf1299[0]
        buf1301 = buf1299[1]
        del buf1299
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1305 = aten.convolution_backward(buf1304, relu_145, primals_475, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_475
        buf1306 = buf1305[0]
        buf1307 = buf1305[1]
        del buf1305
        buf1308 = buf1338; del buf1338  # reuse
        buf1309 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1310 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_33.run(relu_145, buf1306, convolution_157, unsqueeze_3337, squeeze_472, buf1308, buf1309, buf1310, 18, 6272, grid=grid(18), stream=stream0)
        buf1311 = buf1306; del buf1306  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_34.run(buf1311, relu_145, convolution_157, unsqueeze_3337, buf1309, squeeze_472, buf1308, primals_473, 112896, grid=grid(112896), stream=stream0)
        del convolution_157
        del primals_473
        del relu_145
        del squeeze_472
        del unsqueeze_3337
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1312 = aten.convolution_backward(buf1311, relu_126, primals_472, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_472
        buf1313 = buf1312[0]
        buf1314 = buf1312[1]
        del buf1312
        buf1325 = buf1323[1]
        del buf1323
        buf1326 = buf1320; del buf1320  # reuse
        buf1327 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1328 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf1315, convolution_155, unsqueeze_3361, squeeze_466, buf1326, buf1327, buf1328, 36, 6272, grid=grid(36), stream=stream0)
        buf1329 = buf1210; del buf1210  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf1315, convolution_155, unsqueeze_3361, buf1327, squeeze_466, buf1326, primals_467, buf1329, 225792, grid=grid(225792), stream=stream0)
        del convolution_155
        del primals_467
        del squeeze_466
        del unsqueeze_3361
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1330 = aten.convolution_backward(buf1329, relu_126, primals_466, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_466
        buf1331 = buf1330[0]
        buf1332 = buf1330[1]
        del buf1330
        buf1343 = buf1341[1]
        del buf1341
        buf1344 = buf1311; del buf1311  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_new_zeros_56.run(buf1344, 112896, grid=grid(112896), stream=stream0)
        aten.index_put_(buf1344, [None, None, unsqueeze_136, convert_element_type_1], buf1333, True)
        buf1347 = buf1309; del buf1309  # reuse
        buf1348 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1349 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_57.run(buf1344, convolution_153, unsqueeze_3385, squeeze_460, buf1347, buf1348, buf1349, 18, 6272, grid=grid(18), stream=stream0)
        buf1346 = reinterpret_tensor(buf1304, (8, 18, 28, 28), (14112, 784, 28, 1), 0); del buf1304  # reuse
        buf1350 = buf1346; del buf1346  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_58.run(buf1350, buf1344, convolution_153, unsqueeze_3385, buf1348, squeeze_460, buf1347, primals_461, 112896, grid=grid(112896), stream=stream0)
        del buf1344
        del convolution_153
        del primals_461
        del squeeze_460
        del unsqueeze_3385
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1351 = aten.convolution_backward(buf1350, relu_134, primals_460, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1350
        del primals_460
        buf1352 = buf1351[0]
        buf1353 = buf1351[1]
        del buf1351
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1359 = aten.convolution_backward(buf1358, relu_141, primals_457, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1358
        del primals_457
        buf1360 = buf1359[0]
        buf1361 = buf1359[1]
        del buf1359
        buf1362 = buf1355; del buf1355  # reuse
        buf1363 = buf1302; del buf1302  # reuse
        buf1364 = buf1296; del buf1296  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_141, buf1360, convolution_151, unsqueeze_3409, squeeze_454, buf1362, buf1363, buf1364, 72, 1568, grid=grid(72), stream=stream0)
        buf1365 = buf1360; del buf1360  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf1365, relu_141, convolution_151, unsqueeze_3409, buf1363, squeeze_454, buf1362, primals_455, 112896, grid=grid(112896), stream=stream0)
        del convolution_151
        del primals_455
        del relu_141
        del squeeze_454
        del unsqueeze_3409
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1366 = aten.convolution_backward(buf1365, relu_140, primals_454, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1365
        del primals_454
        buf1367 = buf1366[0]
        buf1368 = buf1366[1]
        del buf1366
        buf1369 = buf1294; del buf1294  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_102.run(buf1369, relu_140, relu_142, buf1324, buf1342, buf1367, 112896, grid=grid(112896), stream=stream0)
        del buf1324
        del buf1342
        del relu_140
        del relu_142
        buf1370 = buf1363; del buf1363  # reuse
        buf1371 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1372 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_68.run(buf1369, convolution_150, unsqueeze_3421, squeeze_451, buf1370, buf1371, buf1372, 72, 1568, grid=grid(72), stream=stream0)
        buf1373 = buf1367; del buf1367  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_69.run(buf1369, convolution_150, unsqueeze_3421, buf1371, squeeze_451, buf1370, primals_452, buf1373, 112896, grid=grid(112896), stream=stream0)
        del convolution_150
        del primals_452
        del squeeze_451
        del unsqueeze_3421
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1374 = aten.convolution_backward(buf1373, relu_139, primals_451, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1373
        del primals_451
        buf1375 = buf1374[0]
        buf1376 = buf1374[1]
        del buf1374
        buf1377 = buf1371; del buf1371  # reuse
        buf1378 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1379 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_139, buf1375, convolution_149, unsqueeze_3433, squeeze_448, buf1377, buf1378, buf1379, 72, 1568, grid=grid(72), stream=stream0)
        buf1380 = buf1375; del buf1375  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf1380, relu_139, convolution_149, unsqueeze_3433, buf1378, squeeze_448, buf1377, primals_449, 112896, grid=grid(112896), stream=stream0)
        del convolution_149
        del primals_449
        del relu_139
        del squeeze_448
        del unsqueeze_3433
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1381 = aten.convolution_backward(buf1380, relu_138, primals_448, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_448
        buf1382 = buf1381[0]
        buf1383 = buf1381[1]
        del buf1381
        buf1384 = buf1378; del buf1378  # reuse
        buf1385 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1387 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_72.run(relu_138, buf1369, buf1382, convolution_148, unsqueeze_3445, squeeze_445, buf1384, buf1385, buf1387, 72, 1568, grid=grid(72), stream=stream0)
        buf1386 = buf1380; del buf1380  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_73.run(relu_138, buf1369, buf1382, convolution_148, unsqueeze_3445, buf1385, squeeze_445, buf1384, primals_446, buf1386, 112896, grid=grid(112896), stream=stream0)
        del convolution_148
        del primals_446
        del squeeze_445
        del unsqueeze_3445
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1388 = aten.convolution_backward(buf1386, relu_137, primals_445, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1386
        del primals_445
        buf1389 = buf1388[0]
        buf1390 = buf1388[1]
        del buf1388
        buf1391 = buf1385; del buf1385  # reuse
        buf1392 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1393 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_137, buf1389, convolution_147, unsqueeze_3457, squeeze_442, buf1391, buf1392, buf1393, 72, 1568, grid=grid(72), stream=stream0)
        buf1394 = buf1389; del buf1389  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf1394, relu_137, convolution_147, unsqueeze_3457, buf1392, squeeze_442, buf1391, primals_443, 112896, grid=grid(112896), stream=stream0)
        del convolution_147
        del primals_443
        del relu_137
        del squeeze_442
        del unsqueeze_3457
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1395 = aten.convolution_backward(buf1394, relu_136, primals_442, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1394
        del primals_442
        buf1396 = buf1395[0]
        buf1397 = buf1395[1]
        del buf1395
        buf1398 = buf1369; del buf1369  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_74.run(buf1398, relu_136, relu_138, buf1382, buf1396, 112896, grid=grid(112896), stream=stream0)
        del buf1382
        del relu_136
        del relu_138
        buf1399 = buf1392; del buf1392  # reuse
        buf1400 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1401 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_68.run(buf1398, convolution_146, unsqueeze_3469, squeeze_439, buf1399, buf1400, buf1401, 72, 1568, grid=grid(72), stream=stream0)
        buf1402 = buf1396; del buf1396  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_69.run(buf1398, convolution_146, unsqueeze_3469, buf1400, squeeze_439, buf1399, primals_440, buf1402, 112896, grid=grid(112896), stream=stream0)
        del convolution_146
        del primals_440
        del squeeze_439
        del unsqueeze_3469
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1403 = aten.convolution_backward(buf1402, relu_135, primals_439, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_439
        buf1404 = buf1403[0]
        buf1405 = buf1403[1]
        del buf1403
        buf1406 = buf1400; del buf1400  # reuse
        buf1407 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1408 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_135, buf1404, convolution_145, unsqueeze_3481, squeeze_436, buf1406, buf1407, buf1408, 72, 1568, grid=grid(72), stream=stream0)
        buf1409 = buf1404; del buf1404  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf1409, relu_135, convolution_145, unsqueeze_3481, buf1407, squeeze_436, buf1406, primals_437, 112896, grid=grid(112896), stream=stream0)
        del convolution_145
        del primals_437
        del relu_135
        del squeeze_436
        del unsqueeze_3481
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1410 = aten.convolution_backward(buf1409, relu_118, primals_436, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_436
        buf1411 = buf1410[0]
        buf1412 = buf1410[1]
        del buf1410
        buf1413 = buf1327; del buf1327  # reuse
        buf1414 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1416 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_103.run(relu_134, buf1300, buf1315, buf1352, convolution_144, unsqueeze_3493, squeeze_433, buf1413, buf1414, buf1416, 36, 6272, grid=grid(36), stream=stream0)
        buf1415 = buf1329; del buf1329  # reuse
        buf1417 = buf1415; del buf1415  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_104.run(buf1417, relu_134, buf1300, buf1315, buf1352, convolution_144, unsqueeze_3493, buf1414, squeeze_433, buf1413, primals_434, 225792, grid=grid(225792), stream=stream0)
        del convolution_144
        del primals_434
        del squeeze_433
        del unsqueeze_3493
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1418 = aten.convolution_backward(buf1417, relu_133, primals_433, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1417
        del primals_433
        buf1419 = buf1418[0]
        buf1420 = buf1418[1]
        del buf1418
        buf1421 = buf1414; del buf1414  # reuse
        buf1422 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1423 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_133, buf1419, convolution_143, unsqueeze_3505, squeeze_430, buf1421, buf1422, buf1423, 36, 6272, grid=grid(36), stream=stream0)
        buf1424 = buf1419; del buf1419  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf1424, relu_133, convolution_143, unsqueeze_3505, buf1422, squeeze_430, buf1421, primals_431, 225792, grid=grid(225792), stream=stream0)
        del convolution_143
        del primals_431
        del relu_133
        del squeeze_430
        del unsqueeze_3505
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1425 = aten.convolution_backward(buf1424, relu_132, primals_430, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1424
        del primals_430
        buf1426 = buf1425[0]
        buf1427 = buf1425[1]
        del buf1425
        buf1428 = buf1300; del buf1300  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_105.run(buf1428, relu_132, relu_134, buf1315, buf1352, buf1426, 225792, grid=grid(225792), stream=stream0)
        del buf1315
        del buf1352
        del relu_132
        del relu_134
        buf1429 = buf1422; del buf1422  # reuse
        buf1430 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1431 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf1428, convolution_142, unsqueeze_3517, squeeze_427, buf1429, buf1430, buf1431, 36, 6272, grid=grid(36), stream=stream0)
        buf1432 = buf1426; del buf1426  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf1428, convolution_142, unsqueeze_3517, buf1430, squeeze_427, buf1429, primals_428, buf1432, 225792, grid=grid(225792), stream=stream0)
        del convolution_142
        del primals_428
        del squeeze_427
        del unsqueeze_3517
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1433 = aten.convolution_backward(buf1432, relu_131, primals_427, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1432
        del primals_427
        buf1434 = buf1433[0]
        buf1435 = buf1433[1]
        del buf1433
        buf1436 = buf1430; del buf1430  # reuse
        buf1437 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1438 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_131, buf1434, convolution_141, unsqueeze_3529, squeeze_424, buf1436, buf1437, buf1438, 36, 6272, grid=grid(36), stream=stream0)
        buf1439 = buf1434; del buf1434  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf1439, relu_131, convolution_141, unsqueeze_3529, buf1437, squeeze_424, buf1436, primals_425, 225792, grid=grid(225792), stream=stream0)
        del convolution_141
        del primals_425
        del relu_131
        del squeeze_424
        del unsqueeze_3529
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1440 = aten.convolution_backward(buf1439, relu_130, primals_424, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_424
        buf1441 = buf1440[0]
        buf1442 = buf1440[1]
        del buf1440
        buf1443 = buf1437; del buf1437  # reuse
        buf1444 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1446 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_78.run(relu_130, buf1428, buf1441, convolution_140, unsqueeze_3541, squeeze_421, buf1443, buf1444, buf1446, 36, 6272, grid=grid(36), stream=stream0)
        buf1445 = buf1439; del buf1439  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_79.run(relu_130, buf1428, buf1441, convolution_140, unsqueeze_3541, buf1444, squeeze_421, buf1443, primals_422, buf1445, 225792, grid=grid(225792), stream=stream0)
        del convolution_140
        del primals_422
        del squeeze_421
        del unsqueeze_3541
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1447 = aten.convolution_backward(buf1445, relu_129, primals_421, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1445
        del primals_421
        buf1448 = buf1447[0]
        buf1449 = buf1447[1]
        del buf1447
        buf1450 = buf1444; del buf1444  # reuse
        buf1451 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1452 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_129, buf1448, convolution_139, unsqueeze_3553, squeeze_418, buf1450, buf1451, buf1452, 36, 6272, grid=grid(36), stream=stream0)
        buf1453 = buf1448; del buf1448  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf1453, relu_129, convolution_139, unsqueeze_3553, buf1451, squeeze_418, buf1450, primals_419, 225792, grid=grid(225792), stream=stream0)
        del convolution_139
        del primals_419
        del relu_129
        del squeeze_418
        del unsqueeze_3553
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1454 = aten.convolution_backward(buf1453, relu_128, primals_418, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1453
        del primals_418
        buf1455 = buf1454[0]
        buf1456 = buf1454[1]
        del buf1454
        buf1457 = buf1428; del buf1428  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_80.run(buf1457, relu_128, relu_130, buf1441, buf1455, 225792, grid=grid(225792), stream=stream0)
        del buf1441
        del relu_128
        del relu_130
        buf1458 = buf1451; del buf1451  # reuse
        buf1459 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1460 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf1457, convolution_138, unsqueeze_3565, squeeze_415, buf1458, buf1459, buf1460, 36, 6272, grid=grid(36), stream=stream0)
        buf1461 = buf1455; del buf1455  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf1457, convolution_138, unsqueeze_3565, buf1459, squeeze_415, buf1458, primals_416, buf1461, 225792, grid=grid(225792), stream=stream0)
        del convolution_138
        del primals_416
        del squeeze_415
        del unsqueeze_3565
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1462 = aten.convolution_backward(buf1461, relu_127, primals_415, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1461
        del primals_415
        buf1463 = buf1462[0]
        buf1464 = buf1462[1]
        del buf1462
        buf1465 = buf1459; del buf1459  # reuse
        buf1466 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1467 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_127, buf1463, convolution_137, unsqueeze_3577, squeeze_412, buf1465, buf1466, buf1467, 36, 6272, grid=grid(36), stream=stream0)
        buf1468 = buf1463; del buf1463  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf1468, relu_127, convolution_137, unsqueeze_3577, buf1466, squeeze_412, buf1465, primals_413, 225792, grid=grid(225792), stream=stream0)
        del convolution_137
        del primals_413
        del relu_127
        del squeeze_412
        del unsqueeze_3577
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1469 = aten.convolution_backward(buf1468, relu_116, primals_412, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1468
        del primals_412
        buf1470 = buf1469[0]
        buf1471 = buf1469[1]
        del buf1469
        buf1472 = reinterpret_tensor(buf1407, (18, 4), (1, 18), 0); del buf1407  # reuse
        buf1474 = empty_strided((18, 4), (1, 18), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_106.run(relu_126, buf1313, buf1331, buf1333, convolution_136, unsqueeze_3589, buf1472, buf1474, 72, 6272, grid=grid(72), stream=stream0)
        buf1473 = buf1348; del buf1348  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1472, buf1473, 18, 4, grid=grid(18), stream=stream0)
        buf1475 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1477 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1474, squeeze_409, buf1475, buf1477, 18, 4, grid=grid(18), stream=stream0)
        buf1476 = buf1284; del buf1284  # reuse
        buf1478 = buf1476; del buf1476  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_107.run(buf1478, relu_126, buf1313, buf1331, buf1333, convolution_136, unsqueeze_3589, buf1475, squeeze_409, buf1473, primals_410, 451584, grid=grid(451584), stream=stream0)
        del convolution_136
        del primals_410
        del squeeze_409
        del unsqueeze_3589
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1479 = aten.convolution_backward(buf1478, relu_125, primals_409, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1478
        del primals_409
        buf1480 = buf1479[0]
        buf1481 = buf1479[1]
        del buf1479
        buf1482 = buf1474; del buf1474  # reuse
        buf1484 = buf1472; del buf1472  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_125, buf1480, convolution_135, unsqueeze_3601, buf1482, buf1484, 72, 6272, grid=grid(72), stream=stream0)
        buf1483 = buf1475; del buf1475  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1482, buf1483, 18, 4, grid=grid(18), stream=stream0)
        buf1485 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1486 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1484, squeeze_406, buf1485, buf1486, 18, 4, grid=grid(18), stream=stream0)
        buf1487 = buf1480; del buf1480  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf1487, relu_125, convolution_135, unsqueeze_3601, buf1485, squeeze_406, buf1483, primals_407, 451584, grid=grid(451584), stream=stream0)
        del convolution_135
        del primals_407
        del relu_125
        del squeeze_406
        del unsqueeze_3601
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1488 = aten.convolution_backward(buf1487, relu_124, primals_406, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1487
        del primals_406
        buf1489 = buf1488[0]
        buf1490 = buf1488[1]
        del buf1488
        buf1491 = buf1313; del buf1313  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_108.run(buf1491, relu_124, relu_126, buf1331, buf1333, buf1489, 451584, grid=grid(451584), stream=stream0)
        del buf1331
        del buf1333
        del relu_124
        del relu_126
        buf1492 = buf1484; del buf1484  # reuse
        buf1494 = buf1482; del buf1482  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf1491, convolution_134, unsqueeze_3613, buf1492, buf1494, 72, 6272, grid=grid(72), stream=stream0)
        buf1493 = buf1485; del buf1485  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1492, buf1493, 18, 4, grid=grid(18), stream=stream0)
        buf1495 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1496 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1494, squeeze_403, buf1495, buf1496, 18, 4, grid=grid(18), stream=stream0)
        buf1497 = buf1489; del buf1489  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_84.run(buf1491, convolution_134, unsqueeze_3613, buf1495, squeeze_403, buf1493, primals_404, buf1497, 451584, grid=grid(451584), stream=stream0)
        del convolution_134
        del primals_404
        del squeeze_403
        del unsqueeze_3613
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1498 = aten.convolution_backward(buf1497, relu_123, primals_403, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1497
        del primals_403
        buf1499 = buf1498[0]
        buf1500 = buf1498[1]
        del buf1498
        buf1501 = buf1494; del buf1494  # reuse
        buf1503 = buf1492; del buf1492  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_123, buf1499, convolution_133, unsqueeze_3625, buf1501, buf1503, 72, 6272, grid=grid(72), stream=stream0)
        buf1502 = buf1495; del buf1495  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1501, buf1502, 18, 4, grid=grid(18), stream=stream0)
        buf1504 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1505 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1503, squeeze_400, buf1504, buf1505, 18, 4, grid=grid(18), stream=stream0)
        buf1506 = buf1499; del buf1499  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf1506, relu_123, convolution_133, unsqueeze_3625, buf1504, squeeze_400, buf1502, primals_401, 451584, grid=grid(451584), stream=stream0)
        del convolution_133
        del primals_401
        del relu_123
        del squeeze_400
        del unsqueeze_3625
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1507 = aten.convolution_backward(buf1506, relu_122, primals_400, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_400
        buf1508 = buf1507[0]
        buf1509 = buf1507[1]
        del buf1507
        buf1510 = buf1503; del buf1503  # reuse
        buf1512 = buf1501; del buf1501  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_87.run(relu_122, buf1491, buf1508, convolution_132, unsqueeze_3637, buf1510, buf1512, 72, 6272, grid=grid(72), stream=stream0)
        buf1511 = buf1504; del buf1504  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1510, buf1511, 18, 4, grid=grid(18), stream=stream0)
        buf1513 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1515 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1512, squeeze_397, buf1513, buf1515, 18, 4, grid=grid(18), stream=stream0)
        buf1514 = buf1506; del buf1506  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_88.run(relu_122, buf1491, buf1508, convolution_132, unsqueeze_3637, buf1513, squeeze_397, buf1511, primals_398, buf1514, 451584, grid=grid(451584), stream=stream0)
        del convolution_132
        del primals_398
        del squeeze_397
        del unsqueeze_3637
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1516 = aten.convolution_backward(buf1514, relu_121, primals_397, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1514
        del primals_397
        buf1517 = buf1516[0]
        buf1518 = buf1516[1]
        del buf1516
        buf1519 = buf1512; del buf1512  # reuse
        buf1521 = buf1510; del buf1510  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_121, buf1517, convolution_131, unsqueeze_3649, buf1519, buf1521, 72, 6272, grid=grid(72), stream=stream0)
        buf1520 = buf1513; del buf1513  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1519, buf1520, 18, 4, grid=grid(18), stream=stream0)
        buf1522 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1523 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1521, squeeze_394, buf1522, buf1523, 18, 4, grid=grid(18), stream=stream0)
        buf1524 = buf1517; del buf1517  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf1524, relu_121, convolution_131, unsqueeze_3649, buf1522, squeeze_394, buf1520, primals_395, 451584, grid=grid(451584), stream=stream0)
        del convolution_131
        del primals_395
        del relu_121
        del squeeze_394
        del unsqueeze_3649
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1525 = aten.convolution_backward(buf1524, relu_120, primals_394, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1524
        del primals_394
        buf1526 = buf1525[0]
        buf1527 = buf1525[1]
        del buf1525
        buf1528 = buf1491; del buf1491  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_89.run(buf1528, relu_120, relu_122, buf1508, buf1526, 451584, grid=grid(451584), stream=stream0)
        del buf1508
        del relu_120
        del relu_122
        buf1529 = buf1521; del buf1521  # reuse
        buf1531 = buf1519; del buf1519  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf1528, convolution_130, unsqueeze_3661, buf1529, buf1531, 72, 6272, grid=grid(72), stream=stream0)
        buf1530 = buf1522; del buf1522  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1529, buf1530, 18, 4, grid=grid(18), stream=stream0)
        buf1532 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1533 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1531, squeeze_391, buf1532, buf1533, 18, 4, grid=grid(18), stream=stream0)
        buf1534 = buf1526; del buf1526  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_84.run(buf1528, convolution_130, unsqueeze_3661, buf1532, squeeze_391, buf1530, primals_392, buf1534, 451584, grid=grid(451584), stream=stream0)
        del convolution_130
        del primals_392
        del squeeze_391
        del unsqueeze_3661
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1535 = aten.convolution_backward(buf1534, relu_119, primals_391, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1534
        del primals_391
        buf1536 = buf1535[0]
        buf1537 = buf1535[1]
        del buf1535
        buf1538 = buf1531; del buf1531  # reuse
        buf1540 = buf1529; del buf1529  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_119, buf1536, convolution_129, unsqueeze_3673, buf1538, buf1540, 72, 6272, grid=grid(72), stream=stream0)
        buf1539 = buf1532; del buf1532  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1538, buf1539, 18, 4, grid=grid(18), stream=stream0)
        buf1541 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1542 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1540, squeeze_388, buf1541, buf1542, 18, 4, grid=grid(18), stream=stream0)
        buf1543 = buf1536; del buf1536  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf1543, relu_119, convolution_129, unsqueeze_3673, buf1541, squeeze_388, buf1539, primals_389, 451584, grid=grid(451584), stream=stream0)
        del convolution_129
        del primals_389
        del relu_119
        del squeeze_388
        del unsqueeze_3673
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1544 = aten.convolution_backward(buf1543, relu_115, primals_388, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1543
        del primals_388
        buf1545 = buf1544[0]
        buf1546 = buf1544[1]
        del buf1544
        buf1547 = reinterpret_tensor(buf1540, (72, ), (1, ), 0); del buf1540  # reuse
        buf1548 = reinterpret_tensor(buf1538, (72, ), (1, ), 0); del buf1538  # reuse
        buf1554 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1550 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1556 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_109.run(relu_118, buf1398, buf1411, convolution_128, unsqueeze_3685, convolution_127, unsqueeze_3697, squeeze_385, squeeze_382, buf1547, buf1548, buf1554, buf1550, buf1556, 72, 1568, grid=grid(72), stream=stream0)
        buf1567 = buf1322; del buf1322  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.add, aten.new_zeros, aten.threshold_backward]
        triton_poi_fused__unsafe_index_put_new_zeros_45.run(buf1567, 56448, grid=grid(56448), stream=stream0)
        buf1568 = buf1457; del buf1457  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_110.run(buf1568, relu_116, buf1470, 225792, grid=grid(225792), stream=stream0)
        del relu_116
        aten.index_put_(buf1567, [None, None, unsqueeze_259, convert_element_type_13], buf1568, True)
        buf1571 = buf1466; del buf1466  # reuse
        buf1572 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1573 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_46.run(buf1567, convolution_125, unsqueeze_3721, squeeze_376, buf1571, buf1572, buf1573, 36, 1568, grid=grid(36), stream=stream0)
        buf1570 = buf1316; del buf1316  # reuse
        buf1574 = buf1570; del buf1570  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_47.run(buf1574, buf1567, convolution_125, unsqueeze_3721, buf1572, squeeze_376, buf1571, primals_377, 56448, grid=grid(56448), stream=stream0)
        del convolution_125
        del primals_377
        del squeeze_376
        del unsqueeze_3721
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1575 = aten.convolution_backward(buf1574, relu_114, primals_376, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_376
        buf1576 = buf1575[0]
        buf1585 = buf1340; del buf1340  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.add, aten.new_zeros, aten.threshold_backward]
        triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_35.run(buf1585, 28224, grid=grid(28224), stream=stream0)
        buf1586 = buf1528; del buf1528  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_111.run(buf1586, relu_115, buf1545, 451584, grid=grid(451584), stream=stream0)
        del relu_115
        aten.index_put_(buf1585, [None, None, unsqueeze_250, convert_element_type_9], buf1586, True)
        buf1589 = buf1541; del buf1541  # reuse
        buf1590 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1591 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_54.run(buf1585, convolution_123, unsqueeze_3745, squeeze_370, buf1589, buf1590, buf1591, 18, 1568, grid=grid(18), stream=stream0)
        buf1588 = buf1334; del buf1334  # reuse
        buf1592 = buf1588; del buf1588  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_55.run(buf1592, buf1585, convolution_123, unsqueeze_3745, buf1590, squeeze_370, buf1589, primals_371, 28224, grid=grid(28224), stream=stream0)
        del convolution_123
        del primals_371
        del squeeze_370
        del unsqueeze_3745
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1593 = aten.convolution_backward(buf1592, relu_114, primals_370, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_370
        buf1594 = buf1593[0]
        buf1549 = buf1409; del buf1409  # reuse
        buf1555 = buf1402; del buf1402  # reuse
        buf1606 = buf1576; del buf1576  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_112.run(buf1606, relu_118, buf1398, buf1411, convolution_128, unsqueeze_3685, buf1548, squeeze_385, buf1547, primals_386, convolution_127, unsqueeze_3697, buf1554, squeeze_382, primals_383, relu_114, buf1594, buf1549, buf1555, 112896, grid=grid(112896), stream=stream0)
        del buf1398
        del buf1411
        del buf1594
        del convolution_127
        del convolution_128
        del primals_383
        del primals_386
        del relu_114
        del relu_118
        del squeeze_382
        del squeeze_385
        del unsqueeze_3685
        del unsqueeze_3697
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1551 = aten.convolution_backward(buf1549, relu_106, primals_385, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1549
        del primals_385
        buf1552 = buf1551[0]
        buf1553 = buf1551[1]
        del buf1551
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1557 = aten.convolution_backward(buf1555, relu_117, primals_382, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_382
        buf1558 = buf1557[0]
        buf1559 = buf1557[1]
        del buf1557
        buf1560 = buf1590; del buf1590  # reuse
        buf1561 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1562 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_33.run(relu_117, buf1558, convolution_126, unsqueeze_3709, squeeze_379, buf1560, buf1561, buf1562, 18, 6272, grid=grid(18), stream=stream0)
        buf1563 = buf1558; del buf1558  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_34.run(buf1563, relu_117, convolution_126, unsqueeze_3709, buf1561, squeeze_379, buf1560, primals_380, 112896, grid=grid(112896), stream=stream0)
        del convolution_126
        del primals_380
        del relu_117
        del squeeze_379
        del unsqueeze_3709
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1564 = aten.convolution_backward(buf1563, relu_98, primals_379, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_379
        buf1565 = buf1564[0]
        buf1566 = buf1564[1]
        del buf1564
        buf1577 = buf1575[1]
        del buf1575
        buf1578 = buf1572; del buf1572  # reuse
        buf1579 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1580 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf1568, convolution_124, unsqueeze_3733, squeeze_373, buf1578, buf1579, buf1580, 36, 6272, grid=grid(36), stream=stream0)
        buf1581 = buf1470; del buf1470  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf1568, convolution_124, unsqueeze_3733, buf1579, squeeze_373, buf1578, primals_374, buf1581, 225792, grid=grid(225792), stream=stream0)
        del convolution_124
        del primals_374
        del squeeze_373
        del unsqueeze_3733
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1582 = aten.convolution_backward(buf1581, relu_98, primals_373, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_373
        buf1583 = buf1582[0]
        buf1584 = buf1582[1]
        del buf1582
        buf1595 = buf1593[1]
        del buf1593
        buf1596 = buf1563; del buf1563  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_new_zeros_56.run(buf1596, 112896, grid=grid(112896), stream=stream0)
        aten.index_put_(buf1596, [None, None, unsqueeze_136, convert_element_type_1], buf1586, True)
        buf1599 = buf1561; del buf1561  # reuse
        buf1600 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1601 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_57.run(buf1596, convolution_122, unsqueeze_3757, squeeze_367, buf1599, buf1600, buf1601, 18, 6272, grid=grid(18), stream=stream0)
        buf1598 = reinterpret_tensor(buf1555, (8, 18, 28, 28), (14112, 784, 28, 1), 0); del buf1555  # reuse
        buf1602 = buf1598; del buf1598  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_58.run(buf1602, buf1596, convolution_122, unsqueeze_3757, buf1600, squeeze_367, buf1599, primals_368, 112896, grid=grid(112896), stream=stream0)
        del buf1596
        del convolution_122
        del primals_368
        del squeeze_367
        del unsqueeze_3757
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1603 = aten.convolution_backward(buf1602, relu_106, primals_367, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_367
        buf1604 = buf1603[0]
        buf1605 = buf1603[1]
        del buf1603
        buf1607 = buf1554; del buf1554  # reuse
        buf1608 = buf1548; del buf1548  # reuse
        buf1609 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_68.run(buf1606, convolution_121, unsqueeze_3769, squeeze_364, buf1607, buf1608, buf1609, 72, 1568, grid=grid(72), stream=stream0)
        buf1610 = reinterpret_tensor(buf1602, (8, 72, 14, 14), (14112, 196, 14, 1), 0); del buf1602  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_69.run(buf1606, convolution_121, unsqueeze_3769, buf1608, squeeze_364, buf1607, primals_365, buf1610, 112896, grid=grid(112896), stream=stream0)
        del convolution_121
        del primals_365
        del squeeze_364
        del unsqueeze_3769
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1611 = aten.convolution_backward(buf1610, relu_113, primals_364, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1610
        del primals_364
        buf1612 = buf1611[0]
        buf1613 = buf1611[1]
        del buf1611
        buf1614 = buf1608; del buf1608  # reuse
        buf1615 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1616 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_113, buf1612, convolution_120, unsqueeze_3781, squeeze_361, buf1614, buf1615, buf1616, 72, 1568, grid=grid(72), stream=stream0)
        buf1617 = buf1612; del buf1612  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf1617, relu_113, convolution_120, unsqueeze_3781, buf1615, squeeze_361, buf1614, primals_362, 112896, grid=grid(112896), stream=stream0)
        del convolution_120
        del primals_362
        del relu_113
        del squeeze_361
        del unsqueeze_3781
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1618 = aten.convolution_backward(buf1617, relu_112, primals_361, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_361
        buf1619 = buf1618[0]
        buf1620 = buf1618[1]
        del buf1618
        buf1621 = buf1615; del buf1615  # reuse
        buf1622 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1624 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_72.run(relu_112, buf1606, buf1619, convolution_119, unsqueeze_3793, squeeze_358, buf1621, buf1622, buf1624, 72, 1568, grid=grid(72), stream=stream0)
        buf1623 = buf1617; del buf1617  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_73.run(relu_112, buf1606, buf1619, convolution_119, unsqueeze_3793, buf1622, squeeze_358, buf1621, primals_359, buf1623, 112896, grid=grid(112896), stream=stream0)
        del convolution_119
        del primals_359
        del squeeze_358
        del unsqueeze_3793
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1625 = aten.convolution_backward(buf1623, relu_111, primals_358, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1623
        del primals_358
        buf1626 = buf1625[0]
        buf1627 = buf1625[1]
        del buf1625
        buf1628 = buf1622; del buf1622  # reuse
        buf1629 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1630 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_111, buf1626, convolution_118, unsqueeze_3805, squeeze_355, buf1628, buf1629, buf1630, 72, 1568, grid=grid(72), stream=stream0)
        buf1631 = buf1626; del buf1626  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf1631, relu_111, convolution_118, unsqueeze_3805, buf1629, squeeze_355, buf1628, primals_356, 112896, grid=grid(112896), stream=stream0)
        del convolution_118
        del primals_356
        del relu_111
        del squeeze_355
        del unsqueeze_3805
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1632 = aten.convolution_backward(buf1631, relu_110, primals_355, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1631
        del primals_355
        buf1633 = buf1632[0]
        buf1634 = buf1632[1]
        del buf1632
        buf1635 = buf1606; del buf1606  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_74.run(buf1635, relu_110, relu_112, buf1619, buf1633, 112896, grid=grid(112896), stream=stream0)
        del buf1619
        del relu_110
        del relu_112
        buf1636 = buf1629; del buf1629  # reuse
        buf1637 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1638 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_68.run(buf1635, convolution_117, unsqueeze_3817, squeeze_352, buf1636, buf1637, buf1638, 72, 1568, grid=grid(72), stream=stream0)
        buf1639 = buf1633; del buf1633  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_69.run(buf1635, convolution_117, unsqueeze_3817, buf1637, squeeze_352, buf1636, primals_353, buf1639, 112896, grid=grid(112896), stream=stream0)
        del convolution_117
        del primals_353
        del squeeze_352
        del unsqueeze_3817
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1640 = aten.convolution_backward(buf1639, relu_109, primals_352, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1639
        del primals_352
        buf1641 = buf1640[0]
        buf1642 = buf1640[1]
        del buf1640
        buf1643 = buf1637; del buf1637  # reuse
        buf1644 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1645 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_109, buf1641, convolution_116, unsqueeze_3829, squeeze_349, buf1643, buf1644, buf1645, 72, 1568, grid=grid(72), stream=stream0)
        buf1646 = buf1641; del buf1641  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf1646, relu_109, convolution_116, unsqueeze_3829, buf1644, squeeze_349, buf1643, primals_350, 112896, grid=grid(112896), stream=stream0)
        del convolution_116
        del primals_350
        del relu_109
        del squeeze_349
        del unsqueeze_3829
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1647 = aten.convolution_backward(buf1646, relu_108, primals_349, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_349
        buf1648 = buf1647[0]
        buf1649 = buf1647[1]
        del buf1647
        buf1650 = buf1644; del buf1644  # reuse
        buf1651 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1653 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_72.run(relu_108, buf1635, buf1648, convolution_115, unsqueeze_3841, squeeze_346, buf1650, buf1651, buf1653, 72, 1568, grid=grid(72), stream=stream0)
        buf1652 = buf1646; del buf1646  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_73.run(relu_108, buf1635, buf1648, convolution_115, unsqueeze_3841, buf1651, squeeze_346, buf1650, primals_347, buf1652, 112896, grid=grid(112896), stream=stream0)
        del convolution_115
        del primals_347
        del squeeze_346
        del unsqueeze_3841
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1654 = aten.convolution_backward(buf1652, relu_107, primals_346, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1652
        del primals_346
        buf1655 = buf1654[0]
        buf1656 = buf1654[1]
        del buf1654
        buf1657 = buf1651; del buf1651  # reuse
        buf1658 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1659 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_107, buf1655, convolution_114, unsqueeze_3853, squeeze_343, buf1657, buf1658, buf1659, 72, 1568, grid=grid(72), stream=stream0)
        buf1660 = buf1655; del buf1655  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf1660, relu_107, convolution_114, unsqueeze_3853, buf1658, squeeze_343, buf1657, primals_344, 112896, grid=grid(112896), stream=stream0)
        del convolution_114
        del primals_344
        del relu_107
        del squeeze_343
        del unsqueeze_3853
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1661 = aten.convolution_backward(buf1660, relu_90, primals_343, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_343
        buf1662 = buf1661[0]
        buf1663 = buf1661[1]
        del buf1661
        buf1664 = buf1579; del buf1579  # reuse
        buf1665 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1667 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_103.run(relu_106, buf1552, buf1568, buf1604, convolution_113, unsqueeze_3865, squeeze_340, buf1664, buf1665, buf1667, 36, 6272, grid=grid(36), stream=stream0)
        buf1666 = buf1581; del buf1581  # reuse
        buf1668 = buf1666; del buf1666  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_104.run(buf1668, relu_106, buf1552, buf1568, buf1604, convolution_113, unsqueeze_3865, buf1665, squeeze_340, buf1664, primals_341, 225792, grid=grid(225792), stream=stream0)
        del convolution_113
        del primals_341
        del squeeze_340
        del unsqueeze_3865
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1669 = aten.convolution_backward(buf1668, relu_105, primals_340, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1668
        del primals_340
        buf1670 = buf1669[0]
        buf1671 = buf1669[1]
        del buf1669
        buf1672 = buf1665; del buf1665  # reuse
        buf1673 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1674 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_105, buf1670, convolution_112, unsqueeze_3877, squeeze_337, buf1672, buf1673, buf1674, 36, 6272, grid=grid(36), stream=stream0)
        buf1675 = buf1670; del buf1670  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf1675, relu_105, convolution_112, unsqueeze_3877, buf1673, squeeze_337, buf1672, primals_338, 225792, grid=grid(225792), stream=stream0)
        del convolution_112
        del primals_338
        del relu_105
        del squeeze_337
        del unsqueeze_3877
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1676 = aten.convolution_backward(buf1675, relu_104, primals_337, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1675
        del primals_337
        buf1677 = buf1676[0]
        buf1678 = buf1676[1]
        del buf1676
        buf1679 = buf1552; del buf1552  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_105.run(buf1679, relu_104, relu_106, buf1568, buf1604, buf1677, 225792, grid=grid(225792), stream=stream0)
        del buf1568
        del buf1604
        del relu_104
        del relu_106
        buf1680 = buf1673; del buf1673  # reuse
        buf1681 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1682 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf1679, convolution_111, unsqueeze_3889, squeeze_334, buf1680, buf1681, buf1682, 36, 6272, grid=grid(36), stream=stream0)
        buf1683 = buf1677; del buf1677  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf1679, convolution_111, unsqueeze_3889, buf1681, squeeze_334, buf1680, primals_335, buf1683, 225792, grid=grid(225792), stream=stream0)
        del convolution_111
        del primals_335
        del squeeze_334
        del unsqueeze_3889
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1684 = aten.convolution_backward(buf1683, relu_103, primals_334, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1683
        del primals_334
        buf1685 = buf1684[0]
        buf1686 = buf1684[1]
        del buf1684
        buf1687 = buf1681; del buf1681  # reuse
        buf1688 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1689 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_103, buf1685, convolution_110, unsqueeze_3901, squeeze_331, buf1687, buf1688, buf1689, 36, 6272, grid=grid(36), stream=stream0)
        buf1690 = buf1685; del buf1685  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf1690, relu_103, convolution_110, unsqueeze_3901, buf1688, squeeze_331, buf1687, primals_332, 225792, grid=grid(225792), stream=stream0)
        del convolution_110
        del primals_332
        del relu_103
        del squeeze_331
        del unsqueeze_3901
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1691 = aten.convolution_backward(buf1690, relu_102, primals_331, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_331
        buf1692 = buf1691[0]
        buf1693 = buf1691[1]
        del buf1691
        buf1694 = buf1688; del buf1688  # reuse
        buf1695 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1697 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_78.run(relu_102, buf1679, buf1692, convolution_109, unsqueeze_3913, squeeze_328, buf1694, buf1695, buf1697, 36, 6272, grid=grid(36), stream=stream0)
        buf1696 = buf1690; del buf1690  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_79.run(relu_102, buf1679, buf1692, convolution_109, unsqueeze_3913, buf1695, squeeze_328, buf1694, primals_329, buf1696, 225792, grid=grid(225792), stream=stream0)
        del convolution_109
        del primals_329
        del squeeze_328
        del unsqueeze_3913
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1698 = aten.convolution_backward(buf1696, relu_101, primals_328, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1696
        del primals_328
        buf1699 = buf1698[0]
        buf1700 = buf1698[1]
        del buf1698
        buf1701 = buf1695; del buf1695  # reuse
        buf1702 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1703 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_101, buf1699, convolution_108, unsqueeze_3925, squeeze_325, buf1701, buf1702, buf1703, 36, 6272, grid=grid(36), stream=stream0)
        buf1704 = buf1699; del buf1699  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf1704, relu_101, convolution_108, unsqueeze_3925, buf1702, squeeze_325, buf1701, primals_326, 225792, grid=grid(225792), stream=stream0)
        del convolution_108
        del primals_326
        del relu_101
        del squeeze_325
        del unsqueeze_3925
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1705 = aten.convolution_backward(buf1704, relu_100, primals_325, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1704
        del primals_325
        buf1706 = buf1705[0]
        buf1707 = buf1705[1]
        del buf1705
        buf1708 = buf1679; del buf1679  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_80.run(buf1708, relu_100, relu_102, buf1692, buf1706, 225792, grid=grid(225792), stream=stream0)
        del buf1692
        del relu_100
        del relu_102
        buf1709 = buf1702; del buf1702  # reuse
        buf1710 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1711 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf1708, convolution_107, unsqueeze_3937, squeeze_322, buf1709, buf1710, buf1711, 36, 6272, grid=grid(36), stream=stream0)
        buf1712 = buf1706; del buf1706  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf1708, convolution_107, unsqueeze_3937, buf1710, squeeze_322, buf1709, primals_323, buf1712, 225792, grid=grid(225792), stream=stream0)
        del convolution_107
        del primals_323
        del squeeze_322
        del unsqueeze_3937
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1713 = aten.convolution_backward(buf1712, relu_99, primals_322, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1712
        del primals_322
        buf1714 = buf1713[0]
        buf1715 = buf1713[1]
        del buf1713
        buf1716 = buf1710; del buf1710  # reuse
        buf1717 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1718 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_99, buf1714, convolution_106, unsqueeze_3949, squeeze_319, buf1716, buf1717, buf1718, 36, 6272, grid=grid(36), stream=stream0)
        buf1719 = buf1714; del buf1714  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf1719, relu_99, convolution_106, unsqueeze_3949, buf1717, squeeze_319, buf1716, primals_320, 225792, grid=grid(225792), stream=stream0)
        del convolution_106
        del primals_320
        del relu_99
        del squeeze_319
        del unsqueeze_3949
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1720 = aten.convolution_backward(buf1719, relu_88, primals_319, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1719
        del primals_319
        buf1721 = buf1720[0]
        buf1722 = buf1720[1]
        del buf1720
        buf1723 = reinterpret_tensor(buf1658, (18, 4), (1, 18), 0); del buf1658  # reuse
        buf1725 = empty_strided((18, 4), (1, 18), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_106.run(relu_98, buf1565, buf1583, buf1586, convolution_105, unsqueeze_3961, buf1723, buf1725, 72, 6272, grid=grid(72), stream=stream0)
        buf1724 = buf1600; del buf1600  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1723, buf1724, 18, 4, grid=grid(18), stream=stream0)
        buf1726 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1728 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1725, squeeze_316, buf1726, buf1728, 18, 4, grid=grid(18), stream=stream0)
        buf1727 = buf1545; del buf1545  # reuse
        buf1729 = buf1727; del buf1727  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_107.run(buf1729, relu_98, buf1565, buf1583, buf1586, convolution_105, unsqueeze_3961, buf1726, squeeze_316, buf1724, primals_317, 451584, grid=grid(451584), stream=stream0)
        del convolution_105
        del primals_317
        del squeeze_316
        del unsqueeze_3961
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1730 = aten.convolution_backward(buf1729, relu_97, primals_316, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1729
        del primals_316
        buf1731 = buf1730[0]
        buf1732 = buf1730[1]
        del buf1730
        buf1733 = buf1725; del buf1725  # reuse
        buf1735 = buf1723; del buf1723  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_97, buf1731, convolution_104, unsqueeze_3973, buf1733, buf1735, 72, 6272, grid=grid(72), stream=stream0)
        buf1734 = buf1726; del buf1726  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1733, buf1734, 18, 4, grid=grid(18), stream=stream0)
        buf1736 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1737 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1735, squeeze_313, buf1736, buf1737, 18, 4, grid=grid(18), stream=stream0)
        buf1738 = buf1731; del buf1731  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf1738, relu_97, convolution_104, unsqueeze_3973, buf1736, squeeze_313, buf1734, primals_314, 451584, grid=grid(451584), stream=stream0)
        del convolution_104
        del primals_314
        del relu_97
        del squeeze_313
        del unsqueeze_3973
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1739 = aten.convolution_backward(buf1738, relu_96, primals_313, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1738
        del primals_313
        buf1740 = buf1739[0]
        buf1741 = buf1739[1]
        del buf1739
        buf1742 = buf1565; del buf1565  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_108.run(buf1742, relu_96, relu_98, buf1583, buf1586, buf1740, 451584, grid=grid(451584), stream=stream0)
        del buf1583
        del buf1586
        del relu_96
        del relu_98
        buf1743 = buf1735; del buf1735  # reuse
        buf1745 = buf1733; del buf1733  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf1742, convolution_103, unsqueeze_3985, buf1743, buf1745, 72, 6272, grid=grid(72), stream=stream0)
        buf1744 = buf1736; del buf1736  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1743, buf1744, 18, 4, grid=grid(18), stream=stream0)
        buf1746 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1747 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1745, squeeze_310, buf1746, buf1747, 18, 4, grid=grid(18), stream=stream0)
        buf1748 = buf1740; del buf1740  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_84.run(buf1742, convolution_103, unsqueeze_3985, buf1746, squeeze_310, buf1744, primals_311, buf1748, 451584, grid=grid(451584), stream=stream0)
        del convolution_103
        del primals_311
        del squeeze_310
        del unsqueeze_3985
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1749 = aten.convolution_backward(buf1748, relu_95, primals_310, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1748
        del primals_310
        buf1750 = buf1749[0]
        buf1751 = buf1749[1]
        del buf1749
        buf1752 = buf1745; del buf1745  # reuse
        buf1754 = buf1743; del buf1743  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_95, buf1750, convolution_102, unsqueeze_3997, buf1752, buf1754, 72, 6272, grid=grid(72), stream=stream0)
        buf1753 = buf1746; del buf1746  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1752, buf1753, 18, 4, grid=grid(18), stream=stream0)
        buf1755 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1756 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1754, squeeze_307, buf1755, buf1756, 18, 4, grid=grid(18), stream=stream0)
        buf1757 = buf1750; del buf1750  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf1757, relu_95, convolution_102, unsqueeze_3997, buf1755, squeeze_307, buf1753, primals_308, 451584, grid=grid(451584), stream=stream0)
        del convolution_102
        del primals_308
        del relu_95
        del squeeze_307
        del unsqueeze_3997
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1758 = aten.convolution_backward(buf1757, relu_94, primals_307, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_307
        buf1759 = buf1758[0]
        buf1760 = buf1758[1]
        del buf1758
        buf1761 = buf1754; del buf1754  # reuse
        buf1763 = buf1752; del buf1752  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_87.run(relu_94, buf1742, buf1759, convolution_101, unsqueeze_4009, buf1761, buf1763, 72, 6272, grid=grid(72), stream=stream0)
        buf1762 = buf1755; del buf1755  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1761, buf1762, 18, 4, grid=grid(18), stream=stream0)
        buf1764 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1766 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1763, squeeze_304, buf1764, buf1766, 18, 4, grid=grid(18), stream=stream0)
        buf1765 = buf1757; del buf1757  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_88.run(relu_94, buf1742, buf1759, convolution_101, unsqueeze_4009, buf1764, squeeze_304, buf1762, primals_305, buf1765, 451584, grid=grid(451584), stream=stream0)
        del convolution_101
        del primals_305
        del squeeze_304
        del unsqueeze_4009
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1767 = aten.convolution_backward(buf1765, relu_93, primals_304, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1765
        del primals_304
        buf1768 = buf1767[0]
        buf1769 = buf1767[1]
        del buf1767
        buf1770 = buf1763; del buf1763  # reuse
        buf1772 = buf1761; del buf1761  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_93, buf1768, convolution_100, unsqueeze_4021, buf1770, buf1772, 72, 6272, grid=grid(72), stream=stream0)
        buf1771 = buf1764; del buf1764  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1770, buf1771, 18, 4, grid=grid(18), stream=stream0)
        buf1773 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1774 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1772, squeeze_301, buf1773, buf1774, 18, 4, grid=grid(18), stream=stream0)
        buf1775 = buf1768; del buf1768  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf1775, relu_93, convolution_100, unsqueeze_4021, buf1773, squeeze_301, buf1771, primals_302, 451584, grid=grid(451584), stream=stream0)
        del convolution_100
        del primals_302
        del relu_93
        del squeeze_301
        del unsqueeze_4021
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1776 = aten.convolution_backward(buf1775, relu_92, primals_301, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1775
        del primals_301
        buf1777 = buf1776[0]
        buf1778 = buf1776[1]
        del buf1776
        buf1779 = buf1742; del buf1742  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_89.run(buf1779, relu_92, relu_94, buf1759, buf1777, 451584, grid=grid(451584), stream=stream0)
        del buf1759
        del relu_92
        del relu_94
        buf1780 = buf1772; del buf1772  # reuse
        buf1782 = buf1770; del buf1770  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf1779, convolution_99, unsqueeze_4033, buf1780, buf1782, 72, 6272, grid=grid(72), stream=stream0)
        buf1781 = buf1773; del buf1773  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1780, buf1781, 18, 4, grid=grid(18), stream=stream0)
        buf1783 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1784 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1782, squeeze_298, buf1783, buf1784, 18, 4, grid=grid(18), stream=stream0)
        buf1785 = buf1777; del buf1777  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_84.run(buf1779, convolution_99, unsqueeze_4033, buf1783, squeeze_298, buf1781, primals_299, buf1785, 451584, grid=grid(451584), stream=stream0)
        del convolution_99
        del primals_299
        del squeeze_298
        del unsqueeze_4033
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1786 = aten.convolution_backward(buf1785, relu_91, primals_298, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1785
        del primals_298
        buf1787 = buf1786[0]
        buf1788 = buf1786[1]
        del buf1786
        buf1789 = buf1782; del buf1782  # reuse
        buf1791 = buf1780; del buf1780  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_91, buf1787, convolution_98, unsqueeze_4045, buf1789, buf1791, 72, 6272, grid=grid(72), stream=stream0)
        buf1790 = buf1783; del buf1783  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1789, buf1790, 18, 4, grid=grid(18), stream=stream0)
        buf1792 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1793 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1791, squeeze_295, buf1792, buf1793, 18, 4, grid=grid(18), stream=stream0)
        buf1794 = buf1787; del buf1787  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf1794, relu_91, convolution_98, unsqueeze_4045, buf1792, squeeze_295, buf1790, primals_296, 451584, grid=grid(451584), stream=stream0)
        del convolution_98
        del primals_296
        del relu_91
        del squeeze_295
        del unsqueeze_4045
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1795 = aten.convolution_backward(buf1794, relu_87, primals_295, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1794
        del primals_295
        buf1796 = buf1795[0]
        buf1797 = buf1795[1]
        del buf1795
        buf1798 = buf1635; del buf1635  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_74.run(buf1798, relu_90, relu_108, buf1648, buf1662, 112896, grid=grid(112896), stream=stream0)
        del relu_108
        del relu_90
        buf1819 = buf1574; del buf1574  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.add, aten.new_zeros, aten.threshold_backward]
        triton_poi_fused__unsafe_index_put_new_zeros_45.run(buf1819, 56448, grid=grid(56448), stream=stream0)
        buf1820 = buf1708; del buf1708  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_110.run(buf1820, relu_88, buf1721, 225792, grid=grid(225792), stream=stream0)
        del relu_88
        aten.index_put_(buf1819, [None, None, unsqueeze_259, convert_element_type_13], buf1820, True)
        buf1823 = buf1717; del buf1717  # reuse
        buf1824 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1825 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_46.run(buf1819, convolution_94, unsqueeze_4093, squeeze_283, buf1823, buf1824, buf1825, 36, 1568, grid=grid(36), stream=stream0)
        buf1822 = buf1567; del buf1567  # reuse
        buf1826 = buf1822; del buf1822  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_47.run(buf1826, buf1819, convolution_94, unsqueeze_4093, buf1824, squeeze_283, buf1823, primals_284, 56448, grid=grid(56448), stream=stream0)
        del convolution_94
        del primals_284
        del squeeze_283
        del unsqueeze_4093
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1827 = aten.convolution_backward(buf1826, relu_86, primals_283, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_283
        buf1828 = buf1827[0]
        buf1837 = buf1592; del buf1592  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.add, aten.new_zeros, aten.threshold_backward]
        triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_35.run(buf1837, 28224, grid=grid(28224), stream=stream0)
        buf1838 = buf1779; del buf1779  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_111.run(buf1838, relu_87, buf1796, 451584, grid=grid(451584), stream=stream0)
        del relu_87
        aten.index_put_(buf1837, [None, None, unsqueeze_250, convert_element_type_9], buf1838, True)
        buf1841 = buf1792; del buf1792  # reuse
        buf1842 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1843 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_54.run(buf1837, convolution_92, unsqueeze_4117, squeeze_277, buf1841, buf1842, buf1843, 18, 1568, grid=grid(18), stream=stream0)
        buf1840 = buf1585; del buf1585  # reuse
        buf1844 = buf1840; del buf1840  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_55.run(buf1844, buf1837, convolution_92, unsqueeze_4117, buf1842, squeeze_277, buf1841, primals_278, 28224, grid=grid(28224), stream=stream0)
        del convolution_92
        del primals_278
        del squeeze_277
        del unsqueeze_4117
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1845 = aten.convolution_backward(buf1844, relu_86, primals_277, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_277
        buf1846 = buf1845[0]
        buf1799 = reinterpret_tensor(buf1791, (72, ), (1, ), 0); del buf1791  # reuse
        buf1800 = reinterpret_tensor(buf1789, (72, ), (1, ), 0); del buf1789  # reuse
        buf1806 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1858 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1859 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1801 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1807 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1861 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_100.run(buf1798, convolution_97, unsqueeze_4057, convolution_96, unsqueeze_4069, relu_86, buf1828, buf1846, convolution_90, unsqueeze_4141, squeeze_292, squeeze_289, squeeze_271, buf1799, buf1800, buf1806, buf1858, buf1859, buf1801, buf1807, buf1861, 72, 1568, grid=grid(72), stream=stream0)
        buf1802 = buf1662; del buf1662  # reuse
        buf1808 = buf1648; del buf1648  # reuse
        buf1860 = buf1660; del buf1660  # reuse
        buf1862 = buf1860; del buf1860  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_101.run(buf1862, buf1798, convolution_97, unsqueeze_4057, buf1800, squeeze_292, buf1799, primals_293, convolution_96, unsqueeze_4069, buf1806, squeeze_289, primals_290, relu_86, buf1828, buf1846, convolution_90, unsqueeze_4141, buf1859, squeeze_271, buf1858, primals_272, buf1802, buf1808, 112896, grid=grid(112896), stream=stream0)
        del convolution_90
        del convolution_96
        del convolution_97
        del primals_272
        del primals_290
        del primals_293
        del squeeze_271
        del squeeze_289
        del squeeze_292
        del unsqueeze_4057
        del unsqueeze_4069
        del unsqueeze_4141
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1803 = aten.convolution_backward(buf1802, relu_78, primals_292, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1802
        del primals_292
        buf1804 = buf1803[0]
        buf1805 = buf1803[1]
        del buf1803
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1809 = aten.convolution_backward(buf1808, relu_89, primals_289, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_289
        buf1810 = buf1809[0]
        buf1811 = buf1809[1]
        del buf1809
        buf1812 = buf1842; del buf1842  # reuse
        buf1813 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1814 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_33.run(relu_89, buf1810, convolution_95, unsqueeze_4081, squeeze_286, buf1812, buf1813, buf1814, 18, 6272, grid=grid(18), stream=stream0)
        buf1815 = buf1810; del buf1810  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_34.run(buf1815, relu_89, convolution_95, unsqueeze_4081, buf1813, squeeze_286, buf1812, primals_287, 112896, grid=grid(112896), stream=stream0)
        del convolution_95
        del primals_287
        del relu_89
        del squeeze_286
        del unsqueeze_4081
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1816 = aten.convolution_backward(buf1815, relu_70, primals_286, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_286
        buf1817 = buf1816[0]
        buf1818 = buf1816[1]
        del buf1816
        buf1829 = buf1827[1]
        del buf1827
        buf1830 = buf1824; del buf1824  # reuse
        buf1831 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1832 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf1820, convolution_93, unsqueeze_4105, squeeze_280, buf1830, buf1831, buf1832, 36, 6272, grid=grid(36), stream=stream0)
        buf1833 = buf1721; del buf1721  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf1820, convolution_93, unsqueeze_4105, buf1831, squeeze_280, buf1830, primals_281, buf1833, 225792, grid=grid(225792), stream=stream0)
        del convolution_93
        del primals_281
        del squeeze_280
        del unsqueeze_4105
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1834 = aten.convolution_backward(buf1833, relu_70, primals_280, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_280
        buf1835 = buf1834[0]
        buf1836 = buf1834[1]
        del buf1834
        buf1847 = buf1845[1]
        del buf1845
        buf1848 = buf1815; del buf1815  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_new_zeros_56.run(buf1848, 112896, grid=grid(112896), stream=stream0)
        aten.index_put_(buf1848, [None, None, unsqueeze_136, convert_element_type_1], buf1838, True)
        buf1851 = buf1813; del buf1813  # reuse
        buf1852 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1853 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_57.run(buf1848, convolution_91, unsqueeze_4129, squeeze_274, buf1851, buf1852, buf1853, 18, 6272, grid=grid(18), stream=stream0)
        buf1850 = reinterpret_tensor(buf1808, (8, 18, 28, 28), (14112, 784, 28, 1), 0); del buf1808  # reuse
        buf1854 = buf1850; del buf1850  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_58.run(buf1854, buf1848, convolution_91, unsqueeze_4129, buf1852, squeeze_274, buf1851, primals_275, 112896, grid=grid(112896), stream=stream0)
        del buf1848
        del convolution_91
        del primals_275
        del squeeze_274
        del unsqueeze_4129
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1855 = aten.convolution_backward(buf1854, relu_78, primals_274, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1854
        del primals_274
        buf1856 = buf1855[0]
        buf1857 = buf1855[1]
        del buf1855
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1863 = aten.convolution_backward(buf1862, relu_85, primals_271, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1862
        del primals_271
        buf1864 = buf1863[0]
        buf1865 = buf1863[1]
        del buf1863
        buf1866 = buf1859; del buf1859  # reuse
        buf1867 = buf1806; del buf1806  # reuse
        buf1868 = buf1800; del buf1800  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_85, buf1864, convolution_89, unsqueeze_4153, squeeze_268, buf1866, buf1867, buf1868, 72, 1568, grid=grid(72), stream=stream0)
        buf1869 = buf1864; del buf1864  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf1869, relu_85, convolution_89, unsqueeze_4153, buf1867, squeeze_268, buf1866, primals_269, 112896, grid=grid(112896), stream=stream0)
        del convolution_89
        del primals_269
        del relu_85
        del squeeze_268
        del unsqueeze_4153
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1870 = aten.convolution_backward(buf1869, relu_84, primals_268, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1869
        del primals_268
        buf1871 = buf1870[0]
        buf1872 = buf1870[1]
        del buf1870
        buf1873 = buf1798; del buf1798  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_102.run(buf1873, relu_84, relu_86, buf1828, buf1846, buf1871, 112896, grid=grid(112896), stream=stream0)
        del buf1828
        del buf1846
        del relu_84
        del relu_86
        buf1874 = buf1867; del buf1867  # reuse
        buf1875 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1876 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_68.run(buf1873, convolution_88, unsqueeze_4165, squeeze_265, buf1874, buf1875, buf1876, 72, 1568, grid=grid(72), stream=stream0)
        buf1877 = buf1871; del buf1871  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_69.run(buf1873, convolution_88, unsqueeze_4165, buf1875, squeeze_265, buf1874, primals_266, buf1877, 112896, grid=grid(112896), stream=stream0)
        del convolution_88
        del primals_266
        del squeeze_265
        del unsqueeze_4165
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1878 = aten.convolution_backward(buf1877, relu_83, primals_265, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1877
        del primals_265
        buf1879 = buf1878[0]
        buf1880 = buf1878[1]
        del buf1878
        buf1881 = buf1875; del buf1875  # reuse
        buf1882 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1883 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_83, buf1879, convolution_87, unsqueeze_4177, squeeze_262, buf1881, buf1882, buf1883, 72, 1568, grid=grid(72), stream=stream0)
        buf1884 = buf1879; del buf1879  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf1884, relu_83, convolution_87, unsqueeze_4177, buf1882, squeeze_262, buf1881, primals_263, 112896, grid=grid(112896), stream=stream0)
        del convolution_87
        del primals_263
        del relu_83
        del squeeze_262
        del unsqueeze_4177
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1885 = aten.convolution_backward(buf1884, relu_82, primals_262, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_262
        buf1886 = buf1885[0]
        buf1887 = buf1885[1]
        del buf1885
        buf1888 = buf1882; del buf1882  # reuse
        buf1889 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1891 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_72.run(relu_82, buf1873, buf1886, convolution_86, unsqueeze_4189, squeeze_259, buf1888, buf1889, buf1891, 72, 1568, grid=grid(72), stream=stream0)
        buf1890 = buf1884; del buf1884  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_73.run(relu_82, buf1873, buf1886, convolution_86, unsqueeze_4189, buf1889, squeeze_259, buf1888, primals_260, buf1890, 112896, grid=grid(112896), stream=stream0)
        del convolution_86
        del primals_260
        del squeeze_259
        del unsqueeze_4189
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1892 = aten.convolution_backward(buf1890, relu_81, primals_259, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1890
        del primals_259
        buf1893 = buf1892[0]
        buf1894 = buf1892[1]
        del buf1892
        buf1895 = buf1889; del buf1889  # reuse
        buf1896 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1897 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_81, buf1893, convolution_85, unsqueeze_4201, squeeze_256, buf1895, buf1896, buf1897, 72, 1568, grid=grid(72), stream=stream0)
        buf1898 = buf1893; del buf1893  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf1898, relu_81, convolution_85, unsqueeze_4201, buf1896, squeeze_256, buf1895, primals_257, 112896, grid=grid(112896), stream=stream0)
        del convolution_85
        del primals_257
        del relu_81
        del squeeze_256
        del unsqueeze_4201
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1899 = aten.convolution_backward(buf1898, relu_80, primals_256, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1898
        del primals_256
        buf1900 = buf1899[0]
        buf1901 = buf1899[1]
        del buf1899
        buf1902 = buf1873; del buf1873  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_74.run(buf1902, relu_80, relu_82, buf1886, buf1900, 112896, grid=grid(112896), stream=stream0)
        del buf1886
        del relu_80
        del relu_82
        buf1903 = buf1896; del buf1896  # reuse
        buf1904 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1905 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_68.run(buf1902, convolution_84, unsqueeze_4213, squeeze_253, buf1903, buf1904, buf1905, 72, 1568, grid=grid(72), stream=stream0)
        buf1906 = buf1900; del buf1900  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_69.run(buf1902, convolution_84, unsqueeze_4213, buf1904, squeeze_253, buf1903, primals_254, buf1906, 112896, grid=grid(112896), stream=stream0)
        del convolution_84
        del primals_254
        del squeeze_253
        del unsqueeze_4213
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1907 = aten.convolution_backward(buf1906, relu_79, primals_253, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_253
        buf1908 = buf1907[0]
        buf1909 = buf1907[1]
        del buf1907
        buf1910 = buf1904; del buf1904  # reuse
        buf1911 = empty((72, ), device='cuda', dtype=torch.float32)
        buf1912 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_79, buf1908, convolution_83, unsqueeze_4225, squeeze_250, buf1910, buf1911, buf1912, 72, 1568, grid=grid(72), stream=stream0)
        buf1913 = buf1908; del buf1908  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf1913, relu_79, convolution_83, unsqueeze_4225, buf1911, squeeze_250, buf1910, primals_251, 112896, grid=grid(112896), stream=stream0)
        del convolution_83
        del primals_251
        del relu_79
        del squeeze_250
        del unsqueeze_4225
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1914 = aten.convolution_backward(buf1913, relu_62, primals_250, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_250
        buf1915 = buf1914[0]
        buf1916 = buf1914[1]
        del buf1914
        buf1917 = buf1831; del buf1831  # reuse
        buf1918 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1920 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_103.run(relu_78, buf1804, buf1820, buf1856, convolution_82, unsqueeze_4237, squeeze_247, buf1917, buf1918, buf1920, 36, 6272, grid=grid(36), stream=stream0)
        buf1919 = buf1833; del buf1833  # reuse
        buf1921 = buf1919; del buf1919  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_104.run(buf1921, relu_78, buf1804, buf1820, buf1856, convolution_82, unsqueeze_4237, buf1918, squeeze_247, buf1917, primals_248, 225792, grid=grid(225792), stream=stream0)
        del convolution_82
        del primals_248
        del squeeze_247
        del unsqueeze_4237
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1922 = aten.convolution_backward(buf1921, relu_77, primals_247, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1921
        del primals_247
        buf1923 = buf1922[0]
        buf1924 = buf1922[1]
        del buf1922
        buf1925 = buf1918; del buf1918  # reuse
        buf1926 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1927 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_77, buf1923, convolution_81, unsqueeze_4249, squeeze_244, buf1925, buf1926, buf1927, 36, 6272, grid=grid(36), stream=stream0)
        buf1928 = buf1923; del buf1923  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf1928, relu_77, convolution_81, unsqueeze_4249, buf1926, squeeze_244, buf1925, primals_245, 225792, grid=grid(225792), stream=stream0)
        del convolution_81
        del primals_245
        del relu_77
        del squeeze_244
        del unsqueeze_4249
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1929 = aten.convolution_backward(buf1928, relu_76, primals_244, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1928
        del primals_244
        buf1930 = buf1929[0]
        buf1931 = buf1929[1]
        del buf1929
        buf1932 = buf1804; del buf1804  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_105.run(buf1932, relu_76, relu_78, buf1820, buf1856, buf1930, 225792, grid=grid(225792), stream=stream0)
        del buf1820
        del buf1856
        del relu_76
        del relu_78
        buf1933 = buf1926; del buf1926  # reuse
        buf1934 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1935 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf1932, convolution_80, unsqueeze_4261, squeeze_241, buf1933, buf1934, buf1935, 36, 6272, grid=grid(36), stream=stream0)
        buf1936 = buf1930; del buf1930  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf1932, convolution_80, unsqueeze_4261, buf1934, squeeze_241, buf1933, primals_242, buf1936, 225792, grid=grid(225792), stream=stream0)
        del convolution_80
        del primals_242
        del squeeze_241
        del unsqueeze_4261
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1937 = aten.convolution_backward(buf1936, relu_75, primals_241, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1936
        del primals_241
        buf1938 = buf1937[0]
        buf1939 = buf1937[1]
        del buf1937
        buf1940 = buf1934; del buf1934  # reuse
        buf1941 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1942 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_75, buf1938, convolution_79, unsqueeze_4273, squeeze_238, buf1940, buf1941, buf1942, 36, 6272, grid=grid(36), stream=stream0)
        buf1943 = buf1938; del buf1938  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf1943, relu_75, convolution_79, unsqueeze_4273, buf1941, squeeze_238, buf1940, primals_239, 225792, grid=grid(225792), stream=stream0)
        del convolution_79
        del primals_239
        del relu_75
        del squeeze_238
        del unsqueeze_4273
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1944 = aten.convolution_backward(buf1943, relu_74, primals_238, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_238
        buf1945 = buf1944[0]
        buf1946 = buf1944[1]
        del buf1944
        buf1947 = buf1941; del buf1941  # reuse
        buf1948 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1950 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_78.run(relu_74, buf1932, buf1945, convolution_78, unsqueeze_4285, squeeze_235, buf1947, buf1948, buf1950, 36, 6272, grid=grid(36), stream=stream0)
        buf1949 = buf1943; del buf1943  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_79.run(relu_74, buf1932, buf1945, convolution_78, unsqueeze_4285, buf1948, squeeze_235, buf1947, primals_236, buf1949, 225792, grid=grid(225792), stream=stream0)
        del convolution_78
        del primals_236
        del squeeze_235
        del unsqueeze_4285
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf1951 = aten.convolution_backward(buf1949, relu_73, primals_235, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1949
        del primals_235
        buf1952 = buf1951[0]
        buf1953 = buf1951[1]
        del buf1951
        buf1954 = buf1948; del buf1948  # reuse
        buf1955 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1956 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_73, buf1952, convolution_77, unsqueeze_4297, squeeze_232, buf1954, buf1955, buf1956, 36, 6272, grid=grid(36), stream=stream0)
        buf1957 = buf1952; del buf1952  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf1957, relu_73, convolution_77, unsqueeze_4297, buf1955, squeeze_232, buf1954, primals_233, 225792, grid=grid(225792), stream=stream0)
        del convolution_77
        del primals_233
        del relu_73
        del squeeze_232
        del unsqueeze_4297
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1958 = aten.convolution_backward(buf1957, relu_72, primals_232, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1957
        del primals_232
        buf1959 = buf1958[0]
        buf1960 = buf1958[1]
        del buf1958
        buf1961 = buf1932; del buf1932  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_80.run(buf1961, relu_72, relu_74, buf1945, buf1959, 225792, grid=grid(225792), stream=stream0)
        del buf1945
        del relu_72
        del relu_74
        buf1962 = buf1955; del buf1955  # reuse
        buf1963 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1964 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf1961, convolution_76, unsqueeze_4309, squeeze_229, buf1962, buf1963, buf1964, 36, 6272, grid=grid(36), stream=stream0)
        buf1965 = buf1959; del buf1959  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf1961, convolution_76, unsqueeze_4309, buf1963, squeeze_229, buf1962, primals_230, buf1965, 225792, grid=grid(225792), stream=stream0)
        del convolution_76
        del primals_230
        del squeeze_229
        del unsqueeze_4309
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1966 = aten.convolution_backward(buf1965, relu_71, primals_229, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1965
        del primals_229
        buf1967 = buf1966[0]
        buf1968 = buf1966[1]
        del buf1966
        buf1969 = buf1963; del buf1963  # reuse
        buf1970 = empty((36, ), device='cuda', dtype=torch.float32)
        buf1971 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_71, buf1967, convolution_75, unsqueeze_4321, squeeze_226, buf1969, buf1970, buf1971, 36, 6272, grid=grid(36), stream=stream0)
        buf1972 = buf1967; del buf1967  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf1972, relu_71, convolution_75, unsqueeze_4321, buf1970, squeeze_226, buf1969, primals_227, 225792, grid=grid(225792), stream=stream0)
        del convolution_75
        del primals_227
        del relu_71
        del squeeze_226
        del unsqueeze_4321
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1973 = aten.convolution_backward(buf1972, relu_60, primals_226, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1972
        del primals_226
        buf1974 = buf1973[0]
        buf1975 = buf1973[1]
        del buf1973
        buf1976 = reinterpret_tensor(buf1911, (18, 4), (1, 18), 0); del buf1911  # reuse
        buf1978 = empty_strided((18, 4), (1, 18), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_106.run(relu_70, buf1817, buf1835, buf1838, convolution_74, unsqueeze_4333, buf1976, buf1978, 72, 6272, grid=grid(72), stream=stream0)
        buf1977 = buf1852; del buf1852  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1976, buf1977, 18, 4, grid=grid(18), stream=stream0)
        buf1979 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1981 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1978, squeeze_223, buf1979, buf1981, 18, 4, grid=grid(18), stream=stream0)
        buf1980 = buf1796; del buf1796  # reuse
        buf1982 = buf1980; del buf1980  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_107.run(buf1982, relu_70, buf1817, buf1835, buf1838, convolution_74, unsqueeze_4333, buf1979, squeeze_223, buf1977, primals_224, 451584, grid=grid(451584), stream=stream0)
        del convolution_74
        del primals_224
        del squeeze_223
        del unsqueeze_4333
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf1983 = aten.convolution_backward(buf1982, relu_69, primals_223, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1982
        del primals_223
        buf1984 = buf1983[0]
        buf1985 = buf1983[1]
        del buf1983
        buf1986 = buf1978; del buf1978  # reuse
        buf1988 = buf1976; del buf1976  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_69, buf1984, convolution_73, unsqueeze_4345, buf1986, buf1988, 72, 6272, grid=grid(72), stream=stream0)
        buf1987 = buf1979; del buf1979  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1986, buf1987, 18, 4, grid=grid(18), stream=stream0)
        buf1989 = empty((18, ), device='cuda', dtype=torch.float32)
        buf1990 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1988, squeeze_220, buf1989, buf1990, 18, 4, grid=grid(18), stream=stream0)
        buf1991 = buf1984; del buf1984  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf1991, relu_69, convolution_73, unsqueeze_4345, buf1989, squeeze_220, buf1987, primals_221, 451584, grid=grid(451584), stream=stream0)
        del convolution_73
        del primals_221
        del relu_69
        del squeeze_220
        del unsqueeze_4345
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf1992 = aten.convolution_backward(buf1991, relu_68, primals_220, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf1991
        del primals_220
        buf1993 = buf1992[0]
        buf1994 = buf1992[1]
        del buf1992
        buf1995 = buf1817; del buf1817  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_108.run(buf1995, relu_68, relu_70, buf1835, buf1838, buf1993, 451584, grid=grid(451584), stream=stream0)
        del buf1835
        del buf1838
        del relu_68
        del relu_70
        buf1996 = buf1988; del buf1988  # reuse
        buf1998 = buf1986; del buf1986  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf1995, convolution_72, unsqueeze_4357, buf1996, buf1998, 72, 6272, grid=grid(72), stream=stream0)
        buf1997 = buf1989; del buf1989  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf1996, buf1997, 18, 4, grid=grid(18), stream=stream0)
        buf1999 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2000 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf1998, squeeze_217, buf1999, buf2000, 18, 4, grid=grid(18), stream=stream0)
        buf2001 = buf1993; del buf1993  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_84.run(buf1995, convolution_72, unsqueeze_4357, buf1999, squeeze_217, buf1997, primals_218, buf2001, 451584, grid=grid(451584), stream=stream0)
        del convolution_72
        del primals_218
        del squeeze_217
        del unsqueeze_4357
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2002 = aten.convolution_backward(buf2001, relu_67, primals_217, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2001
        del primals_217
        buf2003 = buf2002[0]
        buf2004 = buf2002[1]
        del buf2002
        buf2005 = buf1998; del buf1998  # reuse
        buf2007 = buf1996; del buf1996  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_67, buf2003, convolution_71, unsqueeze_4369, buf2005, buf2007, 72, 6272, grid=grid(72), stream=stream0)
        buf2006 = buf1999; del buf1999  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2005, buf2006, 18, 4, grid=grid(18), stream=stream0)
        buf2008 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2009 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2007, squeeze_214, buf2008, buf2009, 18, 4, grid=grid(18), stream=stream0)
        buf2010 = buf2003; del buf2003  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf2010, relu_67, convolution_71, unsqueeze_4369, buf2008, squeeze_214, buf2006, primals_215, 451584, grid=grid(451584), stream=stream0)
        del convolution_71
        del primals_215
        del relu_67
        del squeeze_214
        del unsqueeze_4369
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2011 = aten.convolution_backward(buf2010, relu_66, primals_214, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_214
        buf2012 = buf2011[0]
        buf2013 = buf2011[1]
        del buf2011
        buf2014 = buf2007; del buf2007  # reuse
        buf2016 = buf2005; del buf2005  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_87.run(relu_66, buf1995, buf2012, convolution_70, unsqueeze_4381, buf2014, buf2016, 72, 6272, grid=grid(72), stream=stream0)
        buf2015 = buf2008; del buf2008  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2014, buf2015, 18, 4, grid=grid(18), stream=stream0)
        buf2017 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2019 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2016, squeeze_211, buf2017, buf2019, 18, 4, grid=grid(18), stream=stream0)
        buf2018 = buf2010; del buf2010  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_88.run(relu_66, buf1995, buf2012, convolution_70, unsqueeze_4381, buf2017, squeeze_211, buf2015, primals_212, buf2018, 451584, grid=grid(451584), stream=stream0)
        del convolution_70
        del primals_212
        del squeeze_211
        del unsqueeze_4381
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf2020 = aten.convolution_backward(buf2018, relu_65, primals_211, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2018
        del primals_211
        buf2021 = buf2020[0]
        buf2022 = buf2020[1]
        del buf2020
        buf2023 = buf2016; del buf2016  # reuse
        buf2025 = buf2014; del buf2014  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_65, buf2021, convolution_69, unsqueeze_4393, buf2023, buf2025, 72, 6272, grid=grid(72), stream=stream0)
        buf2024 = buf2017; del buf2017  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2023, buf2024, 18, 4, grid=grid(18), stream=stream0)
        buf2026 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2027 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2025, squeeze_208, buf2026, buf2027, 18, 4, grid=grid(18), stream=stream0)
        buf2028 = buf2021; del buf2021  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf2028, relu_65, convolution_69, unsqueeze_4393, buf2026, squeeze_208, buf2024, primals_209, 451584, grid=grid(451584), stream=stream0)
        del convolution_69
        del primals_209
        del relu_65
        del squeeze_208
        del unsqueeze_4393
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2029 = aten.convolution_backward(buf2028, relu_64, primals_208, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2028
        del primals_208
        buf2030 = buf2029[0]
        buf2031 = buf2029[1]
        del buf2029
        buf2032 = buf1995; del buf1995  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_89.run(buf2032, relu_64, relu_66, buf2012, buf2030, 451584, grid=grid(451584), stream=stream0)
        del buf2012
        del relu_64
        del relu_66
        buf2033 = buf2025; del buf2025  # reuse
        buf2035 = buf2023; del buf2023  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf2032, convolution_68, unsqueeze_4405, buf2033, buf2035, 72, 6272, grid=grid(72), stream=stream0)
        buf2034 = buf2026; del buf2026  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2033, buf2034, 18, 4, grid=grid(18), stream=stream0)
        buf2036 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2037 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2035, squeeze_205, buf2036, buf2037, 18, 4, grid=grid(18), stream=stream0)
        buf2038 = buf2030; del buf2030  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_84.run(buf2032, convolution_68, unsqueeze_4405, buf2036, squeeze_205, buf2034, primals_206, buf2038, 451584, grid=grid(451584), stream=stream0)
        del convolution_68
        del primals_206
        del squeeze_205
        del unsqueeze_4405
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2039 = aten.convolution_backward(buf2038, relu_63, primals_205, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2038
        del primals_205
        buf2040 = buf2039[0]
        buf2041 = buf2039[1]
        del buf2039
        buf2042 = buf2035; del buf2035  # reuse
        buf2044 = buf2033; del buf2033  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_63, buf2040, convolution_67, unsqueeze_4417, buf2042, buf2044, 72, 6272, grid=grid(72), stream=stream0)
        buf2043 = buf2036; del buf2036  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2042, buf2043, 18, 4, grid=grid(18), stream=stream0)
        buf2045 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2046 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2044, squeeze_202, buf2045, buf2046, 18, 4, grid=grid(18), stream=stream0)
        buf2047 = buf2040; del buf2040  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf2047, relu_63, convolution_67, unsqueeze_4417, buf2045, squeeze_202, buf2043, primals_203, 451584, grid=grid(451584), stream=stream0)
        del convolution_67
        del primals_203
        del relu_63
        del squeeze_202
        del unsqueeze_4417
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2048 = aten.convolution_backward(buf2047, relu_59, primals_202, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2047
        del primals_202
        buf2049 = buf2048[0]
        buf2050 = buf2048[1]
        del buf2048
        buf2051 = reinterpret_tensor(buf2044, (72, ), (1, ), 0); del buf2044  # reuse
        buf2052 = reinterpret_tensor(buf2042, (72, ), (1, ), 0); del buf2042  # reuse
        buf2058 = empty((72, ), device='cuda', dtype=torch.float32)
        buf2054 = empty((72, ), device='cuda', dtype=torch.float32)
        buf2060 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_109.run(relu_62, buf1902, buf1915, convolution_66, unsqueeze_4429, convolution_65, unsqueeze_4441, squeeze_199, squeeze_196, buf2051, buf2052, buf2058, buf2054, buf2060, 72, 1568, grid=grid(72), stream=stream0)
        buf2071 = buf1826; del buf1826  # reuse
        # Source Nodes: [], Original ATen: [aten.new_zeros]
        triton_poi_fused__unsafe_index_put_new_zeros_45.run(buf2071, 56448, grid=grid(56448), stream=stream0)
        buf2072 = buf1961; del buf1961  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_110.run(buf2072, relu_60, buf1974, 225792, grid=grid(225792), stream=stream0)
        del relu_60
        aten.index_put_(buf2071, [None, None, unsqueeze_259, convert_element_type_13], buf2072, True)
        del convert_element_type_13
        del unsqueeze_259
        buf2075 = buf1970; del buf1970  # reuse
        buf2076 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2077 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_46.run(buf2071, convolution_63, unsqueeze_4465, squeeze_190, buf2075, buf2076, buf2077, 36, 1568, grid=grid(36), stream=stream0)
        buf2074 = buf1819; del buf1819  # reuse
        buf2078 = buf2074; del buf2074  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_47.run(buf2078, buf2071, convolution_63, unsqueeze_4465, buf2076, squeeze_190, buf2075, primals_191, 56448, grid=grid(56448), stream=stream0)
        del buf2071
        del convolution_63
        del primals_191
        del squeeze_190
        del unsqueeze_4465
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2079 = aten.convolution_backward(buf2078, relu_58, primals_190, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2078
        del primals_190
        buf2080 = buf2079[0]
        buf2089 = buf1844; del buf1844  # reuse
        # Source Nodes: [], Original ATen: [aten.new_zeros]
        triton_poi_fused__unsafe_index_put_add_new_zeros_threshold_backward_35.run(buf2089, 28224, grid=grid(28224), stream=stream0)
        buf2090 = buf2032; del buf2032  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_111.run(buf2090, relu_59, buf2049, 451584, grid=grid(451584), stream=stream0)
        del relu_59
        aten.index_put_(buf2089, [None, None, unsqueeze_250, convert_element_type_9], buf2090, True)
        del convert_element_type_9
        del unsqueeze_250
        buf2093 = buf2045; del buf2045  # reuse
        buf2094 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2095 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_54.run(buf2089, convolution_61, unsqueeze_4489, squeeze_184, buf2093, buf2094, buf2095, 18, 1568, grid=grid(18), stream=stream0)
        buf2092 = buf1837; del buf1837  # reuse
        buf2096 = buf2092; del buf2092  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_55.run(buf2096, buf2089, convolution_61, unsqueeze_4489, buf2094, squeeze_184, buf2093, primals_185, 28224, grid=grid(28224), stream=stream0)
        del buf2089
        del convolution_61
        del primals_185
        del squeeze_184
        del unsqueeze_4489
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2097 = aten.convolution_backward(buf2096, relu_58, primals_184, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2096
        del primals_184
        buf2098 = buf2097[0]
        buf2053 = buf1913; del buf1913  # reuse
        buf2059 = buf1906; del buf1906  # reuse
        buf2110 = buf2080; del buf2080  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_112.run(buf2110, relu_62, buf1902, buf1915, convolution_66, unsqueeze_4429, buf2052, squeeze_199, buf2051, primals_200, convolution_65, unsqueeze_4441, buf2058, squeeze_196, primals_197, relu_58, buf2098, buf2053, buf2059, 112896, grid=grid(112896), stream=stream0)
        del buf1902
        del buf1915
        del buf2098
        del convolution_65
        del convolution_66
        del primals_197
        del primals_200
        del relu_58
        del relu_62
        del squeeze_196
        del squeeze_199
        del unsqueeze_4429
        del unsqueeze_4441
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf2055 = aten.convolution_backward(buf2053, relu_50, primals_199, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2053
        del primals_199
        buf2056 = buf2055[0]
        buf2057 = buf2055[1]
        del buf2055
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf2061 = aten.convolution_backward(buf2059, relu_61, primals_196, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_196
        buf2062 = buf2061[0]
        buf2063 = buf2061[1]
        del buf2061
        buf2064 = buf2094; del buf2094  # reuse
        buf2065 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2066 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_33.run(relu_61, buf2062, convolution_64, unsqueeze_4453, squeeze_193, buf2064, buf2065, buf2066, 18, 6272, grid=grid(18), stream=stream0)
        buf2067 = buf2062; del buf2062  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_34.run(buf2067, relu_61, convolution_64, unsqueeze_4453, buf2065, squeeze_193, buf2064, primals_194, 112896, grid=grid(112896), stream=stream0)
        del convolution_64
        del primals_194
        del relu_61
        del squeeze_193
        del unsqueeze_4453
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2068 = aten.convolution_backward(buf2067, relu_42, primals_193, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_193
        buf2069 = buf2068[0]
        buf2070 = buf2068[1]
        del buf2068
        buf2081 = buf2079[1]
        del buf2079
        buf2082 = buf2076; del buf2076  # reuse
        buf2083 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2084 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf2072, convolution_62, unsqueeze_4477, squeeze_187, buf2082, buf2083, buf2084, 36, 6272, grid=grid(36), stream=stream0)
        buf2085 = buf1974; del buf1974  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf2072, convolution_62, unsqueeze_4477, buf2083, squeeze_187, buf2082, primals_188, buf2085, 225792, grid=grid(225792), stream=stream0)
        del convolution_62
        del primals_188
        del squeeze_187
        del unsqueeze_4477
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2086 = aten.convolution_backward(buf2085, relu_42, primals_187, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_187
        buf2087 = buf2086[0]
        buf2088 = buf2086[1]
        del buf2086
        buf2099 = buf2097[1]
        del buf2097
        buf2100 = buf2067; del buf2067  # reuse
        # Source Nodes: [], Original ATen: [aten._unsafe_index_put, aten.new_zeros]
        triton_poi_fused__unsafe_index_put_new_zeros_56.run(buf2100, 112896, grid=grid(112896), stream=stream0)
        aten.index_put_(buf2100, [None, None, unsqueeze_136, convert_element_type_1], buf2090, True)
        buf2103 = buf2065; del buf2065  # reuse
        buf2104 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2105 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_57.run(buf2100, convolution_60, unsqueeze_4501, squeeze_181, buf2103, buf2104, buf2105, 18, 6272, grid=grid(18), stream=stream0)
        buf2102 = reinterpret_tensor(buf2059, (8, 18, 28, 28), (14112, 784, 28, 1), 0); del buf2059  # reuse
        buf2106 = buf2102; del buf2102  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_58.run(buf2106, buf2100, convolution_60, unsqueeze_4501, buf2104, squeeze_181, buf2103, primals_182, 112896, grid=grid(112896), stream=stream0)
        del buf2100
        del convolution_60
        del primals_182
        del squeeze_181
        del unsqueeze_4501
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2107 = aten.convolution_backward(buf2106, relu_50, primals_181, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_181
        buf2108 = buf2107[0]
        buf2109 = buf2107[1]
        del buf2107
        buf2111 = buf2058; del buf2058  # reuse
        buf2112 = buf2052; del buf2052  # reuse
        buf2113 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_68.run(buf2110, convolution_59, unsqueeze_4513, squeeze_178, buf2111, buf2112, buf2113, 72, 1568, grid=grid(72), stream=stream0)
        buf2114 = reinterpret_tensor(buf2106, (8, 72, 14, 14), (14112, 196, 14, 1), 0); del buf2106  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_69.run(buf2110, convolution_59, unsqueeze_4513, buf2112, squeeze_178, buf2111, primals_179, buf2114, 112896, grid=grid(112896), stream=stream0)
        del convolution_59
        del primals_179
        del squeeze_178
        del unsqueeze_4513
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2115 = aten.convolution_backward(buf2114, relu_57, primals_178, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2114
        del primals_178
        buf2116 = buf2115[0]
        buf2117 = buf2115[1]
        del buf2115
        buf2118 = buf2112; del buf2112  # reuse
        buf2119 = empty((72, ), device='cuda', dtype=torch.float32)
        buf2120 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_57, buf2116, convolution_58, unsqueeze_4525, squeeze_175, buf2118, buf2119, buf2120, 72, 1568, grid=grid(72), stream=stream0)
        buf2121 = buf2116; del buf2116  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf2121, relu_57, convolution_58, unsqueeze_4525, buf2119, squeeze_175, buf2118, primals_176, 112896, grid=grid(112896), stream=stream0)
        del convolution_58
        del primals_176
        del relu_57
        del squeeze_175
        del unsqueeze_4525
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2122 = aten.convolution_backward(buf2121, relu_56, primals_175, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_175
        buf2123 = buf2122[0]
        buf2124 = buf2122[1]
        del buf2122
        buf2125 = buf2119; del buf2119  # reuse
        buf2126 = empty((72, ), device='cuda', dtype=torch.float32)
        buf2128 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_72.run(relu_56, buf2110, buf2123, convolution_57, unsqueeze_4537, squeeze_172, buf2125, buf2126, buf2128, 72, 1568, grid=grid(72), stream=stream0)
        buf2127 = buf2121; del buf2121  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_73.run(relu_56, buf2110, buf2123, convolution_57, unsqueeze_4537, buf2126, squeeze_172, buf2125, primals_173, buf2127, 112896, grid=grid(112896), stream=stream0)
        del convolution_57
        del primals_173
        del squeeze_172
        del unsqueeze_4537
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf2129 = aten.convolution_backward(buf2127, relu_55, primals_172, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2127
        del primals_172
        buf2130 = buf2129[0]
        buf2131 = buf2129[1]
        del buf2129
        buf2132 = buf2126; del buf2126  # reuse
        buf2133 = empty((72, ), device='cuda', dtype=torch.float32)
        buf2134 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_55, buf2130, convolution_56, unsqueeze_4549, squeeze_169, buf2132, buf2133, buf2134, 72, 1568, grid=grid(72), stream=stream0)
        buf2135 = buf2130; del buf2130  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf2135, relu_55, convolution_56, unsqueeze_4549, buf2133, squeeze_169, buf2132, primals_170, 112896, grid=grid(112896), stream=stream0)
        del convolution_56
        del primals_170
        del relu_55
        del squeeze_169
        del unsqueeze_4549
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2136 = aten.convolution_backward(buf2135, relu_54, primals_169, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2135
        del primals_169
        buf2137 = buf2136[0]
        buf2138 = buf2136[1]
        del buf2136
        buf2139 = buf2110; del buf2110  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_74.run(buf2139, relu_54, relu_56, buf2123, buf2137, 112896, grid=grid(112896), stream=stream0)
        del buf2123
        del relu_54
        del relu_56
        buf2140 = buf2133; del buf2133  # reuse
        buf2141 = empty((72, ), device='cuda', dtype=torch.float32)
        buf2142 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_68.run(buf2139, convolution_55, unsqueeze_4561, squeeze_166, buf2140, buf2141, buf2142, 72, 1568, grid=grid(72), stream=stream0)
        buf2143 = buf2137; del buf2137  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_69.run(buf2139, convolution_55, unsqueeze_4561, buf2141, squeeze_166, buf2140, primals_167, buf2143, 112896, grid=grid(112896), stream=stream0)
        del convolution_55
        del primals_167
        del squeeze_166
        del unsqueeze_4561
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2144 = aten.convolution_backward(buf2143, relu_53, primals_166, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2143
        del primals_166
        buf2145 = buf2144[0]
        buf2146 = buf2144[1]
        del buf2144
        buf2147 = buf2141; del buf2141  # reuse
        buf2148 = empty((72, ), device='cuda', dtype=torch.float32)
        buf2149 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_53, buf2145, convolution_54, unsqueeze_4573, squeeze_163, buf2147, buf2148, buf2149, 72, 1568, grid=grid(72), stream=stream0)
        buf2150 = buf2145; del buf2145  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf2150, relu_53, convolution_54, unsqueeze_4573, buf2148, squeeze_163, buf2147, primals_164, 112896, grid=grid(112896), stream=stream0)
        del convolution_54
        del primals_164
        del relu_53
        del squeeze_163
        del unsqueeze_4573
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2151 = aten.convolution_backward(buf2150, relu_52, primals_163, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_163
        buf2152 = buf2151[0]
        buf2153 = buf2151[1]
        del buf2151
        buf2154 = buf2148; del buf2148  # reuse
        buf2155 = empty((72, ), device='cuda', dtype=torch.float32)
        buf2157 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_72.run(relu_52, buf2139, buf2152, convolution_53, unsqueeze_4585, squeeze_160, buf2154, buf2155, buf2157, 72, 1568, grid=grid(72), stream=stream0)
        buf2156 = buf2150; del buf2150  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_73.run(relu_52, buf2139, buf2152, convolution_53, unsqueeze_4585, buf2155, squeeze_160, buf2154, primals_161, buf2156, 112896, grid=grid(112896), stream=stream0)
        del convolution_53
        del primals_161
        del squeeze_160
        del unsqueeze_4585
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf2158 = aten.convolution_backward(buf2156, relu_51, primals_160, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2156
        del primals_160
        buf2159 = buf2158[0]
        buf2160 = buf2158[1]
        del buf2158
        buf2161 = buf2155; del buf2155  # reuse
        buf2162 = empty((72, ), device='cuda', dtype=torch.float32)
        buf2163 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_70.run(relu_51, buf2159, convolution_52, unsqueeze_4597, squeeze_157, buf2161, buf2162, buf2163, 72, 1568, grid=grid(72), stream=stream0)
        buf2164 = buf2159; del buf2159  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_71.run(buf2164, relu_51, convolution_52, unsqueeze_4597, buf2162, squeeze_157, buf2161, primals_158, 112896, grid=grid(112896), stream=stream0)
        del convolution_52
        del primals_158
        del relu_51
        del squeeze_157
        del unsqueeze_4597
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2165 = aten.convolution_backward(buf2164, relu_34, primals_157, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2164
        del primals_157
        buf2166 = buf2165[0]
        buf2167 = buf2165[1]
        del buf2165
        buf2168 = buf2083; del buf2083  # reuse
        buf2169 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2171 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_103.run(relu_50, buf2056, buf2072, buf2108, convolution_51, unsqueeze_4609, squeeze_154, buf2168, buf2169, buf2171, 36, 6272, grid=grid(36), stream=stream0)
        buf2170 = buf2085; del buf2085  # reuse
        buf2172 = buf2170; del buf2170  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_104.run(buf2172, relu_50, buf2056, buf2072, buf2108, convolution_51, unsqueeze_4609, buf2169, squeeze_154, buf2168, primals_155, 225792, grid=grid(225792), stream=stream0)
        del convolution_51
        del primals_155
        del squeeze_154
        del unsqueeze_4609
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2173 = aten.convolution_backward(buf2172, relu_49, primals_154, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2172
        del primals_154
        buf2174 = buf2173[0]
        buf2175 = buf2173[1]
        del buf2173
        buf2176 = buf2169; del buf2169  # reuse
        buf2177 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2178 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_49, buf2174, convolution_50, unsqueeze_4621, squeeze_151, buf2176, buf2177, buf2178, 36, 6272, grid=grid(36), stream=stream0)
        buf2179 = buf2174; del buf2174  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf2179, relu_49, convolution_50, unsqueeze_4621, buf2177, squeeze_151, buf2176, primals_152, 225792, grid=grid(225792), stream=stream0)
        del convolution_50
        del primals_152
        del relu_49
        del squeeze_151
        del unsqueeze_4621
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2180 = aten.convolution_backward(buf2179, relu_48, primals_151, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2179
        del primals_151
        buf2181 = buf2180[0]
        buf2182 = buf2180[1]
        del buf2180
        buf2183 = buf2056; del buf2056  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_105.run(buf2183, relu_48, relu_50, buf2072, buf2108, buf2181, 225792, grid=grid(225792), stream=stream0)
        del buf2072
        del buf2108
        del relu_48
        del relu_50
        buf2184 = buf2177; del buf2177  # reuse
        buf2185 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2186 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf2183, convolution_49, unsqueeze_4633, squeeze_148, buf2184, buf2185, buf2186, 36, 6272, grid=grid(36), stream=stream0)
        buf2187 = buf2181; del buf2181  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf2183, convolution_49, unsqueeze_4633, buf2185, squeeze_148, buf2184, primals_149, buf2187, 225792, grid=grid(225792), stream=stream0)
        del convolution_49
        del primals_149
        del squeeze_148
        del unsqueeze_4633
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2188 = aten.convolution_backward(buf2187, relu_47, primals_148, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2187
        del primals_148
        buf2189 = buf2188[0]
        buf2190 = buf2188[1]
        del buf2188
        buf2191 = buf2185; del buf2185  # reuse
        buf2192 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2193 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_47, buf2189, convolution_48, unsqueeze_4645, squeeze_145, buf2191, buf2192, buf2193, 36, 6272, grid=grid(36), stream=stream0)
        buf2194 = buf2189; del buf2189  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf2194, relu_47, convolution_48, unsqueeze_4645, buf2192, squeeze_145, buf2191, primals_146, 225792, grid=grid(225792), stream=stream0)
        del convolution_48
        del primals_146
        del relu_47
        del squeeze_145
        del unsqueeze_4645
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2195 = aten.convolution_backward(buf2194, relu_46, primals_145, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_145
        buf2196 = buf2195[0]
        buf2197 = buf2195[1]
        del buf2195
        buf2198 = buf2192; del buf2192  # reuse
        buf2199 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2201 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_78.run(relu_46, buf2183, buf2196, convolution_47, unsqueeze_4657, squeeze_142, buf2198, buf2199, buf2201, 36, 6272, grid=grid(36), stream=stream0)
        buf2200 = buf2194; del buf2194  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_79.run(relu_46, buf2183, buf2196, convolution_47, unsqueeze_4657, buf2199, squeeze_142, buf2198, primals_143, buf2200, 225792, grid=grid(225792), stream=stream0)
        del convolution_47
        del primals_143
        del squeeze_142
        del unsqueeze_4657
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf2202 = aten.convolution_backward(buf2200, relu_45, primals_142, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2200
        del primals_142
        buf2203 = buf2202[0]
        buf2204 = buf2202[1]
        del buf2202
        buf2205 = buf2199; del buf2199  # reuse
        buf2206 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2207 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_45, buf2203, convolution_46, unsqueeze_4669, squeeze_139, buf2205, buf2206, buf2207, 36, 6272, grid=grid(36), stream=stream0)
        buf2208 = buf2203; del buf2203  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf2208, relu_45, convolution_46, unsqueeze_4669, buf2206, squeeze_139, buf2205, primals_140, 225792, grid=grid(225792), stream=stream0)
        del convolution_46
        del primals_140
        del relu_45
        del squeeze_139
        del unsqueeze_4669
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2209 = aten.convolution_backward(buf2208, relu_44, primals_139, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2208
        del primals_139
        buf2210 = buf2209[0]
        buf2211 = buf2209[1]
        del buf2209
        buf2212 = buf2183; del buf2183  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_80.run(buf2212, relu_44, relu_46, buf2196, buf2210, 225792, grid=grid(225792), stream=stream0)
        del buf2196
        del relu_44
        del relu_46
        buf2213 = buf2206; del buf2206  # reuse
        buf2214 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2215 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf2212, convolution_45, unsqueeze_4681, squeeze_136, buf2213, buf2214, buf2215, 36, 6272, grid=grid(36), stream=stream0)
        buf2216 = buf2210; del buf2210  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf2212, convolution_45, unsqueeze_4681, buf2214, squeeze_136, buf2213, primals_137, buf2216, 225792, grid=grid(225792), stream=stream0)
        del convolution_45
        del primals_137
        del squeeze_136
        del unsqueeze_4681
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2217 = aten.convolution_backward(buf2216, relu_43, primals_136, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2216
        del primals_136
        buf2218 = buf2217[0]
        buf2219 = buf2217[1]
        del buf2217
        buf2220 = buf2214; del buf2214  # reuse
        buf2221 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2222 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_43, buf2218, convolution_44, unsqueeze_4693, squeeze_133, buf2220, buf2221, buf2222, 36, 6272, grid=grid(36), stream=stream0)
        buf2223 = buf2218; del buf2218  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf2223, relu_43, convolution_44, unsqueeze_4693, buf2221, squeeze_133, buf2220, primals_134, 225792, grid=grid(225792), stream=stream0)
        del convolution_44
        del primals_134
        del relu_43
        del squeeze_133
        del unsqueeze_4693
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2224 = aten.convolution_backward(buf2223, relu_33, primals_133, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_133
        buf2225 = buf2224[0]
        buf2226 = buf2224[1]
        del buf2224
        buf2227 = reinterpret_tensor(buf2162, (18, 4), (1, 18), 0); del buf2162  # reuse
        buf2229 = empty_strided((18, 4), (1, 18), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_106.run(relu_42, buf2069, buf2087, buf2090, convolution_43, unsqueeze_4705, buf2227, buf2229, 72, 6272, grid=grid(72), stream=stream0)
        buf2228 = buf2104; del buf2104  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2227, buf2228, 18, 4, grid=grid(18), stream=stream0)
        buf2230 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2232 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2229, squeeze_130, buf2230, buf2232, 18, 4, grid=grid(18), stream=stream0)
        buf2231 = buf2049; del buf2049  # reuse
        buf2233 = buf2231; del buf2231  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_107.run(buf2233, relu_42, buf2069, buf2087, buf2090, convolution_43, unsqueeze_4705, buf2230, squeeze_130, buf2228, primals_131, 451584, grid=grid(451584), stream=stream0)
        del convolution_43
        del primals_131
        del squeeze_130
        del unsqueeze_4705
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2234 = aten.convolution_backward(buf2233, relu_41, primals_130, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2233
        del primals_130
        buf2235 = buf2234[0]
        buf2236 = buf2234[1]
        del buf2234
        buf2237 = buf2229; del buf2229  # reuse
        buf2239 = buf2227; del buf2227  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_41, buf2235, convolution_42, unsqueeze_4717, buf2237, buf2239, 72, 6272, grid=grid(72), stream=stream0)
        buf2238 = buf2230; del buf2230  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2237, buf2238, 18, 4, grid=grid(18), stream=stream0)
        buf2240 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2241 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2239, squeeze_127, buf2240, buf2241, 18, 4, grid=grid(18), stream=stream0)
        buf2242 = buf2235; del buf2235  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf2242, relu_41, convolution_42, unsqueeze_4717, buf2240, squeeze_127, buf2238, primals_128, 451584, grid=grid(451584), stream=stream0)
        del convolution_42
        del primals_128
        del relu_41
        del squeeze_127
        del unsqueeze_4717
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2243 = aten.convolution_backward(buf2242, relu_40, primals_127, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2242
        del primals_127
        buf2244 = buf2243[0]
        buf2245 = buf2243[1]
        del buf2243
        buf2246 = buf2069; del buf2069  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_108.run(buf2246, relu_40, relu_42, buf2087, buf2090, buf2244, 451584, grid=grid(451584), stream=stream0)
        del buf2087
        del buf2090
        del relu_40
        del relu_42
        buf2247 = buf2239; del buf2239  # reuse
        buf2249 = buf2237; del buf2237  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf2246, convolution_41, unsqueeze_4729, buf2247, buf2249, 72, 6272, grid=grid(72), stream=stream0)
        buf2248 = buf2240; del buf2240  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2247, buf2248, 18, 4, grid=grid(18), stream=stream0)
        buf2250 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2251 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2249, squeeze_124, buf2250, buf2251, 18, 4, grid=grid(18), stream=stream0)
        buf2252 = buf2244; del buf2244  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_84.run(buf2246, convolution_41, unsqueeze_4729, buf2250, squeeze_124, buf2248, primals_125, buf2252, 451584, grid=grid(451584), stream=stream0)
        del convolution_41
        del primals_125
        del squeeze_124
        del unsqueeze_4729
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2253 = aten.convolution_backward(buf2252, relu_39, primals_124, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2252
        del primals_124
        buf2254 = buf2253[0]
        buf2255 = buf2253[1]
        del buf2253
        buf2256 = buf2249; del buf2249  # reuse
        buf2258 = buf2247; del buf2247  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_39, buf2254, convolution_40, unsqueeze_4741, buf2256, buf2258, 72, 6272, grid=grid(72), stream=stream0)
        buf2257 = buf2250; del buf2250  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2256, buf2257, 18, 4, grid=grid(18), stream=stream0)
        buf2259 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2260 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2258, squeeze_121, buf2259, buf2260, 18, 4, grid=grid(18), stream=stream0)
        buf2261 = buf2254; del buf2254  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf2261, relu_39, convolution_40, unsqueeze_4741, buf2259, squeeze_121, buf2257, primals_122, 451584, grid=grid(451584), stream=stream0)
        del convolution_40
        del primals_122
        del relu_39
        del squeeze_121
        del unsqueeze_4741
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2262 = aten.convolution_backward(buf2261, relu_38, primals_121, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_121
        buf2263 = buf2262[0]
        buf2264 = buf2262[1]
        del buf2262
        buf2265 = buf2258; del buf2258  # reuse
        buf2267 = buf2256; del buf2256  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_87.run(relu_38, buf2246, buf2263, convolution_39, unsqueeze_4753, buf2265, buf2267, 72, 6272, grid=grid(72), stream=stream0)
        buf2266 = buf2259; del buf2259  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2265, buf2266, 18, 4, grid=grid(18), stream=stream0)
        buf2268 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2270 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2267, squeeze_118, buf2268, buf2270, 18, 4, grid=grid(18), stream=stream0)
        buf2269 = buf2261; del buf2261  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_88.run(relu_38, buf2246, buf2263, convolution_39, unsqueeze_4753, buf2268, squeeze_118, buf2266, primals_119, buf2269, 451584, grid=grid(451584), stream=stream0)
        del convolution_39
        del primals_119
        del squeeze_118
        del unsqueeze_4753
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf2271 = aten.convolution_backward(buf2269, relu_37, primals_118, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2269
        del primals_118
        buf2272 = buf2271[0]
        buf2273 = buf2271[1]
        del buf2271
        buf2274 = buf2267; del buf2267  # reuse
        buf2276 = buf2265; del buf2265  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_37, buf2272, convolution_38, unsqueeze_4765, buf2274, buf2276, 72, 6272, grid=grid(72), stream=stream0)
        buf2275 = buf2268; del buf2268  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2274, buf2275, 18, 4, grid=grid(18), stream=stream0)
        buf2277 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2278 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2276, squeeze_115, buf2277, buf2278, 18, 4, grid=grid(18), stream=stream0)
        buf2279 = buf2272; del buf2272  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf2279, relu_37, convolution_38, unsqueeze_4765, buf2277, squeeze_115, buf2275, primals_116, 451584, grid=grid(451584), stream=stream0)
        del convolution_38
        del primals_116
        del relu_37
        del squeeze_115
        del unsqueeze_4765
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2280 = aten.convolution_backward(buf2279, relu_36, primals_115, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2279
        del primals_115
        buf2281 = buf2280[0]
        buf2282 = buf2280[1]
        del buf2280
        buf2283 = buf2246; del buf2246  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_89.run(buf2283, relu_36, relu_38, buf2263, buf2281, 451584, grid=grid(451584), stream=stream0)
        del buf2263
        del relu_36
        del relu_38
        buf2284 = buf2276; del buf2276  # reuse
        buf2286 = buf2274; del buf2274  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf2283, convolution_37, unsqueeze_4777, buf2284, buf2286, 72, 6272, grid=grid(72), stream=stream0)
        buf2285 = buf2277; del buf2277  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2284, buf2285, 18, 4, grid=grid(18), stream=stream0)
        buf2287 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2288 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2286, squeeze_112, buf2287, buf2288, 18, 4, grid=grid(18), stream=stream0)
        buf2289 = buf2281; del buf2281  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_84.run(buf2283, convolution_37, unsqueeze_4777, buf2287, squeeze_112, buf2285, primals_113, buf2289, 451584, grid=grid(451584), stream=stream0)
        del convolution_37
        del primals_113
        del squeeze_112
        del unsqueeze_4777
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2290 = aten.convolution_backward(buf2289, relu_35, primals_112, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2289
        del primals_112
        buf2291 = buf2290[0]
        buf2292 = buf2290[1]
        del buf2290
        buf2293 = buf2286; del buf2286  # reuse
        buf2295 = buf2284; del buf2284  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_35, buf2291, convolution_36, unsqueeze_4789, buf2293, buf2295, 72, 6272, grid=grid(72), stream=stream0)
        buf2294 = buf2287; del buf2287  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2293, buf2294, 18, 4, grid=grid(18), stream=stream0)
        buf2296 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2297 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2295, squeeze_109, buf2296, buf2297, 18, 4, grid=grid(18), stream=stream0)
        buf2298 = buf2291; del buf2291  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf2298, relu_35, convolution_36, unsqueeze_4789, buf2296, squeeze_109, buf2294, primals_110, 451584, grid=grid(451584), stream=stream0)
        del convolution_36
        del primals_110
        del relu_35
        del squeeze_109
        del unsqueeze_4789
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2299 = aten.convolution_backward(buf2298, relu_32, primals_109, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_109
        buf2300 = buf2299[0]
        buf2301 = buf2299[1]
        del buf2299
        buf2302 = buf2139; del buf2139  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_74.run(buf2302, relu_34, relu_52, buf2152, buf2166, 112896, grid=grid(112896), stream=stream0)
        del buf2152
        del relu_34
        del relu_52
        buf2303 = reinterpret_tensor(buf2295, (72, ), (1, ), 0); del buf2295  # reuse
        buf2304 = reinterpret_tensor(buf2293, (72, ), (1, ), 0); del buf2293  # reuse
        buf2305 = empty((72, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_68.run(buf2302, convolution_35, unsqueeze_4801, squeeze_106, buf2303, buf2304, buf2305, 72, 1568, grid=grid(72), stream=stream0)
        buf2306 = buf2302; del buf2302  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_113.run(buf2306, convolution_35, unsqueeze_4801, buf2304, squeeze_106, buf2303, primals_107, 112896, grid=grid(112896), stream=stream0)
        del convolution_35
        del primals_107
        del squeeze_106
        del unsqueeze_4801
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2307 = aten.convolution_backward(buf2306, relu_33, primals_106, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_106
        buf2308 = buf2307[0]
        buf2309 = buf2307[1]
        del buf2307
        buf2310 = buf2221; del buf2221  # reuse
        buf2311 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2313 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_103.run(relu_33, buf2212, buf2225, buf2308, convolution_34, unsqueeze_4813, squeeze_103, buf2310, buf2311, buf2313, 36, 6272, grid=grid(36), stream=stream0)
        buf2318 = reinterpret_tensor(buf2306, (8, 18, 28, 28), (14112, 784, 28, 1), 0); del buf2306  # reuse
        # Source Nodes: [], Original ATen: [aten.new_zeros]
        triton_poi_fused__unsafe_index_put_new_zeros_56.run(buf2318, 112896, grid=grid(112896), stream=stream0)
        buf2319 = buf2298; del buf2298  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_114.run(relu_32, buf2283, buf2300, buf2319, 451584, grid=grid(451584), stream=stream0)
        aten.index_put_(buf2318, [None, None, unsqueeze_136, convert_element_type_1], buf2319, True)
        del buf2319
        del convert_element_type_1
        del unsqueeze_136
        buf2322 = buf2296; del buf2296  # reuse
        buf2323 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2324 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_57.run(buf2318, convolution_33, unsqueeze_4825, squeeze_100, buf2322, buf2323, buf2324, 18, 6272, grid=grid(18), stream=stream0)
        buf2321 = reinterpret_tensor(buf2166, (8, 18, 28, 28), (14112, 784, 28, 1), 0); del buf2166  # reuse
        buf2325 = buf2321; del buf2321  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_58.run(buf2325, buf2318, convolution_33, unsqueeze_4825, buf2323, squeeze_100, buf2322, primals_101, 112896, grid=grid(112896), stream=stream0)
        del buf2318
        del convolution_33
        del primals_101
        del squeeze_100
        del unsqueeze_4825
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2326 = aten.convolution_backward(buf2325, relu_31, primals_100, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2325
        del primals_100
        buf2327 = buf2326[0]
        buf2312 = buf2223; del buf2223  # reuse
        buf2329 = buf2327; del buf2327  # reuse
        buf2314 = buf2312; del buf2312  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_convolution_backward_native_batch_norm_backward_threshold_backward_115.run(buf2329, buf2314, relu_33, buf2212, buf2225, buf2308, convolution_34, unsqueeze_4813, buf2311, squeeze_103, buf2310, relu_31, primals_104, 225792, grid=grid(225792), stream=stream0)
        del buf2212
        del buf2225
        del buf2308
        del convolution_34
        del primals_104
        del relu_31
        del relu_33
        del squeeze_103
        del unsqueeze_4813
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2315 = aten.convolution_backward(buf2314, relu_23, primals_103, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_103
        buf2316 = buf2315[0]
        buf2317 = buf2315[1]
        del buf2315
        buf2328 = buf2326[1]
        del buf2326
        buf2330 = buf2311; del buf2311  # reuse
        buf2331 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2332 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf2329, convolution_32, unsqueeze_4837, squeeze_97, buf2330, buf2331, buf2332, 36, 6272, grid=grid(36), stream=stream0)
        buf2333 = buf2314; del buf2314  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf2329, convolution_32, unsqueeze_4837, buf2331, squeeze_97, buf2330, primals_98, buf2333, 225792, grid=grid(225792), stream=stream0)
        del convolution_32
        del primals_98
        del squeeze_97
        del unsqueeze_4837
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2334 = aten.convolution_backward(buf2333, relu_30, primals_97, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2333
        del primals_97
        buf2335 = buf2334[0]
        buf2336 = buf2334[1]
        del buf2334
        buf2337 = buf2331; del buf2331  # reuse
        buf2338 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2339 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_30, buf2335, convolution_31, unsqueeze_4849, squeeze_94, buf2337, buf2338, buf2339, 36, 6272, grid=grid(36), stream=stream0)
        buf2340 = buf2335; del buf2335  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf2340, relu_30, convolution_31, unsqueeze_4849, buf2338, squeeze_94, buf2337, primals_95, 225792, grid=grid(225792), stream=stream0)
        del convolution_31
        del primals_95
        del relu_30
        del squeeze_94
        del unsqueeze_4849
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2341 = aten.convolution_backward(buf2340, relu_29, primals_94, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_94
        buf2342 = buf2341[0]
        buf2343 = buf2341[1]
        del buf2341
        buf2344 = buf2338; del buf2338  # reuse
        buf2345 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2347 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_78.run(relu_29, buf2329, buf2342, convolution_30, unsqueeze_4861, squeeze_91, buf2344, buf2345, buf2347, 36, 6272, grid=grid(36), stream=stream0)
        buf2346 = buf2340; del buf2340  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_79.run(relu_29, buf2329, buf2342, convolution_30, unsqueeze_4861, buf2345, squeeze_91, buf2344, primals_92, buf2346, 225792, grid=grid(225792), stream=stream0)
        del convolution_30
        del primals_92
        del squeeze_91
        del unsqueeze_4861
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf2348 = aten.convolution_backward(buf2346, relu_28, primals_91, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2346
        del primals_91
        buf2349 = buf2348[0]
        buf2350 = buf2348[1]
        del buf2348
        buf2351 = buf2345; del buf2345  # reuse
        buf2352 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2353 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_28, buf2349, convolution_29, unsqueeze_4873, squeeze_88, buf2351, buf2352, buf2353, 36, 6272, grid=grid(36), stream=stream0)
        buf2354 = buf2349; del buf2349  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf2354, relu_28, convolution_29, unsqueeze_4873, buf2352, squeeze_88, buf2351, primals_89, 225792, grid=grid(225792), stream=stream0)
        del convolution_29
        del primals_89
        del relu_28
        del squeeze_88
        del unsqueeze_4873
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2355 = aten.convolution_backward(buf2354, relu_27, primals_88, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2354
        del primals_88
        buf2356 = buf2355[0]
        buf2357 = buf2355[1]
        del buf2355
        buf2358 = buf2329; del buf2329  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_80.run(buf2358, relu_27, relu_29, buf2342, buf2356, 225792, grid=grid(225792), stream=stream0)
        del buf2342
        del relu_27
        del relu_29
        buf2359 = buf2352; del buf2352  # reuse
        buf2360 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2361 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf2358, convolution_28, unsqueeze_4885, squeeze_85, buf2359, buf2360, buf2361, 36, 6272, grid=grid(36), stream=stream0)
        buf2362 = buf2356; del buf2356  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_49.run(buf2358, convolution_28, unsqueeze_4885, buf2360, squeeze_85, buf2359, primals_86, buf2362, 225792, grid=grid(225792), stream=stream0)
        del convolution_28
        del primals_86
        del squeeze_85
        del unsqueeze_4885
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2363 = aten.convolution_backward(buf2362, relu_26, primals_85, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2362
        del primals_85
        buf2364 = buf2363[0]
        buf2365 = buf2363[1]
        del buf2363
        buf2366 = buf2360; del buf2360  # reuse
        buf2367 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2368 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_26, buf2364, convolution_27, unsqueeze_4897, squeeze_82, buf2366, buf2367, buf2368, 36, 6272, grid=grid(36), stream=stream0)
        buf2369 = buf2364; del buf2364  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf2369, relu_26, convolution_27, unsqueeze_4897, buf2367, squeeze_82, buf2366, primals_83, 225792, grid=grid(225792), stream=stream0)
        del convolution_27
        del primals_83
        del relu_26
        del squeeze_82
        del unsqueeze_4897
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2370 = aten.convolution_backward(buf2369, relu_25, primals_82, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_82
        buf2371 = buf2370[0]
        buf2372 = buf2370[1]
        del buf2370
        buf2373 = buf2367; del buf2367  # reuse
        buf2374 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2376 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_78.run(relu_25, buf2358, buf2371, convolution_26, unsqueeze_4909, squeeze_79, buf2373, buf2374, buf2376, 36, 6272, grid=grid(36), stream=stream0)
        buf2375 = buf2369; del buf2369  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_79.run(relu_25, buf2358, buf2371, convolution_26, unsqueeze_4909, buf2374, squeeze_79, buf2373, primals_80, buf2375, 225792, grid=grid(225792), stream=stream0)
        del convolution_26
        del primals_80
        del squeeze_79
        del unsqueeze_4909
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf2377 = aten.convolution_backward(buf2375, relu_24, primals_79, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2375
        del primals_79
        buf2378 = buf2377[0]
        buf2379 = buf2377[1]
        del buf2377
        buf2380 = buf2374; del buf2374  # reuse
        buf2381 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2382 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_76.run(relu_24, buf2378, convolution_25, unsqueeze_4921, squeeze_76, buf2380, buf2381, buf2382, 36, 6272, grid=grid(36), stream=stream0)
        buf2383 = buf2378; del buf2378  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_77.run(buf2383, relu_24, convolution_25, unsqueeze_4921, buf2381, squeeze_76, buf2380, primals_77, 225792, grid=grid(225792), stream=stream0)
        del convolution_25
        del primals_77
        del relu_24
        del squeeze_76
        del unsqueeze_4921
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2384 = aten.convolution_backward(buf2383, relu_15, primals_76, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2383
        del primals_76
        buf2385 = buf2384[0]
        buf2386 = buf2384[1]
        del buf2384
        buf2387 = buf2283; del buf2283  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_116.run(buf2387, relu_23, buf2316, relu_32, buf2300, 451584, grid=grid(451584), stream=stream0)
        del buf2300
        del relu_23
        del relu_32
        buf2388 = reinterpret_tensor(buf2304, (18, 4), (1, 18), 0); del buf2304  # reuse
        buf2390 = empty_strided((18, 4), (1, 18), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf2387, convolution_24, unsqueeze_4933, buf2388, buf2390, 72, 6272, grid=grid(72), stream=stream0)
        buf2389 = buf2323; del buf2323  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2388, buf2389, 18, 4, grid=grid(18), stream=stream0)
        buf2391 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2392 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2390, squeeze_73, buf2391, buf2392, 18, 4, grid=grid(18), stream=stream0)
        buf2393 = buf2316; del buf2316  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_84.run(buf2387, convolution_24, unsqueeze_4933, buf2391, squeeze_73, buf2389, primals_74, buf2393, 451584, grid=grid(451584), stream=stream0)
        del convolution_24
        del primals_74
        del squeeze_73
        del unsqueeze_4933
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2394 = aten.convolution_backward(buf2393, relu_22, primals_73, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2393
        del primals_73
        buf2395 = buf2394[0]
        buf2396 = buf2394[1]
        del buf2394
        buf2397 = buf2390; del buf2390  # reuse
        buf2399 = buf2388; del buf2388  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_22, buf2395, convolution_23, unsqueeze_4945, buf2397, buf2399, 72, 6272, grid=grid(72), stream=stream0)
        buf2398 = buf2391; del buf2391  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2397, buf2398, 18, 4, grid=grid(18), stream=stream0)
        buf2400 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2401 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2399, squeeze_70, buf2400, buf2401, 18, 4, grid=grid(18), stream=stream0)
        buf2402 = buf2395; del buf2395  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf2402, relu_22, convolution_23, unsqueeze_4945, buf2400, squeeze_70, buf2398, primals_71, 451584, grid=grid(451584), stream=stream0)
        del convolution_23
        del primals_71
        del relu_22
        del squeeze_70
        del unsqueeze_4945
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2403 = aten.convolution_backward(buf2402, relu_21, primals_70, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_70
        buf2404 = buf2403[0]
        buf2405 = buf2403[1]
        del buf2403
        buf2406 = buf2399; del buf2399  # reuse
        buf2408 = buf2397; del buf2397  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_87.run(relu_21, buf2387, buf2404, convolution_22, unsqueeze_4957, buf2406, buf2408, 72, 6272, grid=grid(72), stream=stream0)
        buf2407 = buf2400; del buf2400  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2406, buf2407, 18, 4, grid=grid(18), stream=stream0)
        buf2409 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2411 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2408, squeeze_67, buf2409, buf2411, 18, 4, grid=grid(18), stream=stream0)
        buf2410 = buf2402; del buf2402  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_88.run(relu_21, buf2387, buf2404, convolution_22, unsqueeze_4957, buf2409, squeeze_67, buf2407, primals_68, buf2410, 451584, grid=grid(451584), stream=stream0)
        del convolution_22
        del primals_68
        del squeeze_67
        del unsqueeze_4957
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf2412 = aten.convolution_backward(buf2410, relu_20, primals_67, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2410
        del primals_67
        buf2413 = buf2412[0]
        buf2414 = buf2412[1]
        del buf2412
        buf2415 = buf2408; del buf2408  # reuse
        buf2417 = buf2406; del buf2406  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_20, buf2413, convolution_21, unsqueeze_4969, buf2415, buf2417, 72, 6272, grid=grid(72), stream=stream0)
        buf2416 = buf2409; del buf2409  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2415, buf2416, 18, 4, grid=grid(18), stream=stream0)
        buf2418 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2419 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2417, squeeze_64, buf2418, buf2419, 18, 4, grid=grid(18), stream=stream0)
        buf2420 = buf2413; del buf2413  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf2420, relu_20, convolution_21, unsqueeze_4969, buf2418, squeeze_64, buf2416, primals_65, 451584, grid=grid(451584), stream=stream0)
        del convolution_21
        del primals_65
        del relu_20
        del squeeze_64
        del unsqueeze_4969
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2421 = aten.convolution_backward(buf2420, relu_19, primals_64, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2420
        del primals_64
        buf2422 = buf2421[0]
        buf2423 = buf2421[1]
        del buf2421
        buf2424 = buf2387; del buf2387  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_89.run(buf2424, relu_19, relu_21, buf2404, buf2422, 451584, grid=grid(451584), stream=stream0)
        del buf2404
        del relu_19
        del relu_21
        buf2425 = buf2417; del buf2417  # reuse
        buf2427 = buf2415; del buf2415  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf2424, convolution_20, unsqueeze_4981, buf2425, buf2427, 72, 6272, grid=grid(72), stream=stream0)
        buf2426 = buf2418; del buf2418  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2425, buf2426, 18, 4, grid=grid(18), stream=stream0)
        buf2428 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2429 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2427, squeeze_61, buf2428, buf2429, 18, 4, grid=grid(18), stream=stream0)
        buf2430 = buf2422; del buf2422  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_84.run(buf2424, convolution_20, unsqueeze_4981, buf2428, squeeze_61, buf2426, primals_62, buf2430, 451584, grid=grid(451584), stream=stream0)
        del convolution_20
        del primals_62
        del squeeze_61
        del unsqueeze_4981
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2431 = aten.convolution_backward(buf2430, relu_18, primals_61, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2430
        del primals_61
        buf2432 = buf2431[0]
        buf2433 = buf2431[1]
        del buf2431
        buf2434 = buf2427; del buf2427  # reuse
        buf2436 = buf2425; del buf2425  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_18, buf2432, convolution_19, unsqueeze_4993, buf2434, buf2436, 72, 6272, grid=grid(72), stream=stream0)
        buf2435 = buf2428; del buf2428  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2434, buf2435, 18, 4, grid=grid(18), stream=stream0)
        buf2437 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2438 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2436, squeeze_58, buf2437, buf2438, 18, 4, grid=grid(18), stream=stream0)
        buf2439 = buf2432; del buf2432  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf2439, relu_18, convolution_19, unsqueeze_4993, buf2437, squeeze_58, buf2435, primals_59, 451584, grid=grid(451584), stream=stream0)
        del convolution_19
        del primals_59
        del relu_18
        del squeeze_58
        del unsqueeze_4993
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2440 = aten.convolution_backward(buf2439, relu_17, primals_58, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_58
        buf2441 = buf2440[0]
        buf2442 = buf2440[1]
        del buf2440
        buf2443 = buf2436; del buf2436  # reuse
        buf2445 = buf2434; del buf2434  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_87.run(relu_17, buf2424, buf2441, convolution_18, unsqueeze_5005, buf2443, buf2445, 72, 6272, grid=grid(72), stream=stream0)
        buf2444 = buf2437; del buf2437  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2443, buf2444, 18, 4, grid=grid(18), stream=stream0)
        buf2446 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2448 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2445, squeeze_55, buf2446, buf2448, 18, 4, grid=grid(18), stream=stream0)
        buf2447 = buf2439; del buf2439  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_88.run(relu_17, buf2424, buf2441, convolution_18, unsqueeze_5005, buf2446, squeeze_55, buf2444, primals_56, buf2447, 451584, grid=grid(451584), stream=stream0)
        del convolution_18
        del primals_56
        del squeeze_55
        del unsqueeze_5005
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf2449 = aten.convolution_backward(buf2447, relu_16, primals_55, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2447
        del primals_55
        buf2450 = buf2449[0]
        buf2451 = buf2449[1]
        del buf2449
        buf2452 = buf2445; del buf2445  # reuse
        buf2454 = buf2443; del buf2443  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_85.run(relu_16, buf2450, convolution_17, unsqueeze_5017, buf2452, buf2454, 72, 6272, grid=grid(72), stream=stream0)
        buf2453 = buf2446; del buf2446  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2452, buf2453, 18, 4, grid=grid(18), stream=stream0)
        buf2455 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2456 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2454, squeeze_52, buf2455, buf2456, 18, 4, grid=grid(18), stream=stream0)
        buf2457 = buf2450; del buf2450  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_86.run(buf2457, relu_16, convolution_17, unsqueeze_5017, buf2455, squeeze_52, buf2453, primals_53, 451584, grid=grid(451584), stream=stream0)
        del convolution_17
        del primals_53
        del relu_16
        del squeeze_52
        del unsqueeze_5017
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2458 = aten.convolution_backward(buf2457, relu_14, primals_52, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2457
        del primals_52
        buf2459 = buf2458[0]
        buf2460 = buf2458[1]
        del buf2458
        buf2461 = buf2358; del buf2358  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_80.run(buf2461, relu_15, relu_25, buf2371, buf2385, 225792, grid=grid(225792), stream=stream0)
        del buf2371
        del buf2385
        del relu_15
        del relu_25
        buf2462 = buf2381; del buf2381  # reuse
        buf2463 = empty((36, ), device='cuda', dtype=torch.float32)
        buf2464 = empty((36, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_48.run(buf2461, convolution_16, unsqueeze_5029, squeeze_49, buf2462, buf2463, buf2464, 36, 6272, grid=grid(36), stream=stream0)
        buf2465 = buf2461; del buf2461  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_117.run(buf2465, convolution_16, unsqueeze_5029, buf2463, squeeze_49, buf2462, primals_50, 225792, grid=grid(225792), stream=stream0)
        del buf2463
        del convolution_16
        del primals_50
        del squeeze_49
        del unsqueeze_5029
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2466 = aten.convolution_backward(buf2465, relu_13, primals_49, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2465
        del primals_49
        buf2467 = buf2466[0]
        buf2468 = buf2466[1]
        del buf2466
        buf2469 = buf2424; del buf2424  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_89.run(buf2469, relu_14, relu_17, buf2441, buf2459, 451584, grid=grid(451584), stream=stream0)
        del buf2441
        del buf2459
        del relu_14
        del relu_17
        buf2470 = buf2454; del buf2454  # reuse
        buf2472 = buf2452; del buf2452  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_81.run(buf2469, convolution_15, unsqueeze_5041, buf2470, buf2472, 72, 6272, grid=grid(72), stream=stream0)
        buf2471 = buf2455; del buf2455  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_82.run(buf2470, buf2471, 18, 4, grid=grid(18), stream=stream0)
        del buf2470
        buf2473 = empty((18, ), device='cuda', dtype=torch.float32)
        buf2474 = empty((18, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_per_fused_native_batch_norm_backward_83.run(buf2472, squeeze_46, buf2473, buf2474, 18, 4, grid=grid(18), stream=stream0)
        del buf2472
        buf2475 = buf2469; del buf2469  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_118.run(buf2475, convolution_15, unsqueeze_5041, buf2473, squeeze_46, buf2471, primals_47, 451584, grid=grid(451584), stream=stream0)
        del buf2473
        del convolution_15
        del primals_47
        del squeeze_46
        del unsqueeze_5041
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2476 = aten.convolution_backward(buf2475, relu_13, primals_46, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2475
        del primals_46
        buf2477 = buf2476[0]
        buf2478 = buf2476[1]
        del buf2476
        buf2479 = buf90; del buf90  # reuse
        buf2480 = buf82; del buf82  # reuse
        buf2482 = empty((256, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_119.run(relu_13, buf2467, buf2477, convolution_14, unsqueeze_5053, squeeze_43, buf2479, buf2480, buf2482, 256, 25088, grid=grid(256), stream=stream0)
        buf2481 = empty((8, 256, 56, 56), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_120.run(relu_13, buf2467, buf2477, convolution_14, unsqueeze_5053, buf2480, squeeze_43, buf2479, primals_44, buf2481, 6422528, grid=grid(6422528), stream=stream0)
        del convolution_14
        del primals_44
        del squeeze_43
        del unsqueeze_5053
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf2483 = aten.convolution_backward(buf2481, relu_12, primals_43, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2481
        del primals_43
        buf2484 = buf2483[0]
        buf2485 = buf2483[1]
        del buf2483
        buf2486 = reinterpret_tensor(buf2480, (64, 4), (1, 64), 0); del buf2480  # reuse
        buf2488 = empty_strided((64, 4), (1, 64), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_121.run(relu_12, buf2484, convolution_13, unsqueeze_5065, buf2486, buf2488, 256, 6272, grid=grid(256), stream=stream0)
        buf2487 = buf110; del buf110  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_122.run(buf2486, buf2487, 64, 4, grid=grid(64), stream=stream0)
        buf2489 = empty((64, ), device='cuda', dtype=torch.float32)
        buf2490 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_123.run(buf2488, squeeze_40, buf2489, buf2490, 64, 4, grid=grid(64), stream=stream0)
        buf2491 = buf2484; del buf2484  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_124.run(buf2491, relu_12, convolution_13, unsqueeze_5065, buf2489, squeeze_40, buf2487, primals_41, 1605632, grid=grid(1605632), stream=stream0)
        del convolution_13
        del primals_41
        del relu_12
        del squeeze_40
        del unsqueeze_5065
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2492 = aten.convolution_backward(buf2491, relu_11, primals_40, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2491
        del primals_40
        buf2493 = buf2492[0]
        buf2494 = buf2492[1]
        del buf2492
        buf2495 = buf2488; del buf2488  # reuse
        buf2497 = buf2486; del buf2486  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_121.run(relu_11, buf2493, convolution_12, unsqueeze_5077, buf2495, buf2497, 256, 6272, grid=grid(256), stream=stream0)
        buf2496 = buf2489; del buf2489  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_122.run(buf2495, buf2496, 64, 4, grid=grid(64), stream=stream0)
        buf2498 = empty((64, ), device='cuda', dtype=torch.float32)
        buf2499 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_123.run(buf2497, squeeze_37, buf2498, buf2499, 64, 4, grid=grid(64), stream=stream0)
        buf2500 = buf2493; del buf2493  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_124.run(buf2500, relu_11, convolution_12, unsqueeze_5077, buf2498, squeeze_37, buf2496, primals_38, 1605632, grid=grid(1605632), stream=stream0)
        del convolution_12
        del primals_38
        del relu_11
        del squeeze_37
        del unsqueeze_5077
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2501 = aten.convolution_backward(buf2500, relu_10, primals_37, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2500
        del primals_37
        buf2502 = buf2501[0]
        buf2503 = buf2501[1]
        del buf2501
        buf2504 = buf2467; del buf2467  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_125.run(buf2504, relu_10, relu_13, buf2477, buf2502, 6422528, grid=grid(6422528), stream=stream0)
        del buf2477
        del relu_10
        del relu_13
        buf2505 = reinterpret_tensor(buf2497, (256, ), (1, ), 0); del buf2497  # reuse
        buf2506 = reinterpret_tensor(buf2495, (256, ), (1, ), 0); del buf2495  # reuse
        buf2507 = empty((256, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_126.run(buf2504, convolution_11, unsqueeze_5089, squeeze_34, buf2505, buf2506, buf2507, 256, 25088, grid=grid(256), stream=stream0)
        buf2508 = buf2502; del buf2502  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_127.run(buf2504, convolution_11, unsqueeze_5089, buf2506, squeeze_34, buf2505, primals_35, buf2508, 6422528, grid=grid(6422528), stream=stream0)
        del convolution_11
        del primals_35
        del squeeze_34
        del unsqueeze_5089
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2509 = aten.convolution_backward(buf2508, relu_9, primals_34, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del primals_34
        buf2510 = buf2509[0]
        buf2511 = buf2509[1]
        del buf2509
        buf2512 = reinterpret_tensor(buf2506, (64, 4), (1, 64), 0); del buf2506  # reuse
        buf2514 = empty_strided((64, 4), (1, 64), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_121.run(relu_9, buf2510, convolution_10, unsqueeze_5101, buf2512, buf2514, 256, 6272, grid=grid(256), stream=stream0)
        buf2513 = buf2498; del buf2498  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_122.run(buf2512, buf2513, 64, 4, grid=grid(64), stream=stream0)
        buf2515 = empty((64, ), device='cuda', dtype=torch.float32)
        buf2516 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_123.run(buf2514, squeeze_31, buf2515, buf2516, 64, 4, grid=grid(64), stream=stream0)
        buf2517 = buf2510; del buf2510  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_124.run(buf2517, relu_9, convolution_10, unsqueeze_5101, buf2515, squeeze_31, buf2513, primals_32, 1605632, grid=grid(1605632), stream=stream0)
        del convolution_10
        del primals_32
        del relu_9
        del squeeze_31
        del unsqueeze_5101
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2518 = aten.convolution_backward(buf2517, relu_8, primals_31, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2517
        del primals_31
        buf2519 = buf2518[0]
        buf2520 = buf2518[1]
        del buf2518
        buf2521 = buf2514; del buf2514  # reuse
        buf2523 = buf2512; del buf2512  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_121.run(relu_8, buf2519, convolution_9, unsqueeze_5113, buf2521, buf2523, 256, 6272, grid=grid(256), stream=stream0)
        buf2522 = buf2515; del buf2515  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_122.run(buf2521, buf2522, 64, 4, grid=grid(64), stream=stream0)
        buf2524 = empty((64, ), device='cuda', dtype=torch.float32)
        buf2525 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_123.run(buf2523, squeeze_28, buf2524, buf2525, 64, 4, grid=grid(64), stream=stream0)
        buf2526 = buf2519; del buf2519  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_124.run(buf2526, relu_8, convolution_9, unsqueeze_5113, buf2524, squeeze_28, buf2522, primals_29, 1605632, grid=grid(1605632), stream=stream0)
        del convolution_9
        del primals_29
        del relu_8
        del squeeze_28
        del unsqueeze_5113
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2527 = aten.convolution_backward(buf2526, relu_7, primals_28, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2526
        del primals_28
        buf2528 = buf2527[0]
        buf2529 = buf2527[1]
        del buf2527
        buf2530 = reinterpret_tensor(buf2523, (256, ), (1, ), 0); del buf2523  # reuse
        buf2531 = reinterpret_tensor(buf2521, (256, ), (1, ), 0); del buf2521  # reuse
        buf2533 = empty((256, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_119.run(relu_7, buf2504, buf2528, convolution_8, unsqueeze_5125, squeeze_25, buf2530, buf2531, buf2533, 256, 25088, grid=grid(256), stream=stream0)
        buf2532 = buf2508; del buf2508  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_120.run(relu_7, buf2504, buf2528, convolution_8, unsqueeze_5125, buf2531, squeeze_25, buf2530, primals_26, buf2532, 6422528, grid=grid(6422528), stream=stream0)
        del convolution_8
        del primals_26
        del squeeze_25
        del unsqueeze_5125
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf2534 = aten.convolution_backward(buf2532, relu_6, primals_25, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2532
        del primals_25
        buf2535 = buf2534[0]
        buf2536 = buf2534[1]
        del buf2534
        buf2537 = reinterpret_tensor(buf2531, (64, 4), (1, 64), 0); del buf2531  # reuse
        buf2539 = empty_strided((64, 4), (1, 64), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_121.run(relu_6, buf2535, convolution_7, unsqueeze_5137, buf2537, buf2539, 256, 6272, grid=grid(256), stream=stream0)
        buf2538 = buf2524; del buf2524  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_122.run(buf2537, buf2538, 64, 4, grid=grid(64), stream=stream0)
        buf2540 = empty((64, ), device='cuda', dtype=torch.float32)
        buf2541 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_123.run(buf2539, squeeze_22, buf2540, buf2541, 64, 4, grid=grid(64), stream=stream0)
        buf2542 = buf2535; del buf2535  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_124.run(buf2542, relu_6, convolution_7, unsqueeze_5137, buf2540, squeeze_22, buf2538, primals_23, 1605632, grid=grid(1605632), stream=stream0)
        del convolution_7
        del primals_23
        del relu_6
        del squeeze_22
        del unsqueeze_5137
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2543 = aten.convolution_backward(buf2542, relu_5, primals_22, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2542
        del primals_22
        buf2544 = buf2543[0]
        buf2545 = buf2543[1]
        del buf2543
        buf2546 = buf2539; del buf2539  # reuse
        buf2548 = buf2537; del buf2537  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_121.run(relu_5, buf2544, convolution_6, unsqueeze_5149, buf2546, buf2548, 256, 6272, grid=grid(256), stream=stream0)
        buf2547 = buf2540; del buf2540  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_122.run(buf2546, buf2547, 64, 4, grid=grid(64), stream=stream0)
        buf2549 = empty((64, ), device='cuda', dtype=torch.float32)
        buf2550 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_123.run(buf2548, squeeze_19, buf2549, buf2550, 64, 4, grid=grid(64), stream=stream0)
        buf2551 = buf2544; del buf2544  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_124.run(buf2551, relu_5, convolution_6, unsqueeze_5149, buf2549, squeeze_19, buf2547, primals_20, 1605632, grid=grid(1605632), stream=stream0)
        del convolution_6
        del primals_20
        del relu_5
        del squeeze_19
        del unsqueeze_5149
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2552 = aten.convolution_backward(buf2551, relu_4, primals_19, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2551
        del primals_19
        buf2553 = buf2552[0]
        buf2554 = buf2552[1]
        del buf2552
        buf2555 = buf2504; del buf2504  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.threshold_backward]
        triton_poi_fused_add_threshold_backward_125.run(buf2555, relu_4, relu_7, buf2528, buf2553, 6422528, grid=grid(6422528), stream=stream0)
        del relu_4
        del relu_7
        buf2556 = reinterpret_tensor(buf2548, (256, ), (1, ), 0); del buf2548  # reuse
        buf2557 = reinterpret_tensor(buf2546, (256, ), (1, ), 0); del buf2546  # reuse
        buf2563 = empty((256, ), device='cuda', dtype=torch.float32)
        buf2558 = empty((256, ), device='cuda', dtype=torch.float32)
        buf2564 = empty((256, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
        triton_red_fused_native_batch_norm_backward_128.run(buf2555, convolution_5, unsqueeze_5161, convolution_4, unsqueeze_5173, squeeze_16, squeeze_13, buf2556, buf2557, buf2563, buf2558, buf2564, 256, 25088, grid=grid(256), stream=stream0)
        buf2559 = buf2553; del buf2553  # reuse
        buf2565 = buf2528; del buf2528  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_129.run(buf2555, convolution_5, unsqueeze_5161, buf2557, squeeze_16, buf2556, primals_17, convolution_4, unsqueeze_5173, buf2563, squeeze_13, primals_14, buf2559, buf2565, 6422528, grid=grid(6422528), stream=stream0)
        del buf2555
        del convolution_4
        del convolution_5
        del primals_14
        del primals_17
        del squeeze_13
        del squeeze_16
        del unsqueeze_5161
        del unsqueeze_5173
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2560 = aten.convolution_backward(buf2559, relu_1, primals_16, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2559
        del primals_16
        buf2561 = buf2560[0]
        buf2562 = buf2560[1]
        del buf2560
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward]
        buf2566 = aten.convolution_backward(buf2565, relu_3, primals_13, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2565
        del primals_13
        buf2567 = buf2566[0]
        buf2568 = buf2566[1]
        del buf2566
        buf2569 = reinterpret_tensor(buf2563, (64, 4), (1, 64), 0); del buf2563  # reuse
        buf2571 = reinterpret_tensor(buf2557, (64, 4), (1, 64), 0); del buf2557  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_121.run(relu_3, buf2567, convolution_3, unsqueeze_5185, buf2569, buf2571, 256, 6272, grid=grid(256), stream=stream0)
        buf2570 = buf2549; del buf2549  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_122.run(buf2569, buf2570, 64, 4, grid=grid(64), stream=stream0)
        buf2572 = empty((64, ), device='cuda', dtype=torch.float32)
        buf2573 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_123.run(buf2571, squeeze_10, buf2572, buf2573, 64, 4, grid=grid(64), stream=stream0)
        buf2574 = buf2567; del buf2567  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_124.run(buf2574, relu_3, convolution_3, unsqueeze_5185, buf2572, squeeze_10, buf2570, primals_11, 1605632, grid=grid(1605632), stream=stream0)
        del convolution_3
        del primals_11
        del relu_3
        del squeeze_10
        del unsqueeze_5185
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2575 = aten.convolution_backward(buf2574, relu_2, primals_10, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2574
        del primals_10
        buf2576 = buf2575[0]
        buf2577 = buf2575[1]
        del buf2575
        buf2578 = buf2571; del buf2571  # reuse
        buf2580 = buf2569; del buf2569  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_121.run(relu_2, buf2576, convolution_2, unsqueeze_5197, buf2578, buf2580, 256, 6272, grid=grid(256), stream=stream0)
        buf2579 = buf2572; del buf2572  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_122.run(buf2578, buf2579, 64, 4, grid=grid(64), stream=stream0)
        buf2581 = empty((64, ), device='cuda', dtype=torch.float32)
        buf2582 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_123.run(buf2580, squeeze_7, buf2581, buf2582, 64, 4, grid=grid(64), stream=stream0)
        buf2583 = buf2576; del buf2576  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_124.run(buf2583, relu_2, convolution_2, unsqueeze_5197, buf2581, squeeze_7, buf2579, primals_8, 1605632, grid=grid(1605632), stream=stream0)
        del convolution_2
        del primals_8
        del relu_2
        del squeeze_7
        del unsqueeze_5197
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2584 = aten.convolution_backward(buf2583, relu_1, primals_7, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2583
        del primals_7
        buf2585 = buf2584[0]
        buf2586 = buf2584[1]
        del buf2584
        buf2587 = buf2580; del buf2580  # reuse
        buf2589 = buf2578; del buf2578  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_add_native_batch_norm_backward_threshold_backward_130.run(relu_1, buf2561, buf2585, convolution_1, unsqueeze_5209, buf2587, buf2589, 256, 6272, grid=grid(256), stream=stream0)
        buf2588 = buf2581; del buf2581  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_122.run(buf2587, buf2588, 64, 4, grid=grid(64), stream=stream0)
        del buf2587
        buf2590 = empty((64, ), device='cuda', dtype=torch.float32)
        buf2592 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_123.run(buf2589, squeeze_4, buf2590, buf2592, 64, 4, grid=grid(64), stream=stream0)
        del buf2589
        buf2591 = buf2561; del buf2561  # reuse
        # Source Nodes: [], Original ATen: [aten.add, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_add_native_batch_norm_backward_threshold_backward_131.run(buf2591, relu_1, buf2585, convolution_1, unsqueeze_5209, buf2590, squeeze_4, buf2588, primals_5, 1605632, grid=grid(1605632), stream=stream0)
        del buf2585
        del convolution_1
        del primals_5
        del relu_1
        del squeeze_4
        del unsqueeze_5209
        # Source Nodes: [], Original ATen: [aten.convolution_backward]
        buf2593 = aten.convolution_backward(buf2591, relu, primals_4, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False])
        del buf2591
        del primals_4
        buf2594 = buf2593[0]
        buf2595 = buf2593[1]
        del buf2593
        buf2596 = empty((64, 13), device='cuda', dtype=torch.float32)
        buf2598 = empty((64, 13), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_red_fused_native_batch_norm_backward_threshold_backward_132.run(relu, buf2594, convolution, unsqueeze_5221, buf2596, buf2598, 832, 7720, grid=grid(832), stream=stream0)
        buf2597 = buf2590; del buf2590  # reuse
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_133.run(buf2596, buf2597, 64, 13, grid=grid(64), stream=stream0)
        del buf2596
        buf2599 = empty((64, ), device='cuda', dtype=torch.float32)
        buf2600 = empty((64, ), device='cuda', dtype=torch.float32)
        # Source Nodes: [], Original ATen: [aten.native_batch_norm_backward, aten.threshold_backward]
        triton_per_fused_native_batch_norm_backward_threshold_backward_134.run(buf2598, squeeze_1, buf2599, buf2600, 64, 13, grid=grid(64), stream=stream0)
        del buf2598
        buf2601 = buf2594; del buf2594  # reuse
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        triton_poi_fused_convolution_backward_native_batch_norm_backward_threshold_backward_135.run(buf2601, relu, convolution, unsqueeze_5221, buf2599, squeeze_1, buf2597, primals_2, 6422528, grid=grid(6422528), stream=stream0)
        del buf2599
        del convolution
        del primals_2
        del relu
        del squeeze_1
        del unsqueeze_5221
        # Source Nodes: [], Original ATen: [aten.convolution_backward, aten.native_batch_norm_backward, aten.threshold_backward]
        buf2602 = aten.convolution_backward(buf2601, primals_1957, primals_1, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [False, True, False])
        del buf2601
        del primals_1
        del primals_1957
        buf2603 = buf2602[1]
        return (buf2603, buf2600, buf2597, buf2595, buf2592, buf2588, buf2586, buf2582, buf2579, buf2577, buf2573, buf2570, buf2568, buf2564, buf2556, buf2562, buf2558, buf2556, buf2554, buf2550, buf2547, buf2545, buf2541, buf2538, buf2536, buf2533, buf2530, buf2529, buf2525, buf2522, buf2520, buf2516, buf2513, buf2511, buf2507, buf2505, buf2503, buf2499, buf2496, buf2494, buf2490, buf2487, buf2485, buf2482, buf2479, buf2478, buf2474, buf2471, buf2468, buf2464, buf2462, buf2460, buf2456, buf2453, buf2451, buf2448, buf2444, buf2442, buf2438, buf2435, buf2433, buf2429, buf2426, buf2423, buf2419, buf2416, buf2414, buf2411, buf2407, buf2405, buf2401, buf2398, buf2396, buf2392, buf2389, buf2386, buf2382, buf2380, buf2379, buf2376, buf2373, buf2372, buf2368, buf2366, buf2365, buf2361, buf2359, buf2357, buf2353, buf2351, buf2350, buf2347, buf2344, buf2343, buf2339, buf2337, buf2336, buf2332, buf2330, buf2328, buf2324, buf2322, buf2317, buf2313, buf2310, buf2309, buf2305, buf2303, buf2301, buf2297, buf2294, buf2292, buf2288, buf2285, buf2282, buf2278, buf2275, buf2273, buf2270, buf2266, buf2264, buf2260, buf2257, buf2255, buf2251, buf2248, buf2245, buf2241, buf2238, buf2236, buf2232, buf2228, buf2226, buf2222, buf2220, buf2219, buf2215, buf2213, buf2211, buf2207, buf2205, buf2204, buf2201, buf2198, buf2197, buf2193, buf2191, buf2190, buf2186, buf2184, buf2182, buf2178, buf2176, buf2175, buf2171, buf2168, buf2167, buf2163, buf2161, buf2160, buf2157, buf2154, buf2153, buf2149, buf2147, buf2146, buf2142, buf2140, buf2138, buf2134, buf2132, buf2131, buf2128, buf2125, buf2124, buf2120, buf2118, buf2117, buf2113, buf2111, buf2109, buf2105, buf2103, buf2099, buf2095, buf2093, buf2088, buf2084, buf2082, buf2081, buf2077, buf2075, buf2070, buf2066, buf2064, buf2063, buf2060, buf2051, buf2057, buf2054, buf2051, buf2050, buf2046, buf2043, buf2041, buf2037, buf2034, buf2031, buf2027, buf2024, buf2022, buf2019, buf2015, buf2013, buf2009, buf2006, buf2004, buf2000, buf1997, buf1994, buf1990, buf1987, buf1985, buf1981, buf1977, buf1975, buf1971, buf1969, buf1968, buf1964, buf1962, buf1960, buf1956, buf1954, buf1953, buf1950, buf1947, buf1946, buf1942, buf1940, buf1939, buf1935, buf1933, buf1931, buf1927, buf1925, buf1924, buf1920, buf1917, buf1916, buf1912, buf1910, buf1909, buf1905, buf1903, buf1901, buf1897, buf1895, buf1894, buf1891, buf1888, buf1887, buf1883, buf1881, buf1880, buf1876, buf1874, buf1872, buf1868, buf1866, buf1865, buf1861, buf1858, buf1857, buf1853, buf1851, buf1847, buf1843, buf1841, buf1836, buf1832, buf1830, buf1829, buf1825, buf1823, buf1818, buf1814, buf1812, buf1811, buf1807, buf1799, buf1805, buf1801, buf1799, buf1797, buf1793, buf1790, buf1788, buf1784, buf1781, buf1778, buf1774, buf1771, buf1769, buf1766, buf1762, buf1760, buf1756, buf1753, buf1751, buf1747, buf1744, buf1741, buf1737, buf1734, buf1732, buf1728, buf1724, buf1722, buf1718, buf1716, buf1715, buf1711, buf1709, buf1707, buf1703, buf1701, buf1700, buf1697, buf1694, buf1693, buf1689, buf1687, buf1686, buf1682, buf1680, buf1678, buf1674, buf1672, buf1671, buf1667, buf1664, buf1663, buf1659, buf1657, buf1656, buf1653, buf1650, buf1649, buf1645, buf1643, buf1642, buf1638, buf1636, buf1634, buf1630, buf1628, buf1627, buf1624, buf1621, buf1620, buf1616, buf1614, buf1613, buf1609, buf1607, buf1605, buf1601, buf1599, buf1595, buf1591, buf1589, buf1584, buf1580, buf1578, buf1577, buf1573, buf1571, buf1566, buf1562, buf1560, buf1559, buf1556, buf1547, buf1553, buf1550, buf1547, buf1546, buf1542, buf1539, buf1537, buf1533, buf1530, buf1527, buf1523, buf1520, buf1518, buf1515, buf1511, buf1509, buf1505, buf1502, buf1500, buf1496, buf1493, buf1490, buf1486, buf1483, buf1481, buf1477, buf1473, buf1471, buf1467, buf1465, buf1464, buf1460, buf1458, buf1456, buf1452, buf1450, buf1449, buf1446, buf1443, buf1442, buf1438, buf1436, buf1435, buf1431, buf1429, buf1427, buf1423, buf1421, buf1420, buf1416, buf1413, buf1412, buf1408, buf1406, buf1405, buf1401, buf1399, buf1397, buf1393, buf1391, buf1390, buf1387, buf1384, buf1383, buf1379, buf1377, buf1376, buf1372, buf1370, buf1368, buf1364, buf1362, buf1361, buf1357, buf1354, buf1353, buf1349, buf1347, buf1343, buf1339, buf1337, buf1332, buf1328, buf1326, buf1325, buf1321, buf1319, buf1314, buf1310, buf1308, buf1307, buf1303, buf1295, buf1301, buf1297, buf1295, buf1293, buf1289, buf1287, buf1285, buf1281, buf1278, buf1276, buf1273, buf1269, buf1267, buf1263, buf1260, buf1258, buf1254, buf1251, buf1248, buf1244, buf1241, buf1239, buf1236, buf1232, buf1230, buf1226, buf1223, buf1221, buf1217, buf1214, buf1211, buf1207, buf1205, buf1204, buf1201, buf1198, buf1197, buf1193, buf1191, buf1190, buf1186, buf1184, buf1182, buf1178, buf1176, buf1175, buf1172, buf1169, buf1168, buf1164, buf1162, buf1161, buf1157, buf1155, buf1153, buf1149, buf1147, buf1146, buf1143, buf1140, buf1139, buf1135, buf1133, buf1132, buf1128, buf1126, buf1124, buf1120, buf1118, buf1117, buf1114, buf1111, buf1110, buf1106, buf1104, buf1103, buf1099, buf1097, buf1095, buf1091, buf1089, buf1088, buf1085, buf1082, buf1081, buf1077, buf1075, buf1074, buf1070, buf1068, buf1066, buf1062, buf1060, buf1059, buf1056, buf1053, buf1052, buf1048, buf1046, buf1045, buf1041, buf1039, buf1037, buf1033, buf1031, buf1027, buf1023, buf1021, buf1017, buf1013, buf1011, buf1006, buf1002, buf1000, buf999, buf995, buf993, buf989, buf985, buf983, buf978, buf974, buf972, buf971, buf967, buf959, buf965, buf961, buf959, buf958, buf954, buf952, buf947, buf943, buf941, buf940, buf936, buf934, buf933, buf929, buf908, buf927, buf923, buf921, buf920, buf916, buf908, buf914, buf910, buf908, buf906, buf902, buf899, buf897, buf894, buf890, buf888, buf884, buf881, buf879, buf875, buf872, buf869, buf865, buf862, buf860, buf857, buf853, buf851, buf847, buf844, buf842, buf838, buf835, buf832, buf828, buf826, buf825, buf822, buf819, buf818, buf814, buf812, buf811, buf807, buf805, buf803, buf799, buf797, buf796, buf793, buf790, buf789, buf785, buf783, buf782, buf778, buf776, buf774, buf770, buf768, buf767, buf764, buf761, buf760, buf756, buf754, buf753, buf749, buf747, buf745, buf741, buf739, buf738, buf735, buf732, buf731, buf727, buf725, buf724, buf720, buf718, buf716, buf712, buf710, buf709, buf706, buf703, buf702, buf698, buf696, buf695, buf691, buf689, buf687, buf683, buf681, buf680, buf677, buf674, buf673, buf669, buf667, buf666, buf662, buf660, buf658, buf654, buf652, buf648, buf644, buf642, buf638, buf634, buf632, buf627, buf623, buf621, buf620, buf616, buf614, buf610, buf606, buf604, buf599, buf595, buf593, buf592, buf588, buf580, buf586, buf582, buf580, buf579, buf575, buf573, buf568, buf564, buf562, buf561, buf557, buf555, buf554, buf550, buf529, buf548, buf544, buf542, buf541, buf537, buf529, buf535, buf531, buf529, buf527, buf523, buf520, buf518, buf515, buf511, buf509, buf505, buf502, buf500, buf496, buf493, buf490, buf486, buf483, buf481, buf478, buf474, buf472, buf468, buf465, buf463, buf459, buf456, buf453, buf449, buf447, buf446, buf443, buf440, buf439, buf435, buf433, buf432, buf428, buf426, buf424, buf420, buf418, buf417, buf414, buf411, buf410, buf406, buf404, buf403, buf399, buf397, buf395, buf391, buf389, buf388, buf385, buf382, buf381, buf377, buf375, buf374, buf370, buf368, buf366, buf362, buf360, buf359, buf356, buf353, buf352, buf348, buf346, buf345, buf341, buf339, buf337, buf333, buf331, buf330, buf327, buf324, buf323, buf319, buf317, buf316, buf312, buf310, buf308, buf304, buf302, buf301, buf298, buf295, buf294, buf290, buf288, buf287, buf283, buf281, buf279, buf275, buf273, buf269, buf265, buf263, buf259, buf255, buf253, buf248, buf244, buf242, buf241, buf237, buf235, buf231, buf227, buf225, buf220, buf216, buf214, buf213, buf209, buf201, buf207, buf203, buf201, buf200, buf196, buf194, buf189, buf185, buf183, buf182, buf178, buf176, buf175, buf172, buf150, buf169, buf165, buf163, buf162, buf159, buf150, buf156, buf153, buf150, buf149, buf145, buf142, buf140, buf136, buf133, buf131, buf127, buf117, buf124, buf120, buf117, buf115, buf111, buf109, buf108, buf104, buf102, buf101, buf97, buf89, buf95, buf91, buf89, buf88, buf85, buf84, buf81, buf80, buf76, buf74, buf73, buf69, buf67, buf66, buf62, buf54, buf60, buf56, buf54, buf53, buf50, buf49, buf46, buf45, buf41, buf39, buf38, buf34, buf32, buf31, buf27, buf19, buf25, buf21, buf19, buf18, buf15, buf14, buf11, buf10, buf7, buf6, buf3, reinterpret_tensor(buf1, (1000, 2048), (2048, 1), 0), reinterpret_tensor(buf2, (1000, ), (1, ), 0), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, )


def benchmark_compiled_module(times=10, repeat=10):
    from torch._dynamo.testing import rand_strided
    from torch._inductor.utils import print_performance
    primals_1 = rand_strided((64, 3, 3, 3), (27, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_2 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_4 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_5 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_7 = rand_strided((64, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_8 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_10 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_11 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_13 = rand_strided((256, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_14 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_16 = rand_strided((256, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_17 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_19 = rand_strided((64, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_20 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_22 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_23 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_25 = rand_strided((256, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_26 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_28 = rand_strided((64, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_29 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_31 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_32 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_34 = rand_strided((256, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_35 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_37 = rand_strided((64, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_38 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_40 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_41 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_43 = rand_strided((256, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_44 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_46 = rand_strided((18, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_47 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_49 = rand_strided((36, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_50 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_52 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_53 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_55 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_56 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_58 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_59 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_61 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_62 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_64 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_65 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_67 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_68 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_70 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_71 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_73 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_74 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_76 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_77 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_79 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_80 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_82 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_83 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_85 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_86 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_88 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_89 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_91 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_92 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_94 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_95 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_97 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_98 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_100 = rand_strided((18, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_101 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_103 = rand_strided((36, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_104 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_106 = rand_strided((72, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_107 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_109 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_110 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_112 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_113 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_115 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_116 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_118 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_119 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_121 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_122 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_124 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_125 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_127 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_128 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_130 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_131 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_133 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_134 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_136 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_137 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_139 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_140 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_142 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_143 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_145 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_146 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_148 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_149 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_151 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_152 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_154 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_155 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_157 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_158 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_160 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_161 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_163 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_164 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_166 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_167 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_169 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_170 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_172 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_173 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_175 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_176 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_178 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_179 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_181 = rand_strided((18, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_182 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_184 = rand_strided((18, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_185 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_187 = rand_strided((36, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_188 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_190 = rand_strided((36, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_191 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_193 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_194 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_196 = rand_strided((72, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_197 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_199 = rand_strided((72, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_200 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_202 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_203 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_205 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_206 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_208 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_209 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_211 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_212 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_214 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_215 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_217 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_218 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_220 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_221 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_223 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_224 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_226 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_227 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_229 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_230 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_232 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_233 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_235 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_236 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_238 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_239 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_241 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_242 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_244 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_245 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_247 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_248 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_250 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_251 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_253 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_254 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_256 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_257 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_259 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_260 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_262 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_263 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_265 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_266 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_268 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_269 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_271 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_272 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_274 = rand_strided((18, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_275 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_277 = rand_strided((18, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_278 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_280 = rand_strided((36, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_281 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_283 = rand_strided((36, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_284 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_286 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_287 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_289 = rand_strided((72, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_290 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_292 = rand_strided((72, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_293 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_295 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_296 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_298 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_299 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_301 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_302 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_304 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_305 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_307 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_308 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_310 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_311 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_313 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_314 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_316 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_317 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_319 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_320 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_322 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_323 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_325 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_326 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_328 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_329 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_331 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_332 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_334 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_335 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_337 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_338 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_340 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_341 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_343 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_344 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_346 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_347 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_349 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_350 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_352 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_353 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_355 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_356 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_358 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_359 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_361 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_362 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_364 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_365 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_367 = rand_strided((18, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_368 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_370 = rand_strided((18, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_371 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_373 = rand_strided((36, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_374 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_376 = rand_strided((36, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_377 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_379 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_380 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_382 = rand_strided((72, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_383 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_385 = rand_strided((72, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_386 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_388 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_389 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_391 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_392 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_394 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_395 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_397 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_398 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_400 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_401 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_403 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_404 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_406 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_407 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_409 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_410 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_412 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_413 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_415 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_416 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_418 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_419 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_421 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_422 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_424 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_425 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_427 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_428 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_430 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_431 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_433 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_434 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_436 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_437 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_439 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_440 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_442 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_443 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_445 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_446 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_448 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_449 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_451 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_452 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_454 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_455 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_457 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_458 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_460 = rand_strided((18, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_461 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_463 = rand_strided((18, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_464 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_466 = rand_strided((36, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_467 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_469 = rand_strided((36, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_470 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_472 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_473 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_475 = rand_strided((72, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_476 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_478 = rand_strided((72, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_479 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_481 = rand_strided((144, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_482 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_484 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_485 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_487 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_488 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_490 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_491 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_493 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_494 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_496 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_497 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_499 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_500 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_502 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_503 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_505 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_506 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_508 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_509 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_511 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_512 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_514 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_515 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_517 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_518 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_520 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_521 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_523 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_524 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_526 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_527 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_529 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_530 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_532 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_533 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_535 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_536 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_538 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_539 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_541 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_542 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_544 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_545 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_547 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_548 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_550 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_551 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_553 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_554 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_556 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_557 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_559 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_560 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_562 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_563 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_565 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_566 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_568 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_569 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_571 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_572 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_574 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_575 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_577 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_578 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_580 = rand_strided((18, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_581 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_583 = rand_strided((18, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_584 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_586 = rand_strided((18, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_587 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_589 = rand_strided((36, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_590 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_592 = rand_strided((36, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_593 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_595 = rand_strided((36, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_596 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_598 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_599 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_601 = rand_strided((72, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_602 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_604 = rand_strided((72, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_605 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_607 = rand_strided((72, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_608 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_610 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_611 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_613 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_614 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_616 = rand_strided((144, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_617 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_619 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_620 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_622 = rand_strided((144, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_623 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_625 = rand_strided((144, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_626 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_628 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_629 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_631 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_632 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_634 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_635 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_637 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_638 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_640 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_641 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_643 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_644 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_646 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_647 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_649 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_650 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_652 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_653 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_655 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_656 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_658 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_659 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_661 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_662 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_664 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_665 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_667 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_668 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_670 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_671 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_673 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_674 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_676 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_677 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_679 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_680 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_682 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_683 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_685 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_686 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_688 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_689 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_691 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_692 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_694 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_695 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_697 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_698 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_700 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_701 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_703 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_704 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_706 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_707 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_709 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_710 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_712 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_713 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_715 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_716 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_718 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_719 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_721 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_722 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_724 = rand_strided((18, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_725 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_727 = rand_strided((18, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_728 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_730 = rand_strided((18, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_731 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_733 = rand_strided((36, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_734 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_736 = rand_strided((36, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_737 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_739 = rand_strided((36, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_740 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_742 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_743 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_745 = rand_strided((72, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_746 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_748 = rand_strided((72, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_749 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_751 = rand_strided((72, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_752 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_754 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_755 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_757 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_758 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_760 = rand_strided((144, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_761 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_763 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_764 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_766 = rand_strided((144, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_767 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_769 = rand_strided((144, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_770 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_772 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_773 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_775 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_776 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_778 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_779 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_781 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_782 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_784 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_785 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_787 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_788 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_790 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_791 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_793 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_794 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_796 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_797 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_799 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_800 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_802 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_803 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_805 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_806 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_808 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_809 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_811 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_812 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_814 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_815 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_817 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_818 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_820 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_821 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_823 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_824 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_826 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_827 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_829 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_830 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_832 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_833 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_835 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_836 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_838 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_839 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_841 = rand_strided((72, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_842 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_844 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_845 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_847 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_848 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_850 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_851 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_853 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_854 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_856 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_857 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_859 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_860 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_862 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_863 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_865 = rand_strided((144, 144, 3, 3), (1296, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_866 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_868 = rand_strided((18, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_869 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_871 = rand_strided((18, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_872 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_874 = rand_strided((18, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_875 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_877 = rand_strided((36, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_878 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_880 = rand_strided((36, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_881 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_883 = rand_strided((36, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_884 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_886 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_887 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_889 = rand_strided((72, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_890 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_892 = rand_strided((72, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_893 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_895 = rand_strided((72, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_896 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_898 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_899 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_901 = rand_strided((18, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_902 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_904 = rand_strided((144, 18, 3, 3), (162, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_905 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_907 = rand_strided((36, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_908 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_910 = rand_strided((144, 36, 3, 3), (324, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_911 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_913 = rand_strided((144, 72, 3, 3), (648, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_914 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_916 = rand_strided((32, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_917 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_919 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_920 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_922 = rand_strided((128, 32, 1, 1), (32, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_923 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_925 = rand_strided((128, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_926 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_928 = rand_strided((64, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_929 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_931 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_932 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_934 = rand_strided((256, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_935 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_937 = rand_strided((256, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_938 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_940 = rand_strided((256, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_942 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_944 = rand_strided((128, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_945 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_947 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_948 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_950 = rand_strided((512, 128, 1, 1), (128, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_951 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_953 = rand_strided((512, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_954 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_956 = rand_strided((512, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_958 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_960 = rand_strided((256, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_961 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_963 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_964 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_966 = rand_strided((1024, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_967 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_969 = rand_strided((1024, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_970 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_972 = rand_strided((1024, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
    primals_974 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_976 = rand_strided((2048, 1024, 1, 1), (1024, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    primals_978 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
    primals_1957 = rand_strided((8, 3, 224, 224), (150528, 50176, 224, 1), device='cuda:0', dtype=torch.float32)
    convolution = rand_strided((8, 64, 112, 112), (802816, 12544, 112, 1), device='cuda:0', dtype=torch.float32)
    squeeze_1 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu = rand_strided((8, 64, 112, 112), (802816, 12544, 112, 1), device='cuda:0', dtype=torch.float32)
    convolution_1 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_4 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_1 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_2 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_7 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_2 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_3 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_10 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_3 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_4 = rand_strided((8, 256, 56, 56), (802816, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_13 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_5 = rand_strided((8, 256, 56, 56), (802816, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_16 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_4 = rand_strided((8, 256, 56, 56), (802816, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_6 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_19 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_5 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_7 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_22 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_6 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_8 = rand_strided((8, 256, 56, 56), (802816, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_25 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_7 = rand_strided((8, 256, 56, 56), (802816, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_9 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_28 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_8 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_10 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_31 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_9 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_11 = rand_strided((8, 256, 56, 56), (802816, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_34 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_10 = rand_strided((8, 256, 56, 56), (802816, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_12 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_37 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_11 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_13 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_40 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_12 = rand_strided((8, 64, 56, 56), (200704, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_14 = rand_strided((8, 256, 56, 56), (802816, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_43 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_13 = rand_strided((8, 256, 56, 56), (802816, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_15 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_46 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_14 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_16 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_49 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_15 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_17 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_52 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_16 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_18 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_55 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_17 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_19 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_58 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_18 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_20 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_61 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_19 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_21 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_64 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_20 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_22 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_67 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_21 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_23 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_70 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_22 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_24 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_73 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_23 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_25 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_76 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_24 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_26 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_79 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_25 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_27 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_82 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_26 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_28 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_85 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_27 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_29 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_88 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_28 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_30 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_91 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_29 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_31 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_94 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_30 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_32 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_97 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_31 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_33 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_100 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    convert_element_type_1 = rand_strided((56, ), (1, ), device='cuda:0', dtype=torch.int64)
    unsqueeze_136 = rand_strided((56, 1), (1, 1), device='cuda:0', dtype=torch.int64)
    relu_32 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_34 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_103 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_33 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_35 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_106 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_34 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_36 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_109 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_35 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_37 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_112 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_36 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_38 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_115 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_37 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_39 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_118 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_38 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_40 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_121 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_39 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_41 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_124 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_40 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_42 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_127 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_41 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_43 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_130 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_42 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_44 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_133 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_43 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_45 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_136 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_44 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_46 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_139 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_45 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_47 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_142 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_46 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_48 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_145 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_47 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_49 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_148 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_48 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_50 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_151 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_49 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_51 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_154 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_50 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_52 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_157 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_51 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_53 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_160 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_52 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_54 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_163 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_53 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_55 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_166 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_54 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_56 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_169 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_55 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_57 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_172 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_56 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_58 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_175 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_57 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_59 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_178 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_58 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_60 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_181 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_61 = rand_strided((8, 18, 14, 14), (3528, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_184 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    convert_element_type_9 = rand_strided((56, ), (1, ), device='cuda:0', dtype=torch.int64)
    unsqueeze_250 = rand_strided((56, 1), (1, 1), device='cuda:0', dtype=torch.int64)
    relu_59 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_62 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_187 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_63 = rand_strided((8, 36, 14, 14), (7056, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_190 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    convert_element_type_13 = rand_strided((28, ), (1, ), device='cuda:0', dtype=torch.int64)
    unsqueeze_259 = rand_strided((28, 1), (1, 1), device='cuda:0', dtype=torch.int64)
    relu_60 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_64 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_193 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_61 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_65 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_196 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_66 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_199 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_62 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_67 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_202 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_63 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_68 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_205 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_64 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_69 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_208 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_65 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_70 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_211 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_66 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_71 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_214 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_67 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_72 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_217 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_68 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_73 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_220 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_69 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_74 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_223 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_70 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_75 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_226 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_71 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_76 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_229 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_72 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_77 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_232 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_73 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_78 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_235 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_74 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_79 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_238 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_75 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_80 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_241 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_76 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_81 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_244 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_77 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_82 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_247 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_78 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_83 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_250 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_79 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_84 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_253 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_80 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_85 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_256 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_81 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_86 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_259 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_82 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_87 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_262 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_83 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_88 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_265 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_84 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_89 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_268 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_85 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_90 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_271 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_86 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_91 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_274 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_92 = rand_strided((8, 18, 14, 14), (3528, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_277 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_87 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_93 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_280 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_94 = rand_strided((8, 36, 14, 14), (7056, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_283 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_88 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_95 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_286 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_89 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_96 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_289 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_97 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_292 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_90 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_98 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_295 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_91 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_99 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_298 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_92 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_100 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_301 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_93 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_101 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_304 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_94 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_102 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_307 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_95 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_103 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_310 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_96 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_104 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_313 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_97 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_105 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_316 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_98 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_106 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_319 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_99 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_107 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_322 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_100 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_108 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_325 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_101 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_109 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_328 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_102 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_110 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_331 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_103 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_111 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_334 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_104 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_112 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_337 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_105 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_113 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_340 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_106 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_114 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_343 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_107 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_115 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_346 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_108 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_116 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_349 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_109 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_117 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_352 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_110 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_118 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_355 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_111 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_119 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_358 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_112 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_120 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_361 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_113 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_121 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_364 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_114 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_122 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_367 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_123 = rand_strided((8, 18, 14, 14), (3528, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_370 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_115 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_124 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_373 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_125 = rand_strided((8, 36, 14, 14), (7056, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_376 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_116 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_126 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_379 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_117 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_127 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_382 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_128 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_385 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_118 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_129 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_388 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_119 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_130 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_391 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_120 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_131 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_394 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_121 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_132 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_397 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_122 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_133 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_400 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_123 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_134 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_403 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_124 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_135 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_406 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_125 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_136 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_409 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_126 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_137 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_412 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_127 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_138 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_415 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_128 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_139 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_418 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_129 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_140 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_421 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_130 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_141 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_424 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_131 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_142 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_427 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_132 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_143 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_430 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_133 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_144 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_433 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_134 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_145 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_436 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_135 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_146 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_439 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_136 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_147 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_442 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_137 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_148 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_445 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_138 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_149 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_448 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_139 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_150 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_451 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_140 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_151 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_454 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_141 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_152 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_457 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_142 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_153 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_460 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_154 = rand_strided((8, 18, 14, 14), (3528, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_463 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_143 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_155 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_466 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_156 = rand_strided((8, 36, 14, 14), (7056, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_469 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_144 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_157 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_472 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_145 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_158 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_475 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_159 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_478 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_146 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_160 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_481 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_147 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_161 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_484 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_148 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_162 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_487 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_149 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_163 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_490 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_150 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_164 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_493 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_151 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_165 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_496 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_152 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_166 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_499 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_153 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_167 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_502 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_154 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_168 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_505 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_155 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_169 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_508 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_156 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_170 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_511 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_157 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_171 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_514 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_158 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_172 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_517 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_159 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_173 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_520 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_160 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_174 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_523 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_161 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_175 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_526 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_162 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_176 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_529 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_163 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_177 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_532 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_164 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_178 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_535 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_165 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_179 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_538 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_166 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_180 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_541 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_167 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_181 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_544 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_168 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_182 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_547 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_169 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_183 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_550 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_170 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_184 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_553 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_171 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_185 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_556 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_172 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_186 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_559 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_173 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_187 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_562 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_174 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_188 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_565 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_175 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_189 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_568 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_176 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_190 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_571 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_177 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_191 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_574 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_178 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_192 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_577 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_179 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_193 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_580 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_194 = rand_strided((8, 18, 14, 14), (3528, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_583 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_195 = rand_strided((8, 18, 7, 7), (882, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_586 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    convert_element_type_61 = rand_strided((56, ), (1, ), device='cuda:0', dtype=torch.int64)
    unsqueeze_799 = rand_strided((56, 1), (1, 1), device='cuda:0', dtype=torch.int64)
    relu_180 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_196 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_589 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_197 = rand_strided((8, 36, 14, 14), (7056, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_592 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_198 = rand_strided((8, 36, 7, 7), (1764, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_595 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    convert_element_type_69 = rand_strided((28, ), (1, ), device='cuda:0', dtype=torch.int64)
    unsqueeze_813 = rand_strided((28, 1), (1, 1), device='cuda:0', dtype=torch.int64)
    relu_181 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_199 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_598 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_182 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_200 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_601 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_201 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_604 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_202 = rand_strided((8, 72, 7, 7), (3528, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_607 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    convert_element_type_73 = rand_strided((14, ), (1, ), device='cuda:0', dtype=torch.int64)
    unsqueeze_830 = rand_strided((14, 1), (1, 1), device='cuda:0', dtype=torch.int64)
    relu_183 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_203 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_610 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_184 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_204 = rand_strided((8, 18, 14, 14), (3528, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_613 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_185 = rand_strided((8, 18, 14, 14), (3528, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_205 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_616 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_206 = rand_strided((8, 36, 14, 14), (7056, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_619 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_186 = rand_strided((8, 36, 14, 14), (7056, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_207 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_622 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_208 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_625 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_187 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_209 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_628 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_188 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_210 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_631 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_189 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_211 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_634 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_190 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_212 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_637 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_191 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_213 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_640 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_192 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_214 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_643 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_193 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_215 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_646 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_194 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_216 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_649 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_195 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_217 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_652 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_196 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_218 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_655 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_197 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_219 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_658 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_198 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_220 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_661 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_199 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_221 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_664 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_200 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_222 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_667 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_201 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_223 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_670 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_202 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_224 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_673 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_203 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_225 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_676 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_204 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_226 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_679 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_205 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_227 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_682 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_206 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_228 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_685 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_207 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_229 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_688 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_208 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_230 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_691 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_209 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_231 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_694 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_210 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_232 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_697 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_211 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_233 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_700 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_212 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_234 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_703 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_213 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_235 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_706 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_214 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_236 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_709 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_215 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_237 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_712 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_216 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_238 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_715 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_217 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_239 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_718 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_218 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_240 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_721 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_219 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_241 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_724 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_242 = rand_strided((8, 18, 14, 14), (3528, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_727 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_243 = rand_strided((8, 18, 7, 7), (882, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_730 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_220 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_244 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_733 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_245 = rand_strided((8, 36, 14, 14), (7056, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_736 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_246 = rand_strided((8, 36, 7, 7), (1764, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_739 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_221 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_247 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_742 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_222 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_248 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_745 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_249 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_748 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_250 = rand_strided((8, 72, 7, 7), (3528, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_751 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_223 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_251 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_754 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_224 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_252 = rand_strided((8, 18, 14, 14), (3528, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_757 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_225 = rand_strided((8, 18, 14, 14), (3528, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_253 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_760 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_254 = rand_strided((8, 36, 14, 14), (7056, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_763 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_226 = rand_strided((8, 36, 14, 14), (7056, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_255 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_766 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_256 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_769 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_227 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_257 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_772 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_228 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_258 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_775 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_229 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_259 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_778 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_230 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_260 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_781 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_231 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_261 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_784 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_232 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_262 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_787 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_233 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_263 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_790 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_234 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_264 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_793 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_235 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_265 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_796 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_236 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_266 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_799 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_237 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_267 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_802 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_238 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_268 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_805 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_239 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_269 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_808 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_240 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_270 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_811 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_241 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_271 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_814 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_242 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_272 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_817 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_243 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_273 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_820 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_244 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_274 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_823 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_245 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_275 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_826 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_246 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_276 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_829 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_247 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_277 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_832 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_248 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_278 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_835 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_249 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_279 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_838 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_250 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_280 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_841 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_251 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_281 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_844 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_252 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_282 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_847 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_253 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_283 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_850 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_254 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_284 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_853 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_255 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_285 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_856 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_256 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_286 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_859 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_257 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_287 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_862 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_258 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_288 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_865 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_259 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_289 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_868 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_290 = rand_strided((8, 18, 14, 14), (3528, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_871 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_291 = rand_strided((8, 18, 7, 7), (882, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_874 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_260 = rand_strided((8, 18, 56, 56), (56448, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_292 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_877 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_293 = rand_strided((8, 36, 14, 14), (7056, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_880 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_294 = rand_strided((8, 36, 7, 7), (1764, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_883 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_261 = rand_strided((8, 36, 28, 28), (28224, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_295 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_886 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_262 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_296 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_889 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_297 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_892 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_298 = rand_strided((8, 72, 7, 7), (3528, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_895 = rand_strided((72, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_263 = rand_strided((8, 72, 14, 14), (14112, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_299 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_898 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_264 = rand_strided((8, 18, 28, 28), (14112, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_300 = rand_strided((8, 18, 14, 14), (3528, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_901 = rand_strided((18, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_265 = rand_strided((8, 18, 14, 14), (3528, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_301 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_904 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_302 = rand_strided((8, 36, 14, 14), (7056, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_907 = rand_strided((36, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_266 = rand_strided((8, 36, 14, 14), (7056, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_303 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_910 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_304 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_913 = rand_strided((144, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_267 = rand_strided((8, 144, 7, 7), (7056, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_305 = rand_strided((8, 32, 56, 56), (100352, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_916 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_268 = rand_strided((8, 32, 56, 56), (100352, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_306 = rand_strided((8, 32, 56, 56), (100352, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_919 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_269 = rand_strided((8, 32, 56, 56), (100352, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_307 = rand_strided((8, 128, 56, 56), (401408, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_922 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_308 = rand_strided((8, 128, 56, 56), (401408, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    squeeze_925 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_270 = rand_strided((8, 128, 56, 56), (401408, 3136, 56, 1), device='cuda:0', dtype=torch.float32)
    convolution_309 = rand_strided((8, 64, 28, 28), (50176, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_928 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_271 = rand_strided((8, 64, 28, 28), (50176, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_310 = rand_strided((8, 64, 28, 28), (50176, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_931 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_272 = rand_strided((8, 64, 28, 28), (50176, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_311 = rand_strided((8, 256, 28, 28), (200704, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_934 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_312 = rand_strided((8, 256, 28, 28), (200704, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_937 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_313 = rand_strided((8, 256, 28, 28), (200704, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    squeeze_940 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    add_1866 = rand_strided((8, 256, 28, 28), (200704, 784, 28, 1), device='cuda:0', dtype=torch.float32)
    convolution_314 = rand_strided((8, 128, 14, 14), (25088, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_943 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_275 = rand_strided((8, 128, 14, 14), (25088, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_315 = rand_strided((8, 128, 14, 14), (25088, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_946 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_276 = rand_strided((8, 128, 14, 14), (25088, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_316 = rand_strided((8, 512, 14, 14), (100352, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_949 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_317 = rand_strided((8, 512, 14, 14), (100352, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_952 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_318 = rand_strided((8, 512, 14, 14), (100352, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    squeeze_955 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
    add_1893 = rand_strided((8, 512, 14, 14), (100352, 196, 14, 1), device='cuda:0', dtype=torch.float32)
    convolution_319 = rand_strided((8, 256, 7, 7), (12544, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_958 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_279 = rand_strided((8, 256, 7, 7), (12544, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_320 = rand_strided((8, 256, 7, 7), (12544, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_961 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
    relu_280 = rand_strided((8, 256, 7, 7), (12544, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_321 = rand_strided((8, 1024, 7, 7), (50176, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_964 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_322 = rand_strided((8, 1024, 7, 7), (50176, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_967 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    convolution_323 = rand_strided((8, 1024, 7, 7), (50176, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_970 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
    add_1920 = rand_strided((8, 1024, 7, 7), (50176, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    convolution_324 = rand_strided((8, 2048, 7, 7), (100352, 49, 7, 1), device='cuda:0', dtype=torch.float32)
    squeeze_973 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
    clone = rand_strided((8, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
    permute_1 = rand_strided((1000, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
    le = rand_strided((8, 2048, 7, 7), (100352, 49, 7, 1), device='cuda:0', dtype=torch.bool)
    unsqueeze_1333 = rand_strided((1, 2048, 1, 1), (2048, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    le_1 = rand_strided((8, 1024, 7, 7), (50176, 49, 7, 1), device='cuda:0', dtype=torch.bool)
    unsqueeze_1345 = rand_strided((1, 1024, 1, 1), (1024, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    le_2 = rand_strided((8, 1024, 7, 7), (50176, 49, 7, 1), device='cuda:0', dtype=torch.bool)
    unsqueeze_1357 = rand_strided((1, 1024, 1, 1), (1024, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1369 = rand_strided((1, 1024, 1, 1), (1024, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1381 = rand_strided((1, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1393 = rand_strided((1, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    le_5 = rand_strided((8, 512, 14, 14), (100352, 196, 14, 1), device='cuda:0', dtype=torch.bool)
    unsqueeze_1405 = rand_strided((1, 512, 1, 1), (512, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    le_6 = rand_strided((8, 512, 14, 14), (100352, 196, 14, 1), device='cuda:0', dtype=torch.bool)
    unsqueeze_1417 = rand_strided((1, 512, 1, 1), (512, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1429 = rand_strided((1, 512, 1, 1), (512, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1441 = rand_strided((1, 128, 1, 1), (128, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1453 = rand_strided((1, 128, 1, 1), (128, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    le_9 = rand_strided((8, 256, 28, 28), (200704, 784, 28, 1), device='cuda:0', dtype=torch.bool)
    unsqueeze_1465 = rand_strided((1, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    le_10 = rand_strided((8, 256, 28, 28), (200704, 784, 28, 1), device='cuda:0', dtype=torch.bool)
    unsqueeze_1477 = rand_strided((1, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1489 = rand_strided((1, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1501 = rand_strided((1, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1513 = rand_strided((1, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1525 = rand_strided((1, 128, 1, 1), (128, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1537 = rand_strided((1, 128, 1, 1), (128, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1549 = rand_strided((1, 32, 1, 1), (32, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1561 = rand_strided((1, 32, 1, 1), (32, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1573 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1585 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1597 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1609 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1621 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1633 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1645 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1657 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1669 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1681 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1693 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1705 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1717 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1729 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1741 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1753 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1765 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1777 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1789 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1801 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1813 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1825 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1837 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1849 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1861 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1873 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1885 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1897 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1909 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1921 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1933 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1945 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1957 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1969 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1981 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_1993 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2005 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2017 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2029 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2041 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2053 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2065 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2077 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2089 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2101 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2113 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2125 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2137 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2149 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2161 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2173 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2185 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2197 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2209 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2221 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2233 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2245 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2257 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2269 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2281 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2293 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2305 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2317 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2329 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2341 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2353 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2365 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2377 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2389 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2401 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2413 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2425 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2437 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2449 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2461 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2473 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2485 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2497 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2509 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2521 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2533 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2545 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2557 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2569 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2581 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2593 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2605 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2617 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2629 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2641 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2653 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2665 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2677 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2689 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2701 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2713 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2725 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2737 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2749 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2761 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2773 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2785 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2797 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2809 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2821 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2833 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2845 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2857 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2869 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2881 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2893 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2905 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2917 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2929 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2941 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2953 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2965 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2977 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_2989 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3001 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3013 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3025 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3037 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3049 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3061 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3073 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3085 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3097 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3109 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3121 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3133 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3145 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3157 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3169 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3181 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3193 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3205 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3217 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3229 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3241 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3253 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3265 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3277 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3289 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3301 = rand_strided((1, 144, 1, 1), (144, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3313 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3325 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3337 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3349 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3361 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3373 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3385 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3397 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3409 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3421 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3433 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3445 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3457 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3469 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3481 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3493 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3505 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3517 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3529 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3541 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3553 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3565 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3577 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3589 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3601 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3613 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3625 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3637 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3649 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3661 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3673 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3685 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3697 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3709 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3721 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3733 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3745 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3757 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3769 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3781 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3793 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3805 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3817 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3829 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3841 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3853 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3865 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3877 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3889 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3901 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3913 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3925 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3937 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3949 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3961 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3973 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3985 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_3997 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4009 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4021 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4033 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4045 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4057 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4069 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4081 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4093 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4105 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4117 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4129 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4141 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4153 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4165 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4177 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4189 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4201 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4213 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4225 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4237 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4249 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4261 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4273 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4285 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4297 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4309 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4321 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4333 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4345 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4357 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4369 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4381 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4393 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4405 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4417 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4429 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4441 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4453 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4465 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4477 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4489 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4501 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4513 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4525 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4537 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4549 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4561 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4573 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4585 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4597 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4609 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4621 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4633 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4645 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4657 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4669 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4681 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4693 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4705 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4717 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4729 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4741 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4753 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4765 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4777 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4789 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4801 = rand_strided((1, 72, 1, 1), (72, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4813 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4825 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4837 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4849 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4861 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4873 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4885 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4897 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4909 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4921 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4933 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4945 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4957 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4969 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4981 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_4993 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5005 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5017 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5029 = rand_strided((1, 36, 1, 1), (36, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5041 = rand_strided((1, 18, 1, 1), (18, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5053 = rand_strided((1, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5065 = rand_strided((1, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5077 = rand_strided((1, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5089 = rand_strided((1, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5101 = rand_strided((1, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5113 = rand_strided((1, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5125 = rand_strided((1, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5137 = rand_strided((1, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5149 = rand_strided((1, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5161 = rand_strided((1, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5173 = rand_strided((1, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5185 = rand_strided((1, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5197 = rand_strided((1, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5209 = rand_strided((1, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    unsqueeze_5221 = rand_strided((1, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
    tangents_1 = rand_strided((8, 1000), (1000, 1), device='cuda:0', dtype=torch.float32)
    return print_performance(lambda: call([primals_1, primals_2, primals_4, primals_5, primals_7, primals_8, primals_10, primals_11, primals_13, primals_14, primals_16, primals_17, primals_19, primals_20, primals_22, primals_23, primals_25, primals_26, primals_28, primals_29, primals_31, primals_32, primals_34, primals_35, primals_37, primals_38, primals_40, primals_41, primals_43, primals_44, primals_46, primals_47, primals_49, primals_50, primals_52, primals_53, primals_55, primals_56, primals_58, primals_59, primals_61, primals_62, primals_64, primals_65, primals_67, primals_68, primals_70, primals_71, primals_73, primals_74, primals_76, primals_77, primals_79, primals_80, primals_82, primals_83, primals_85, primals_86, primals_88, primals_89, primals_91, primals_92, primals_94, primals_95, primals_97, primals_98, primals_100, primals_101, primals_103, primals_104, primals_106, primals_107, primals_109, primals_110, primals_112, primals_113, primals_115, primals_116, primals_118, primals_119, primals_121, primals_122, primals_124, primals_125, primals_127, primals_128, primals_130, primals_131, primals_133, primals_134, primals_136, primals_137, primals_139, primals_140, primals_142, primals_143, primals_145, primals_146, primals_148, primals_149, primals_151, primals_152, primals_154, primals_155, primals_157, primals_158, primals_160, primals_161, primals_163, primals_164, primals_166, primals_167, primals_169, primals_170, primals_172, primals_173, primals_175, primals_176, primals_178, primals_179, primals_181, primals_182, primals_184, primals_185, primals_187, primals_188, primals_190, primals_191, primals_193, primals_194, primals_196, primals_197, primals_199, primals_200, primals_202, primals_203, primals_205, primals_206, primals_208, primals_209, primals_211, primals_212, primals_214, primals_215, primals_217, primals_218, primals_220, primals_221, primals_223, primals_224, primals_226, primals_227, primals_229, primals_230, primals_232, primals_233, primals_235, primals_236, primals_238, primals_239, primals_241, primals_242, primals_244, primals_245, primals_247, primals_248, primals_250, primals_251, primals_253, primals_254, primals_256, primals_257, primals_259, primals_260, primals_262, primals_263, primals_265, primals_266, primals_268, primals_269, primals_271, primals_272, primals_274, primals_275, primals_277, primals_278, primals_280, primals_281, primals_283, primals_284, primals_286, primals_287, primals_289, primals_290, primals_292, primals_293, primals_295, primals_296, primals_298, primals_299, primals_301, primals_302, primals_304, primals_305, primals_307, primals_308, primals_310, primals_311, primals_313, primals_314, primals_316, primals_317, primals_319, primals_320, primals_322, primals_323, primals_325, primals_326, primals_328, primals_329, primals_331, primals_332, primals_334, primals_335, primals_337, primals_338, primals_340, primals_341, primals_343, primals_344, primals_346, primals_347, primals_349, primals_350, primals_352, primals_353, primals_355, primals_356, primals_358, primals_359, primals_361, primals_362, primals_364, primals_365, primals_367, primals_368, primals_370, primals_371, primals_373, primals_374, primals_376, primals_377, primals_379, primals_380, primals_382, primals_383, primals_385, primals_386, primals_388, primals_389, primals_391, primals_392, primals_394, primals_395, primals_397, primals_398, primals_400, primals_401, primals_403, primals_404, primals_406, primals_407, primals_409, primals_410, primals_412, primals_413, primals_415, primals_416, primals_418, primals_419, primals_421, primals_422, primals_424, primals_425, primals_427, primals_428, primals_430, primals_431, primals_433, primals_434, primals_436, primals_437, primals_439, primals_440, primals_442, primals_443, primals_445, primals_446, primals_448, primals_449, primals_451, primals_452, primals_454, primals_455, primals_457, primals_458, primals_460, primals_461, primals_463, primals_464, primals_466, primals_467, primals_469, primals_470, primals_472, primals_473, primals_475, primals_476, primals_478, primals_479, primals_481, primals_482, primals_484, primals_485, primals_487, primals_488, primals_490, primals_491, primals_493, primals_494, primals_496, primals_497, primals_499, primals_500, primals_502, primals_503, primals_505, primals_506, primals_508, primals_509, primals_511, primals_512, primals_514, primals_515, primals_517, primals_518, primals_520, primals_521, primals_523, primals_524, primals_526, primals_527, primals_529, primals_530, primals_532, primals_533, primals_535, primals_536, primals_538, primals_539, primals_541, primals_542, primals_544, primals_545, primals_547, primals_548, primals_550, primals_551, primals_553, primals_554, primals_556, primals_557, primals_559, primals_560, primals_562, primals_563, primals_565, primals_566, primals_568, primals_569, primals_571, primals_572, primals_574, primals_575, primals_577, primals_578, primals_580, primals_581, primals_583, primals_584, primals_586, primals_587, primals_589, primals_590, primals_592, primals_593, primals_595, primals_596, primals_598, primals_599, primals_601, primals_602, primals_604, primals_605, primals_607, primals_608, primals_610, primals_611, primals_613, primals_614, primals_616, primals_617, primals_619, primals_620, primals_622, primals_623, primals_625, primals_626, primals_628, primals_629, primals_631, primals_632, primals_634, primals_635, primals_637, primals_638, primals_640, primals_641, primals_643, primals_644, primals_646, primals_647, primals_649, primals_650, primals_652, primals_653, primals_655, primals_656, primals_658, primals_659, primals_661, primals_662, primals_664, primals_665, primals_667, primals_668, primals_670, primals_671, primals_673, primals_674, primals_676, primals_677, primals_679, primals_680, primals_682, primals_683, primals_685, primals_686, primals_688, primals_689, primals_691, primals_692, primals_694, primals_695, primals_697, primals_698, primals_700, primals_701, primals_703, primals_704, primals_706, primals_707, primals_709, primals_710, primals_712, primals_713, primals_715, primals_716, primals_718, primals_719, primals_721, primals_722, primals_724, primals_725, primals_727, primals_728, primals_730, primals_731, primals_733, primals_734, primals_736, primals_737, primals_739, primals_740, primals_742, primals_743, primals_745, primals_746, primals_748, primals_749, primals_751, primals_752, primals_754, primals_755, primals_757, primals_758, primals_760, primals_761, primals_763, primals_764, primals_766, primals_767, primals_769, primals_770, primals_772, primals_773, primals_775, primals_776, primals_778, primals_779, primals_781, primals_782, primals_784, primals_785, primals_787, primals_788, primals_790, primals_791, primals_793, primals_794, primals_796, primals_797, primals_799, primals_800, primals_802, primals_803, primals_805, primals_806, primals_808, primals_809, primals_811, primals_812, primals_814, primals_815, primals_817, primals_818, primals_820, primals_821, primals_823, primals_824, primals_826, primals_827, primals_829, primals_830, primals_832, primals_833, primals_835, primals_836, primals_838, primals_839, primals_841, primals_842, primals_844, primals_845, primals_847, primals_848, primals_850, primals_851, primals_853, primals_854, primals_856, primals_857, primals_859, primals_860, primals_862, primals_863, primals_865, primals_866, primals_868, primals_869, primals_871, primals_872, primals_874, primals_875, primals_877, primals_878, primals_880, primals_881, primals_883, primals_884, primals_886, primals_887, primals_889, primals_890, primals_892, primals_893, primals_895, primals_896, primals_898, primals_899, primals_901, primals_902, primals_904, primals_905, primals_907, primals_908, primals_910, primals_911, primals_913, primals_914, primals_916, primals_917, primals_919, primals_920, primals_922, primals_923, primals_925, primals_926, primals_928, primals_929, primals_931, primals_932, primals_934, primals_935, primals_937, primals_938, primals_940, primals_942, primals_944, primals_945, primals_947, primals_948, primals_950, primals_951, primals_953, primals_954, primals_956, primals_958, primals_960, primals_961, primals_963, primals_964, primals_966, primals_967, primals_969, primals_970, primals_972, primals_974, primals_976, primals_978, primals_1957, convolution, squeeze_1, relu, convolution_1, squeeze_4, relu_1, convolution_2, squeeze_7, relu_2, convolution_3, squeeze_10, relu_3, convolution_4, squeeze_13, convolution_5, squeeze_16, relu_4, convolution_6, squeeze_19, relu_5, convolution_7, squeeze_22, relu_6, convolution_8, squeeze_25, relu_7, convolution_9, squeeze_28, relu_8, convolution_10, squeeze_31, relu_9, convolution_11, squeeze_34, relu_10, convolution_12, squeeze_37, relu_11, convolution_13, squeeze_40, relu_12, convolution_14, squeeze_43, relu_13, convolution_15, squeeze_46, relu_14, convolution_16, squeeze_49, relu_15, convolution_17, squeeze_52, relu_16, convolution_18, squeeze_55, relu_17, convolution_19, squeeze_58, relu_18, convolution_20, squeeze_61, relu_19, convolution_21, squeeze_64, relu_20, convolution_22, squeeze_67, relu_21, convolution_23, squeeze_70, relu_22, convolution_24, squeeze_73, relu_23, convolution_25, squeeze_76, relu_24, convolution_26, squeeze_79, relu_25, convolution_27, squeeze_82, relu_26, convolution_28, squeeze_85, relu_27, convolution_29, squeeze_88, relu_28, convolution_30, squeeze_91, relu_29, convolution_31, squeeze_94, relu_30, convolution_32, squeeze_97, relu_31, convolution_33, squeeze_100, convert_element_type_1, unsqueeze_136, relu_32, convolution_34, squeeze_103, relu_33, convolution_35, squeeze_106, relu_34, convolution_36, squeeze_109, relu_35, convolution_37, squeeze_112, relu_36, convolution_38, squeeze_115, relu_37, convolution_39, squeeze_118, relu_38, convolution_40, squeeze_121, relu_39, convolution_41, squeeze_124, relu_40, convolution_42, squeeze_127, relu_41, convolution_43, squeeze_130, relu_42, convolution_44, squeeze_133, relu_43, convolution_45, squeeze_136, relu_44, convolution_46, squeeze_139, relu_45, convolution_47, squeeze_142, relu_46, convolution_48, squeeze_145, relu_47, convolution_49, squeeze_148, relu_48, convolution_50, squeeze_151, relu_49, convolution_51, squeeze_154, relu_50, convolution_52, squeeze_157, relu_51, convolution_53, squeeze_160, relu_52, convolution_54, squeeze_163, relu_53, convolution_55, squeeze_166, relu_54, convolution_56, squeeze_169, relu_55, convolution_57, squeeze_172, relu_56, convolution_58, squeeze_175, relu_57, convolution_59, squeeze_178, relu_58, convolution_60, squeeze_181, convolution_61, squeeze_184, convert_element_type_9, unsqueeze_250, relu_59, convolution_62, squeeze_187, convolution_63, squeeze_190, convert_element_type_13, unsqueeze_259, relu_60, convolution_64, squeeze_193, relu_61, convolution_65, squeeze_196, convolution_66, squeeze_199, relu_62, convolution_67, squeeze_202, relu_63, convolution_68, squeeze_205, relu_64, convolution_69, squeeze_208, relu_65, convolution_70, squeeze_211, relu_66, convolution_71, squeeze_214, relu_67, convolution_72, squeeze_217, relu_68, convolution_73, squeeze_220, relu_69, convolution_74, squeeze_223, relu_70, convolution_75, squeeze_226, relu_71, convolution_76, squeeze_229, relu_72, convolution_77, squeeze_232, relu_73, convolution_78, squeeze_235, relu_74, convolution_79, squeeze_238, relu_75, convolution_80, squeeze_241, relu_76, convolution_81, squeeze_244, relu_77, convolution_82, squeeze_247, relu_78, convolution_83, squeeze_250, relu_79, convolution_84, squeeze_253, relu_80, convolution_85, squeeze_256, relu_81, convolution_86, squeeze_259, relu_82, convolution_87, squeeze_262, relu_83, convolution_88, squeeze_265, relu_84, convolution_89, squeeze_268, relu_85, convolution_90, squeeze_271, relu_86, convolution_91, squeeze_274, convolution_92, squeeze_277, relu_87, convolution_93, squeeze_280, convolution_94, squeeze_283, relu_88, convolution_95, squeeze_286, relu_89, convolution_96, squeeze_289, convolution_97, squeeze_292, relu_90, convolution_98, squeeze_295, relu_91, convolution_99, squeeze_298, relu_92, convolution_100, squeeze_301, relu_93, convolution_101, squeeze_304, relu_94, convolution_102, squeeze_307, relu_95, convolution_103, squeeze_310, relu_96, convolution_104, squeeze_313, relu_97, convolution_105, squeeze_316, relu_98, convolution_106, squeeze_319, relu_99, convolution_107, squeeze_322, relu_100, convolution_108, squeeze_325, relu_101, convolution_109, squeeze_328, relu_102, convolution_110, squeeze_331, relu_103, convolution_111, squeeze_334, relu_104, convolution_112, squeeze_337, relu_105, convolution_113, squeeze_340, relu_106, convolution_114, squeeze_343, relu_107, convolution_115, squeeze_346, relu_108, convolution_116, squeeze_349, relu_109, convolution_117, squeeze_352, relu_110, convolution_118, squeeze_355, relu_111, convolution_119, squeeze_358, relu_112, convolution_120, squeeze_361, relu_113, convolution_121, squeeze_364, relu_114, convolution_122, squeeze_367, convolution_123, squeeze_370, relu_115, convolution_124, squeeze_373, convolution_125, squeeze_376, relu_116, convolution_126, squeeze_379, relu_117, convolution_127, squeeze_382, convolution_128, squeeze_385, relu_118, convolution_129, squeeze_388, relu_119, convolution_130, squeeze_391, relu_120, convolution_131, squeeze_394, relu_121, convolution_132, squeeze_397, relu_122, convolution_133, squeeze_400, relu_123, convolution_134, squeeze_403, relu_124, convolution_135, squeeze_406, relu_125, convolution_136, squeeze_409, relu_126, convolution_137, squeeze_412, relu_127, convolution_138, squeeze_415, relu_128, convolution_139, squeeze_418, relu_129, convolution_140, squeeze_421, relu_130, convolution_141, squeeze_424, relu_131, convolution_142, squeeze_427, relu_132, convolution_143, squeeze_430, relu_133, convolution_144, squeeze_433, relu_134, convolution_145, squeeze_436, relu_135, convolution_146, squeeze_439, relu_136, convolution_147, squeeze_442, relu_137, convolution_148, squeeze_445, relu_138, convolution_149, squeeze_448, relu_139, convolution_150, squeeze_451, relu_140, convolution_151, squeeze_454, relu_141, convolution_152, squeeze_457, relu_142, convolution_153, squeeze_460, convolution_154, squeeze_463, relu_143, convolution_155, squeeze_466, convolution_156, squeeze_469, relu_144, convolution_157, squeeze_472, relu_145, convolution_158, squeeze_475, convolution_159, squeeze_478, relu_146, convolution_160, squeeze_481, relu_147, convolution_161, squeeze_484, relu_148, convolution_162, squeeze_487, relu_149, convolution_163, squeeze_490, relu_150, convolution_164, squeeze_493, relu_151, convolution_165, squeeze_496, relu_152, convolution_166, squeeze_499, relu_153, convolution_167, squeeze_502, relu_154, convolution_168, squeeze_505, relu_155, convolution_169, squeeze_508, relu_156, convolution_170, squeeze_511, relu_157, convolution_171, squeeze_514, relu_158, convolution_172, squeeze_517, relu_159, convolution_173, squeeze_520, relu_160, convolution_174, squeeze_523, relu_161, convolution_175, squeeze_526, relu_162, convolution_176, squeeze_529, relu_163, convolution_177, squeeze_532, relu_164, convolution_178, squeeze_535, relu_165, convolution_179, squeeze_538, relu_166, convolution_180, squeeze_541, relu_167, convolution_181, squeeze_544, relu_168, convolution_182, squeeze_547, relu_169, convolution_183, squeeze_550, relu_170, convolution_184, squeeze_553, relu_171, convolution_185, squeeze_556, relu_172, convolution_186, squeeze_559, relu_173, convolution_187, squeeze_562, relu_174, convolution_188, squeeze_565, relu_175, convolution_189, squeeze_568, relu_176, convolution_190, squeeze_571, relu_177, convolution_191, squeeze_574, relu_178, convolution_192, squeeze_577, relu_179, convolution_193, squeeze_580, convolution_194, squeeze_583, convolution_195, squeeze_586, convert_element_type_61, unsqueeze_799, relu_180, convolution_196, squeeze_589, convolution_197, squeeze_592, convolution_198, squeeze_595, convert_element_type_69, unsqueeze_813, relu_181, convolution_199, squeeze_598, relu_182, convolution_200, squeeze_601, convolution_201, squeeze_604, convolution_202, squeeze_607, convert_element_type_73, unsqueeze_830, relu_183, convolution_203, squeeze_610, relu_184, convolution_204, squeeze_613, relu_185, convolution_205, squeeze_616, convolution_206, squeeze_619, relu_186, convolution_207, squeeze_622, convolution_208, squeeze_625, relu_187, convolution_209, squeeze_628, relu_188, convolution_210, squeeze_631, relu_189, convolution_211, squeeze_634, relu_190, convolution_212, squeeze_637, relu_191, convolution_213, squeeze_640, relu_192, convolution_214, squeeze_643, relu_193, convolution_215, squeeze_646, relu_194, convolution_216, squeeze_649, relu_195, convolution_217, squeeze_652, relu_196, convolution_218, squeeze_655, relu_197, convolution_219, squeeze_658, relu_198, convolution_220, squeeze_661, relu_199, convolution_221, squeeze_664, relu_200, convolution_222, squeeze_667, relu_201, convolution_223, squeeze_670, relu_202, convolution_224, squeeze_673, relu_203, convolution_225, squeeze_676, relu_204, convolution_226, squeeze_679, relu_205, convolution_227, squeeze_682, relu_206, convolution_228, squeeze_685, relu_207, convolution_229, squeeze_688, relu_208, convolution_230, squeeze_691, relu_209, convolution_231, squeeze_694, relu_210, convolution_232, squeeze_697, relu_211, convolution_233, squeeze_700, relu_212, convolution_234, squeeze_703, relu_213, convolution_235, squeeze_706, relu_214, convolution_236, squeeze_709, relu_215, convolution_237, squeeze_712, relu_216, convolution_238, squeeze_715, relu_217, convolution_239, squeeze_718, relu_218, convolution_240, squeeze_721, relu_219, convolution_241, squeeze_724, convolution_242, squeeze_727, convolution_243, squeeze_730, relu_220, convolution_244, squeeze_733, convolution_245, squeeze_736, convolution_246, squeeze_739, relu_221, convolution_247, squeeze_742, relu_222, convolution_248, squeeze_745, convolution_249, squeeze_748, convolution_250, squeeze_751, relu_223, convolution_251, squeeze_754, relu_224, convolution_252, squeeze_757, relu_225, convolution_253, squeeze_760, convolution_254, squeeze_763, relu_226, convolution_255, squeeze_766, convolution_256, squeeze_769, relu_227, convolution_257, squeeze_772, relu_228, convolution_258, squeeze_775, relu_229, convolution_259, squeeze_778, relu_230, convolution_260, squeeze_781, relu_231, convolution_261, squeeze_784, relu_232, convolution_262, squeeze_787, relu_233, convolution_263, squeeze_790, relu_234, convolution_264, squeeze_793, relu_235, convolution_265, squeeze_796, relu_236, convolution_266, squeeze_799, relu_237, convolution_267, squeeze_802, relu_238, convolution_268, squeeze_805, relu_239, convolution_269, squeeze_808, relu_240, convolution_270, squeeze_811, relu_241, convolution_271, squeeze_814, relu_242, convolution_272, squeeze_817, relu_243, convolution_273, squeeze_820, relu_244, convolution_274, squeeze_823, relu_245, convolution_275, squeeze_826, relu_246, convolution_276, squeeze_829, relu_247, convolution_277, squeeze_832, relu_248, convolution_278, squeeze_835, relu_249, convolution_279, squeeze_838, relu_250, convolution_280, squeeze_841, relu_251, convolution_281, squeeze_844, relu_252, convolution_282, squeeze_847, relu_253, convolution_283, squeeze_850, relu_254, convolution_284, squeeze_853, relu_255, convolution_285, squeeze_856, relu_256, convolution_286, squeeze_859, relu_257, convolution_287, squeeze_862, relu_258, convolution_288, squeeze_865, relu_259, convolution_289, squeeze_868, convolution_290, squeeze_871, convolution_291, squeeze_874, relu_260, convolution_292, squeeze_877, convolution_293, squeeze_880, convolution_294, squeeze_883, relu_261, convolution_295, squeeze_886, relu_262, convolution_296, squeeze_889, convolution_297, squeeze_892, convolution_298, squeeze_895, relu_263, convolution_299, squeeze_898, relu_264, convolution_300, squeeze_901, relu_265, convolution_301, squeeze_904, convolution_302, squeeze_907, relu_266, convolution_303, squeeze_910, convolution_304, squeeze_913, relu_267, convolution_305, squeeze_916, relu_268, convolution_306, squeeze_919, relu_269, convolution_307, squeeze_922, convolution_308, squeeze_925, relu_270, convolution_309, squeeze_928, relu_271, convolution_310, squeeze_931, relu_272, convolution_311, squeeze_934, convolution_312, squeeze_937, convolution_313, squeeze_940, add_1866, convolution_314, squeeze_943, relu_275, convolution_315, squeeze_946, relu_276, convolution_316, squeeze_949, convolution_317, squeeze_952, convolution_318, squeeze_955, add_1893, convolution_319, squeeze_958, relu_279, convolution_320, squeeze_961, relu_280, convolution_321, squeeze_964, convolution_322, squeeze_967, convolution_323, squeeze_970, add_1920, convolution_324, squeeze_973, clone, permute_1, le, unsqueeze_1333, le_1, unsqueeze_1345, le_2, unsqueeze_1357, unsqueeze_1369, unsqueeze_1381, unsqueeze_1393, le_5, unsqueeze_1405, le_6, unsqueeze_1417, unsqueeze_1429, unsqueeze_1441, unsqueeze_1453, le_9, unsqueeze_1465, le_10, unsqueeze_1477, unsqueeze_1489, unsqueeze_1501, unsqueeze_1513, unsqueeze_1525, unsqueeze_1537, unsqueeze_1549, unsqueeze_1561, unsqueeze_1573, unsqueeze_1585, unsqueeze_1597, unsqueeze_1609, unsqueeze_1621, unsqueeze_1633, unsqueeze_1645, unsqueeze_1657, unsqueeze_1669, unsqueeze_1681, unsqueeze_1693, unsqueeze_1705, unsqueeze_1717, unsqueeze_1729, unsqueeze_1741, unsqueeze_1753, unsqueeze_1765, unsqueeze_1777, unsqueeze_1789, unsqueeze_1801, unsqueeze_1813, unsqueeze_1825, unsqueeze_1837, unsqueeze_1849, unsqueeze_1861, unsqueeze_1873, unsqueeze_1885, unsqueeze_1897, unsqueeze_1909, unsqueeze_1921, unsqueeze_1933, unsqueeze_1945, unsqueeze_1957, unsqueeze_1969, unsqueeze_1981, unsqueeze_1993, unsqueeze_2005, unsqueeze_2017, unsqueeze_2029, unsqueeze_2041, unsqueeze_2053, unsqueeze_2065, unsqueeze_2077, unsqueeze_2089, unsqueeze_2101, unsqueeze_2113, unsqueeze_2125, unsqueeze_2137, unsqueeze_2149, unsqueeze_2161, unsqueeze_2173, unsqueeze_2185, unsqueeze_2197, unsqueeze_2209, unsqueeze_2221, unsqueeze_2233, unsqueeze_2245, unsqueeze_2257, unsqueeze_2269, unsqueeze_2281, unsqueeze_2293, unsqueeze_2305, unsqueeze_2317, unsqueeze_2329, unsqueeze_2341, unsqueeze_2353, unsqueeze_2365, unsqueeze_2377, unsqueeze_2389, unsqueeze_2401, unsqueeze_2413, unsqueeze_2425, unsqueeze_2437, unsqueeze_2449, unsqueeze_2461, unsqueeze_2473, unsqueeze_2485, unsqueeze_2497, unsqueeze_2509, unsqueeze_2521, unsqueeze_2533, unsqueeze_2545, unsqueeze_2557, unsqueeze_2569, unsqueeze_2581, unsqueeze_2593, unsqueeze_2605, unsqueeze_2617, unsqueeze_2629, unsqueeze_2641, unsqueeze_2653, unsqueeze_2665, unsqueeze_2677, unsqueeze_2689, unsqueeze_2701, unsqueeze_2713, unsqueeze_2725, unsqueeze_2737, unsqueeze_2749, unsqueeze_2761, unsqueeze_2773, unsqueeze_2785, unsqueeze_2797, unsqueeze_2809, unsqueeze_2821, unsqueeze_2833, unsqueeze_2845, unsqueeze_2857, unsqueeze_2869, unsqueeze_2881, unsqueeze_2893, unsqueeze_2905, unsqueeze_2917, unsqueeze_2929, unsqueeze_2941, unsqueeze_2953, unsqueeze_2965, unsqueeze_2977, unsqueeze_2989, unsqueeze_3001, unsqueeze_3013, unsqueeze_3025, unsqueeze_3037, unsqueeze_3049, unsqueeze_3061, unsqueeze_3073, unsqueeze_3085, unsqueeze_3097, unsqueeze_3109, unsqueeze_3121, unsqueeze_3133, unsqueeze_3145, unsqueeze_3157, unsqueeze_3169, unsqueeze_3181, unsqueeze_3193, unsqueeze_3205, unsqueeze_3217, unsqueeze_3229, unsqueeze_3241, unsqueeze_3253, unsqueeze_3265, unsqueeze_3277, unsqueeze_3289, unsqueeze_3301, unsqueeze_3313, unsqueeze_3325, unsqueeze_3337, unsqueeze_3349, unsqueeze_3361, unsqueeze_3373, unsqueeze_3385, unsqueeze_3397, unsqueeze_3409, unsqueeze_3421, unsqueeze_3433, unsqueeze_3445, unsqueeze_3457, unsqueeze_3469, unsqueeze_3481, unsqueeze_3493, unsqueeze_3505, unsqueeze_3517, unsqueeze_3529, unsqueeze_3541, unsqueeze_3553, unsqueeze_3565, unsqueeze_3577, unsqueeze_3589, unsqueeze_3601, unsqueeze_3613, unsqueeze_3625, unsqueeze_3637, unsqueeze_3649, unsqueeze_3661, unsqueeze_3673, unsqueeze_3685, unsqueeze_3697, unsqueeze_3709, unsqueeze_3721, unsqueeze_3733, unsqueeze_3745, unsqueeze_3757, unsqueeze_3769, unsqueeze_3781, unsqueeze_3793, unsqueeze_3805, unsqueeze_3817, unsqueeze_3829, unsqueeze_3841, unsqueeze_3853, unsqueeze_3865, unsqueeze_3877, unsqueeze_3889, unsqueeze_3901, unsqueeze_3913, unsqueeze_3925, unsqueeze_3937, unsqueeze_3949, unsqueeze_3961, unsqueeze_3973, unsqueeze_3985, unsqueeze_3997, unsqueeze_4009, unsqueeze_4021, unsqueeze_4033, unsqueeze_4045, unsqueeze_4057, unsqueeze_4069, unsqueeze_4081, unsqueeze_4093, unsqueeze_4105, unsqueeze_4117, unsqueeze_4129, unsqueeze_4141, unsqueeze_4153, unsqueeze_4165, unsqueeze_4177, unsqueeze_4189, unsqueeze_4201, unsqueeze_4213, unsqueeze_4225, unsqueeze_4237, unsqueeze_4249, unsqueeze_4261, unsqueeze_4273, unsqueeze_4285, unsqueeze_4297, unsqueeze_4309, unsqueeze_4321, unsqueeze_4333, unsqueeze_4345, unsqueeze_4357, unsqueeze_4369, unsqueeze_4381, unsqueeze_4393, unsqueeze_4405, unsqueeze_4417, unsqueeze_4429, unsqueeze_4441, unsqueeze_4453, unsqueeze_4465, unsqueeze_4477, unsqueeze_4489, unsqueeze_4501, unsqueeze_4513, unsqueeze_4525, unsqueeze_4537, unsqueeze_4549, unsqueeze_4561, unsqueeze_4573, unsqueeze_4585, unsqueeze_4597, unsqueeze_4609, unsqueeze_4621, unsqueeze_4633, unsqueeze_4645, unsqueeze_4657, unsqueeze_4669, unsqueeze_4681, unsqueeze_4693, unsqueeze_4705, unsqueeze_4717, unsqueeze_4729, unsqueeze_4741, unsqueeze_4753, unsqueeze_4765, unsqueeze_4777, unsqueeze_4789, unsqueeze_4801, unsqueeze_4813, unsqueeze_4825, unsqueeze_4837, unsqueeze_4849, unsqueeze_4861, unsqueeze_4873, unsqueeze_4885, unsqueeze_4897, unsqueeze_4909, unsqueeze_4921, unsqueeze_4933, unsqueeze_4945, unsqueeze_4957, unsqueeze_4969, unsqueeze_4981, unsqueeze_4993, unsqueeze_5005, unsqueeze_5017, unsqueeze_5029, unsqueeze_5041, unsqueeze_5053, unsqueeze_5065, unsqueeze_5077, unsqueeze_5089, unsqueeze_5101, unsqueeze_5113, unsqueeze_5125, unsqueeze_5137, unsqueeze_5149, unsqueeze_5161, unsqueeze_5173, unsqueeze_5185, unsqueeze_5197, unsqueeze_5209, unsqueeze_5221, tangents_1]), times=times, repeat=repeat)


if __name__ == "__main__":
    from torch._inductor.wrapper_benchmark import compiled_module_main
    compiled_module_main('hrnet_w18', benchmark_compiled_module)
